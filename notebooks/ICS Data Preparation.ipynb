{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.style\n",
    "matplotlib.style.use(\"seaborn\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import seaborn as sn\n",
    "sn.color_palette(\"hls\", 17)\n",
    "import scipy.stats as st\n",
    "import math\n",
    "\n",
    "from pingouin import rcorr\n",
    "import pingouin as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from sys import platform\n",
    "if platform == \"darwin\":\n",
    "    sys.path.append(os.path.dirname(os.path.realpath(__file__)) + \"/..\")\n",
    "    smart_nlp_path = ''\n",
    "elif platform == \"win32\":\n",
    "    sys.path.append('../')\n",
    "    smart_nlp_path = os.getcwd()\n",
    "    smart_nlp_path = \"\\\\\".join([smart_nlp_path.split(\"\\\\\")[i] for i in range(0,len(smart_nlp_path.split(\"\\\\\"))-1)]+[\"/\"])\n",
    "\n",
    "from module.trend_analysis_functions import *\n",
    "from module.topic_model_plus_class import Topic_Model_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3050: DtypeWarning: Columns (7,13,18,19,36) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "incident_file = smart_nlp_path+r\"input data\\summary_reports_cleaned.csv\"\n",
    "incident_summary_df = pd.read_csv(incident_file)\n",
    "incident_summary_df = incident_summary_df.drop(\"Unnamed: 0\", axis=1)\n",
    "incident_summary_df = incident_summary_df.loc[incident_summary_df[\"START_YEAR\"]>=2006].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hazard Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3242: DtypeWarning: Columns (24) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data extracted from:  C:\\Users\\srandrad\\smart_nlp\\/\\input data\\ICS_filtered_preprocessed_data_extra_cols.csv\n"
     ]
    }
   ],
   "source": [
    "document_id_col = \"INCIDENT_ID\"\n",
    "extra_cols = [\"CY\",\"DISCOVERY_DATE\", \"START_YEAR\", \"REPORT_DOY\", \"DISCOVERY_DOY\",\n",
    "              \"TOTAL_PERSONNEL\", \"TOTAL_AERIAL\", \"PCT_CONTAINED_COMPLETED\"]\n",
    "list_of_attributes = [\"Combined Text\"]\n",
    "file = smart_nlp_path+r\"\\input data\\ICS_filtered_preprocessed_data_extra_cols.csv\"\n",
    "\n",
    "ICS = Topic_Model_plus(document_id_col=document_id_col, extra_cols=extra_cols, list_of_attributes=list_of_attributes, combine_cols=False)\n",
    "ICS.extract_preprocessed_data(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df = ICS.data_df\n",
    "hazard_file = smart_nlp_path+r\"\\output data\\hazard_interpretation_v2.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\openpyxl\\compat\\numbers.py:41: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  numpy.float,\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [05:01<00:00, 33.45s/it]\n"
     ]
    }
   ],
   "source": [
    "time_of_occurence_days, time_of_occurence_pct_contained, frequency, fires, frequency_fires, categories, hazards, years, ids = calc_metrics(hazard_file, preprocessed_df, rm_outliers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "to prepare the data for the models, we need to add new columns including: \n",
    "- Region - categorical\n",
    "- Hazard Occurence - one hot\n",
    "- Severity - continuous\n",
    "- Days Burning - continuous\n",
    "- Reports so far - continuous\n",
    "- total text from all reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = {'AICC':['AK'],\n",
    "          'EACC':['MN', 'IA', 'WI', 'IL', 'IN', 'MO', 'MI', 'OH', 'WV', 'PA',\n",
    "                 'NY', 'VT', 'NH', 'ME', 'MA', 'RI', 'CT', 'NJ', 'DE', 'MD'],\n",
    "          'GBCC':['NV', 'UT', {'ID':[\"46n\"]}],\n",
    "           'SACC': [{'TX':[\"100w\"]}, 'OK', 'AR', 'LA', 'MS', 'AL', 'GA', 'FL', 'SC', 'NC',\n",
    "                   'TN', 'KY', 'VA'],\n",
    "           'NWCC': ['OR','WA'],\n",
    "           'CA':['CA'], #OSCC and ONCC about 38 N\n",
    "           'NRCC':['MT', 'ND', {'ID':[\"46n\"]}],\n",
    "           'RMCC':['CO', 'WY', 'SD', 'KS', 'NE'],\n",
    "           'SWCC':['NM', 'AZ', {'TX':[\"100w\"]}],\n",
    "           'HICC':['HI']\n",
    "          }\n",
    "states = [state for region in regions for state in regions[region] if not isinstance(state,dict)]\n",
    "region_by_state = {state: region for state in states for region in regions if state in regions[region]}\n",
    "#region_by_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_states = {'TX':[(\"100\",'w'), ('less','SACC'), ('greater', 'SWCC')],\n",
    "                'ID':[(\"46\",\"n\"), ('less', 'GBCC'), ('greater', 'NRCC')]}\n",
    "direction_dict = {'n':'POO_LATITUDE', 's':'POO_LATITUDE', 'w':'POO_LONGITUDE', 'e':'POO_LONGITUDE'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2012', '004462', 'COPCO']\n"
     ]
    }
   ],
   "source": [
    "region_per_incident = []#{}\n",
    "for i in range(len(incident_summary_df)):\n",
    "    incident_region = None\n",
    "    id_ = incident_summary_df.iloc[i]['INCIDENT_ID']\n",
    "    state = incident_summary_df.iloc[i]['POO_STATE']\n",
    "    if isinstance(state, float):\n",
    "    #    print(id_)\n",
    "        id_ = id_.split(\"_\")\n",
    "        if len(id_)>1:\n",
    "            state = id_[1].split(\"-\")[0]\n",
    "            if len(state)>2:\n",
    "                state = 'CA'#only one instance of this manually checked and verified it is in california\n",
    "                print(id_)\n",
    "    if state in region_by_state:\n",
    "        incident_region = region_by_state[state]\n",
    "    elif state in split_states:\n",
    "        (pos, direct) = split_states[state][0]\n",
    "        incident_loc = float(incident_summary_df.iloc[i][direction_dict[direct]])\n",
    "        if incident_loc <= float(pos):\n",
    "            incident_region = split_states[state][1][1]\n",
    "        else:\n",
    "            incident_region = split_states[state][2][1]\n",
    "   \n",
    "    region_per_incident.append(incident_region)\n",
    "\n",
    "incident_summary_df['Incident_region'] = region_per_incident\n",
    "#incident_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sitrep_regions = []\n",
    "for i in range(len(preprocessed_df)):\n",
    "    rep_region = None\n",
    "    id_ = preprocessed_df.iloc[i]['INCIDENT_ID']\n",
    "    incident_df = incident_summary_df.loc[incident_summary_df['INCIDENT_ID']==id_].reset_index(drop=True)\n",
    "    if len(incident_df)>1: \n",
    "        print(\"multiple summary reports\")\n",
    "    else:\n",
    "        rep_region = incident_df.at[0,'Incident_region']\n",
    "    sitrep_regions.append(rep_region)\n",
    "preprocessed_df['Incident_region'] = sitrep_regions\n",
    "#preprocessed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Severity and Hazard Occurrence for sit reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fires_per_hazard = {hazard:[fire for year in fires[hazard] for fire in fires[hazard][year]] for hazard in fires}\n",
    "hazard_df_data = {hazard:[] for hazard in fires_per_hazard}\n",
    "incident_ids = preprocessed_df['INCIDENT_ID'].tolist()\n",
    "for hazard in fires_per_hazard:\n",
    "    for fire_id in incident_ids:\n",
    "        target = 0\n",
    "        if fire_id in fires_per_hazard[hazard]:\n",
    "            target = 1\n",
    "        hazard_df_data[hazard].append(target)\n",
    "for hazard in fires_per_hazard:\n",
    "    preprocessed_df[hazard] = hazard_df_data[hazard]\n",
    "#preprocessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_severity = []\n",
    "for i in range(len(preprocessed_df)):\n",
    "    severity = int(preprocessed_df.iloc[i]['FATALITIES']) + int(preprocessed_df.iloc[i]['INJURIES']) + int(preprocessed_df.iloc[i]['STR_DAMAGED']) +  int(preprocessed_df.iloc[i]['STR_DESTROYED'])\n",
    "    total_severity.append(severity)\n",
    "preprocessed_df['Severity'] = total_severity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Severity and Hazard occurence for summary reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fires_per_hazard = {hazard:[fire for year in fires[hazard] for fire in fires[hazard][year]] for hazard in fires}\n",
    "incident_ids = incident_summary_df['INCIDENT_ID'].tolist()\n",
    "hazards = [hazard.replace(\" \", \"_\") for hazard in fires_per_hazard]\n",
    "hazard_df_data = {hazard:[] for hazard in hazards}\n",
    "for hazard in hazards:\n",
    "    for fire_id in incident_ids:\n",
    "        target = 0\n",
    "        if fire_id in fires_per_hazard[hazard.replace(\"_\",\" \")]:\n",
    "            target = 1\n",
    "        hazard_df_data[hazard].append(target)\n",
    "for hazard in hazards:\n",
    "    incident_summary_df[hazard] = hazard_df_data[hazard]\n",
    "total_severity = []\n",
    "for i in range(len(incident_summary_df)):\n",
    "    severity = int(incident_summary_df.iloc[i]['FATALITIES']) + int(incident_summary_df.iloc[i]['INJURIES_TOTAL']) + int(incident_summary_df.iloc[i]['STR_DAMAGED_TOTAL']) +  int(incident_summary_df.iloc[i]['STR_DESTROYED_TOTAL'])\n",
    "    total_severity.append(severity)\n",
    "incident_summary_df['Severity'] = total_severity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Reports for incident so far & Days Burning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add col for num of reports so far and Days Burning\n",
    "reports_so_far = []\n",
    "days_burning_so_far = []\n",
    "for i in range(len(preprocessed_df)):\n",
    "    unique_id = preprocessed_df.iloc[i]['Unique IDs'].split(\"_\")[-1]\n",
    "    reports_so_far.append(int(unique_id))\n",
    "    #correct dates\n",
    "    time_of_hazard = int(preprocessed_df.iloc[i]['REPORT_DOY'])\n",
    "    start_date = int(preprocessed_df.iloc[i]['DISCOVERY_DOY'])\n",
    "    if time_of_hazard<start_date: \n",
    "        #print(\"dates corrected\")\n",
    "        if time_of_hazard<30 and start_date<330: #report day is days since start, not doy \n",
    "            time_of_hazard+=start_date\n",
    "        elif time_of_hazard<30 and start_date>=330:\n",
    "            start_date = start_date-365 #fire spans two years\n",
    "        else: #start and report day were incorrectly switched\n",
    "            temp_start = start_date\n",
    "            start_date = time_of_hazard\n",
    "            time_of_hazard = temp_start\n",
    "    days_burning_so_far.append(time_of_hazard-int(start_date))\n",
    "preprocessed_df['NUM_REPORTS'] = reports_so_far\n",
    "preprocessed_df['DAYS_BURING'] = days_burning_so_far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Text from incident reports so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 44363/44363 [00:17<00:00, 2609.21it/s]\n"
     ]
    }
   ],
   "source": [
    "total_text_so_far = []\n",
    "preprocessed_df['Total Incident Text'] = [[] for i in range(len(preprocessed_df))]\n",
    "prev_id = 0 \n",
    "for i in tqdm(range(len(preprocessed_df))):\n",
    "    incident_id = preprocessed_df.iloc[i]['INCIDENT_ID']\n",
    "    if prev_id == incident_id:\n",
    "        preprocessed_df.at[i,'Total Incident Text'] = preprocessed_df.iloc[i-1]['Total Incident Text'] + preprocessed_df.iloc[i]['Combined Text']\n",
    "    else:\n",
    "        preprocessed_df.at[i,'Total Incident Text'] = preprocessed_df.iloc[i]['Combined Text']\n",
    "    prev_id = incident_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CY</th>\n",
       "      <th>DISCOVERY_DATE</th>\n",
       "      <th>INCIDENT_ID</th>\n",
       "      <th>PCT_CONTAINED_COMPLETED</th>\n",
       "      <th>START_YEAR</th>\n",
       "      <th>TOTAL_AERIAL</th>\n",
       "      <th>TOTAL_PERSONNEL</th>\n",
       "      <th>REPORT_DOY</th>\n",
       "      <th>DISCOVERY_DOY</th>\n",
       "      <th>Combined Text</th>\n",
       "      <th>...</th>\n",
       "      <th>Infrastructure</th>\n",
       "      <th>Extreme Weather</th>\n",
       "      <th>Ecological</th>\n",
       "      <th>Hazardous Terrain</th>\n",
       "      <th>Floods</th>\n",
       "      <th>Dry Weather</th>\n",
       "      <th>Severity</th>\n",
       "      <th>NUM_REPORTS</th>\n",
       "      <th>DAYS_BURING</th>\n",
       "      <th>Total Incident Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>2010-07-15 15:00:00</td>\n",
       "      <td>2000_CA-RRU-062485_VALLEY COMPLEX</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "      <td>[resource, share, cactus]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[resource, share, cactus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>2010-07-15 15:00:00</td>\n",
       "      <td>2000_CA-RRU-062485_VALLEY COMPLEX</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "      <td>[resource, share, incident, cactus, incident, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[resource, share, cactus, resource, share, inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>2010-07-15 15:00:00</td>\n",
       "      <td>2000_CA-RRU-062485_VALLEY COMPLEX</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "      <td>[resource, share, cactus, erratic, wind, due, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[resource, share, cactus, resource, share, inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>2010-07-15 15:00:00</td>\n",
       "      <td>2000_CA-RRU-062485_VALLEY COMPLEX</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>192.333333</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "      <td>[resource, share, cactus, cactus, become, vall...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[resource, share, cactus, resource, share, inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>2010-07-15 15:00:00</td>\n",
       "      <td>2000_CA-RRU-062485_VALLEY COMPLEX</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>192.333333</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "      <td>[resource, share, cactus, cactus, become, vall...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[resource, share, cactus, resource, share, inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44358</th>\n",
       "      <td>2014</td>\n",
       "      <td>2014-03-15 14:30:00</td>\n",
       "      <td>2014_VAVAS1403037_BEAVER LODGE RD.</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>[fast, spread, field]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[fast, spread, field]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44359</th>\n",
       "      <td>2014</td>\n",
       "      <td>2014-03-19 14:00:00</td>\n",
       "      <td>2014_VAVAS1406037_AIRPORT MOUNTAIN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>80</td>\n",
       "      <td>78</td>\n",
       "      <td>[heavy, plume, primary, carrier]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[heavy, plume, primary, carrier]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44360</th>\n",
       "      <td>2014</td>\n",
       "      <td>2014-08-20 13:00:00</td>\n",
       "      <td>2014_WA-WFS-513_SAND RIDGE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>234</td>\n",
       "      <td>232</td>\n",
       "      <td>[heavy, canyon, river, mainly, canyon, come, e...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[heavy, canyon, river, mainly, canyon, come, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44361</th>\n",
       "      <td>2014</td>\n",
       "      <td>2014-08-20 13:00:00</td>\n",
       "      <td>2014_WA-WFS-513_SAND RIDGE</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>235</td>\n",
       "      <td>232</td>\n",
       "      <td>[laid, night, test, wind, remain, canyon, peri...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[heavy, canyon, river, mainly, canyon, come, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44362</th>\n",
       "      <td>2014</td>\n",
       "      <td>2014-08-20 13:00:00</td>\n",
       "      <td>2014_WA-WFS-513_SAND RIDGE</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>235</td>\n",
       "      <td>232</td>\n",
       "      <td>[report, incident, wind, test, overnight]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[heavy, canyon, river, mainly, canyon, come, e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44363 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CY       DISCOVERY_DATE                         INCIDENT_ID  \\\n",
       "0      2010  2010-07-15 15:00:00   2000_CA-RRU-062485_VALLEY COMPLEX   \n",
       "1      2010  2010-07-15 15:00:00   2000_CA-RRU-062485_VALLEY COMPLEX   \n",
       "2      2010  2010-07-15 15:00:00   2000_CA-RRU-062485_VALLEY COMPLEX   \n",
       "3      2010  2010-07-15 15:00:00   2000_CA-RRU-062485_VALLEY COMPLEX   \n",
       "4      2010  2010-07-15 15:00:00   2000_CA-RRU-062485_VALLEY COMPLEX   \n",
       "...     ...                  ...                                 ...   \n",
       "44358  2014  2014-03-15 14:30:00  2014_VAVAS1403037_BEAVER LODGE RD.   \n",
       "44359  2014  2014-03-19 14:00:00  2014_VAVAS1406037_AIRPORT MOUNTAIN   \n",
       "44360  2014  2014-08-20 13:00:00          2014_WA-WFS-513_SAND RIDGE   \n",
       "44361  2014  2014-08-20 13:00:00          2014_WA-WFS-513_SAND RIDGE   \n",
       "44362  2014  2014-08-20 13:00:00          2014_WA-WFS-513_SAND RIDGE   \n",
       "\n",
       "       PCT_CONTAINED_COMPLETED  START_YEAR  TOTAL_AERIAL  TOTAL_PERSONNEL  \\\n",
       "0                         80.0      2010.0      5.000000       230.000000   \n",
       "1                         60.0      2010.0      5.000000       230.000000   \n",
       "2                         30.0      2010.0      4.000000       165.000000   \n",
       "3                        100.0      2010.0      4.333333       192.333333   \n",
       "4                         60.0      2010.0      4.333333       192.333333   \n",
       "...                        ...         ...           ...              ...   \n",
       "44358                    100.0      2014.0      0.000000        13.000000   \n",
       "44359                     85.0      2014.0      0.000000        18.500000   \n",
       "44360                      0.0      2014.0      1.000000        95.000000   \n",
       "44361                     86.0      2014.0      1.000000       120.000000   \n",
       "44362                    100.0      2014.0      0.000000        46.000000   \n",
       "\n",
       "       REPORT_DOY  DISCOVERY_DOY  \\\n",
       "0             197            196   \n",
       "1             197            196   \n",
       "2             197            196   \n",
       "3             197            196   \n",
       "4             197            196   \n",
       "...           ...            ...   \n",
       "44358          74             74   \n",
       "44359          80             78   \n",
       "44360         234            232   \n",
       "44361         235            232   \n",
       "44362         235            232   \n",
       "\n",
       "                                           Combined Text  ... Infrastructure  \\\n",
       "0                              [resource, share, cactus]  ...              0   \n",
       "1      [resource, share, incident, cactus, incident, ...  ...              0   \n",
       "2      [resource, share, cactus, erratic, wind, due, ...  ...              0   \n",
       "3      [resource, share, cactus, cactus, become, vall...  ...              0   \n",
       "4      [resource, share, cactus, cactus, become, vall...  ...              0   \n",
       "...                                                  ...  ...            ...   \n",
       "44358                              [fast, spread, field]  ...              0   \n",
       "44359                   [heavy, plume, primary, carrier]  ...              0   \n",
       "44360  [heavy, canyon, river, mainly, canyon, come, e...  ...              0   \n",
       "44361  [laid, night, test, wind, remain, canyon, peri...  ...              0   \n",
       "44362          [report, incident, wind, test, overnight]  ...              0   \n",
       "\n",
       "       Extreme Weather  Ecological  Hazardous Terrain  Floods  Dry Weather  \\\n",
       "0                    1           0                  1       0            0   \n",
       "1                    1           0                  1       0            0   \n",
       "2                    1           0                  1       0            0   \n",
       "3                    1           0                  1       0            0   \n",
       "4                    1           0                  1       0            0   \n",
       "...                ...         ...                ...     ...          ...   \n",
       "44358                0           0                  0       0            0   \n",
       "44359                0           0                  0       0            0   \n",
       "44360                0           0                  0       0            0   \n",
       "44361                0           0                  0       0            0   \n",
       "44362                0           0                  0       0            0   \n",
       "\n",
       "       Severity  NUM_REPORTS  DAYS_BURING  \\\n",
       "0             0            0            1   \n",
       "1             0            1            1   \n",
       "2             0            2            1   \n",
       "3             0            4            1   \n",
       "4             1            5            1   \n",
       "...         ...          ...          ...   \n",
       "44358         2            0            0   \n",
       "44359         0            1            2   \n",
       "44360         0            0            2   \n",
       "44361         0            1            3   \n",
       "44362         0            2            3   \n",
       "\n",
       "                                     Total Incident Text  \n",
       "0                              [resource, share, cactus]  \n",
       "1      [resource, share, cactus, resource, share, inc...  \n",
       "2      [resource, share, cactus, resource, share, inc...  \n",
       "3      [resource, share, cactus, resource, share, inc...  \n",
       "4      [resource, share, cactus, resource, share, inc...  \n",
       "...                                                  ...  \n",
       "44358                              [fast, spread, field]  \n",
       "44359                   [heavy, plume, primary, carrier]  \n",
       "44360  [heavy, canyon, river, mainly, canyon, come, e...  \n",
       "44361  [heavy, canyon, river, mainly, canyon, come, e...  \n",
       "44362  [heavy, canyon, river, mainly, canyon, come, e...  \n",
       "\n",
       "[44363 rows x 47 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "incident_summary_df.columns = incident_summary_df.columns.str.replace(\" \", \"_\")\n",
    "preprocessed_df.columns = preprocessed_df.columns.str.replace(\" \",\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df.to_csv(\"ICS_predictive_model_sitreps.csv\")\n",
    "incident_summary_df.to_csv(\"ICS_predictive_model_summaryreps.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27549102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.style\n",
    "matplotlib.style.use(\"seaborn\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "import seaborn as sns\n",
    "sns.color_palette(\"hls\", 17)\n",
    "import scipy.stats as st\n",
    "import math\n",
    "\n",
    "from pingouin import rcorr\n",
    "import pingouin as pg\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputClassifier, ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifierCV, RidgeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, cross_validate, cross_val_score, learning_curve\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, precision_score, recall_score, plot_roc_curve, roc_curve, auc, roc_auc_score,precision_recall_curve, hamming_loss, multilabel_confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn import feature_selection #import chi2\n",
    "\n",
    "## for deep learning\n",
    "from tensorflow.keras import models, layers, preprocessing as kprocessing\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ac8bdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "from module.trend_analysis_functions import *\n",
    "from module.topic_model_plus_class import Topic_Model_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8eeb422",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(os.path.join(os.path.dirname(os.getcwd()),'data','ICS_predictive_sitreps_full_test.csv')).drop([\"Unnamed: 0\"], axis=1)\n",
    "train_data = pd.read_csv(os.path.join(os.path.dirname(os.getcwd()),'data','ICS_predictive_sitreps_full_train.csv')).drop([\"Unnamed: 0\"], axis=1)\n",
    "val_data = pd.read_csv(os.path.join(os.path.dirname(os.getcwd()),'data','ICS_predictive_sitreps_full_val.csv')).drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2d8ad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [\"TOTAL_PERSONNEL\", \"TOTAL_AERIAL\", \"PCT_CONTAINED_COMPLETED\",\n",
    "              \"ACRES\",  \"WF_FSR\", \"INJURIES\", \"FATALITIES\", \"EST_IM_COST_TO_DATE\", \"STR_DAMAGED\",\n",
    "              \"STR_DESTROYED\", \"NEW_ACRES\", \"EVACUATION_IN_PROGRESS\", \n",
    "              \"NUM_REPORTS\", \"DAYS_BURING\", #'Combined_Text', \n",
    "              'Incident_region_AICC', \n",
    "              'Incident_region_CA', 'Incident_region_EACC','Incident_region_GBCC', 'Incident_region_HICC', \n",
    "              'Incident_region_NRCC','Incident_region_NWCC', 'Incident_region_RMCC', 'Incident_region_SACC',\n",
    "              'Incident_region_SWCC', 'INC_MGMT_ORG_ABBREV_1', 'INC_MGMT_ORG_ABBREV_2','INC_MGMT_ORG_ABBREV_3', \n",
    "              'INC_MGMT_ORG_ABBREV_4','INC_MGMT_ORG_ABBREV_5', 'INC_MGMT_ORG_ABBREV_B','INC_MGMT_ORG_ABBREV_C', \n",
    "              'INC_MGMT_ORG_ABBREV_D','INC_MGMT_ORG_ABBREV_E', 'INC_MGMT_ORG_ABBREV_F']\n",
    "targets = [\"Traffic\",\"Command_Transitions\",\"Evacuations\", \"Inaccurate_Mapping\", \"Aerial_Grounding\", \n",
    "           \"Resource_Issues\", \"Injuries\", \"Cultural_Resources\",\"Livestock\", \"Law_Violations\", \"Military_Base\", \n",
    "           \"Infrastructure\", \"Extreme_Weather\", \"Ecological\", \"Hazardous_Terrain\", \"Floods\", \"Dry_Weather\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fc03ee",
   "metadata": {},
   "source": [
    "# Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67c66a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_quote_marks(word_list):\n",
    "    word_list = word_list.strip(\"[]\").split(\", \")\n",
    "    word_list = [w.replace(\"'\",\"\") for w in word_list]\n",
    "    word_list = \" \".join(word_list)\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f32de368",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [train_data, val_data, test_data]\n",
    "for df in dfs:\n",
    "    cleaned_combined_text = []\n",
    "    for text in df['Combined_Text']:\n",
    "        cleaned_text = remove_quote_marks(text)\n",
    "        cleaned_combined_text.append(cleaned_text)\n",
    "    df['Combined_Text'] = cleaned_combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "251bff48",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = train_data['Raw_Combined_Text']; ytrain = train_data[targets]\n",
    "Xval = val_data['Raw_Combined_Text']; yval = val_data[targets]\n",
    "Xtest = test_data['Raw_Combined_Text']; ytest = test_data[targets]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ba9be9",
   "metadata": {},
   "source": [
    "# Vectorize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b41472c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "\n",
    "Xtrain_vec = embed(Xtrain)\n",
    "Xval_vec = embed(Xval)\n",
    "Xtest_vec = embed(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a657a868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4710, 512])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e01b8ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4710,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12ae696",
   "metadata": {},
   "source": [
    "### Method: classifier chain\n",
    "Note: classifier chains tend to perform worse on larget sets of targets. Also the performance is highly dependent on the order of the chain, so all orderings would ideally be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bad6ae6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "classifiers = [LogisticRegression(max_iter=10000,multi_class='ovr'), RandomForestClassifier(random_state=1),\n",
    "              KNeighborsClassifier(weights='distance'), MLPClassifier(random_state=1), RidgeClassifier()]\n",
    "classifier_names = ['logistic regression', 'random forest', 'knn', 'MLP NN', 'Ridge']\n",
    "test_hamming_loss = []; train_hamming_loss = []\n",
    "test_acc = []; train_acc = []\n",
    "test_f1 = []; train_f1 = []\n",
    "test_precision = []; train_precision = []\n",
    "test_recall = []; train_recall = []\n",
    "for clf in tqdm(classifiers):\n",
    "    classifier = ClassifierChain(clf)\n",
    "    classifier.fit(Xtrain_vec, ytrain[targets])\n",
    "    # predict\n",
    "    train_preds = classifier.predict(Xtrain_vec)\n",
    "    predictions = classifier.predict(Xtest_vec)\n",
    "    test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "    test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "    train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "    test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "    train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "    test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "    train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "    test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "    train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "    \n",
    "comparison = pd.DataFrame({\"Base Estimator\": classifier_names,\n",
    "                           \"train f1\": train_f1, \"test f1\": test_f1,\n",
    "                          \"train accuracy\":train_acc, \"test accuracy\": test_acc,\n",
    "                          \"train recall\": train_recall, \"test recall\": test_recall,\n",
    "                          \"train precision\": train_precision, \"test precision\": test_precision,\n",
    "                          \"train hamming loss\": train_hamming_loss, \"test hamming loss\": test_hamming_loss})\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b03badd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base Estimator</th>\n",
       "      <th>train f1</th>\n",
       "      <th>test f1</th>\n",
       "      <th>train accuracy</th>\n",
       "      <th>test accuracy</th>\n",
       "      <th>train recall</th>\n",
       "      <th>test recall</th>\n",
       "      <th>train precision</th>\n",
       "      <th>test precision</th>\n",
       "      <th>train hamming loss</th>\n",
       "      <th>test hamming loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random forest</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.101</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.413</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.067</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>knn</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.228</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.345</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.252</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP NN</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Base Estimator  train f1  test f1  train accuracy  test accuracy  \\\n",
       "0  logistic regression     0.335    0.164           0.424          0.405   \n",
       "1        random forest     1.000    0.101           1.000          0.413   \n",
       "2                  knn     1.000    0.228           1.000          0.345   \n",
       "3               MLP NN     0.995    0.201           0.997          0.347   \n",
       "4                Ridge     0.199    0.131           0.422          0.410   \n",
       "\n",
       "   train recall  test recall  train precision  test precision  \\\n",
       "0         0.243        0.122            0.642           0.272   \n",
       "1         1.000        0.067            1.000           0.294   \n",
       "2         1.000        0.252            1.000           0.221   \n",
       "3         0.996        0.170            0.994           0.263   \n",
       "4         0.141        0.091            0.628           0.276   \n",
       "\n",
       "   train hamming loss  test hamming loss  \n",
       "0               0.098              0.105  \n",
       "1               0.000              0.100  \n",
       "2               0.000              0.143  \n",
       "3               0.000              0.115  \n",
       "4               0.099              0.101  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960c9789",
   "metadata": {},
   "source": [
    "### Method: multioutput classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a26cd1",
   "metadata": {},
   "source": [
    "### Power set label \n",
    "problem transformation to multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f7cb65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srandrad\\AppData\\Local\\Temp\\1/ipykernel_16776/443457025.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ytrain['powerlabel'] = ytrain.apply(lambda x : sum([(2**i)*x[targets[i]] for i in range(len(targets))]),axis=1)\n",
      "C:\\Users\\srandrad\\AppData\\Local\\Temp\\1/ipykernel_16776/443457025.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  yval['powerlabel'] = yval.apply(lambda x : sum([(2**i)*x[targets[i]] for i in range(len(targets))]),axis=1)\n",
      "C:\\Users\\srandrad\\AppData\\Local\\Temp\\1/ipykernel_16776/443457025.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ytest['powerlabel'] = ytest.apply(lambda x : sum([(2**i)*x[targets[i]] for i in range(len(targets))]),axis=1)\n"
     ]
    }
   ],
   "source": [
    "ytrain['powerlabel'] = ytrain.apply(lambda x : sum([(2**i)*x[targets[i]] for i in range(len(targets))]),axis=1)\n",
    "yval['powerlabel'] = yval.apply(lambda x : sum([(2**i)*x[targets[i]] for i in range(len(targets))]),axis=1)\n",
    "ytest['powerlabel'] = ytest.apply(lambda x : sum([(2**i)*x[targets[i]] for i in range(len(targets))]),axis=1)\n",
    "#ytrain['powerlabel'].hist(bins=np.unique(ytrain['powerlabel']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4059df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hamming_loss = []; train_hamming_loss = []\n",
    "test_acc = []; train_acc = []\n",
    "test_f1 = []; train_f1 = []\n",
    "test_precision = []; train_precision = []\n",
    "test_recall = []; train_recall = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1616ab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [KNeighborsClassifier(weights='distance'),#SVC(kernel=\"linear\", C=0.025),SVC(gamma=2, C=1),\n",
    "               LinearSVC(multi_class='crammer_singer',max_iter=100000, class_weight='balanced'), DecisionTreeClassifier(),\n",
    "               RandomForestClassifier(random_state=1, n_estimators=200),LogisticRegression(max_iter=10000,multi_class='multinomial'),\n",
    "               MLPClassifier(alpha=1, max_iter=1000), RidgeClassifier(), AdaBoostClassifier()]\n",
    "               #GaussianNB(), QuadraticDiscriminantAnalysis()]\n",
    "total_names = ['Knn', #\"Linear SVM\", \"RBF SVM\",\n",
    "                \"Linear SVM\", \"Decision Tree\", \"Random Forest\", \n",
    "                   \"Logisitc Regression\", 'MLP NN', 'Ridge', 'Adaboost']#, 'Gaussian NB', 'QDA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c37b7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▌                                                                         | 1/8 [00:46<05:28, 46.92s/it]"
     ]
    }
   ],
   "source": [
    "for clf in tqdm(classifiers):\n",
    "    classifier = clf#, n_jobs=-1)\n",
    "    classifier.fit(Xtrain_vec, ytrain['powerlabel'])\n",
    "    predictions = classifier.predict(Xtest_vec)\n",
    "    train_preds = classifier.predict(Xtrain_vec)\n",
    "    test_acc.append(round(accuracy_score(ytest['powerlabel'],predictions),3)); train_acc.append(round(accuracy_score(ytrain['powerlabel'],train_preds),3))\n",
    "    test_f1.append(round(f1_score(ytest['powerlabel'],predictions, average='macro',zero_division=0),3))\n",
    "    train_f1.append(round(f1_score(ytrain['powerlabel'],train_preds, average='macro',zero_division=0),3))\n",
    "    test_precision.append(round(precision_score(ytest['powerlabel'],predictions, average='macro', zero_division=0),3))\n",
    "    train_precision.append(round(precision_score(ytrain['powerlabel'],train_preds, average='macro', zero_division=0),3))\n",
    "    test_recall.append(round(recall_score(ytest['powerlabel'],predictions, average='macro', zero_division=0),3))\n",
    "    train_recall.append(round(recall_score(ytrain['powerlabel'],train_preds, average='macro', zero_division=0),3))\n",
    "    test_hamming_loss.append(round(hamming_loss(ytest['powerlabel'],predictions),3))\n",
    "    train_hamming_loss.append(round(hamming_loss(ytrain['powerlabel'],train_preds),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fa3977",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame({\"Model\":total_names,\n",
    "                           \"train f1\": train_f1, \"test f1\": test_f1,\n",
    "                          \"train accuracy\":train_acc, \"test accuracy\": test_acc,\n",
    "                          \"train recall\": train_recall, \"test recall\": test_recall,\n",
    "                          \"train precision\": train_precision, \"test precision\": test_precision,\n",
    "                          \"train hamming loss\": train_hamming_loss, \"test hamming loss\": test_hamming_loss})\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6255c1fc",
   "metadata": {},
   "source": [
    "### Method: One vs Rest classifier\n",
    "note: this one performs better without the extreme over sampling -> maybe a simple over sampling approach is preferred here. Over fitting is definitely occuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29f1caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = ytrain[targets]\n",
    "ytest = ytest[targets]\n",
    "yval = yval[targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c6002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [KNeighborsClassifier(weights='uniform', p=1),SVC(kernel=\"linear\", C=0.025),SVC(gamma=2, C=1),\n",
    "               #GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "               DecisionTreeClassifier(criterion='entropy', max_features='sqrt', class_weight=None, splitter='best'),\n",
    "               RandomForestClassifier(criterion='entropy',max_features='auto', class_weight='balanced', n_estimators=100),\n",
    "               LogisticRegression(max_iter=10000,multi_class='ovr',solver='sag'),\n",
    "               MLPClassifier(alpha=1, max_iter=1000), RidgeClassifier(alpha=10), AdaBoostClassifier(learning_rate=1), \n",
    "               XGBClassifier(booster='gbtree', n_estimators=100, max_depth=4, eval_metric='logloss',use_label_encoder=False)\n",
    "              ]#GaussianNB(), QuadraticDiscriminantAnalysis()]\n",
    "classifier_name = ['Knn', \"Linear SVM\", \"RBF SVM\", #\"Gaussian Process\",\n",
    "                   \"Decision Tree\", \"Random Forest\", \n",
    "                   \"Logisitc Regression\", 'MLP NN', 'Ridge', 'Adaboost', 'XGBoost' ]#,'Gaussian NB', 'QDA'\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c754717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hamming_loss = []; train_hamming_loss = []\n",
    "test_acc = []; train_acc = []\n",
    "test_f1 = []; train_f1 = []\n",
    "test_precision = []; train_precision = []\n",
    "test_recall = []; train_recall = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fbf46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf in tqdm(classifiers):\n",
    "    classifier = OneVsRestClassifier(clf)#, n_jobs=-1)\n",
    "    classifier.fit(Xtrain_vec, ytrain)\n",
    "    predictions = classifier.predict(Xtest_vec)\n",
    "    train_preds = classifier.predict(Xtrain_vec)\n",
    "    test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "    test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "    train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "    test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "    train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "    test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "    train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "    test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "    train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b0a0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame({\"Model\":classifier_name,\n",
    "                          \"train f1\": train_f1, \"test f1\": test_f1,\n",
    "                          \"train accuracy\":train_acc, \"test accuracy\": test_acc,\n",
    "                          \"train recall\": train_recall, \"test recall\": test_recall,\n",
    "                          \"train precision\": train_precision, \"test precision\": test_precision,\n",
    "                          \"train hamming loss\": train_hamming_loss, \"test hamming loss\": test_hamming_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8b09d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18cdc1f",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6a409f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(features, num_neurons, drop_rate=0.5, num_layers=1, reg='dropout', LSTM=False):\n",
    "    initializer = tf.keras.initializers.GlorotNormal()\n",
    "    USE_input = tf.keras.layers.Input(shape=[], dtype=tf.string, name='USE_input')\n",
    "    USE_layer = hub.KerasLayer('https://tfhub.dev/google/universal-sentence-encoder/4', \n",
    "                    trainable=True)(USE_input)\n",
    "    if LSTM:\n",
    "        USE_layer= tf.keras.layers.Reshape((1, 512))(USE_layer)\n",
    "        USE_output = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, dropout=0.3, recurrent_dropout=0.3, kernel_regularizer=tf.keras.regularizers.l2(0.01)))(USE_layer)\n",
    "    else:\n",
    "        USE_output = tf.keras.layers.Dense(17, activation='sigmoid')(USE_layer)\n",
    "        \n",
    "    meta_input = tf.keras.layers.Input(shape=(features,), name='meta_input')\n",
    "    combined_USE_meta = tf.keras.layers.Concatenate()([USE_output, meta_input])\n",
    "    prev_layer = combined_USE_meta\n",
    "    for i in range(num_layers):\n",
    "        curr_layer = tf.keras.layers.Dense(num_neurons, activation='tanh',kernel_initializer=initializer,#'he_uniform',\n",
    "                                 #kernel_regularizer=keras.regularizers.l2(0.01),\n",
    "                                 #bias_regularizer=keras.regularizers.l2(0.01)\n",
    "                                 )(prev_layer)\n",
    "        if reg == 'dropout':\n",
    "            curr_layer = tf.keras.layers.Dropout(rate=drop_rate)(curr_layer)\n",
    "        prev_layer = curr_layer\n",
    "    output = tf.keras.layers.Dense(17, activation='sigmoid')(prev_layer)\n",
    "    model = tf.keras.Model(inputs=[USE_input , meta_input], outputs=output)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "92f500a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "USE_input (InputLayer)          [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer_12 (KerasLayer)     (None, 512)          256797824   USE_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 1, 512)       0           keras_layer_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 256)          656384      reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "meta_input (InputLayer)         [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 290)          0           bidirectional_7[0][0]            \n",
      "                                                                 meta_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 500)          145500      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 500)          0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 500)          250500      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 500)          0           dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 500)          250500      dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 500)          0           dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 500)          250500      dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 500)          0           dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 500)          250500      dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 500)          0           dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 500)          250500      dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 500)          0           dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 500)          250500      dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 500)          0           dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 500)          250500      dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 500)          0           dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 500)          250500      dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 500)          0           dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 500)          250500      dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 500)          0           dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 17)           8517        dropout_21[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 259,862,725\n",
      "Trainable params: 259,862,725\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(features=len(predictors), num_neurons=500, num_layers=10, LSTM=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ccd02583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "def Hamming_loss(y_true, y_pred):\n",
    "    tmp = K.abs(y_true-y_pred)\n",
    "    return K.mean(K.cast(K.greater(tmp,0.5),dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0cf099ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {}\n",
    "for c in range(len(targets)):\n",
    "    class_weights[c] = ytrain.shape[0]/(2*np.count_nonzero(ytrain[targets[c]]==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0fe903f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch = 256\n",
    "num_epochs = 10\n",
    "lr = 1e-4\n",
    "# First we need to define the optimizer to be used. We use Adam here with default hyper-parameters\n",
    "optim = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "# then, we need to compile the model: this configures the model for training\n",
    "model.compile(loss='categorical_crossentropy',#loss_fn,#'categorical_crossentropy',\n",
    "              optimizer=optim, metrics=['accuracy',Hamming_loss])#, hamming_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642cbed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = {\"USE_input\": Xtrain, \"meta_input\": np.asarray(train_data[predictors]).astype(np.float32)}\n",
    "X_val = {\"USE_input\": Xval, \"meta_input\": np.asarray(val_data[predictors]).astype(np.float32)}\n",
    "training = model.fit(x=X_train, y=ytrain.astype(float), batch_size=mini_batch, \n",
    "                    epochs=num_epochs, shuffle=True, verbose=0, validation_data=(X_val, yval.astype(float)),\n",
    "                    class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4a00ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss and accuracy\n",
    "plt.figure(figsize=(8, 6))\n",
    "FONT=14\n",
    "plt.plot(range(num_epochs), training.history['loss'], label='training loss')\n",
    "plt.plot(range(num_epochs), training.history['val_loss'], label='validation loss')\n",
    "plt.xlabel('Number of epochs', fontsize=FONT)\n",
    "plt.ylabel('Loss', fontsize=FONT)\n",
    "plt.legend(fontsize=FONT)\n",
    "plt.tick_params(axis='both', which='major', labelsize=FONT)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "FONT=14\n",
    "plt.plot(range(num_epochs), training.history['accuracy'], label='training accuracy')\n",
    "plt.plot(range(num_epochs), training.history['val_accuracy'], label='validation accuracy')\n",
    "plt.xlabel('Number of epochs', fontsize=FONT)\n",
    "plt.ylabel('accuracy', fontsize=FONT)\n",
    "plt.legend(fontsize=FONT)\n",
    "plt.tick_params(axis='both', which='major', labelsize=FONT)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "FONT=14\n",
    "plt.plot(range(num_epochs), training.history['Hamming_loss'], label='training hamming loss')\n",
    "plt.plot(range(num_epochs), training.history['val_Hamming_loss'], label='validation hamming loss')\n",
    "plt.xlabel('Number of epochs', fontsize=FONT)\n",
    "plt.ylabel('Hamming Loss', fontsize=FONT)\n",
    "plt.legend(fontsize=FONT)\n",
    "plt.tick_params(axis='both', which='major', labelsize=FONT)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20acbc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hamming_loss = []; train_hamming_loss = []\n",
    "test_acc = []; train_acc = []\n",
    "test_f1 = []; train_f1 = []\n",
    "test_precision = []; train_precision = []\n",
    "test_recall = []; train_recall = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76474651",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## test\n",
    "X_test = {\"USE_input\": Xtest, \"meta_input\": np.asarray(test_data[predictors]).astype(np.float32)}\n",
    "predicted_raw = model.predict(X_test)\n",
    "predicted = np.around(predicted_raw)\n",
    "y_test_array = ytest.to_numpy()\n",
    "## Accuracy, Precision, Recall\n",
    "accuracy = accuracy_score(ytest, predicted)\n",
    "#auc_score = roc_auc_score(ytest, predicted, \n",
    "#                            multi_class=\"ovr\")\n",
    "print(\"Hamming loss:\", round(hamming_loss(ytest, predicted),3))\n",
    "print(\"Accuracy:\",  round(accuracy,3))\n",
    "#print(\"Auc:\", round(auc_score,3))\n",
    "print(\"Detail:\")\n",
    "print(classification_report(ytest, predicted,zero_division=0))\n",
    "\n",
    "predictions = np.around(model.predict(X_test))\n",
    "train_preds =np.around(model.predict(X_train))\n",
    "test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "## Plot confusion matrix\n",
    "\n",
    "ml_cm = multilabel_confusion_matrix(ytest.to_numpy(), predicted)\n",
    "i=0\n",
    "for cm in ml_cm:\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, \n",
    "                cbar=False)\n",
    "    ax.set(xlabel=\"Pred\", ylabel=\"True\", title=\"Confusion matrix \"+targets[i])\n",
    "    plt.yticks(rotation=0)\n",
    "    i+=1\n",
    "## Plot roc\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(18,6))\n",
    "for i in range(len(targets)):\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_array[:,i],  \n",
    "                           predicted[:,i])\n",
    "    ax[0].plot(fpr, tpr, lw=3, \n",
    "              label='{0} (area={1:0.2f})'.format(targets[i], \n",
    "                              auc(fpr, tpr))\n",
    "               )\n",
    "ax[0].plot([0,1], [0,1], color='navy', lw=3, linestyle='--')\n",
    "ax[0].set(xlim=[-0.05,1.0], ylim=[0.0,1.05], \n",
    "          xlabel='False Positive Rate', \n",
    "          ylabel=\"True Positive Rate (Recall)\", \n",
    "          title=\"Receiver operating characteristic\")\n",
    "ax[0].legend(loc=\"lower right\")\n",
    "ax[0].grid(True)\n",
    "    \n",
    "## Plot precision-recall curve\n",
    "for i in range(len(targets)):\n",
    "    precision, recall, thresholds = precision_recall_curve(\n",
    "                 y_test_array[:,i], predicted[:,i])\n",
    "    ax[1].plot(recall, precision, lw=3, \n",
    "               label='{0} (area={1:0.2f})'.format(targets[i], \n",
    "                                  auc(recall, precision))\n",
    "              )\n",
    "ax[1].set(xlim=[0.0,1.05], ylim=[0.0,1.05], xlabel='Recall', \n",
    "          ylabel=\"Precision\", title=\"Precision-Recall curve\")\n",
    "ax[1].legend(loc=\"best\")\n",
    "ax[1].grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a263e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame({\"train f1\": train_f1, \"test f1\": test_f1,\n",
    "                          \"train accuracy\":train_acc, \"test accuracy\": test_acc,\n",
    "                          \"train recall\": train_recall, \"test recall\": test_recall,\n",
    "                          \"train precision\": train_precision, \"test precision\": test_precision,\n",
    "                          \"train hamming loss\": train_hamming_loss, \"test hamming loss\": test_hamming_loss})\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c3545e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\srandrad\\smart_nlp\\models\\USE_hazard_classification_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\srandrad\\smart_nlp\\models\\USE_hazard_classification_model\\assets\n"
     ]
    }
   ],
   "source": [
    "#model.save(os.path.join(os.path.dirname(os.getcwd()),'models','USE_hazard_classification_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "714dae82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = os.path.join(os.path.dirname(os.getcwd()),'results','hazard_classification_model.png')\n",
    "tf.keras.utils.plot_model(model, to_file=filename, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19474e0",
   "metadata": {},
   "source": [
    "## Hyper parameter optimization - one vs rest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b40df0b",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9874f95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_neighbors': [50]+[i for i in range(55,1055,100)],\n",
    "         #'weights':['uniform', 'distance'],\n",
    "         #'p':[1,2]}\n",
    "best_params = {'weights': 'uniform', 'p': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a60c1977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 50, 'weights': 'uniform', 'p': 1}\n"
     ]
    }
   ],
   "source": [
    "for param in params:\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in params[param]:\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = OneVsRestClassifier(KNeighborsClassifier(**test_params))#, n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain)\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10670360",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a11d7189",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C': [1*(10**i) for i in range(0,2,1)],\n",
    "         'class_weight':[None, \"balanced\"],\n",
    "          'gamma': ['scale', 'auto',2],\n",
    "         'break_ties':[True,False]}\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1d0311b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|███████████████████████████████████████                                       | 1/2 [1:23:08<1:23:08, 4988.81s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [3:37:21<00:00, 6520.75s/it]\u001b[A\n",
      " 25%|███████████████████                                                         | 1/4 [3:37:21<10:52:04, 13041.51s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|███████████████████████████████████████                                       | 1/2 [1:01:04<1:01:04, 3664.18s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [2:57:00<00:00, 5310.44s/it]\u001b[A\n",
      " 50%|██████████████████████████████████████▌                                      | 2/4 [6:34:22<6:27:15, 11617.62s/it]\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|██████████████████████████                                                    | 1/3 [1:10:22<2:20:44, 4222.04s/it]\u001b[A\n",
      " 67%|█████████████████████████████████████████████████████▎                          | 2/3 [1:55:06<55:17, 3317.72s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 3/3 [3:29:34<00:00, 4191.42s/it]\u001b[A\n",
      " 75%|█████████████████████████████████████████████████████████                   | 3/4 [10:03:56<3:20:54, 12054.45s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|███████████████████████████████████████                                       | 1/2 [1:00:50<1:00:50, 3650.09s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [2:01:48<00:00, 3654.32s/it]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 4/4 [12:05:45<00:00, 10886.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'class_weight': None, 'gamma': 'scale', 'break_ties': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = OneVsRestClassifier(SVC(**test_params), n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain)\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50a6b478",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26052b20",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47f7177b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'criterion':['gini', 'entropy'],\n",
    "         'max_features':['auto', 'sqrt', 'log2'],\n",
    "         'class_weight':[None, \"balanced\"],\n",
    "         'splitter':['best', 'random']}\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf62b5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████████▌                                         | 1/2 [02:19<02:19, 139.50s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [03:26<00:00, 103.06s/it]\u001b[A\n",
      " 25%|████████████████████▊                                                              | 1/4 [03:26<10:18, 206.14s/it]\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|████████████████████████████                                                        | 1/3 [00:04<00:09,  4.73s/it]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████                            | 2/3 [00:09<00:04,  4.83s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:12<00:00,  4.13s/it]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 2/4 [03:38<03:04, 92.18s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:04<00:04,  4.96s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:10<00:00,  5.06s/it]\u001b[A\n",
      " 75%|███████████████████████████████████████████████████████████████                     | 3/4 [03:48<00:54, 54.71s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:05<00:05,  5.18s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:06<00:00,  3.48s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [03:55<00:00, 58.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_features': 'sqrt', 'class_weight': 'balanced', 'splitter': 'best'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = OneVsRestClassifier(DecisionTreeClassifier(**test_params), n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain)\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16834866",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a5e2294",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'criterion':['gini', 'entropy'],\n",
    "         'max_features':['auto', 'sqrt', 'log2'],\n",
    "         'class_weight':[None, \"balanced\"],\n",
    "         'n_estimators':[i for i in range(50, 550, 50)]}\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26e30a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████████▌                                         | 1/2 [04:27<04:27, 267.13s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [08:25<00:00, 252.89s/it]\u001b[A\n",
      " 25%|████████████████████▊                                                              | 1/4 [08:25<25:17, 505.79s/it]\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███████████████████████████▋                                                       | 1/3 [03:59<07:59, 239.96s/it]\u001b[A\n",
      " 67%|███████████████████████████████████████████████████████▎                           | 2/3 [07:59<03:59, 239.42s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [09:54<00:00, 198.08s/it]\u001b[A\n",
      " 50%|█████████████████████████████████████████▌                                         | 2/4 [18:20<18:35, 557.82s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████████▌                                         | 1/2 [04:01<04:01, 241.28s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [08:00<00:00, 240.41s/it]\u001b[A\n",
      " 75%|██████████████████████████████████████████████████████████████▎                    | 3/4 [26:20<08:42, 522.66s/it]\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|████████▏                                                                         | 1/10 [01:58<17:48, 118.69s/it]\u001b[A\n",
      " 20%|████████████████▍                                                                 | 2/10 [05:58<25:19, 189.90s/it]\u001b[A\n",
      " 30%|████████████████████████▌                                                         | 3/10 [11:56<31:08, 266.89s/it]\u001b[A\n",
      " 40%|████████████████████████████████▊                                                 | 4/10 [19:55<35:03, 350.55s/it]\u001b[A\n",
      " 50%|█████████████████████████████████████████                                         | 5/10 [29:58<36:48, 441.68s/it]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████▏                                | 6/10 [42:10<36:00, 540.12s/it]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████████▍                        | 7/10 [56:17<32:01, 640.46s/it]\u001b[A\n",
      " 80%|████████████████████████████████████████████████████████████████                | 8/10 [1:12:27<24:51, 745.58s/it]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████████        | 9/10 [1:30:47<14:16, 856.10s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 10/10 [1:51:10<00:00, 667.09s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 4/4 [2:17:31<00:00, 2062.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_features': 'auto', 'class_weight': None, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = OneVsRestClassifier(RandomForestClassifier(**test_params), n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain)\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20f6f9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(criterion='entropy',max_features='auto', class_weight='balanced', n_estimators=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9cc85c",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed19dbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'solver':['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "          'C': [i for i in range(1,11,1)],\n",
    "         'class_weight':[None, \"balanced\"]}\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f2fc091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|████████████████████▊                                                              | 1/4 [02:20<07:02, 140.75s/it]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 2/4 [02:43<02:22, 71.34s/it]\u001b[A\n",
      " 75%|███████████████████████████████████████████████████████████████                     | 3/4 [02:52<00:42, 42.93s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [03:01<00:00, 45.45s/it]\u001b[A\n",
      " 33%|███████████████████████████▋                                                       | 1/3 [03:01<06:03, 181.81s/it]\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|████████▏                                                                         | 1/10 [02:22<21:24, 142.73s/it]\u001b[A\n",
      " 20%|████████████████▍                                                                 | 2/10 [05:06<20:39, 154.91s/it]\u001b[A\n",
      " 30%|████████████████████████▌                                                         | 3/10 [07:51<18:38, 159.78s/it]\u001b[A\n",
      " 40%|████████████████████████████████▊                                                 | 4/10 [10:55<16:55, 169.29s/it]\u001b[A\n",
      " 50%|█████████████████████████████████████████                                         | 5/10 [14:00<14:35, 175.01s/it]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████▏                                | 6/10 [16:50<11:32, 173.15s/it]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████████▍                        | 7/10 [20:07<09:03, 181.01s/it]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 8/10 [23:10<06:03, 181.66s/it]\u001b[A\n",
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 9/10 [25:58<02:57, 177.29s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [29:11<00:00, 175.15s/it]\u001b[A\n",
      " 67%|██████████████████████████████████████████████████████▋                           | 2/3 [32:13<18:25, 1105.19s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████████▌                                         | 1/2 [02:18<02:18, 138.56s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [04:54<00:00, 147.11s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [37:07<00:00, 742.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'newton-cg', 'C': 1, 'class_weight': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = OneVsRestClassifier(LogisticRegression(max_iter=10000,multi_class='ovr',**test_params), n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain)\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdf5b6b",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5f10bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'alpha': [1*((10)**(i)) for i in range(-4,3,1)],\n",
    "         'learning_rate':['constant', 'invscaling', 'adaptive'],\n",
    "          'hidden_layer_sizes':[(50,), (50,50), (50,50,50), (100,), (100,100), (100,100,100)]}\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f35672ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|███████████▊                                                                       | 1/7 [04:04<24:26, 244.42s/it]\u001b[A\n",
      " 29%|███████████████████████▏                                                         | 2/7 [22:16<1:01:54, 742.96s/it]\u001b[A\n",
      " 43%|█████████████████████████████████▍                                            | 3/7 [1:07:21<1:49:16, 1639.00s/it]\u001b[A\n",
      " 57%|████████████████████████████████████████████▌                                 | 4/7 [1:31:29<1:18:11, 1563.68s/it]\u001b[A\n",
      " 71%|█████████████████████████████████████████████████████████▏                      | 5/7 [1:39:54<39:23, 1181.63s/it]\u001b[A\n",
      " 86%|████████████████████████████████████████████████████████████████████▌           | 6/7 [1:52:04<17:08, 1028.06s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 7/7 [2:05:56<00:00, 1079.56s/it]\u001b[A\n",
      " 33%|██████████████████████████                                                    | 1/3 [2:05:56<4:11:53, 7556.95s/it]\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███████████████████████████▎                                                      | 1/3 [26:21<52:42, 1581.13s/it]\u001b[A\n",
      " 67%|██████████████████████████████████████████████████████▋                           | 2/3 [53:00<26:31, 1591.60s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 3/3 [1:16:12<00:00, 1524.11s/it]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████                          | 2/3 [3:22:09<1:36:41, 5801.30s/it]\n",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|█████████████▌                                                                   | 1/6 [15:34<1:17:53, 934.77s/it]\u001b[A\n",
      " 33%|██████████████████████████▋                                                     | 2/6 [37:10<1:16:27, 1146.92s/it]\u001b[A\n",
      " 50%|███████████████████████████████████████                                       | 3/6 [1:09:51<1:15:56, 1518.82s/it]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████                          | 4/6 [1:50:50<1:02:59, 1889.96s/it]\u001b[A\n",
      " 83%|██████████████████████████████████████████████████████████████████▋             | 5/6 [2:40:17<37:58, 2278.41s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 6/6 [3:24:27<00:00, 2044.56s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 3/3 [6:46:36<00:00, 8132.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.1, 'learning_rate': 'invscaling', 'hidden_layer_sizes': (100,)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = OneVsRestClassifier(MLPClassifier(max_iter=1000,**test_params), n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain)\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072f3395",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7b964ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'alpha': [1*((10)**(i)) for i in range(-4,3,1)],\n",
    "         'class_weight':[None, \"balanced\"]\n",
    "         }\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84f029ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|████████████                                                                        | 1/7 [00:04<00:29,  4.92s/it]\u001b[A\n",
      " 29%|████████████████████████                                                            | 2/7 [00:07<00:18,  3.78s/it]\u001b[A\n",
      " 43%|████████████████████████████████████                                                | 3/7 [00:11<00:13,  3.47s/it]\u001b[A\n",
      " 57%|████████████████████████████████████████████████                                    | 4/7 [00:14<00:10,  3.34s/it]\u001b[A\n",
      " 71%|████████████████████████████████████████████████████████████                        | 5/7 [00:17<00:06,  3.23s/it]\u001b[A\n",
      " 86%|████████████████████████████████████████████████████████████████████████            | 6/7 [00:20<00:03,  3.17s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:23<00:00,  3.32s/it]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:23<00:23, 23.22s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:03<00:03,  3.20s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:06<00:00,  3.14s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:29<00:00, 14.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1, 'class_weight': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = OneVsRestClassifier(RidgeClassifier(**test_params), n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain)\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957660a7",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70022d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth':[None]+[i for i in range(3,25)]}#'booster': ['gbtree', 'gblinear', 'dart'], 'n_estimators': [i for i in range(100, 500, 25)]}\n",
    "best_params = {'booster': 'gbtree','n_estimators':100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9c4e949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]\n",
      "  0%|                                                                                           | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|███▍                                                                            | 1/23 [13:10<4:49:59, 790.89s/it]\u001b[A\n",
      "  9%|██████▉                                                                         | 2/23 [20:04<3:19:02, 568.71s/it]\u001b[A\n",
      " 13%|██████████▍                                                                     | 3/23 [28:57<3:04:11, 552.57s/it]\u001b[A\n",
      " 17%|█████████████▉                                                                  | 4/23 [39:56<3:08:18, 594.64s/it]\u001b[A\n",
      " 22%|█████████████████▍                                                              | 5/23 [53:06<3:19:33, 665.20s/it]\u001b[A\n",
      " 26%|████████████████████▎                                                         | 6/23 [1:08:03<3:30:47, 743.97s/it]\u001b[A\n",
      " 30%|███████████████████████▋                                                      | 7/23 [1:24:22<3:38:50, 820.65s/it]\u001b[A\n",
      " 35%|███████████████████████████▏                                                  | 8/23 [1:41:29<3:41:35, 886.39s/it]\u001b[A\n",
      " 39%|██████████████████████████████▌                                               | 9/23 [2:00:00<3:43:12, 956.63s/it]\u001b[A\n",
      " 43%|█████████████████████████████████                                           | 10/23 [2:19:36<3:41:58, 1024.46s/it]\u001b[A\n",
      " 48%|████████████████████████████████████▎                                       | 11/23 [2:39:45<3:36:11, 1080.95s/it]\u001b[A\n",
      " 52%|███████████████████████████████████████▋                                    | 12/23 [3:00:40<3:27:50, 1133.67s/it]\u001b[A\n",
      " 57%|██████████████████████████████████████████▉                                 | 13/23 [3:21:25<3:14:34, 1167.44s/it]\u001b[A\n",
      " 61%|██████████████████████████████████████████████▎                             | 14/23 [3:42:48<3:00:21, 1202.44s/it]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████▌                          | 15/23 [4:04:37<2:44:37, 1234.64s/it]\u001b[A\n",
      " 70%|████████████████████████████████████████████████████▊                       | 16/23 [4:26:43<2:27:13, 1261.91s/it]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████████▏                   | 17/23 [5:04:06<2:35:42, 1557.12s/it]\u001b[A\n",
      " 78%|███████████████████████████████████████████████████████████▍                | 18/23 [5:27:00<2:05:09, 1501.92s/it]\u001b[A\n",
      " 83%|██████████████████████████████████████████████████████████████▊             | 19/23 [5:49:53<1:37:33, 1463.25s/it]\u001b[A\n",
      " 87%|██████████████████████████████████████████████████████████████████          | 20/23 [6:12:18<1:11:23, 1427.92s/it]\u001b[A\n",
      " 91%|███████████████████████████████████████████████████████████████████████▏      | 21/23 [6:35:24<47:10, 1415.09s/it]\u001b[A\n",
      " 96%|██████████████████████████████████████████████████████████████████████████▌   | 22/23 [6:58:40<23:29, 1409.35s/it]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 23/23 [7:21:59<00:00, 1153.01s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1/1 [7:21:59<00:00, 26519.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'booster': 'gbtree', 'n_estimators': 100, 'max_depth': 15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = OneVsRestClassifier(XGBClassifier(**test_params), n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain)\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08595d37",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "afc25c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'base_estimator':[None, DecisionTreeClassifier(criterion='entropy', max_features='sqrt', class_weight=None, splitter='best')],\n",
    "          'n_estimators':[i for i in range(50, 550, 50)],\n",
    "          'learning_rate':[1*((10)**(i)) for i in range(-4,2,1)]\n",
    "         }\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72468a6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████████▌                                         | 1/2 [06:34<06:34, 394.78s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = OneVsRestClassifier(AdaBoostClassifier(**test_params), n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain)\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46436f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "AdaBoostClassifier('learning_rate'=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdc1177",
   "metadata": {},
   "source": [
    "## Hyper parameter optimization - classifier chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae92039",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0dfa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_neighbors': [1]+[i for i in range(5,55,5)],\n",
    "         'weights':['uniform', 'distance'],\n",
    "         'p':[1,2]}\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ac193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in params:\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in params[param]:\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = ClassifierChain(KNeighborsClassifier(**test_params), n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain)\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fd08d1",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e01d8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C': [1*(10**i) for i in range(-4,2,1)],\n",
    "         'class_weight':[None, \"balanced\"],\n",
    "          'gamma': ['scale', 'auto',2],\n",
    "         'break_ties':[True,False]}\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c50261",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = ClassifierChain(SVC(**test_params), n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain)\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7c7f86",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d18af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'criterion':['gini', 'entropy'],\n",
    "         'max_features':['auto', 'sqrt', 'log2'],\n",
    "         'class_weight':[None, \"balanced\"],\n",
    "         'splitter':['best', 'random']}\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4ace49",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = ClassifierChain(DecisionTreeClassifier(**test_params), n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain)\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7942867",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2c4c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'criterion':['gini', 'entropy'],\n",
    "         'max_features':['auto', 'sqrt', 'log2'],\n",
    "         'class_weight':[None, \"balanced\"],\n",
    "         'n_estimators':[i for i in range(50, 550, 50)]}\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df9ceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = ClassifierChain(RandomForestClassifier(**test_params), n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain)\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c04707",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(criterion='entropy',max_features='auto', class_weight='balanced', n_estimators=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a100cb5",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd0e329",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'solver':['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "          'C': [i for i in range(1,11,1)],\n",
    "         'class_weight':[None, \"balanced\"]}\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551ad194",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = ClassifierChain(LogisticRegression(max_iter=10000,multi_class='ovr',**test_params), n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain)\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdbb513",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de84e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'alpha': [1*((10)**(i)) for i in range(-4,3,1)],\n",
    "         'learning_rate':['constant', 'invscaling', 'adaptive'],\n",
    "          'hidden_layer_sizes':[(50,), (50,50), (50,50,50), (100,), (100,100), (100,100,100)]}\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c286dfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = ClassifierChain(MLPClassifier(max_iter=1000,**test_params), n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain)\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20be6628",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd49ca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'alpha': [1*((10)**(i)) for i in range(-4,3,1)],\n",
    "         'class_weight':[None, \"balanced\"]\n",
    "         }\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d6521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = ClassifierChain(RidgeClassifier(**test_params), n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain)\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4146890",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4134e4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth':[None]+[i for i in range(3,25)]}#'booster': ['gbtree', 'gblinear', 'dart'], 'n_estimators': [i for i in range(100, 500, 25)]}\n",
    "best_params = {'booster': 'gbtree','n_estimators':100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e636a037",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = ClassifierChain(XGBClassifier(**test_params), n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain)\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c133826",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afcafab",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'base_estimator':[None, DecisionTreeClassifier(criterion='entropy', max_features='sqrt', class_weight=None, splitter='best')],\n",
    "          'n_estimators':[i for i in range(50, 550, 50)],\n",
    "          'learning_rate':[1*((10)**(i)) for i in range(-4,2,1)]\n",
    "         }\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39feface",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = ClassifierChain(AdaBoostClassifier(**test_params), n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain)\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92842884",
   "metadata": {},
   "outputs": [],
   "source": [
    "AdaBoostClassifier('learning_rate'=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbcc511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68a132c2",
   "metadata": {},
   "source": [
    "## Hyper parameter optimization - Label Powerset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce107faf",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff58c197",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_neighbors': [1]+[i for i in range(5,55,5)],\n",
    "         'weights':['uniform', 'distance'],\n",
    "         'p':[1,2]}\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4692fbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in params:\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in params[param]:\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = KNeighborsClassifier(**test_params)#, n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain['powerlabel'])\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest['powerlabel'],predictions),3)); train_acc.append(round(accuracy_score(ytrain['powerlabel'],train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest['powerlabel'],predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain['powerlabel'],train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest['powerlabel'],predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain['powerlabel'],train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest['powerlabel'],predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain['powerlabel'],train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest['powerlabel'],predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain['powerlabel'],train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e93597",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1ebc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C': [1*(10**i) for i in range(-4,2,1)],\n",
    "         'class_weight':[None, \"balanced\"],\n",
    "          'gamma': ['scale', 'auto',2],\n",
    "         'break_ties':[True,False]}\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f4938",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = SVC(**test_params)#, n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain['powerlabel'])\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest['powerlabel'],predictions),3)); train_acc.append(round(accuracy_score(ytrain['powerlabel'],train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest['powerlabel'],predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain['powerlabel'],train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest['powerlabel'],predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain['powerlabel'],train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest['powerlabel'],predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain['powerlabel'],train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest['powerlabel'],predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain['powerlabel'],train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecce5a7d",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15297191",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'criterion':['gini', 'entropy'],\n",
    "         'max_features':['auto', 'sqrt', 'log2'],\n",
    "         'class_weight':[None, \"balanced\"],\n",
    "         'splitter':['best', 'random']}\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d686218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = DecisionTreeClassifier(**test_params)#, n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain['powerlabel'])\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest['powerlabel'],predictions),3)); train_acc.append(round(accuracy_score(ytrain['powerlabel'],train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest['powerlabel'],predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain['powerlabel'],train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest['powerlabel'],predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain['powerlabel'],train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest['powerlabel'],predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain['powerlabel'],train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest['powerlabel'],predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain['powerlabel'],train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ce9dd2",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7e8848",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'criterion':['gini', 'entropy'],\n",
    "         'max_features':['auto', 'sqrt', 'log2'],\n",
    "         'class_weight':[None, \"balanced\"],\n",
    "         'n_estimators':[i for i in range(50, 550, 50)]}\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb5d937",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = RandomForestClassifier(**test_params)#, n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain['powerlabel'])\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest['powerlabel'],predictions),3)); train_acc.append(round(accuracy_score(ytrain['powerlabel'],train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest['powerlabel'],predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain['powerlabel'],train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest['powerlabel'],predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain['powerlabel'],train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest['powerlabel'],predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain['powerlabel'],train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest['powerlabel'],predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain['powerlabel'],train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046e553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(criterion='entropy',max_features='auto', class_weight='balanced', n_estimators=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd98554",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ed3b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'solver':['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "          'C': [i for i in range(1,11,1)],\n",
    "         'class_weight':[None, \"balanced\"]}\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd067ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = LogisticRegression(max_iter=10000,multi_class='ovr',**test_params)#, n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain['powerlabel'])\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest['powerlabel'],predictions),3)); train_acc.append(round(accuracy_score(ytrain['powerlabel'],train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest['powerlabel'],predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain['powerlabel'],train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest['powerlabel'],predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain['powerlabel'],train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest['powerlabel'],predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain['powerlabel'],train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest['powerlabel'],predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain['powerlabel'],train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b56961",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5690bce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'alpha': [1*((10)**(i)) for i in range(-4,3,1)],\n",
    "         'learning_rate':['constant', 'invscaling', 'adaptive'],\n",
    "          'hidden_layer_sizes':[(50,), (50,50), (50,50,50), (100,), (100,100), (100,100,100)]}\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d88dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = MLPClassifier(max_iter=1000,**test_params)#, n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain['powerlabel'])\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest['powerlabel'],predictions),3)); train_acc.append(round(accuracy_score(ytrain['powerlabel'],train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest['powerlabel'],predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain['powerlabel'],train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest['powerlabel'],predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain['powerlabel'],train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest['powerlabel'],predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain['powerlabel'],train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest['powerlabel'],predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain['powerlabel'],train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868a6942",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ea29f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'alpha': [1*((10)**(i)) for i in range(-4,3,1)],\n",
    "         'class_weight':[None, \"balanced\"]\n",
    "         }\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f65841",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = RidgeClassifier(**test_params)#, n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain['powerlabel'])\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest['powerlabel'],predictions),3)); train_acc.append(round(accuracy_score(ytrain['powerlabel'],train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest['powerlabel'],predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain['powerlabel'],train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest['powerlabel'],predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain['powerlabel'],train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest['powerlabel'],predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain['powerlabel'],train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest['powerlabel'],predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain['powerlabel'],train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc97ac9b",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10a5869",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth':[None]+[i for i in range(3,25)]}#'booster': ['gbtree', 'gblinear', 'dart'], 'n_estimators': [i for i in range(100, 500, 25)]}\n",
    "best_params = {'booster': 'gbtree','n_estimators':100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4118298",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = XGBClassifier(**test_params)#, n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain['powerlabel'])\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest['powerlabel'],predictions),3)); train_acc.append(round(accuracy_score(ytrain['powerlabel'],train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest['powerlabel'],predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain['powerlabel'],train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest['powerlabel'],predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain['powerlabel'],train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest['powerlabel'],predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain['powerlabel'],train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest['powerlabel'],predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain['powerlabel'],train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0439a983",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2e31b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'base_estimator':[None, DecisionTreeClassifier(criterion='entropy', max_features='sqrt', class_weight=None, splitter='best')],\n",
    "          'n_estimators':[i for i in range(50, 550, 50)],\n",
    "          'learning_rate':[1*((10)**(i)) for i in range(-4,2,1)]\n",
    "         }\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3a69d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = AdaBoostClassifier(**test_params)#, n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain['powerlabel'])\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest['powerlabel'],predictions),3)); train_acc.append(round(accuracy_score(ytrain['powerlabel'],train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest['powerlabel'],predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain['powerlabel'],train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest['powerlabel'],predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain['powerlabel'],train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest['powerlabel'],predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain['powerlabel'],train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest['powerlabel'],predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain['powerlabel'],train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029ba6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "AdaBoostClassifier('learning_rate'=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e34627d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ef9d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea58793a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c88159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.style\n",
    "matplotlib.style.use(\"seaborn\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "sns.color_palette(\"hls\", 17)\n",
    "import scipy.stats as st\n",
    "import math\n",
    "\n",
    "from pingouin import rcorr\n",
    "import pingouin as pg\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputClassifier, ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifierCV, RidgeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, cross_validate, cross_val_score, learning_curve\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, precision_score, recall_score, plot_roc_curve, roc_curve, auc, roc_auc_score,precision_recall_curve, hamming_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn import feature_selection #import chi2\n",
    "\n",
    "import gensim\n",
    "import gensim.downloader as gensim_api\n",
    "## for deep learning\n",
    "from tensorflow.keras import models, layers, preprocessing as kprocessing\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from sys import platform\n",
    "if platform == \"darwin\":\n",
    "    sys.path.append(os.path.dirname(os.path.realpath(__file__)) + \"/..\")\n",
    "    smart_nlp_path = ''\n",
    "elif platform == \"win32\":\n",
    "    sys.path.append('../')\n",
    "    smart_nlp_path = os.getcwd()\n",
    "    smart_nlp_path = \"\\\\\".join([smart_nlp_path.split(\"\\\\\")[i] for i in range(0,len(smart_nlp_path.split(\"\\\\\"))-1)]+[\"/\"])\n",
    "\n",
    "from module.trend_analysis_functions import *\n",
    "from module.topic_model_plus_class import Topic_Model_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(os.path.join(os.path.dirname(os.getcwd()),'data','ICS_predictive_sitreps_full_test.csv')).drop([\"Unnamed: 0\"], axis=1)\n",
    "train_data = pd.read_csv(os.path.join(os.path.dirname(os.getcwd()),'data','ICS_predictive_sitreps_full_train.csv')).drop([\"Unnamed: 0\"], axis=1)\n",
    "val_data = pd.read_csv(os.path.join(os.path.dirname(os.getcwd()),'data','ICS_predictive_sitreps_full_val.csv')).drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [\"TOTAL_PERSONNEL\", \"TOTAL_AERIAL\", \"PCT_CONTAINED_COMPLETED\",\n",
    "              \"ACRES\",  \"WF_FSR\", \"INJURIES\", \"FATALITIES\", \"EST_IM_COST_TO_DATE\", \"STR_DAMAGED\",\n",
    "              \"STR_DESTROYED\", \"NEW_ACRES\", \"EVACUATION_IN_PROGRESS\", \n",
    "              \"NUM_REPORTS\", \"DAYS_BURING\", 'Combined_Text', 'Incident_region_AICC', \n",
    "              'Incident_region_CA', 'Incident_region_EACC','Incident_region_GBCC', 'Incident_region_HICC', \n",
    "              'Incident_region_NRCC','Incident_region_NWCC', 'Incident_region_RMCC', 'Incident_region_SACC',\n",
    "              'Incident_region_SWCC', 'INC_MGMT_ORG_ABBREV_1', 'INC_MGMT_ORG_ABBREV_2','INC_MGMT_ORG_ABBREV_3', \n",
    "              'INC_MGMT_ORG_ABBREV_4','INC_MGMT_ORG_ABBREV_5', 'INC_MGMT_ORG_ABBREV_B','INC_MGMT_ORG_ABBREV_C', \n",
    "              'INC_MGMT_ORG_ABBREV_D','INC_MGMT_ORG_ABBREV_E', 'INC_MGMT_ORG_ABBREV_F']\n",
    "targets = [\"Traffic\",\"Command_Transitions\",\"Evacuations\", \"Inaccurate_Mapping\", \"Aerial_Grounding\", \n",
    "           \"Resource_Issues\", \"Injuries\", \"Cultural_Resources\",\"Livestock\", \"Law_Violations\", \"Military_Base\", \n",
    "           \"Infrastructure\", \"Extreme_Weather\", \"Ecological\", \"Hazardous_Terrain\", \"Floods\", \"Dry_Weather\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_quote_marks(word_list):\n",
    "    word_list = word_list.strip(\"[]\").split(\", \")\n",
    "    word_list = [w.replace(\"'\",\"\") for w in word_list]\n",
    "    word_list = \" \".join(word_list)\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [train_data, val_data, test_data]\n",
    "for df in dfs:\n",
    "    cleaned_combined_text = []\n",
    "    for text in df['Combined_Text']:\n",
    "        cleaned_text = remove_quote_marks(text)\n",
    "        cleaned_combined_text.append(cleaned_text)\n",
    "    df['Combined_Text'] = cleaned_combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = train_data['Combined_Text']; ytrain = train_data[targets]\n",
    "Xval = val_data['Combined_Text']; yval = val_data[targets]\n",
    "Xtest = test_data['Combined_Text']; ytest = test_data[targets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power set label \n",
    "problem transformation to multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-aeffb04db6be>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ytrain['powerlabel'] = ytrain.apply(lambda x : sum([(2**i)*x[targets[i]] for i in range(len(targets))]),axis=1)\n",
      "<ipython-input-8-aeffb04db6be>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  yval['powerlabel'] = yval.apply(lambda x : sum([(2**i)*x[targets[i]] for i in range(len(targets))]),axis=1)\n",
      "<ipython-input-8-aeffb04db6be>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ytest['powerlabel'] = ytest.apply(lambda x : sum([(2**i)*x[targets[i]] for i in range(len(targets))]),axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ytrain['powerlabel'] = ytrain.apply(lambda x : sum([(2**i)*x[targets[i]] for i in range(len(targets))]),axis=1)\n",
    "yval['powerlabel'] = yval.apply(lambda x : sum([(2**i)*x[targets[i]] for i in range(len(targets))]),axis=1)\n",
    "ytest['powerlabel'] = ytest.apply(lambda x : sum([(2**i)*x[targets[i]] for i in range(len(targets))]),axis=1)\n",
    "ytrain['powerlabel'].hist(bins=np.unique(ytrain['powerlabel']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-iDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,3), norm='l2', max_features=10000)\n",
    "vectorizer.fit(Xtrain)\n",
    "Xtrain_vec = vectorizer.transform(Xtrain)\n",
    "Xval_vec =  vectorizer.transform(Xval)\n",
    "Xtest_vec= vectorizer.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decreasing the number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_names = vectorizer.get_feature_names()\n",
    "p_value_limit = 0.95\n",
    "dtf_features = pd.DataFrame()\n",
    "for cat in targets:\n",
    "    chi2, p = feature_selection.chi2(Xtrain_vec, ytrain[[cat]])\n",
    "    dtf_features = dtf_features.append(pd.DataFrame(\n",
    "                   {\"feature\":X_names, \"score\":1-p, \"y\":cat}))\n",
    "    dtf_features = dtf_features.sort_values([\"y\",\"score\"], \n",
    "                    ascending=[True,False])\n",
    "    dtf_features = dtf_features[dtf_features[\"score\"]>p_value_limit]\n",
    "X_names = dtf_features[\"feature\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for cat in y:\n",
    "#    print(\"# {}:\".format(cat))\n",
    "#    print(\"  . selected features:\",\n",
    "#         len(dtf_features[dtf_features[\"y\"]==cat]))\n",
    "#    print(\"  . top features:\", \",\".join(\n",
    "#        dtf_features[dtf_features[\"y\"]==cat][\"feature\"].values[:10]))\n",
    "#    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(vocabulary=X_names)\n",
    "vectorizer.fit(Xtrain)\n",
    "Xtrain_vec = vectorizer.transform(Xtrain)\n",
    "Xval_vec =  vectorizer.transform(Xval)\n",
    "Xtest_vec = vectorizer.transform(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method: classifier chain\n",
    "Note: classifier chains tend to perform worse on larget sets of targets. Also the performance is highly dependent on the order of the chain, so all orderings would ideally be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [LogisticRegression(max_iter=10000,multi_class='ovr'), RandomForestClassifier(random_state=1),\n",
    "              KNeighborsClassifier(weights='distance'), MLPClassifier(random_state=1), RidgeClassifierCV()]\n",
    "classifier_names = ['logistic regression', 'random forest', 'knn', 'MLP NN', 'Ridge']\n",
    "test_hamming_loss = []; train_hamming_loss = []\n",
    "test_acc = []; train_acc = []\n",
    "test_f1 = []; train_f1 = []\n",
    "test_precision = []; train_precision = []\n",
    "test_recall = []; train_recall = []\n",
    "for clf in classifiers:\n",
    "    classifier = ClassifierChain(clf)\n",
    "    classifier.fit(Xtrain_vec, ytrain[targets])\n",
    "    # predict\n",
    "    train_preds = classifier.predict(Xtrain_vec)\n",
    "    predictions = classifier.predict(Xtest_vec)\n",
    "    test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "    test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "    train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "    test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "    train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "    test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "    train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "    test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "    train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "    \n",
    "comparison = pd.DataFrame({\"Base Estimator\": classifier_names,\n",
    "                           \"train f1\": train_f1, \"test f1\": test_f1,\n",
    "                          \"train accuracy\":train_acc, \"test accuracy\": test_acc,\n",
    "                          \"train recall\": train_recall, \"test recall\": test_recall,\n",
    "                          \"train precision\": train_precision, \"test precision\": test_precision,\n",
    "                          \"train hamming loss\": train_hamming_loss, \"test hamming loss\": test_hamming_loss})\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base Estimator</th>\n",
       "      <th>hamming loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.100737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random forest</td>\n",
       "      <td>0.096191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.112589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP NN</td>\n",
       "      <td>0.107931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.101948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Base Estimator  hamming loss\n",
       "0  logistic regression      0.100737\n",
       "1        random forest      0.096191\n",
       "2                  knn      0.112589\n",
       "3               MLP NN      0.107931\n",
       "4                Ridge      0.101948"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method: multioutput classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hamming_loss = []; train_hamming_loss = []\n",
    "test_acc = []; train_acc = []\n",
    "test_f1 = []; train_f1 = []\n",
    "test_precision = []; train_precision = []\n",
    "test_recall = []; train_recall = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [KNeighborsClassifier(weights='distance'),#SVC(kernel=\"linear\", C=0.025),SVC(gamma=2, C=1),\n",
    "               LinearSVC(multi_class='crammer_singer',max_iter=100000, class_weight='balanced'), DecisionTreeClassifier(),\n",
    "               RandomForestClassifier(random_state=1, n_estimators=200),LogisticRegression(max_iter=10000,multi_class='multinomial'),\n",
    "               MLPClassifier(alpha=1, max_iter=1000), RidgeClassifierCV(), AdaBoostClassifier()]\n",
    "               #GaussianNB(), QuadraticDiscriminantAnalysis()]\n",
    "total_names = ['Knn', #\"Linear SVM\", \"RBF SVM\",\n",
    "                \"Linear SVM\", \"Decision Tree\", \"Random Forest\", \n",
    "                   \"Logisitc Regression\", 'MLP NN', 'Ridge', 'Adaboost']#, 'Gaussian NB', 'QDA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▌                                                                         | 1/8 [00:40<04:45, 40.85s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 8/8 [1:12:12<00:00, 541.60s/it]\n"
     ]
    }
   ],
   "source": [
    "for clf in tqdm(classifiers):\n",
    "    classifier = clf#MultiOutputClassifier(clf)#, n_jobs=-1)\n",
    "    classifier.fit(Xtrain_vec, ytrain['powerlabel'])\n",
    "    predictions = classifier.predict(Xtest_vec)\n",
    "    train_preds = classifier.predict(Xtrain_vec)\n",
    "    test_acc.append(round(accuracy_score(ytest['powerlabel'],predictions),3)); train_acc.append(round(accuracy_score(ytrain['powerlabel'],train_preds),3))\n",
    "    test_f1.append(round(f1_score(ytest['powerlabel'],predictions, average='macro',zero_division=0),3))\n",
    "    train_f1.append(round(f1_score(ytrain['powerlabel'],train_preds, average='macro',zero_division=0),3))\n",
    "    test_precision.append(round(precision_score(ytest['powerlabel'],predictions, average='macro', zero_division=0),3))\n",
    "    train_precision.append(round(precision_score(ytrain['powerlabel'],train_preds, average='macro', zero_division=0),3))\n",
    "    test_recall.append(round(recall_score(ytest['powerlabel'],predictions, average='macro', zero_division=0),3))\n",
    "    train_recall.append(round(recall_score(ytrain['powerlabel'],train_preds, average='macro', zero_division=0),3))\n",
    "    test_hamming_loss.append(round(hamming_loss(ytest['powerlabel'],predictions),3))\n",
    "    train_hamming_loss.append(round(hamming_loss(ytrain['powerlabel'],train_preds),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>train f1</th>\n",
       "      <th>test f1</th>\n",
       "      <th>train accuracy</th>\n",
       "      <th>test accuracy</th>\n",
       "      <th>train recall</th>\n",
       "      <th>test recall</th>\n",
       "      <th>train precision</th>\n",
       "      <th>test precision</th>\n",
       "      <th>train hamming loss</th>\n",
       "      <th>test hamming loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Knn</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logisitc Regression</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP NN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  train f1  test f1  train accuracy  test accuracy  \\\n",
       "0                  Knn     0.997    0.003           0.997          0.401   \n",
       "1           Linear SVM     0.551    0.001           0.353          0.007   \n",
       "2        Decision Tree     0.997    0.003           0.997          0.329   \n",
       "3        Random Forest     0.997    0.003           0.997          0.416   \n",
       "4  Logisitc Regression     0.143    0.006           0.575          0.416   \n",
       "5               MLP NN     0.001    0.003           0.416          0.415   \n",
       "6                Ridge     0.220    0.003           0.588          0.408   \n",
       "7             Adaboost     0.002    0.003           0.424          0.423   \n",
       "\n",
       "   train recall  test recall  train precision  test precision  \\\n",
       "0         0.996        0.004            0.998           0.007   \n",
       "1         0.964        0.003            0.441           0.002   \n",
       "2         0.996        0.003            0.998           0.004   \n",
       "3         0.997        0.004            0.997           0.008   \n",
       "4         0.124        0.007            0.215           0.007   \n",
       "5         0.001        0.004            0.000           0.002   \n",
       "6         0.206        0.004            0.313           0.003   \n",
       "7         0.003        0.005            0.002           0.002   \n",
       "\n",
       "   train hamming loss  test hamming loss  \n",
       "0               0.003              0.599  \n",
       "1               0.647              0.993  \n",
       "2               0.003              0.671  \n",
       "3               0.003              0.584  \n",
       "4               0.425              0.584  \n",
       "5               0.584              0.585  \n",
       "6               0.412              0.592  \n",
       "7               0.576              0.577  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison = pd.DataFrame({\"Model\":total_names,\n",
    "                           \"train f1\": train_f1, \"test f1\": test_f1,\n",
    "                          \"train accuracy\":train_acc, \"test accuracy\": test_acc,\n",
    "                          \"train recall\": train_recall, \"test recall\": test_recall,\n",
    "                          \"train precision\": train_precision, \"test precision\": test_precision,\n",
    "                          \"train hamming loss\": train_hamming_loss, \"test hamming loss\": test_hamming_loss})\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method: One vs Rest classifier\n",
    "note: this one performs better without the extreme over sampling -> maybe a simple over sampling approach is preferred here. Over fitting is definitely occuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = ytrain[targets]\n",
    "ytest = ytest[targets]\n",
    "yval = yval[targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [KNeighborsClassifier(weights='uniform', p=2,n_neighbors=45),SVC(kernel=\"linear\", C=0.025),SVC(gamma=2, C=1),\n",
    "               #GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "               DecisionTreeClassifier(criterion='entropy', max_features='sqrt', class_weight=None, splitter='best'),\n",
    "               RandomForestClassifier(criterion='entropy',max_features='auto', class_weight='balanced', n_estimators=100),\n",
    "               LogisticRegression(max_iter=10000,multi_class='ovr',solver='sag'),\n",
    "               MLPClassifier(alpha=1, max_iter=1000), \n",
    "               RidgeClassifier(alpha=10), AdaBoostClassifier(learning_rate=1), \n",
    "               XGBClassifier(booster='gbtree', n_estimators=100, max_depth=4)\n",
    "              ]#GaussianNB(), QuadraticDiscriminantAnalysis()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [KNeighborsClassifier(weights='uniform', p=2,n_neighbors=45),SVC(kernel=\"linear\", C=0.025),SVC(gamma='scale', break_ties=True, C=1),\n",
    "               #GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "               DecisionTreeClassifier(criterion='gini', max_features='auto', class_weight=None, splitter='random'),\n",
    "               RandomForestClassifier(criterion='gini',max_features='auto', class_weight=None, n_estimators=50),\n",
    "               LogisticRegression(max_iter=10000,multi_class='ovr',solver='newton-cg', C=1),\n",
    "               MLPClassifier(alpha=1, max_iter=1000, learning_rate='constant', hidden_layer_sizes=(50, 50)), RidgeClassifier(alpha=10), AdaBoostClassifier(learning_rate=0.1,n_estimators=50), \n",
    "               XGBClassifier(booster='gbtree', n_estimators=100, max_depth=None, eval_metric='logloss', use_label_encoder=False)\n",
    "              ]#GaussianNB(), QuadraticDiscriminantAnalysis()]\n",
    "classifier_name = ['Knn', \"Linear SVM\", \"RBF SVM\", #\"Gaussian Process\",\n",
    "                   \"Decision Tree\", \"Random Forest\", \n",
    "                   \"Logisitc Regression\", 'MLP NN', 'Ridge', 'Adaboost', 'XGBoost' ]#,'Gaussian NB', 'QDA'\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hamming_loss = []; train_hamming_loss = []\n",
    "test_acc = []; train_acc = []\n",
    "test_f1 = []; train_f1 = []\n",
    "test_precision = []; train_precision = []\n",
    "test_recall = []; train_recall = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 10/10 [3:52:28<00:00, 1394.81s/it]\n"
     ]
    }
   ],
   "source": [
    "for clf in tqdm(classifiers):\n",
    "    classifier = OneVsRestClassifier(clf)#, n_jobs=-1)\n",
    "    classifier.fit(Xtrain_vec, ytrain)\n",
    "    predictions = classifier.predict(Xtest_vec)\n",
    "    train_preds = classifier.predict(Xtrain_vec)\n",
    "    test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "    test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "    train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "    test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "    train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "    test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "    train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "    test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "    train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame({\"Model\":classifier_name,\n",
    "                          \"train f1\": train_f1, \"test f1\": test_f1,\n",
    "                          \"train accuracy\":train_acc, \"test accuracy\": test_acc,\n",
    "                          \"train recall\": train_recall, \"test recall\": test_recall,\n",
    "                          \"train precision\": train_precision, \"test precision\": test_precision,\n",
    "                          \"train hamming loss\": train_hamming_loss, \"test hamming loss\": test_hamming_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>train f1</th>\n",
       "      <th>test f1</th>\n",
       "      <th>train accuracy</th>\n",
       "      <th>test accuracy</th>\n",
       "      <th>train recall</th>\n",
       "      <th>test recall</th>\n",
       "      <th>train precision</th>\n",
       "      <th>test precision</th>\n",
       "      <th>train hamming loss</th>\n",
       "      <th>test hamming loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Knn</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.162</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logisitc Regression</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLP NN</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  train f1  test f1  train accuracy  test accuracy  \\\n",
       "0                  Knn     0.527    0.019           0.475          0.408   \n",
       "1           Linear SVM     0.091    0.072           0.426          0.425   \n",
       "2              RBF SVM     0.898    0.165           0.776          0.424   \n",
       "3        Decision Tree     0.999    0.172           0.997          0.233   \n",
       "4        Random Forest     0.998    0.103           0.993          0.428   \n",
       "5  Logisitc Regression     0.629    0.202           0.498          0.409   \n",
       "6               MLP NN     0.427    0.185           0.473          0.414   \n",
       "7                Ridge     0.484    0.163           0.472          0.410   \n",
       "8             Adaboost     0.229    0.133           0.425          0.430   \n",
       "9              XGBoost     0.863    0.264           0.660          0.417   \n",
       "\n",
       "   train recall  test recall  train precision  test precision  \\\n",
       "0         0.373        0.010            0.956           0.281   \n",
       "1         0.073        0.059            0.619           0.147   \n",
       "2         0.834        0.120            0.976           0.504   \n",
       "3         0.998        0.162            1.000           0.186   \n",
       "4         0.996        0.079            0.999           0.283   \n",
       "5         0.497        0.154            0.895           0.408   \n",
       "6         0.334        0.146            0.719           0.374   \n",
       "7         0.359        0.120            0.881           0.451   \n",
       "8         0.157        0.092            0.820           0.338   \n",
       "9         0.782        0.208            0.974           0.425   \n",
       "\n",
       "   train hamming loss  test hamming loss  \n",
       "0               0.081              0.109  \n",
       "1               0.102              0.096  \n",
       "2               0.021              0.092  \n",
       "3               0.000              0.141  \n",
       "4               0.001              0.095  \n",
       "5               0.063              0.095  \n",
       "6               0.069              0.093  \n",
       "7               0.072              0.094  \n",
       "8               0.100              0.095  \n",
       "9               0.037              0.093  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_neighbors': [1]+[i for i in range(5,55,5)],\n",
    "         'weights':['uniform', 'distance'],\n",
    "         'p':[1,2]}\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 45, 'weights': 'uniform', 'p': 2}\n"
     ]
    }
   ],
   "source": [
    "for param in params:\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in params[param]:\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = OneVsRestClassifier(KNeighborsClassifier(**test_params))#, n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain)\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C': [1*(10**i) for i in range(-4,2,1)],\n",
    "         'class_weight':[None, \"balanced\"],\n",
    "          'gamma': ['scale', 'auto',2],\n",
    "         'break_ties':[True,False]}\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|█████████████▎                                                                  | 1/6 [46:46<3:53:51, 2806.28s/it]\u001b[A\n",
      " 33%|██████████████████████████                                                    | 2/6 [1:32:29<3:05:49, 2787.46s/it]\u001b[A\n",
      " 50%|███████████████████████████████████████                                       | 3/6 [2:18:16<2:18:45, 2775.09s/it]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████                          | 4/6 [3:07:28<1:34:16, 2828.38s/it]\u001b[A\n",
      " 83%|██████████████████████████████████████████████████████████████████▋             | 5/6 [4:28:52<57:24, 3444.91s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 6/6 [6:30:51<00:00, 3908.61s/it]\u001b[A\n",
      " 25%|███████████████████                                                         | 1/4 [6:30:51<19:32:35, 23451.67s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|███████████████████████████████████████                                       | 1/2 [1:21:21<1:21:21, 4881.82s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [2:55:44<00:00, 5272.32s/it]\u001b[A\n",
      " 50%|██████████████████████████████████████                                      | 2/4 [9:26:36<10:52:39, 19579.57s/it]\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|██████████████████████████                                                    | 1/3 [1:21:40<2:43:21, 4900.78s/it]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████                          | 2/3 [1:57:49<1:08:01, 4081.26s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 3/3 [4:12:35<00:00, 5051.88s/it]\u001b[A\n",
      " 75%|█████████████████████████████████████████████████████████                   | 3/4 [13:39:11<5:04:12, 18252.39s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|███████████████████████████████████████                                       | 1/2 [1:21:06<1:21:06, 4866.81s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [2:42:26<00:00, 4873.22s/it]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 4/4 [16:21:38<00:00, 14724.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'class_weight': None, 'gamma': 'scale', 'break_ties': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = OneVsRestClassifier(SVC(**test_params))#, n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain)\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'criterion':['gini', 'entropy'],\n",
    "         'max_features':['auto', 'sqrt', 'log2'],\n",
    "         'class_weight':[None, \"balanced\"],\n",
    "         'splitter':['best', 'random']}\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████████▌                                         | 1/2 [02:17<02:17, 137.78s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [03:46<00:00, 113.40s/it]\u001b[A\n",
      " 25%|████████████████████▊                                                              | 1/4 [03:46<11:20, 226.79s/it]\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|████████████████████████████                                                        | 1/3 [00:08<00:17,  8.67s/it]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████                            | 2/3 [00:17<00:08,  8.65s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:27<00:00,  9.19s/it]\u001b[A\n",
      " 50%|█████████████████████████████████████████▌                                         | 2/4 [04:14<05:34, 167.03s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:08<00:08,  8.88s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:16<00:00,  8.30s/it]\u001b[A\n",
      " 75%|██████████████████████████████████████████████████████████████▎                    | 3/4 [04:30<02:01, 121.91s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:08<00:08,  8.65s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:19<00:00,  9.75s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [04:50<00:00, 72.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_features': 'auto', 'class_weight': None, 'splitter': 'random'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = OneVsRestClassifier(DecisionTreeClassifier(**test_params))#, n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain)\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'criterion':['gini', 'entropy'],\n",
    "         'max_features':['auto', 'sqrt', 'log2'],\n",
    "         'class_weight':[None, \"balanced\"],\n",
    "         'n_estimators':[i for i in range(50, 550, 50)]}\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████████▌                                         | 1/2 [09:44<09:44, 584.60s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [18:19<00:00, 549.85s/it]\u001b[A\n",
      " 25%|████████████████████▌                                                             | 1/4 [18:19<54:59, 1099.71s/it]\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███████████████████████████▋                                                       | 1/3 [09:43<19:27, 583.95s/it]\u001b[A\n",
      " 67%|███████████████████████████████████████████████████████▎                           | 2/3 [19:28<09:44, 584.09s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [30:29<00:00, 609.92s/it]\u001b[A\n",
      " 50%|█████████████████████████████████████████                                         | 2/4 [48:49<43:57, 1318.73s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████████▌                                         | 1/2 [09:42<09:42, 582.24s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [18:40<00:00, 560.20s/it]\u001b[A\n",
      " 75%|████████████████████████████████████████████████████████████                    | 3/4 [1:07:29<20:59, 1259.23s/it]\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|████████▏                                                                         | 1/10 [04:53<43:58, 293.17s/it]\u001b[A\n",
      " 20%|████████████████▍                                                                 | 2/10 [14:35<50:40, 380.01s/it]\u001b[A\n",
      " 30%|████████████████████████                                                        | 3/10 [29:09<1:01:37, 528.18s/it]\u001b[A\n",
      " 40%|████████████████████████████████                                                | 4/10 [48:35<1:11:56, 719.49s/it]\u001b[A\n",
      " 50%|███████████████████████████████████████                                       | 5/10 [1:12:49<1:18:19, 939.82s/it]\u001b[A\n",
      " 60%|██████████████████████████████████████████████▏                              | 6/10 [1:41:50<1:18:40, 1180.21s/it]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████▉                       | 7/10 [2:15:52<1:11:55, 1438.58s/it]\u001b[A\n",
      " 80%|███████████████████████████████████████████████████████████████▏               | 8/10 [2:54:45<56:54, 1707.13s/it]\u001b[A\n",
      " 90%|███████████████████████████████████████████████████████████████████████        | 9/10 [3:38:26<33:01, 1981.27s/it]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 10/10 [4:27:09<00:00, 1602.94s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 4/4 [5:34:39<00:00, 5019.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_features': 'auto', 'class_weight': None, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = OneVsRestClassifier(RandomForestClassifier(**test_params))#, n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain)\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(criterion='gini',max_features='auto', class_weight='None', n_estimators=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'solver':['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "          'C': [i for i in range(1,11,1)],\n",
    "         'class_weight':[None, \"balanced\"]}\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|█████████████████████                                                               | 1/4 [00:07<00:21,  7.22s/it]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 2/4 [00:12<00:13,  6.75s/it]\u001b[A\n",
      " 75%|███████████████████████████████████████████████████████████████                     | 3/4 [00:16<00:05,  5.82s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:24<00:00,  6.14s/it]\u001b[A\n",
      " 33%|████████████████████████████                                                        | 1/3 [00:24<00:49, 24.58s/it]\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|████████▎                                                                          | 1/10 [00:06<01:00,  6.69s/it]\u001b[A\n",
      " 20%|████████████████▌                                                                  | 2/10 [00:13<00:54,  6.86s/it]\u001b[A\n",
      " 30%|████████████████████████▉                                                          | 3/10 [00:21<00:50,  7.18s/it]\u001b[A\n",
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:30<00:45,  7.54s/it]\u001b[A\n",
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:38<00:39,  7.83s/it]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [00:47<00:32,  8.11s/it]\u001b[A\n",
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [00:56<00:25,  8.41s/it]\u001b[A\n",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [01:06<00:17,  8.72s/it]\u001b[A\n",
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [01:15<00:08,  8.93s/it]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:25<00:00,  8.53s/it]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████                            | 2/3 [01:49<00:42, 42.80s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:06<00:06,  6.54s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:13<00:00,  6.78s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [02:03<00:00, 41.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'newton-cg', 'C': 1, 'class_weight': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = OneVsRestClassifier(LogisticRegression(max_iter=10000,multi_class='ovr',**test_params))#, n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain)\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'alpha': [1*((10)**(i)) for i in range(-4,3,1)],\n",
    "         'learning_rate':['constant', 'invscaling', 'adaptive'],\n",
    "          'hidden_layer_sizes':[(50,), (50,50), (50,50,50), (100,), (100,100), (100,100,100)]}\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|██████████▊                                                                 | 1/7 [3:01:23<18:08:20, 10883.44s/it]\u001b[A\n",
      " 29%|█████████████████████▋                                                      | 2/7 [6:35:46<15:56:26, 11477.24s/it]\u001b[A\n",
      " 43%|████████████████████████████████▏                                          | 3/7 [11:20:18<14:37:02, 13155.61s/it]\u001b[A\n",
      " 57%|███████████████████████████████████████████▍                                | 4/7 [13:49:08<9:54:24, 11888.07s/it]\u001b[A\n",
      " 71%|███████████████████████████████████████████████████████                      | 5/7 [14:32:28<5:03:23, 9101.64s/it]\u001b[A\n",
      " 86%|██████████████████████████████████████████████████████████████████           | 6/7 [15:46:18<2:08:20, 7700.23s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 7/7 [16:54:14<00:00, 8693.46s/it]\u001b[A\n",
      " 33%|█████████████████████████                                                  | 1/3 [16:54:14<33:48:28, 60854.24s/it]\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|██████████████████████████▋                                                     | 1/3 [47:42<1:35:24, 2862.24s/it]\u001b[A\n",
      " 67%|█████████████████████████████████████████████████████▎                          | 2/3 [1:34:31<47:26, 2846.41s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 3/3 [2:22:48<00:00, 2856.29s/it]\u001b[A\n",
      " 67%|██████████████████████████████████████████████████                         | 2/3 [19:17:03<12:32:48, 45168.63s/it]\n",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|█████████████▎                                                                  | 1/6 [23:58<1:59:53, 1438.77s/it]\u001b[A\n",
      " 33%|██████████████████████████                                                    | 2/6 [1:26:36<2:22:17, 2134.39s/it]\u001b[A\n",
      " 50%|███████████████████████████████████████                                       | 3/6 [2:49:33<2:29:21, 2987.24s/it]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████                          | 4/6 [3:36:14<1:37:42, 2931.36s/it]\u001b[A\n",
      " 83%|█████████████████████████████████████████████████████████████████             | 5/6 [5:30:50<1:08:34, 4114.89s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 6/6 [7:43:49<00:00, 4638.21s/it]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3/3 [27:00:52<00:00, 32417.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1, 'learning_rate': 'constant', 'hidden_layer_sizes': (50, 50)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = OneVsRestClassifier(MLPClassifier(max_iter=1000,**test_params))#, n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain)\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'alpha': [1*((10)**(i)) for i in range(-4,3,1)],\n",
    "         'class_weight':[None, \"balanced\"]\n",
    "         }\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|████████████                                                                        | 1/7 [00:06<00:39,  6.54s/it]\u001b[A\n",
      " 29%|████████████████████████                                                            | 2/7 [00:12<00:32,  6.46s/it]\u001b[A\n",
      " 43%|████████████████████████████████████                                                | 3/7 [00:18<00:24,  6.18s/it]\u001b[A\n",
      " 57%|████████████████████████████████████████████████                                    | 4/7 [00:22<00:16,  5.43s/it]\u001b[A\n",
      " 71%|████████████████████████████████████████████████████████████                        | 5/7 [00:24<00:08,  4.45s/it]\u001b[A\n",
      " 86%|████████████████████████████████████████████████████████████████████████            | 6/7 [00:25<00:03,  3.51s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:26<00:00,  3.77s/it]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:26<00:26, 26.41s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:01<00:01,  1.27s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.31s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:29<00:00, 14.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 10, 'class_weight': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = OneVsRestClassifier(RidgeClassifier(**test_params))#, n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain)\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth':[None]+[i for i in range(3,25)]}#'booster': ['gbtree', 'gblinear', 'dart'], 'n_estimators': [i for i in range(100, 500, 25)]}\n",
    "best_params = {'booster': 'gbtree','n_estimators':100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]\n",
      "  0%|                                                                                           | 0/23 [00:00<?, ?it/s]\u001b[AC:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:35:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:36:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:36:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:36:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:36:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:36:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:36:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:36:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:36:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:36:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:36:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:36:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:36:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:36:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:37:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:37:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:37:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|███▌                                                                               | 1/23 [01:25<31:30, 85.95s/it]\u001b[AC:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:37:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:37:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:37:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:37:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:37:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:37:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:37:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:37:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:37:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:37:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:37:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:37:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:37:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:37:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:38:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:38:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:38:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  9%|███████▏                                                                           | 2/23 [02:16<26:22, 75.35s/it]\u001b[AC:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:38:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:38:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:38:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:38:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:38:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:38:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:38:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:38:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:38:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:38:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:38:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:38:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:38:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:39:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:39:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:39:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:39:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|██████████▊                                                                        | 3/23 [03:21<24:05, 72.29s/it]\u001b[AC:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:39:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:39:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:39:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:39:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:39:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:39:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:39:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:39:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:39:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:40:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:40:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:40:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:40:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:40:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:40:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:40:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:40:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|██████████████▍                                                                    | 4/23 [04:40<23:30, 74.23s/it]\u001b[AC:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:40:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:40:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:40:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:40:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:40:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:41:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:41:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:41:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:41:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:41:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:41:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:41:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:41:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:41:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:41:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:41:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:42:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██████████████████                                                                 | 5/23 [06:12<23:51, 79.52s/it]\u001b[AC:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:42:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:42:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:42:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:42:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:42:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:42:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:42:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:42:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:43:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:43:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:43:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:43:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:43:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:43:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:43:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:43:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:43:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|█████████████████████▋                                                             | 6/23 [07:59<24:54, 87.92s/it]\u001b[AC:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:43:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:44:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:44:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:44:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:44:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:44:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:44:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:44:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:44:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:45:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:45:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:45:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:45:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:45:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:45:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:45:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:45:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|█████████████████████████▎                                                         | 7/23 [09:59<26:00, 97.53s/it]\u001b[AC:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:45:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:46:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:46:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:46:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:46:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:46:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:46:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:46:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:47:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:47:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:47:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:47:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:47:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:47:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:47:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:47:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:47:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|████████████████████████████▌                                                     | 8/23 [12:10<26:50, 107.37s/it]\u001b[AC:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:48:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:48:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:48:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:48:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:48:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:48:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:49:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:49:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:49:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:49:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:49:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:49:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:49:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:49:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:50:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:50:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:50:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 39%|████████████████████████████████                                                  | 9/23 [14:32<27:30, 117.90s/it]\u001b[AC:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:50:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:50:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:50:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:50:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:51:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:51:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:51:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:51:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:52:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:52:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:52:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:52:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:52:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:52:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:52:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:52:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 43%|███████████████████████████████████▏                                             | 10/23 [17:09<28:03, 129.48s/it]\u001b[AC:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:53:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:53:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:53:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:53:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:53:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:53:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:54:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:54:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:54:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:54:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:54:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:54:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:54:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:55:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:55:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:55:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:55:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 48%|██████████████████████████████████████▋                                          | 11/23 [19:54<28:04, 140.35s/it]\u001b[AC:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:55:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:56:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:56:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:56:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:56:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:56:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:57:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:57:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:57:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:57:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:57:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:57:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:57:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:58:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:58:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:58:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:58:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 52%|██████████████████████████████████████████▎                                      | 12/23 [22:51<27:44, 151.30s/it]\u001b[AC:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:58:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:58:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:59:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:59:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:59:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:59:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:00:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:00:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:00:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:00:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:00:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:00:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:00:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:01:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:01:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:01:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:01:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 57%|█████████████████████████████████████████████▊                                   | 13/23 [26:00<27:04, 162.47s/it]\u001b[AC:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:01:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:02:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:02:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:02:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:02:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:03:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:03:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:03:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:03:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:03:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:03:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:04:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:04:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:04:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:04:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:04:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:04:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 61%|█████████████████████████████████████████████████▎                               | 14/23 [29:18<25:59, 173.26s/it]\u001b[AC:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:05:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:05:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:05:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:05:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:06:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:06:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:06:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:06:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:07:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:07:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:07:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:07:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:07:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:07:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:08:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:08:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:08:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|████████████████████████████████████████████████████▊                            | 15/23 [32:47<24:31, 183.88s/it]\u001b[AC:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:08:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:08:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:09:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:09:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:09:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:09:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:10:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:10:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:10:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:10:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:10:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:11:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:11:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:11:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:11:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:11:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:12:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|████████████████████████████████████████████████████████▎                        | 16/23 [36:25<22:39, 194.28s/it]\u001b[AC:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:12:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:13:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:13:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:13:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:14:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:14:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:14:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:14:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:14:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:14:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:15:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:15:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:15:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 74%|███████████████████████████████████████████████████████████▊                     | 17/23 [40:14<20:26, 204.49s/it]\u001b[AC:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:16:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:16:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:16:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:17:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:17:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:17:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:17:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:18:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:18:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:18:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:18:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:18:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:18:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:19:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:19:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:19:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:19:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 78%|███████████████████████████████████████████████████████████████▍                 | 18/23 [44:12<17:52, 214.57s/it]\u001b[AC:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:20:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:20:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:20:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:21:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:21:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:21:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:21:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:22:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:22:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:22:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:22:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:22:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:22:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:23:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:23:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:23:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:23:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 83%|██████████████████████████████████████████████████████████████████▉              | 19/23 [48:20<14:58, 224.57s/it]\u001b[AC:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:24:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:25:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:25:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:25:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:26:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:26:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:26:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:26:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:26:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:26:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:27:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:27:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:27:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:28:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:28:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 87%|██████████████████████████████████████████████████████████████████████▍          | 20/23 [52:37<11:43, 234.36s/it]\u001b[AC:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:28:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:28:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:29:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:29:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:29:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:30:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:30:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:30:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:31:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:31:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:31:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:31:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:31:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:32:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:32:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:32:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:32:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 91%|█████████████████████████████████████████████████████████████████████████▉       | 21/23 [57:12<08:12, 246.45s/it]\u001b[AC:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:33:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:33:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:33:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:34:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:34:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:34:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:35:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:35:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:35:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:35:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:35:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:36:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:36:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:36:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:36:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:37:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:37:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 96%|███████████████████████████████████████████████████████████████████████████▌   | 22/23 [1:01:46<04:14, 254.76s/it]\u001b[AC:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:37:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:38:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:38:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:38:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:39:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:39:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:39:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:40:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:40:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:40:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:40:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:40:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:40:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:41:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:41:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:41:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:42:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 23/23 [1:06:28<00:00, 173.41s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 1/1 [1:06:28<00:00, 3988.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'booster': 'gbtree', 'n_estimators': 100, 'max_depth': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = OneVsRestClassifier(XGBClassifier(**test_params))#, n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain)\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'base_estimator':[None, DecisionTreeClassifier(criterion='entropy', max_features='sqrt', class_weight=None, splitter='best')],\n",
    "          'n_estimators':[i for i in range(50, 550, 50)],\n",
    "          'learning_rate':[1*((10)**(i)) for i in range(-4,2,1)]\n",
    "         }\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [01:13<01:13, 73.60s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [03:11<00:00, 95.58s/it]\u001b[A\n",
      " 33%|███████████████████████████▋                                                       | 1/3 [03:11<06:22, 191.16s/it]\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|████████▎                                                                          | 1/10 [01:12<10:55, 72.82s/it]\u001b[A\n",
      " 20%|████████████████▌                                                                  | 2/10 [03:39<12:39, 94.95s/it]\u001b[A\n",
      " 30%|████████████████████████▌                                                         | 3/10 [07:18<15:25, 132.24s/it]\u001b[A\n",
      " 40%|████████████████████████████████▊                                                 | 4/10 [12:09<17:59, 179.91s/it]\u001b[A\n",
      " 50%|█████████████████████████████████████████                                         | 5/10 [18:12<19:33, 234.76s/it]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████▏                                | 6/10 [25:28<19:40, 295.10s/it]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████████▍                        | 7/10 [33:55<17:56, 358.79s/it]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 8/10 [43:38<14:12, 426.02s/it]\u001b[A\n",
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 9/10 [54:36<08:15, 495.49s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 10/10 [1:06:42<00:00, 400.29s/it]\u001b[A\n",
      " 67%|█████████████████████████████████████████████████████▎                          | 2/3 [1:09:54<22:14, 1334.68s/it]\n",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|██████████████                                                                      | 1/6 [01:13<06:06, 73.33s/it]\u001b[A\n",
      " 33%|████████████████████████████                                                        | 2/6 [02:25<04:51, 72.98s/it]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 3/6 [03:38<03:38, 72.94s/it]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████                            | 4/6 [04:50<02:25, 72.82s/it]\u001b[A\n",
      " 83%|██████████████████████████████████████████████████████████████████████              | 5/6 [06:03<01:12, 72.83s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [06:35<00:00, 65.94s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 3/3 [1:16:29<00:00, 1529.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_estimator': None, 'n_estimators': 50, 'learning_rate': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for param in tqdm(params):\n",
    "    test_hamming_loss = []; train_hamming_loss = []\n",
    "    test_acc = []; train_acc = []\n",
    "    test_f1 = []; train_f1 = []\n",
    "    test_precision = []; train_precision = []\n",
    "    test_recall = []; train_recall = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        classifier = OneVsRestClassifier(AdaBoostClassifier(**test_params))#, n_jobs=-1)\n",
    "        classifier.fit(Xtrain_vec, ytrain)\n",
    "        predictions = classifier.predict(Xtest_vec)\n",
    "        train_preds = classifier.predict(Xtrain_vec)\n",
    "        test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "        test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "        train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "        test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "        train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "        test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "        train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "    best_params[param] = params[param][np.argmin(test_hamming_loss)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expression cannot contain assignment, perhaps you meant \"==\"? (<ipython-input-30-34170afdf0e9>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-30-34170afdf0e9>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    AdaBoostClassifier('learning_rate'=1)\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expression cannot contain assignment, perhaps you meant \"==\"?\n"
     ]
    }
   ],
   "source": [
    "AdaBoostClassifier(learning_rate=0.1,n_estimators=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method: LSTM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_lstm(history_window, num_features, num_neurons):\n",
    "    \n",
    "    input_layer = keras.layers.Input(shape=(history_window, num_features))\n",
    "    \n",
    "    rnn_layer = keras.layers.LSTM(num_neurons, activation='sigmoid')(input_layer)\n",
    "    \n",
    "    output = keras.layers.Dense(num_features)(rnn_layer)\n",
    "\n",
    "    LSTM_model = keras.Model(input_layer, output)\n",
    "    \n",
    "    return LSTM_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot confusion matrix\n",
    "\n",
    "ml_cm = multilabel_confusion_matrix(ytest.to_numpy(), predicted)\n",
    "i=0\n",
    "for cm in ml_cm:\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, \n",
    "                cbar=False)\n",
    "    ax.set(xlabel=\"Pred\", ylabel=\"True\", title=\"Confusion matrix \"+targets[i])\n",
    "    plt.yticks(rotation=0)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

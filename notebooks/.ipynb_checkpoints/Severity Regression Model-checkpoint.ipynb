{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.style\n",
    "matplotlib.style.use(\"seaborn\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "sns.color_palette(\"hls\", 17)\n",
    "#import scipy.stats as st\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "from pingouin import rcorr\n",
    "import pingouin as pg\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.multioutput import RegressorChain, MultiOutputRegressor\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifierCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm \n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, cross_validate, cross_val_score, learning_curve\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, precision_score, recall_score, plot_roc_curve, roc_curve, auc, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import feature_selection #import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(\"..\"))\n",
    "\n",
    "from module.trend_analysis_functions import *\n",
    "from module.topic_model_plus_class import Topic_Model_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(os.path.join(os.path.dirname(os.getcwd()),'data','ICS_predictive_sitreps_full_test.csv')).drop([\"Unnamed: 0\"], axis=1)\n",
    "train_data = pd.read_csv(os.path.join(os.path.dirname(os.getcwd()),'data','ICS_predictive_sitreps_full_train.csv')).drop([\"Unnamed: 0\"], axis=1)\n",
    "val_data = pd.read_csv(os.path.join(os.path.dirname(os.getcwd()),'data','ICS_predictive_sitreps_full_val.csv')).drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CY</th>\n",
       "      <th>DISCOVERY_DATE</th>\n",
       "      <th>INCIDENT_ID</th>\n",
       "      <th>PCT_CONTAINED_COMPLETED</th>\n",
       "      <th>START_YEAR</th>\n",
       "      <th>TOTAL_AERIAL</th>\n",
       "      <th>TOTAL_PERSONNEL</th>\n",
       "      <th>REPORT_DOY</th>\n",
       "      <th>DISCOVERY_DOY</th>\n",
       "      <th>Combined_Text</th>\n",
       "      <th>...</th>\n",
       "      <th>INC_MGMT_ORG_ABBREV_2</th>\n",
       "      <th>INC_MGMT_ORG_ABBREV_3</th>\n",
       "      <th>INC_MGMT_ORG_ABBREV_4</th>\n",
       "      <th>INC_MGMT_ORG_ABBREV_5</th>\n",
       "      <th>INC_MGMT_ORG_ABBREV_A</th>\n",
       "      <th>INC_MGMT_ORG_ABBREV_B</th>\n",
       "      <th>INC_MGMT_ORG_ABBREV_C</th>\n",
       "      <th>INC_MGMT_ORG_ABBREV_D</th>\n",
       "      <th>INC_MGMT_ORG_ABBREV_E</th>\n",
       "      <th>INC_MGMT_ORG_ABBREV_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>7/15/2010 15:00</td>\n",
       "      <td>2000_CA-RRU-062485_VALLEY COMPLEX</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.052083</td>\n",
       "      <td>0.043860</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "      <td>['resource', 'share', 'cactus']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>7/15/2010 15:00</td>\n",
       "      <td>2000_CA-RRU-062485_VALLEY COMPLEX</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.052083</td>\n",
       "      <td>0.043860</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "      <td>['resource', 'share', 'incident', 'cactus', 'i...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>7/15/2010 15:00</td>\n",
       "      <td>2000_CA-RRU-062485_VALLEY COMPLEX</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.031465</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "      <td>['resource', 'share', 'cactus', 'erratic', 'wi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>7/15/2010 15:00</td>\n",
       "      <td>2000_CA-RRU-062485_VALLEY COMPLEX</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.045139</td>\n",
       "      <td>0.036677</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "      <td>['resource', 'share', 'cactus', 'cactus', 'bec...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>7/15/2010 15:00</td>\n",
       "      <td>2000_CA-RRU-062485_VALLEY COMPLEX</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.045139</td>\n",
       "      <td>0.036677</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "      <td>['resource', 'share', 'cactus', 'cactus', 'bec...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39352</th>\n",
       "      <td>2014</td>\n",
       "      <td>4/11/2014 17:00</td>\n",
       "      <td>2014_N041114-22_CHIMNEY TOP FIRE</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>106</td>\n",
       "      <td>101</td>\n",
       "      <td>['rain', 'fell', 'hour', 'everything']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39353</th>\n",
       "      <td>2014</td>\n",
       "      <td>3/10/2014 14:00</td>\n",
       "      <td>2014_VA-VAS 0140633_OVER YONDER FIRE</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>71</td>\n",
       "      <td>69</td>\n",
       "      <td>['acre', 'revise', 'downward', 'result', 'actu...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39354</th>\n",
       "      <td>2014</td>\n",
       "      <td>3/10/2014 14:00</td>\n",
       "      <td>2014_VA-VAS 0140633_OVER YONDER FIRE</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>71</td>\n",
       "      <td>69</td>\n",
       "      <td>['acre', 'revise', 'downward', 'result', 'actu...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39355</th>\n",
       "      <td>2014</td>\n",
       "      <td>4/20/2014 9:00</td>\n",
       "      <td>2014_VAS1400605_ISSAC'S BRANCH</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>113</td>\n",
       "      <td>110</td>\n",
       "      <td>['flame', 'length', 'steep', 'limited', 'access']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39356</th>\n",
       "      <td>2014</td>\n",
       "      <td>3/15/2014 14:30</td>\n",
       "      <td>2014_VAVAS1403037_BEAVER LODGE RD.</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>['fast', 'spread', 'field']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39357 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CY   DISCOVERY_DATE                           INCIDENT_ID  \\\n",
       "0      2010  7/15/2010 15:00     2000_CA-RRU-062485_VALLEY COMPLEX   \n",
       "1      2010  7/15/2010 15:00     2000_CA-RRU-062485_VALLEY COMPLEX   \n",
       "2      2010  7/15/2010 15:00     2000_CA-RRU-062485_VALLEY COMPLEX   \n",
       "3      2010  7/15/2010 15:00     2000_CA-RRU-062485_VALLEY COMPLEX   \n",
       "4      2010  7/15/2010 15:00     2000_CA-RRU-062485_VALLEY COMPLEX   \n",
       "...     ...              ...                                   ...   \n",
       "39352  2014  4/11/2014 17:00      2014_N041114-22_CHIMNEY TOP FIRE   \n",
       "39353  2014  3/10/2014 14:00  2014_VA-VAS 0140633_OVER YONDER FIRE   \n",
       "39354  2014  3/10/2014 14:00  2014_VA-VAS 0140633_OVER YONDER FIRE   \n",
       "39355  2014   4/20/2014 9:00        2014_VAS1400605_ISSAC'S BRANCH   \n",
       "39356  2014  3/15/2014 14:30    2014_VAVAS1403037_BEAVER LODGE RD.   \n",
       "\n",
       "       PCT_CONTAINED_COMPLETED  START_YEAR  TOTAL_AERIAL  TOTAL_PERSONNEL  \\\n",
       "0                     0.000017        2010      0.052083         0.043860   \n",
       "1                     0.000012        2010      0.052083         0.043860   \n",
       "2                     0.000006        2010      0.041667         0.031465   \n",
       "3                     0.000021        2010      0.045139         0.036677   \n",
       "4                     0.000012        2010      0.045139         0.036677   \n",
       "...                        ...         ...           ...              ...   \n",
       "39352                 0.000021        2014      0.000000         0.000191   \n",
       "39353                 0.000021        2014      0.000000         0.001812   \n",
       "39354                 0.000021        2014      0.000000         0.001812   \n",
       "39355                 0.000008        2014      0.000000         0.003623   \n",
       "39356                 0.000021        2014      0.000000         0.002479   \n",
       "\n",
       "       REPORT_DOY  DISCOVERY_DOY  \\\n",
       "0             197            196   \n",
       "1             197            196   \n",
       "2             197            196   \n",
       "3             197            196   \n",
       "4             197            196   \n",
       "...           ...            ...   \n",
       "39352         106            101   \n",
       "39353          71             69   \n",
       "39354          71             69   \n",
       "39355         113            110   \n",
       "39356          74             74   \n",
       "\n",
       "                                           Combined_Text  ...  \\\n",
       "0                        ['resource', 'share', 'cactus']  ...   \n",
       "1      ['resource', 'share', 'incident', 'cactus', 'i...  ...   \n",
       "2      ['resource', 'share', 'cactus', 'erratic', 'wi...  ...   \n",
       "3      ['resource', 'share', 'cactus', 'cactus', 'bec...  ...   \n",
       "4      ['resource', 'share', 'cactus', 'cactus', 'bec...  ...   \n",
       "...                                                  ...  ...   \n",
       "39352             ['rain', 'fell', 'hour', 'everything']  ...   \n",
       "39353  ['acre', 'revise', 'downward', 'result', 'actu...  ...   \n",
       "39354  ['acre', 'revise', 'downward', 'result', 'actu...  ...   \n",
       "39355  ['flame', 'length', 'steep', 'limited', 'access']  ...   \n",
       "39356                        ['fast', 'spread', 'field']  ...   \n",
       "\n",
       "      INC_MGMT_ORG_ABBREV_2 INC_MGMT_ORG_ABBREV_3  INC_MGMT_ORG_ABBREV_4  \\\n",
       "0                         0                     0                      1   \n",
       "1                         0                     0                      1   \n",
       "2                         0                     0                      1   \n",
       "3                         0                     0                      1   \n",
       "4                         0                     0                      1   \n",
       "...                     ...                   ...                    ...   \n",
       "39352                     0                     0                      0   \n",
       "39353                     0                     0                      0   \n",
       "39354                     0                     0                      0   \n",
       "39355                     0                     0                      0   \n",
       "39356                     0                     0                      0   \n",
       "\n",
       "       INC_MGMT_ORG_ABBREV_5  INC_MGMT_ORG_ABBREV_A  INC_MGMT_ORG_ABBREV_B  \\\n",
       "0                          0                      0                      0   \n",
       "1                          0                      0                      0   \n",
       "2                          0                      0                      0   \n",
       "3                          0                      0                      0   \n",
       "4                          0                      0                      0   \n",
       "...                      ...                    ...                    ...   \n",
       "39352                      1                      0                      0   \n",
       "39353                      1                      0                      0   \n",
       "39354                      1                      0                      0   \n",
       "39355                      1                      0                      0   \n",
       "39356                      1                      0                      0   \n",
       "\n",
       "       INC_MGMT_ORG_ABBREV_C  INC_MGMT_ORG_ABBREV_D  INC_MGMT_ORG_ABBREV_E  \\\n",
       "0                          0                      0                      0   \n",
       "1                          0                      0                      0   \n",
       "2                          0                      0                      0   \n",
       "3                          0                      0                      0   \n",
       "4                          0                      0                      0   \n",
       "...                      ...                    ...                    ...   \n",
       "39352                      0                      0                      0   \n",
       "39353                      0                      0                      0   \n",
       "39354                      0                      0                      0   \n",
       "39355                      0                      0                      0   \n",
       "39356                      0                      0                      0   \n",
       "\n",
       "       INC_MGMT_ORG_ABBREV_F  \n",
       "0                          0  \n",
       "1                          0  \n",
       "2                          0  \n",
       "3                          0  \n",
       "4                          0  \n",
       "...                      ...  \n",
       "39352                      0  \n",
       "39353                      0  \n",
       "39354                      0  \n",
       "39355                      0  \n",
       "39356                      0  \n",
       "\n",
       "[39357 rows x 81 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (7,13,18,19,36) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "summary_reps = pd.read_csv(os.path.join(os.path.dirname(os.getcwd()),'data','ICS_predictive_summaryreps_full.csv')).drop([\"Unnamed: 0\"], axis=1)#os.path.join(os.path.dirname(os.getcwd()),'data','summary_reports_cleaned.csv')).drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8973"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = list(train_data[\"INCIDENT_ID\"].unique()) + list(test_data['INCIDENT_ID'].unique())+list(val_data['INCIDENT_ID'].unique())\n",
    "print(len(ids))\n",
    "summary_reps = summary_reps.loc[summary_reps[\"INCIDENT_ID\"].isin(ids)].reset_index(drop=True)\n",
    "len(summary_reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CY', 'DISCOVERY_DATE', 'INCIDENT_ID', 'PCT_CONTAINED_COMPLETED',\n",
       "       'START_YEAR', 'TOTAL_AERIAL', 'TOTAL_PERSONNEL', 'REPORT_DOY',\n",
       "       'DISCOVERY_DOY', 'Combined_Text', 'Unique_IDs', 'Raw_Combined_Text',\n",
       "       'ACRES', 'WF_FSR', 'INJURIES', 'FATALITIES', 'EST_IM_COST_TO_DATE',\n",
       "       'STR_DAMAGED', 'STR_DESTROYED', 'NEW_ACRES', 'POO_STATE',\n",
       "       'POO_LATITUDE', 'POO_LONGITUDE', 'WEATHER_CONCERNS_NARR',\n",
       "       'INC_MGMT_ORG_ABBREV', 'EVACUATION_IN_PROGRESS', 'Incident_region',\n",
       "       'NUM_REPORTS', 'DAYS_BURING', 'Severity', 'Traffic',\n",
       "       'Command_Transitions', 'Evacuations', 'Inaccurate_Mapping',\n",
       "       'Aerial_Grounding', 'Resource_Issues', 'Injuries', 'Cultural_Resources',\n",
       "       'Livestock', 'Law_Violations', 'Military_Base', 'Infrastructure',\n",
       "       'Extreme_Weather', 'Ecological', 'Hazardous_Terrain', 'Floods',\n",
       "       'Dry_Weather', 'Total_Incident_Text', 'Current_total_Injuries',\n",
       "       'Current_total_Structures_Damages',\n",
       "       'Current_total_Structures_Destroyed', 'Current_total_Fatalities',\n",
       "       'Diff_Injuries', 'Diff_Structures_Damages', 'Diff_Structures_Destroyed',\n",
       "       'Diff_Fatalities', 'Total_Injuries', 'Total_Structures_Damages',\n",
       "       'Total_Structures_Destroyed', 'Total_Fatalities',\n",
       "       'Incident_region_AICC', 'Incident_region_CA', 'Incident_region_EACC',\n",
       "       'Incident_region_GBCC', 'Incident_region_HICC', 'Incident_region_NRCC',\n",
       "       'Incident_region_NWCC', 'Incident_region_RMCC', 'Incident_region_SACC',\n",
       "       'Incident_region_SWCC', 'INC_MGMT_ORG_ABBREV_1',\n",
       "       'INC_MGMT_ORG_ABBREV_2', 'INC_MGMT_ORG_ABBREV_3',\n",
       "       'INC_MGMT_ORG_ABBREV_4', 'INC_MGMT_ORG_ABBREV_5',\n",
       "       'INC_MGMT_ORG_ABBREV_A', 'INC_MGMT_ORG_ABBREV_B',\n",
       "       'INC_MGMT_ORG_ABBREV_C', 'INC_MGMT_ORG_ABBREV_D',\n",
       "       'INC_MGMT_ORG_ABBREV_E', 'INC_MGMT_ORG_ABBREV_F'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcols = ['TOTAL_AERIAL', 'TOTAL_PERSONNEL', 'WF_FSR', 'DAYS_BURING', 'ACRES','PCT_CONTAINED_COMPLETED', #'Current_total_Injuries',\n",
    "       #'Current_total_Structures_Damages',\n",
    "       #'Current_total_Structures_Destroyed', 'Current_total_Fatalities',\n",
    "         'INJURIES','FATALITIES', 'STR_DESTROYED','STR_DAMAGED', 'Traffic',\n",
    "       'Command_Transitions', 'Evacuations', 'Inaccurate_Mapping',\n",
    "       'Aerial_Grounding', 'Resource_Issues', 'Injuries', 'Cultural_Resources',\n",
    "       'Livestock', 'Law_Violations', 'Military_Base', 'Infrastructure',\n",
    "       'Extreme_Weather', 'Ecological', 'Hazardous_Terrain', 'Floods',\n",
    "       'Dry_Weather', 'Incident_region_AICC', 'Incident_region_CA', 'Incident_region_EACC',\n",
    "       'Incident_region_GBCC', 'Incident_region_HICC', 'Incident_region_NRCC',\n",
    "       'Incident_region_NWCC', 'Incident_region_RMCC', 'Incident_region_SACC',\n",
    "       'Incident_region_SWCC']\n",
    "ycols = ['Total_Injuries', 'Total_Structures_Damages', 'Total_Structures_Destroyed',\n",
    "       'Total_Fatalities']# ['Diff_Injuries', 'Diff_Structures_Damages', 'Diff_Structures_Destroyed','Diff_Fatalities']\n",
    "Xtrain = train_data[xcols]; ytrain = train_data[ycols]\n",
    "Xval = val_data[xcols]; yval = val_data[ycols]\n",
    "Xtest = test_data[xcols]; ytest = test_data[ycols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39357, 37)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 37)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xval.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models to test:\n",
    "- SVM\n",
    "- NB\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- xgboost\n",
    "- AdaBoost\n",
    "- NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 8/8 [2:11:26<00:00, 985.81s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">MSE</th>\n",
       "      <th colspan=\"10\" halign=\"left\">R^2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">train</th>\n",
       "      <th colspan=\"5\" halign=\"left\">test</th>\n",
       "      <th colspan=\"5\" halign=\"left\">train</th>\n",
       "      <th colspan=\"5\" halign=\"left\">test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>injuries</th>\n",
       "      <th>str dam</th>\n",
       "      <th>str des</th>\n",
       "      <th>fatalities</th>\n",
       "      <th>average</th>\n",
       "      <th>injuries</th>\n",
       "      <th>str dam</th>\n",
       "      <th>str des</th>\n",
       "      <th>fatalities</th>\n",
       "      <th>average</th>\n",
       "      <th>injuries</th>\n",
       "      <th>str dam</th>\n",
       "      <th>str des</th>\n",
       "      <th>fatalities</th>\n",
       "      <th>average</th>\n",
       "      <th>injuries</th>\n",
       "      <th>str dam</th>\n",
       "      <th>str des</th>\n",
       "      <th>fatalities</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>20.154</td>\n",
       "      <td>319.996</td>\n",
       "      <td>5054.163</td>\n",
       "      <td>0.061</td>\n",
       "      <td>1348.593</td>\n",
       "      <td>11.841</td>\n",
       "      <td>16.904</td>\n",
       "      <td>2146.704</td>\n",
       "      <td>0.014</td>\n",
       "      <td>543.866</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-84.358</td>\n",
       "      <td>-305.883</td>\n",
       "      <td>0.851</td>\n",
       "      <td>-97.357</td>\n",
       "      <td>-0.731</td>\n",
       "      <td>-14.428</td>\n",
       "      <td>-268.648</td>\n",
       "      <td>0.439</td>\n",
       "      <td>-70.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14.147</td>\n",
       "      <td>30.885</td>\n",
       "      <td>582.821</td>\n",
       "      <td>0.013</td>\n",
       "      <td>156.967</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>20.627</td>\n",
       "      <td>42.065</td>\n",
       "      <td>277.371</td>\n",
       "      <td>0.175</td>\n",
       "      <td>85.059</td>\n",
       "      <td>18.884</td>\n",
       "      <td>5.302</td>\n",
       "      <td>476.662</td>\n",
       "      <td>0.008</td>\n",
       "      <td>125.214</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.600</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Ridge</th>\n",
       "      <td>27.262</td>\n",
       "      <td>108.328</td>\n",
       "      <td>553.713</td>\n",
       "      <td>0.268</td>\n",
       "      <td>172.393</td>\n",
       "      <td>15.025</td>\n",
       "      <td>16.119</td>\n",
       "      <td>373.805</td>\n",
       "      <td>0.034</td>\n",
       "      <td>101.246</td>\n",
       "      <td>-0.256</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.328</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>5.026</td>\n",
       "      <td>13.461</td>\n",
       "      <td>103.636</td>\n",
       "      <td>0.018</td>\n",
       "      <td>30.535</td>\n",
       "      <td>18.567</td>\n",
       "      <td>7.494</td>\n",
       "      <td>415.735</td>\n",
       "      <td>0.042</td>\n",
       "      <td>110.459</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.948</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>27.236</td>\n",
       "      <td>108.330</td>\n",
       "      <td>553.687</td>\n",
       "      <td>0.268</td>\n",
       "      <td>172.380</td>\n",
       "      <td>15.053</td>\n",
       "      <td>16.006</td>\n",
       "      <td>373.740</td>\n",
       "      <td>0.034</td>\n",
       "      <td>101.208</td>\n",
       "      <td>-0.239</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.317</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.035</td>\n",
       "      <td>16.061</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.024</td>\n",
       "      <td>11.932</td>\n",
       "      <td>12.408</td>\n",
       "      <td>682.226</td>\n",
       "      <td>0.007</td>\n",
       "      <td>176.643</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>-0.718</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1927.329</td>\n",
       "      <td>0.000</td>\n",
       "      <td>481.832</td>\n",
       "      <td>29.461</td>\n",
       "      <td>165.194</td>\n",
       "      <td>1743.018</td>\n",
       "      <td>0.248</td>\n",
       "      <td>484.480</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.436</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.859</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      MSE                                                   \\\n",
       "                    train                                             test   \n",
       "                 injuries  str dam   str des fatalities   average injuries   \n",
       "SVM                20.154  319.996  5054.163      0.061  1348.593   11.841   \n",
       "GradientBoosting    0.000    0.000     0.000      0.000     0.000   14.147   \n",
       "Random Forest      20.627   42.065   277.371      0.175    85.059   18.884   \n",
       "Bayesian Ridge     27.262  108.328   553.713      0.268   172.393   15.025   \n",
       "MLP                 5.026   13.461   103.636      0.018    30.535   18.567   \n",
       "XGBoost            27.236  108.330   553.687      0.268   172.380   15.053   \n",
       "AdaBoost            0.000    0.035    16.061      0.000     4.024   11.932   \n",
       "Decision Tree       0.000    0.000  1927.329      0.000   481.832   29.461   \n",
       "\n",
       "                                                             R^2          \\\n",
       "                                                           train           \n",
       "                  str dam   str des fatalities  average injuries str dam   \n",
       "SVM                16.904  2146.704      0.014  543.866   -0.036 -84.358   \n",
       "GradientBoosting   30.885   582.821      0.013  156.967    1.000   1.000   \n",
       "Random Forest       5.302   476.662      0.008  125.214    0.059   0.861   \n",
       "Bayesian Ridge     16.119   373.805      0.034  101.246   -0.256   0.547   \n",
       "MLP                 7.494   415.735      0.042  110.459    0.884   0.960   \n",
       "XGBoost            16.006   373.740      0.034  101.208   -0.239   0.550   \n",
       "AdaBoost           12.408   682.226      0.007  176.643    1.000   1.000   \n",
       "Decision Tree     165.194  1743.018      0.248  484.480    1.000   1.000   \n",
       "\n",
       "                                                                        \\\n",
       "                                                 test                    \n",
       "                  str des fatalities average injuries str dam  str des   \n",
       "SVM              -305.883      0.851 -97.357   -0.731 -14.428 -268.648   \n",
       "GradientBoosting    1.000      1.000   1.000   -0.159   0.339    0.476   \n",
       "Random Forest       0.943      0.538   0.600   -0.340   0.639    0.786   \n",
       "Bayesian Ridge      0.882      0.140   0.328   -0.320   0.451    0.772   \n",
       "MLP                 0.980      0.969   0.948   -0.225   0.531    0.800   \n",
       "XGBoost             0.883      0.140   0.334   -0.317   0.452    0.772   \n",
       "AdaBoost            0.997      1.000   0.999   -0.718   0.179    0.363   \n",
       "Decision Tree       0.436      1.000   0.859   -0.069   0.205    0.045   \n",
       "\n",
       "                                     \n",
       "                                     \n",
       "                 fatalities average  \n",
       "SVM                   0.439 -70.842  \n",
       "GradientBoosting      0.538   0.299  \n",
       "Random Forest         0.679   0.441  \n",
       "Bayesian Ridge        0.256   0.290  \n",
       "MLP                   0.481   0.397  \n",
       "XGBoost               0.255   0.291  \n",
       "AdaBoost              0.670   0.124  \n",
       "Decision Tree         0.305   0.121  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names = [\"SVM\", \"GradientBoosting\", \"Random Forest\", \"Bayesian Ridge\", \"MLP\", \"XGBoost\", \"AdaBoost\", \"Decision Tree\"]\n",
    "cols = {(str(score),str(model),str(metric)):[] for score in [\"MSE\",\"R^2\"] for model in [\"train\",\"test\"] for metric in ['injuries','str dam', 'str des', 'fatalities', 'average']}\n",
    "\n",
    "models = [svm.SVR(kernel='rbf', C=1.2), GradientBoostingRegressor(max_features='log2',n_estimators=150, random_state=0, max_depth=22,criterion='mse'), \n",
    "          RandomForestRegressor(criterion='mse',max_features='auto',n_estimators=175, random_state=0, max_depth=4),\n",
    "          linear_model.BayesianRidge(alpha_1=100, alpha_2=10000, lambda_1=100, lambda_2=100),\n",
    "          MLPRegressor(random_state=0, max_iter=10000, alpha=0.1, learning_rate='constant', 'hidden_layer_sizes': (100,)), xgb.XGBRegressor(booster='gblinear',n_estimators=150),\n",
    "         AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion='mae', max_features='sqrt', splitter='random'), n_estimators=50, learning_rate=0.1, loss='exponential'), \n",
    "         DecisionTreeRegressor(criterion='mae', max_features='sqrt', splitter='random')]\n",
    "for m in tqdm(models):\n",
    "    mdl = MultiOutputRegressor(m)\n",
    "    mdl.fit(Xtrain, ytrain)\n",
    "    train_pred = np.around(mdl.predict(Xtrain)); train_pred[train_pred<0] = 0\n",
    "    test_pred = np.around(mdl.predict(Xtest)); test_pred[test_pred<0] = 0\n",
    "\n",
    "    train_score = np.around(r2_score(train_pred, ytrain, multioutput='raw_values'),3)\n",
    "    cols[('R^2','train','injuries')].append(train_score[0]); cols[('R^2', 'train', 'str dam')].append(train_score[1])\n",
    "    cols[('R^2','train','str des')].append(train_score[2]); cols[('R^2', 'train', 'fatalities')].append(train_score[3])\n",
    "    cols[('R^2','train','average')].append(round(r2_score(train_pred, ytrain),3))\n",
    "    \n",
    "    test_score = np.around(r2_score(test_pred, ytest,multioutput='raw_values'),3)\n",
    "    cols[('R^2','test','injuries')].append(test_score[0]); cols[('R^2','test','str dam')].append(test_score[1])\n",
    "    cols[('R^2','test','str des')].append(test_score[2]); cols[('R^2','test','fatalities')].append(test_score[3])\n",
    "    cols[('R^2','test','average')].append(round(r2_score(test_pred, ytest),3))\n",
    "    \n",
    "    train_MSE = np.around(mean_squared_error(ytrain, train_pred,multioutput='raw_values'),3)\n",
    "    cols[('MSE','train','injuries')].append(train_MSE[0]); cols[('MSE', 'train', 'str dam')].append(train_MSE[1])\n",
    "    cols[('MSE','train','str des')].append(train_MSE[2]); cols[('MSE', 'train', 'fatalities')].append(train_MSE[3])\n",
    "    cols[('MSE','train','average')].append(round(mean_squared_error(train_pred, ytrain),3))\n",
    "    \n",
    "    test_MSE = np.around(mean_squared_error(ytest, test_pred,multioutput='raw_values'),3)\n",
    "    cols[('MSE','test','injuries')].append(test_MSE[0]); cols[('MSE','test','str dam')].append(test_MSE[1])\n",
    "    cols[('MSE','test','str des')].append(test_MSE[2]); cols[('MSE','test','fatalities')].append(test_MSE[3])\n",
    "    cols[('MSE','test','average')].append(round(mean_squared_error(test_pred, ytest),3))\n",
    "    \n",
    "columns = pd.MultiIndex.from_tuples([col for col in cols])\n",
    "results_df = pd.DataFrame(cols, columns=columns, index=model_names)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(criterion='mse',max_features='auto',n_estimators=175, random_state=0, max_depth=4)\n",
    "mdl = MultiOutputRegressor(m)\n",
    "train_test = pd.concat([Xtrain,Xtest])\n",
    "ytrain_test = pd.concat([ytrain,ytest])\n",
    "mdl.fit(train_test, ytrain_test)\n",
    "#preds = np.around(mdl.predict(Xtest))\n",
    "#preds[preds<0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds = pd.DataFrame(preds, columns = ytest.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(os.path.dirname(os.getcwd()),'models','severity_model_test.sav')\n",
    "pickle.dump(mdl, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rbf\n",
      "poly\n",
      "sigmoid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernels</th>\n",
       "      <th>train r</th>\n",
       "      <th>test r</th>\n",
       "      <th>train MSE</th>\n",
       "      <th>test MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.167</td>\n",
       "      <td>1360.986</td>\n",
       "      <td>548.563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poly</td>\n",
       "      <td>0.443</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>1296.726</td>\n",
       "      <td>431.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>-172151.310</td>\n",
       "      <td>-2422859.185</td>\n",
       "      <td>397845.384</td>\n",
       "      <td>251074.174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kernels     train r       test r   train MSE    test MSE\n",
       "0      rbf       0.387        0.167    1360.986     548.563\n",
       "1     poly       0.443       -0.240    1296.726     431.341\n",
       "2  sigmoid -172151.310 -2422859.185  397845.384  251074.174"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernals = ['rbf', 'poly', 'sigmoid']\n",
    "train_r = []\n",
    "test_r = []\n",
    "train_MSE = []\n",
    "test_MSE = []\n",
    "for kernal in kernals:\n",
    "    print(kernal)\n",
    "    mdl = MultiOutputRegressor(svm.SVR(kernel=kernal))\n",
    "    \n",
    "    mdl.fit(Xtrain, ytrain)\n",
    "    train_r.append(round(mdl.score(Xtrain, ytrain),3))\n",
    "    test_r.append(round(mdl.score(Xtest, ytest),3))\n",
    "    train_MSE.append(round(mean_squared_error(ytrain, mdl.predict(Xtrain)),3))\n",
    "    test_MSE.append(round(mean_squared_error(ytest, mdl.predict(Xtest)),3))\n",
    "\n",
    "model_comparisons = pd.DataFrame({\n",
    "    \"kernels\": kernals,\n",
    "    \"train r\": train_r,\n",
    "    \"test r\": test_r,\n",
    "    \"train MSE\": train_MSE,\n",
    "    \"test MSE\": test_MSE})\n",
    "\n",
    "model_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c-value</th>\n",
       "      <th>train r</th>\n",
       "      <th>test r</th>\n",
       "      <th>train MSE</th>\n",
       "      <th>test MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.068</td>\n",
       "      <td>1429.138</td>\n",
       "      <td>574.649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.102</td>\n",
       "      <td>1418.610</td>\n",
       "      <td>569.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.123</td>\n",
       "      <td>1409.920</td>\n",
       "      <td>566.491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.136</td>\n",
       "      <td>1402.196</td>\n",
       "      <td>563.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.143</td>\n",
       "      <td>1394.807</td>\n",
       "      <td>561.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.146</td>\n",
       "      <td>1387.642</td>\n",
       "      <td>558.508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.148</td>\n",
       "      <td>1380.645</td>\n",
       "      <td>555.948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.154</td>\n",
       "      <td>1373.884</td>\n",
       "      <td>553.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1367.341</td>\n",
       "      <td>550.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.167</td>\n",
       "      <td>1360.986</td>\n",
       "      <td>548.563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.1</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.173</td>\n",
       "      <td>1354.729</td>\n",
       "      <td>546.268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.2</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.178</td>\n",
       "      <td>1348.600</td>\n",
       "      <td>544.029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    c-value  train r  test r  train MSE  test MSE\n",
       "0       0.1    0.131   0.068   1429.138   574.649\n",
       "1       0.2    0.193   0.102   1418.610   569.669\n",
       "2       0.3    0.241   0.123   1409.920   566.491\n",
       "3       0.4    0.280   0.136   1402.196   563.748\n",
       "4       0.5    0.311   0.143   1394.807   561.104\n",
       "5       0.6    0.336   0.146   1387.642   558.508\n",
       "6       0.7    0.353   0.148   1380.645   555.948\n",
       "7       0.8    0.365   0.154   1373.884   553.402\n",
       "8       0.9    0.377   0.160   1367.341   550.923\n",
       "9       1.0    0.387   0.167   1360.986   548.563\n",
       "10      1.1    0.397   0.173   1354.729   546.268\n",
       "11      1.2    0.405   0.178   1348.600   544.029"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_vals = [1e-1,2e-1,3e-1,4e-1,5e-1, 6e-1,7e-1,8e-1, 9e-1, 1, 1.1, 1.2]\n",
    "train_r = []\n",
    "test_r = []\n",
    "train_MSE = []\n",
    "test_MSE = []\n",
    "for c in c_vals:\n",
    "    mdl = MultiOutputRegressor(svm.SVR(C=c,kernel='rbf'))\n",
    "    \n",
    "    mdl.fit(Xtrain, ytrain)\n",
    "    train_r.append(round(mdl.score(Xtrain, ytrain),3))\n",
    "    test_r.append(round(mdl.score(Xtest, ytest),3))\n",
    "    train_MSE.append(round(mean_squared_error(ytrain, mdl.predict(Xtrain)),3))\n",
    "    test_MSE.append(round(mean_squared_error(ytest, mdl.predict(Xtest)),3))\n",
    "\n",
    "model_comparisons = pd.DataFrame({\n",
    "    \"c-value\": c_vals,\n",
    "    \"train r\": train_r,\n",
    "    \"test r\": test_r,\n",
    "    \"train MSE\": train_MSE,\n",
    "    \"test MSE\": test_MSE})\n",
    "\n",
    "model_comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'loss' : ['huber','quantile', 'lad', 'ls'],#'squared_error', 'absolute_error', 'huber', 'quantile'], #'lad', #'ls'\n",
    "              'criterion': ['friedman_mse', 'mse'],\n",
    "              'max_depth': [i for i in range(3,25)],\n",
    "              'n_estimators': [i for i in range(100, 500, 25)],\n",
    "              'max_features': ['auto', 'sqrt', 'log2']}\n",
    "best_params = {'criterion': 'friedman_mse', 'max_depth': 3, 'n_estimators': 100, 'max_features': 'auto'}#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|█████████████████████                                                               | 1/4 [00:15<00:45, 15.30s/it]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 2/4 [00:34<00:32, 16.32s/it]\u001b[A\n",
      " 75%|███████████████████████████████████████████████████████████████                     | 3/4 [00:52<00:16, 16.92s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:09<00:00, 17.39s/it]\u001b[A\n",
      " 20%|████████████████▊                                                                   | 1/5 [01:09<04:38, 69.58s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:15<00:15, 15.18s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:30<00:00, 15.12s/it]\u001b[A\n",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [01:39<02:53, 57.78s/it]\n",
      "  0%|                                                                                           | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|███▊                                                                               | 1/22 [00:15<05:16, 15.09s/it]\u001b[A\n",
      "  9%|███████▌                                                                           | 2/22 [00:30<05:02, 15.14s/it]\u001b[A\n",
      " 14%|███████████▎                                                                       | 3/22 [00:45<04:47, 15.16s/it]\u001b[A\n",
      " 18%|███████████████                                                                    | 4/22 [01:00<04:32, 15.13s/it]\u001b[A\n",
      " 23%|██████████████████▊                                                                | 5/22 [01:15<04:16, 15.10s/it]\u001b[A\n",
      " 27%|██████████████████████▋                                                            | 6/22 [01:30<04:01, 15.09s/it]\u001b[A\n",
      " 32%|██████████████████████████▍                                                        | 7/22 [01:45<03:46, 15.08s/it]\u001b[A\n",
      " 36%|██████████████████████████████▏                                                    | 8/22 [02:00<03:31, 15.10s/it]\u001b[A\n",
      " 41%|█████████████████████████████████▉                                                 | 9/22 [02:16<03:17, 15.19s/it]\u001b[A\n",
      " 45%|█████████████████████████████████████▎                                            | 10/22 [02:31<03:03, 15.30s/it]\u001b[A\n",
      " 50%|█████████████████████████████████████████                                         | 11/22 [02:47<02:48, 15.34s/it]\u001b[A\n",
      " 55%|████████████████████████████████████████████▋                                     | 12/22 [03:02<02:33, 15.40s/it]\u001b[A\n",
      " 59%|████████████████████████████████████████████████▍                                 | 13/22 [03:18<02:18, 15.43s/it]\u001b[A\n",
      " 64%|████████████████████████████████████████████████████▏                             | 14/22 [03:33<02:03, 15.42s/it]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████████▉                          | 15/22 [03:48<01:47, 15.37s/it]\u001b[A\n",
      " 73%|███████████████████████████████████████████████████████████▋                      | 16/22 [04:04<01:31, 15.31s/it]\u001b[A\n",
      " 77%|███████████████████████████████████████████████████████████████▎                  | 17/22 [04:19<01:16, 15.27s/it]\u001b[A\n",
      " 82%|███████████████████████████████████████████████████████████████████               | 18/22 [04:34<01:00, 15.24s/it]\u001b[A\n",
      " 86%|██████████████████████████████████████████████████████████████████████▊           | 19/22 [04:49<00:45, 15.22s/it]\u001b[A\n",
      " 91%|██████████████████████████████████████████████████████████████████████████▌       | 20/22 [05:04<00:30, 15.19s/it]\u001b[A\n",
      " 95%|██████████████████████████████████████████████████████████████████████████████▎   | 21/22 [05:19<00:15, 15.17s/it]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [05:35<00:00, 15.23s/it]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [07:14<04:41, 140.97s/it]\n",
      "  0%|                                                                                           | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "  6%|█████                                                                           | 1/16 [08:51<2:12:57, 531.86s/it]\u001b[A\n",
      " 12%|██████████                                                                      | 2/16 [17:58<2:05:09, 536.38s/it]\u001b[A\n",
      " 19%|███████████████                                                                 | 3/16 [27:07<1:57:02, 540.16s/it]\u001b[A\n",
      " 25%|████████████████████                                                            | 4/16 [35:58<1:47:28, 537.37s/it]\u001b[A\n",
      " 31%|█████████████████████████                                                       | 5/16 [44:51<1:38:16, 536.08s/it]\u001b[A\n",
      " 38%|██████████████████████████████                                                  | 6/16 [53:58<1:29:54, 539.43s/it]\u001b[A\n",
      " 44%|██████████████████████████████████▏                                           | 7/16 [1:03:07<1:21:20, 542.25s/it]\u001b[A\n",
      " 50%|███████████████████████████████████████                                       | 8/16 [1:12:15<1:12:30, 543.82s/it]\u001b[A\n",
      " 56%|███████████████████████████████████████████▉                                  | 9/16 [1:21:49<1:04:30, 552.97s/it]\u001b[A\n",
      " 62%|█████████████████████████████████████████████████▍                             | 10/16 [1:31:23<55:55, 559.18s/it]\u001b[A\n",
      " 69%|██████████████████████████████████████████████████████▎                        | 11/16 [1:40:27<46:14, 554.83s/it]\u001b[A\n",
      " 75%|███████████████████████████████████████████████████████████▎                   | 12/16 [1:49:18<36:29, 547.44s/it]\u001b[A\n",
      " 81%|████████████████████████████████████████████████████████████████▏              | 13/16 [1:57:52<26:52, 537.39s/it]\u001b[A\n",
      " 88%|█████████████████████████████████████████████████████████████████████▏         | 14/16 [2:06:25<17:40, 530.11s/it]\u001b[A\n",
      " 94%|██████████████████████████████████████████████████████████████████████████     | 15/16 [2:15:34<08:55, 535.97s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 16/16 [2:24:46<00:00, 542.94s/it]\u001b[A\n",
      " 80%|████████████████████████████████████████████████████████████████                | 4/5 [2:32:01<45:04, 2704.78s/it]\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███████████████████████████▋                                                       | 1/3 [12:56<25:53, 776.98s/it]\u001b[A\n",
      " 67%|███████████████████████████████████████████████████████▎                           | 2/3 [26:33<13:08, 788.86s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [39:39<00:00, 793.03s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 5/5 [3:11:40<00:00, 2300.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'mse', 'max_depth': 22, 'n_estimators': 150, 'max_features': 'log2', 'loss': 'huber'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for param in tqdm(params):\n",
    "    train_r = []\n",
    "    test_r = []\n",
    "    train_MSE = []\n",
    "    test_MSE = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        clf = MultiOutputRegressor(GradientBoostingRegressor(**test_params))\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        train_r.append(round(clf.score(Xtrain, ytrain),3))\n",
    "        test_r.append(round(clf.score(Xtest, ytest),3))\n",
    "        train_MSE.append(round(mean_squared_error(ytrain, clf.predict(Xtrain)),3))\n",
    "        test_MSE.append(round(mean_squared_error(ytest, clf.predict(Xtest)),3))\n",
    "    best_params[param] = params[param][np.argmin(test_MSE)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "GradientBoostingRegressor(max_features='log2',n_estimators=150, random_state=0, max_depth=22,criterion='mse')\n",
    "#gradient_boosting_mdl = GradientBoostingRegressor(max_features='auto',n_estimators=100, random_state=0, max_depth=3,criterion='friedman_mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {#'criterion': ['mse', 'mae'],#'absolute_error', \n",
    "                            #'squared_error'],\n",
    "              'max_depth': [i for i in range(3,25)],\n",
    "              'n_estimators': [i for i in range(100, 500, 25)],\n",
    "              'max_features': ['auto', 'sqrt', 'log2']}\n",
    "best_params={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\n",
      "  0%|                                                                                           | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|███▊                                                                               | 1/22 [00:12<04:32, 12.96s/it]\u001b[A\n",
      "  9%|███████▌                                                                           | 2/22 [00:29<04:42, 14.14s/it]\u001b[A\n",
      " 14%|███████████▎                                                                       | 3/22 [00:49<05:01, 15.87s/it]\u001b[A\n",
      " 18%|███████████████                                                                    | 4/22 [01:13<05:26, 18.15s/it]\u001b[A\n",
      " 23%|██████████████████▊                                                                | 5/22 [01:40<05:53, 20.82s/it]\u001b[A\n",
      " 27%|██████████████████████▋                                                            | 6/22 [02:10<06:19, 23.71s/it]\u001b[A\n",
      " 32%|██████████████████████████▍                                                        | 7/22 [02:44<06:41, 26.77s/it]\u001b[A\n",
      " 36%|██████████████████████████████▏                                                    | 8/22 [03:22<07:00, 30.03s/it]\u001b[A\n",
      " 41%|█████████████████████████████████▉                                                 | 9/22 [04:02<07:11, 33.18s/it]\u001b[A\n",
      " 45%|█████████████████████████████████████▎                                            | 10/22 [04:46<07:17, 36.44s/it]\u001b[A\n",
      " 50%|█████████████████████████████████████████                                         | 11/22 [05:34<07:16, 39.70s/it]\u001b[A\n",
      " 55%|████████████████████████████████████████████▋                                     | 12/22 [06:24<07:08, 42.80s/it]\u001b[A\n",
      " 59%|████████████████████████████████████████████████▍                                 | 13/22 [07:18<06:55, 46.22s/it]\u001b[A\n",
      " 64%|████████████████████████████████████████████████████▏                             | 14/22 [08:15<06:35, 49.38s/it]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████████▉                          | 15/22 [09:14<06:05, 52.27s/it]\u001b[A\n",
      " 73%|███████████████████████████████████████████████████████████▋                      | 16/22 [10:13<05:27, 54.52s/it]\u001b[A\n",
      " 77%|███████████████████████████████████████████████████████████████▎                  | 17/22 [11:13<04:40, 56.11s/it]\u001b[A\n",
      " 82%|███████████████████████████████████████████████████████████████████               | 18/22 [12:15<03:50, 57.66s/it]\u001b[A\n",
      " 86%|██████████████████████████████████████████████████████████████████████▊           | 19/22 [13:17<02:56, 58.95s/it]\u001b[A\n",
      " 91%|██████████████████████████████████████████████████████████████████████████▌       | 20/22 [14:19<02:00, 60.08s/it]\u001b[A\n",
      " 95%|██████████████████████████████████████████████████████████████████████████████▎   | 21/22 [15:22<01:01, 61.00s/it]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [16:26<00:00, 44.85s/it]\u001b[A\n",
      " 33%|███████████████████████████▋                                                       | 1/3 [16:26<32:53, 986.60s/it]\n",
      "  0%|                                                                                           | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "  6%|█████▏                                                                             | 1/16 [00:15<03:56, 15.79s/it]\u001b[A\n",
      " 12%|██████████▍                                                                        | 2/16 [00:35<03:58, 17.04s/it]\u001b[A\n",
      " 19%|███████████████▌                                                                   | 3/16 [00:59<04:09, 19.19s/it]\u001b[A\n",
      " 25%|████████████████████▊                                                              | 4/16 [01:27<04:20, 21.74s/it]\u001b[A\n",
      " 31%|█████████████████████████▉                                                         | 5/16 [02:00<04:35, 25.03s/it]\u001b[A\n",
      " 38%|███████████████████████████████▏                                                   | 6/16 [02:37<04:45, 28.56s/it]\u001b[A\n",
      " 44%|████████████████████████████████████▎                                              | 7/16 [03:16<04:46, 31.85s/it]\u001b[A\n",
      " 50%|█████████████████████████████████████████▌                                         | 8/16 [04:00<04:42, 35.32s/it]\u001b[A\n",
      " 56%|██████████████████████████████████████████████▋                                    | 9/16 [04:47<04:32, 38.93s/it]\u001b[A\n",
      " 62%|███████████████████████████████████████████████████▎                              | 10/16 [05:38<04:15, 42.60s/it]\u001b[A\n",
      " 69%|████████████████████████████████████████████████████████▍                         | 11/16 [06:34<03:52, 46.45s/it]\u001b[A\n",
      " 75%|█████████████████████████████████████████████████████████████▌                    | 12/16 [07:33<03:21, 50.37s/it]\u001b[A\n",
      " 81%|██████████████████████████████████████████████████████████████████▋               | 13/16 [08:36<02:42, 54.17s/it]\u001b[A\n",
      " 88%|███████████████████████████████████████████████████████████████████████▊          | 14/16 [09:43<01:56, 58.02s/it]\u001b[A\n",
      " 94%|████████████████████████████████████████████████████████████████████████████▉     | 15/16 [10:54<01:01, 61.82s/it]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [12:09<00:00, 45.59s/it]\u001b[A\n",
      " 67%|███████████████████████████████████████████████████████▎                           | 2/3 [28:35<15:09, 909.43s/it]\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|████████████████████████████                                                        | 1/3 [00:27<00:55, 27.58s/it]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████                            | 2/3 [00:34<00:21, 21.27s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:39<00:00, 13.28s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [29:15<00:00, 585.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 4, 'n_estimators': 175, 'max_features': 'auto'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for param in tqdm(params):\n",
    "    train_r = []\n",
    "    test_r = []\n",
    "    train_MSE = []\n",
    "    test_MSE = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        clf = MultiOutputRegressor(RandomForestRegressor(**test_params))\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        train_r.append(round(clf.score(Xtrain, ytrain),3))\n",
    "        test_r.append(round(clf.score(Xtest, ytest),3))\n",
    "        train_MSE.append(round(mean_squared_error(ytrain, clf.predict(Xtrain)),3))\n",
    "        test_MSE.append(round(mean_squared_error(ytest, clf.predict(Xtest)),3))\n",
    "    best_params[param] = params[param][np.argmin(test_MSE)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf = RandomForestRegressor(criterion='mae',max_features='sqrt',n_estimators=100, random_state=0, max_depth=20)\n",
    "rf = RandomForestRegressor(criterion='mse',max_features='auto',n_estimators=175, random_state=0, max_depth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:03<00:00,  4.36it/s]\n",
      "  0%|                                                                                           | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_1 best value: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:03<00:00,  4.43it/s]\n",
      "  0%|                                                                                           | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_2 best value: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:03<00:00,  4.38it/s]\n",
      "  0%|                                                                                           | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_1 best value: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:03<00:00,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_2 best value: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vals = [10000, 100,1000,10,1,0.01,1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10]\n",
    "params = ['alpha_1','alpha_2','lambda_1','lambda_2']\n",
    "for param in params:\n",
    "    train_r = []\n",
    "    test_r = []\n",
    "    train_MSE = []\n",
    "    test_MSE = []\n",
    "    for val in tqdm(vals):\n",
    "        input_params = {param:val}\n",
    "        clf = MultiOutputRegressor(linear_model.BayesianRidge(**input_params))\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        train_r.append(round(clf.score(Xtrain, ytrain),3))\n",
    "        test_r.append(round(clf.score(Xtest, ytest),3))\n",
    "        train_MSE.append(round(mean_squared_error(ytrain, clf.predict(Xtrain)),3))\n",
    "        test_MSE.append(round(mean_squared_error(ytest, clf.predict(Xtest)),3))\n",
    "    print(param+\" best value:\", vals[np.argmin(test_MSE)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ridge = linear_model.BayesianRidge(alpha_1=10000, alpha_2=100, lambda_1=1, lambda_2=0.0001)\n",
    "ridge = linear_model.BayesianRidge(alpha_1=100, alpha_2=10000, lambda_1=100, lambda_2=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srandrad\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\dtypes.py:585: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object,\n",
      "C:\\Users\\srandrad\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\dtypes.py:627: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object,\n",
      "C:\\Users\\srandrad\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\dtypes.py:637: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool,\n",
      "C:\\Users\\srandrad\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:176: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object: SlowAppendObjectArrayToTensorProto,\n",
      "C:\\Users\\srandrad\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:177: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool: SlowAppendBoolArrayToTensorProto,\n",
      "C:\\Users\\srandrad\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\numpy_ops\\np_random.py:110: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def randint(low, high=None, size=None, dtype=onp.int):  # pylint: disable=missing-function-docstring\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dnn_with_reg(input_shape, num_neuron, reg, drop_rate=0.5):\n",
    "\n",
    "    # this is our input layer, we need to identify the shape of the input data\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    if reg == 'l1':\n",
    "        layer1 = keras.layers.Dense(num_neuron, activation='tanh',\n",
    "                                    kernel_regularizer=keras.regularizers.l1(0.01))(input_layer)\n",
    "        layer2 = keras.layers.Dense(num_neuron, activation='tanh',\n",
    "                                    kernel_regularizer=keras.regularizers.l1(0.01))(layer1)\n",
    "        #layer3 = keras.layers.Dense(num_neuron, activation='tanh',\n",
    "        #                            kernel_regularizer=keras.regularizers.l1(0.01))(layer2)\n",
    "    elif reg == 'l2':\n",
    "        layer1 = keras.layers.Dense(num_neuron, activation='tanh',\n",
    "                                    kernel_regularizer=keras.regularizers.l2(0.1))(input_layer)\n",
    "        #layer2 = keras.layers.Dense(num_neuron, activation='tanh',\n",
    "        #                            kernel_regularizer=keras.regularizers.l2(0.01))(layer1)\n",
    "        #layer3 = keras.layers.Dense(num_neuron, activation='tanh',\n",
    "        #                            kernel_regularizer=keras.regularizers.l2(0.01))(layer2)\n",
    "    elif reg == 'dropout':\n",
    "        layer1 = keras.layers.Dense(num_neuron, activation='tanh')(input_layer)\n",
    "        dropout1 = keras.layers.Dropout(rate=drop_rate)(layer1)\n",
    "        layer2 = keras.layers.Dense(num_neuron, activation='tanh')(dropout1)\n",
    "        #dropout2 = keras.layers.Dropout(rate=drop_rate)(layer2)\n",
    "        #layer3 = keras.layers.Dense(num_neuron, activation='tanh')(dropout2)\n",
    "        \n",
    "    output_layer = keras.layers.Dense(4)(layer1)#(layer3)\n",
    "\n",
    "    # then we define the entire model based on input and output\n",
    "\n",
    "    model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdl = build_dnn_with_reg(len(xcols), 100, reg='l2')\n",
    "\n",
    "optim = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "mdl.compile(optimizer=optim,\n",
    "                 loss='mse',\n",
    "                 metrics=['MeanSquaredError'#,'AUC',\n",
    "                         ])\n",
    "\n",
    "mini_batch=256\n",
    "num_epochs=15\n",
    "# We define the learning rate decay as a callback\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.5)\n",
    "\n",
    "\n",
    "# now we are ready to train the model\n",
    "training = mdl.fit(Xtrain, ytrain,\n",
    "                       batch_size=mini_batch,\n",
    "                       epochs=num_epochs,\n",
    "                       validation_data=(Xval, yval),\n",
    "                       #callbacks=[reduce_lr],\n",
    "                   verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss and AUC\n",
    "plt.figure(figsize=(8, 6))\n",
    "FONT=14\n",
    "plt.plot(range(num_epochs), training.history['loss'], label='training loss')\n",
    "plt.plot(range(num_epochs), training.history['val_loss'], label='validation loss')\n",
    "plt.xlabel('Number of epochs', fontsize=FONT)\n",
    "plt.ylabel('Loss', fontsize=FONT)\n",
    "plt.legend(fontsize=FONT)\n",
    "plt.tick_params(axis='both', which='major', labelsize=FONT)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">MSE</th>\n",
       "      <th colspan=\"10\" halign=\"left\">R^2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">train</th>\n",
       "      <th colspan=\"5\" halign=\"left\">test</th>\n",
       "      <th colspan=\"5\" halign=\"left\">train</th>\n",
       "      <th colspan=\"5\" halign=\"left\">test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>injuries</th>\n",
       "      <th>str dam</th>\n",
       "      <th>str des</th>\n",
       "      <th>fatalities</th>\n",
       "      <th>average</th>\n",
       "      <th>injuries</th>\n",
       "      <th>str dam</th>\n",
       "      <th>str des</th>\n",
       "      <th>fatalities</th>\n",
       "      <th>average</th>\n",
       "      <th>injuries</th>\n",
       "      <th>str dam</th>\n",
       "      <th>str des</th>\n",
       "      <th>fatalities</th>\n",
       "      <th>average</th>\n",
       "      <th>injuries</th>\n",
       "      <th>str dam</th>\n",
       "      <th>str des</th>\n",
       "      <th>fatalities</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DNN</th>\n",
       "      <td>38.845</td>\n",
       "      <td>345.619</td>\n",
       "      <td>5218.052</td>\n",
       "      <td>0.571</td>\n",
       "      <td>1400.772</td>\n",
       "      <td>15.367</td>\n",
       "      <td>19.841</td>\n",
       "      <td>2052.428</td>\n",
       "      <td>0.029</td>\n",
       "      <td>521.916</td>\n",
       "      <td>-5.055</td>\n",
       "      <td>-173.076</td>\n",
       "      <td>-265.485</td>\n",
       "      <td>-267.323</td>\n",
       "      <td>-177.735</td>\n",
       "      <td>-1.797</td>\n",
       "      <td>-9.333</td>\n",
       "      <td>-112.051</td>\n",
       "      <td>-11.575</td>\n",
       "      <td>-33.689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MSE                                                           \\\n",
       "       train                                             test           \n",
       "    injuries  str dam   str des fatalities   average injuries str dam   \n",
       "DNN   38.845  345.619  5218.052      0.571  1400.772   15.367  19.841   \n",
       "\n",
       "                                       R^2                               \\\n",
       "                                     train                                \n",
       "      str des fatalities  average injuries  str dam  str des fatalities   \n",
       "DNN  2052.428      0.029  521.916   -5.055 -173.076 -265.485   -267.323   \n",
       "\n",
       "                                                           \n",
       "                 test                                      \n",
       "     average injuries str dam  str des fatalities average  \n",
       "DNN -177.735   -1.797  -9.333 -112.051    -11.575 -33.689  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = {(str(score),str(model),str(metric)):[] for score in [\"MSE\",\"R^2\"] for model in [\"train\",\"test\"] for metric in ['injuries','str dam', 'str des', 'fatalities', 'average']}\n",
    "\n",
    "train_pred = np.around(mdl.predict(Xtrain)); train_pred[train_pred<0] = 0\n",
    "test_pred = np.around(mdl.predict(Xtest)); test_pred[test_pred<0] = 0\n",
    "\n",
    "train_score = np.around(r2_score(train_pred, ytrain, multioutput='raw_values'),3)\n",
    "cols[('R^2','train','injuries')].append(train_score[0]); cols[('R^2', 'train', 'str dam')].append(train_score[1])\n",
    "cols[('R^2','train','str des')].append(train_score[2]); cols[('R^2', 'train', 'fatalities')].append(train_score[3])\n",
    "cols[('R^2','train','average')].append(round(r2_score(train_pred, ytrain),3))\n",
    "\n",
    "test_score = np.around(r2_score(test_pred, ytest,multioutput='raw_values'),3)\n",
    "cols[('R^2','test','injuries')].append(test_score[0]); cols[('R^2','test','str dam')].append(test_score[1])\n",
    "cols[('R^2','test','str des')].append(test_score[2]); cols[('R^2','test','fatalities')].append(test_score[3])\n",
    "cols[('R^2','test','average')].append(round(r2_score(test_pred, ytest),3))\n",
    "\n",
    "train_MSE = np.around(mean_squared_error(ytrain, train_pred,multioutput='raw_values'),3)\n",
    "cols[('MSE','train','injuries')].append(train_MSE[0]); cols[('MSE', 'train', 'str dam')].append(train_MSE[1])\n",
    "cols[('MSE','train','str des')].append(train_MSE[2]); cols[('MSE', 'train', 'fatalities')].append(train_MSE[3])\n",
    "cols[('MSE','train','average')].append(round(mean_squared_error(train_pred, ytrain),3))\n",
    "\n",
    "test_MSE = np.around(mean_squared_error(ytest, test_pred,multioutput='raw_values'),3)\n",
    "cols[('MSE','test','injuries')].append(test_MSE[0]); cols[('MSE','test','str dam')].append(test_MSE[1])\n",
    "cols[('MSE','test','str des')].append(test_MSE[2]); cols[('MSE','test','fatalities')].append(test_MSE[3])\n",
    "cols[('MSE','test','average')].append(round(mean_squared_error(test_pred, ytest),3))\n",
    "\n",
    "\n",
    "columns = pd.MultiIndex.from_tuples([col for col in cols])\n",
    "results_df = pd.DataFrame(cols, columns=columns, index=['DNN'])\n",
    "#results_df['Model'] = ['DNN']\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 67%|████████████████████████████████████████████████████████                            | 2/3 [00:07<00:04,  4.61s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:47<00:00, 15.87s/it]\n",
      "  0%|                                                                                           | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "booster best value: gblinear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "  6%|█████▏                                                                             | 1/16 [00:05<01:25,  5.70s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 12%|██████████▍                                                                        | 2/16 [00:12<01:25,  6.12s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 19%|███████████████▌                                                                   | 3/16 [00:21<01:28,  6.81s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 25%|████████████████████▊                                                              | 4/16 [00:30<01:32,  7.70s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 31%|█████████████████████████▉                                                         | 5/16 [00:41<01:35,  8.68s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 38%|███████████████████████████████▏                                                   | 6/16 [00:54<01:37,  9.77s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 44%|████████████████████████████████████▎                                              | 7/16 [01:07<01:37, 10.87s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 50%|█████████████████████████████████████████▌                                         | 8/16 [01:22<01:35, 11.92s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 56%|██████████████████████████████████████████████▋                                    | 9/16 [01:37<01:31, 13.05s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 62%|███████████████████████████████████████████████████▎                              | 10/16 [01:54<01:25, 14.28s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 69%|████████████████████████████████████████████████████████▍                         | 11/16 [02:13<01:17, 15.47s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 75%|█████████████████████████████████████████████████████████████▌                    | 12/16 [02:32<01:06, 16.69s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 81%|██████████████████████████████████████████████████████████████████▋               | 13/16 [02:53<00:53, 17.92s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 88%|███████████████████████████████████████████████████████████████████████▊          | 14/16 [03:15<00:38, 19.12s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 94%|████████████████████████████████████████████████████████████████████████████▉     | 15/16 [03:38<00:20, 20.36s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [04:03<00:00, 15.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators best value: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "params = {'booster': ['gbtree', 'gblinear', 'dart'], 'n_estimators': [i for i in range(100, 500, 25)]}\n",
    "tree_params = {'max_depth':[i for i in range(3,25)]}\n",
    "for param in params:\n",
    "    train_r = []\n",
    "    test_r = []\n",
    "    train_MSE = []\n",
    "    test_MSE = []\n",
    "    for val in tqdm(params[param]):\n",
    "        input_params = {param:val}\n",
    "        clf = MultiOutputRegressor(xgb.XGBRegressor(**input_params))\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        train_r.append(round(clf.score(Xtrain, ytrain),3))\n",
    "        test_r.append(round(clf.score(Xtest, ytest),3))\n",
    "        train_MSE.append(round(mean_squared_error(ytrain, clf.predict(Xtrain)),3))\n",
    "        test_MSE.append(round(mean_squared_error(ytest, clf.predict(Xtest)),3))\n",
    "    print(param+\" best value:\", params[param][np.argmin(test_MSE)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_mdl = xgb.XGBRegressor(booster='gblinear',n_estimators=150)#100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'criterion':['mse', 'mae', 'friedman_mse'],\n",
    "         'max_features':['auto', 'sqrt', 'log2'],\n",
    "         'splitter':['best', 'random']}\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|████████████████████████████                                                        | 1/3 [00:01<00:02,  1.10s/it]\u001b[A\n",
      " 67%|███████████████████████████████████████████████████████▎                           | 2/3 [08:30<02:33, 153.46s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [08:31<00:00, 170.37s/it]\u001b[A\n",
      " 33%|███████████████████████████▋                                                       | 1/3 [08:31<17:02, 511.12s/it]\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███████████████████████████▋                                                       | 1/3 [10:16<20:32, 616.24s/it]\u001b[A\n",
      " 67%|███████████████████████████████████████████████████████▎                           | 2/3 [12:48<07:56, 476.92s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [14:48<00:00, 296.31s/it]\u001b[A\n",
      " 67%|███████████████████████████████████████████████████████▎                           | 2/3 [23:20<10:24, 624.46s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████████▌                                         | 1/2 [02:36<02:36, 156.01s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [05:53<00:00, 176.92s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [29:13<00:00, 584.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'mae', 'max_features': 'sqrt', 'splitter': 'random'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for param in tqdm(params):\n",
    "    train_r = []\n",
    "    test_r = []\n",
    "    train_MSE = []\n",
    "    test_MSE = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        clf = MultiOutputRegressor(DecisionTreeRegressor(**test_params))\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        train_r.append(round(clf.score(Xtrain, ytrain),3))\n",
    "        test_r.append(round(clf.score(Xtest, ytest),3))\n",
    "        train_MSE.append(round(mean_squared_error(ytrain, clf.predict(Xtrain)),3))\n",
    "        test_MSE.append(round(mean_squared_error(ytest, clf.predict(Xtest)),3))\n",
    "    best_params[param] = params[param][np.argmin(test_MSE)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTreeRegressor(criterion='mae', max_features='sqrt', splitter='random')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'base_estimator':[None, DecisionTreeRegressor(criterion='mse', max_features='auto', splitter='random')],\n",
    "          'n_estimators':[i for i in range(50, 550, 50)],\n",
    "          'learning_rate':[1*((10)**(i)) for i in range(-4,3,1)],\n",
    "          'loss':['linear', 'square', 'exponential']\n",
    "         }\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:09<00:09,  9.49s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:37<00:00, 18.96s/it]\u001b[A\n",
      " 25%|█████████████████████                                                               | 1/4 [00:37<01:53, 37.93s/it]\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|████████▎                                                                          | 1/10 [00:27<04:08, 27.60s/it]\u001b[A\n",
      " 20%|████████████████▌                                                                  | 2/10 [01:21<04:45, 35.63s/it]\u001b[A\n",
      " 30%|████████████████████████▉                                                          | 3/10 [02:42<05:44, 49.20s/it]\u001b[A\n",
      " 40%|█████████████████████████████████▏                                                 | 4/10 [04:30<06:40, 66.79s/it]\u001b[A\n",
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [06:39<07:06, 85.34s/it]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████▏                                | 6/10 [09:13<07:03, 105.96s/it]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████████▍                        | 7/10 [12:15<06:26, 128.90s/it]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 8/10 [15:42<05:04, 152.11s/it]\u001b[A\n",
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 9/10 [19:35<02:56, 176.37s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [23:50<00:00, 143.00s/it]\u001b[A\n",
      " 50%|█████████████████████████████████████████▌                                         | 2/4 [24:27<15:11, 455.55s/it]\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|████████████                                                                        | 1/7 [00:38<03:52, 38.83s/it]\u001b[A\n",
      " 29%|████████████████████████                                                            | 2/7 [01:16<03:13, 38.63s/it]\u001b[A\n",
      " 43%|████████████████████████████████████                                                | 3/7 [01:54<02:33, 38.44s/it]\u001b[A\n",
      " 57%|████████████████████████████████████████████████                                    | 4/7 [02:33<01:55, 38.34s/it]\u001b[A\n",
      " 71%|████████████████████████████████████████████████████████████                        | 5/7 [03:00<01:10, 35.14s/it]\u001b[A\n",
      " 86%|████████████████████████████████████████████████████████████████████████            | 6/7 [03:07<00:26, 26.56s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [03:08<00:00, 26.91s/it]\u001b[A\n",
      " 75%|██████████████████████████████████████████████████████████████▎                    | 3/4 [27:36<06:15, 375.39s/it]\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|████████████████████████████                                                        | 1/3 [00:37<01:15, 37.56s/it]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████                            | 2/3 [01:16<00:38, 38.02s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:56<00:00, 38.85s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 4/4 [29:32<00:00, 443.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_estimator': DecisionTreeRegressor(max_features='auto', splitter='random'), 'n_estimators': 50, 'learning_rate': 0.1, 'loss': 'exponential'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for param in tqdm(params):\n",
    "    train_r = []\n",
    "    test_r = []\n",
    "    train_MSE = []\n",
    "    test_MSE = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        clf = MultiOutputRegressor(AdaBoostRegressor(**test_params))\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        train_r.append(round(clf.score(Xtrain, ytrain),3))\n",
    "        test_r.append(round(clf.score(Xtest, ytest),3))\n",
    "        train_MSE.append(round(mean_squared_error(ytrain, clf.predict(Xtrain)),3))\n",
    "        test_MSE.append(round(mean_squared_error(ytest, clf.predict(Xtest)),3))\n",
    "    best_params[param] = params[param][np.argmin(test_MSE)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_features='auto',\n",
       "                                                       splitter='random'),\n",
       "                  learning_rate=1, loss='square')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_features='auto', splitter='random'), n_estimators=50, learning_rate=1, loss='square')\n",
    "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_features='auto', splitter='random'), n_estimators=50, learning_rate=0.1, loss='exponential')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'alpha': [1*((10)**(i)) for i in range(-4,3,1)],\n",
    "         'learning_rate':['constant', 'invscaling', 'adaptive'],\n",
    "          'hidden_layer_sizes':[(50,), (50,50), (50,50,50), (100,), (100,100), (100,100,100)]}\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|███████████▊                                                                       | 1/7 [07:39<45:58, 459.81s/it]\u001b[A\n",
      " 29%|███████████████████████▋                                                           | 2/7 [14:38<36:16, 435.38s/it]\u001b[A\n",
      " 43%|███████████████████████████████████▌                                               | 3/7 [21:42<28:41, 430.49s/it]\u001b[A\n",
      " 57%|███████████████████████████████████████████████▍                                   | 4/7 [26:59<19:16, 385.46s/it]\u001b[A\n",
      " 71%|███████████████████████████████████████████████████████████▎                       | 5/7 [31:25<11:24, 342.36s/it]\u001b[A\n",
      " 86%|███████████████████████████████████████████████████████████████████████▏           | 6/7 [33:29<04:28, 268.15s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 7/7 [34:14<00:00, 293.54s/it]\u001b[A\n",
      " 33%|██████████████████████████▋                                                     | 1/3 [34:14<1:08:29, 2054.78s/it]\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███████████████████████████▋                                                       | 1/3 [05:15<10:31, 315.96s/it]\u001b[A\n",
      " 67%|███████████████████████████████████████████████████████▎                           | 2/3 [10:32<05:16, 316.47s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [15:49<00:00, 316.60s/it]\u001b[A\n",
      " 67%|██████████████████████████████████████████████████████▋                           | 2/3 [50:04<23:24, 1404.80s/it]\n",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|█████████████▊                                                                     | 1/6 [06:09<30:48, 369.62s/it]\u001b[A\n",
      " 33%|███████████████████████████▋                                                       | 2/6 [09:13<17:21, 260.41s/it]\u001b[A\n",
      " 50%|█████████████████████████████████████████▌                                         | 3/6 [12:09<11:05, 221.92s/it]\u001b[A\n",
      " 67%|███████████████████████████████████████████████████████▎                           | 4/6 [17:28<08:40, 260.06s/it]\u001b[A\n",
      " 83%|█████████████████████████████████████████████████████████████████████▏             | 5/6 [20:48<03:58, 238.56s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 6/6 [24:32<00:00, 245.34s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 3/3 [1:14:36<00:00, 1492.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.1, 'learning_rate': 'constant', 'hidden_layer_sizes': (100,)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for param in tqdm(params):\n",
    "    train_r = []\n",
    "    test_r = []\n",
    "    train_MSE = []\n",
    "    test_MSE = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        clf = MultiOutputRegressor(MLPRegressor(random_state=0, max_iter=10000,**test_params))\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        train_r.append(round(clf.score(Xtrain, ytrain),3))\n",
    "        test_r.append(round(clf.score(Xtest, ytest),3))\n",
    "        train_MSE.append(round(mean_squared_error(ytrain, clf.predict(Xtrain)),3))\n",
    "        test_MSE.append(round(mean_squared_error(ytest, clf.predict(Xtest)),3))\n",
    "    best_params[param] = params[param][np.argmin(test_MSE)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\outdated\\utils.py:14: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.4.0, the latest is 0.5.0.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.style\n",
    "matplotlib.style.use(\"seaborn\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import seaborn as sns\n",
    "sns.color_palette(\"hls\", 17)\n",
    "import scipy.stats as st\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from pingouin import rcorr\n",
    "import pingouin as pg\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.multioutput import RegressorChain, MultiOutputRegressor\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifierCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm \n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, cross_validate, cross_val_score, learning_curve\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, precision_score, recall_score, plot_roc_curve, roc_curve, auc, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import feature_selection #import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(\"..\"))\n",
    "\n",
    "from module.trend_analysis_functions import *\n",
    "from module.topic_model_plus_class import Topic_Model_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3050: DtypeWarning: Columns (26) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(os.path.join(os.path.dirname(os.getcwd()),'data','ICS_predictive_sitreps_test.csv')).drop([\"Unnamed: 0\",\"Unnamed: 0.1\"], axis=1)\n",
    "train_data = pd.read_csv(os.path.join(os.path.dirname(os.getcwd()),'data','ICS_predictive_sitreps_train.csv')).drop([\"Unnamed: 0\",\"Unnamed: 0.1\"], axis=1)\n",
    "val_data = pd.read_csv(os.path.join(os.path.dirname(os.getcwd()),'data','ICS_predictive_sitreps_val.csv')).drop([\"Unnamed: 0\",\"Unnamed: 0.1\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CY</th>\n",
       "      <th>DISCOVERY_DATE</th>\n",
       "      <th>INCIDENT_ID</th>\n",
       "      <th>PCT_CONTAINED_COMPLETED</th>\n",
       "      <th>START_YEAR</th>\n",
       "      <th>TOTAL_AERIAL</th>\n",
       "      <th>TOTAL_PERSONNEL</th>\n",
       "      <th>REPORT_DOY</th>\n",
       "      <th>DISCOVERY_DOY</th>\n",
       "      <th>Combined_Text</th>\n",
       "      <th>...</th>\n",
       "      <th>Current_total_Structures_Destroyed</th>\n",
       "      <th>Current_total_Fatalities</th>\n",
       "      <th>Diff_Injuries</th>\n",
       "      <th>Diff_Structures_Damages</th>\n",
       "      <th>Diff_Structures_Destroyed</th>\n",
       "      <th>Diff_Fatalities</th>\n",
       "      <th>Total_Injuries</th>\n",
       "      <th>Total_Structures_Damages</th>\n",
       "      <th>Total_Structures_Destroyed</th>\n",
       "      <th>Total_Fatalities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>2010-07-15 15:00:00</td>\n",
       "      <td>2000_CA-RRU-062485_VALLEY COMPLEX</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "      <td>['resource', 'share', 'cactus']</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>2010-07-15 15:00:00</td>\n",
       "      <td>2000_CA-RRU-062485_VALLEY COMPLEX</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "      <td>['resource', 'share', 'incident', 'cactus', 'i...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>2010-07-15 15:00:00</td>\n",
       "      <td>2000_CA-RRU-062485_VALLEY COMPLEX</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "      <td>['resource', 'share', 'cactus', 'erratic', 'wi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>2010-07-15 15:00:00</td>\n",
       "      <td>2000_CA-RRU-062485_VALLEY COMPLEX</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>192.333333</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "      <td>['resource', 'share', 'cactus', 'cactus', 'bec...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>2010-07-15 15:00:00</td>\n",
       "      <td>2000_CA-RRU-062485_VALLEY COMPLEX</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>192.333333</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "      <td>['resource', 'share', 'cactus', 'cactus', 'bec...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18591</th>\n",
       "      <td>2014</td>\n",
       "      <td>2014-03-15 14:30:00</td>\n",
       "      <td>2014_VAVAS1403037_BEAVER LODGE RD.</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>['fast', 'spread', 'field']</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18592</th>\n",
       "      <td>2014</td>\n",
       "      <td>2014-03-19 14:00:00</td>\n",
       "      <td>2014_VAVAS1406037_AIRPORT MOUNTAIN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>80</td>\n",
       "      <td>78</td>\n",
       "      <td>['heavy', 'plume', 'primary', 'carrier']</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18593</th>\n",
       "      <td>2014</td>\n",
       "      <td>2014-08-20 13:00:00</td>\n",
       "      <td>2014_WA-WFS-513_SAND RIDGE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>234</td>\n",
       "      <td>232</td>\n",
       "      <td>['heavy', 'canyon', 'river', 'mainly', 'canyon...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18594</th>\n",
       "      <td>2014</td>\n",
       "      <td>2014-08-20 13:00:00</td>\n",
       "      <td>2014_WA-WFS-513_SAND RIDGE</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>235</td>\n",
       "      <td>232</td>\n",
       "      <td>['laid', 'night', 'test', 'wind', 'remain', 'c...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18595</th>\n",
       "      <td>2014</td>\n",
       "      <td>2014-08-20 13:00:00</td>\n",
       "      <td>2014_WA-WFS-513_SAND RIDGE</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>235</td>\n",
       "      <td>232</td>\n",
       "      <td>['report', 'incident', 'wind', 'test', 'overni...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18596 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CY       DISCOVERY_DATE                         INCIDENT_ID  \\\n",
       "0      2010  2010-07-15 15:00:00   2000_CA-RRU-062485_VALLEY COMPLEX   \n",
       "1      2010  2010-07-15 15:00:00   2000_CA-RRU-062485_VALLEY COMPLEX   \n",
       "2      2010  2010-07-15 15:00:00   2000_CA-RRU-062485_VALLEY COMPLEX   \n",
       "3      2010  2010-07-15 15:00:00   2000_CA-RRU-062485_VALLEY COMPLEX   \n",
       "4      2010  2010-07-15 15:00:00   2000_CA-RRU-062485_VALLEY COMPLEX   \n",
       "...     ...                  ...                                 ...   \n",
       "18591  2014  2014-03-15 14:30:00  2014_VAVAS1403037_BEAVER LODGE RD.   \n",
       "18592  2014  2014-03-19 14:00:00  2014_VAVAS1406037_AIRPORT MOUNTAIN   \n",
       "18593  2014  2014-08-20 13:00:00          2014_WA-WFS-513_SAND RIDGE   \n",
       "18594  2014  2014-08-20 13:00:00          2014_WA-WFS-513_SAND RIDGE   \n",
       "18595  2014  2014-08-20 13:00:00          2014_WA-WFS-513_SAND RIDGE   \n",
       "\n",
       "       PCT_CONTAINED_COMPLETED  START_YEAR  TOTAL_AERIAL  TOTAL_PERSONNEL  \\\n",
       "0                         80.0      2010.0      5.000000       230.000000   \n",
       "1                         60.0      2010.0      5.000000       230.000000   \n",
       "2                         30.0      2010.0      4.000000       165.000000   \n",
       "3                        100.0      2010.0      4.333333       192.333333   \n",
       "4                         60.0      2010.0      4.333333       192.333333   \n",
       "...                        ...         ...           ...              ...   \n",
       "18591                    100.0      2014.0      0.000000        13.000000   \n",
       "18592                     85.0      2014.0      0.000000        18.500000   \n",
       "18593                      0.0      2014.0      1.000000        95.000000   \n",
       "18594                     86.0      2014.0      1.000000       120.000000   \n",
       "18595                    100.0      2014.0      0.000000        46.000000   \n",
       "\n",
       "       REPORT_DOY  DISCOVERY_DOY  \\\n",
       "0             197            196   \n",
       "1             197            196   \n",
       "2             197            196   \n",
       "3             197            196   \n",
       "4             197            196   \n",
       "...           ...            ...   \n",
       "18591          74             74   \n",
       "18592          80             78   \n",
       "18593         234            232   \n",
       "18594         235            232   \n",
       "18595         235            232   \n",
       "\n",
       "                                           Combined_Text  ...  \\\n",
       "0                        ['resource', 'share', 'cactus']  ...   \n",
       "1      ['resource', 'share', 'incident', 'cactus', 'i...  ...   \n",
       "2      ['resource', 'share', 'cactus', 'erratic', 'wi...  ...   \n",
       "3      ['resource', 'share', 'cactus', 'cactus', 'bec...  ...   \n",
       "4      ['resource', 'share', 'cactus', 'cactus', 'bec...  ...   \n",
       "...                                                  ...  ...   \n",
       "18591                        ['fast', 'spread', 'field']  ...   \n",
       "18592           ['heavy', 'plume', 'primary', 'carrier']  ...   \n",
       "18593  ['heavy', 'canyon', 'river', 'mainly', 'canyon...  ...   \n",
       "18594  ['laid', 'night', 'test', 'wind', 'remain', 'c...  ...   \n",
       "18595  ['report', 'incident', 'wind', 'test', 'overni...  ...   \n",
       "\n",
       "      Current_total_Structures_Destroyed  Current_total_Fatalities  \\\n",
       "0                                    0.0                       0.0   \n",
       "1                                    0.0                       0.0   \n",
       "2                                    0.0                       0.0   \n",
       "3                                    0.0                       0.0   \n",
       "4                                    0.0                       0.0   \n",
       "...                                  ...                       ...   \n",
       "18591                                1.0                       0.0   \n",
       "18592                                0.0                       0.0   \n",
       "18593                                0.0                       0.0   \n",
       "18594                                0.0                       0.0   \n",
       "18595                                0.0                       0.0   \n",
       "\n",
       "       Diff_Injuries  Diff_Structures_Damages  Diff_Structures_Destroyed  \\\n",
       "0                1.0                      0.0                        0.0   \n",
       "1                1.0                      0.0                        0.0   \n",
       "2                1.0                      0.0                        0.0   \n",
       "3                1.0                      0.0                        0.0   \n",
       "4                0.0                      0.0                        0.0   \n",
       "...              ...                      ...                        ...   \n",
       "18591            0.0                      0.0                        0.0   \n",
       "18592            0.0                      0.0                        0.0   \n",
       "18593            0.0                      0.0                        0.0   \n",
       "18594            0.0                      0.0                        0.0   \n",
       "18595            0.0                      0.0                        0.0   \n",
       "\n",
       "       Diff_Fatalities  Total_Injuries  Total_Structures_Damages  \\\n",
       "0                  0.0             1.0                       0.0   \n",
       "1                  0.0             1.0                       0.0   \n",
       "2                  0.0             1.0                       0.0   \n",
       "3                  0.0             1.0                       0.0   \n",
       "4                  0.0             1.0                       0.0   \n",
       "...                ...             ...                       ...   \n",
       "18591              0.0             0.0                       1.0   \n",
       "18592              0.0             0.0                       0.0   \n",
       "18593              0.0             0.0                       0.0   \n",
       "18594              0.0             0.0                       0.0   \n",
       "18595              0.0             0.0                       0.0   \n",
       "\n",
       "       Total_Structures_Destroyed Total_Fatalities  \n",
       "0                             0.0              0.0  \n",
       "1                             0.0              0.0  \n",
       "2                             0.0              0.0  \n",
       "3                             0.0              0.0  \n",
       "4                             0.0              0.0  \n",
       "...                           ...              ...  \n",
       "18591                         1.0              0.0  \n",
       "18592                         0.0              0.0  \n",
       "18593                         0.0              0.0  \n",
       "18594                         0.0              0.0  \n",
       "18595                         0.0              0.0  \n",
       "\n",
       "[18596 rows x 59 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CY</th>\n",
       "      <th>DISCOVERY_DATE</th>\n",
       "      <th>INCIDENT_ID</th>\n",
       "      <th>PCT_CONTAINED_COMPLETED</th>\n",
       "      <th>START_YEAR</th>\n",
       "      <th>TOTAL_AERIAL</th>\n",
       "      <th>TOTAL_PERSONNEL</th>\n",
       "      <th>REPORT_DOY</th>\n",
       "      <th>DISCOVERY_DOY</th>\n",
       "      <th>Combined_Text</th>\n",
       "      <th>...</th>\n",
       "      <th>Incident_region_AICC</th>\n",
       "      <th>Incident_region_CA</th>\n",
       "      <th>Incident_region_EACC</th>\n",
       "      <th>Incident_region_GBCC</th>\n",
       "      <th>Incident_region_HICC</th>\n",
       "      <th>Incident_region_NRCC</th>\n",
       "      <th>Incident_region_NWCC</th>\n",
       "      <th>Incident_region_RMCC</th>\n",
       "      <th>Incident_region_SACC</th>\n",
       "      <th>Incident_region_SWCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>2010-07-15 15:00:00</td>\n",
       "      <td>2000_CA-RRU-062485_VALLEY COMPLEX</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "      <td>['resource', 'share', 'cactus']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>2010-07-15 15:00:00</td>\n",
       "      <td>2000_CA-RRU-062485_VALLEY COMPLEX</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "      <td>['resource', 'share', 'incident', 'cactus', 'i...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>2010-07-15 15:00:00</td>\n",
       "      <td>2000_CA-RRU-062485_VALLEY COMPLEX</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "      <td>['resource', 'share', 'cactus', 'erratic', 'wi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>2010-07-15 15:00:00</td>\n",
       "      <td>2000_CA-RRU-062485_VALLEY COMPLEX</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>192.333333</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "      <td>['resource', 'share', 'cactus', 'cactus', 'bec...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>2010-07-15 15:00:00</td>\n",
       "      <td>2000_CA-RRU-062485_VALLEY COMPLEX</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>192.333333</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "      <td>['resource', 'share', 'cactus', 'cactus', 'bec...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18591</th>\n",
       "      <td>2014</td>\n",
       "      <td>2014-03-15 14:30:00</td>\n",
       "      <td>2014_VAVAS1403037_BEAVER LODGE RD.</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>['fast', 'spread', 'field']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18592</th>\n",
       "      <td>2014</td>\n",
       "      <td>2014-03-19 14:00:00</td>\n",
       "      <td>2014_VAVAS1406037_AIRPORT MOUNTAIN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>80</td>\n",
       "      <td>78</td>\n",
       "      <td>['heavy', 'plume', 'primary', 'carrier']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18593</th>\n",
       "      <td>2014</td>\n",
       "      <td>2014-08-20 13:00:00</td>\n",
       "      <td>2014_WA-WFS-513_SAND RIDGE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>234</td>\n",
       "      <td>232</td>\n",
       "      <td>['heavy', 'canyon', 'river', 'mainly', 'canyon...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18594</th>\n",
       "      <td>2014</td>\n",
       "      <td>2014-08-20 13:00:00</td>\n",
       "      <td>2014_WA-WFS-513_SAND RIDGE</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>235</td>\n",
       "      <td>232</td>\n",
       "      <td>['laid', 'night', 'test', 'wind', 'remain', 'c...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18595</th>\n",
       "      <td>2014</td>\n",
       "      <td>2014-08-20 13:00:00</td>\n",
       "      <td>2014_WA-WFS-513_SAND RIDGE</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>235</td>\n",
       "      <td>232</td>\n",
       "      <td>['report', 'incident', 'wind', 'test', 'overni...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18596 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CY       DISCOVERY_DATE                         INCIDENT_ID  \\\n",
       "0      2010  2010-07-15 15:00:00   2000_CA-RRU-062485_VALLEY COMPLEX   \n",
       "1      2010  2010-07-15 15:00:00   2000_CA-RRU-062485_VALLEY COMPLEX   \n",
       "2      2010  2010-07-15 15:00:00   2000_CA-RRU-062485_VALLEY COMPLEX   \n",
       "3      2010  2010-07-15 15:00:00   2000_CA-RRU-062485_VALLEY COMPLEX   \n",
       "4      2010  2010-07-15 15:00:00   2000_CA-RRU-062485_VALLEY COMPLEX   \n",
       "...     ...                  ...                                 ...   \n",
       "18591  2014  2014-03-15 14:30:00  2014_VAVAS1403037_BEAVER LODGE RD.   \n",
       "18592  2014  2014-03-19 14:00:00  2014_VAVAS1406037_AIRPORT MOUNTAIN   \n",
       "18593  2014  2014-08-20 13:00:00          2014_WA-WFS-513_SAND RIDGE   \n",
       "18594  2014  2014-08-20 13:00:00          2014_WA-WFS-513_SAND RIDGE   \n",
       "18595  2014  2014-08-20 13:00:00          2014_WA-WFS-513_SAND RIDGE   \n",
       "\n",
       "       PCT_CONTAINED_COMPLETED  START_YEAR  TOTAL_AERIAL  TOTAL_PERSONNEL  \\\n",
       "0                         80.0      2010.0      5.000000       230.000000   \n",
       "1                         60.0      2010.0      5.000000       230.000000   \n",
       "2                         30.0      2010.0      4.000000       165.000000   \n",
       "3                        100.0      2010.0      4.333333       192.333333   \n",
       "4                         60.0      2010.0      4.333333       192.333333   \n",
       "...                        ...         ...           ...              ...   \n",
       "18591                    100.0      2014.0      0.000000        13.000000   \n",
       "18592                     85.0      2014.0      0.000000        18.500000   \n",
       "18593                      0.0      2014.0      1.000000        95.000000   \n",
       "18594                     86.0      2014.0      1.000000       120.000000   \n",
       "18595                    100.0      2014.0      0.000000        46.000000   \n",
       "\n",
       "       REPORT_DOY  DISCOVERY_DOY  \\\n",
       "0             197            196   \n",
       "1             197            196   \n",
       "2             197            196   \n",
       "3             197            196   \n",
       "4             197            196   \n",
       "...           ...            ...   \n",
       "18591          74             74   \n",
       "18592          80             78   \n",
       "18593         234            232   \n",
       "18594         235            232   \n",
       "18595         235            232   \n",
       "\n",
       "                                           Combined_Text  ...  \\\n",
       "0                        ['resource', 'share', 'cactus']  ...   \n",
       "1      ['resource', 'share', 'incident', 'cactus', 'i...  ...   \n",
       "2      ['resource', 'share', 'cactus', 'erratic', 'wi...  ...   \n",
       "3      ['resource', 'share', 'cactus', 'cactus', 'bec...  ...   \n",
       "4      ['resource', 'share', 'cactus', 'cactus', 'bec...  ...   \n",
       "...                                                  ...  ...   \n",
       "18591                        ['fast', 'spread', 'field']  ...   \n",
       "18592           ['heavy', 'plume', 'primary', 'carrier']  ...   \n",
       "18593  ['heavy', 'canyon', 'river', 'mainly', 'canyon...  ...   \n",
       "18594  ['laid', 'night', 'test', 'wind', 'remain', 'c...  ...   \n",
       "18595  ['report', 'incident', 'wind', 'test', 'overni...  ...   \n",
       "\n",
       "      Incident_region_AICC  Incident_region_CA  Incident_region_EACC  \\\n",
       "0                        0                   1                     0   \n",
       "1                        0                   1                     0   \n",
       "2                        0                   1                     0   \n",
       "3                        0                   1                     0   \n",
       "4                        0                   1                     0   \n",
       "...                    ...                 ...                   ...   \n",
       "18591                    0                   0                     0   \n",
       "18592                    0                   0                     0   \n",
       "18593                    0                   0                     0   \n",
       "18594                    0                   0                     0   \n",
       "18595                    0                   0                     0   \n",
       "\n",
       "       Incident_region_GBCC  Incident_region_HICC  Incident_region_NRCC  \\\n",
       "0                         0                     0                     0   \n",
       "1                         0                     0                     0   \n",
       "2                         0                     0                     0   \n",
       "3                         0                     0                     0   \n",
       "4                         0                     0                     0   \n",
       "...                     ...                   ...                   ...   \n",
       "18591                     0                     0                     0   \n",
       "18592                     0                     0                     0   \n",
       "18593                     0                     0                     0   \n",
       "18594                     0                     0                     0   \n",
       "18595                     0                     0                     0   \n",
       "\n",
       "       Incident_region_NWCC  Incident_region_RMCC  Incident_region_SACC  \\\n",
       "0                         0                     0                     0   \n",
       "1                         0                     0                     0   \n",
       "2                         0                     0                     0   \n",
       "3                         0                     0                     0   \n",
       "4                         0                     0                     0   \n",
       "...                     ...                   ...                   ...   \n",
       "18591                     0                     0                     1   \n",
       "18592                     0                     0                     1   \n",
       "18593                     1                     0                     0   \n",
       "18594                     1                     0                     0   \n",
       "18595                     1                     0                     0   \n",
       "\n",
       "      Incident_region_SWCC  \n",
       "0                        0  \n",
       "1                        0  \n",
       "2                        0  \n",
       "3                        0  \n",
       "4                        0  \n",
       "...                    ...  \n",
       "18591                    0  \n",
       "18592                    0  \n",
       "18593                    0  \n",
       "18594                    0  \n",
       "18595                    0  \n",
       "\n",
       "[18596 rows x 69 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions = pd.get_dummies(train_data.Incident_region, prefix='Incident_region')\n",
    "train_data = pd.concat([train_data, regions], axis=1)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CY', 'DISCOVERY_DATE', 'INCIDENT_ID', 'PCT_CONTAINED_COMPLETED',\n",
       "       'START_YEAR', 'TOTAL_AERIAL', 'TOTAL_PERSONNEL', 'REPORT_DOY',\n",
       "       'DISCOVERY_DOY', 'Combined_Text', 'Unique_IDs', 'ACRES', 'WF_FSR',\n",
       "       'INJURIES', 'FATALITIES', 'EST_IM_COST_TO_DATE', 'STR_DAMAGED',\n",
       "       'STR_DESTROYED', 'NEW_ACRES', 'POO_STATE', 'POO_LATITUDE',\n",
       "       'POO_LONGITUDE', 'WEATHER_CONCERNS_NARR', 'INC_MGMT_ORG_ABBREV',\n",
       "       'EVACUATION_IN_PROGRESS', 'Incident_region', 'NUM_REPORTS',\n",
       "       'DAYS_BURING', 'Severity', 'Traffic', 'Command_Transitions',\n",
       "       'Evacuations', 'Inaccurate_Mapping', 'Aerial_Grounding',\n",
       "       'Resource_Issues', 'Injuries', 'Cultural_Resources', 'Livestock',\n",
       "       'Law_Violations', 'Military_Base', 'Infrastructure', 'Extreme_Weather',\n",
       "       'Ecological', 'Hazardous_Terrain', 'Floods', 'Dry_Weather',\n",
       "       'Total_Incident_Text', 'Current_total_Injuries',\n",
       "       'Current_total_Structures_Damages',\n",
       "       'Current_total_Structures_Destroyed', 'Current_total_Fatalities',\n",
       "       'Diff_Injuries', 'Diff_Structures_Damages', 'Diff_Structures_Destroyed',\n",
       "       'Diff_Fatalities', 'Total_Injuries', 'Total_Structures_Damages',\n",
       "       'Total_Structures_Destroyed', 'Total_Fatalities',\n",
       "       'Incident_region_AICC', 'Incident_region_CA', 'Incident_region_EACC',\n",
       "       'Incident_region_GBCC', 'Incident_region_HICC', 'Incident_region_NRCC',\n",
       "       'Incident_region_NWCC', 'Incident_region_RMCC', 'Incident_region_SACC',\n",
       "       'Incident_region_SWCC'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcols = ['TOTAL_AERIAL', 'TOTAL_PERSONNEL', 'WF_FSR', 'DAYS_BURING', 'ACRES','PCT_CONTAINED_COMPLETED', 'Current_total_Injuries',\n",
    "       'Current_total_Structures_Damages',\n",
    "       'Current_total_Structures_Destroyed', 'Current_total_Fatalities','Traffic',\n",
    "       'Command_Transitions', 'Evacuations', 'Inaccurate_Mapping',\n",
    "       'Aerial_Grounding', 'Resource_Issues', 'Injuries', 'Cultural_Resources',\n",
    "       'Livestock', 'Law_Violations', 'Military_Base', 'Infrastructure',\n",
    "       'Extreme_Weather', 'Ecological', 'Hazardous_Terrain', 'Floods',\n",
    "       'Dry_Weather', 'Incident_region_AICC', 'Incident_region_CA', 'Incident_region_EACC',\n",
    "       'Incident_region_GBCC', 'Incident_region_HICC', 'Incident_region_NRCC',\n",
    "       'Incident_region_NWCC', 'Incident_region_RMCC', 'Incident_region_SACC',\n",
    "       'Incident_region_SWCC']\n",
    "ycols = ['Diff_Injuries', 'Diff_Structures_Damages', 'Diff_Structures_Destroyed',\n",
    "       'Diff_Fatalities']\n",
    "Xtrain = train_data[xcols]; ytrain = train_data[ycols]\n",
    "Xval = val_data[xcols]; yval = val_data[ycols]\n",
    "Xtest = test_data[xcols]; ytest = test_data[ycols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models to test:\n",
    "- SVM\n",
    "- NB\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- xgboost\n",
    "- AdaBoost\n",
    "- NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "      <th>train MSE</th>\n",
       "      <th>test MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>-11931.242</td>\n",
       "      <td>-3.504</td>\n",
       "      <td>8.122</td>\n",
       "      <td>0.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.151</td>\n",
       "      <td>-0.522</td>\n",
       "      <td>2.814</td>\n",
       "      <td>1.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>-2.468</td>\n",
       "      <td>-7.915</td>\n",
       "      <td>8.226</td>\n",
       "      <td>0.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bayesian Ridge</td>\n",
       "      <td>-0.308</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>8.170</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP</td>\n",
       "      <td>-170.045</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>7.778</td>\n",
       "      <td>1.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-15750.494</td>\n",
       "      <td>-0.233</td>\n",
       "      <td>8.170</td>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.978</td>\n",
       "      <td>-1.347</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model  train score  test score  train MSE  test MSE\n",
       "0               SVM   -11931.242      -3.504      8.122     0.870\n",
       "1  GradientBoosting        0.151      -0.522      2.814     1.101\n",
       "2     Random Forest       -2.468      -7.915      8.226     0.957\n",
       "3    Bayesian Ridge       -0.308      -0.244      8.170     0.750\n",
       "4               MLP     -170.045      -0.019      7.778     1.102\n",
       "5           XGBoost   -15750.494      -0.233      8.170     0.748\n",
       "6          AdaBoost        0.978      -1.347      0.070     0.933\n",
       "7     Decision Tree        1.000      -0.023      0.000     1.904"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names = [\"SVM\", \"GradientBoosting\", \"Random Forest\", \"Bayesian Ridge\", \"MLP\", \"XGBoost\", \"AdaBoost\", \"Decision Tree\"]\n",
    "train_score = []; test_score = []; train_MSE = []; test_MSE = []\n",
    "models = [svm.SVR(kernel='rbf', C=0.4), GradientBoostingRegressor(max_features='log2',n_estimators=100, random_state=0, max_depth=5), \n",
    "          RandomForestRegressor(criterion='mae',max_features='log2',n_estimators=125, random_state=0, max_depth=6),\n",
    "          linear_model.BayesianRidge(alpha_1=10000, alpha_2=10000, lambda_1=10, lambda_2=0.001),\n",
    "          MLPRegressor(random_state=0, max_iter=1000), xgb.XGBRegressor(booster='gblinear',n_estimators=100),\n",
    "         AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_features='auto', splitter='random'), n_estimators=50, learning_rate=1, loss='square'), \n",
    "          DecisionTreeRegressor(criterion='mse', max_features='auto', splitter='random')]\n",
    "for m in models:\n",
    "    mdl = MultiOutputRegressor(m)\n",
    "    mdl.fit(norm_Xtrain, ytrain)\n",
    "    train_pred = np.around(mdl.predict(norm_Xtrain)); train_pred[train_pred<0] = 0\n",
    "    test_pred = np.around(mdl.predict(norm_Xtest)); test_pred[test_pred<0] = 0\n",
    "    train_score.append(round(r2_score(train_pred, ytrain),3))\n",
    "    test_score.append(round(r2_score(test_pred, ytest),3))\n",
    "    train_MSE.append(round(mean_squared_error(ytrain, train_pred),3))\n",
    "    test_MSE.append(round(mean_squared_error(ytest, test_pred),3))\n",
    "\n",
    "results_df = pd.DataFrame({\"model\": model_names,\n",
    "                          \"train score\": train_score,\n",
    "                          \"test score\": test_score,\n",
    "                          \"train MSE\": train_MSE,\n",
    "                          \"test MSE\": test_MSE})\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = xgb.XGBRegressor(booster='gblinear',n_estimators=100)\n",
    "mdl = MultiOutputRegressor(m)\n",
    "mdl.fit(norm_Xtrain, ytrain)\n",
    "preds = np.around(mdl.predict(norm_Xtest))\n",
    "preds[preds<0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame(preds, columns = ytest.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      Diff_Injuries  Diff_Structures_Damages  Diff_Structures_Destroyed  \\\n",
       " 0               0.0                      0.0                        0.0   \n",
       " 1               0.0                      0.0                        0.0   \n",
       " 2               0.0                      0.0                        0.0   \n",
       " 3               0.0                      0.0                        0.0   \n",
       " 4               0.0                      0.0                        0.0   \n",
       " ...             ...                      ...                        ...   \n",
       " 2502           -0.0                      0.0                        0.0   \n",
       " 2503           -0.0                     -0.0                       -0.0   \n",
       " 2504           -0.0                      0.0                        0.0   \n",
       " 2505           -0.0                      0.0                        0.0   \n",
       " 2506           -0.0                      0.0                        0.0   \n",
       " \n",
       "       Diff_Fatalities  \n",
       " 0                 0.0  \n",
       " 1                 0.0  \n",
       " 2                 0.0  \n",
       " 3                 0.0  \n",
       " 4                 0.0  \n",
       " ...               ...  \n",
       " 2502              0.0  \n",
       " 2503              0.0  \n",
       " 2504              0.0  \n",
       " 2505              0.0  \n",
       " 2506              0.0  \n",
       " \n",
       " [2507 rows x 4 columns],\n",
       "       Diff_Injuries  Diff_Structures_Damages  Diff_Structures_Destroyed  \\\n",
       " 0               0.0                      0.0                        0.0   \n",
       " 1               0.0                      0.0                        0.0   \n",
       " 2               0.0                      0.0                        0.0   \n",
       " 3               0.0                      0.0                        0.0   \n",
       " 4               0.0                      0.0                        0.0   \n",
       " ...             ...                      ...                        ...   \n",
       " 2502            0.0                      0.0                        0.0   \n",
       " 2503            0.0                      0.0                        0.0   \n",
       " 2504            0.0                      0.0                        0.0   \n",
       " 2505            0.0                      0.0                        0.0   \n",
       " 2506            0.0                      0.0                        0.0   \n",
       " \n",
       "       Diff_Fatalities  \n",
       " 0                 0.0  \n",
       " 1                 0.0  \n",
       " 2                 0.0  \n",
       " 3                 0.0  \n",
       " 4                 0.0  \n",
       " ...               ...  \n",
       " 2502              0.0  \n",
       " 2503              0.0  \n",
       " 2504              0.0  \n",
       " 2505              0.0  \n",
       " 2506              0.0  \n",
       " \n",
       " [2507 rows x 4 columns])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2.,  3.,  4., 15., 13., 14.,  6.,  5.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest['Diff_Injuries'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4., 5.], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds['Diff_Injuries'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rbf\n",
      "poly\n",
      "sigmoid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernels</th>\n",
       "      <th>train r</th>\n",
       "      <th>test r</th>\n",
       "      <th>train MSE</th>\n",
       "      <th>test MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.341</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>8.039</td>\n",
       "      <td>0.846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poly</td>\n",
       "      <td>0.350</td>\n",
       "      <td>-0.913</td>\n",
       "      <td>8.009</td>\n",
       "      <td>0.942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>-1612.193</td>\n",
       "      <td>-1047658.104</td>\n",
       "      <td>11287.970</td>\n",
       "      <td>12093.547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kernels   train r       test r  train MSE   test MSE\n",
       "0      rbf     0.341       -0.120      8.039      0.846\n",
       "1     poly     0.350       -0.913      8.009      0.942\n",
       "2  sigmoid -1612.193 -1047658.104  11287.970  12093.547"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernals = ['rbf', 'poly', 'sigmoid']\n",
    "train_r = []\n",
    "test_r = []\n",
    "train_MSE = []\n",
    "test_MSE = []\n",
    "for kernal in kernals:\n",
    "    print(kernal)\n",
    "    mdl = MultiOutputRegressor(svm.SVR(kernel=kernal))\n",
    "    \n",
    "    mdl.fit(norm_Xtrain, ytrain)\n",
    "    train_r.append(round(mdl.score(norm_Xtrain, ytrain),3))\n",
    "    test_r.append(round(mdl.score(norm_Xtest, ytest),3))\n",
    "    train_MSE.append(round(mean_squared_error(ytrain, mdl.predict(norm_Xtrain)),3))\n",
    "    test_MSE.append(round(mean_squared_error(ytest, mdl.predict(norm_Xtest)),3))\n",
    "\n",
    "model_comparisons = pd.DataFrame({\n",
    "    \"kernels\": kernals,\n",
    "    \"train r\": train_r,\n",
    "    \"test r\": test_r,\n",
    "    \"train MSE\": train_MSE,\n",
    "    \"test MSE\": test_MSE})\n",
    "\n",
    "model_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c-value</th>\n",
       "      <th>train r</th>\n",
       "      <th>test r</th>\n",
       "      <th>train MSE</th>\n",
       "      <th>test MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.288</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>8.213</td>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.304</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>8.158</td>\n",
       "      <td>0.873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.314</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>8.125</td>\n",
       "      <td>0.862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.322</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>8.099</td>\n",
       "      <td>0.856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.328</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>8.080</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.332</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>8.067</td>\n",
       "      <td>0.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.335</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>8.057</td>\n",
       "      <td>0.848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.338</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>8.050</td>\n",
       "      <td>0.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.339</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>8.044</td>\n",
       "      <td>0.846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.341</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>8.039</td>\n",
       "      <td>0.846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.1</td>\n",
       "      <td>0.342</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>8.035</td>\n",
       "      <td>0.846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.2</td>\n",
       "      <td>0.343</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>8.032</td>\n",
       "      <td>0.846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    c-value  train r  test r  train MSE  test MSE\n",
       "0       0.1    0.288  -0.080      8.213     0.895\n",
       "1       0.2    0.304  -0.002      8.158     0.873\n",
       "2       0.3    0.314  -0.003      8.125     0.862\n",
       "3       0.4    0.322  -0.020      8.099     0.856\n",
       "4       0.5    0.328  -0.039      8.080     0.854\n",
       "5       0.6    0.332  -0.058      8.067     0.849\n",
       "6       0.7    0.335  -0.078      8.057     0.848\n",
       "7       0.8    0.338  -0.097      8.050     0.845\n",
       "8       0.9    0.339  -0.114      8.044     0.846\n",
       "9       1.0    0.341  -0.120      8.039     0.846\n",
       "10      1.1    0.342  -0.127      8.035     0.846\n",
       "11      1.2    0.343  -0.133      8.032     0.846"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_vals = [1e-1,2e-1,3e-1,4e-1,5e-1, 6e-1,7e-1,8e-1, 9e-1, 1, 1.1, 1.2]\n",
    "train_r = []\n",
    "test_r = []\n",
    "train_MSE = []\n",
    "test_MSE = []\n",
    "for c in c_vals:\n",
    "    mdl = MultiOutputRegressor(svm.SVR(C=c,kernel='rbf'))\n",
    "    \n",
    "    mdl.fit(norm_Xtrain, ytrain)\n",
    "    train_r.append(round(mdl.score(norm_Xtrain, ytrain),3))\n",
    "    test_r.append(round(mdl.score(norm_Xtest, ytest),3))\n",
    "    train_MSE.append(round(mean_squared_error(ytrain, mdl.predict(norm_Xtrain)),3))\n",
    "    test_MSE.append(round(mean_squared_error(ytest, mdl.predict(norm_Xtest)),3))\n",
    "\n",
    "model_comparisons = pd.DataFrame({\n",
    "    \"c-value\": c_vals,\n",
    "    \"train r\": train_r,\n",
    "    \"test r\": test_r,\n",
    "    \"train MSE\": train_MSE,\n",
    "    \"test MSE\": test_MSE})\n",
    "\n",
    "model_comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {'loss' : ['huber'],\n",
    "              'criterion': ['friedman_mse', 'squared_error'],\n",
    "              'max_depth': [i for i in range(3,25)],\n",
    "              'n_estimators': [i for i in range(100, 500, 25)],\n",
    "              'max_features': ['auto', 'sqrt', 'log2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [05:30<00:00, 15.03s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>train r</th>\n",
       "      <th>test r</th>\n",
       "      <th>train MSE</th>\n",
       "      <th>test MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>-630.324</td>\n",
       "      <td>3.495</td>\n",
       "      <td>6.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.839</td>\n",
       "      <td>-1041.193</td>\n",
       "      <td>1.358</td>\n",
       "      <td>6.268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.937</td>\n",
       "      <td>-326.621</td>\n",
       "      <td>0.208</td>\n",
       "      <td>4.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.956</td>\n",
       "      <td>-861.562</td>\n",
       "      <td>0.145</td>\n",
       "      <td>9.289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.972</td>\n",
       "      <td>-1746.020</td>\n",
       "      <td>0.092</td>\n",
       "      <td>14.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>0.981</td>\n",
       "      <td>-1921.548</td>\n",
       "      <td>0.063</td>\n",
       "      <td>12.457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>0.987</td>\n",
       "      <td>-1174.147</td>\n",
       "      <td>0.041</td>\n",
       "      <td>11.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0.991</td>\n",
       "      <td>-1546.413</td>\n",
       "      <td>0.028</td>\n",
       "      <td>12.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>0.995</td>\n",
       "      <td>-2526.105</td>\n",
       "      <td>0.015</td>\n",
       "      <td>17.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>0.998</td>\n",
       "      <td>-3144.763</td>\n",
       "      <td>0.007</td>\n",
       "      <td>17.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13</td>\n",
       "      <td>0.999</td>\n",
       "      <td>-2861.907</td>\n",
       "      <td>0.003</td>\n",
       "      <td>17.294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-2635.187</td>\n",
       "      <td>0.001</td>\n",
       "      <td>17.197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-2249.845</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14.827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-1963.868</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-1436.221</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-2927.231</td>\n",
       "      <td>0.000</td>\n",
       "      <td>15.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>19</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-1868.923</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-2683.361</td>\n",
       "      <td>0.000</td>\n",
       "      <td>17.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>21</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-2072.729</td>\n",
       "      <td>0.000</td>\n",
       "      <td>13.577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>22</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-2494.033</td>\n",
       "      <td>0.000</td>\n",
       "      <td>15.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>23</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-2684.221</td>\n",
       "      <td>0.000</td>\n",
       "      <td>16.498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>24</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-2887.095</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18.037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    depth  train r    test r  train MSE  test MSE\n",
       "0       3    0.672  -630.324      3.495     6.211\n",
       "1       4    0.839 -1041.193      1.358     6.268\n",
       "2       5    0.937  -326.621      0.208     4.751\n",
       "3       6    0.956  -861.562      0.145     9.289\n",
       "4       7    0.972 -1746.020      0.092    14.765\n",
       "5       8    0.981 -1921.548      0.063    12.457\n",
       "6       9    0.987 -1174.147      0.041    11.312\n",
       "7      10    0.991 -1546.413      0.028    12.724\n",
       "8      11    0.995 -2526.105      0.015    17.000\n",
       "9      12    0.998 -3144.763      0.007    17.345\n",
       "10     13    0.999 -2861.907      0.003    17.294\n",
       "11     14    1.000 -2635.187      0.001    17.197\n",
       "12     15    1.000 -2249.845      0.000    14.827\n",
       "13     16    1.000 -1963.868      0.000    12.543\n",
       "14     17    1.000 -1436.221      0.000    11.324\n",
       "15     18    1.000 -2927.231      0.000    15.976\n",
       "16     19    1.000 -1868.923      0.000    12.713\n",
       "17     20    1.000 -2683.361      0.000    17.375\n",
       "18     21    1.000 -2072.729      0.000    13.577\n",
       "19     22    1.000 -2494.033      0.000    15.763\n",
       "20     23    1.000 -2684.221      0.000    16.498\n",
       "21     24    1.000 -2887.095      0.000    18.037"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_r = []\n",
    "test_r = []\n",
    "train_MSE = []\n",
    "test_MSE = []\n",
    "for depth in tqdm(param_dist['max_depth']):\n",
    "    clf = MultiOutputRegressor(GradientBoostingRegressor(random_state=0, max_depth=depth))\n",
    "    clf.fit(norm_Xtrain, ytrain)\n",
    "    train_r.append(round(clf.score(norm_Xtrain, ytrain),3))\n",
    "    test_r.append(round(clf.score(norm_Xtest, ytest),3))\n",
    "    train_MSE.append(round(mean_squared_error(ytrain, clf.predict(norm_Xtrain)),3))\n",
    "    test_MSE.append(round(mean_squared_error(ytest, clf.predict(norm_Xtest)),3))\n",
    "\n",
    "model_comparisons = pd.DataFrame({\n",
    "    \"depth\": param_dist['max_depth'],\n",
    "    \"train r\": train_r,\n",
    "    \"test r\": test_r,\n",
    "    \"train MSE\": train_MSE,\n",
    "    \"test MSE\": test_MSE})\n",
    "model_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best depth: 24\n"
     ]
    }
   ],
   "source": [
    "print(\"best depth:\",param_dist['max_depth'][np.argmin(test_MSE)])\n",
    "depth = param_dist['max_depth'][np.argmin(test_MSE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [06:46<00:00, 25.42s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>train r</th>\n",
       "      <th>test r</th>\n",
       "      <th>train MSE</th>\n",
       "      <th>test MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.937</td>\n",
       "      <td>-326.621</td>\n",
       "      <td>0.208</td>\n",
       "      <td>4.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125</td>\n",
       "      <td>0.943</td>\n",
       "      <td>-327.015</td>\n",
       "      <td>0.188</td>\n",
       "      <td>4.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150</td>\n",
       "      <td>0.949</td>\n",
       "      <td>-327.516</td>\n",
       "      <td>0.166</td>\n",
       "      <td>4.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>175</td>\n",
       "      <td>0.954</td>\n",
       "      <td>-327.607</td>\n",
       "      <td>0.150</td>\n",
       "      <td>4.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.957</td>\n",
       "      <td>-327.694</td>\n",
       "      <td>0.139</td>\n",
       "      <td>4.823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>225</td>\n",
       "      <td>0.962</td>\n",
       "      <td>-327.697</td>\n",
       "      <td>0.124</td>\n",
       "      <td>4.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>250</td>\n",
       "      <td>0.964</td>\n",
       "      <td>-327.736</td>\n",
       "      <td>0.118</td>\n",
       "      <td>4.848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>275</td>\n",
       "      <td>0.966</td>\n",
       "      <td>-327.744</td>\n",
       "      <td>0.109</td>\n",
       "      <td>4.869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>300</td>\n",
       "      <td>0.970</td>\n",
       "      <td>-327.741</td>\n",
       "      <td>0.099</td>\n",
       "      <td>4.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>325</td>\n",
       "      <td>0.971</td>\n",
       "      <td>-327.757</td>\n",
       "      <td>0.094</td>\n",
       "      <td>4.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>350</td>\n",
       "      <td>0.973</td>\n",
       "      <td>-328.035</td>\n",
       "      <td>0.089</td>\n",
       "      <td>4.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>375</td>\n",
       "      <td>0.974</td>\n",
       "      <td>-328.044</td>\n",
       "      <td>0.083</td>\n",
       "      <td>4.907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>400</td>\n",
       "      <td>0.976</td>\n",
       "      <td>-328.079</td>\n",
       "      <td>0.080</td>\n",
       "      <td>4.911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>425</td>\n",
       "      <td>0.976</td>\n",
       "      <td>-328.096</td>\n",
       "      <td>0.077</td>\n",
       "      <td>4.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>450</td>\n",
       "      <td>0.977</td>\n",
       "      <td>-328.103</td>\n",
       "      <td>0.073</td>\n",
       "      <td>4.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>475</td>\n",
       "      <td>0.978</td>\n",
       "      <td>-328.108</td>\n",
       "      <td>0.071</td>\n",
       "      <td>4.929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    depth  train r   test r  train MSE  test MSE\n",
       "0     100    0.937 -326.621      0.208     4.751\n",
       "1     125    0.943 -327.015      0.188     4.775\n",
       "2     150    0.949 -327.516      0.166     4.788\n",
       "3     175    0.954 -327.607      0.150     4.815\n",
       "4     200    0.957 -327.694      0.139     4.823\n",
       "5     225    0.962 -327.697      0.124     4.838\n",
       "6     250    0.964 -327.736      0.118     4.848\n",
       "7     275    0.966 -327.744      0.109     4.869\n",
       "8     300    0.970 -327.741      0.099     4.885\n",
       "9     325    0.971 -327.757      0.094     4.896\n",
       "10    350    0.973 -328.035      0.089     4.898\n",
       "11    375    0.974 -328.044      0.083     4.907\n",
       "12    400    0.976 -328.079      0.080     4.911\n",
       "13    425    0.976 -328.096      0.077     4.924\n",
       "14    450    0.977 -328.103      0.073     4.928\n",
       "15    475    0.978 -328.108      0.071     4.929"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_r = []\n",
    "test_r = []\n",
    "train_MSE = []\n",
    "test_MSE = []\n",
    "for n in tqdm(param_dist['n_estimators']):\n",
    "    clf = MultiOutputRegressor(GradientBoostingRegressor(n_estimators=n, random_state=0, max_depth=depth))\n",
    "    clf.fit(norm_Xtrain, ytrain)\n",
    "    train_r.append(round(clf.score(norm_Xtrain, ytrain),3))\n",
    "    test_r.append(round(clf.score(norm_Xtest, ytest),3))\n",
    "    train_MSE.append(round(mean_squared_error(ytrain, clf.predict(norm_Xtrain)),3))\n",
    "    test_MSE.append(round(mean_squared_error(ytest, clf.predict(norm_Xtest)),3))\n",
    "\n",
    "model_comparisons = pd.DataFrame({\n",
    "    \"depth\": param_dist['n_estimators'],\n",
    "    \"train r\": train_r,\n",
    "    \"test r\": test_r,\n",
    "    \"train MSE\": train_MSE,\n",
    "    \"test MSE\": test_MSE})\n",
    "model_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best n-estimators: 100\n"
     ]
    }
   ],
   "source": [
    "print(\"best n-estimators:\",param_dist['n_estimators'][np.argmin(test_MSE)])\n",
    "n = param_dist['n_estimators'][np.argmin(test_MSE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:12<00:00,  4.14s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>train r</th>\n",
       "      <th>test r</th>\n",
       "      <th>train MSE</th>\n",
       "      <th>test MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auto</td>\n",
       "      <td>0.937</td>\n",
       "      <td>-326.621</td>\n",
       "      <td>0.208</td>\n",
       "      <td>4.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.796</td>\n",
       "      <td>-100.814</td>\n",
       "      <td>1.922</td>\n",
       "      <td>1.515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log2</td>\n",
       "      <td>0.734</td>\n",
       "      <td>-52.436</td>\n",
       "      <td>2.802</td>\n",
       "      <td>1.104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  depth  train r   test r  train MSE  test MSE\n",
       "0  auto    0.937 -326.621      0.208     4.751\n",
       "1  sqrt    0.796 -100.814      1.922     1.515\n",
       "2  log2    0.734  -52.436      2.802     1.104"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_r = []\n",
    "test_r = []\n",
    "train_MSE = []\n",
    "test_MSE = []\n",
    "for feature in tqdm(param_dist['max_features']):\n",
    "    clf = MultiOutputRegressor(GradientBoostingRegressor(max_features=feature,n_estimators=n, random_state=0, max_depth=depth))\n",
    "    clf.fit(norm_Xtrain, ytrain)\n",
    "    train_r.append(round(clf.score(norm_Xtrain, ytrain),3))\n",
    "    test_r.append(round(clf.score(norm_Xtest, ytest),3))\n",
    "    train_MSE.append(round(mean_squared_error(ytrain, clf.predict(norm_Xtrain)),3))\n",
    "    test_MSE.append(round(mean_squared_error(ytest, clf.predict(norm_Xtest)),3))\n",
    "\n",
    "model_comparisons = pd.DataFrame({\n",
    "    \"depth\": param_dist['max_features'],\n",
    "    \"train r\": train_r,\n",
    "    \"test r\": test_r,\n",
    "    \"train MSE\": train_MSE,\n",
    "    \"test MSE\": test_MSE})\n",
    "model_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boosting_mdl = GradientBoostingRegressor(max_features='log2',n_estimators=100, random_state=0, max_depth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {'criterion': ['mse'],#'absolute_error', \n",
    "                            #'squared_error'],\n",
    "              'max_depth': [i for i in range(3,25)],\n",
    "              'n_estimators': [i for i in range(100, 500, 25)],\n",
    "              'max_features': ['auto', 'sqrt', 'log2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [02:54<00:00,  7.92s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>train r</th>\n",
       "      <th>test r</th>\n",
       "      <th>train MSE</th>\n",
       "      <th>test MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.528</td>\n",
       "      <td>-813.286</td>\n",
       "      <td>5.033</td>\n",
       "      <td>7.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.619</td>\n",
       "      <td>-743.150</td>\n",
       "      <td>3.867</td>\n",
       "      <td>6.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.680</td>\n",
       "      <td>-655.083</td>\n",
       "      <td>3.170</td>\n",
       "      <td>6.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.742</td>\n",
       "      <td>-565.468</td>\n",
       "      <td>2.461</td>\n",
       "      <td>6.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.778</td>\n",
       "      <td>-722.546</td>\n",
       "      <td>2.130</td>\n",
       "      <td>7.257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>0.796</td>\n",
       "      <td>-716.148</td>\n",
       "      <td>2.053</td>\n",
       "      <td>7.231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>0.814</td>\n",
       "      <td>-723.834</td>\n",
       "      <td>1.980</td>\n",
       "      <td>7.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0.828</td>\n",
       "      <td>-786.192</td>\n",
       "      <td>1.935</td>\n",
       "      <td>7.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>0.840</td>\n",
       "      <td>-786.195</td>\n",
       "      <td>1.901</td>\n",
       "      <td>7.543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>0.848</td>\n",
       "      <td>-786.206</td>\n",
       "      <td>1.873</td>\n",
       "      <td>7.551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13</td>\n",
       "      <td>0.855</td>\n",
       "      <td>-786.208</td>\n",
       "      <td>1.853</td>\n",
       "      <td>7.567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>0.859</td>\n",
       "      <td>-786.207</td>\n",
       "      <td>1.838</td>\n",
       "      <td>7.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15</td>\n",
       "      <td>0.862</td>\n",
       "      <td>-786.212</td>\n",
       "      <td>1.827</td>\n",
       "      <td>7.581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16</td>\n",
       "      <td>0.865</td>\n",
       "      <td>-786.209</td>\n",
       "      <td>1.820</td>\n",
       "      <td>7.569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17</td>\n",
       "      <td>0.866</td>\n",
       "      <td>-786.210</td>\n",
       "      <td>1.815</td>\n",
       "      <td>7.574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18</td>\n",
       "      <td>0.868</td>\n",
       "      <td>-786.211</td>\n",
       "      <td>1.811</td>\n",
       "      <td>7.578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>19</td>\n",
       "      <td>0.868</td>\n",
       "      <td>-786.211</td>\n",
       "      <td>1.808</td>\n",
       "      <td>7.578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20</td>\n",
       "      <td>0.869</td>\n",
       "      <td>-786.210</td>\n",
       "      <td>1.806</td>\n",
       "      <td>7.573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>21</td>\n",
       "      <td>0.870</td>\n",
       "      <td>-786.210</td>\n",
       "      <td>1.805</td>\n",
       "      <td>7.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>22</td>\n",
       "      <td>0.870</td>\n",
       "      <td>-786.211</td>\n",
       "      <td>1.805</td>\n",
       "      <td>7.577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>23</td>\n",
       "      <td>0.870</td>\n",
       "      <td>-786.211</td>\n",
       "      <td>1.804</td>\n",
       "      <td>7.579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>24</td>\n",
       "      <td>0.870</td>\n",
       "      <td>-786.211</td>\n",
       "      <td>1.803</td>\n",
       "      <td>7.579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    depth  train r   test r  train MSE  test MSE\n",
       "0       3    0.528 -813.286      5.033     7.003\n",
       "1       4    0.619 -743.150      3.867     6.455\n",
       "2       5    0.680 -655.083      3.170     6.782\n",
       "3       6    0.742 -565.468      2.461     6.324\n",
       "4       7    0.778 -722.546      2.130     7.257\n",
       "5       8    0.796 -716.148      2.053     7.231\n",
       "6       9    0.814 -723.834      1.980     7.284\n",
       "7      10    0.828 -786.192      1.935     7.538\n",
       "8      11    0.840 -786.195      1.901     7.543\n",
       "9      12    0.848 -786.206      1.873     7.551\n",
       "10     13    0.855 -786.208      1.853     7.567\n",
       "11     14    0.859 -786.207      1.838     7.562\n",
       "12     15    0.862 -786.212      1.827     7.581\n",
       "13     16    0.865 -786.209      1.820     7.569\n",
       "14     17    0.866 -786.210      1.815     7.574\n",
       "15     18    0.868 -786.211      1.811     7.578\n",
       "16     19    0.868 -786.211      1.808     7.578\n",
       "17     20    0.869 -786.210      1.806     7.573\n",
       "18     21    0.870 -786.210      1.805     7.576\n",
       "19     22    0.870 -786.211      1.805     7.577\n",
       "20     23    0.870 -786.211      1.804     7.579\n",
       "21     24    0.870 -786.211      1.803     7.579"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_r = []\n",
    "test_r = []\n",
    "train_MSE = []\n",
    "test_MSE = []\n",
    "for depth in tqdm(param_dist['max_depth']):\n",
    "    clf = MultiOutputRegressor(RandomForestRegressor(random_state=0, max_depth=depth))\n",
    "    clf.fit(norm_Xtrain, ytrain)\n",
    "    train_r.append(round(clf.score(norm_Xtrain, ytrain),3))\n",
    "    test_r.append(round(clf.score(norm_Xtest, ytest),3))\n",
    "    train_MSE.append(round(mean_squared_error(ytrain, clf.predict(norm_Xtrain)),3))\n",
    "    test_MSE.append(round(mean_squared_error(ytest, clf.predict(norm_Xtest)),3))\n",
    "\n",
    "model_comparisons = pd.DataFrame({\n",
    "    \"depth\": param_dist['max_depth'],\n",
    "    \"train r\": train_r,\n",
    "    \"test r\": test_r,\n",
    "    \"train MSE\": train_MSE,\n",
    "    \"test MSE\": test_MSE})\n",
    "model_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best depth: 6\n"
     ]
    }
   ],
   "source": [
    "print(\"best depth:\",param_dist['max_depth'][np.argmin(test_MSE)])\n",
    "depth = param_dist['max_depth'][np.argmin(test_MSE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [04:30<00:00, 16.88s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>train r</th>\n",
       "      <th>test r</th>\n",
       "      <th>train MSE</th>\n",
       "      <th>test MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.742</td>\n",
       "      <td>-565.468</td>\n",
       "      <td>2.461</td>\n",
       "      <td>6.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125</td>\n",
       "      <td>0.741</td>\n",
       "      <td>-564.700</td>\n",
       "      <td>2.470</td>\n",
       "      <td>6.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150</td>\n",
       "      <td>0.744</td>\n",
       "      <td>-643.985</td>\n",
       "      <td>2.436</td>\n",
       "      <td>6.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>175</td>\n",
       "      <td>0.752</td>\n",
       "      <td>-813.013</td>\n",
       "      <td>2.314</td>\n",
       "      <td>8.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.751</td>\n",
       "      <td>-847.287</td>\n",
       "      <td>2.328</td>\n",
       "      <td>8.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>225</td>\n",
       "      <td>0.752</td>\n",
       "      <td>-842.138</td>\n",
       "      <td>2.309</td>\n",
       "      <td>8.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>250</td>\n",
       "      <td>0.748</td>\n",
       "      <td>-894.675</td>\n",
       "      <td>2.372</td>\n",
       "      <td>8.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>275</td>\n",
       "      <td>0.753</td>\n",
       "      <td>-912.782</td>\n",
       "      <td>2.304</td>\n",
       "      <td>8.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>300</td>\n",
       "      <td>0.754</td>\n",
       "      <td>-904.247</td>\n",
       "      <td>2.277</td>\n",
       "      <td>8.617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>325</td>\n",
       "      <td>0.754</td>\n",
       "      <td>-952.740</td>\n",
       "      <td>2.283</td>\n",
       "      <td>8.877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>350</td>\n",
       "      <td>0.756</td>\n",
       "      <td>-984.495</td>\n",
       "      <td>2.253</td>\n",
       "      <td>9.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>375</td>\n",
       "      <td>0.753</td>\n",
       "      <td>-952.237</td>\n",
       "      <td>2.292</td>\n",
       "      <td>8.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>400</td>\n",
       "      <td>0.755</td>\n",
       "      <td>-942.494</td>\n",
       "      <td>2.273</td>\n",
       "      <td>8.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>425</td>\n",
       "      <td>0.755</td>\n",
       "      <td>-944.051</td>\n",
       "      <td>2.265</td>\n",
       "      <td>8.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>450</td>\n",
       "      <td>0.756</td>\n",
       "      <td>-984.758</td>\n",
       "      <td>2.250</td>\n",
       "      <td>8.874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>475</td>\n",
       "      <td>0.758</td>\n",
       "      <td>-998.596</td>\n",
       "      <td>2.224</td>\n",
       "      <td>8.976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    depth  train r   test r  train MSE  test MSE\n",
       "0     100    0.742 -565.468      2.461     6.324\n",
       "1     125    0.741 -564.700      2.470     6.302\n",
       "2     150    0.744 -643.985      2.436     6.729\n",
       "3     175    0.752 -813.013      2.314     8.042\n",
       "4     200    0.751 -847.287      2.328     8.240\n",
       "5     225    0.752 -842.138      2.309     8.255\n",
       "6     250    0.748 -894.675      2.372     8.550\n",
       "7     275    0.753 -912.782      2.304     8.693\n",
       "8     300    0.754 -904.247      2.277     8.617\n",
       "9     325    0.754 -952.740      2.283     8.877\n",
       "10    350    0.756 -984.495      2.253     9.059\n",
       "11    375    0.753 -952.237      2.292     8.811\n",
       "12    400    0.755 -942.494      2.273     8.630\n",
       "13    425    0.755 -944.051      2.265     8.627\n",
       "14    450    0.756 -984.758      2.250     8.874\n",
       "15    475    0.758 -998.596      2.224     8.976"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_r = []\n",
    "test_r = []\n",
    "train_MSE = []\n",
    "test_MSE = []\n",
    "for n in tqdm(param_dist['n_estimators']):\n",
    "    clf = MultiOutputRegressor(RandomForestRegressor(n_estimators=n, random_state=0, max_depth=depth))\n",
    "    clf.fit(norm_Xtrain, ytrain)\n",
    "    train_r.append(round(clf.score(norm_Xtrain, ytrain),3))\n",
    "    test_r.append(round(clf.score(norm_Xtest, ytest),3))\n",
    "    train_MSE.append(round(mean_squared_error(ytrain, clf.predict(norm_Xtrain)),3))\n",
    "    test_MSE.append(round(mean_squared_error(ytest, clf.predict(norm_Xtest)),3))\n",
    "\n",
    "model_comparisons = pd.DataFrame({\n",
    "    \"depth\": param_dist['n_estimators'],\n",
    "    \"train r\": train_r,\n",
    "    \"test r\": test_r,\n",
    "    \"train MSE\": train_MSE,\n",
    "    \"test MSE\": test_MSE})\n",
    "model_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best n-estimators: 125\n"
     ]
    }
   ],
   "source": [
    "print(\"best n-estimators:\",param_dist['n_estimators'][np.argmin(test_MSE)])\n",
    "n = param_dist['n_estimators'][np.argmin(test_MSE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:11<00:00,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best features: log2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>train r</th>\n",
       "      <th>test r</th>\n",
       "      <th>train MSE</th>\n",
       "      <th>test MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auto</td>\n",
       "      <td>0.741</td>\n",
       "      <td>-564.700</td>\n",
       "      <td>2.470</td>\n",
       "      <td>6.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.513</td>\n",
       "      <td>-16.016</td>\n",
       "      <td>5.577</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log2</td>\n",
       "      <td>0.484</td>\n",
       "      <td>-20.300</td>\n",
       "      <td>5.949</td>\n",
       "      <td>0.954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  depth  train r   test r  train MSE  test MSE\n",
       "0  auto    0.741 -564.700      2.470     6.302\n",
       "1  sqrt    0.513  -16.016      5.577     0.995\n",
       "2  log2    0.484  -20.300      5.949     0.954"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_r = []\n",
    "test_r = []\n",
    "train_MSE = []\n",
    "test_MSE = []\n",
    "for feature in tqdm(param_dist['max_features']):\n",
    "    clf = MultiOutputRegressor(RandomForestRegressor(max_features=feature,n_estimators=n, random_state=0, max_depth=depth))\n",
    "    clf.fit(norm_Xtrain, ytrain)\n",
    "    train_r.append(round(clf.score(norm_Xtrain, ytrain),3))\n",
    "    test_r.append(round(clf.score(norm_Xtest, ytest),3))\n",
    "    train_MSE.append(round(mean_squared_error(ytrain, clf.predict(norm_Xtrain)),3))\n",
    "    test_MSE.append(round(mean_squared_error(ytest, clf.predict(norm_Xtest)),3))\n",
    "\n",
    "model_comparisons = pd.DataFrame({\n",
    "    \"depth\": param_dist['max_features'],\n",
    "    \"train r\": train_r,\n",
    "    \"test r\": test_r,\n",
    "    \"train MSE\": train_MSE,\n",
    "    \"test MSE\": test_MSE})\n",
    "print(\"best features:\",param_dist['max_features'][np.argmin(test_MSE)])\n",
    "feature = param_dist['max_features'][np.argmin(test_MSE)]\n",
    "model_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [05:27<00:00, 163.92s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>train r</th>\n",
       "      <th>test r</th>\n",
       "      <th>train MSE</th>\n",
       "      <th>test MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mae</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.269</td>\n",
       "      <td>8.212</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mse</td>\n",
       "      <td>0.484</td>\n",
       "      <td>-20.300</td>\n",
       "      <td>5.949</td>\n",
       "      <td>0.954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion  train r  test r  train MSE  test MSE\n",
       "0       mae    0.288   0.269      8.212     0.928\n",
       "1       mse    0.484 -20.300      5.949     0.954"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_r = []\n",
    "test_r = []\n",
    "train_MSE = []\n",
    "test_MSE = []\n",
    "param_dist['criterion']=['mae','mse']\n",
    "for crit in tqdm(param_dist['criterion']):\n",
    "    clf = MultiOutputRegressor(RandomForestRegressor(criterion=crit,max_features=feature,n_estimators=n, random_state=0, max_depth=depth))\n",
    "    clf.fit(norm_Xtrain, ytrain)\n",
    "    train_r.append(round(clf.score(norm_Xtrain, ytrain),3))\n",
    "    test_r.append(round(clf.score(norm_Xtest, ytest),3))\n",
    "    train_MSE.append(round(mean_squared_error(ytrain, clf.predict(norm_Xtrain)),3))\n",
    "    test_MSE.append(round(mean_squared_error(ytest, clf.predict(norm_Xtest)),3))\n",
    "\n",
    "model_comparisons = pd.DataFrame({\n",
    "    \"criterion\": ['mae','mse'],\n",
    "    \"train r\": train_r,\n",
    "    \"test r\": test_r,\n",
    "    \"train MSE\": train_MSE,\n",
    "    \"test MSE\": test_MSE})\n",
    "model_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(criterion='mae',max_features='log2',n_estimators=125, random_state=0, max_depth=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:01<00:00, 10.68it/s]\n",
      " 13%|███████████                                                                        | 2/15 [00:00<00:01, 10.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_1 best value: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:01<00:00, 10.74it/s]\n",
      "  7%|█████▌                                                                             | 1/15 [00:00<00:01,  9.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_2 best value: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:01<00:00, 10.71it/s]\n",
      " 13%|███████████                                                                        | 2/15 [00:00<00:01, 10.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_1 best value: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:01<00:00, 10.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_2 best value: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vals = [10000, 100,1000,10,1,0.01,1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10]\n",
    "params = ['alpha_1','alpha_2','lambda_1','lambda_2']\n",
    "for param in params:\n",
    "    train_r = []\n",
    "    test_r = []\n",
    "    train_MSE = []\n",
    "    test_MSE = []\n",
    "    for val in tqdm(vals):\n",
    "        input_params = {param:val}\n",
    "        clf = MultiOutputRegressor(linear_model.BayesianRidge(**input_params))\n",
    "        clf.fit(norm_Xtrain, ytrain)\n",
    "        train_r.append(round(clf.score(norm_Xtrain, ytrain),3))\n",
    "        test_r.append(round(clf.score(norm_Xtest, ytest),3))\n",
    "        train_MSE.append(round(mean_squared_error(ytrain, clf.predict(norm_Xtrain)),3))\n",
    "        test_MSE.append(round(mean_squared_error(ytest, clf.predict(norm_Xtest)),3))\n",
    "    print(param+\" best value:\", vals[np.argmin(test_MSE)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = linear_model.BayesianRidge(alpha_1=10000, alpha_2=10000, lambda_1=10, lambda_2=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 67%|████████████████████████████████████████████████████████                            | 2/3 [00:08<00:04,  4.73s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:59<00:00, 19.70s/it]\n",
      "  0%|                                                                                           | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "booster best value: gblinear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "  6%|█████▏                                                                             | 1/16 [00:04<01:10,  4.67s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 12%|██████████▍                                                                        | 2/16 [00:15<01:31,  6.52s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 19%|███████████████▌                                                                   | 3/16 [00:25<01:36,  7.42s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 25%|████████████████████▊                                                              | 4/16 [00:36<01:44,  8.68s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 31%|█████████████████████████▉                                                         | 5/16 [00:45<01:35,  8.72s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 38%|███████████████████████████████▏                                                   | 6/16 [00:49<01:12,  7.28s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 44%|████████████████████████████████████▎                                              | 7/16 [00:53<00:57,  6.38s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 50%|█████████████████████████████████████████▌                                         | 8/16 [00:58<00:47,  5.91s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|██████████████████████████████████████████████▋                                    | 9/16 [01:03<00:39,  5.67s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 62%|███████████████████████████████████████████████████▎                              | 10/16 [01:09<00:33,  5.62s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 69%|████████████████████████████████████████████████████████▍                         | 11/16 [01:15<00:28,  5.71s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 75%|█████████████████████████████████████████████████████████████▌                    | 12/16 [01:21<00:23,  5.89s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 81%|██████████████████████████████████████████████████████████████████▋               | 13/16 [01:28<00:18,  6.15s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 88%|███████████████████████████████████████████████████████████████████████▊          | 14/16 [01:35<00:12,  6.47s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 94%|████████████████████████████████████████████████████████████████████████████▉     | 15/16 [01:42<00:06,  6.83s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [01:50<00:00,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators best value: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "params = {'booster': ['gbtree', 'gblinear', 'dart'], 'n_estimators': [i for i in range(100, 500, 25)]}\n",
    "tree_params = {'max_depth':[i for i in range(3,25)]}\n",
    "for param in params:\n",
    "    train_r = []\n",
    "    test_r = []\n",
    "    train_MSE = []\n",
    "    test_MSE = []\n",
    "    for val in tqdm(params[param]):\n",
    "        input_params = {param:val}\n",
    "        clf = MultiOutputRegressor(xgb.XGBRegressor(**input_params))\n",
    "        clf.fit(norm_Xtrain, ytrain)\n",
    "        train_r.append(round(clf.score(norm_Xtrain, ytrain),3))\n",
    "        test_r.append(round(clf.score(norm_Xtest, ytest),3))\n",
    "        train_MSE.append(round(mean_squared_error(ytrain, clf.predict(norm_Xtrain)),3))\n",
    "        test_MSE.append(round(mean_squared_error(ytest, clf.predict(norm_Xtest)),3))\n",
    "    print(param+\" best value:\", params[param][np.argmin(test_MSE)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_mdl = xgb.XGBRegressor(booster='gblinear',n_estimators=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'criterion':['mse', 'mae', 'friedman_mse'],\n",
    "         'max_features':['auto', 'sqrt', 'log2'],\n",
    "         'splitter':['best', 'random']}\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|████████████████████████████                                                        | 1/3 [00:00<00:00,  5.51it/s]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████                            | 2/3 [01:08<00:20, 20.51s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:08<00:00, 22.77s/it]\u001b[A\n",
      " 33%|████████████████████████████                                                        | 1/3 [01:08<02:16, 68.30s/it]\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|████████████████████████████                                                        | 1/3 [00:00<00:00,  5.78it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  9.25it/s]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████                            | 2/3 [01:08<00:47, 47.91s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:00<00:00,  5.52it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  7.05it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:08<00:00, 22.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'mse', 'max_features': 'auto', 'splitter': 'random'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for param in tqdm(params):\n",
    "    train_r = []\n",
    "    test_r = []\n",
    "    train_MSE = []\n",
    "    test_MSE = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        clf = MultiOutputRegressor(DecisionTreeRegressor(**test_params))\n",
    "        clf.fit(norm_Xtrain, ytrain)\n",
    "        train_r.append(round(clf.score(norm_Xtrain, ytrain),3))\n",
    "        test_r.append(round(clf.score(norm_Xtest, ytest),3))\n",
    "        train_MSE.append(round(mean_squared_error(ytrain, clf.predict(norm_Xtrain)),3))\n",
    "        test_MSE.append(round(mean_squared_error(ytest, clf.predict(norm_Xtest)),3))\n",
    "    best_params[param] = params[param][np.argmin(test_MSE)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'base_estimator':[None, DecisionTreeRegressor(criterion='mse', max_features='auto', splitter='random')],\n",
    "          'n_estimators':[i for i in range(50, 550, 50)],\n",
    "          'learning_rate':[1*((10)**(i)) for i in range(-4,3,1)],\n",
    "          'loss':['linear', 'square', 'exponential']\n",
    "         }\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:02<00:02,  2.42s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:06<00:00,  3.13s/it]\u001b[A\n",
      " 25%|█████████████████████                                                               | 1/4 [00:06<00:18,  6.27s/it]\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|████████▎                                                                          | 1/10 [00:04<00:43,  4.87s/it]\u001b[A\n",
      " 20%|████████████████▌                                                                  | 2/10 [00:14<00:51,  6.40s/it]\u001b[A\n",
      " 30%|████████████████████████▉                                                          | 3/10 [00:29<01:01,  8.74s/it]\u001b[A\n",
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:47<01:10, 11.67s/it]\u001b[A\n",
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [01:09<01:13, 14.76s/it]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [01:36<01:13, 18.30s/it]\u001b[A\n",
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [02:06<01:06, 22.04s/it]\u001b[A\n",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [02:42<00:52, 26.04s/it]\u001b[A\n",
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [03:22<00:30, 30.29s/it]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [04:05<00:00, 24.60s/it]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 2/4 [04:12<02:36, 78.18s/it]\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|████████████                                                                        | 1/7 [00:05<00:34,  5.78s/it]\u001b[A\n",
      " 29%|████████████████████████                                                            | 2/7 [00:11<00:28,  5.76s/it]\u001b[A\n",
      " 43%|████████████████████████████████████                                                | 3/7 [00:17<00:22,  5.73s/it]\u001b[A\n",
      " 57%|████████████████████████████████████████████████                                    | 4/7 [00:22<00:16,  5.64s/it]\u001b[A\n",
      " 71%|████████████████████████████████████████████████████████████                        | 5/7 [00:27<00:10,  5.32s/it]\u001b[A\n",
      " 86%|████████████████████████████████████████████████████████████████████████            | 6/7 [00:27<00:03,  3.93s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:28<00:00,  4.01s/it]\u001b[A\n",
      " 75%|███████████████████████████████████████████████████████████████                     | 3/4 [04:40<01:03, 63.15s/it]\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|████████████████████████████                                                        | 1/3 [00:04<00:09,  4.79s/it]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████                            | 2/3 [00:08<00:04,  4.60s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.86s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [04:54<00:00, 73.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_estimator': DecisionTreeRegressor(max_features='auto', splitter='random'), 'n_estimators': 50, 'learning_rate': 1, 'loss': 'square'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for param in tqdm(params):\n",
    "    train_r = []\n",
    "    test_r = []\n",
    "    train_MSE = []\n",
    "    test_MSE = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        clf = MultiOutputRegressor(AdaBoostRegressor(**test_params))\n",
    "        clf.fit(norm_Xtrain, ytrain)\n",
    "        train_r.append(round(clf.score(norm_Xtrain, ytrain),3))\n",
    "        test_r.append(round(clf.score(norm_Xtest, ytest),3))\n",
    "        train_MSE.append(round(mean_squared_error(ytrain, clf.predict(norm_Xtrain)),3))\n",
    "        test_MSE.append(round(mean_squared_error(ytest, clf.predict(norm_Xtest)),3))\n",
    "    best_params[param] = params[param][np.argmin(test_MSE)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_features='auto', splitter='random'), n_estimators=50, learning_rate=1, loss='square')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

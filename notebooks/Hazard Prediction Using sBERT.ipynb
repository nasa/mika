{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.style\n",
    "matplotlib.style.use(\"seaborn\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "sns.color_palette(\"hls\", 17)\n",
    "import scipy.stats as st\n",
    "import math\n",
    "\n",
    "from pingouin import rcorr\n",
    "import pingouin as pg\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputClassifier, ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifierCV, RidgeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, cross_validate, cross_val_score, learning_curve\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, precision_score, recall_score, plot_roc_curve, roc_curve, auc, roc_auc_score,precision_recall_curve, hamming_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn import feature_selection #import chi2\n",
    "\n",
    "import gensim\n",
    "import gensim.downloader as gensim_api\n",
    "## for deep learning\n",
    "from tensorflow.keras import models, layers, preprocessing as kprocessing\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from sys import platform\n",
    "if platform == \"darwin\":\n",
    "    sys.path.append(os.path.dirname(os.path.realpath(__file__)) + \"/..\")\n",
    "    smart_nlp_path = ''\n",
    "elif platform == \"win32\":\n",
    "    sys.path.append('../')\n",
    "    smart_nlp_path = os.getcwd()\n",
    "    smart_nlp_path = \"\\\\\".join([smart_nlp_path.split(\"\\\\\")[i] for i in range(0,len(smart_nlp_path.split(\"\\\\\"))-1)]+[\"/\"])\n",
    "\n",
    "from module.trend_analysis_functions import *\n",
    "from module.topic_model_plus_class import Topic_Model_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(os.path.join(os.path.dirname(os.getcwd()),'data','ICS_predictive_sitreps_test.csv')).drop([\"Unnamed: 0\"], axis=1)\n",
    "train_data = pd.read_csv(os.path.join(os.path.dirname(os.getcwd()),'data','ICS_predictive_sitreps_train.csv')).drop([\"Unnamed: 0\"], axis=1)\n",
    "val_data = pd.read_csv(os.path.join(os.path.dirname(os.getcwd()),'data','ICS_predictive_sitreps_val.csv')).drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [\"TOTAL_PERSONNEL\", \"TOTAL_AERIAL\", \"PCT_CONTAINED_COMPLETED\",\n",
    "              \"ACRES\",  \"WF_FSR\", \"INJURIES\", \"FATALITIES\", \"EST_IM_COST_TO_DATE\", \"STR_DAMAGED\",\n",
    "              \"STR_DESTROYED\", \"NEW_ACRES\", \"EVACUATION_IN_PROGRESS\", \n",
    "              \"NUM_REPORTS\", \"DAYS_BURING\", 'Combined_Text', 'Incident_region_AICC', \n",
    "              'Incident_region_CA', 'Incident_region_EACC','Incident_region_GBCC', 'Incident_region_HICC', \n",
    "              'Incident_region_NRCC','Incident_region_NWCC', 'Incident_region_RMCC', 'Incident_region_SACC',\n",
    "              'Incident_region_SWCC', 'INC_MGMT_ORG_ABBREV_1', 'INC_MGMT_ORG_ABBREV_2','INC_MGMT_ORG_ABBREV_3', \n",
    "              'INC_MGMT_ORG_ABBREV_4','INC_MGMT_ORG_ABBREV_5', 'INC_MGMT_ORG_ABBREV_B','INC_MGMT_ORG_ABBREV_C', \n",
    "              'INC_MGMT_ORG_ABBREV_D','INC_MGMT_ORG_ABBREV_E', 'INC_MGMT_ORG_ABBREV_F']\n",
    "targets = [\"Traffic\",\"Command_Transitions\",\"Evacuations\", \"Inaccurate_Mapping\", \"Aerial_Grounding\", \n",
    "           \"Resource_Issues\", \"Injuries\", \"Cultural_Resources\",\"Livestock\", \"Law_Violations\", \"Military_Base\", \n",
    "           \"Infrastructure\", \"Extreme_Weather\", \"Ecological\", \"Hazardous_Terrain\", \"Floods\", \"Dry_Weather\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_quote_marks(word_list):\n",
    "    word_list = word_list.strip(\"[]\").split(\", \")\n",
    "    word_list = [w.replace(\"'\",\"\") for w in word_list]\n",
    "    word_list = \" \".join(word_list)\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [train_data, val_data, test_data]\n",
    "for df in dfs:\n",
    "    cleaned_combined_text = []\n",
    "    for text in df['Combined_Text']:\n",
    "        cleaned_text = remove_quote_marks(text)\n",
    "        cleaned_combined_text.append(cleaned_text)\n",
    "    df['Combined_Text'] = cleaned_combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = train_data['Combined_Text']; ytrain = train_data[targets]\n",
    "Xval = val_data['Combined_Text']; yval = val_data[targets]\n",
    "Xtest = test_data['Combined_Text']; ytest = test_data[targets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82cd070088a40438c0e8c72f138e082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=1175.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06938fb0c32a441aac364ba19e33ce14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=10177.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec399a637984275bee3ac05d995cc3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=612.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a32027ff1a40058df2400eb53c001c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=116.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff467c75e384f0c9fc2dfc3b8a236db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=39265.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf40a4b88054e0782525ecc65851863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=349.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e406d6dd6c466daf002ea1073ae6eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=90888945.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a675bfec2ae3438a98cb3fd5b525cce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=53.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c04ee3495ce471b926bbe358478f5e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=112.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e1130b4d6a465c8afdc31dc439416d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=466247.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4267b329524504b18c11ebd06e4365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=350.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ebaae7ff22f44338a40698996d3a191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=13156.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10ba78c0e6e4bc9a451938d009db996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=231508.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f764ddaefd4d455ab788479c041c267d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=190.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "vec_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "Xtrain_vec = vec_model.encode(Xtrain)\n",
    "Xval_vec = vec_model.encode(Xval)\n",
    "Xtest_vec = vec_model.encode(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2504, 384)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2504,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method: classifier chain\n",
    "Note: classifier chains tend to perform worse on larget sets of targets. Also the performance is highly dependent on the order of the chain, so all orderings would ideally be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "classifiers = [LogisticRegression(max_iter=10000,multi_class='ovr'), RandomForestClassifier(random_state=1),\n",
    "              KNeighborsClassifier(weights='distance'), MLPClassifier(random_state=1), RidgeClassifierCV()]\n",
    "classifier_names = ['logistic regression', 'random forest', 'knn', 'MLP NN', 'Ridge']\n",
    "test_hamming_loss = []; train_hamming_loss = []\n",
    "test_acc = []; train_acc = []\n",
    "test_f1 = []; train_f1 = []\n",
    "test_precision = []; train_precision = []\n",
    "test_recall = []; train_recall = []\n",
    "for clf in classifiers:\n",
    "    classifier = ClassifierChain(clf)\n",
    "    classifier.fit(Xtrain_vec, ytrain[targets])\n",
    "    # predict\n",
    "    predictions = classifier.predict(Xtest_vec)\n",
    "    test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "    test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "    train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "    test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "    train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "    test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "    train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "    test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "    train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))\n",
    "    \n",
    "comparison = pd.DataFrame({\"Base Estimator\": classifier_names,\n",
    "                           \"train f1\": train_f1, \"test f1\": test_f1,\n",
    "                          \"train accuracy\":train_acc, \"test accuracy\": test_acc,\n",
    "                          \"train recall\": train_recall, \"test recall\": test_recall,\n",
    "                          \"train precision\": train_precision, \"test precision\": test_precision,\n",
    "                          \"train hamming loss\": train_hamming_loss, \"test hamming loss\": test_hamming_loss})\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base Estimator</th>\n",
       "      <th>hamming loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.058330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random forest</td>\n",
       "      <td>0.059505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.073717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP NN</td>\n",
       "      <td>0.063968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.058941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Base Estimator  hamming loss\n",
       "0  logistic regression      0.058330\n",
       "1        random forest      0.059505\n",
       "2                  knn      0.073717\n",
       "3               MLP NN      0.063968\n",
       "4                Ridge      0.058941"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method: multioutput classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hamming_loss = []; train_hamming_loss = []\n",
    "test_acc = []; train_acc = []\n",
    "test_f1 = []; train_f1 = []\n",
    "test_precision = []; train_precision = []\n",
    "test_recall = []; train_recall = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [KNeighborsClassifier(weights='distance'),#SVC(kernel=\"linear\", C=0.025),SVC(gamma=2, C=1),\n",
    "               LinearSVC(multi_class='crammer_singer',max_iter=100000, class_weight='balanced'), DecisionTreeClassifier(),\n",
    "               RandomForestClassifier(random_state=1, n_estimators=200),LogisticRegression(max_iter=10000,multi_class='multinomial'),\n",
    "               MLPClassifier(alpha=1, max_iter=1000), RidgeClassifierCV(), AdaBoostClassifier()]\n",
    "               #GaussianNB(), QuadraticDiscriminantAnalysis()]\n",
    "total_names = ['Knn', #\"Linear SVM\", \"RBF SVM\",\n",
    "                \"Linear SVM\", \"Decision Tree\", \"Random Forest\", \n",
    "                   \"Logisitc Regression\", 'MLP NN', 'Ridge', 'Adaboost']#, 'Gaussian NB', 'QDA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▌                                                                         | 1/8 [00:07<00:49,  7.13s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [10:43<00:00, 80.49s/it]\n"
     ]
    }
   ],
   "source": [
    "for clf in tqdm(classifiers):\n",
    "    classifier = clf#MultiOutputClassifier(clf)#, n_jobs=-1)\n",
    "    classifier.fit(Xtrain_vec, ytrain['powerlabel'])\n",
    "    predictions = classifier.predict(Xtest_vec)\n",
    "    train_preds = classifier.predict(Xtrain_vec)\n",
    "    test_acc.append(round(accuracy_score(ytest['powerlabel'],predictions),3)); train_acc.append(round(accuracy_score(ytrain['powerlabel'],train_preds),3))\n",
    "    test_f1.append(round(f1_score(ytest['powerlabel'],predictions, average='macro',zero_division=0),3))\n",
    "    train_f1.append(round(f1_score(ytrain['powerlabel'],train_preds, average='macro',zero_division=0),3))\n",
    "    test_precision.append(round(precision_score(ytest['powerlabel'],predictions, average='macro', zero_division=0),3))\n",
    "    train_precision.append(round(precision_score(ytrain['powerlabel'],train_preds, average='macro', zero_division=0),3))\n",
    "    test_recall.append(round(recall_score(ytest['powerlabel'],predictions, average='macro', zero_division=0),3))\n",
    "    train_recall.append(round(recall_score(ytrain['powerlabel'],train_preds, average='macro', zero_division=0),3))\n",
    "    test_hamming_loss.append(round(hamming_loss(ytest['powerlabel'],predictions),3))\n",
    "    train_hamming_loss.append(round(hamming_loss(ytrain['powerlabel'],train_preds),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>train f1</th>\n",
       "      <th>test f1</th>\n",
       "      <th>train accuracy</th>\n",
       "      <th>test accuracy</th>\n",
       "      <th>train recall</th>\n",
       "      <th>test recall</th>\n",
       "      <th>train precision</th>\n",
       "      <th>test precision</th>\n",
       "      <th>train hamming loss</th>\n",
       "      <th>test hamming loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Knn</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logisitc Regression</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP NN</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  train f1  test f1  train accuracy  test accuracy  \\\n",
       "0                  Knn     0.985    0.006           0.991          0.532   \n",
       "1           Linear SVM     0.432    0.004           0.253          0.038   \n",
       "2        Decision Tree     0.985    0.008           0.991          0.448   \n",
       "3        Random Forest     0.986    0.006           0.991          0.538   \n",
       "4  Logisitc Regression     0.054    0.008           0.653          0.543   \n",
       "5               MLP NN     0.002    0.006           0.594          0.538   \n",
       "6                Ridge     0.172    0.008           0.682          0.539   \n",
       "7             Adaboost     0.005    0.007           0.596          0.538   \n",
       "\n",
       "   train recall  test recall  train precision  test precision  \\\n",
       "0         0.982        0.007            0.991           0.012   \n",
       "1         0.962        0.007            0.321           0.007   \n",
       "2         0.982        0.008            0.991           0.009   \n",
       "3         0.984        0.007            0.990           0.009   \n",
       "4         0.045        0.010            0.098           0.010   \n",
       "5         0.002        0.008            0.002           0.005   \n",
       "6         0.157        0.009            0.260           0.007   \n",
       "7         0.006        0.010            0.005           0.006   \n",
       "\n",
       "   train hamming loss  test hamming loss  \n",
       "0               0.009              0.468  \n",
       "1               0.747              0.962  \n",
       "2               0.009              0.552  \n",
       "3               0.009              0.462  \n",
       "4               0.347              0.457  \n",
       "5               0.406              0.462  \n",
       "6               0.318              0.461  \n",
       "7               0.404              0.462  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison = pd.DataFrame({\"Model\":total_names,\n",
    "                           \"train f1\": train_f1, \"test f1\": test_f1,\n",
    "                          \"train accuracy\":train_acc, \"test accuracy\": test_acc,\n",
    "                          \"train recall\": train_recall, \"test recall\": test_recall,\n",
    "                          \"train precision\": train_precision, \"test precision\": test_precision,\n",
    "                          \"train hamming loss\": train_hamming_loss, \"test hamming loss\": test_hamming_loss})\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method: One vs Rest classifier\n",
    "note: this one performs better without the extreme over sampling -> maybe a simple over sampling approach is preferred here. Over fitting is definitely occuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = ytrain[targets]\n",
    "ytest = ytest[targets]\n",
    "yval = yval[targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [KNeighborsClassifier(weights='uniform', p=1),SVC(kernel=\"linear\", C=0.025),SVC(gamma=2, C=1),\n",
    "               #GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "               DecisionTreeClassifier(criterion='entropy', max_features='sqrt', class_weight=None, splitter='best'),\n",
    "               RandomForestClassifier(criterion='entropy',max_features='auto', class_weight='balanced', n_estimators=100),\n",
    "               LogisticRegression(max_iter=10000,multi_class='ovr',solver='sag'),\n",
    "               MLPClassifier(alpha=1, max_iter=1000), RidgeClassifier(alpha=10), AdaBoostClassifier(learning_rate=1), \n",
    "               XGBClassifier(booster='gbtree', n_estimators=100, max_depth=4)\n",
    "              ]#GaussianNB(), QuadraticDiscriminantAnalysis()]\n",
    "classifier_name = ['Knn', \"Linear SVM\", \"RBF SVM\", #\"Gaussian Process\",\n",
    "                   \"Decision Tree\", \"Random Forest\", \n",
    "                   \"Logisitc Regression\", 'MLP NN', 'Ridge', 'Adaboost', 'XGBoost' ]#,'Gaussian NB', 'QDA'\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hamming_loss = []; train_hamming_loss = []\n",
    "test_acc = []; train_acc = []\n",
    "test_f1 = []; train_f1 = []\n",
    "test_precision = []; train_precision = []\n",
    "test_recall = []; train_recall = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████████        | 9/10 [1:20:07<06:58, 418.99s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:01:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:01:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:01:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:02:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:02:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:02:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:02:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:03:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:03:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:03:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:03:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:03:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:03:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:04:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:04:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:04:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:04:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 10/10 [1:23:44<00:00, 502.42s/it]\n"
     ]
    }
   ],
   "source": [
    "for clf in tqdm(classifiers):\n",
    "    classifier = OneVsRestClassifier(clf)#, n_jobs=-1)\n",
    "    classifier.fit(Xtrain_vec, ytrain)\n",
    "    predictions = classifier.predict(Xtest_vec)\n",
    "    train_preds = classifier.predict(Xtrain_vec)\n",
    "    test_acc.append(round(accuracy_score(ytest,predictions),3)); train_acc.append(round(accuracy_score(ytrain,train_preds),3))\n",
    "    test_f1.append(round(f1_score(ytest,predictions, average='macro',zero_division=0),3))\n",
    "    train_f1.append(round(f1_score(ytrain,train_preds, average='macro',zero_division=0),3))\n",
    "    test_precision.append(round(precision_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "    train_precision.append(round(precision_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "    test_recall.append(round(recall_score(ytest,predictions, average='macro', zero_division=0),3))\n",
    "    train_recall.append(round(recall_score(ytrain,train_preds, average='macro', zero_division=0),3))\n",
    "    test_hamming_loss.append(round(hamming_loss(ytest,predictions),3))\n",
    "    train_hamming_loss.append(round(hamming_loss(ytrain,train_preds),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame({\"Model\":classifier_name,\n",
    "                          \"train f1\": train_f1, \"test f1\": test_f1,\n",
    "                          \"train accuracy\":train_acc, \"test accuracy\": test_acc,\n",
    "                          \"train recall\": train_recall, \"test recall\": test_recall,\n",
    "                          \"train precision\": train_precision, \"test precision\": test_precision,\n",
    "                          \"train hamming loss\": train_hamming_loss, \"test hamming loss\": test_hamming_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>train f1</th>\n",
       "      <th>test f1</th>\n",
       "      <th>train accuracy</th>\n",
       "      <th>test accuracy</th>\n",
       "      <th>train recall</th>\n",
       "      <th>test recall</th>\n",
       "      <th>train precision</th>\n",
       "      <th>test precision</th>\n",
       "      <th>train hamming loss</th>\n",
       "      <th>test hamming loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Knn</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.111</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.311</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.102</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.032</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.020</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logisitc Regression</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLP NN</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  train f1  test f1  train accuracy  test accuracy  \\\n",
       "0                  Knn     0.625    0.105           0.720          0.464   \n",
       "1           Linear SVM     0.001    0.001           0.587          0.537   \n",
       "2              RBF SVM     0.646    0.053           0.777          0.534   \n",
       "3        Decision Tree     1.000    0.111           1.000          0.311   \n",
       "4        Random Forest     1.000    0.032           1.000          0.535   \n",
       "5  Logisitc Regression     0.108    0.060           0.595          0.531   \n",
       "6               MLP NN     0.048    0.050           0.589          0.534   \n",
       "7                Ridge     0.044    0.042           0.590          0.537   \n",
       "8             Adaboost     0.340    0.106           0.574          0.508   \n",
       "9              XGBoost     0.889    0.069           0.856          0.508   \n",
       "\n",
       "   train recall  test recall  train precision  test precision  \\\n",
       "0         0.537        0.093            0.768           0.149   \n",
       "1         0.001        0.001            0.039           0.050   \n",
       "2         0.508        0.040            0.928           0.082   \n",
       "3         1.000        0.102            1.000           0.151   \n",
       "4         0.999        0.020            1.000           0.083   \n",
       "5         0.073        0.045            0.552           0.147   \n",
       "6         0.035        0.036            0.078           0.081   \n",
       "7         0.032        0.030            0.103           0.083   \n",
       "8         0.274        0.076            0.591           0.269   \n",
       "9         0.854        0.051            0.933           0.163   \n",
       "\n",
       "   train hamming loss  test hamming loss  \n",
       "0               0.027              0.073  \n",
       "1               0.053              0.062  \n",
       "2               0.020              0.056  \n",
       "3               0.000              0.092  \n",
       "4               0.000              0.059  \n",
       "5               0.047              0.057  \n",
       "6               0.049              0.057  \n",
       "7               0.049              0.057  \n",
       "8               0.049              0.062  \n",
       "9               0.010              0.060  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter optomization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.style\n",
    "matplotlib.style.use(\"seaborn\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "sns.color_palette(\"hls\", 17)\n",
    "#import scipy.stats as st\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "from pingouin import rcorr\n",
    "import pingouin as pg\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.multioutput import RegressorChain, MultiOutputRegressor\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifierCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm \n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, cross_validate, cross_val_score, learning_curve\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, precision_score, recall_score, plot_roc_curve, roc_curve, auc, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import feature_selection #import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(\"..\"))\n",
    "\n",
    "from module.trend_analysis_functions import *\n",
    "from module.topic_model_plus_class import Topic_Model_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(os.path.join(os.path.dirname(os.getcwd()),'data','ICS_predictive_sitreps_full_test.csv')).drop([\"Unnamed: 0\"], axis=1)\n",
    "train_data = pd.read_csv(os.path.join(os.path.dirname(os.getcwd()),'data','ICS_predictive_sitreps_full_train.csv')).drop([\"Unnamed: 0\"], axis=1)\n",
    "val_data = pd.read_csv(os.path.join(os.path.dirname(os.getcwd()),'data','ICS_predictive_sitreps_full_val.csv')).drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CY</th>\n",
       "      <th>DISCOVERY_DATE</th>\n",
       "      <th>INCIDENT_ID</th>\n",
       "      <th>PCT_CONTAINED_COMPLETED</th>\n",
       "      <th>START_YEAR</th>\n",
       "      <th>TOTAL_AERIAL</th>\n",
       "      <th>TOTAL_PERSONNEL</th>\n",
       "      <th>REPORT_DOY</th>\n",
       "      <th>DISCOVERY_DOY</th>\n",
       "      <th>Combined_Text</th>\n",
       "      <th>...</th>\n",
       "      <th>INC_MGMT_ORG_ABBREV_2</th>\n",
       "      <th>INC_MGMT_ORG_ABBREV_3</th>\n",
       "      <th>INC_MGMT_ORG_ABBREV_4</th>\n",
       "      <th>INC_MGMT_ORG_ABBREV_5</th>\n",
       "      <th>INC_MGMT_ORG_ABBREV_A</th>\n",
       "      <th>INC_MGMT_ORG_ABBREV_B</th>\n",
       "      <th>INC_MGMT_ORG_ABBREV_C</th>\n",
       "      <th>INC_MGMT_ORG_ABBREV_D</th>\n",
       "      <th>INC_MGMT_ORG_ABBREV_E</th>\n",
       "      <th>INC_MGMT_ORG_ABBREV_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>7/15/2010 15:00</td>\n",
       "      <td>2000_CA-RRU-062485_VALLEY COMPLEX</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.052083</td>\n",
       "      <td>0.043860</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "      <td>['resource', 'share', 'cactus']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>7/15/2010 15:00</td>\n",
       "      <td>2000_CA-RRU-062485_VALLEY COMPLEX</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.052083</td>\n",
       "      <td>0.043860</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "      <td>['resource', 'share', 'incident', 'cactus', 'i...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>7/15/2010 15:00</td>\n",
       "      <td>2000_CA-RRU-062485_VALLEY COMPLEX</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.031465</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "      <td>['resource', 'share', 'cactus', 'erratic', 'wi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>7/15/2010 15:00</td>\n",
       "      <td>2000_CA-RRU-062485_VALLEY COMPLEX</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.045139</td>\n",
       "      <td>0.036677</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "      <td>['resource', 'share', 'cactus', 'cactus', 'bec...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>7/15/2010 15:00</td>\n",
       "      <td>2000_CA-RRU-062485_VALLEY COMPLEX</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.045139</td>\n",
       "      <td>0.036677</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "      <td>['resource', 'share', 'cactus', 'cactus', 'bec...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39352</th>\n",
       "      <td>2014</td>\n",
       "      <td>4/11/2014 17:00</td>\n",
       "      <td>2014_N041114-22_CHIMNEY TOP FIRE</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>106</td>\n",
       "      <td>101</td>\n",
       "      <td>['rain', 'fell', 'hour', 'everything']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39353</th>\n",
       "      <td>2014</td>\n",
       "      <td>3/10/2014 14:00</td>\n",
       "      <td>2014_VA-VAS 0140633_OVER YONDER FIRE</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>71</td>\n",
       "      <td>69</td>\n",
       "      <td>['acre', 'revise', 'downward', 'result', 'actu...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39354</th>\n",
       "      <td>2014</td>\n",
       "      <td>3/10/2014 14:00</td>\n",
       "      <td>2014_VA-VAS 0140633_OVER YONDER FIRE</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>71</td>\n",
       "      <td>69</td>\n",
       "      <td>['acre', 'revise', 'downward', 'result', 'actu...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39355</th>\n",
       "      <td>2014</td>\n",
       "      <td>4/20/2014 9:00</td>\n",
       "      <td>2014_VAS1400605_ISSAC'S BRANCH</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>113</td>\n",
       "      <td>110</td>\n",
       "      <td>['flame', 'length', 'steep', 'limited', 'access']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39356</th>\n",
       "      <td>2014</td>\n",
       "      <td>3/15/2014 14:30</td>\n",
       "      <td>2014_VAVAS1403037_BEAVER LODGE RD.</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>['fast', 'spread', 'field']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39357 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CY   DISCOVERY_DATE                           INCIDENT_ID  \\\n",
       "0      2010  7/15/2010 15:00     2000_CA-RRU-062485_VALLEY COMPLEX   \n",
       "1      2010  7/15/2010 15:00     2000_CA-RRU-062485_VALLEY COMPLEX   \n",
       "2      2010  7/15/2010 15:00     2000_CA-RRU-062485_VALLEY COMPLEX   \n",
       "3      2010  7/15/2010 15:00     2000_CA-RRU-062485_VALLEY COMPLEX   \n",
       "4      2010  7/15/2010 15:00     2000_CA-RRU-062485_VALLEY COMPLEX   \n",
       "...     ...              ...                                   ...   \n",
       "39352  2014  4/11/2014 17:00      2014_N041114-22_CHIMNEY TOP FIRE   \n",
       "39353  2014  3/10/2014 14:00  2014_VA-VAS 0140633_OVER YONDER FIRE   \n",
       "39354  2014  3/10/2014 14:00  2014_VA-VAS 0140633_OVER YONDER FIRE   \n",
       "39355  2014   4/20/2014 9:00        2014_VAS1400605_ISSAC'S BRANCH   \n",
       "39356  2014  3/15/2014 14:30    2014_VAVAS1403037_BEAVER LODGE RD.   \n",
       "\n",
       "       PCT_CONTAINED_COMPLETED  START_YEAR  TOTAL_AERIAL  TOTAL_PERSONNEL  \\\n",
       "0                     0.000017        2010      0.052083         0.043860   \n",
       "1                     0.000012        2010      0.052083         0.043860   \n",
       "2                     0.000006        2010      0.041667         0.031465   \n",
       "3                     0.000021        2010      0.045139         0.036677   \n",
       "4                     0.000012        2010      0.045139         0.036677   \n",
       "...                        ...         ...           ...              ...   \n",
       "39352                 0.000021        2014      0.000000         0.000191   \n",
       "39353                 0.000021        2014      0.000000         0.001812   \n",
       "39354                 0.000021        2014      0.000000         0.001812   \n",
       "39355                 0.000008        2014      0.000000         0.003623   \n",
       "39356                 0.000021        2014      0.000000         0.002479   \n",
       "\n",
       "       REPORT_DOY  DISCOVERY_DOY  \\\n",
       "0             197            196   \n",
       "1             197            196   \n",
       "2             197            196   \n",
       "3             197            196   \n",
       "4             197            196   \n",
       "...           ...            ...   \n",
       "39352         106            101   \n",
       "39353          71             69   \n",
       "39354          71             69   \n",
       "39355         113            110   \n",
       "39356          74             74   \n",
       "\n",
       "                                           Combined_Text  ...  \\\n",
       "0                        ['resource', 'share', 'cactus']  ...   \n",
       "1      ['resource', 'share', 'incident', 'cactus', 'i...  ...   \n",
       "2      ['resource', 'share', 'cactus', 'erratic', 'wi...  ...   \n",
       "3      ['resource', 'share', 'cactus', 'cactus', 'bec...  ...   \n",
       "4      ['resource', 'share', 'cactus', 'cactus', 'bec...  ...   \n",
       "...                                                  ...  ...   \n",
       "39352             ['rain', 'fell', 'hour', 'everything']  ...   \n",
       "39353  ['acre', 'revise', 'downward', 'result', 'actu...  ...   \n",
       "39354  ['acre', 'revise', 'downward', 'result', 'actu...  ...   \n",
       "39355  ['flame', 'length', 'steep', 'limited', 'access']  ...   \n",
       "39356                        ['fast', 'spread', 'field']  ...   \n",
       "\n",
       "      INC_MGMT_ORG_ABBREV_2 INC_MGMT_ORG_ABBREV_3  INC_MGMT_ORG_ABBREV_4  \\\n",
       "0                         0                     0                      1   \n",
       "1                         0                     0                      1   \n",
       "2                         0                     0                      1   \n",
       "3                         0                     0                      1   \n",
       "4                         0                     0                      1   \n",
       "...                     ...                   ...                    ...   \n",
       "39352                     0                     0                      0   \n",
       "39353                     0                     0                      0   \n",
       "39354                     0                     0                      0   \n",
       "39355                     0                     0                      0   \n",
       "39356                     0                     0                      0   \n",
       "\n",
       "       INC_MGMT_ORG_ABBREV_5  INC_MGMT_ORG_ABBREV_A  INC_MGMT_ORG_ABBREV_B  \\\n",
       "0                          0                      0                      0   \n",
       "1                          0                      0                      0   \n",
       "2                          0                      0                      0   \n",
       "3                          0                      0                      0   \n",
       "4                          0                      0                      0   \n",
       "...                      ...                    ...                    ...   \n",
       "39352                      1                      0                      0   \n",
       "39353                      1                      0                      0   \n",
       "39354                      1                      0                      0   \n",
       "39355                      1                      0                      0   \n",
       "39356                      1                      0                      0   \n",
       "\n",
       "       INC_MGMT_ORG_ABBREV_C  INC_MGMT_ORG_ABBREV_D  INC_MGMT_ORG_ABBREV_E  \\\n",
       "0                          0                      0                      0   \n",
       "1                          0                      0                      0   \n",
       "2                          0                      0                      0   \n",
       "3                          0                      0                      0   \n",
       "4                          0                      0                      0   \n",
       "...                      ...                    ...                    ...   \n",
       "39352                      0                      0                      0   \n",
       "39353                      0                      0                      0   \n",
       "39354                      0                      0                      0   \n",
       "39355                      0                      0                      0   \n",
       "39356                      0                      0                      0   \n",
       "\n",
       "       INC_MGMT_ORG_ABBREV_F  \n",
       "0                          0  \n",
       "1                          0  \n",
       "2                          0  \n",
       "3                          0  \n",
       "4                          0  \n",
       "...                      ...  \n",
       "39352                      0  \n",
       "39353                      0  \n",
       "39354                      0  \n",
       "39355                      0  \n",
       "39356                      0  \n",
       "\n",
       "[39357 rows x 81 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (7,13,18,19,36) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "summary_reps = pd.read_csv(os.path.join(os.path.dirname(os.getcwd()),'data','ICS_predictive_summaryreps_full.csv')).drop([\"Unnamed: 0\"], axis=1)#os.path.join(os.path.dirname(os.getcwd()),'data','summary_reports_cleaned.csv')).drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8973"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = list(train_data[\"INCIDENT_ID\"].unique()) + list(test_data['INCIDENT_ID'].unique())+list(val_data['INCIDENT_ID'].unique())\n",
    "print(len(ids))\n",
    "summary_reps = summary_reps.loc[summary_reps[\"INCIDENT_ID\"].isin(ids)].reset_index(drop=True)\n",
    "len(summary_reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CY', 'DISCOVERY_DATE', 'INCIDENT_ID', 'PCT_CONTAINED_COMPLETED',\n",
       "       'START_YEAR', 'TOTAL_AERIAL', 'TOTAL_PERSONNEL', 'REPORT_DOY',\n",
       "       'DISCOVERY_DOY', 'Combined_Text', 'Unique_IDs', 'Raw_Combined_Text',\n",
       "       'ACRES', 'WF_FSR', 'INJURIES', 'FATALITIES', 'EST_IM_COST_TO_DATE',\n",
       "       'STR_DAMAGED', 'STR_DESTROYED', 'NEW_ACRES', 'POO_STATE',\n",
       "       'POO_LATITUDE', 'POO_LONGITUDE', 'WEATHER_CONCERNS_NARR',\n",
       "       'INC_MGMT_ORG_ABBREV', 'EVACUATION_IN_PROGRESS', 'Incident_region',\n",
       "       'NUM_REPORTS', 'DAYS_BURING', 'Severity', 'Traffic',\n",
       "       'Command_Transitions', 'Evacuations', 'Inaccurate_Mapping',\n",
       "       'Aerial_Grounding', 'Resource_Issues', 'Injuries', 'Cultural_Resources',\n",
       "       'Livestock', 'Law_Violations', 'Military_Base', 'Infrastructure',\n",
       "       'Extreme_Weather', 'Ecological', 'Hazardous_Terrain', 'Floods',\n",
       "       'Dry_Weather', 'Total_Incident_Text', 'Current_total_Injuries',\n",
       "       'Current_total_Structures_Damages',\n",
       "       'Current_total_Structures_Destroyed', 'Current_total_Fatalities',\n",
       "       'Diff_Injuries', 'Diff_Structures_Damages', 'Diff_Structures_Destroyed',\n",
       "       'Diff_Fatalities', 'Total_Injuries', 'Total_Structures_Damages',\n",
       "       'Total_Structures_Destroyed', 'Total_Fatalities',\n",
       "       'Incident_region_AICC', 'Incident_region_CA', 'Incident_region_EACC',\n",
       "       'Incident_region_GBCC', 'Incident_region_HICC', 'Incident_region_NRCC',\n",
       "       'Incident_region_NWCC', 'Incident_region_RMCC', 'Incident_region_SACC',\n",
       "       'Incident_region_SWCC', 'INC_MGMT_ORG_ABBREV_1',\n",
       "       'INC_MGMT_ORG_ABBREV_2', 'INC_MGMT_ORG_ABBREV_3',\n",
       "       'INC_MGMT_ORG_ABBREV_4', 'INC_MGMT_ORG_ABBREV_5',\n",
       "       'INC_MGMT_ORG_ABBREV_A', 'INC_MGMT_ORG_ABBREV_B',\n",
       "       'INC_MGMT_ORG_ABBREV_C', 'INC_MGMT_ORG_ABBREV_D',\n",
       "       'INC_MGMT_ORG_ABBREV_E', 'INC_MGMT_ORG_ABBREV_F'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcols = ['TOTAL_AERIAL', 'TOTAL_PERSONNEL', 'WF_FSR', 'DAYS_BURING', 'ACRES','PCT_CONTAINED_COMPLETED', #'Current_total_Injuries',\n",
    "       #'Current_total_Structures_Damages',\n",
    "       #'Current_total_Structures_Destroyed', 'Current_total_Fatalities',\n",
    "         'INJURIES','FATALITIES', 'STR_DESTROYED','STR_DAMAGED', 'Traffic',\n",
    "       'Command_Transitions', 'Evacuations', 'Inaccurate_Mapping',\n",
    "       'Aerial_Grounding', 'Resource_Issues', 'Injuries', 'Cultural_Resources',\n",
    "       'Livestock', 'Law_Violations', 'Military_Base', 'Infrastructure',\n",
    "       'Extreme_Weather', 'Ecological', 'Hazardous_Terrain', 'Floods',\n",
    "       'Dry_Weather', 'Incident_region_AICC', 'Incident_region_CA', 'Incident_region_EACC',\n",
    "       'Incident_region_GBCC', 'Incident_region_HICC', 'Incident_region_NRCC',\n",
    "       'Incident_region_NWCC', 'Incident_region_RMCC', 'Incident_region_SACC',\n",
    "       'Incident_region_SWCC']\n",
    "ycols = ['Total_Injuries', 'Total_Structures_Damages', 'Total_Structures_Destroyed',\n",
    "       'Total_Fatalities']# ['Diff_Injuries', 'Diff_Structures_Damages', 'Diff_Structures_Destroyed','Diff_Fatalities']\n",
    "Xtrain = train_data[xcols]; ytrain = train_data[ycols]\n",
    "Xval = val_data[xcols]; yval = val_data[ycols]\n",
    "Xtest = test_data[xcols]; ytest = test_data[ycols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39357, 37)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 37)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xval.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models to test:\n",
    "- SVM\n",
    "- NB\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- xgboost\n",
    "- AdaBoost\n",
    "- NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 8/8 [2:11:26<00:00, 985.81s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">MSE</th>\n",
       "      <th colspan=\"10\" halign=\"left\">R^2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">train</th>\n",
       "      <th colspan=\"5\" halign=\"left\">test</th>\n",
       "      <th colspan=\"5\" halign=\"left\">train</th>\n",
       "      <th colspan=\"5\" halign=\"left\">test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>injuries</th>\n",
       "      <th>str dam</th>\n",
       "      <th>str des</th>\n",
       "      <th>fatalities</th>\n",
       "      <th>average</th>\n",
       "      <th>injuries</th>\n",
       "      <th>str dam</th>\n",
       "      <th>str des</th>\n",
       "      <th>fatalities</th>\n",
       "      <th>average</th>\n",
       "      <th>injuries</th>\n",
       "      <th>str dam</th>\n",
       "      <th>str des</th>\n",
       "      <th>fatalities</th>\n",
       "      <th>average</th>\n",
       "      <th>injuries</th>\n",
       "      <th>str dam</th>\n",
       "      <th>str des</th>\n",
       "      <th>fatalities</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>20.154</td>\n",
       "      <td>319.996</td>\n",
       "      <td>5054.163</td>\n",
       "      <td>0.061</td>\n",
       "      <td>1348.593</td>\n",
       "      <td>11.841</td>\n",
       "      <td>16.904</td>\n",
       "      <td>2146.704</td>\n",
       "      <td>0.014</td>\n",
       "      <td>543.866</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-84.358</td>\n",
       "      <td>-305.883</td>\n",
       "      <td>0.851</td>\n",
       "      <td>-97.357</td>\n",
       "      <td>-0.731</td>\n",
       "      <td>-14.428</td>\n",
       "      <td>-268.648</td>\n",
       "      <td>0.439</td>\n",
       "      <td>-70.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14.147</td>\n",
       "      <td>30.885</td>\n",
       "      <td>582.821</td>\n",
       "      <td>0.013</td>\n",
       "      <td>156.967</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>20.627</td>\n",
       "      <td>42.065</td>\n",
       "      <td>277.371</td>\n",
       "      <td>0.175</td>\n",
       "      <td>85.059</td>\n",
       "      <td>18.884</td>\n",
       "      <td>5.302</td>\n",
       "      <td>476.662</td>\n",
       "      <td>0.008</td>\n",
       "      <td>125.214</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.600</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Ridge</th>\n",
       "      <td>27.262</td>\n",
       "      <td>108.328</td>\n",
       "      <td>553.713</td>\n",
       "      <td>0.268</td>\n",
       "      <td>172.393</td>\n",
       "      <td>15.025</td>\n",
       "      <td>16.119</td>\n",
       "      <td>373.805</td>\n",
       "      <td>0.034</td>\n",
       "      <td>101.246</td>\n",
       "      <td>-0.256</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.328</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>5.026</td>\n",
       "      <td>13.461</td>\n",
       "      <td>103.636</td>\n",
       "      <td>0.018</td>\n",
       "      <td>30.535</td>\n",
       "      <td>18.567</td>\n",
       "      <td>7.494</td>\n",
       "      <td>415.735</td>\n",
       "      <td>0.042</td>\n",
       "      <td>110.459</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.948</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>27.236</td>\n",
       "      <td>108.330</td>\n",
       "      <td>553.687</td>\n",
       "      <td>0.268</td>\n",
       "      <td>172.380</td>\n",
       "      <td>15.053</td>\n",
       "      <td>16.006</td>\n",
       "      <td>373.740</td>\n",
       "      <td>0.034</td>\n",
       "      <td>101.208</td>\n",
       "      <td>-0.239</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.317</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.035</td>\n",
       "      <td>16.061</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.024</td>\n",
       "      <td>11.932</td>\n",
       "      <td>12.408</td>\n",
       "      <td>682.226</td>\n",
       "      <td>0.007</td>\n",
       "      <td>176.643</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>-0.718</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1927.329</td>\n",
       "      <td>0.000</td>\n",
       "      <td>481.832</td>\n",
       "      <td>29.461</td>\n",
       "      <td>165.194</td>\n",
       "      <td>1743.018</td>\n",
       "      <td>0.248</td>\n",
       "      <td>484.480</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.436</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.859</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      MSE                                                   \\\n",
       "                    train                                             test   \n",
       "                 injuries  str dam   str des fatalities   average injuries   \n",
       "SVM                20.154  319.996  5054.163      0.061  1348.593   11.841   \n",
       "GradientBoosting    0.000    0.000     0.000      0.000     0.000   14.147   \n",
       "Random Forest      20.627   42.065   277.371      0.175    85.059   18.884   \n",
       "Bayesian Ridge     27.262  108.328   553.713      0.268   172.393   15.025   \n",
       "MLP                 5.026   13.461   103.636      0.018    30.535   18.567   \n",
       "XGBoost            27.236  108.330   553.687      0.268   172.380   15.053   \n",
       "AdaBoost            0.000    0.035    16.061      0.000     4.024   11.932   \n",
       "Decision Tree       0.000    0.000  1927.329      0.000   481.832   29.461   \n",
       "\n",
       "                                                             R^2          \\\n",
       "                                                           train           \n",
       "                  str dam   str des fatalities  average injuries str dam   \n",
       "SVM                16.904  2146.704      0.014  543.866   -0.036 -84.358   \n",
       "GradientBoosting   30.885   582.821      0.013  156.967    1.000   1.000   \n",
       "Random Forest       5.302   476.662      0.008  125.214    0.059   0.861   \n",
       "Bayesian Ridge     16.119   373.805      0.034  101.246   -0.256   0.547   \n",
       "MLP                 7.494   415.735      0.042  110.459    0.884   0.960   \n",
       "XGBoost            16.006   373.740      0.034  101.208   -0.239   0.550   \n",
       "AdaBoost           12.408   682.226      0.007  176.643    1.000   1.000   \n",
       "Decision Tree     165.194  1743.018      0.248  484.480    1.000   1.000   \n",
       "\n",
       "                                                                        \\\n",
       "                                                 test                    \n",
       "                  str des fatalities average injuries str dam  str des   \n",
       "SVM              -305.883      0.851 -97.357   -0.731 -14.428 -268.648   \n",
       "GradientBoosting    1.000      1.000   1.000   -0.159   0.339    0.476   \n",
       "Random Forest       0.943      0.538   0.600   -0.340   0.639    0.786   \n",
       "Bayesian Ridge      0.882      0.140   0.328   -0.320   0.451    0.772   \n",
       "MLP                 0.980      0.969   0.948   -0.225   0.531    0.800   \n",
       "XGBoost             0.883      0.140   0.334   -0.317   0.452    0.772   \n",
       "AdaBoost            0.997      1.000   0.999   -0.718   0.179    0.363   \n",
       "Decision Tree       0.436      1.000   0.859   -0.069   0.205    0.045   \n",
       "\n",
       "                                     \n",
       "                                     \n",
       "                 fatalities average  \n",
       "SVM                   0.439 -70.842  \n",
       "GradientBoosting      0.538   0.299  \n",
       "Random Forest         0.679   0.441  \n",
       "Bayesian Ridge        0.256   0.290  \n",
       "MLP                   0.481   0.397  \n",
       "XGBoost               0.255   0.291  \n",
       "AdaBoost              0.670   0.124  \n",
       "Decision Tree         0.305   0.121  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names = [\"SVM\", \"GradientBoosting\", \"Random Forest\", \"Bayesian Ridge\", \"MLP\", \"XGBoost\", \"AdaBoost\", \"Decision Tree\"]\n",
    "cols = {(str(score),str(model),str(metric)):[] for score in [\"MSE\",\"R^2\"] for model in [\"train\",\"test\"] for metric in ['injuries','str dam', 'str des', 'fatalities', 'average']}\n",
    "\n",
    "models = [svm.SVR(kernel='rbf', C=1.2), GradientBoostingRegressor(max_features='log2',n_estimators=150, random_state=0, max_depth=22,criterion='mse'), \n",
    "          RandomForestRegressor(criterion='mse',max_features='auto',n_estimators=175, random_state=0, max_depth=4),\n",
    "          linear_model.BayesianRidge(alpha_1=100, alpha_2=10000, lambda_1=100, lambda_2=100),\n",
    "          MLPRegressor(random_state=0, max_iter=10000, alpha=0.1, learning_rate='constant', 'hidden_layer_sizes': (100,)), xgb.XGBRegressor(booster='gblinear',n_estimators=150),\n",
    "         AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion='mae', max_features='sqrt', splitter='random'), n_estimators=50, learning_rate=0.1, loss='exponential'), \n",
    "         DecisionTreeRegressor(criterion='mae', max_features='sqrt', splitter='random')]\n",
    "for m in tqdm(models):\n",
    "    mdl = MultiOutputRegressor(m)\n",
    "    mdl.fit(Xtrain, ytrain)\n",
    "    train_pred = np.around(mdl.predict(Xtrain)); train_pred[train_pred<0] = 0\n",
    "    test_pred = np.around(mdl.predict(Xtest)); test_pred[test_pred<0] = 0\n",
    "\n",
    "    train_score = np.around(r2_score(train_pred, ytrain, multioutput='raw_values'),3)\n",
    "    cols[('R^2','train','injuries')].append(train_score[0]); cols[('R^2', 'train', 'str dam')].append(train_score[1])\n",
    "    cols[('R^2','train','str des')].append(train_score[2]); cols[('R^2', 'train', 'fatalities')].append(train_score[3])\n",
    "    cols[('R^2','train','average')].append(round(r2_score(train_pred, ytrain),3))\n",
    "    \n",
    "    test_score = np.around(r2_score(test_pred, ytest,multioutput='raw_values'),3)\n",
    "    cols[('R^2','test','injuries')].append(test_score[0]); cols[('R^2','test','str dam')].append(test_score[1])\n",
    "    cols[('R^2','test','str des')].append(test_score[2]); cols[('R^2','test','fatalities')].append(test_score[3])\n",
    "    cols[('R^2','test','average')].append(round(r2_score(test_pred, ytest),3))\n",
    "    \n",
    "    train_MSE = np.around(mean_squared_error(ytrain, train_pred,multioutput='raw_values'),3)\n",
    "    cols[('MSE','train','injuries')].append(train_MSE[0]); cols[('MSE', 'train', 'str dam')].append(train_MSE[1])\n",
    "    cols[('MSE','train','str des')].append(train_MSE[2]); cols[('MSE', 'train', 'fatalities')].append(train_MSE[3])\n",
    "    cols[('MSE','train','average')].append(round(mean_squared_error(train_pred, ytrain),3))\n",
    "    \n",
    "    test_MSE = np.around(mean_squared_error(ytest, test_pred,multioutput='raw_values'),3)\n",
    "    cols[('MSE','test','injuries')].append(test_MSE[0]); cols[('MSE','test','str dam')].append(test_MSE[1])\n",
    "    cols[('MSE','test','str des')].append(test_MSE[2]); cols[('MSE','test','fatalities')].append(test_MSE[3])\n",
    "    cols[('MSE','test','average')].append(round(mean_squared_error(test_pred, ytest),3))\n",
    "    \n",
    "columns = pd.MultiIndex.from_tuples([col for col in cols])\n",
    "results_df = pd.DataFrame(cols, columns=columns, index=model_names)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = xgb.XGBRegressor(booster='gblinear',n_estimators=100)\n",
    "mdl = MultiOutputRegressor(m)\n",
    "mdl.fit(Xtrain, ytrain)\n",
    "preds = np.around(mdl.predict(Xtest))\n",
    "preds[preds<0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame(preds, columns = ytest.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(os.path.dirname(os.getcwd()),'models','severity_model_test.sav')\n",
    "pickle.dump(mdl, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rbf\n",
      "poly\n",
      "sigmoid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernels</th>\n",
       "      <th>train r</th>\n",
       "      <th>test r</th>\n",
       "      <th>train MSE</th>\n",
       "      <th>test MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.167</td>\n",
       "      <td>1360.986</td>\n",
       "      <td>548.563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poly</td>\n",
       "      <td>0.443</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>1296.726</td>\n",
       "      <td>431.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>-172151.310</td>\n",
       "      <td>-2422859.185</td>\n",
       "      <td>397845.384</td>\n",
       "      <td>251074.174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kernels     train r       test r   train MSE    test MSE\n",
       "0      rbf       0.387        0.167    1360.986     548.563\n",
       "1     poly       0.443       -0.240    1296.726     431.341\n",
       "2  sigmoid -172151.310 -2422859.185  397845.384  251074.174"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernals = ['rbf', 'poly', 'sigmoid']\n",
    "train_r = []\n",
    "test_r = []\n",
    "train_MSE = []\n",
    "test_MSE = []\n",
    "for kernal in kernals:\n",
    "    print(kernal)\n",
    "    mdl = MultiOutputRegressor(svm.SVR(kernel=kernal))\n",
    "    \n",
    "    mdl.fit(Xtrain, ytrain)\n",
    "    train_r.append(round(mdl.score(Xtrain, ytrain),3))\n",
    "    test_r.append(round(mdl.score(Xtest, ytest),3))\n",
    "    train_MSE.append(round(mean_squared_error(ytrain, mdl.predict(Xtrain)),3))\n",
    "    test_MSE.append(round(mean_squared_error(ytest, mdl.predict(Xtest)),3))\n",
    "\n",
    "model_comparisons = pd.DataFrame({\n",
    "    \"kernels\": kernals,\n",
    "    \"train r\": train_r,\n",
    "    \"test r\": test_r,\n",
    "    \"train MSE\": train_MSE,\n",
    "    \"test MSE\": test_MSE})\n",
    "\n",
    "model_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c-value</th>\n",
       "      <th>train r</th>\n",
       "      <th>test r</th>\n",
       "      <th>train MSE</th>\n",
       "      <th>test MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.068</td>\n",
       "      <td>1429.138</td>\n",
       "      <td>574.649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.102</td>\n",
       "      <td>1418.610</td>\n",
       "      <td>569.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.123</td>\n",
       "      <td>1409.920</td>\n",
       "      <td>566.491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.136</td>\n",
       "      <td>1402.196</td>\n",
       "      <td>563.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.143</td>\n",
       "      <td>1394.807</td>\n",
       "      <td>561.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.146</td>\n",
       "      <td>1387.642</td>\n",
       "      <td>558.508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.148</td>\n",
       "      <td>1380.645</td>\n",
       "      <td>555.948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.154</td>\n",
       "      <td>1373.884</td>\n",
       "      <td>553.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1367.341</td>\n",
       "      <td>550.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.167</td>\n",
       "      <td>1360.986</td>\n",
       "      <td>548.563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.1</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.173</td>\n",
       "      <td>1354.729</td>\n",
       "      <td>546.268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.2</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.178</td>\n",
       "      <td>1348.600</td>\n",
       "      <td>544.029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    c-value  train r  test r  train MSE  test MSE\n",
       "0       0.1    0.131   0.068   1429.138   574.649\n",
       "1       0.2    0.193   0.102   1418.610   569.669\n",
       "2       0.3    0.241   0.123   1409.920   566.491\n",
       "3       0.4    0.280   0.136   1402.196   563.748\n",
       "4       0.5    0.311   0.143   1394.807   561.104\n",
       "5       0.6    0.336   0.146   1387.642   558.508\n",
       "6       0.7    0.353   0.148   1380.645   555.948\n",
       "7       0.8    0.365   0.154   1373.884   553.402\n",
       "8       0.9    0.377   0.160   1367.341   550.923\n",
       "9       1.0    0.387   0.167   1360.986   548.563\n",
       "10      1.1    0.397   0.173   1354.729   546.268\n",
       "11      1.2    0.405   0.178   1348.600   544.029"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_vals = [1e-1,2e-1,3e-1,4e-1,5e-1, 6e-1,7e-1,8e-1, 9e-1, 1, 1.1, 1.2]\n",
    "train_r = []\n",
    "test_r = []\n",
    "train_MSE = []\n",
    "test_MSE = []\n",
    "for c in c_vals:\n",
    "    mdl = MultiOutputRegressor(svm.SVR(C=c,kernel='rbf'))\n",
    "    \n",
    "    mdl.fit(Xtrain, ytrain)\n",
    "    train_r.append(round(mdl.score(Xtrain, ytrain),3))\n",
    "    test_r.append(round(mdl.score(Xtest, ytest),3))\n",
    "    train_MSE.append(round(mean_squared_error(ytrain, mdl.predict(Xtrain)),3))\n",
    "    test_MSE.append(round(mean_squared_error(ytest, mdl.predict(Xtest)),3))\n",
    "\n",
    "model_comparisons = pd.DataFrame({\n",
    "    \"c-value\": c_vals,\n",
    "    \"train r\": train_r,\n",
    "    \"test r\": test_r,\n",
    "    \"train MSE\": train_MSE,\n",
    "    \"test MSE\": test_MSE})\n",
    "\n",
    "model_comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'loss' : ['huber','quantile', 'lad', 'ls'],#'squared_error', 'absolute_error', 'huber', 'quantile'], #'lad', #'ls'\n",
    "              'criterion': ['friedman_mse', 'mse'],\n",
    "              'max_depth': [i for i in range(3,25)],\n",
    "              'n_estimators': [i for i in range(100, 500, 25)],\n",
    "              'max_features': ['auto', 'sqrt', 'log2']}\n",
    "best_params = {'criterion': 'friedman_mse', 'max_depth': 3, 'n_estimators': 100, 'max_features': 'auto'}#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|█████████████████████                                                               | 1/4 [00:15<00:45, 15.30s/it]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 2/4 [00:34<00:32, 16.32s/it]\u001b[A\n",
      " 75%|███████████████████████████████████████████████████████████████                     | 3/4 [00:52<00:16, 16.92s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:09<00:00, 17.39s/it]\u001b[A\n",
      " 20%|████████████████▊                                                                   | 1/5 [01:09<04:38, 69.58s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:15<00:15, 15.18s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:30<00:00, 15.12s/it]\u001b[A\n",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [01:39<02:53, 57.78s/it]\n",
      "  0%|                                                                                           | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|███▊                                                                               | 1/22 [00:15<05:16, 15.09s/it]\u001b[A\n",
      "  9%|███████▌                                                                           | 2/22 [00:30<05:02, 15.14s/it]\u001b[A\n",
      " 14%|███████████▎                                                                       | 3/22 [00:45<04:47, 15.16s/it]\u001b[A\n",
      " 18%|███████████████                                                                    | 4/22 [01:00<04:32, 15.13s/it]\u001b[A\n",
      " 23%|██████████████████▊                                                                | 5/22 [01:15<04:16, 15.10s/it]\u001b[A\n",
      " 27%|██████████████████████▋                                                            | 6/22 [01:30<04:01, 15.09s/it]\u001b[A\n",
      " 32%|██████████████████████████▍                                                        | 7/22 [01:45<03:46, 15.08s/it]\u001b[A\n",
      " 36%|██████████████████████████████▏                                                    | 8/22 [02:00<03:31, 15.10s/it]\u001b[A\n",
      " 41%|█████████████████████████████████▉                                                 | 9/22 [02:16<03:17, 15.19s/it]\u001b[A\n",
      " 45%|█████████████████████████████████████▎                                            | 10/22 [02:31<03:03, 15.30s/it]\u001b[A\n",
      " 50%|█████████████████████████████████████████                                         | 11/22 [02:47<02:48, 15.34s/it]\u001b[A\n",
      " 55%|████████████████████████████████████████████▋                                     | 12/22 [03:02<02:33, 15.40s/it]\u001b[A\n",
      " 59%|████████████████████████████████████████████████▍                                 | 13/22 [03:18<02:18, 15.43s/it]\u001b[A\n",
      " 64%|████████████████████████████████████████████████████▏                             | 14/22 [03:33<02:03, 15.42s/it]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████████▉                          | 15/22 [03:48<01:47, 15.37s/it]\u001b[A\n",
      " 73%|███████████████████████████████████████████████████████████▋                      | 16/22 [04:04<01:31, 15.31s/it]\u001b[A\n",
      " 77%|███████████████████████████████████████████████████████████████▎                  | 17/22 [04:19<01:16, 15.27s/it]\u001b[A\n",
      " 82%|███████████████████████████████████████████████████████████████████               | 18/22 [04:34<01:00, 15.24s/it]\u001b[A\n",
      " 86%|██████████████████████████████████████████████████████████████████████▊           | 19/22 [04:49<00:45, 15.22s/it]\u001b[A\n",
      " 91%|██████████████████████████████████████████████████████████████████████████▌       | 20/22 [05:04<00:30, 15.19s/it]\u001b[A\n",
      " 95%|██████████████████████████████████████████████████████████████████████████████▎   | 21/22 [05:19<00:15, 15.17s/it]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [05:35<00:00, 15.23s/it]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [07:14<04:41, 140.97s/it]\n",
      "  0%|                                                                                           | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "  6%|█████                                                                           | 1/16 [08:51<2:12:57, 531.86s/it]\u001b[A\n",
      " 12%|██████████                                                                      | 2/16 [17:58<2:05:09, 536.38s/it]\u001b[A\n",
      " 19%|███████████████                                                                 | 3/16 [27:07<1:57:02, 540.16s/it]\u001b[A\n",
      " 25%|████████████████████                                                            | 4/16 [35:58<1:47:28, 537.37s/it]\u001b[A\n",
      " 31%|█████████████████████████                                                       | 5/16 [44:51<1:38:16, 536.08s/it]\u001b[A\n",
      " 38%|██████████████████████████████                                                  | 6/16 [53:58<1:29:54, 539.43s/it]\u001b[A\n",
      " 44%|██████████████████████████████████▏                                           | 7/16 [1:03:07<1:21:20, 542.25s/it]\u001b[A\n",
      " 50%|███████████████████████████████████████                                       | 8/16 [1:12:15<1:12:30, 543.82s/it]\u001b[A\n",
      " 56%|███████████████████████████████████████████▉                                  | 9/16 [1:21:49<1:04:30, 552.97s/it]\u001b[A\n",
      " 62%|█████████████████████████████████████████████████▍                             | 10/16 [1:31:23<55:55, 559.18s/it]\u001b[A\n",
      " 69%|██████████████████████████████████████████████████████▎                        | 11/16 [1:40:27<46:14, 554.83s/it]\u001b[A\n",
      " 75%|███████████████████████████████████████████████████████████▎                   | 12/16 [1:49:18<36:29, 547.44s/it]\u001b[A\n",
      " 81%|████████████████████████████████████████████████████████████████▏              | 13/16 [1:57:52<26:52, 537.39s/it]\u001b[A\n",
      " 88%|█████████████████████████████████████████████████████████████████████▏         | 14/16 [2:06:25<17:40, 530.11s/it]\u001b[A\n",
      " 94%|██████████████████████████████████████████████████████████████████████████     | 15/16 [2:15:34<08:55, 535.97s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 16/16 [2:24:46<00:00, 542.94s/it]\u001b[A\n",
      " 80%|████████████████████████████████████████████████████████████████                | 4/5 [2:32:01<45:04, 2704.78s/it]\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███████████████████████████▋                                                       | 1/3 [12:56<25:53, 776.98s/it]\u001b[A\n",
      " 67%|███████████████████████████████████████████████████████▎                           | 2/3 [26:33<13:08, 788.86s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [39:39<00:00, 793.03s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 5/5 [3:11:40<00:00, 2300.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'mse', 'max_depth': 22, 'n_estimators': 150, 'max_features': 'log2', 'loss': 'huber'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for param in tqdm(params):\n",
    "    train_r = []\n",
    "    test_r = []\n",
    "    train_MSE = []\n",
    "    test_MSE = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        clf = MultiOutputRegressor(GradientBoostingRegressor(**test_params))\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        train_r.append(round(clf.score(Xtrain, ytrain),3))\n",
    "        test_r.append(round(clf.score(Xtest, ytest),3))\n",
    "        train_MSE.append(round(mean_squared_error(ytrain, clf.predict(Xtrain)),3))\n",
    "        test_MSE.append(round(mean_squared_error(ytest, clf.predict(Xtest)),3))\n",
    "    best_params[param] = params[param][np.argmin(test_MSE)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "GradientBoostingRegressor(max_features='log2',n_estimators=150, random_state=0, max_depth=22,criterion='mse')\n",
    "#gradient_boosting_mdl = GradientBoostingRegressor(max_features='auto',n_estimators=100, random_state=0, max_depth=3,criterion='friedman_mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {#'criterion': ['mse', 'mae'],#'absolute_error', \n",
    "                            #'squared_error'],\n",
    "              'max_depth': [i for i in range(3,25)],\n",
    "              'n_estimators': [i for i in range(100, 500, 25)],\n",
    "              'max_features': ['auto', 'sqrt', 'log2']}\n",
    "best_params={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\n",
      "  0%|                                                                                           | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|███▊                                                                               | 1/22 [00:12<04:32, 12.96s/it]\u001b[A\n",
      "  9%|███████▌                                                                           | 2/22 [00:29<04:42, 14.14s/it]\u001b[A\n",
      " 14%|███████████▎                                                                       | 3/22 [00:49<05:01, 15.87s/it]\u001b[A\n",
      " 18%|███████████████                                                                    | 4/22 [01:13<05:26, 18.15s/it]\u001b[A\n",
      " 23%|██████████████████▊                                                                | 5/22 [01:40<05:53, 20.82s/it]\u001b[A\n",
      " 27%|██████████████████████▋                                                            | 6/22 [02:10<06:19, 23.71s/it]\u001b[A\n",
      " 32%|██████████████████████████▍                                                        | 7/22 [02:44<06:41, 26.77s/it]\u001b[A\n",
      " 36%|██████████████████████████████▏                                                    | 8/22 [03:22<07:00, 30.03s/it]\u001b[A\n",
      " 41%|█████████████████████████████████▉                                                 | 9/22 [04:02<07:11, 33.18s/it]\u001b[A\n",
      " 45%|█████████████████████████████████████▎                                            | 10/22 [04:46<07:17, 36.44s/it]\u001b[A\n",
      " 50%|█████████████████████████████████████████                                         | 11/22 [05:34<07:16, 39.70s/it]\u001b[A\n",
      " 55%|████████████████████████████████████████████▋                                     | 12/22 [06:24<07:08, 42.80s/it]\u001b[A\n",
      " 59%|████████████████████████████████████████████████▍                                 | 13/22 [07:18<06:55, 46.22s/it]\u001b[A\n",
      " 64%|████████████████████████████████████████████████████▏                             | 14/22 [08:15<06:35, 49.38s/it]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████████▉                          | 15/22 [09:14<06:05, 52.27s/it]\u001b[A\n",
      " 73%|███████████████████████████████████████████████████████████▋                      | 16/22 [10:13<05:27, 54.52s/it]\u001b[A\n",
      " 77%|███████████████████████████████████████████████████████████████▎                  | 17/22 [11:13<04:40, 56.11s/it]\u001b[A\n",
      " 82%|███████████████████████████████████████████████████████████████████               | 18/22 [12:15<03:50, 57.66s/it]\u001b[A\n",
      " 86%|██████████████████████████████████████████████████████████████████████▊           | 19/22 [13:17<02:56, 58.95s/it]\u001b[A\n",
      " 91%|██████████████████████████████████████████████████████████████████████████▌       | 20/22 [14:19<02:00, 60.08s/it]\u001b[A\n",
      " 95%|██████████████████████████████████████████████████████████████████████████████▎   | 21/22 [15:22<01:01, 61.00s/it]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [16:26<00:00, 44.85s/it]\u001b[A\n",
      " 33%|███████████████████████████▋                                                       | 1/3 [16:26<32:53, 986.60s/it]\n",
      "  0%|                                                                                           | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "  6%|█████▏                                                                             | 1/16 [00:15<03:56, 15.79s/it]\u001b[A\n",
      " 12%|██████████▍                                                                        | 2/16 [00:35<03:58, 17.04s/it]\u001b[A\n",
      " 19%|███████████████▌                                                                   | 3/16 [00:59<04:09, 19.19s/it]\u001b[A\n",
      " 25%|████████████████████▊                                                              | 4/16 [01:27<04:20, 21.74s/it]\u001b[A\n",
      " 31%|█████████████████████████▉                                                         | 5/16 [02:00<04:35, 25.03s/it]\u001b[A\n",
      " 38%|███████████████████████████████▏                                                   | 6/16 [02:37<04:45, 28.56s/it]\u001b[A\n",
      " 44%|████████████████████████████████████▎                                              | 7/16 [03:16<04:46, 31.85s/it]\u001b[A\n",
      " 50%|█████████████████████████████████████████▌                                         | 8/16 [04:00<04:42, 35.32s/it]\u001b[A\n",
      " 56%|██████████████████████████████████████████████▋                                    | 9/16 [04:47<04:32, 38.93s/it]\u001b[A\n",
      " 62%|███████████████████████████████████████████████████▎                              | 10/16 [05:38<04:15, 42.60s/it]\u001b[A\n",
      " 69%|████████████████████████████████████████████████████████▍                         | 11/16 [06:34<03:52, 46.45s/it]\u001b[A\n",
      " 75%|█████████████████████████████████████████████████████████████▌                    | 12/16 [07:33<03:21, 50.37s/it]\u001b[A\n",
      " 81%|██████████████████████████████████████████████████████████████████▋               | 13/16 [08:36<02:42, 54.17s/it]\u001b[A\n",
      " 88%|███████████████████████████████████████████████████████████████████████▊          | 14/16 [09:43<01:56, 58.02s/it]\u001b[A\n",
      " 94%|████████████████████████████████████████████████████████████████████████████▉     | 15/16 [10:54<01:01, 61.82s/it]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [12:09<00:00, 45.59s/it]\u001b[A\n",
      " 67%|███████████████████████████████████████████████████████▎                           | 2/3 [28:35<15:09, 909.43s/it]\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|████████████████████████████                                                        | 1/3 [00:27<00:55, 27.58s/it]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████                            | 2/3 [00:34<00:21, 21.27s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:39<00:00, 13.28s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [29:15<00:00, 585.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 4, 'n_estimators': 175, 'max_features': 'auto'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for param in tqdm(params):\n",
    "    train_r = []\n",
    "    test_r = []\n",
    "    train_MSE = []\n",
    "    test_MSE = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        clf = MultiOutputRegressor(RandomForestRegressor(**test_params))\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        train_r.append(round(clf.score(Xtrain, ytrain),3))\n",
    "        test_r.append(round(clf.score(Xtest, ytest),3))\n",
    "        train_MSE.append(round(mean_squared_error(ytrain, clf.predict(Xtrain)),3))\n",
    "        test_MSE.append(round(mean_squared_error(ytest, clf.predict(Xtest)),3))\n",
    "    best_params[param] = params[param][np.argmin(test_MSE)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf = RandomForestRegressor(criterion='mae',max_features='sqrt',n_estimators=100, random_state=0, max_depth=20)\n",
    "rf = RandomForestRegressor(criterion='mse',max_features='auto',n_estimators=175, random_state=0, max_depth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:03<00:00,  4.36it/s]\n",
      "  0%|                                                                                           | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_1 best value: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:03<00:00,  4.43it/s]\n",
      "  0%|                                                                                           | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_2 best value: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:03<00:00,  4.38it/s]\n",
      "  0%|                                                                                           | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_1 best value: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:03<00:00,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_2 best value: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vals = [10000, 100,1000,10,1,0.01,1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10]\n",
    "params = ['alpha_1','alpha_2','lambda_1','lambda_2']\n",
    "for param in params:\n",
    "    train_r = []\n",
    "    test_r = []\n",
    "    train_MSE = []\n",
    "    test_MSE = []\n",
    "    for val in tqdm(vals):\n",
    "        input_params = {param:val}\n",
    "        clf = MultiOutputRegressor(linear_model.BayesianRidge(**input_params))\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        train_r.append(round(clf.score(Xtrain, ytrain),3))\n",
    "        test_r.append(round(clf.score(Xtest, ytest),3))\n",
    "        train_MSE.append(round(mean_squared_error(ytrain, clf.predict(Xtrain)),3))\n",
    "        test_MSE.append(round(mean_squared_error(ytest, clf.predict(Xtest)),3))\n",
    "    print(param+\" best value:\", vals[np.argmin(test_MSE)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ridge = linear_model.BayesianRidge(alpha_1=10000, alpha_2=100, lambda_1=1, lambda_2=0.0001)\n",
    "ridge = linear_model.BayesianRidge(alpha_1=100, alpha_2=10000, lambda_1=100, lambda_2=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srandrad\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\dtypes.py:585: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object,\n",
      "C:\\Users\\srandrad\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\dtypes.py:627: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object,\n",
      "C:\\Users\\srandrad\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\dtypes.py:637: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool,\n",
      "C:\\Users\\srandrad\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:176: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object: SlowAppendObjectArrayToTensorProto,\n",
      "C:\\Users\\srandrad\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:177: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool: SlowAppendBoolArrayToTensorProto,\n",
      "C:\\Users\\srandrad\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\numpy_ops\\np_random.py:110: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def randint(low, high=None, size=None, dtype=onp.int):  # pylint: disable=missing-function-docstring\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dnn_with_reg(input_shape, num_neuron, reg, drop_rate=0.5):\n",
    "\n",
    "    # this is our input layer, we need to identify the shape of the input data\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    if reg == 'l1':\n",
    "        layer1 = keras.layers.Dense(num_neuron, activation='tanh',\n",
    "                                    kernel_regularizer=keras.regularizers.l1(0.01))(input_layer)\n",
    "        layer2 = keras.layers.Dense(num_neuron, activation='tanh',\n",
    "                                    kernel_regularizer=keras.regularizers.l1(0.01))(layer1)\n",
    "        #layer3 = keras.layers.Dense(num_neuron, activation='tanh',\n",
    "        #                            kernel_regularizer=keras.regularizers.l1(0.01))(layer2)\n",
    "    elif reg == 'l2':\n",
    "        layer1 = keras.layers.Dense(num_neuron, activation='tanh',\n",
    "                                    kernel_regularizer=keras.regularizers.l2(0.1))(input_layer)\n",
    "        #layer2 = keras.layers.Dense(num_neuron, activation='tanh',\n",
    "        #                            kernel_regularizer=keras.regularizers.l2(0.01))(layer1)\n",
    "        #layer3 = keras.layers.Dense(num_neuron, activation='tanh',\n",
    "        #                            kernel_regularizer=keras.regularizers.l2(0.01))(layer2)\n",
    "    elif reg == 'dropout':\n",
    "        layer1 = keras.layers.Dense(num_neuron, activation='tanh')(input_layer)\n",
    "        dropout1 = keras.layers.Dropout(rate=drop_rate)(layer1)\n",
    "        layer2 = keras.layers.Dense(num_neuron, activation='tanh')(dropout1)\n",
    "        #dropout2 = keras.layers.Dropout(rate=drop_rate)(layer2)\n",
    "        #layer3 = keras.layers.Dense(num_neuron, activation='tanh')(dropout2)\n",
    "        \n",
    "    output_layer = keras.layers.Dense(4)(layer1)#(layer3)\n",
    "\n",
    "    # then we define the entire model based on input and output\n",
    "\n",
    "    model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdl = build_dnn_with_reg(len(xcols), 100, reg='l2')\n",
    "\n",
    "optim = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "mdl.compile(optimizer=optim,\n",
    "                 loss='mse',\n",
    "                 metrics=['MeanSquaredError'#,'AUC',\n",
    "                         ])\n",
    "\n",
    "mini_batch=256\n",
    "num_epochs=1500\n",
    "# We define the learning rate decay as a callback\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.5)\n",
    "\n",
    "\n",
    "# now we are ready to train the model\n",
    "training = mdl.fit(Xtrain, ytrain,\n",
    "                       batch_size=mini_batch,\n",
    "                       epochs=num_epochs,\n",
    "                       validation_data=(Xval, yval),\n",
    "                       #callbacks=[reduce_lr],\n",
    "                   verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss and AUC\n",
    "plt.figure(figsize=(8, 6))\n",
    "FONT=14\n",
    "plt.plot(range(num_epochs), training.history['loss'], label='training loss')\n",
    "plt.plot(range(num_epochs), training.history['val_loss'], label='validation loss')\n",
    "plt.xlabel('Number of epochs', fontsize=FONT)\n",
    "plt.ylabel('Loss', fontsize=FONT)\n",
    "plt.legend(fontsize=FONT)\n",
    "plt.tick_params(axis='both', which='major', labelsize=FONT)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">MSE</th>\n",
       "      <th colspan=\"10\" halign=\"left\">R^2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">train</th>\n",
       "      <th colspan=\"5\" halign=\"left\">test</th>\n",
       "      <th colspan=\"5\" halign=\"left\">train</th>\n",
       "      <th colspan=\"5\" halign=\"left\">test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>injuries</th>\n",
       "      <th>str dam</th>\n",
       "      <th>str des</th>\n",
       "      <th>fatalities</th>\n",
       "      <th>average</th>\n",
       "      <th>injuries</th>\n",
       "      <th>str dam</th>\n",
       "      <th>str des</th>\n",
       "      <th>fatalities</th>\n",
       "      <th>average</th>\n",
       "      <th>injuries</th>\n",
       "      <th>str dam</th>\n",
       "      <th>str des</th>\n",
       "      <th>fatalities</th>\n",
       "      <th>average</th>\n",
       "      <th>injuries</th>\n",
       "      <th>str dam</th>\n",
       "      <th>str des</th>\n",
       "      <th>fatalities</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DNN</th>\n",
       "      <td>27.524</td>\n",
       "      <td>226.001</td>\n",
       "      <td>826.171</td>\n",
       "      <td>0.403</td>\n",
       "      <td>270.025</td>\n",
       "      <td>15.442</td>\n",
       "      <td>49.518</td>\n",
       "      <td>365.533</td>\n",
       "      <td>0.08</td>\n",
       "      <td>107.643</td>\n",
       "      <td>-0.393</td>\n",
       "      <td>-1.349</td>\n",
       "      <td>0.729</td>\n",
       "      <td>-3.238</td>\n",
       "      <td>-1.063</td>\n",
       "      <td>-0.324</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.799</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MSE                                                                  \\\n",
       "       train                                           test                    \n",
       "    injuries  str dam  str des fatalities  average injuries str dam  str des   \n",
       "DNN   27.524  226.001  826.171      0.403  270.025   15.442  49.518  365.533   \n",
       "\n",
       "                             R^2                                              \\\n",
       "                           train                                        test   \n",
       "    fatalities  average injuries str dam str des fatalities average injuries   \n",
       "DNN       0.08  107.643   -0.393  -1.349   0.729     -3.238  -1.063   -0.324   \n",
       "\n",
       "                                        \n",
       "                                        \n",
       "    str dam str des fatalities average  \n",
       "DNN   0.296   0.799     -0.294   0.119  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = {(str(score),str(model),str(metric)):[] for score in [\"MSE\",\"R^2\"] for model in [\"train\",\"test\"] for metric in ['injuries','str dam', 'str des', 'fatalities', 'average']}\n",
    "\n",
    "train_pred = np.around(mdl.predict(Xtrain)); train_pred[train_pred<0] = 0\n",
    "test_pred = np.around(mdl.predict(Xtest)); test_pred[test_pred<0] = 0\n",
    "\n",
    "train_score = np.around(r2_score(train_pred, ytrain, multioutput='raw_values'),3)\n",
    "cols[('R^2','train','injuries')].append(train_score[0]); cols[('R^2', 'train', 'str dam')].append(train_score[1])\n",
    "cols[('R^2','train','str des')].append(train_score[2]); cols[('R^2', 'train', 'fatalities')].append(train_score[3])\n",
    "cols[('R^2','train','average')].append(round(r2_score(train_pred, ytrain),3))\n",
    "\n",
    "test_score = np.around(r2_score(test_pred, ytest,multioutput='raw_values'),3)\n",
    "cols[('R^2','test','injuries')].append(test_score[0]); cols[('R^2','test','str dam')].append(test_score[1])\n",
    "cols[('R^2','test','str des')].append(test_score[2]); cols[('R^2','test','fatalities')].append(test_score[3])\n",
    "cols[('R^2','test','average')].append(round(r2_score(test_pred, ytest),3))\n",
    "\n",
    "train_MSE = np.around(mean_squared_error(ytrain, train_pred,multioutput='raw_values'),3)\n",
    "cols[('MSE','train','injuries')].append(train_MSE[0]); cols[('MSE', 'train', 'str dam')].append(train_MSE[1])\n",
    "cols[('MSE','train','str des')].append(train_MSE[2]); cols[('MSE', 'train', 'fatalities')].append(train_MSE[3])\n",
    "cols[('MSE','train','average')].append(round(mean_squared_error(train_pred, ytrain),3))\n",
    "\n",
    "test_MSE = np.around(mean_squared_error(ytest, test_pred,multioutput='raw_values'),3)\n",
    "cols[('MSE','test','injuries')].append(test_MSE[0]); cols[('MSE','test','str dam')].append(test_MSE[1])\n",
    "cols[('MSE','test','str des')].append(test_MSE[2]); cols[('MSE','test','fatalities')].append(test_MSE[3])\n",
    "cols[('MSE','test','average')].append(round(mean_squared_error(test_pred, ytest),3))\n",
    "\n",
    "\n",
    "columns = pd.MultiIndex.from_tuples([col for col in cols])\n",
    "results_df = pd.DataFrame(cols, columns=columns, index=['DNN'])\n",
    "#results_df['Model'] = ['DNN']\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 67%|████████████████████████████████████████████████████████                            | 2/3 [00:07<00:04,  4.61s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:47<00:00, 15.87s/it]\n",
      "  0%|                                                                                           | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "booster best value: gblinear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "  6%|█████▏                                                                             | 1/16 [00:05<01:25,  5.70s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 12%|██████████▍                                                                        | 2/16 [00:12<01:25,  6.12s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 19%|███████████████▌                                                                   | 3/16 [00:21<01:28,  6.81s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 25%|████████████████████▊                                                              | 4/16 [00:30<01:32,  7.70s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 31%|█████████████████████████▉                                                         | 5/16 [00:41<01:35,  8.68s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 38%|███████████████████████████████▏                                                   | 6/16 [00:54<01:37,  9.77s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 44%|████████████████████████████████████▎                                              | 7/16 [01:07<01:37, 10.87s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 50%|█████████████████████████████████████████▌                                         | 8/16 [01:22<01:35, 11.92s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 56%|██████████████████████████████████████████████▋                                    | 9/16 [01:37<01:31, 13.05s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 62%|███████████████████████████████████████████████████▎                              | 10/16 [01:54<01:25, 14.28s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 69%|████████████████████████████████████████████████████████▍                         | 11/16 [02:13<01:17, 15.47s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 75%|█████████████████████████████████████████████████████████████▌                    | 12/16 [02:32<01:06, 16.69s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 81%|██████████████████████████████████████████████████████████████████▋               | 13/16 [02:53<00:53, 17.92s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 88%|███████████████████████████████████████████████████████████████████████▊          | 14/16 [03:15<00:38, 19.12s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      " 94%|████████████████████████████████████████████████████████████████████████████▉     | 15/16 [03:38<00:20, 20.36s/it]C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\srandrad\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [04:03<00:00, 15.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators best value: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "params = {'booster': ['gbtree', 'gblinear', 'dart'], 'n_estimators': [i for i in range(100, 500, 25)]}\n",
    "tree_params = {'max_depth':[i for i in range(3,25)]}\n",
    "for param in params:\n",
    "    train_r = []\n",
    "    test_r = []\n",
    "    train_MSE = []\n",
    "    test_MSE = []\n",
    "    for val in tqdm(params[param]):\n",
    "        input_params = {param:val}\n",
    "        clf = MultiOutputRegressor(xgb.XGBRegressor(**input_params))\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        train_r.append(round(clf.score(Xtrain, ytrain),3))\n",
    "        test_r.append(round(clf.score(Xtest, ytest),3))\n",
    "        train_MSE.append(round(mean_squared_error(ytrain, clf.predict(Xtrain)),3))\n",
    "        test_MSE.append(round(mean_squared_error(ytest, clf.predict(Xtest)),3))\n",
    "    print(param+\" best value:\", params[param][np.argmin(test_MSE)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_mdl = xgb.XGBRegressor(booster='gblinear',n_estimators=150)#100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'criterion':['mse', 'mae', 'friedman_mse'],\n",
    "         'max_features':['auto', 'sqrt', 'log2'],\n",
    "         'splitter':['best', 'random']}\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|████████████████████████████                                                        | 1/3 [00:01<00:02,  1.10s/it]\u001b[A\n",
      " 67%|███████████████████████████████████████████████████████▎                           | 2/3 [08:30<02:33, 153.46s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [08:31<00:00, 170.37s/it]\u001b[A\n",
      " 33%|███████████████████████████▋                                                       | 1/3 [08:31<17:02, 511.12s/it]\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███████████████████████████▋                                                       | 1/3 [10:16<20:32, 616.24s/it]\u001b[A\n",
      " 67%|███████████████████████████████████████████████████████▎                           | 2/3 [12:48<07:56, 476.92s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [14:48<00:00, 296.31s/it]\u001b[A\n",
      " 67%|███████████████████████████████████████████████████████▎                           | 2/3 [23:20<10:24, 624.46s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████████▌                                         | 1/2 [02:36<02:36, 156.01s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [05:53<00:00, 176.92s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [29:13<00:00, 584.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'mae', 'max_features': 'sqrt', 'splitter': 'random'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for param in tqdm(params):\n",
    "    train_r = []\n",
    "    test_r = []\n",
    "    train_MSE = []\n",
    "    test_MSE = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        clf = MultiOutputRegressor(DecisionTreeRegressor(**test_params))\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        train_r.append(round(clf.score(Xtrain, ytrain),3))\n",
    "        test_r.append(round(clf.score(Xtest, ytest),3))\n",
    "        train_MSE.append(round(mean_squared_error(ytrain, clf.predict(Xtrain)),3))\n",
    "        test_MSE.append(round(mean_squared_error(ytest, clf.predict(Xtest)),3))\n",
    "    best_params[param] = params[param][np.argmin(test_MSE)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTreeRegressor(criterion='mae', max_features='sqrt', splitter='random')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'base_estimator':[None, DecisionTreeRegressor(criterion='mse', max_features='auto', splitter='random')],\n",
    "          'n_estimators':[i for i in range(50, 550, 50)],\n",
    "          'learning_rate':[1*((10)**(i)) for i in range(-4,3,1)],\n",
    "          'loss':['linear', 'square', 'exponential']\n",
    "         }\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:09<00:09,  9.49s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:37<00:00, 18.96s/it]\u001b[A\n",
      " 25%|█████████████████████                                                               | 1/4 [00:37<01:53, 37.93s/it]\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|████████▎                                                                          | 1/10 [00:27<04:08, 27.60s/it]\u001b[A\n",
      " 20%|████████████████▌                                                                  | 2/10 [01:21<04:45, 35.63s/it]\u001b[A\n",
      " 30%|████████████████████████▉                                                          | 3/10 [02:42<05:44, 49.20s/it]\u001b[A\n",
      " 40%|█████████████████████████████████▏                                                 | 4/10 [04:30<06:40, 66.79s/it]\u001b[A\n",
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [06:39<07:06, 85.34s/it]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████▏                                | 6/10 [09:13<07:03, 105.96s/it]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████████▍                        | 7/10 [12:15<06:26, 128.90s/it]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 8/10 [15:42<05:04, 152.11s/it]\u001b[A\n",
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 9/10 [19:35<02:56, 176.37s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [23:50<00:00, 143.00s/it]\u001b[A\n",
      " 50%|█████████████████████████████████████████▌                                         | 2/4 [24:27<15:11, 455.55s/it]\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|████████████                                                                        | 1/7 [00:38<03:52, 38.83s/it]\u001b[A\n",
      " 29%|████████████████████████                                                            | 2/7 [01:16<03:13, 38.63s/it]\u001b[A\n",
      " 43%|████████████████████████████████████                                                | 3/7 [01:54<02:33, 38.44s/it]\u001b[A\n",
      " 57%|████████████████████████████████████████████████                                    | 4/7 [02:33<01:55, 38.34s/it]\u001b[A\n",
      " 71%|████████████████████████████████████████████████████████████                        | 5/7 [03:00<01:10, 35.14s/it]\u001b[A\n",
      " 86%|████████████████████████████████████████████████████████████████████████            | 6/7 [03:07<00:26, 26.56s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [03:08<00:00, 26.91s/it]\u001b[A\n",
      " 75%|██████████████████████████████████████████████████████████████▎                    | 3/4 [27:36<06:15, 375.39s/it]\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|████████████████████████████                                                        | 1/3 [00:37<01:15, 37.56s/it]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████                            | 2/3 [01:16<00:38, 38.02s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:56<00:00, 38.85s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 4/4 [29:32<00:00, 443.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_estimator': DecisionTreeRegressor(max_features='auto', splitter='random'), 'n_estimators': 50, 'learning_rate': 0.1, 'loss': 'exponential'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for param in tqdm(params):\n",
    "    train_r = []\n",
    "    test_r = []\n",
    "    train_MSE = []\n",
    "    test_MSE = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        clf = MultiOutputRegressor(AdaBoostRegressor(**test_params))\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        train_r.append(round(clf.score(Xtrain, ytrain),3))\n",
    "        test_r.append(round(clf.score(Xtest, ytest),3))\n",
    "        train_MSE.append(round(mean_squared_error(ytrain, clf.predict(Xtrain)),3))\n",
    "        test_MSE.append(round(mean_squared_error(ytest, clf.predict(Xtest)),3))\n",
    "    best_params[param] = params[param][np.argmin(test_MSE)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_features='auto',\n",
       "                                                       splitter='random'),\n",
       "                  learning_rate=1, loss='square')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_features='auto', splitter='random'), n_estimators=50, learning_rate=1, loss='square')\n",
    "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_features='auto', splitter='random'), n_estimators=50, learning_rate=0.1, loss='exponential')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'alpha': [1*((10)**(i)) for i in range(-4,3,1)],\n",
    "         'learning_rate':['constant', 'invscaling', 'adaptive'],\n",
    "          'hidden_layer_sizes':[(50,), (50,50), (50,50,50), (100,), (100,100), (100,100,100)]}\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|███████████▊                                                                       | 1/7 [07:39<45:58, 459.81s/it]\u001b[A\n",
      " 29%|███████████████████████▋                                                           | 2/7 [14:38<36:16, 435.38s/it]\u001b[A\n",
      " 43%|███████████████████████████████████▌                                               | 3/7 [21:42<28:41, 430.49s/it]\u001b[A\n",
      " 57%|███████████████████████████████████████████████▍                                   | 4/7 [26:59<19:16, 385.46s/it]\u001b[A\n",
      " 71%|███████████████████████████████████████████████████████████▎                       | 5/7 [31:25<11:24, 342.36s/it]\u001b[A\n",
      " 86%|███████████████████████████████████████████████████████████████████████▏           | 6/7 [33:29<04:28, 268.15s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 7/7 [34:14<00:00, 293.54s/it]\u001b[A\n",
      " 33%|██████████████████████████▋                                                     | 1/3 [34:14<1:08:29, 2054.78s/it]\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███████████████████████████▋                                                       | 1/3 [05:15<10:31, 315.96s/it]\u001b[A\n",
      " 67%|███████████████████████████████████████████████████████▎                           | 2/3 [10:32<05:16, 316.47s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [15:49<00:00, 316.60s/it]\u001b[A\n",
      " 67%|██████████████████████████████████████████████████████▋                           | 2/3 [50:04<23:24, 1404.80s/it]\n",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|█████████████▊                                                                     | 1/6 [06:09<30:48, 369.62s/it]\u001b[A\n",
      " 33%|███████████████████████████▋                                                       | 2/6 [09:13<17:21, 260.41s/it]\u001b[A\n",
      " 50%|█████████████████████████████████████████▌                                         | 3/6 [12:09<11:05, 221.92s/it]\u001b[A\n",
      " 67%|███████████████████████████████████████████████████████▎                           | 4/6 [17:28<08:40, 260.06s/it]\u001b[A\n",
      " 83%|█████████████████████████████████████████████████████████████████████▏             | 5/6 [20:48<03:58, 238.56s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 6/6 [24:32<00:00, 245.34s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 3/3 [1:14:36<00:00, 1492.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.1, 'learning_rate': 'constant', 'hidden_layer_sizes': (100,)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for param in tqdm(params):\n",
    "    train_r = []\n",
    "    test_r = []\n",
    "    train_MSE = []\n",
    "    test_MSE = []\n",
    "    for val in tqdm(params[param]):\n",
    "        test_params = {param:val}\n",
    "        test_params.update(best_params)\n",
    "        clf = MultiOutputRegressor(MLPRegressor(random_state=0, max_iter=10000,**test_params))\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        train_r.append(round(clf.score(Xtrain, ytrain),3))\n",
    "        test_r.append(round(clf.score(Xtest, ytest),3))\n",
    "        train_MSE.append(round(mean_squared_error(ytrain, clf.predict(Xtrain)),3))\n",
    "        test_MSE.append(round(mean_squared_error(ytest, clf.predict(Xtest)),3))\n",
    "    best_params[param] = params[param][np.argmin(test_MSE)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{"Driving Event":"See attached PDF.","Lesson ID":26803}
{"Driving Event":"NASA's exoplanet Discovery mission Kepler was reconstituted as the K2 mission a year after the failure of the second of Kepler's four reaction wheels in 2013 May. Fine control of the spacecraft pointing is now accomplished through the use of the two remaining well-functioning reaction wheels and balancing the pressure of sunlight on the solar panels, which constrains K2 observations to fields in the ecliptic for up to approximately 80 days each.","Lesson ID":28903}
{"Driving Event":"During Ground Launch Sequencer (GLS) validation testing in Firing Room 1, a primary server failure occurred, which raised concerns about the LRS redundancy architecture. After further investigating the concerns, it was discovered that a failure of a Kennedy Ground Control Subsystem (KGCS) communications rack or Launch Control System (LCS) gateway late in launch countdown could result in the inability to safe the ICPS Ordnance Control Units (OCU\u2019s). Additionally, visibility of position indications for the LAS and Booster Ignition Safe and Arm circuits would be lost. It was concerning that issue was not identified sooner, especially since LRS had already completed Verification and Validation (V&V) testing and its Design Certification Review (DCR). The conclusion was that a full end-to-end \/ cross-subsystem redundancy and failure analysis was never performed. The analysis was only performed at the subsystem (LRS) level. Reference Figure 1, which shows the baseline design for the full end-to-end signal path (from the end item through LRS and back to KGCS). If only the LRS to end-item portion of the path is evaluated, it appears that the end items have proper redundancy. For instance, items 4, 5, and 6 can tolerate a failure of the LRS 36751 primary enclosure or the LRS 36752 secondary enclosure and still be operable. However, when following the signal path all the way back to KGCS or the LCS gateway, it can easily be seen that the 34613 communications rack or LCS Gateway 2 are single point failures that will result in complete loss of end items 4, 5 and 6. From a testing perspective, failure scenarios (i.e. loss of a PLC) were only tested at the LRS level and were not tested at the integrated level (i.e. loss of KGCS comm rack or LCS gateway). Figure 1 - LRS End Item Signal Path with Baseline Architecture There were two options to resolve the issue. The first involved reconfiguring how LRS interfaces with the end items - this would have involved extensive hardware and software modifications. The second option involved reconfiguring how KGCS interfaces with LRS \u2013 this involved swapping two fiber optic cables that connect KGCS to LRS and minor software updates. Ultimately, the latter option was chosen to resolve the issue. The updated end-to-end signal path can be seen in Figure 2. Figure 2 - LRS End Item Signal path with Modified Architecture","Lesson ID":28101}
{"Driving Event":"The successful 35-minute Jupiter Orbit Insertion (JOI) maneuver on July 4, 2016 allowed the planet Jupiter to capture the Juno spacecraft. The NASA\/Caltech Jet Propulsion Laboratory (JPL) then began preparing for the final major burn designed to change its orbit, with a period of 54 days, to its 14-day nominal operational science orbit. The final major burn to slow Juno and place the spacecraft in a tighter orbit around the planet (Figure 1) was planned as a period reduction maneuver (PRM), sometimes referred to for this mission as a Perijove Reduction Maneuver (although geometric perijove was not being changed by the maneuver). The PRM was intended as a regulated main engine burn in which both the fuel and oxidizer tank pressures are regulated during the burn by a helium pressurization system. This regulatory system is connected to the fuel and oxidizer tanks via passive check valves, and pyrolitic isolation valves in the oxidizer side (Figure 2). Figure 1. Juno\u2019s orbital grid During preparations for the Juno PRM on October 13, 2016, telemetry on tank pressure readings revealed an anomaly during the pre-PRM tank pressurization activity (Reference (1)). A series of check valves between the helium tank and the fuel tanks remained closed for about four minutes after imposition of a positive pressure difference that should have immediately opened them. Further review of telemetry showed the oxidizer check valves had also malfunctioned in the same mode but to a lesser extent during the first few minutes of the prior burn-- the JOI maneuver performed in July. The telemetry further showed unexpected gas-side pressure increases suggestive of unintended upstream flow when the oxidizer tank pressure exceeded the gas-side pressure during the Deep Space Maneuver (DSM-2) performed 45 months earlier. Figure 2. A simplified Juno Propulsion Subsystem block diagram. Juno utilizes a weight-saving and redundant approach to spacecraft propulsion, with a bi-propellant main propulsion system and a monopropellant Reaction Control System. The main propulsion system uses hydrazine as fuel and nitrogen tetroxide as oxidizer. Lower than expected pressures in either the fuel or oxidizer tanks can result in unintended oxidizer-to-fuel mixture ratios in the main engine during the burn, with potential effects ranging from under-performance (to nominal performance) to catastrophic failure. Hence, the \u201cstuck-closed check valve\u201d anomaly eventually led to a decision by the Juno project to forego the PRM altogether. The most likely cause for the pre-PRM fuel check valve anomaly was contamination, with the contaminant consisting of vapor fuel-oxidizer reaction products (FORP). The pre-JOI failure of the oxidizer check valve to immediately open is believed to be caused by excessive oxidizer exposure; but it could also be FORP contamination, with either possibility caused by an oxidizer leak failure that occurred in the previous maneuver (DSM-2). According to this scenario, the earlier oxidizer check valve leak failure (at DSM-2) produced excessive amounts of oxidizer in the gas side leading to: The oxidizer check valves sticking closed (at pre-JOI). The high oxidizer vapor content creating FORP at the fuel check valves. The FORP leading to the subsequent \u201cstuck closed check valve\u201d anomaly at pre-PRM. Because FORP contamination was a well\u2013known failure mode during Juno design and development, multiple safeguards, such as quad-redundant check valves and oxidizer-side pyrolitic isolation valves, were employed. But these measures were obviously insufficient. While an anomaly resolution team determined that the fuel tank could be pressurized and a main engine burn executed in a blowdown mode to execute the PRM-- even in the presence of the anomalous check valves-- the project elected to avoid the risk of possibly attaining a less-than-desirable orbit and remain in the 53-day capture orbit for the remainder of the Juno mission. The higher-than-planned orbital period does not affect the quality of the science collected by Juno during each flyby because the altitude over Jupiter is the same at the time of closest approach. In terms of the total quantity of science return, it has recently been announced (Reference (3)) that the Juno mission will be extended three years until at least July 2021 so it can complete the additional 18 perijoves needed to finish mapping Jupiter. Another outcome of the longer orbit is that Juno will spend less time within Jupiter\u2019s radiation belts on each orbit, reducing the accumulated radiation exposure of the spacecraft. References: \u201cPRM Pressurization Check Valve Issue,\u201d JPL Incident Surprise Anomaly (ISA) No. 60324, JPL-internal document, October 13, 2016. \u201cJuno Check Valve Anomaly Recovery Discussion,\u201d JPL-internal document, Juno Project, December 15, 2016. https:\/\/prs.jpl.nasa.gov\/NET\/DownloadAttachment.aspx?iAttachmentID=60144 (JPL internal access only). \u201cNASA Re-plans Juno's Jupiter Mission,\u201d Jet Propulsion Laboratory, June 6, 2018. https:\/\/www.jpl.nasa.gov\/news\/news.php?feature=7153 .","Lesson ID":28105}
{"Driving Event":"The MSFC stress analysis team was asked to perform a fatigue analysis early in the life cycle of the VFM activity. At the time, the engineering drawings were still preliminary. Nevertheless, the analysis team was asked to proceed at risk with performing fatigue analysis to the preliminary configuration. Sometime after the analysis was complete, the tube stub configuration was changed. The dimension of a radius in the VFM\u2019s sense tube was changed from \u201c0.05 inches\u201d to \u201c0.02 inches max\u201d (see Figure 1). This was motivated by a concern in having adequate straight section to enable orbital tube welding during the VFM\u2019s integration to the spacecraft assembly. However, the analysis team was not made aware of the change. Furthermore, the analysis team did not have formal signature authority during the release process, thereby missing an opportunity for the fatigue analysis to be corrected prior to initial release of the drawings. Figure 1: Location of Tube Stub Radius before left and after right final drawing release","Lesson ID":28202}
{"Driving Event":"In order to complete assembly of the Europa Clipper VFM component, the VFM team developed and qualified a weld procedure specification (WPS). This was done early in the product\u2019s life cycle and prior to completion of the VFM flight design. This required the team to attempt to represent the internal geometry of the VFM on a \u201cbest effort\u201d basis. Although AMS2680C only requires that the weld joint be represented, the team strived to include the features of the converging section of the VFM to account for the small amount of heat sink expected at the area below the weld root. After the weld failure occurred, it was determined that the test sample did not adequately represent the flight hardware weld. In fact, the amount of material below the weld root was half of what was expected. Therefore new weld parameters had to be developed to reduce the heat input of the weld and avoid melting the material at the weld root reinforcement. Though a design review was conducted for the approval of the final VFM design, the agenda did not include a comparison of the flight design to the weld test samples.","Lesson ID":28201}
{"Driving Event":"The gravitational force exerted on an object changes across the surface of a planet as well as above the surface, varying with latitude, altitude, and differences in the local topography. For example, the density of underlying rock or the presence of nearby mountains can produce a very small variation (on the order of 0.01% or less) in gravity. (Underlying rock would mostly affect the vertical velocity of a falling object, whereas a nearby mountain would mostly affect horizontal velocity.) In comparison, the gravitational variations attributable to latitude may be over 50 times as significant as local topography. The apparent reduction in gravity or weight with altitude can even affect the cruise performance of high performance terrestrial aircraft (Reference (1)). The novel and successful \u201csky crane\u201d descent of the MSL rover in August 2012 was designed to attain a soft landing on Mars. As with MSL, the similar Mars 2020 (M2020) rover being built by the NASA\/Caltech Jet Propulsion Laboratory (JPL) will have many components that have limited margin for dynamic loading during touchdown. Consequently, inaccurate estimation of vertical or horizontal touchdown velocity could result in damage to the rover during the landing. The onboard gravity estimate for the MSL Descent Stage (aka \u201cSky Crane\u201d) terminal maneuver, a sequence which began with rover separation at 21 meters above the Mars surface and ended in rover touchdown, was based on a coarse geopotential (gravity) model without local gravity effects. However, post-landing analysis of the maneuver revealed both vertical and horizontal velocity errors that were substantially attributable to errors in gravity estimates (References (2) and (5)): Vertical. The prediction for vertical touchdown velocity was 0.75 meters\/second (\u00b1 0.1 m\/s 3-sigma). The actual MSL vertical touchdown velocity was 0.63 m\/s. Horizontal. The prediction for horizontal touchdown velocity was 0 m\/s (\u00b1 0.11 m\/s 3-sigma). The actual MSL horizontal touchdown velocity was 0.18 m\/s (Figure 1). The dust-related \u201csandy radar\u201d effect (i.e., unknown variations in soil conditions that may cause significant data outliers among the radar measurements) was also a contributor to the horizontal velocity error, though to a lesser extent than local gravity contamination. Figure 1. MSL \u201cSky Crane\u201d maneuver In retrospect, it\u2019s understood that these estimates were made with an oversimplified model. This is what took place as far as touchdown velocities during the MSL landing according to the EDL reconstruction and the MSL NavFilter design: By design after rover separation at 21 m altitude, only two of the six Terminal Descent Sensor (TDS) antennas were used by the NavFilter to estimate the spacecraft 3-axis ground-relative velocity, forcing the NavFilter to propagate vertical velocity using only the Inertial Measurement Unit (IMU) accelerometer measurements and a model of gravity. This gives lower accuracy than an approach that includes TDS measurements in the vertical velocity estimate. Estimating the vertical velocity from TDS measurements would have required at least one more active TDS antenna. The switch from six to two TDS antennas at rover separation was dictated by the concern of RF multipath effects from the deployed rover that would have affected the four TDS antennas which were switched off. The horizontal velocity was estimated by the two SkyCrane TDS antennas and the NavFilter also estimated horizontal gravity model errors \u2014 making it insensitive to them. Not only do errors in the vertical gravity model in the on-board filter produce errors in the vertical velocity estimate but those errors also couple into the horizontal channel through the geometry of the TDS SkyCrane antennas. Since those antennas were close to 45 degrees from the vertical, this coupling was 1-to-1: thus, for example, a 0.1 m\/sec of vertical velocity estimation error would translate to about 0.1 m\/sec error in the estimate of horizontal velocity. The MSL landing site was in Gale Crater: such large impact craters are consistent with dense underlying mass concentrations and gravitational anomalies (Figure 2) that locally deviate from the coarse gravity model. MSL\u2019s actual gravitational acceleration differed from the on-board coarse gravity model-based estimate by ~ 4.5 mm\/sec2 (0.12% of Mars-G), resulting in an unintended vertical acceleration of ~4.5 mm\/s2. This small difference when applied over the last ~18 seconds of the flight with two TDS antennas resulted in a touchdown vertical velocity error of -0.088 m\/s, which is approximately equal to the 3-sigma uncertainty. As mentioned above, due to the coupling between the vertical and horizontal channels, about the same velocity estimation error existed in the horizontal channel due to the on-board vertical-axis gravity model error. Figure 2. Map of Gale Crater surface gravity anomalies. MSL landed near the outer boundary of the upper left reddish area. Factors during the MSL EDL\/GN&C design that contributed to this flight anomaly and its importance: A small trade study was conducted by JPL\u2019s MSL Guidance, Navigation, and Control (GN&C) team to figure out the correct order of the on-board gravity model. The team started with the gravity model used in the Mars Viking and Mars Phoenix projects, which was a J2 gravity model, and tested it against a simulation with a higher order truth gravity model (J3). This test showed that the errors of the simple J2 gravity model against the J3 truth model were negligible and decided to keep the same on-board gravity model as Viking and Phoenix. The mistake in this study was to assume that the gravity model error between the on-board J2 model and the J3 truth gravity model was larger than the largest of Mars gravity anomalies. This was far from being the case for the Gale Crater gravity anomaly. Not only was the crude J2 model not adequate for that landing site, but even the MRO110C Mars gravity model, which is of 110th order, modeled only half of the gravity anomaly experienced by MSL on landing day. Only the MGM2011 gravity model, developed by Curtin University's Western Australian Centre for Geodesy, and that uses MOLA surface topography in its derivation, covers the full gravity anomaly experienced by MSL. It is also important to note that the Gale Crater gravity anomaly represents a ~3-sigma high anomaly when compared to all the other landing sites on Mars. At an early phase of EDL development, the independent POST verification and validation (V&V) team did run the EDL simulation with a much higher order gravity models (MRO 85x85) in the truth side against the J2 gravity model in the on-board NavFilter and did not uncover any statistically incorrect touchdown velocity errors that would have challenged the approximation in the on-board gravity model. It is not clear at this point whether the \u201cnegative\u201d result was due to the fact that at that early stage we did not have the complete end-to-end EDL\/GN&C flight software for the gravity model error to manifest itself or because the runs were done with a landing site that had a negligible gravity anomaly. In any case, this \u201cnegative\u201d result reinforced the incorrect belief that Mars gravity anomalies were negligible as far as the performance of MSL EDL\/GN&C. Later in the EDL development, because the Monte Carlo runs with the MRO 85x85 gravity model took much longer times, it was decided to switch back to the J3 gravity model to expedite the multiple Monte Carlo studies that were being carried out as part of the overall EDL V&V campaign. Perhaps performing a Monte Carlo run with the MRO 85x85 truth gravity model and with the Gale Crater landing site would have caused the EDL\/GN&C team to rethink their incorrect perception on the relevance of the Mars gravity anomalies, despite that model only covering half of the effect of the actual gravity anomaly. [This paragraph describes the JPL design approach to making the MSL Descent Stage performance, including the TDS and the NavFilter, robust to gravity model errors. It has been redacted for International Traffic in Arms Regulations (ITAR) compliance. \u201cU.S. Persons\u201d may obtain a copy of the complete document, including this redacted paragraph, by contacting either Michelle Drabik at michelle.drabik@jpl.nasa.gov, or the JPL Office of the Chief Engineer.] The MSL rover was originally required to survive vertical touchdown velocities of up to 1m\/sec without mechanical damage. This rover requirement was compared against a 3-sigma maximum GN&C vertical velocity requirement of 0.85 m\/sec. This would have provided a generous margin in the capability of the system (GN&C provides < 0.85 m\/sec touchdown velocity and the rover handles up to 1 m\/sec touchdown velocity). However, by the day of launch, the rover maximum touchdown vertical velocity was downgraded to 0.85 m\/sec, eroding all the margin held at the system level, and making the effects of the gravity anomaly experienced by MSL potentially more serious, had the sign been in the opposite direction. Given that MSL required a one order of magnitude reduction in the touchdown velocity dispersions relative to the Mars Viking, Mars Phoenix, and Mars InSight projects, some system margins should have been kept all the way to landing day. Summarizing: The EDL\/GN&C team did not appreciate during the design and the V&V phases of MSL that there existed gravity anomalies on Mars large enough to have a significant effect on the rover touchdown velocity if not represented properly in both the on-board and simulation gravity models. This shortcoming can be classified perhaps as an unknown-known: the community of Mars gravity experts actually had a non-statistical model of gravity that fulfilled the needs of MSL, but the MSL EDL\/GNC team did not know of its importance for achieving the very low touchdown velocity required by a SkyCrane rover landing. Therefore, the team did not seek the engagement of that community. (Notice that this is not the case of a day-of-landing-unknown, like wind velocities, which require a statistical model to represent them in a Monte Carlo simulation; here the gravity model was known by a community of gravity experts with high certainty). The original design principle of measuring directly 3-axis ground-relative velocity with the TDS all the way until touchdown, which would have made the NavFilter much less sensitive to gravity model errors, was abandoned-- perhaps without the proper risk analysis. The original system margin between the maximum touchdown velocity delivered by the EDL\/GN&C design and the capability of the rover to survive it undamaged was allowed to degrade through the design cycle. This was particularly troublesome given that MSL was attempting a one-order-of-magnitude reduction in touchdown velocity dispersions as compared to previous soft-landers. References: W. J. G. Pinsker, \u201cThe Effect of Variations in Local Gravity and of Aircraft Speed on the Effective Weight of Aircraft in High Performance Cruise,\u201d U.K. Ministry of Defence, 1972. Steve Sell, Ravi Prakash, Fred Serricchio, Allen Chen, et al., \u201cTouchdown Velocity Issue,\u201d JPL-internal document, April 29, 2013. Adam D. Steltzner, A. Miguel San Martin, Tommaso P. Rivellini, Allen Chen, and Devin Kipp, \u201cMars Science Laboratory Entry, Descent, and Landing System Development Challenges,\u201d Journal of Spacecraft and Rockets, Vol. 51, No. 4, July\u2013August 2014. Adam Steltzner & Allen Chen, \u201cMars Science Laboratory Entry, Descent and Landing Case Study,\u201d JPL-internal document, October 20, 2015. \u201cMSL Touchdown Velocity Error,\u201d JPL Incident Surprise Anomaly (ISA) #54993, September 5, 2013.","Lesson ID":27901}
{"Driving Event":"Soil Moisture Active Passive (SMAP) is an Earth-orbiting observatory designed to create global, high-resolution mapping of soil moisture and its freeze\/thaw state. SMAP consists of a 3-axis stabilized spacecraft bus and a spun instrument assembly (SIA) (Figure 1). The SMAP science instrument payload consists of an L-band radiometer provided by the NASA Goddard Space Flight Center and an L-band radar provided by the NASA\/Caltech Jet Propulsion Laboratory (JPL). Figure 1. SMAP on-orbit architecture On July 7, 2015, the radar portion of the SMAP Radar\/Radiometer instrument failed in a high-energy proton rich portion of the orbit called the South Atlantic Anomaly (SAA), after two months of nominal science operations. The project team attempted to recover radar operability, but was unsuccessful. The SMAP project determined that the failure was in the radar LVPS. JPL convened a Failure Review Board (FRB), which issued a report (Reference (2)) concurring with the conclusion that the failure is located within the radar\u2019s LVPS. However, in the course of the investigation the FRB was unable to identify a single specific proximate cause or root cause of the failure. Instead, Reference (2) states on Page 1, \u201cit is clear that the failure of the SMAP Radar LVPS likely resulted from an interaction among several contributing causes, any one of which may or may not have directly resulted in a failure if it had occurred in isolation In effect, this failure was a circumstance that managed to evade the integrated set of checks and balances put in place to ensure mission success.\u201d However, additional testing conducted subsequent to the completion of Reference (2) revealed a likely proximate cause of the radar failure (Reference (3)) \u2014 still within the LVPS. The investigation revealed that back voltage (i.e., counter-electromotive force, or CEMF) resulting from leakage inductance in the load transformer in the LVPS circuit caused voltage spikes that significantly exceeded the 250 V rated voltage applied between the source and drain of the MOSFET. (All transformers produce leakage inductance, the amount and adverse effects subject to design tradeoffs.) MOSFETs are known to be vulnerable to Single-Event Burnout (SEB) and Single-Event Gate Rupture (SEGR) when, and only when, a MOSFET\u2019s drain-to-source voltage exceeds a failure threshold. To verify that the SMAP on-orbit anomaly could have been caused by this condition, nine power MOSFETs were tested for heavy-ion induced Single-Event Effect (SEE) failures on April 11, 2016. Another nine were tested for protons using a different radiation facility on June 10, 2016. To ensure flight-like testing, both sets of tests used the SMAP LVPS breadboard assembly (Figure 2). The tested parts were not from the flight lot; however, they were verified by the manufacturer to have been made from the same mask set of a high-reliability foundry, so SEE response was expected to be very similar, or identical, to the flight lot. SEE response is tightly controlled by the manufacturer, so lot-to-lot process variations matter very little. Thus, Reference (3) concludes that the SEE response of the tested devices is representative of the flight lot. Once the manufacturer\u2019s voltage rating was exceeded in the course of the tests, all 18 irradiated test parts exhibited catastrophic SEE, identified as single-event burnout (SEB), which resulted in circuit failure. Figure 2. SMAP LVPS breadboard circuit. MOSFET device is circled in red The amount of proton radiation fluence estimated over the 208 days of total spacecraft orbital exposure results in a failure likelihood that supports the conclusion that it suffered a radiation-related failure. The characterization that the anomaly was a radiation-induced destructive Single Event Effect (SEE) is supported by the instantaneous onset of the on-orbit failure. References: \u201cSMAP SAR HPA turned off unexpectedly,\u201d JPL Incident Surprise Anomaly (ISA) No. 58469, July 7, 2015. JPL \u201cSoil Moisture Active Passive (SMAP) Failure Review Board Report,\u201d April 22, 2016. Leif Scheick, et al, \u201cSingle-Event Testing of the IRHMS57264SE power MOSFET in the Low Voltage Power Supply Circuit for SMAP,\u201d JPL-internal test report, October 18, 2016. The as yet unpublished lesson learned that covers the JPL FRB report will be referenced here. (To obtain a copy of a lesson learned reference, contact Michelle Drabik or the JPL Office of the Chief Engineer.)","Lesson ID":27701}
{"Driving Event":"Recent designs of pyro control circuits utilized D Flip-Flops (F\/Fs) to latch critical signals that must persist after loss of main power. These F\/Fs and subsequent logic, control the MOSFETs used to fire the pyro initiator. These designs used discrete D-type F\/Fs in the configuration shown in Fig. 1 to latch the incoming signal that was applied to the clock line (CP) input. Figure 1: Sensitive Latching Circuit One circuit inadvertently fired a pyro during a pyro shock test and the sensitivity of this configuration was deemed to be a contributor to root cause.","Lesson ID":27003}
{"Driving Event":"The CERES FM-6 instrument includes three sensor assemblies that all use the ICM for internal calibration. The Short-Wave Internal Calibration Source (SWICS) includes a lamp, a Circuit Card Assembly (CCA), mirror, and photodiode. As shown in Figure 1, the photodiode views the SWICS tungsten filament lamp via a hole in the fold mirror through a band pass filter (700nm-800nm) mounted in front of the photodiode can. Figure 1. SWICS Lamp and Monitor Photodiode During baseline instrument calibration in May 2012, performance issues were observed for the SWICS. As seen in Figure 1, the lamp output can be observed by both the short-wave sensor itself and the monitor photodiode. During the 45 day calibration campaign, the short-wave sensor indicated that the lamp was brightening approximately 0.02%\/day. During that same time, the monitor photodiode indicated dimming of approximately -0.03%\/day. It should be noted that the photodiode is a relatively narrowband measurement, sensitive in the range 700nm to 800nm while the broadband short-wave sensor measures 300nm to > 3\u03bcm. An extensive investigation ruled out the electronics and many other possible root causes. The investigation discovered and corrected filter assembly issues that turned out to not be significant enough to be the root cause for the observed problem. Eventually, the SWICS lamp assembly\u2019s translucent DC93-500 RTV was determined to be a critical part of the optical path. As shown in Figure 2, rays emitted from the back of the lamp filament scatter forward into the SWICS optical train from the flat surface behind the bulb housing. Because of the location of the flat surface with respect to the lenses, more light scattered from the flat surface reaches the SWICS photodiode than the short-wave sensor. In fact, nearly half of the photodiode signal comes from reflections off the back plane of the lamp housing. Hence, the photodiode output is much more sensitive to physical changes in the RTV and changes in the material properties of the RTV than the short-wave sensor. Physical changes in the RTV that could vary over time include debonding from the lamp housing, void\/bubble movement and mold deformation with temperature. In addition, material transmission changes in the RTV due to outgassing under vacuum could have a larger impact on the photodiode because of the narrower spectral sampling. Therefore, the evidence points to photodiode sensitivity to physical changes in the RTV and changes in the RTV optical properties as the root cause for the ICM instability.","Lesson ID":27001}
{"Driving Event":"The loss of Advanced Baseline Imager (ABI) cooling capability seen on the GOES-17 weather satellite soon after its launch in March 2018 resulted in a thorough investigation of the loop heat pipe (LHP) thermal control system. One of the possible proximate causes investigated was that NCG-supported vapor bubbles might have blocked the flow regulators that are present at the end of each of the five parallel LHP condenser legs. Since anomalous performance was seen in ground tests of the GOES-17 LHPs, the physics of bubbles in the slow moving liquid (on the order of 1.5 m\/s or 5 ft\/min) was investigated. It was determined that when the radiator was tested on edge and some flow paths were vertical: Counterflow would exist in the vertical condenser passages, meaning that bubbles would not be transported through the serpentine condenser flow passage to the flow regulators. It was determined that when the radiator was tested horizontally and all flow paths were horizontal: Even large vapor bubbles would not fill the tube completely \u2013 leaving a liquid flow path underneath. This plus the fact that the flow regulator was located below the condenser tube eliminated the possibility of bubble transport to the flow regulator. In 0-g, large bubbles would fill the condenser tube and would be transported to the flow regulator with the liquid flow. The difference in behavior means that the effect of large NCG-supported vapor bubbles would be very different in 0-g and in 1-g.","Lesson ID":26703}
{"Driving Event":"While working on an open expander cycle engine that MSFC had been developing for several years, a turbomachinery design engineer had difficulties designing the fuel pump around potential stall instabilities. The design engineer was referencing engineering design practices from a common centrifugal pump design and performance text book. The text book was \u201cCentrifugal Pump Design and Performance\u201d by David Japikse, William Marscher and Raymond Furst. 2006 edition. The design engineer consulted with a fluid dynamics engineer who had more experience with unsteady fluid dynamics and instabilities on turbopumps. The fluids engineer consulted his copy of \u201cCentrifugal Pump Design and Performance\u201d by David Japikse, William Marscher and Raymond Furst, 1997 edition and ran a simulation. By deriving information from data given in the 1997 book and by plugging in the some dimensions and speeds, the data and trend line predicted a 3-lobed rotating stall. The conclusion was that the design engineer had designed the diffuser right on top of a 3-lobed ~200 psi rotating stall. The fluids engineer familiar with the instabilities asked the design engineer why he hadn\u2019t used the book to guide the design of the fuel pump. The design engineer brought his book over and showed that the instability information didn\u2019t exist in his book, nor did any data or detailed information on the instabilities for that section. The newer (2006) version of the book had all the data, empirical data, and some explanations removed. The 1997 version of the book had been handed down to the fluid dynamics engineer from a more senior lead engineer who had left the fluid dynamics branch. As stated by the fluids engineer, \u201cWhen [the Team Lead in the Branch] left to [go to another organization] back in 2008, I inherited a couple cabinets full of pump and turbine papers, data, including a bunch of SSME stuff and this [1997] book. ..[The team lead who left] was not the team lead when we worked on the pump design that had the instability, which [consequently] shed light on the book issue. .. When I left [the Turbomachinery Branch], I held onto the book and a few of the old pieces of 1970s data and a couple of pictures from back then. There wasn\u2019t anyone to pass it to that wanted the rest so I shredded it. Since then, most of those people have left the [Turbomachinery] branch to pursue opportunities elsewhere and [there was] not a lot of work on the horizon in that branch. I expect that there are a few people left around here that have that data in cabinets, whether they know it or not, and a couple people may at least know that it exists and where to find it. I would expect the data is also scattered around in various old journals that are available online. The real problem is knowing where to access the data.\u201d","Lesson ID":25701}
{"Driving Event":"ECOSTRESS is one of a new class of low-cost, rapid-development, NASA science instruments. Delivered to the International Space Station (ISS) in July 2018, it will measure the temperature of plants growing in specific locations on Earth over the course of a solar year. During system-level Electromagnetic Interference and Compatibility (EMI\/EMC) testing in the summer of 2017, the ECOSTRESS payload was also tested for Power Quality (PQ), a requirement levied from Reference (1) for electrical hardware that interfaces with the ISS. This test was the first standard system-level PQ test for an ISS payload conducted at JPL. Efforts to develop this test capability began two years prior on a part-time basis, given limited EMC personnel availability and a tight project budget. Key prerequisites were acquiring the necessary test equipment for input impedance measurement and developing all the various transient waveforms and power conditions specified in Reference (1). Because correspondence with counterparts at NASA Johnson Space Center (JSC) and NASA Marshall Space Flight Center (MSFC) was limited, interpretation of the test requirements was largely left up to JPL EMC personnel. By the spring of 2017, training on impedance measurement was provided by JSC\u2019s ISS Power Laboratory, along with clarification on some of the other PQ test issues. PQ testing at JPL (Figure 1) included the following: Surge and Inrush Current Limits Reverse Current Small Signal Stability and Constraints on Input Impedance Large Signal Stability Interface C (i.e., one of several power distribution tests used for ISS science payloads) at Normal and Non-Normal Power Conditions Compatibility with Soft Start\/Stop and Current Limiting Remote Power Controller Figure 1. ECOSTRESS Integration and Test personnel unwrap payload in the EMC anechoic chamber at JPL Despite the PC test capability startup challenges, the majority of tests were performed adequately with a mix of compliant and non-compliant results (i.e. impedance out-of-spec). For some tests, the verification seemed incomplete (e.g., oscilloscope capture timescale too short for large signal stability), but the data from other PQ tests on ECOSTRESS and OCO-3 indicated full compliance. One test error occurred during reverse current because the current probe was clamped in the wrong position and thus captured non-representative results. But this was alleviated through proper testing of the OCO-3 power converter unit, which is similar to ECOSTRESS\u2019s. One particular test that raised the concern of the ECOSTRESS team was Interface C at Normal\/Non-Normal Power Conditions, because the test procedure called for power cycling after each transient condition. Testing was halted midway, and a meeting between Assembly, Test, and Launch Operations (ATLO), payload power, and EMC personnel convened to discuss risks of such a test approach. The designers of the converter unit found the numerous power cycles acceptable, but ATLO preferred they be minimized. The transient tests were modified so they occurred in one long sequence with significant gaps of steady power in between to give the ECOSTRESS team time to identify any susceptibilities and for the EMC team to capture all required waveforms. The new test sequence was rehearsed on a load resistor. The change was then redlined accordingly, with approval from both ECOSTRESS and the EMC team, and the remaining power conditions were simulated without payload-related issues. PQ testing was completed on schedule, and the test results were reviewed and accepted by the ECOSTRESS project, JPL EMC, and partners at JSC. The appropriate waivers\/tailoring interpretation agreements (TIAs) with JSC, MSFC, and the Japanese Space Agency (JAXA) were made based on the EMC and PQ test report (Reference (2)). References: Space Station Protocol (SSP) 52051 (Rev B), User Electric Power Specifications and Standards - 120Volt DC Loads, Vol. ECOSTRESS EMI\/EMC\/Power Quality Test Report, M. Soriano, Jet Propulsion Laboratory IOM 5137-17-066A, March 9, 2018. ECOSTRESS SMA Lessons Learned, H. Kwong-Fu, June 21, 2018. JPL Design Principles, Rev. 7, JPL DocID 43913, March 27, 2018, Paragraph 8.1.3.","Lesson ID":26303}
{"Driving Event":"The SSC Fire Department (FD) serves as first responders for fire, emergency and emergency medical services (EMS) for the center and was on scene within six minutes of the first alarm. The FD laid two fire hoses, one from a water hydrant located near the northeast corner of Building 1100 and one from a standpipe on the 2nd floor to the fire on the 3rd floor. The fire was brought under control within 15 minutes of the initial attack by the FD. For the fire to occur, one event and two conditions had to be met and were identified as the three Proximate Causes: an ignition event, available fuel, and an adequate oxygen supply. This process identified undersized and improperly routed extension cords as the most likely ignition source. These results were fed into the E&CF tool for additional assessment. An E&CF Tree was generated based on the three Proximate Causes (see Figure 1, Events and Causal Factors Tree). Each Proximate Cause was developed to examine all reasonable or possible hypotheses for how the mishap might have occurred, and to systematically rule out as many alternatives as the evidence allowed. Based on evidence at the scene, the fire originated in an asbestos decontamination station, which was a wood-framed enclosure covered with six mil. plastic. The station was not in use on the day of the mishap. All elements required for a fire were present in the area: oxygen at normal levels, combustibles, and potential ignition sources that included task lighting, equipment and extension cords. Utilizing the investigative approach above, the source of ignition for the fire was determined to be undersized and improperly routed extension cords. Three Root Causes and two Contributing Factors were identified, resulting in seven Recommended Corrective Actions","Lesson ID":5437}
{"Driving Event":"The SAGE III project performed sine burst tests on the IAM to verify an acceleration loads requirement. Originally, the IAM was designed with the CMP installed directly to the top of the IAM. (See Figure 1 for nomenclature and general configuration. All figures are from the SAGE III-10-054-TR-001 IAM SN002 Protoflight Vibration Test Report \u2013 modified to emphasize features of relevance for this submission). Figure 1 SAGE III Configuration Vibration testing of the IAM Engineering Development Unit (EDU) was performed using a CMP mass model installed directly to the top of the IAM EDU and there were no issues during the sine bursts. The predicted vehicle flight vibration loads increased around the same time as the IAM EDU test, leading to higher than acceptable vibration responses for the CMP sensors on top of the IAM. This required a redesign to include wire rope isolators between the IAM and CMP, which reduced vibration levels on the CMP sensors but also introduced additional low frequency lateral modes of the CMP. The IAM flight unit vibration test was performed with a CMP mass model installed to the top of the IAM using wire rope isolators, and the low frequency lateral modes of the CMP mass model caused difficulties during the sine burst testing. Standard practice during sine burst testing is to perform the test at less than one-third of the first resonant frequency of the test article to avoid dynamic amplification [NASA-STD-7008 Section 5.4.1.3]. During testing of the IAM flight unit, the resonant frequency of the CMP mass model on isolators was identified during low level sine sweeps as 34 Hz or higher for lateral axis testing, and the sine burst frequency in those axes was 11 Hz [SAGE III-10-054-TR-001]. This would appear to meet the requirement of being less than one-third of the first resonant frequency, but the wire rope isolators have nonlinear stiffness and damping characteristics, so the predictions from the low level sine sweeps do not apply to higher amplitude tests such as sine bursts. This behavior of the wire rope isolators was generally understood and accounted for in pre-test analysis, but the actual response of the CMP mass model during the sine burst tests had more displacement than expected. The first sine burst in a lateral axis resulted in a wire rope of one of the isolators contacting one of the accelerometers. The accelerometer was moved prior to the second test to avoid contact. Another observation during the first sine burst was that the contamination control bag placed around the IAM (see Figure 2) was also covering the CMP mass model, which resulted in the bag being pulled taut several times during the sine burst. The contamination control bag was modified to only cover the IAM for the remaining tests (See Figure 3), leaving the CMP mass model and wire rope isolators free to move without restriction for the following test. Figure 2 X-Axis setup with contamination control bag covering CMP (located near side on top) Figure 3 Y-Axis setup with contamination control bag NOT covering CMP (visible on top) The second sine burst in a lateral axis exhibited displacements of a similar magnitude to the first sine burst due to dynamic amplification, but there was no contact of wire ropes with other hardware or instrumentation during that test. The final sine burst in the vertical axis had very little dynamic amplification and the CMP mass model response closely matched the input.","Lesson ID":25801}
{"Driving Event":"Failure of the second of four reaction wheels during Kepler mission.","Lesson ID":25504}
{"Driving Event":"Failure of the second of four reaction wheels on the Kepler mission in 2013.","Lesson ID":25503}
{"Driving Event":"The Kepler mission was launched in April of 2009 into an Earth-trailing orbit with the goal of searching for Earth-sized planets in the habitable zone around sun-like stars. The Kepler mission completed its primary mission in November of 2012 and was approved for an extended mission two years beyond that, with the option of two more if the spacecraft remained healthy. Lessons were learned over an extended period of time during Kepler\/K2 Mission Ops. The date shown is roughly at the Kepler\/K2 transition.","Lesson ID":25505}
{"Driving Event":"The Exploration Systems Development\/ Exploration Ground Systems (ESD\/EGS) Program contracted with recognized aerospace consultants for the analysis of Space Launch System\/Multi-Purpose Crew Vehicle (SLS\/MPCV) launch vehicle launch availability analyses. With the scope of deliverables limited to just the analysis results, there was limited understanding of the model upon which the analyses were accomplished. Additionally, little in the way of official model documentation was required or produced (e.g., model design documentation including assumptions, results of model testing, model user\u2019s guide). The situation was exacerbated by the lack of internal subject matter expertise for the analyses. As such, some results from analyses with the M&S were questioned, which stemmed at least in part from a lack of understanding of what was included in the model and how it worked.","Lesson ID":25509}
{"Driving Event":"The heritage HPIW valve configuration is Flexflo valves, which are plumbed to the Fail-Open position, requiring actuation pressure to maintain the valve in the closed position. The GN actuation solenoid valve is set to Normally-Open configuration, to allow for continuous pressure to the valve actuator to maintain it in the closed position. Due to difficulty in repair or replacement of the Flexflo valve, an effort was initiated to explore an option for a Fail-Closed butterfly Valve configuration. This valve\/actuator assembly was ordered in 2007, installation into the test stand and initial checkout occurred in 2011, and subsequent operation of the valve was unsuccessfully attempted in 2013. During the intervening years, multiple engineers were involved with the valve actuator assembly and system configuration changes. In February 2013, the A-1 Test Stand HPIW water system was brought back online, and it was discovered that the butterfly valve was not cycling properly. Initial troubleshooting efforts were hampered by the unique configuration, and a lack of full understanding of the original engineer\u2019s intent in the design. The installation of the butterfly valve was intended to be a temporary change, and the system drawings had not been updated to reflect the new valve\/actuator type, the addition of a pressure regulator and pressure gage, and the change from a Fail-Open to a Fail-Closed actuation configuration. The existing drawings also did not have sufficient detail of the actuation system plumbing in the control box CP-362, to enable thorough review of tubing routing supplying multiple valves with actuation pressure. The tubing inside the control box was configured to allow the operator to utilize 3-way valves to select a flow path to bypass the solenoid valve leg while maintaining purge pressure in order to keep the Flexflo valve closed. During the initial installation, it was recognized that the butterfly valve actuator was rated for 145 psig maximum, and that a regulator was installed to reduce pressure to 80 psig for operation. However, neither the system operating pressure nor relief valve protection were reduced for this change. The regulator and pressure gage were relocated to CP-362, and placed inside the solenoid valve leg. There was no recognition at the time that this change would allow the full 350 psig system pressure to bypass the regulator gage, and there would be no visible pressure indication to the operator. At the time of the event, further modifications were planned, which would have eliminated the bypass leg, yet there were still no plans to add relief valve protection. While securing pressure to implement these changes, the 3-way valves were turned to the bypass position, and the actuator was over pressurized, resulting in the hardware failure and ejection of components.","Lesson ID":24501}
{"Driving Event":"In the first few decades after World War II, NACA and NASA engineers developed launch vehicle aerodynamic design Guidelines which, if followed, will mitigate severe unacceptable behavior such as buffeting, bimodality, and hysteresis. An example is the set of rules developed for blunted hammerhead launch vehicles. The Guidelines, which are over 50 years old, are given in the chart below taken from Figure 2 of the cited reference. Despite the very long history of the above rules, two recent designs for NASA did not follow them, resulting in problematic behavior that required costly redesign. The problematic behavior in both cases was discovered in wind tunnel tests. It was also found that the problematic behavior could not be replicated with Reynolds-Averaged Navier-Stokes Computational Fluid Dynamics (CFD), which has been the code type of choice for conceptual design. The problematic behavior in both cases begins at the cone-cylinder junction formed (\u21131 and \u2113 2 in the figure), in both cases, at the intersection of \u2113 1 which was a blunted cone with a half-angle of roughly 30 degrees and \u2113 2, which was a cylinder. But it could occur with any hammerhead design as pictured above. At subsonic speeds, the air flow separates at the junction. In transonic flow, in addition, shock waves form on the \u2113 2 cylindrical section, which are unsteady and also cause (and interfere with) separated flow. The Guidelines call for a half-angle of no more than 15 degrees. Wind tunnel tests of both vehicles showed severe unsteady buffeting flow in the region of the junction. In both cases, the junction was redesigned to mitigate the behavior which could include buffeting, bimodality, and hysteresis.","Lesson ID":25602}
{"Driving Event":"In the late 1970s, the space shuttle\u2019s turbopump bearings were not meeting the design requirements. A bearing tester, Bearing, Seals, and Materials Tester (BSMT), was designed and built at Marshall Space Flight Center (MSFC). The tester would use the flight bearings with cryogenic coolants and duplicate operating conditions as closely as possible. Testing began in the early 1980s and continued with this rig until 1993. Approximately 25 separate builds of this rig were tested and run in either liquid nitrogen or liquid oxygen. Advanced bearing materials were run, new lubricating schemes were investigated, and internal geometries were changed. In 1995, a new test rig, the LH2 Test Rig, was designed and was capable of testing ball, roller, and hydrostatic bearings in either liquid oxygen or liquid hydrogen. To date, this rig has been assembled and run five times with combinations of ball and roller bearings. Figure 2: BSMT bearing test rig on stand Figure 3: LH2 bearing rig on test stand","Lesson ID":24006}
{"Driving Event":"The NASA Engineering and Safety Center (NESC) was requested by the Commercial Crew Program (CCP) Chief Engineer to identify deficiencies within certain AFTS CASS software builds. The AFTS CASS assessed was version 1.1 (CASS OR1 Update1), a very early release. Note: The CASS developers improved the software development processes for the development of the CASS Operational Release 2 (OR2) release. The issues reported by the static code analysis of CASS OR1.1 have all been addressed in the CASS OR2 release. The static analysis tools verified complete adherence to Motor Industry Software Reliability Association (MISRA) C++ 2008 with no issues.","Lesson ID":24503}
{"Driving Event":"The evaluation of the spiral development model in current use led to an important observation emphasizing the importance of understanding the relationship, and resulting different viewpoints, of different development models. NASA policy (NPR 7120.5 and NPR 7123.1B) and guidance (NASA Systems Engineering Handbook (SP-2016-6105), Rev 2) are primarily based on the waterfall development model. Programs using the lifecycle models described in these references must be aware that providers using a different life cycle model will not conform to the NASA waterfall model. This can lead to a variety of unfulfilled expectations and design activities that happen in a different sequence and time phasing than expected by the NASA model. For example, the NASA waterfall model has one set of SRR (Systems Requirements Review), PDR (Preliminary Design Review), CDR (Critical Design Review), DCR (Design Certification Review), and AR (Acceptance Review) as the system progresses through the development lifecycle. The design of a system following a spiral model, however, evolves with each pass through the spiral. Design aspects from spiral 1 are verified in spiral 1 and will continue to maintain this heritage as the system evolves through other spirals. However, it is also true that subsequent spirals may change or eliminate capabilities verified in earlier spirals. The tracking of these items through each spiral requires a tracking of the changes to the design for each spiral, keeping in mind that multiple system SRRs, PDRs, CDRs, DCRs, and ARs are being executed (one set for each spiral loop). Thus, the view of the results in the final spiral incorporates the results from earlier spirals without reviewing these capabilities again. This presents a unique challenge for engineers who may have to re-verify the entire system at each spiral completion to ensure affected system functions and interactions are properly captured and understood.","Lesson ID":24502}
{"Driving Event":"The Atmospheric Carbon and Transport (ACT)-America is an Earth Venture Suborbital mission that collects data in three regions across the eastern US, to better understand sources, sinks, and transport of carbon. The project involves five, six-week airborne measurement campaigns over 3 years, covering each season and summer twice. The project employs the Wallops-based C-130 and the Langley-based B-200 aircraft. During the Winter-2017 campaign, while the C-130 was flying at about 1,000 feet outside of Shreveport, Louisiana, it struck a black vulture, causing significant damage to the wing (see Figure 1 in uploaded file). The aircraft was able to land safely with no harm to the crew. Repairs delayed further use of the aircraft five days, after which the campaign continued successfully. Figure 1. Bird impact damage to the C-130","Lesson ID":24403}
{"Driving Event":"The EGS Program performed subsystem-level and integrated verification and validation (V&V) testing during its design and development phase leading up to Exploration Mission 1. Umbilicals and launch accessories were tested at the Launch Equipment Test Facility. Other tests were performed where systems were deployed in various facilities. Completion of tests was delayed and the budget allocated for the testing was exceeded. Testing was at times delayed due to spare parts being unavailable, services (e.g. calibration) not being able to support the testing schedule, and delays in correcting issues encountered during testing and quickly returning to testing. Figure 1: Umbilical testing at the Launch Equiptment Test Facility (LETF)","Lesson ID":23901}
{"Driving Event":"The GSDO Program System Requirements Review was held in 2012 and the Preliminary Design Review was held in 2014 to help establish the groundwork needed to launch NASA\u2019s Orion spacecraft. During the time leading up to the December 2014 launch of Exploration Flight Test 1 (EFT-1), the first Orion test flight, the GSDO Program set up the Cradle database for requirements management. The project schema was configured and the program determined how requirements would be tracked and closed. Cost and schedule impacts occurred due to a number of issues with how the requirements were structured, allocated and closed. System acceptance or certification reviews were delayed due to the lack of an efficient process for closing requirements or making closure evidence available in configuration-managed repositories. Significant resources were needed in order to correct problems with the GSDO Program\u2019s requirements set and the allocation, management and closure of requirements. Requirements related to Exploration Mission 1 (EM-1) and Exploration Mission 2 (EM-2) were not cleanly separated by mission. There were EM-2 children of EM-1 requirements. Verification and validation testing could not close the EM-1 parent requirements since EM-2 implementation and testing were considered future work for the EM-1 requirements. These problems were corrected by adding an effectivity field to specify dates associated with each requirement, and requirements had to be separated by mission. The Engineering organization kept its own set of subsystem-level requirements outside of the Cradle database, and its requirements set did not always accurately reflect changes to the Program\u2019s requirements set. The Engineering organization also had some requirements that had not been allocated by the Program. The problem was corrected by shifting the Engineering organization\u2019s management of its requirements to the Program\u2019s requirements database. Design verification matrices (DVM) were used by the Engineering organization as closure evidence for requirements, but were not integrated with the Program requirements database. These matrices did not always have the correct requirements and did not always have links to configuration-managed evidence from testing. This required reworking DVMs. There were delays in the availability of configuration-managed evidence of test completion. These delays were the result of inefficient processes for placing test results into configuration-managed repositories or having a test procedure that had so much testing included in it that the procedure could not be completed in a timely manner. This was addressed by splitting long test sequences into shorter ones when evidence of test completion was needed quickly, and by implementing an efficient process for getting test reports into configuration-managed repositories. GSDO\u2019s requirements were not allocated through the ground system structure down to the lowest level (subsystem or project). At the time, the GSDO Program made use of an Integrated Product Team (IPT) structure. Program-level requirements were allocated to each IPT and eventually to each subsystem or project. When the Program reorganized and stopped using IPTs, the requirements needed significant rework. Design standards (such as KSC-DE-512-SM, Facility Systems, Ground Support Systems, and Ground Support Equipment General Design Requirements) give specific requirements as well as invoking other standards. These were allocated to subsystems or projects and were not further decomposed. Some requirements buried in these standards were not addressed. At the individual project level, all requirements levied by design specifications and standards need to be pulled out and the applicable requirements need to be spelled out in the project\u2019s requirements.","Lesson ID":23801}
{"Driving Event":"Select NASA Programs, Projects, and organizations are considering a non-traditional approach to electrical, electronic, and electromechanical (EEE) parts selection, qualification, and screening for avionics systems. These programs propose to use automotive and non-automotive commercial-off-the-shelf (COTS) EEE parts with no parts level screening and qualification. Non-automotive and automotive parts specifications do not include screening requirements. In lieu of part level screening and qualification, these Programs propose to perform only board and\/or box-level testing. Destructive physical analysis (DPA), Production Part Approval Process (PPAP) documentation, and vendor site visits (for evaluating fabrication process controls) will be used as the basis for automotive COTS part qualification. Equivalent manufacturer historical data (e.g., failure in time (FIT) rates, manufacturing process data, etc.), vendor visits, and DPA will be used as the basis for non-automotive COTS part qualification. NASA is a relatively low volume consumer of high reliability EEE parts and has typically used United States (U.S.) military specifications and standards (Mil-Prf-38534, Mil-Prf- 38535, Mil-Prf-19500, MIL-STD- 883, MIL-STD-750, etc.) for EEE parts procurement criteria. The military standardization system ensures that parts made to these specifications are built, screened, and qualified to the same standards by different manufacturers, regardless of the application or the procurement volume. However, for automotive COTS parts, high volume buyers (e.g., automotive manufacturers) typically establish close working relationships with their suppliers and develop a comprehensive PPAP to meet their unique application and reliability requirements. NASA faces significant challenges in establishing these close relationships with most manufacturers, as infrequent procurement demand and low parts volume does not provide sufficient incentive for manufacturers to make such time and financial investment. Testing was performed on a variety of automotive and non-automotive COTS EEE parts. The testing included DPA, environmental characterization, and radiation testing on automotive and non-automotive COTS EEE parts to determine their suitability for NASA avionics system applications. The results of the tests were significant. Automotive and non-automotive COTS EEE part types tested exhibited a high Destructive Physical Analysis (DPA) defect rate (i.e., 21% for automotive, and 22% for non-automotive parts) with statistically indistinguishable patterns of non-conformances to NASA GSFC S-311-M-70 (Specification for Destructive Physical Analyses). Of the automotive and non-automotive COTS EEE part types tested, defects were distributed across manufacturers and part categories. During environmental testing, one of six automotive, and one of one non-automotive COTS EEE part types did not pass the subset of the Automotive Executive Council (AEC) Q101 qualification tests, due to electrical failures observed after highly accelerated stress testing (HAST) and thermal cycling. The results of the radiation tests indicated that automotive and non-automotive parts are more likely to exhibit significant part-to-part and lot-to-lot variability. No consistent trends between vendors or across part types have emerged to assist in predicting where such variability may arise without testing large samples of the parts.","Lesson ID":23502}
{"Driving Event":"In 2015 JPL completed a non-NASA sponsored research task to design a multi-limbed robot (Figure 1). JPL experience in the design of semi-autonomous mechanical systems had previously shown promise when applied to replacing human workers in hazardous terrestrial environments. The task was intended to demonstrate the stability (Figure 2) needed to complete challenging tasks under supervised tele-operation while in the degraded human environment typical of natural and man-made disasters. The robot featured a LiDAR (Light Detection and Ranging) device and stereo cameras to sketch out its environment in three dimensions. Figure 1. The robot employs four general purpose limbs and hands, capable of both mobility and manipulation, to achieve passively stable stances; establish multi-point anchored connections to supports such as ladders, railings, and stair treads; and brace itself during forceful manipulation operations. Figure 2. The robot performing a task-- walking over obstacles Shortly after swapping in a spare Li-ion battery into the robot and plugging it in to charge in the JPL Bldg. 198\/B6 laboratory on June 14, 2016, the battery spontaneously ignited in a sustained combustion (Figure 3) that caused significant damage to the robot (Reference (1)). One JPL affiliate from an adjacent laboratory activated the fire alarm, while another attempted unsuccessfully to extinguish the fire with a CO2 fire extinguisher. Another attempt with another CO2 fire extinguisher succeeded temporarily, but the Li-ion battery reignited. Attempts by the JPL Fire Department to extinguish the fire with an ABC Class extinguisher had no effect, and it was only when the battery was disconnected from charging, the robot was rolled outside of the lab, and a copious amount of water was delivered by a fire hose, that the fire was extinguished. No personnel were injured in the incident, which was characterized as a Type C mishap. Figure 3. The robot battery ignited explosively. (Play video) Li-ion batteries are in common use as power supplies, and they are becoming increasingly prevalent due to their high energy density, minimal memory effect, and slow rate of self-discharge when not in use. The individual cells contain both an oxidizer (cathode), fuel (anode), and organic electrolyte, separated by a porous polymer layer in a sealed container. If they are allowed to react directly (e.g., by a failure of the separator), the fuel and oxidizer produce heat and gas with consequences that can be catastrophic (i.e., loss of life, strategic facilities, or the mission). Because only limited specifications and usage guidance is typically available from battery manufacturers, users may need to seek additional clarification. The project had purchased three battery packs, manufactured by a California company, that contained a total of 96 Li-ion pouch cells supplied by a small Korean company, which in turn sourced them from an unspecified Chinese manufacturer. Each battery pack included a battery management system (BMS) that had not been configured at delivery for over-temperature or over-voltage cut-offs; and according to the battery users, the BMS was not able to correctly calculate the state of charge (SOC) for the battery pack. In addition, the BMS was bypassed during the on-robot charging. The JPL Pre-Operational Safety Review (Pre-OSR) hazard analysis for the robot operation did not list any hazards from Li-ion batteries. Further, it lacked procedures for charging\/storing Li-ion batteries or for fire emergencies. It also lacked a fail-safe system in case of a thermal runaway, a battery replacement procedure, and formal documented procedures for battery replacement and charging. (Also, the affiliate was not trained in use of the fire extinguisher.) The battery was charged while installed in the robot, which deviated from the project procedures. Also, lessons learned from JPL\u2019s previous non-flight Li-ion battery fire (Reference (2), which recommended \u201cReview the implementation of battery charge and conditioning management\u2026\u201d) had not been incorporated by JPL into non-flight battery management processes. The design and operation of Li-ion batteries used in JPL spaceflight applications are reviewed by battery experts in the JPL Electrochemical Technology Group, but this oversight was not requested (beyond the early proposal stage) by the subject non-flight project. The proximate cause of the mishap was attributed (Reference (5)) to charging the battery without a BMS that had been properly configured to control the temperature, voltage, or current. This resulted in overcharging of cells within the battery, thermal runaway (i.e., a rapid, uncontrolled, increase in temperature), and ignition (Figure 4). Figure 4. The robot battery after the fire References: JPL Mishap Report No. 3450, June 14, 2016. \u201cLithium-Ion Battery Fire,\u201d NEN #3516, NASA Lesson Learned Information System (LLIS), May 18, 2010. \u201dBattery Fire at the Madrid DSN Facility,\u201d NEN #12401, NASA Lesson Learned Information System (LLIS), October 15, 2014. Report of the Li-ion Battery Incident Investigation Team (NASA Mishap Information System #16-100818), JPL Occupational Safety Program Office, February 10, 2017. Lynne Lee, \u201cLithium-Ion Batteries, The Good, The Bad & The Ugly,\u201d NASA Senior Management ViTS Meeting, October 3, 2016. JPL Interim Battery Safety Work Practices (SWP), March 2017. JPL Lithium-Based Cell and Battery Selection, Procurement and Operational Guidelines, September 25, 2017. https:\/\/gateway.jpl.nasa.gov\/sites\/safety\/Shared%20Documents\/Program%20Documents\/Fire%20Life%20Safety\/JPL%20Li%20Based%20Battery%20Use%20Guidelines%209-25-17[3].pdf","Lesson ID":23701}
{"Driving Event":"The RapidScat scatterometer was installed on the ISS in September 2014 to provide a replacement for the wide-swath scatterometry measurements that were lost when the antenna on the SeaWinds payload aboard the QuikSCAT satellite stopped rotating. Scatterometers are radar instruments that measure wind speed and direction over the ocean; they are useful for weather forecasting, hurricane monitoring, and observations of large-scale climate phenomena such as El Nin\u0303o. Built by the NASA\/Caltech Jet Propulsion Laboratory (JPL), RapidScat is mounted to the exterior of the ISS\u2019s Columbus science laboratory module (Figure 1). Columbus was built and is operated by the European Space Agency. Figure 1. Illustration of the location of RapidScat on the ISS and its operation Station power is generated centrally by solar arrays and routed via a 120 VDC system to all Station users. Inside Columbus, the incoming power goes through two Power Distribution Units (PDUs) and then, as 120 VDC or 28 VDC, to all payload racks, external platform locations (e.g., RapidScat), center aisle standard utility panels, and subsystems. On August 19, 2016, the Columbus module experienced a shutdown of power to PDU-1, which supplied power to RapidScat and multiple other internal and external payloads and ISS systems (Reference (1)). Two minutes prior to the power bus shutdown, the RapidScat radar unexpectedly powered down and stopped sending telemetry. On August 20, an attempt to power RapidScat resulted in an overcurrent event. Subsequent attempts to power RapidScat all resulted in overcurrent events, and because the front-end power electronics are not on-orbit serviceable, the RapidScat mission could not be re-activated. The limited telemetry available suggests that RapidScat (Figure 2) responded to an under-voltage condition in the Columbus-supplied power by either shutting down or rebooting its computer. Approximately two minutes later, this Columbus PDU-1 power anomaly resulted in a sudden removal of power to RapidScat (and other payloads and hardware fed by the Columbus power system). Subsequent attempts to power the instrument resulted in over-current induced trips, suggesting that a substantial internal hard short developed directly across the power bus (Reference (2)). Figure 2. When QuikSCAT stopped collecting wide swath wind data in late 2009, JPL came up with a quick and cost-effective replacement that used the framework of the ISS and reused hardware originally built to test parts of QuikSCAT. Failure analysis performed to account for the observed telemetry and symptoms suggests that RapidScat may have been damaged by a combination of (1) the under-voltage condition and (2) inductive kickback when PDU-1 suddenly lost power. During instrument development at JPL, ground testing of a sudden power off scenario was not done with an inductive load attached. It is plausible that one or more field-effect transistors (FETs) were stressed or driven to short by inductive kickback during or after the PDU-1 sudden power off event (Reference (3)). Subsequent simulation of various failure modes revealed a heretofore undiscovered weakness in the design that left portions of the instrument\u2019s solid-state switch circuits vulnerable to stress in the event of uncontrolled removal of power. It now seems most likely that the PDU-1 sudden loss of power event and a design weakness combined to cause the failure of a number of components in the power supply. The RapidScat mission did not have specific science requirements (although it accepted a set of science objectives consistent with a two-year mission). The primary RapidScat mission goal (which was essentially accomplished during its ~2 years of operation) was to demonstrate (1) the agile reuse of flight-worthy hardware and (2) the capability of a Class D-like project to deploy and host a science-class instrument. References: \u201cLoss of Feeder 1 Power at COL SDX site,\u201d JPL Incident Surprise Anomaly (ISA) No. 60031, August 19, 2016. Charles Benson, \u201cRapidScat Failure Analysis,\u201d IOM #3460-16-017, December 19, 2016. Stacey Boland, \u201cAnomaly: ISS Feeder 1 Power Loss,\u201d October 21, 2016. Patricia D. Lock, \u201cCandidate Lesson Learned from RapidScat Anomaly,\u201d JPL e-mail to David Oberhettinger, August 30, 2017.","Lesson ID":23201}
{"Driving Event":"JPL is the lead NASA field center for the robotic exploration of the solar system (and beyond); currently, it has an unprecedented 33 missions that have been launched and are in the operations phase (Figure 1) and another 22 spacecraft in development (Figure 2). JPL spacecraft are typically one-of-a-kind and are designed to perform missions that have never before been attempted. Despite many uncertainties about what the spacecraft will encounter, these systems often exceed expectations: the Opportunity rover was expected to survive 90 days on Mars, and it is still operating there 13 years after the 2004 landing. Despite extensive ground testing of design innovations, their actual mission is the first time they are exposed to outer space. Figure 1. Current JPL spaceflight projects, i.e., in post-launch operations (View larger image) Figure 2. JPL spaceflight projects in development, i.e., phases A through D (View larger image) Whether an innovation stems from a great leap of imagination or from an incremental improvement, it is built upon lessons that were learned from prior successes and failures. For example, JPL attempts to codify 80 years of spacecraft engineering \u201cgood sense\u201d in its Design Principles (Reference (1))\u2014a list of over 350 \u201ccommandments\u201d that represent a consensus reached by JPL engineers. Of equal or greater importance to the development of flawless products, however, has been to employ a deliberate, painstaking, approach to engineering of flight systems. Rob Manning, the Acting JPL Chief Engineer, suggests (Reference (2)) that JPL\u2019s established pattern of ensuring success has been to: Give our staff time to learn, think, and mull before committing to something new. Encourage them to talk to their colleagues about the idea in their offices to sound it out. Encourage them to build a computer simulation of the thing to see how it will work. Encourage them to build a working prototype inside a physical lab and have them look it over really well. Then we give them time to explain the proposed or prototyped design to colleagues in larger settings we call peer reviews where they can quietly cross-check the design without a lot of drama. Eventually, we send the design to other organizations (like Reliability Engineering) to check the design analyses more formally. Next, we invest in a more final (and more expensive) version of the thing they are building and let them test it more thoroughly in their lab. Finally, a near final version is made and we hire a bunch of formal independent testers to hook it up into a larger setting, formally check the design, and hunt down the last of the bugs and goofs that the designer and the reviewers might have missed. Then, throughout the project life cycle, we continually monitor what we have built to identify problems; and when we can, we fix them. Some of the above elements are given greater or lesser emphasis over the years, but they provide a system of checks and balances that have shown to contribute to the design of an essentially flawless product. In his presentation, however, Rob Manning also pointed out that taking these steps and following all the design rules do not prevent \u201cfailures of imagination.\u201d For example, Mars Science Laboratory rover wheels are exhibiting premature wear partly because cemented, pointy, Mars rocks are more prevalent than we expected. After all, it is the unknowns themselves that spur us to scientific exploration. Nevertheless, JPL launches flight systems with confidence that it has followed a rational and deliberate process for screening out major design defects. References: JPL Design Principles, Rev. 6, JPL DocID No. 43913, October 4, 2012. Rob Manning, \u201cCan Failure be a Measure of Success?,\u201d JPL LEAP Seminar, March 24, 2017. https:\/\/jpltube.jpl.nasa.gov\/Watch=vJztL7","Lesson ID":22601}
{"Driving Event":"The control, instrumentation and electrical power system for the VAB 175 ton crane was replaced via a CoF design-build contract. During the DCR for the VAB 175 ton crane held on July 14, 2017, it was discovered that a Human Factors Assessment had not been conducted in advance of this review. A subsequent human factors assessment discovered that the control panel height was placed too low to easily allow an operator to move in close to the screen to access the touch screen and make selections and the operator indicated it may be necessary to switch hands during operation.The human factors group determined that the human factor findings would not adversely affect the operation of the crane. Human factors must be assessed in a timely manner in accordance with KDP-P-2713 Technical Review Process or KDP-P-2713A Technical Review Process for EM-2 Architect and Engineering (A&E) Design and Development (as applicable) for GSDO CoF projects that effect element subsystems and require either a DCR or System Acceptance Review (SAR). The CoF process did not factor this into the Statement of Work (SOW) and the review processes were not followed.","Lesson ID":22501}
{"Driving Event":"The MSL \u201cCuriosity\u201d rover landed on August 6, 2012, and it has currently driven 19 kilometers (Reference (1)) across the Martian surface. Curiosity's six aluminum wheels were designed for mobility on loose sand, rocks perched on sand, and flat bedrock. The design was tested under simulated conditions in the Mars Yard outdoor test facility. Like the wheels on the three prior Mars rovers, however, the wheel (Figure 1) was designed with very limited knowledge of the specific terrain features that would eventually be encountered during Mars surface operations. Figure 1. Components of a Curiosity wheel As the rover drives across the surface of Mars, the rover operations team at the NASA\/Caltech Jet Propulsion Laboratory (JPL) employs the Mars Hand Lens Imager (MAHLI) camera on the rover's robotic arm to check the condition of the wheels at routine intervals. On sol 411 (October 2, 2013) imagery revealed a puncture in the skin of the left front wheel (Figure 2). This did not raise a concern because such wear and tear was expected, especially in the thinnest areas of the wheel skin between the chevron-shaped grousers (treads). (Previous Mars rover wheels had straight skin protrusions; the chevron feature was provided for the purpose of preventing sideways slip.) However, subsequent visual wheel inspections revealed higher than expected wheel wear, which prompted JPL to start tracking the progression of wheel damage. Figure 2. Detail view of the inner surface of Curiosity's left front wheel on sol 411. Arrow points to tear. Within a few months of the sol 411 anomaly, the MSL project became concerned by the apparent increase in the rate of wheel damage (Reference (2)), and a tiger team was formed to analyze the problem. By sol 463 (November 24, 2013), a large rip had opened above the Morse-code holes in the left front wheel that was much larger than expected and exceeded any damage seen in testing. The progressive damage to MSL wheels has continued (Figure 3). This rip, and the others that would follow is attributed to single-event punctures, as well as metal fatigue, due partially to the prevalence of ventifacts embedded in bedrock (i.e., immobile, wind-eroded pyramidal rocks). This terrain had not been simulated in pre-launch testing of the wheel (Reference (3), Sec. 4.18) because only limited knowledge about the terrain was available. The stresses from deformation and the metal fatigue are highest on the skin near the tips of the chevron features, and many tears seem to propagate from the chevron tips. Figure 3. MAHLI full-wheel imagery of Curiosity's left-middle wheel taken on April 18, 2016 (sol 1,315) The impact of ventifacts is exacerbated by a dynamic mechanical load on the wheels. The design of the rocker-bogie system (Figure 4) includes wheels that all rotate at the same speed and downward-angled arms that support the middle and front wheels. If a front or middle wheel hangs up on a rock and the rest of the rover keeps driving, the arm exerts a downward force on the wheel. This increases wheel loading well beyond the static weight of the vehicle, and it is sufficient to cause local grouser yielding and skin puncture. The MSL rear wheels, which have experienced minimal damage, do not see this downward force because they are merely dragged behind the arm like a trailer on a hitch. Where this pushing force might have been expected to merely shift a loose pointy rock, subsequent testing has shown that the punctures are primarily due to the prevalence of pointy rocks that are immobile\u2014either cemented into the ground or a part of the bedrock.[1] Figure 4. The rocker-bogie mobility system (the wheels depicted are not the Curiosity design) surmounts the face of a vertical obstacle (rock) by having the center and rear wheels force the front wheels against the obstacle. The rotation of the front wheel then lifts the vehicle up and over the obstacle. The rear wheel then presses the middle wheel against the obstacle and the front wheel pulls it against the obstacle until the middle wheel is lifted up and over. Finally, the rear wheel is pulled over the obstacle by the front two wheels. The rover test program did not consider driving-related loads to be the only potential cause of wheel damage. The MSL project had placed more emphasis during wheel testing on landing touchdown loads, the expected worst case wheel failure mode, than on terrain-influenced driving loads. (Post-touchdown imaging revealed only slight damage-- a minor crack in the L2 wheel (Reference (4), p. 5.) The MSL project has implemented corrective actions to mitigate the extent of future damage. These include establishment of guidelines, based on visual observations and on verification in the Mars Yard, for (1) assessing wheel wear progression and (2) minimizing wheel wear while driving. The latter measure involves avoiding driving over hard surfaces with a high concentration of sharp ventifacts and, where feasible, driving backward on \u201cwheel hostile\u201d terrain to reduce the load on the front wheels. These measures have proven effective in managing the rate of damage (Reference (2)): the rover will be able to complete its extended mission, and it will likely be capable of additional extensions to the MSL mission. The major effects of the wheel damage problem are to slow the progress of Curiosity and to limit the paths the mission can choose to explore. The design of the MSL wheels has been more susceptible than anticipated to puncture and cracking, particularly following interaction with certain types of terrain (Reference (2)). Specifically, the root cause analysis (Reference (6), p. 29-30) of the premature MSL wheel wear offers some instructive lessons learned: The wheel design is not robust to fatigue. Nominal vehicle weight, in combination with nominal drive torque, causes wheel skin stresses to exceed the endurance limit of the material, initiating cracks. Position control of drive actuators causes non-trivial inter-mobility forces while traversing obstacles, due to differences in the traveled distance of each wheel. These forces increase wheel loading well beyond the static weight of the vehicle, and are sufficient to cause local grouser yielding and skin puncture. Terrain matters! The wheel design is not robust to puncture on naturally occurring ventifacts. Wheel skin sheet metal is susceptible to puncture from obstacles that are well within the sharpness of naturally occurring ventifacts found on Earth, and likely on Mars. Skin loss around a grouser (whether from fatigue cracks or puncture) causes a change in the wheel load path, loading said grouser beyond the material yield limit. This material overload situation will eventually cause all wheel grousers to fail, generally at the location where the grousers meet the wheel internal stiffening ring (Figure 1). Turning-in-Place (TiP) is preferentially harder on wheel W2, increasing reaction loads beyond that of W2\u2019s normal driving loads. Compounding the issue, W2 turns on a smaller Ackermann arc during TiP maneuvers; small Ackermann turning radii contribute to wheel damage. Steering while sitting atop an obstacle at the wheel edge caused the highest loads observed during test. This process, however, does not appear to be a primary damage mode-- likely due to the low probability of coming to rest atop a sharp obstacle at the extreme edges of the wheel, and then commanding a steering operation. The follow-on Mars 2020 rover project is designing and testing a modified wheel with greater durability over harsh terrain and sand traverse performance equal to MSL (despite an increase in rover mass), while minimizing wheel mass growth (Reference (7), p. 12). References: http:\/\/curiosityrover.com\/tracking\/drivelog.html \u201cWheel Wear,\u201d JPL Incident Surprise Anomaly (ISA) Report No. 55561, December 18, 2013. \u201cMars Science Laboratory Wheel Damage Mechanical Tiger Team \u2013 Final Report,\u201d JPL Document No. D-78450\/MSL-266-3989, January 6, 2015. R.E. Arvidson, et al, \u201cRelating Geolocic Units and Mobility System Kinematics Contributing to Curiosity Wheel Damage at Gale Crater, Mars,\u201d Journal of Terramechanics, TER 691, March 20, 2017. Patrick DeGrosse Jr. \u201cMSL Wheel Damage,\u201d JPL Incident Surprise Anomaly (ISA) Report No. 56534, June 18, 2014. Patrick DeGrosse Jr., \u201cWhat is Causing the Damage?,\u201d September 25, 2014. \u201cM2020 Mobility Wheel & Flexure Initial Design Review,\u201d Mars 2020 Mission Formulation, June 14, 2016. MARS 2020 Project, Surface Terrain Model Specification Document, JPL Document No. D\u201093886, October 1, 2015. 1 \u201cWhen we conduct tests on Earth with the best analogues that we can find, we believe that they will behave in a certain way. But Mars doesn't have to agree with us. So one of the difficulties is that the Mars material is just fundamentally unknown. But to be blunt, if it were all known then we wouldn\u2019t need to go there.\u201d - Fuk K. Li, Director, JPL Mars Exploration Directorate","Lesson ID":22401}
{"Driving Event":"CloudSat is an Earth orbiter that uses a radar instrument to advance understanding of cloud abundance, distribution, structure, and radiative properties. Designed and operated by the NASA\/Caltech Jet Propulsion Laboratory (JPL), CloudSat performs 16 orbits each day in formation as part of the A-Train constellation of satellites (currently OCO-2, GCOM-W, Aqua, CloudSat, CALIPSO, PARASOL, and Aura). CloudSat employs two articulating solar arrays to generate 1,000 watts of electrical power to recharge a 40 amp-hr battery. A Power Control Unit (PCU) regulates battery charging and distributes power to the spacecraft over a hardwired power bus and four switchable power buses. CloudSat completed its two-year primary mission successfully. Five years after the 2006 launch into sun-synchronous orbit, the CloudSat spacecraft battery experienced the first of a series of under-voltage (UV) conditions that triggered a spacecraft emergency mode and turned off the spacecraft computer. Telemetry was available in real time only during ground passes. The first and each successive UV event (i.e., UV-3 fault) caused autonomous switching to a lower battery charge rate that required the ground controllers to repeatedly command a higher charge rate. With the battery temperature dropping, ground was unable to repeat these commands for a couple days due to an unrelated ground network problem, and another day without this charge rate commanding would have caused battery discharge, battery freezing, and the loss of the spacecraft. It took 8 weeks to regain enough control of the spacecraft computer to begin recovery efforts. The battery anomaly was attributed (Reference (1)) to \u201cdiffusion-limiting current, a condition caused by corrosion of the positive electrode which results in the net loss of electrolyte (i.e., dry-out of electrolyte in the membrane). The reduced amount of electrolyte reduces the ability to support the current demands and there is a sudden drop in voltage when the diffusion-limit is reached.\u201d This failure mechanism had never before been seen on orbit. The requirements for recovering the spacecraft to normal operations were daunting (Reference (2)): The peak discharge current during the sun-eclipse part of the orbit had to be <5.25 amps, but the spacecraft normally used ~15 amps during eclipse. Only ~2.3 amp-hrs (10% of pre-anomaly performance) was available during the 34-minute eclipse. The Attitude Control System (ACS) had to be powered off during eclipse because it alone used ~7 amps. The spacecraft and the Cloud Radar had to be kept warm enough during the sunlit period so that the thermostatically-controlled heaters would not power on during eclipse. The innovative solution implemented 6 months after the anomaly was to go to a Daylight-Only Operations (DO-Op) Mode in which the 3-axis stabilized spacecraft and nadir-pointing radar were transitioned into a spinning spacecraft during every eclipse (Figure 1). That is, at each umbra exit from eclipse, the power from the solar arrays are used to spin the reaction wheels to quickly orient the science boresight so that the vehicle recovers from hibernation and resumes science data collection in only a few minutes. No science is performed during eclipse, so CloudSat achieves 56 percent of the pre-anomaly science product each orbit. Figure 1. The new nominal operating mode, DO-Op (Daylight-Only Operations), astounded the project team when it was first proposed. References: Nayak, Witkowski, Vane, et al, \u201cCloudSat Anomaly Recovery and Operational Lessons Learned,\u201d 12th International Conference on Space Operations, Stockholm, Sweden, June 2012. http:\/\/www.dtic.mil\/dtic\/tr\/fulltext\/u2\/a568401.pdf Deborah Vane, \u201cCloudSat Battery Anomaly 2011,\u201d JPL project managers\u2019 Pause & Learn session, April 18, 2017.","Lesson ID":22502}
{"Driving Event":"SMAP was recommended by NASA\u2019s 2007 Earth Science Decadal Survey as a Tier 1 mission. Launched in January 2015 into a polar sun-synchronous orbit at 685 km altitude, the SMAP spacecraft has a primary mission duration of three years. The science objective is global, high resolution, mapping of Earth\u2019s soil moisture and the soil\u2019s freeze-thaw state. JPL partners with NASA Goddard Space Flight Center on the mission, and JPL\u2019s role includes mission operations. SMAP is presently facing the challenge (Reference (1)) of going from a fully staffed Commissioning Phase with about 20 operations personnel working extended hours on console, to a Science Phase with about 4 individuals working on console about once per month. (Figure 1 visually redefines what is meant by the ops term \u201cdark room\u201d\u2014the continuously dimly illuminated mission control center where the consoles (e.g., Telecom console) and overhead displays are located.) Although some ground-based automation had been implemented on two previous JPL missions, SMAP Mission Operations was unsure whether the space observatory could be operated by such a small team once SMAP\u2019s in-orbit antenna deployment and initial shakedown were complete. COMMISSIONING PHASE Extended hours on console (initially 24\/7, then 7 days\/wk) Systems\/Flight\/ACE\/ Scheduling staffing: ~10 FTE Subsystems: 3-4 FTE (each) GDS: ~6 FTE OPERATIONS PHASE 9\/80 schedule (on console ~once per month) Systems\/Flight\/ACE\/ Scheduling staffing: ~2 FTE Subsystems: 0.2-0.5 FTE (each) GDS: ~1 FTE Figure 1. SMAP \u201clights out\u201d mission operations SMAP completes about 20 orbital communication passes every day that last about 8 minutes apiece. This requires a number of routine ground support activities that potentially lend themselves to automation: Connecting to ground stations and processing downlinked data in real time Routing downlink data to analysis software Generation of spacecraft trajectories from Doppler navigation data Generation of spacecraft clock\/spacecraft event time (SCLK-SCET) correlation from spacecraft time packets Monitoring telemetry, and alerting the operations team to off-nominal events Performing data accountability Another candidate for automation is the routine commanding of the spacecraft that takes place on demand, or scheduled as frequently as every 6 hours, such as non-volatile memory (NVM) management (i.e., bad blocks), updating the onboard ephemeris, and bulk upload of files. The operator merely has to load in a command file that states what needs to be sent and when it needs to be sent, and the bot does the rest. Rather than a monolithic system, the SMAP automation is distributed throughout the various flight operations and ground data system tools. Many different JPL developers and organizations were involved in automating core SMAP ops functions, which include: PAD: Pass Automation Daemon FNS: File Notification Service TARDIS: Traceable Automation Remote Display Interruptible Scheduler (TARDIS produces ephemeris from Doppler navigation data.) ANF: Alarm Notification Filter TQR: Telemetry Query and Reporting ATCS: Automated Time Correlation Service DMT: Data Management Tool SMAP AUTO: Closed loop commanding of spacecraft. SMAP also made use of the existing multi-mission command and telemetry system (AMPCS), adding automation interfaces. The goal of the SMAP effort was to automate ground based operations and to increase the reliability and efficiency of the operations team (Reference (2)). For reliability, the driving philosophy has been to avoid complexity, shunning fancy code in favor of simple standalone scripts with minimal dependencies on external infrastructure. For reusability, there is no SMAP-specific code in the core ground-based pass\/workflow automation software (~8,000 LOC): JPL plans to reuse the code for automating the upcoming NISAR and SWOT missions. For extensibility and flexibility, additional capabilities (i.e., custom code) can be ingested and executed during a pass without even bringing down the system. Critical to automation, the SMAP Operations Team receives alerts (e-mail and SMS messages) in response to off-nominal scenarios. Automation of SMAP operations has resulted in a huge number of files moved around on a daily basis. As of July 2017, there have been 13,236 passes with 99.3 percent success, and 536,790 workflow activities with a 99.9 percent success rate. In addition, of the 10,347 Science Phase command products, 91% were automated and 9% were produced manually and sent to the spacecraft. Also, the ability to scale commanding without human intervention has encouraged SMAP to command a lot more often, while decreasing data latency and improving on-orbit pointing accuracy. Figure 2 illustrates the decrease in manual commanding and the increase in automated commanding from the beginning of the Commissioning Phase to the beginning of the Science Phase; spikes in human activity during the Science Phase are related to anomalies (e.g., Reference (3)) or significant engineering activities such as the installation of software. Figure 2. SMAP manual vs. automated closed loop commanding (SMAP AUTO) comprises a total of over 100 commands per week. There are weeks during which there are no manual commands radiated to the vehicle. (View larger image) References: \u201cLights Out Operations: SMAP Mission Operations and Ground Data Systems,\u201d JPL Mission Systems & Operations Division, JPL Tube, April 19, 2017. https:\/\/jpltube.jpl.nasa.gov\/Watch=l9XIN6 Christopher Swan, \u201cAutomated Commanding of the SMAP Spacecraft Enables Efficient, Reliable, and Responsive Operations,\u201d 2016 IEEE Aerospace Conference, 5-12 March 2016. \u201cMissing Record of Commands Radiated,\u201d JPL Incident Surprise Anomaly (ISA) No. 59918, July 20, 2016. Chris Swan and Antonio Sanders, \u201cLights Out Operations: SMAP Mission Operations and Ground Data Systems,\u201d Mission Systems and Operations Division Autonomous Operations Seminar Series, April 19, 2017","Lesson ID":22101}
{"Driving Event":"An employee attempted to enter an older facility using an entrance that has a steep ramp without a landing at the doorway. After ascending the ramp the employee grasped the door handle and pulled. Unfortunately, the door flexed and rebounded causing the employee to lose balance and fall down the ramp. Upon falling, the employee\u2019s head struck the pavement of the adjacent parking lot and suffered a permanent-partial injury. Upon investigation it was found that the ramp leading into the facility had a slope of 1:6.27 (9 feet 5 inches run with a drop of 1 feet 6 inches) which exceeds the California Building Code for Historical Buildings (Accessibility Section, 8-603.6). In addition, it was found that the egress\/ingress way had no handrails and it and the grounds outside the building were covered with leaves which impaired footing and visibility. Figure 1: Photo of doorway after mitigations","Lesson ID":21803}
{"Driving Event":"Pushing the boundaries of engineering invention and space exploration has produced great achievements, but at the price of mistakes that are sometimes costly. Spaceflight projects managed by the NASA\/Caltech Jet Propulsion Laboratory (JPL) have exhibited a trend of increasing complexity (Reference (1)) in which the implications of an engineering decision are not always obvious, potentially leading to error. In the spacecraft design process, however, failures should be valued and embraced for the lessons they teach: little is learned from a series of tests that are designed to be successful. JPL is specifically charged by our NASA stakeholder to embark on cutting edge, never before attempted, missions that pose a high risk. Hence, a single-minded focus on failure avoidance will tend to forestall the risk-taking that leads to technical breakthroughs. During a March 2017 seminar on the value of failure (Reference (2)), the Chief Engineer of the JPL Engineering & Science Directorate (ESD), spoke of the importance of an engineering culture that gives employees \u201cspace to fail.\u201d Even where a supportive institutional culture prevails, \u201cspace to fail\u201d requires that an employee\u2019s superiors echo the institutional acceptance of failure, and that the employee also buys into the concept that there is space to fail. For example, JPL currently seeks to design some lower cost, higher risk, Class D missions that waive some standard analyses, reviews, and tests, but project staff may be reluctant to personally accept the heightened risk of failure. The science culture readily accepts the value of experimental results that disprove an established theory, but engineers may not greet a series of negative results with such enthusiasm. A JPL cultural example (Reference (2)) that an employee is given \u201cspace to fail\u201d is a \u201cYes\u201d answer to the following questions: Do people let you say \u201cstupid\u201d ideas in meetings without subtly \u201cputting you in your place\u201d? Does your manager allow you to share your work with others outside your organization without worry that defects or goofs might be uncovered by \u201csomeone else\u201d? When you fail, are you given a second chance to try again? Are you encouraged to learn from your mistakes rather than being disciplined or ostracized? Are you encouraged to go out and try your idea? Do you have time to think and mull before you commit to an idea or act? When you learn from your mistakes, do you feel comfortable about sharing those lessons? Do you believe that, as [a JPL engineer] says, \u201cFailures are ammo in your arsenal, not baggage that weighs you down.\u201d? The ESD Chief Engineer (and former MSL Chief Engineer) has also stated: \u201cGiven that engineers are human and humans make mistakes, how was it possible that a $2.4B rover (MSL) successfully landed on Mars? There were thousands of places in the very complex design where a single mistake could have resulted in mission failure. Did MSL hire people who did not make mistakes? No. All of us on the MSL team literally made thousands of mission-critical human errors during the design and development including mistakes after launch. Was MSL just lucky? Perhaps, but we can\u2019t count on luck to succeed. Instead, we must provide venues and a culture for enabling our team members to discover their mistakes locally without retribution, humiliation, nor drama. In fact, the constant, fearless, and open discovery and correction of mistakes (via trial and error) is a sure sign that the right things are being done to ensure mission success.\u201c JPL\u2019s first Mars rover mission was a valuable disrupter of conventional thinking in that it was motivated by a desire to dramatically reduce the cost of landing on Mars. Therefore, there was a willingness to embrace the risk of failure, an aspect of the JPL culture that is represented in the statements in Figure 1. Where the Mars Viking mission employed conventional rockets to touch down on the surface in 1976, Mars Pathfinder in 1997 demonstrated a novel landing system that deployed a parachute, lowered the lander on a tether, and then inflated a set of airbags before the rover dropped 100 feet to bounce across the plain. The mission was envisioned as a proof-of-concept for the various technologies, then unproven in spaceflight, that would enable future Mars surface exploration. Pathfinder returned more than 2.3 billion bits of information, including 16,500 pictures and 8.5 million science measurements, and it proved exploration technologies for use in future generations of Mars rovers. Figure 1. Employee viewpoints expressed in \u201cJPL Culture of Innovation\u201d video (Reference (3)) JPL invents products where we may make only a single unit that is designed to go somewhere previously unreachable. JPL takes prudent risks where design solutions are subjected to rigorous engineering analysis and test. A culture that discourages employees from taking risks may stifle innovation on spaceflight missions that are clearly not for the timid. References: \u201cNASA Study of Flight Software Complexity,\u201d NEN #2050, NASA Lesson Learned Information System (LLIS), May 5, 2009. Rob Manning, \u201cCan Failure be a Measure of Success?,\u201d JPL LEAP Seminar, March 24, 2017. https:\/\/jpltube.jpl.nasa.gov\/Watch=vJztL7 \u201cJPL Culture of Innovation,\u201d September 15, 2016. https:\/\/www.youtube.com\/watch?v=RFrGkSyxTgI http:\/\/ethics.jpl.nasa.gov","Lesson ID":21601}
{"Driving Event":"The James Webb Space Telescope (JWST) Integrated Science Instrument Module (ISIM) thermal control system includes aluminum foil thermal straps for controlling heat flow to and from temperature-critical instruments in order to meet science instrument thermal performance requirements. A stackup of aluminum 1100, indium spacer and high purity aluminum foil in compression, as well as threaded inserts in aluminum 1100 in tension, was used in many of the thermal strap joints to improve thermal conduction through the bolted interfaces of the strap assemblies. Figure 1 shows the material stackup of a typical joint. After the second ISIM cryogenic vacuum test, an inspection of the thermal strap joints was requested from the ISIM thermal team. During the inspection, loosened bolts were found in the thermal strap joints attached to the ISIM structure.1,2 Figure 2 shows an example of one of the thermal strap joint configurations on ISIM. A re-design of the thermal strap joints, including re-sizing of the threaded inserts and an updated torque application of the bolted joints3, was necessary to ensure mechanical integrity and maintain thermal performance.","Lesson ID":22003}
{"Driving Event":"In March 2017, a Chinese vulnerability assessment company posted an exploit for the popular Apache Struts2 web framework. Within hours, an addition to a common penetration testing application called Metasploit had been added that would scan for this vulnerability. This caused the attack vector of the exploit to be rapidly distributed before the software vendor could post a patch update to fix the issue. This zero-day exploit was quickly picked up by several malicious groups and used to attack websites using the Struts2 framework. Among those attacked were several public-facing NASA sites, including NASA TechPort (https:\/\/techport.nasa.gov). Up to this point, the only mention of this vulnerability by the software vendor was a post on their wiki page describing a potential vulnerability of moderate concern - no Mitre Common Vulnerabilities and Exposures (CVE) had been created and no patch release had been announced. The issue was further exacerbated by the notoriously high level of effort required to update the Struts2 software package due to extensive dependencies and breaking changes between major release versions. Because the NASA TechPort Team had incorporated log-monitoring and notification mechanisms, they were notified within a matter of minutes of suspicious behavior. The TechPort Team immediately invoked their Incident Response Plan and gathered the key members of the Response Team, which included the system administrator, security lead, and technical lead. After assessing the situation and determining that no patch was available from the vendor, the TechPort Team devised a custom solution to the issue which was rapidly tested and deployed. The success of this fix was primarily due to the TechPort Team\u2019s DevOps working model and the rapid deployment capabilities of a team-operated cloud computing environment.","Lesson ID":21301}
{"Driving Event":"Located on the JPL campus near the East Gate, Building 159 contains several electric motor-driven pumps (Figure 1) that pump water to cisterns located on the hillside above the building. Figure 1. The pumps inside Building 159. The left photo shows the light blue water pumps that are driven by dark grey electric motors behind them. In the middle photo, a red arrow points to the sheet metal guard over the coupling that connects each pump to its corresponding motor. The right photo shows the pump controls. At 10:00 pm on Saturday, July 19, 2014, Pump No. M1608 stopped pumping water when the 3\/16 x 3\/16-inch steel key failed: this key transmitted the torque from the pump-side coupling hub to the pump shaft. The electric motor continued to spin the pump-side coupling hub on the pump shaft until frictional heating caused the shaft to fail in a \u201cburn off\u201d mode. The 50 horsepower, 3550 rpm motor then propelled this 10-pound cast iron jaw coupling hub (Figure 2 left) through a sheet metal guard (Figure 2 top) and then through the window above the door to Building 159 (Figure 3). The pump-side coupling hub flew across Explorer Road and struck the railing on the southwest corner of the bridge over the Arroyo Seco outside the JPL East Gate\u2014a distance of about 95 ft.\u2014and came to rest on the sidewalk near the southeast end of the bridge (Figure 4). Figure 2. The left photo shows Pump No. M1608\u2019s cast iron jaw coupling, with the twisted off section of the pump shaft remaining in the bore. The top right photo shows the remains of the guard that covered the failed coupling; the guard prevents workers from coming into contact with the spinning coupling. The bottom right photo shows the remaining stub of the twisted-off pump shaft protruding from the blue pump, and the grey motor-side coupling hub that \u201cpitched\u201d the pump-side coupling hub through the guard. Figure 3. Hole in window through which pump-side coupling hub exited Building 159. Figure 4. The left photo shows the damage to the concrete railing. The right photo shows where the hub came to rest on the far (southeast) end of the bridge, approximately 250 ft. beyond the initial point of impact. Preventative maintenance had been performed on all three pumps in Bldg. 159 only five days prior to the incident, and no issues were identified with the pump that later failed. The proximate cause of the mishap was the shearing of the shaft key into two pieces. (Reference (1)). This likely happened during motor starting, since during a start this 50 horsepower motor can deliver more than twice its rated torque. The root cause was probably the replacement of the original shaft key with a used key that was a different size. In addition, it appears that the used key was installed upside down compared to its previous uses. After a few starts, this likely resulted in at least a partial loss of preload in the set screw which clamps it against the bottom of the shaft keyway. After the key sheared, the relative motion of the spinning pump-side coupling hub with respect to the pump shaft caused rapid frictional heating that weakened the pump shaft to failure. A separate failure investigation (Reference (2)) by the JPL Facilities Division pointed to excessive pump on\/off cycles that were programmed to maintain the water level in the water storage tank to within a one-inch deadband. Reference (2) suggests that the programming was incorrect, resulting in too frequent pump starts and stops. It also identified \u201cage and fatigue\u201d as affecting the keystock material strength. The mishap caused no injuries and only minor damage to facilities. References: Mark Balzer, \u201cFailure Analysis of Building 159 Pump House Incident,\u201d 352E-MB-1402, December 16, 2014. Mark Kanipe, \u201cEMCOR Root Cause Analysis - Bldg. 159 Pump Failure,\u201d August 25, 2014.","Lesson ID":20201}
{"Driving Event":"During checkout testing of the single component force balance for the jet exit rig we discovered significant hysteresis in the load cell measurement, much more than would be expected for this type of measurement system. Examination of the screws in the load cell string, and the tolerances on the relevant drawing, led to the conclusion that the mounting blocks and flexures were not adequately attached to each other. Figure 1: A fairly typical load cell string","Lesson ID":18701}
{"Driving Event":"Vibration overtest close call of the Global Precipitation Measurement (GPM) mission Power System Electronics Box","Lesson ID":18601}
{"Driving Event":"Prior to start of I&T activities, the MMS Standing Review Board (SRB), Aerospace Corporation and HQ all identified significant risk that the MMS I&T plan for the multiple build effort would encounter issues leading to major cost and schedule increases. The MMS project planned every event in detail beforehand and included all players involved in the planning process. Although, the MMS I&T plans changed over time, the I&T effort went extremely well.","Lesson ID":19601}
{"Driving Event":"The Atmospheric Infrared Sounder (AIRS) is a scanning instrument that was launched in 2002 aboard NASA's Aqua satellite to support Earth climate research and to improve weather forecasting. The Advanced Microwave Sounding Unit-A (AMSU-A) is a 15-channel microwave temperature sounder on AIRS that includes two independently operated modules. One of these (AMSU-A2) provides science data on Earth moisture (total precipitable water and cloud liquid water). On September 24, 2016, without any warning signs from downlinked telemetry, the AMSU-A2 instrument experienced a sudden loss of the power supplied by the Aqua satellite (Reference (1)). (All other instruments on Aqua continued to operate nominally.) The Aqua relays controlling quiet bus power to the instrument did not respond to ground commands. The AMSU-A manufacturer concluded that a fuse blew in the spacecraft power circuit associated with the AMSU-A2 quiet bus relays, and that the proximate cause was most likely a short or overcurrent condition in the AMSU-A2 instrument. Recovery of AMSU-A2 operation would have required switching it to a redundant power bus, but this was considered risky because of possible anomaly-induced damage and because of the likelihood that the large current surge upon powering would harm other Aqua instruments residing on the redundant power bus. Hence, the decision was to leave AMSU-A2 non-operational. AMSU-A2 had already completed its primary mission, and loss of AMSU-A2 science return in the extended mission was determined to pose a minor impact on Level 2 AIRS science products. The AIRS Operations Team agreed (Reference (2)) with the contractor\u2019s analysis that the most likely AMSU-A2 subsystem to have developed a short or overcurrent condition was the DC-DC converter. Although the root cause of the failure is unknown, it could possibly have been caused by a high energy ionizing particle inducing a single event upset (SEU). They also noted that the AMSU-A2 Power Control Assembly and DC-DC Converter lacked circuit protection such as crowbars, which restore function by recycling the power. References: \u201cAMSU-A2 quiet bus anomaly,\u201d JPL Incident Surprise Anomaly (ISA) No. 60251, September 27, 2016. William Mathews & Fred O\u2019Callaghan, \u201cAMSU-A2 Anomaly of September 24, 2016,\u201d January 31, 2017.","Lesson ID":19501}
{"Driving Event":"Polyimide tape (Figure 1) is used extensively in the fabrication of spacecraft as an insulation and protection layer on electrostatically sensitive and fragile components. The features of this thin, flexible, film include light weight, a low outgassing rate, stability at temperature extremes, and thermal conductivity even at very low temperatures. Polyimide tape is manufactured in electrically conductive and non-conductive versions; the black-colored conductive version, which contains tiny nickel-plated spheres embedded in its adhesive, is considered to be non-magnetic. Figure 1. Applications for polyimide tape The NASA\/Caltech Jet Propulsion Laboratory (JPL) launched the Juno spacecraft on its mission to Jupiter in August 2011. Juno\u2019s science instruments include two fluxgate magnetometers (FGMs) and one scalar helium magnetometer (SHM) that will map the planet\u2019s magnetic field, determine the dynamics of its interior, and determine the three-dimensional structure of Jupiter\u2019s polar magnetosphere and its auroras. These sensors are located on the end of one of the three solar arrays on a small boom 12 meters from the center of the spacecraft (Figure 2); this location is intended to assure that the sensors will not be magnetically contaminated by stray magnetic fields generated by the spacecraft bus. Figure 2. Location of magnetometers on Juno spacecraft Electrically conductive polyimide tape was applied by the system contractor to the Juno solar panels at the magnetometer attachment point. Subsequent testing revealed the presence of an unanticipated magnetic field, and further investigation traced the source of the magnetic contamination to the polyimide tape. Analysis of this anomaly attributed the magnetic field to the conductive adhesive on the tape: it employs microscopic plastic spheres plated with a nickel-phosphorus alloy for electrical conductivity. Nickel does not normally take a magnetic charge. However, the tape manufacturer\u2019s supplier sought to control the phosphorous content of the nickel because it inhibits the plating process. While this alloy is non-magnetic when the phosphorus content is greater than 11.2 percent (Reference (1)), low phosphorus nickel is highly magnetic. There was no information available in the documentation provided with the widely-used conductive polyimide tape to indicate to the JPL Magnetic Control Review Board (MCRB) that there was a risk that this tape could become magnetized. Further inquiry by the Juno project showed that an electrically conductive foil used to wrap wires on Juno was also not recognized for its potential to become magnetized due to the nickel alloy content in that material (Reference (2)). It should also be noted that Juno employs survival heaters to protect the instruments during spaceflight. In such cases, even suspect materials may not be adequately reviewed. If undiscovered, the magnetization of the tape on the boom and on the wires could have degraded the science results from the spacecraft\u2019s magnetometer instruments. References: ASTM B733 \u2212 15, Standard Specification for Autocatalytic (Electroless) Nickel-Phosphorus Coatings on Metal, November 1, 2015. \u201cBlack Kapton\u00ae Magnetic Characterization,\u201d Juno Project, June 8, 2010. \u201cSpacecraft DC Magnetic Cleanliness for JPL Flight Systems, Subsystems and Assemblies, Rev. 0\u201d JPL Document DocID 78656, October 26, 2012, Section 7.2.2. NASA-STD-(I)-6016, Standard Materials and Processes Requirements For Spacecraft, September 11, 2016, Sec. 4.1.2.","Lesson ID":18901}
{"Driving Event":"LandSat-8 Thermal Infrared Sensor (TIRS) on-orbit anomaly, Magnetospheric Multi-Scale Mission integration and test (I&T)","Lesson ID":18502}
{"Driving Event":"The Nuclear Compton Telescope launch failure on April 29, 2010 in Alice Springs Australia.","Lesson ID":18503}
{"Driving Event":"The GPM Core Observatory left NASA Goddard on November 19, 2013 and arrived at its destination in Japan on November 24, 2013. The 7,300 mile journey started at the Goddard Space Flight Center in Maryland, with the observatory being transported by truck to Andrews Air Force Base where the container was loaded onto an Air Force C-5 transport aircraft. The next step was expected to be a 15-hour flight, followed by a journey on a barge to reach the island of Tanegashima in Southern Japan and a last stretch by truck to the launch pad. While the launch happened as expected and GPM performed well, the journey from Goddard to the launch site was not without obstacles. One such obstacle was the weather. Unanticipated headwinds prevented the planned in-flight refuel. The flight was forced to land for refueling in Anchorage, Alaska. A wind storm turned what could have been a two-hour stopover into two days. Given the complexity of the transport, the delay has significant impacts on preparations in Japan. Resources: GPM Ships Out to Japan for Launch, November 25, 2013. https:\/\/svs.gsfc.nasa.gov\/11424 New Video Shows GPM\u2019s Journey to Japan. https:\/\/pmm.nasa.gov\/articles\/new-video-shows-gpms-journey-japan","Lesson ID":18401}
{"Driving Event":"The Interface Adapter Module (IAM) of the Stratospheric Aerosol and Gas Experiment III on the International Space Station (SAGE III on ISS) provides electronics interfaces between the various elements of the instrument and the ISS. The IAM flight software is responsible for ensuring that its stored data is not lost or unusable by a single corruption or failure of flash memory.","Lesson ID":18803}
{"Driving Event":"Typical software developments require interfacing with commercial hardware through software applications called drivers. These drivers are often identified early during the design and implementation, installed onto the development machines, and then overlooked without being configuration managed. However without these support drivers, the developed solution cannot be transitioned to other similar hardware. In addition if the hardware being used experiences failure, it can become a research effort to re-identify the required drivers, locate their sources, and re-establish the supporting environment (hardware and software).","Lesson ID":18801}
{"Driving Event":"NPR 7150.2 requires four process requirements related to bidirectional traceability. These requirements consist of tracking software requirements at six multiple levels from the top-down and bottom-up. This includes between the software requirements and higher-level requirements, software requirements and software architecture, software architecture and software design, software requirements and software design, software design and software code, and software requirements and software test procedures. SAGE III on ISS met the intent of these requirements by tracking them within the existing Requirements Management processes established by the project\u2019s Systems Engineers. This process established a structured method of handling requirements definition, management, and verification using CORETM as their primary tool. This process provided for systematic identification of the flight software requirements and automated the traceability of the software requirements to the higher and lower level requirements along with the verification artifacts. The verification process included the normal software test processes that ensured the requirements and software works in the intended operational environment. This confidence is gained by running the software at various levels against test scenarios designed to detect failures or defects while accomplishing the intended functions (requirements). The software product\u2019s technical excellence was assured through the normal project and Branch-level Peer Reviews and project technical reviews which involved the project management, engineering, assurance, and Branch-level Technical Authorities.","Lesson ID":18802}
{"Driving Event":"Initial structural random vibration testing on the Stratospheric Aerosol and Gas Experiment (SAGE) III on the International Space Station (ISS) Instrument Adapter Module (IAM) and Contamination Module Package (CMP) Engineering Development Units (EDUs) showed structural responses high enough to potentially fail the CMP\u2019s Temperature-controlled Quartz Microbalance (TQM) sensors. The CMP was originally hard mounted to the top of the IAM, but this system produced amplified responses in the CMP. To reduce the response, wire rope isolators (WRIs) were installed between the CMP and IAM at the four interface locations. Initial analysis models predicted new responses which did not closely match the test results with the isolators. A stiffness and damping correlation study was done on the WRIs which showed stiffness values different than vendor-published data and non-uniform damping rates across the frequency spectrum of interest. After these variations in the isolators were included in the analysis models, predicted responses more closely matched the test results.","Lesson ID":19101}
{"Driving Event":"From the \u201cOverview of the Orbiting Carbon Observatory (OCO Mishap Investigations Results For Public Release\u201d memo: \u201cThe Orbiting Carbon Observatory was a National Aeronautics and Space Administration satellite mission that was launched on an Orbital Taurus XL launch vehicle. On Feb. 24, 2009, the OCO mission (Taurus T8) lifted off from Launch Complex 576-E at Vandenberg Air Force Base (VAFB) in California at 4:55:31 a.m. EST. \u201cThe OCO mission was lost in a launch failure when the payload fairing of the Taurus launch vehicle failed to separate during ascent. A payload fairing is a clamshell-shaped cover that encloses and protects a payload on the pad and during early flight. Fairings are a standard component of expendable launch vehicles, and they are always jettisoned as soon as possible after a launch vehicle has achieved an altitude where aeroheating is no longer a risk to the satellite. On this flight, the fairing should have been jettisoned shortly after Stage 2 ignition. However, the fairing remained attached for the remainder of the flight. The OCO satellite was separated from the Stage 3, but was contained within the still attached fairing.\u201d From the \u201cOverview of the Glory Mishap Investigations Results For Public Release\u201d memo: \u201cThe Glory spacecraft was a NASA satellite mission launched March 4,2011, as the primary payload aboard an Orbital Sciences (Orbital) Taurus XL T9 launch vehicle from Space Launch Complex 576-E at Vandenberg Air Force Vase (VAFB) in California. Liftoff was a 2:09:44.418 a.m. PST. \u201cThe mission proceeded nominally through Stage 2 ignition\u2026but the fairing failed to separate as planned.\u201d","Lesson ID":15702}
{"Driving Event":"This lesson was learned during TVAC testing (Nov 2013 \u2013 February 2014) of the SAGE III on ISS IA and the subsequent model correlation effort. During the IA TVAC Test, quartz halogen lamps were used to achieve temperature settings within the LaRC 8\u2019 x15\u2019 TVAC chamber. The subsequent correlation of the thermal model was delayed because in the initial runs to correlate the model, many components were far hotter in test than in the model, even during the unpowered conditions. This led to the discovery that the quartz lamps in the 8\u2019x15\u2019 chamber produced a significant fraction of their output (70-90%) in the solar spectrum, rather than in the infrared (IR) spectrum as expected. Since the thermal model for this test setup had assumed only infrared (IR) radiation, correlation using the existing model was not feasible. Materials on the exterior of the SAGE III IA consist primarily of silver Teflon. The solar absorptivity of silver Teflon is less than its IR absorptivity by a factor of 16. In addition, the aluminum of the TVAC support tray had a relatively high solar absorptivity. These factors meant that the radiant heating within the chamber was radically different than in the thermal model. To accurately model the true behavior within the chamber, a different set of optical properties would be needed for each lamp setting; a higher lamp setting moves the peak of the spectrum farther into the solar range, and changes the material\u2019s absorption of that flux. In addition, if the lamps are modeled explicitly, several different radiation cases must be run, one for each lamp bank, for each flux waveband fraction. Realistically, each radiation case with a different lamp setting should use different material optical properties. This is exceedingly difficult to do. In addition to requiring more model development time and more model uncertainty, the run times for the model will be four times longer since there will be more radiation runs necessary. Runs of transients would not be feasible, which substantially impacts the modeling capability. An uncorrelated thermal model would mean that thermal predictions for flight would be less accurate. To be able to correlate the IA thermal model to the testing that was performed, a characterization test was run in April 2014 (SAGE III-05-385-TR-001). This test allowed characterization of the solar flux level within the chamber and the chamber thermal gradients, which allowed improved correlation of the IA thermal model (SAGE III-THM-052). Due to the complexity and uncertainty involved in correlating thermal models to test data obtained while quartz lamps are operating, as well as the importance of the accuracy of the system-level IP model correlation, it was necessary to determine a way to complete Instrument Payload (IP) TVAC testing without using the lamps. A Ground Support Equipment (GSE) heater plate system was designed which allowed the IP temperature targets to be achieved with the use of the 8\u2019 x 15\u2019 chamber\u2019s cold shroud and without using the quartz lamps. This heater plate system is described in SAGE III-10-137, and proved successful in allowing the IP temperature targets to be achieved while collecting data that was useful for model correlation. These heater plates continue to be used in the 8\u2019 x 15\u2019 chamber by other projects.","Lesson ID":18804}
{"Driving Event":"The Chandra X-ray Observatory is part of NASA\u2019s fleet of \u201cGreat Observatories\u201d along with the Hubble Space Telescope, the Spitzer Space Telescope, and the now deorbited Compton Gamma Ray Observatory. The observatory was designed to detect x-ray emissions from some of the hottest regions of the galaxy including exploded stars, clusters of galaxies, and matter around black holes. One of the observatory\u2019s key scientific instruments is the Advanced CCD Imaging Spectrometer (ACIS), which is one of four primary and two focal plane instruments. Due to the sensitivity of the charged coupled devices (CCD\u2019s), an aperture door was designed and built by Lockheed-Martin that protected the instrument during testing and the time leading up to launch. Because the actuators had a significant flight heritage of flawless performance, it was determined that a single paraffin actuator with redundant heaters would be adequate for a one-time on orbit activation requirement. This meant a failure of the actuator on-orbit would mean loss of mission. While in the vacuum chamber on June 18, 1998, opening the ACIS door was planned in a final test so that instrument could be evaluated for light leakage in the spacecraft. When the opening procedure was run, the door failed to open. This failure caused a serious concern with the team leadership. No flaw in the design or operation of the door was discovered. A new door procedure was tested multiple times in a different facility and opened as expected. Program management had to decide whether or not to launch the telescope given that a test failure was still unexplained and the single string fault would mean loss of mission.","Lesson ID":17901}
{"Driving Event":"In the early 1990\u2019s US and Italian scientists collaborated to study the electrodynamics of dragging a satellite on a tether through the electrically charged portion of Earth's atmosphere called the ionosphere. An electrical current induced in the long wire could be used for power and thrust generation for a satellite. Other tether uses include momentum exchange, artificial gravity, deployment of sensors or antennas, and gravity-gradient stabilization for satellites. Before the Tethered Space Satellite (TSS-1), no long tether had ever been flown, so many questions existed on how it would actually behave. Pre-flight testing system level tests involved setting up a tether receiver to catch the 12.5 mile tether onto another reel as it was being unwound by the deployer reel mechanism. Testing only the reel mechanism is straightforward. This test becomes more complicated when the TSS is mounted on the flight pallet at Kennedy Space Center (KSC). A few months before flight, the TSS payload had been integrated onto the Spacelab pallet and system level tests, including unreeling and reeling the tether, had been successfully completed. Some of this testing equipment was then shipped back to the contractor. Systems-level load analyses, which cannot be run until all information about each payload is finalized, was run in parallel with the physical integration of the hardware into the Shuttle payload bay. The coupled loads analysis revealed that a single bolt attaching the deployer reel mechanism to the support structure had a \u201cnegative margin\u201d \u2013 which is an indication that it might fail during operation. Hardware certification rules do not allow for hardware to fly with negative margins, so this issue had to be resolved before the flight. Since there is conservatism in engineering analysis, there is an option to \u201cwaive\u201d the margin requirement, and fly the experiment as is. On the other hand, a structural failure of one payload could have serious or catastrophic consequences to other payloads and possibly the mission. Minor design changes or fixes might be feasible within the payload bay prior to launch. Any major design changes that required the spooling test to validate the hardware, or for the pallet to be removed, would cause TSS not to be ready for the Shuttle launch. A decision was made to replace the bolt predicted to have a negative margin with another bolt that required a slight configuration change. When the satellite experiment was being deployed, the tether hung up on the modified bolt configuration, preventing successful deployment of the satellite.","Lesson ID":17905}
{"Driving Event":"The Space Shuttle was developed by NASA to be a largely reusable launch system which could provide frequent access to low earth orbit. Like all previous launch systems, safe reentry for the crew and payload required the use of a thermal protection system (TPS). Unlike previous spacecraft though, the Shuttle\u2019s TPS was exposed from launch, making it sensitive to debris which could be generated by the vehicle on ascent. The most likely and potentially destructive source of debris was considered to be ice, which could build-up anywhere on the External Tank (ET) where there was exposed metal. Ice could form during ground operations after the cryogenic propellants had been loaded and then be knocked loose on ascent. In order to prevent both ice build-up and boil-off of the propellants, the entire ET and all protuberances (orbiter attach points, pressurization lines, propellant feed lines, etc.) were covered with a spray on foam insulation (SOFI) type TPS. Unfortunately the foam was also susceptible to liberation during ascent, and posed a debris risk of its own. In February of 2003, during ascent on STS-107, an ~2 pound piece of foam was liberated from the left ET bipod and impacted the leading edge of Columbia\u2019s left wing. The resulting damage to the Reinforced Carbon-Carbon TPS in that location was severe enough that on reentry a jet of hot gas was able to enter the vehicle. The eventual structural failure of the wing and resultant loss of control led to vehicle break-up, and the loss of the entire crew. Following the Columbia tragedy the Space Shuttle fleet was grounded for two and a half years to determine the root cause of the incident and implement the necessary design changes. On July 26, 2005, Space Shuttle Discovery launched on the Return to Flight (RTF) mission, STS-114. On ascent, the ET shed foam from numerous locations, where the largest piece was twenty-five times greater than the certified limit. The shuttle fleet was grounded again and two separate in-flight anomaly (IFA) teams were established to determine the root cause of each piece of debris. On June 26, 2006 the Space Shuttle Program held the STS-121 Flight Readiness Review (FRR). The ET Project provided a status of the design and process changes addressing the IFA teams\u2019 recommendations for ET-119, the external tank on this next scheduled flight. The FRR board\u2019s responsibility was to determine if the vehicle was acceptable to fly. This was the second Return to Flight mission since the Columbia accident.","Lesson ID":17903}
{"Driving Event":"The FASTRAC engine project was initiated to demonstrate the feasibility of low cost engine development, give early career propulsion engineers hands-on hardware experience and end-to-end design experience, grow the experience base of propulsion systems engineering, and enable the NASA propulsion community to become a \u201csmart buyer\u201d for future propulsion systems. Commercial, off-the-shelf technologies and common manufacturing methods were adapted to broaden competition and aid in producing lower cost hardware. Development of the FASTRAC engine would institutionalize future rocket development projects and flight hardware procurement activities. NASA had been studying the Bantam booster at the time as a low cost launch vehicle. The Bantam vehicle was designed around a propulsion test article to be used to test FASTRAC engines at Stennis. The requirements for the test configuration correlated between FASTRAC and the Bantam Booster. Rather far along in the development of the FASTRAC engine, NASA selected a contractor to integrate a flight demonstration vehicle from another program, X-34, with the FASTRAC engine. NASA signed a memorandum of understanding with the contractor who was given lead responsibility for vehicle design, fabrication, integration, and initial flight testing for powered flight of the X-34 test vehicle. MSFC was to develop the engine for the X-34. The original engine requirements did not correlate with the X-34 vehicle requirements and the dynamics of the contract structure led to misunderstandings between MSFC, the contractor, and NASA headquarters. This case study illustrates a type of government-contractor relationship that introduced communication problems needing resolution.","Lesson ID":17802}
{"Driving Event":"Test site selection is a critical element of the design, development and production of a new system. With the advent of the new Space Launch System (SLS), the National Aeronautics and Space Administration (NASA) had a number of test site selection decisions that needed to be made early enough in the Program to support the planned Launch Readiness Date (LRD). This case study focuses on decisions that needed to be made in 2011 and 2012 in preparation for the April 2013 DPMC decision about where to execute the Main Propulsion Test that is commonly referred to as \u201cGreen Run.\u201d Those decisions relied upon cooperative analysis between the Program, the Test Lab and Center Operations. The Program decided to perform a single green run test on the integrated core stage prior to shipment of it to Kennedy Space Center (KSC) for use in the EM-1 test flight of the SLS vehicle. The SLS Program had to decide where to perform SLS green run testing.","Lesson ID":17902}
{"Driving Event":"The NASA\/Caltech Jet Propulsion Laboratory (JPL) makes extensive use of high fidelity testbeds, incorporating flight or flight-like hardware and software, for system development and for system-level test with the equipment powered. During mission operations following launch, the testbed also performs an essential role in reproducing and correcting the problems and failures that occur to spacecraft during spaceflight and surface operations. Assuring that a JPL project has adequate components to support extensive testing in the testbed has proven to be a success factor for projects that typically launch only a single spacecraft. Consequently, a system testbed may contain hardware that the project cannot replace. The system testbed for the Mars 2020 rover project is located in a JPL test facility that also houses the testbeds for Mars Science Laboratory (MSL) and Mars Exploration Rover (MER). They share a common humidifier system for treating ambient airflow in the vicinity of the testbeds. At 7:00 am on July 2, 2014, a project engineer observed that a warning indicator light on the humidifier\u2019s secondary containment drip evaporator overflow pan was illuminated, and he immediately covered the hardware on the Mars 2020 testbed with an anti-static plastic sheet. A few minutes later, water streamed onto the covered equipment (Reference (1)). It was quickly determined that the humidifier system strainer was plugged, causing water (instead of steam for humidity control) to spray into the air plenum located in the ceiling and to stream onto the covered equipment (Figure 1). No damage to any testbed equipment occurred. The humidifier alarm is connected to an emergency notification system that alerted the JPL (on duty 24\/7) facility maintenance contractor; they responded to the alarm, turned off the water and cleaned the plugged strainers. Subsequent investigation, however, established that the preventative maintenance instructions for the building did not show the location of the strainers; nor did they require periodic cleaning of the strainers, which had never been cleaned (Reference (2)). JPL System Safety (Reference (3)) views this incident as a \"close call\": if it had occurred late at night or if alert staff had not been present, significant damage to irreplaceable Mars 2020 flight development and flight support hardware would have resulted. In addition, the incident presented a personnel safety slip hazard because the secondary drain routed overflow onto the smooth tile floor directly in front of the access doors to the facility. This incident also added to the impression that the testbed facility has had a trend of anomalies since 2003, including a negative pressure event (Reference (4)) where the air conditioning vents pulled air out instead of blowing it in. (This made it \u201cnearly impossible\u201d to open the outward-hinged doors.) It was discovered after this air conditioning event that (like the building reported in Reference (5) that experienced a flood) the building was not on the JPL critical facility list. References: JPL Mishap Report No. 3087 (Bldg. 317), July 2, 2014. \u201cWater leak on ceiling in RCE lab on 7\/2\/2014,\u201d JPL Problem\/Failure Report No. 56641, July 8, 2014. \u201cJuly 2014 Testbed Mishap,\u201d e-mail from Matthew Riley, May 11, 2016. \u201cWater leak in CETB lab,\u201d JPL Problem\/Failure Report No. 56630, July 7, 2014. \u201cPoor Coordination of Routine Maintenance Spoiled an Important Test,\u201d NEN No. 10401, NASA Lesson Learned Information System (LLIS), August 11, 2014. \u201cProvide Adequate Maintenance and Hazard Response for UPS Units,\u201d NEN No. 12101, NASA Lesson Learned Information System (LLIS), July 14, 2014. JPL Mishap Report No. 0100 (Bldg. 318), November 11, 2002. JPL Mishap Report No. 1995 (Bldg. 306), November 13, 2009. JPL Mishap Report No. 2001 (Bldg. 306), November 24, 2009. JPL Mishap Report No. 2365 (Bldg. 317), February 17, 2011. JPL Mishap Report No. 1822 (Bldg. 179), February 14, 2009. \u201cEnsure Test Monitoring Software Imposes Limits to Prevent Overtest,\u201d NEN No. 1529, NASA Lesson Learned Information System (LLIS), October 11, 2004. \u201cContamination of the Mars Observer Spacecraft by Environmental Conditioning,\u201d NEN No. 441, NASA Lesson Learned Information System (LLIS), August 23, 1996.","Lesson ID":17701}
{"Driving Event":"During the course of GN2 V&V operations in the MPPF, personnel noted heritage panels labeled as \u201cGaseous Outlet Panels\u201d. One such panel, located on the south wall had been previously opened and remained open enough to see inside, all of the gaseous lines were clearly capped\/terminated, leading personnel to assume that all 6 of the similar GN2 panels shared the same configuration. After testing was initiated and facility GN2 pressure was applied, another cabinet was opened and it was observed to still have valves, regulators, gages, etc. installed for both the GN2 and Gaseous Helium (Ghe) systems and that pressure was present. Further investigation identified that 4 of the 6 heritage panels had valves, regulators, and gages rather than capped lines. Following discussions with GN2 Systems Engineers, Lead Design Engineers, Facility representatives, and Chief Engineers, the V&V work was halted until the panels could be more thoroughly evaluated and placed into a safe configuration. KSC utilizes different organizations to operate and maintain different types of systems (e.g. Information Technology systems, facilities and facility systems, or Ground Support Equipment). The GSDO Program also used various organizations to do facility modifications and Ground Support Equipment. The situation is also complex because of the mixture of unmodified heritage systems and new\/modified systems. The MPPF facility GN2 system is partly unmodified heritage and partly new\/modified. The drawings for the heritage part of the system were created and maintained by an organization different than that designing and implementing the new\/modified part of the system. This leads to multiple organizations with responsibilities in the same facility and different groups may be modifying or maintaining different parts of the same system. Facility modification drawing (245G2200002) does not consistently identify supply lines, and the interior layout of the panels was unclear.","Lesson ID":17601}
{"Driving Event":"A pilot effort was conducted on the CxP Extravehicular Activity (EVA) Project as part of the Agency\u2019s Earned Value Management Capability Project. This pilot effort drove the identification of the issue regarding inconsistent WBS element nomenclature.","Lesson ID":5862}
{"Driving Event":"During the EFT-1 recovery operation, several events delayed the recovery operation. These include: 1) time required to reconfigure support equipment to prevent equipment failure; 2) time required to accomplish underwater heatshield imagery; and 3) time required to pass tending lines from the recovery ship to small boats. In addition, there was a pre-determined procedural delay to measure thermal soak back (the amount of thermal energy absorbed by the CM). As a result, the time from splashdown to CM secured in the well deck exceeded seven hours. Figure 1. The capsule floating in the water alongside the recovery ship is connected to a cable and pulled into the ship.","Lesson ID":14801}
{"Driving Event":"The Orbiting Carbon Observatory (OCO), an Earth-orbiting satellite mission managed by the NASA\/Caltech Jet Propulsion Laboratory (JPL), was designed to make precise, time-dependent, global measurements of atmospheric carbon dioxide (CO2)\u2014a greenhouse gas related to climate change. OCO was a cost-constrained project, and when the OCO spacecraft was lost due to a launch vehicle separation failure, the follow-on OCO-2 project was intended to feature a design identical to OCO with as few changes as possible. The OCO\/OCO-2 instrument does not measure CO2 directly, but rather the intensity of the sunlight reflected from the presence of CO2 in a column of air. Three spectrometers each use a diffraction grating (Figure 1) to separate the incoming sunlight into a spectrum of multiple component colors. The need to detect very small variations in intensity over a range of 3048 different colors requires high instrument resolution and precision. As the spacecraft follows a near-polar ground track, Earth observations made by the instrument switch periodically between the Nadir, Glint, and Target modes, with the Glint mode suited to observing solar radiance reflected from the ocean surface. Figure 1. The OCO-2 weak band diffraction grating (above) functions similar to the surface of a compact disk or DVD During the initial on-orbit checkout of OCO-2 following the July 2014 launch, it was discovered that the data produced by Glint mode observations did not match the model (Reference (1)). Further investigation (References (2) and (3)) revealed that the instrument design failed to transmit light polarized parallel to the long axis of the aperture slit, as needed for Glint mode. This results in the anomalous (decreased) radiance levels shown in Figure 2. (This anomaly has a much smaller impact on other observation modes, and it only affects Glint mode observations over the ocean\u2014most strongly at solar zenith angles near 52 degrees (i.e., the Brewster angle for seawater).) Figure 2. This plot of actual Glint mode radiance levels received on-orbit shows that they fail to track to the desired polarization. View larger image This design error was discovered neither in the design process, in the review process, nor by the ground test program. The error originated from a decision, made shortly before the OCO Preliminary Design Review (PDR), when a design change was implemented. Specifically, the original requirement to make the design insensitive to polarization could not be met, so the instrument was redesigned for a single polarization. The implications of this modification were not recognized by the JPL or contractor system engineers. The OCO-2 project repeated the OCO build and test activities without performing a critical review or validation of the OCO requirements and design. Factors contributing to the flight anomaly included: When responsibility for OCO Optics Subsystem assembly and test was transferred to JPL from the contractor in November 2006, the Level 4 (Subsystem) and Level 5 (Assembly) requirements were not transferred. JPL selected some Level 3 (Instrument) requirements to use for Level 4 requirements, but the polarization orientation requirement (L3G.279) was not selected. The comment associated with this decision was, \u201cIf we trust vendor data, impossible to miss.\u201d There was a conscious decision that Level 3 test would be sufficient to verify the remaining requirements. (The polarization orientation was also not covered by the Hardware Review & Certification Record (HRCR) process. See Reference (4).) Among the items listed on the Summary of Instrument Changes prepared by the OCO project in March 2003, \u201cpolarization\u201d did not appear. Subsequently, the summary of the June 2004 OCO PDR makes no reference to polarization. (Members of the OCO team felt that they were rushed to PDR and had to select only critical design elements for emphasis\u2014that excluded polarization). The OCO-2 project employed a highly tailored formulation period ending with Critical Design Review (CDR). No System Requirements Review (SRR) or PDR was held, implying a high degree of trust in the work done by the OCO project. Near the beginning of integration and test (I&T) for the OCO mission, the project decided to bring the instrument in-house from the contractor. This resulted in a transfer of I&T and verification and validation (V&V) roles to JPL without adequate continuity of involvement by the instrument designers in test design. The system test of the instrument did not include verification of the absolute polarization angle. There was no opportunity to test the instrument at the Observatory System level prior to launch. Despite the polarization anomaly, OCO-2 is able to achieve the volume and quality of science data specified in Level 1 requirements due to the implementation of an operational workaround. Using attitude control to rotate the entire spacecraft closer to the instrument\u2019s polarization response for the Glint mode operations was sufficient to significantly increase the radiance levels. The potential impact of this workaround on solar array orientation\/battery charging was mitigated by the spacecraft having healthy instrument technical margins (e.g., battery charge rate). The design of the OCO-3 follow-on instrument to be installed aboard the International Space Station has been modified to address the polarization issue. Also, a test to verify the system\u2019s correct polarization will be conducted prior to the first system-level thermal-vacuum test (Reference (5)). References: \u201cGlint data are not consistent with the prelaunch understanding of instrument polarization response,\u201d JPL Incident Surprise Anomaly (ISA) No. 57003, September 11, 2014. \u201cOCO-2 Glint Mode Polarization: Low Signals from Ocean Surfaces at Mid-Range Solar Zenith Angles,\u201c NASA\/Caltech Jet Propulsion Laboratory (JPL), September 15, 2014. Final Report, Independent OCO-2 Polarization Anomaly Assessment Team, NASA\/Caltech Jet Propulsion Laboratory (JPL), January 14, 2015. \u201cHardware Review\/Certification Requirement,\u201d NEN #656, Lesson Learned Information System (LLIS), February 1, 1999. \u201cOCO-2 Lessons are Being Applied,\u201d OCO-3 Critical Design Review (CDR), June 15-16, 2016.","Lesson ID":17001}
{"Driving Event":"Unenclosed propellant tanks on satellites in Earth orbit have long been a concern due to the risk of orbital debris colliding with the tanks. Propellant tanks in deep space too may need additional protection beyond that provided by the tank structure, depending on the severity of the micrometeoroid flux and the spacecraft orientation along the spacecraft trajectory (Reference (1). For Earth-orbiting spacecraft, however, additional design measures to protect propulsion systems may be goaded by a recently updated NASA orbital debris model (ORDEM). The most recent version of the model (Reference (2)) provides a larger set of observational data on the orbital debris environment (debris spatial density, flux, etc.) than found in the 2001 release of ORDEM 2.0\u2014 new data that suggests spacecraft will incur a higher risk of damage. In addition to the increased debris in space and the higher risk to orbiters documented in the revised model, NASA policies related to debris in low Earth orbit (LEO) became more stringent in 2007 (Reference (3)). For Earth orbiters, particle strikes on propellant tanks comprise two failure modes: The impact will cause a breach in the tank, leading to a loss of propellant that may shorten or end the mission. The strike will cause an explosion or catastrophic failure of the tank, resulting in both mission termination and an addition to the orbital debris field. This added debris may increase the risk to other spacecraft.1 Mitigation of the micrometeoroid and orbital debris (MMOD) risk has typically involved adding multi-layer insulation (MLI) shielding to the tanks. Because Reference (2) adds steel debris to the ORDEM model, making MLI ineffective as a shielding wall, the SMAP project considered additional protection measures. Launched in January 2015, SMAP measures soil moisture and freeze-thaw state using a lightweight, deployable, reflector antenna system that rotates around the nadir axis and makes conical scans of the Earth\u2019s surface. A spherical titanium propellant tank (Figure 1) equipped with an elastomeric diaphragm expulsion device held 81 kilograms of hydrazine at launch, was pressurized pre-launch, and is operated in (mono-propellant) blowdown mode throughout the 3-year or longer mission. Figure 1. SMAP propellant tank after installation at JPL In the original design, the SMAP propellant tank was only partially enclosed by the spacecraft structure, with the expulsion outlet and dome oriented outward, and with an offset thermal blanket attached to the surface of the tank. This left the tank exposed at the base via the open end of the launch vehicle interface (Figure 2). Figure 2. Cutaway of spacecraft structure showing the location of the propellant tank. The underside of the tank is exposed to space At Preliminary Design Review (PDR), it was estimated that the spacecraft would be in compliance with NASA requirements; i.e., it would have a 99 percent probability of surviving MMOD through post-mission disposal (Reference (4)). However, the initial analysis of the risk of impact-induced tank rupture showed the risk was not in compliance. Because the SMAP spacecraft design had an adequate mass margin, and because it was destined for an orbit with a high debris flux, JPL decided to add a hemispherical aluminum tank cover to protect the tank (Figure 3). Figure 3. MMOD shield (purple domed structure) covering the SMAP propellant tank, viewed through the (green) launch vehicle adapter ring. 1Mitigating the impact of a strike by venting the pressurant gas when the spacecraft is decommissioned is infeasible because the helium is behind a bladder. Adding a pressurant vent valve to the design is an option, but it would add to propulsion system complexity and might introduce new failure modes. References: \u201cMicrometeoroid Protection,\u201d NASA Preferred Practice No. PD-EC-1107, May 1996. http:\/\/oce.jpl.nasa.gov\/practices\/1107.pdf NASA Orbital Debris Engineering Model, ORDEM 3.0, April 2014. http:\/\/orbitaldebris.jsc.nasa.gov\/model\/engrmodel.html NASA Procedural Requirement (NPR) 8715.6 \u201cNASA Procedural Requirements for Limiting Orbital Debris,\u201d 2007. (Current version is Rev. A with Change 1, dated May 14, 2009.) SMAP Orbital Debris Assessment Report, Rev. C, JPL Document No. D-45953, December 15, 2014, p. 82.","Lesson ID":16901}
{"Driving Event":"Launched in January 2015, the SMAP spacecraft (Figure 1) provides high spatial resolution radiometric and radar measurements of soil moisture and gravity freeze-thaw state. The SMAP radar and radiometer share a lightweight, deployable, reflector antenna system that rotates around the nadir axis and makes conical scans gravity of the Earth\u2019s surface. Figure 1. The 6-meter diameter, 65.5 kg antenna is made of gold-coated mesh. The feedhorn transmits and receives radar signals (active) and collects microwave emissions (passive). When stowed for launch, the flexible mesh reflector antenna\/boom assembly (RBA) is folded against the spacecraft into a compact volume of 30 by 120 cm (1 by 4 ft.) to fit within the launch vehicle fairing. The mesh is edged with a perimeter truss, a ring of lightweight graphite supports that opens like a camp chair when deployed. Once deployed in a complex sequence (Figure 2), the surface shape of the mesh must be accurate within about 3 millimeters. Figure 2. Movie - The boom takes about 20 minutes to deploy. First, a pyro cable cutter releases the boom cradle, the preloaded tension in the boom moves it away from the satellite bus, and a motor winds a cable that pulls the boom to its full extension, with a jerky motion when the root and elbow hinges latch.) Then, it takes about 33 minutes for a pyro to release the furled reflector antenna, for stored energy to spring it partially open, and for a second motor to wind a cable to pull the reflector to its fully opened circular configuration. The SMAP project was challenged in designing and testing a large deployed-size, low-mass structure in a microgravity environment. The ability to test such a structure (mounted atop a 5-meter length boom, with the stiffness to rotate at about 15 rpm) on the ground in a flight-like manner was limited because it was not designed to deploy in Earth gravity. Hence, the complete deployment sequence could not be tested: instead, the sequence had to be tested piecemeal. Furthermore, testing required compensating for the effects of gravity experienced during ground test by using specialized equipment (Figure 3) that had certain unavoidable limitations. For this reason, ground testing was supplemented with sophisticated modeling analysis. Figure 3. SMAP's antenna is fully unfurled during a ground test. The structure under the golden, semi-transparent antenna surface holds the surface in its correct shape. The structure above the surface (not visible in photo) supports the antenna in Earth's gravity. Designed for use in the microgravity of space, the antenna does not have the mechanical strength necessary to support its own weight on the Earth's surface. Source: publically available The July 2013 SMAP RBA deployment test (Reference (1)) displayed unexpected asymmetric deployment, large lateral deflections of a batten truss element (Figure 4), and loads that possibly exceeded the batten flight limit loads. An asynchronous deployment is when one or more bay diagonals fail to reach ratchets prior to the first bay diagonal going over the final detent. An inspection of the reflector found a design defect and a manufacturing defect that increased friction within the system. Specifically, with one deploying bay of the perimeter truss deploying farther than an adjacent bay, high moment loading was applied to the batten strut between the two bays. Although the test did not damage the flight Reflector, the need to add garter springs and make other design changes imposed significant stress on the project\u2019s personnel, budget, and schedule, and it jeopardized the planned mission launch date. Figure 4. In the reflector deployment load anomaly, the batten (see marking) exhibited significant deflection during deployment testing [Photo provided by contractor per contract with JPL.] Large mesh antennas previously used by military and communications satellites are expected to see greater use in civil space missions (e.g., NISAR and BIOMASS). References: \u201cUnexpected Asynchronous Behavior and High Tension Required for RBA Powered Reflector Deploy,\u201d JPL Problem\/Failure Report No. 55161, October 3, 2013. Chris White, \u201cSMAP Deployable Reflector Lessons Learned Summary,\u201d IOM ESFPO-2014-288, May 23, 2014. E. McCoy, \u201cLarge Deployable Reflector Workshop Report,\u201d IOM 3550-15-002, June 3, 2015. Don Sevilla, \u201cSMAP Reflector Development Lessons Learned for NISAR,\u201d May 20, 2015.","Lesson ID":16501}
{"Driving Event":"Juno, a Jupiter orbiter designed and operated by the NASA\/Caltech Jet Propulsion Laboratory (JPL), was launched in August 2011. Over the first three months of Juno cruise, the spacecraft experienced a set of anomalies of varying durations and signatures in synchronous dynamic random-access memory (SDRAM) memory modules (Reference (1)). These included a multi-bit error (MBE), clusters of single bit errors (SBEs), and stuck bits. In April 2012, four months before the Mars rovers landing, the MSL project discovered (Reference (2)) that a SEFI1 had occurred on the backup MSL Rover Computer Element (RCE-B). This resulted in a large number of SBEs and double bit errors (DBEs) in the Nonvolatile Memory and Camera Interface Board (NVMCAM) SDRAM memory. Analysis, ground test, and flight testing determined that this SEFI event was similar to the Juno SEFI event. A cold reboot of MSL\u2019s RCE-B resolved the issue, a swap to the backup computer (RCE-B) was performed, and MSL operations have continued nominally. However, where the likelihood and impact of a SEFI event on SDRAM is acceptable during the cruise phase and the operations phase of a mission, the risk is greater during the Entry, Descent, and Landing (EDL) phase. If the MSL SEFI had occurred shortly prior to or during EDL, and were it not for the MSL Second Chance (SECC) flight software, the SEFI would most likely have been mission-ending. SEFI-triggered DBEs are continuing to occur during MSL surface operations (Reference (3)), but because they clear during the following cold boot, they are considered a transient event. The JPL electronic parts specialists pointed out to the MSL project, based on parts test data, that radiation-induced SEFI incidents were a strong possibility for the SDRAM part. However, this information was not communicated to the appropriate MSL systems engineers or to the MSL avionics chief engineer. The Juno anomalies also prompted concern at JPL because the Gravity Recovery and Interior Laboratory (GRAIL) spacecraft was flying memory devices from the same manufacturer\u2019s lot in a similar space environment. The Soil Moisture Active Passive (SMAP) mission was also considered to be potentially impacted by the SDRAM susceptibility to radiation damage. 1A SEFI is a space radiation-induced event often associated with an upset in a control bit or register in a programmable digital device (Reference (4)). Like a single event upset (SEU), it can result from a single heavy ion strike upon the component, but it is manifested in a somewhat different manner. That is, a SEFI is a soft error that causes the component to reset, lock-up, or otherwise malfunction in a detectable way, but a SEFI does not require power cycling of the device to restore operability. References: \u201cNVM SDRAM Vulnerability\u201d (MSL, Juno, GRAIL, SMAP), JPL Problem\/Failure Report (PFR) No. 50582, November 15, 2011. \u201cRCE-B NVMCAM Double Bit Errors\u201d (MSL, Juno), JPL Incident\/Surprise Anomaly (ISA) No. 51764, April 10, 2012. \u201cNVMCAM SDRAM DBEs on Sol 803,\u201d JPL Incident\/Surprise Anomaly (ISA) No. 57325, November 10, 2014. JEDEC specification JESD89A, \u201cMeasurement and Reporting of Alpha Particle and Terrestrial Cosmic Ray-Induced Soft Errors in Semiconductor Devices,\u201d JEDEC Solid State Technology Association, October 2006, p. 3.","Lesson ID":16303}
{"Driving Event":"DSN is a set of large antennas and communication facilities, managed by the NASA\/Caltech Jet Propulsion Laboratory (JPL) and located at Goldstone (California), near Madrid (Spain), and near Canberra (Australia), that provide uplink and downlink services to deep space missions. The geographical distribution of the three antenna complexes around the globe permits continuous communications between the ground and the spacecraft as the Earth revolves. On August 21, 2011, a lightning strike to earth approximately 150 to 200 meters from the DSS-54 34-meter antenna (Figure 1) at the MDSCC caused extensive equipment damage. A total of 34 items related to DSS-54 and DSS-55, including various circuit boards, modules, controllers, and assemblies related to antenna positioning, monitoring, power processing, and facility infrastructure suffered damage from the strike (References (1) and (2)). Figure 1. Madrid DSS-54 antenna The four antennas at the MDSCC each incorporate protection against lightning strikes. However, the facility grounding system and surge protection proved inadequate for the severity of the lightning storm (Reference (2)). No personnel were injured because MDSCC personnel are not allowed outdoors in the vicinity of antennas when lightning is forecast. The total damage was estimated at $58,000. The damage had a direct impact on DSN operations, affecting the JPL DAWN project and others: DAWN lost 180 minutes of command capability and lost 141 minutes of telemetry data. THEMIS-B lost 22 minutes of telemetry data and 22 minutes of radiometric data. GEOTAIL lost 60 minutes of telemetry data. STEREO-A lost 244 minutes of command capability, 250 minutes of telemetry data, and 244 minutes of radiometric data. MESSENGER lost 26 minutes of radiometric data. Following the incident, DSN embarked on repairs to damaged equipment-- and on facility improvements to correct the deficiencies reported in Reference (2). As one example of an identified deficiency, although the DSS-54 Antenna apex was well grounded, it was found that the North Camera Pole (Figure 2) did not have its base (Figure 3) grounded to the DSS-54 Antenna buried ground ring. Most of the MDSCC improvements-- intended to decrease facility lightning susceptibility-- have now been completed, and the lessons learned are being flowed to the other two DSN complexes. Figure 2. North Camera Pole located outside the access control (inner) fence Figure 3. Base of the North Camera Pole References: MRS No. 2487, JPL Mishap Reporting System, August 23, 2011. Site Inspection Report, NASA DSS-54 Antenna Madrid Deep Space Communications Complex, September 18, 2015.","Lesson ID":16301}
{"Driving Event":"NASA\u2019s Space Technology Mission Directorate, (STMD) formed an STMD-sponsored ''brazing tiger team\" with metallurgical and manufacturing subject matter experts (SMEs) within the Agency to provide technical assistance on various brazing issues for four STMD-funded activities. The SMEs were from MSFC, LaRC, GSFC, GRC, and the NESC Chief Engineer Office. MSFC was assigned the leadership role. The request came at an opportune time for MSFC since MSFC was in the process of working a brazing issue on the Microgravity Materials Science Research Rack Sample Ampoule Cartridge. The goals for this team of brazing SMEs were to provide real time resolution for the specific brazing issues encountered by each of the four activities, evaluate new technology solutions, and enhance our Agency's knowledge of brazing and brazing processes. Four STMD projects were experiencing brazing issues: \u2022 Cryocooler\/GRC \u2022 Water Phase Change Material (pCM) Heat Exchanger (HX)\/JSC \u2022 Green Propellant Infusion Mission (GPIM)\/GRC \u2022 Nuclear Systems NaK Heater Head\/GRC. During information gathering, JPL engineers presented their lessons learned from the brazing issues resolved on the Deep Space Atomic Clock ion trap tube brazing. JSC proactively offered subject knowledge to the team to assist in developing solutions for the aluminum cold plate dip brazing process. After discussions on the above referenced projects, one onsite visit was made to Mezzo Technologies in Baton Rouge, Louisiana to review the manufacturing processes used for the PCM HX project. Provided here are brief overviews of the primary issues and potential solutions being worked by the respective projects. Additional detail can be provided by the respective project managers. \u2022 The Nuclear Systems NaK Heater Head braze assembly consisted of stainless steel tube, Inconel flange, and copper acceptors. These braze joints were failing as a result of unfilled or starved joints due to thermal expansion mismatch and part movement during brazing. o The solution was to redesign the head assembly using common materials to avoid thermal expansion mismatch. o All joints were redesigned to mechanical or welded joints with the exception of one brazed joint. The redesigned one piece inner heater head assembly will eliminate braze joints and will be used as the backup heater head. The Cryocooler heat exchanger braze assembly consisted of stainless steel manifold sheets and thousands of thin-walled microtubes. The braze issues included excessive flow of the braze alloy causing blockage of the microtubes and erosion of the thin walled tubes due to excessive base metal\/braze alloy interalloying. Under the Cryocooler Project, Mezzo had not progressed any further with regard to brazing challenges. Mezzo milled the tube sheet boss features with the precision and concentricity necessary to enable successful buildup of a trial recuperator core which was subsequently CNC laser welded by Creare, Inc. of Hanover, New Hampshire. Although this trial laser welded core had some small cross-stream leaks, the number of leaks was less than with any other joining technique attempted. The leaks are expected to be repairable by repeating laser welding. There is one additional trial core to be built before the full scale recuperator is manufactured and performance tested. Work was still ongoing. The PCM HX is making changes to thicker wall tubes to minimize base metal erosion or scarring during the braze process and increase structural stability. The thermal performance of the thicker-walled tubes will be assessed. In addition, Mezzo is investigating different braze alloys, the quantity of braze alloy used, and the braze cycle to control inter-diffusion in order to prevent base metal erosion which weakens the tube walls for the thinner wall tube design. GIPM is developing furnace braze processes for the Iridium\/Inconel 625 Injector, an induction braze for the Iridium\/Iridium-Rhenium Injector Chamber, and an EB braze for the Copper\/Inconel 625 Thermal Shunt Injector Spud. Analysis of brazing issues were not complete at the time this lessons learned was written. The team was satisfied that the procedures for dip brazing used on the aluminum cold plate are adequate. However, because dip braze temperatures are close to the melting point of the aluminum structure, questions remain regarding whether the material properties are negatively affected during the dip brazing process. o Witness specimen tensile testing was recommended to assess strength effects o Hardness \u2013 tensile strength curves generated by GSFC were provided for testing o The team recommended that the entire brazing procedure, specifically the amount of time at temperature, should be assessed to identify and mitigate any negative effects of the brazing process on mechanical properties.","Lesson ID":14001}
{"Driving Event":"The Dawn mission to orbit and explore the two major objects in the main asteroid belt, protoplanet Vesta and dwarf planet Ceres, would have been infeasible without the use of solar electric propulsion (SEP). (Even orbiting only one of these bodies would have been difficult to achieve within the NASA Discovery Program if chemical propulsion were used.) Dawn SEP is implemented as an ion propulsion system (IPS), with strong inheritance from the successful development and operation of the IPS on the Deep Space 1 (DS1) spacecraft, launched in 1998. Launched in 2007, the Dawn mission is managed by the NASA\/Caltech Jet Propulsion Laboratory (JPL), with instruments contributed by European partners from Italy and Germany. Dawn employs thrust vector control (TVC) in which the attitude control system (ACS) commands a thrust gimbal assembly (TGA) that is attached (Figure 1) to each of the three ion engines and adjusts engine pointing. DS1 also controlled two engine axes by gimballing a very similar ion engine, but DS1 used an entirely different TGA design. Figure 1. Dawn Ion Thruster Gimbal Assembly (TGA) hexapod gimbal. Each one of Dawn\u2019s three ion thrusters includes 1 TGA with 6 supporting struts and 2 actuators. The thruster\u2019s neutralizer defines the 12:00 location when viewed from the \u201cdownstream\u201d side of the thruster. The 6 struts support the ion thruster at 3 gimbal pad locations-- 2:00, 6:00, 10:00. Each of the 2 actuators attaches to a single strut. When an actuator is commanded to rotate, bearings in the struts allow them to move, thus pushing or pulling the ion thruster at the pads. Five years into the Dawn mission, downlinked data indicated an unexpected change in steady state gimbal angles while thrusting (Reference (1)). It was determined that the TGA3 motors were not executing all of the commanded steps when commanded to move at near the maximum step rate. The behavior initially was acceptable but two years later had grown to a level that it needed correction. Operations and system design personnel conducted flight tests of new parameters that appeared to correct the problem. Shortly thereafter, however, the TGA3 +Y gimbal motor did not move to the commanded position and appeared to have moved in the wrong direction. This motor positioning error gradually led to a spacecraft attitude error, causing the spacecraft to enter safe mode. The degradation of TGA performance occurred earlier than predicted by life testing, and it points to a difference between actual flight conditions and the conditions simulated by test: Test Assumptions. TGA ground testing (References (2) and (3)) included a test of the crank arm spherical bearing and the actuator motor assembly (not attached to a crank arm) over a range of temperatures in the clockwise direction and in the counterclockwise direction. A major concern evaluated during October 2005 life testing of a flight-like TGA actuator assembly was the characteristics of the gearing lubricant at elevated temperatures. At that time, tiny motions of the actuator assembly (dithering) in the aft section of the actuator (the planetary gears, harmonic gears, output bearings) were not considered to be a significant failure mode. Flight Conditions. The TGA actuators have moved tens of millions of steps each, with the great majority of those steps taken at just a few (< 10) steps at a time during a TVC event which typically lasted for one to four weeks. In addition, virtually all of Dawn's TVC has occurred across a total range for all of the mission of \u00b1 500 stepper motor steps. While this range produces 62.5 motor revolutions at the stepper motor, which is adequate for redistributing lubrication at the fore end of the actuator, it is only about 3.3 motor revolutions at the planetary gears and 0.03 degrees for mechanical parts within and aft of the harmonic drives. This means there were many very tiny motions within the actuators, with little opportunity for lubrication to be redistributed. The scenario leads to a likelihood of mechanical wear in parts such as the harmonic drive resulting in backlash. During the cruise phase of the Dawn mission, bearings, gear teeth and other mechanical parts in the fore end of the actuator have likely been properly lubricated because of the large number of revolutions in that part of the actuator. But downstream of the stepper motor (Figures 2 and 3), the mechanical parts have dithered over a very small range of travel, likely causing substantial mechanical wear due to lack of lubrication. Dithering tends to push lubricant away from the moving interfaces and form \u201cdams\u201d of lubricant, degrade lubricant, or produce wear debris that can build up at the edges of the dithering range of motion. Figure 2. Detailed design of the DAWN TGA Actuator. Motions within the TGA become progressively smaller downstream of the stepper motor. After recovering from the safe mode entry, the Dawn project switched back to the original parameters and swapped to TGA2 (Reference (4)). The project then resumed ion engine thrusting with no further TGA problems. The risk of the swap was viewed as low due to extensive operational experience with TGA-2 (which has never displayed the anomalous symptoms), the occurrence of the swap late in the mission, and the availability of TGA1 should another swap be necessary. Dawn\u2019s practice has been to redistribute lubricant by sweeping the operating gimbal set through its full range every two months-- and every six months on the dormant sets. With the swap to TGA2, Dawn is expected to complete the mission with that gimbal and associated ion engine, and no further mission impact is expected from this anomaly. Figure 3. DAWN TGA Actuator close-up. Bearings, gears, gear teeth, races, and strut bearings are all subject to lubricant removal from numerous small motions. References: \u201cDawn Steady State Gimbal Position Changing More Than Expected,\u201d JPL Incident Surprise Anomaly (ISA) No. 53730, December 20, 2012. JPL IOM 5133-04-009, DAWN's Gimbal Spherical Bearing Test Report, April 7, 2004. Life Testing of DAWN Thruster Gimbal Assembly (TGA) Life Test Unit (LTU) Actuator, October 25, 2005. \u201cDawn in safemode due to attitude fault,\u201d JPL Incident Surprise Anomaly (ISA) No. 58451, July 1, 2015.","Lesson ID":15301}
{"Driving Event":"A Fixed Price Contractor (FPC) was awarded the Revitalize Power Cable and Duct Distribution System, Industrial Area Phase 3 A contractor was awarded the Revitalize Power Cable and Duct Distribution System, Industrial Area Phase 3 Project on January 4, 2007. Phase 3 required work in the KSC Industrial Area that primarily involved replacing medium voltage cables in the underground duct distribution system and the demolition and removal of the obsolete cable. The contractors task associated with the mishap was the identification and cutting of underground cable in manholes. The removal of medium voltage cables is labor intensive. The paper insulated lead covered (PILC) cable typically weighs 9 pounds per linear foot, with typical lengths about 600 feet. Once the cable identified for demolition is de-energized, the cable is cut at the first manhole, and then the cut end is pulled by a truck operated winch, while in an adjacent manhole cable movement is observed to identify which cable is to be cut next. Now cut at two ends, the cable is pulled to remove from the manhole. This process is repeated as the project work moves successively from manhole to manhole. Configurations in each manhole are different, due both to physical size of the manhole, and the number and placement of cable runs. Work in the manholes require confined space entry permits and fall protection. Should manhole configurations not permit the removal of a cut section of cable, the cable is abandoned in place. On the morning of March 3, 2008, the contractor removed cable \u2018E\u2019 between MHP-24 and MHP-21 in accordance to contract drawing. The last section of cable \u2018E\u2019 and cable \u2018B\u2019 (Feeder 207) remained between MHP-21 and MHP-20. The contractor had three employees working at this site on the day of the incident: 1) an electrician designated to perform all work in the manhole, including cable identification, rigging and cutting, 2) the job foreman acting as the confined space manhole attendant, and 3) a line truck operator. To begin the removal of cable \u2018B\u2019, the contractor positioned their line-truck (which would be pulling the already cut end of the cable) at MHP-21. The electrician rigged cable \u2018B\u2019 with the pulling chain in MHP-21 and then entered MHP-20 to observe for movement of the cable that would be pulled, identifying which cable was to be cut. Using hand signals, the line truck operator pulled on the cable while the electrician in MHP-20 looked for the cable that moved. The cable was pulled two times to verify that the correct cable was identified. Each time the cable was pulled the electrician had his hand on the cable, and saw and felt two to four inches of movement. \u201cPositively certain\u201d that he had the correct cable, the electrician then proceeded to cut the cable with hand operated insulated ratchet cutters. What the electrician perceived as the de-energized cable \u2018B\u2019 was actually an energized 13.2KV cable (Feeder 207). As the ratchet cutters penetrated the bottom of the cable, it created a ground fault on B-Phase. This resulted in an arc flash (ball of fire) and instantaneously tripped the upstream relay for Feeder 207 at the Orsino Substation. As the short occurred at the bottom of the cable, the arc flash\/blast was projected down and away from the electrician. The manhole filled with smoke, and once it cleared, the electrician, uninjured, climbed out of the manhole with the assistance of his crew, leaving the cutters in place on the cable. A power outage occurred at 3:12 pm.","Lesson ID":5736}
{"Driving Event":"During Verification and Validation of the CMASS, there were delays due to lack of spare parts to support testing. Delays were also caused by parts being pulled from logistics inventory that had not been modified as required for use in the CMASS system. Late stage design changes made finalizing the spare parts analyses impossible. Cost and schedule overruns were substantial.","Lesson ID":14701}
{"Driving Event":"NASA utilizes Support Requirements and the Agency Support Requirements System to obtain commodities and services from internal and external supplier organizations, the Department of Defense and other Government Agencies. Support Requirements may include (but are not limited to) services such as photography; capture and streaming of video and data; warehouse services; packaging, storage, shipping and transportation; parts cleaning; and communications services. Support Requirements may also include items such as commodities, cleaners, solvents and fuel. Coupled with the use of the Agency Support Requirements System, Programs or major Projects develop processes to identify, review and approve their Support Requirements. The Program\/Project must ensure that all stakeholder organizations (including requesters and suppliers) understand and adhere to the process. It is especially important to ensure that all parties understand who pays for requested items and how they will pay. The Space Launch System (SLS), Multi-Purpose Crew Vehicle (MPCV) and GSDO Programs formed a working group which developed a Mission Support Requirements Document describing the Support Requirements of each Program at a high level. This working group also serves an integration function by ensuring that each Program understands and approves the budget for all of its Support Requirements. This also includes elimination of duplication of requirements and addressing situations where ownership and budgeting are ambiguous. The working group did not address EFT-1 Support Requirements Integration. Prior to the launch of EFT-1, institutional suppliers at the Kennedy Space Center responded to requests for support related to the EFT-1 launch from organizations outside KSC. The requesters assumed since the support was being provided by KSC that they would not need to pay for the services. There was also a case where the requester asked for real-time video on the day of launch but because the requester did not thoroughly coordinate the delivery of the video with all stakeholders, on the day of launch they could not receive the video they requested. GSDO institutional suppliers provided services not planned for by the GSDO Program and outside the scope of GSDO. The GSDO Program incurred unplanned costs due to these services. The result of this was that there were schedule delays and cost overruns. The Exploration Flight Test-1 Orion on its Delta IV Heavy November 2014 Launch of EFT-1 on December 5, 2014 The Orion Exploration Flight Test-1 crew module before splashdown December 5, 2014","Lesson ID":14902}
{"Driving Event":"A UAV was landed at a speed well above the design speed for the landing gear. The left main gear collapsed and the UAV veered off of the left edge of the runway while tumbling and shedding parts of the airframe, resulting in extensive damage to the vehicle. The pilot experienced time pressure to land the UAV as he thought it was about to run out of fuel (typically resulting in a crash in this type of UAV). The UAV actually had triple the flight time that the pilot thought was available. The pilot was unable to adequately manage the UAV's energy throughout the entire flight and ultimately landed at 35 knots above the design speed for the gear, resulting in landing gear failure. The pilot did not know and was not briefed on the design speed limit for the landing gear. The flight crew, standing unprotected at the runway edge, could have been injured if the UAV had landed sooner and the right main gear had collapsed.","Lesson ID":1710}
{"Driving Event":"The high landed mass of MSL required a Descent Stage (DS) to maneuver over the surface of Mars and gently lower the one-ton rover to the ground. This required the most sophisticated propulsion system ever developed by the NASA\/Caltech Jet Propulsion Laboratory (JPL), with up to 400 kg of propellant consumed in 30 seconds of powered descent and maneuvering. The propellant tanks and filters for the DS propulsion system (DSPS) were manufactured out of a lightweight titanium alloy. Because the propellant tubing and other components were made from a stainless steel alloy that cannot be welded to titanium, short bimetallic transition tubes had to be joined to the tanks and filters (Reference (1)). Such dissimilar metals are joined by a \u201cfriction forging\u201d process (Figure 1) that forms a solid state joint and does not melt and weaken the material. Although MSL required larger (up to 1-inch diameter) transition tubes than are common on spacecraft propulsion systems, JPL did not perceive the 26 DSPS joints to be a risk item and did not provide detailed specifications for their fabrication. The procurement of the transition tubes was delegated to the filter and tank suppliers. Figure 1. After completion of a friction forging (aka \u201cinertial welding\u201d) procedure similar to that demonstrated in the above video, the joined material was then machined into a hollow tube for welding onto a DS propulsion component. Several inertial welding anomalies occurred over the course of DSPS development: During qualification of a transition tube for use on a filter, the tube failed to meet the tensile strength requirements specified by the filter manufacturer. Because it met requirements for the JPL application with a large margin, JPL failed to recognize the significance of the fact that the failure occurred precisely at the solid state joint rather than in the stainless steel tube stub where a properly formed joint should have failed. Subsequently, the root cause of this failure was inadequately investigated. Near the completion of DSPS assembly and test, two transition tubes undergoing fatigue testing (Figure 2) failed at relatively low stress levels (Reference (2)). Both failures appeared to have occurred right at the solid state joint (Figure 3) rather than in the parent metal. Figure 2. MSL propulsion line fatigue test configuration Figure 3. MSL DSPS transition tubes Subsequently, a detailed investigation of the integrity of all the various sizes of DSPS transition tubes found: Lot acceptance test failures were found to have occurred in all the welded lots\u2014all occurring at the solid state joint rather than in the parent metal, and indicating that local melting had occurred during the forging process, as shown in Figure 4. When a lot acceptance test unit failed the tensile strength test, the interface welding vendor would simply test another unit from the lot as a substitute for the failed unit. The tank and filter vendors would then receive a Certificate of Conformance indicating the lot met all requirements, but neither the vendors nor JPL penetrated beyond the certificates\u2019 cover sheets to note the reported tensile strength failures. Possibly due to proprietary technology, the interface welding vendor failed to inform the tank and filter vendors or JPL that the specified titanium alloy was not the alloy best suited to forming robust joints. Ultimately, all the transition tubes in the DSPS had to be removed in an extremely expensive rework that replaced the initially welded units with brazed joints between the steel and titanium alloys. Figure 4. Scanning Electron Microscope image showing a melt zone (appearing as a pattern of cracks and black occlusions) in the inertial weld joint. Local melting during the forging process leads to the formation of brittle intermetallic alloys indicative of an unsound joint. The development of the MSL DSPS culminated in the successful 2012 landing of the Curiosity rover on Mars. References: Carl S. Guernsey and Jeffrey M. Weiss, \u201cLessons Learned from the Development of the MSL DS Propulsion System,\u201d AAS 13-457, 23rd AAS\/AIAA Spaceflight Mechanics Meeting, Kauai, Hawaii, February 10-14 2013, p. 12-14. \u201cFirst Cycle Failure of Transition Tube,\u201d JPL Problem\/Failure Report No. 13641, September 22, 2008.","Lesson ID":14201}
{"Driving Event":"The Deep Space Network (DSN) is a set of large antennas and communication facilities, managed by the NASA\/Caltech Jet Propulsion Laboratory (JPL) and located at Goldstone (California), near Madrid (Spain), and near Canberra (Australia), that provide uplink and downlink services to deep space missions. The geographical distribution of the three antenna complexes around the globe permits continuous communications between the ground and the spacecraft as the Earth revolves. The complexes are each isolated in somewhat remote locations that, combined with local terrain features, help prevent radio frequency interference. Figure 1 depicts the Deep Space Station (DSS) antennas that comprise the Goldstone facility, including the huge 70-meter DSS-14 antenna. Facility maintenance, operations, and engineering support on this mission-critical ground support equipment is provided mainly by contractors at each complex. Figure 1. Goldstone Deep Space Network Antenna Complex On the morning of July 16th 2014, four employees from the GDSCC Antenna Maintenance Department were tasked with welding a new mid-handrail onto the quadleg ladders poised above the DSS-14 antenna dish (Figure 2). The workers protected the dish by placing a piece of plywood under the planned work area. However, the workers did not place protective material along the entire run over which they would be carrying sections of handrail above the dish. Once the welding equipment had been hoisted up the quadleg ladders and secured in place, a gloved worker began carrying sections of handrail up the quadleg ladder to the welding location. After the first section of handrail had been successfully welded in place, a worker carried the second section up the quadleg. Upon reaching the area where the handrail section was to be welded, he discovered that the section did not fit. He then grasped the discrepant handrail and returned down the ladder intending to resize it or obtain a replacement. During the descent, the section of discrepant part was held in his left hand while his left arm was hooked around the existing handrail. Reaching the junction on the quadleg ladder where the angled section and the vertical section meet (Figure 2), he adjusted his position to make the transition. This caused him to lose his grip on the section of handrail, and it fell onto the dish. The handrail penetrated the dish (Figure 3), striking a cross brace below the dish panel that stopped it from striking the ground. Figure 2. Structure housing the electronics on DSS-14. Red arrow indicates the slope transition on the quadleg ladder Figure 3. Damage to the antenna dish with hand glove for size comparison Despite the personnel safety risks evident in repeated ascents and descents on the ladders (see Figure 2), Reference (1) reports that no Job Hazard Analysis (JHA) was prepared prior to performing the maintenance task. Reference (1) classifies the incident as \u201cClass II \u2013 Critical (i.e., \u2018A condition that may cause severe\/lost time injury or occupational illness\u2019)\u201d The antenna is scheduled to be repaired, with the hole to be patched using an aluminum patch panel. References: 1. Deep Space Network Mishap Report, \u201cDSS-14 Quad leg,\u201d July 28, 2014.","Lesson ID":14101}
{"Driving Event":"Landing the high mass of Mars Science Laboratory (MSL) required a Descent Stage (DS) to descend to the surface of Mars and gently lower the one-ton rover to the ground. This required the most sophisticated propulsion system ever developed by the NASA\/Caltech Jet Propulsion Laboratory (JPL). With up to 400 kg of propellant consumed in 30 seconds of powered descent and maneuvering, and relatively high (25,000 N) maximum thrust, MSL required propulsion tubes (up to 1-inch diameter) that were much larger than typical spacecraft propulsion system tubing. Conventional propulsion systems designed by JPL (i.e., with smaller diameter pressurant lines and fittings) are more flexible, and thus the internal pressure loads are the primary driver of mechanical stress. With an increase in the tubing diameter, such as was required for the MSL descent stage, the propulsion system becomes more rigid, and stress from vibration and quasi-static accelerations became quite significant. When propulsion systems require tubing diameters exceeding approximately 3\/8 inches, modeling must be done at the structural level for a given routing scheme. This is to assure that the relative motion of propulsion assemblies at different parts of the structure do not induce excessive stress. The secondary structural plates on which propulsion component subassemblies are mounted should be stiff enough to avoid excessive line stresses or loading of the components in flight environments. This stress analysis for MSL was made more difficult by the extreme complexity of the MSL DS propulsion line layout. This is illustrated in Figure 1, which shows the circuitous propulsion line routing throughout the DS structure. Figure 1. MSL DS propulsion lines. The purple lines are routed to the Mars Lander Engines (MLEs) used for terminal descent. The green lines are routed to the Reaction Control System (RCS) thrusters used to maintain attitude prior to atmospheric entry and to perform aero maneuvering during the entry. The blue lines connect the propellant tanks to the pyro valve assemblies. The yellow lines are routed from the pressurant tank. The propulsion line stress analysis revealed some complex stress states. There were numerous locations within the feed system where the conventional factors-of-safety on yield could not be met, and it was necessary to resort to fatigue life assessments. Indeed, the standard practice in fabricating propulsion tubing does not include stress relief after bending, so localized yielding is present in the as-fabricated tubes. Experimental testing (Figure 2) was done to confirm the material fatigue life predictions in the complex stress state typical of bent tubing under cyclical loading. In addition, the very scale of the DS Propulsion Subsystem mandated extensive testing to evaluate and mitigate the potential for water hammer effects produced by the pulsing of the RCS thrusters during atmospheric entry. Figure 2. Component strut fatigue testing setup depicting a failure due to accidental compression over-loading The scope of this analysis and test effort was not fully appreciated until very late in system development\u2014around the time of the Critical Design Review (CDR) for the DS Propulsion Subsystem. This led to many changes to the propulsion line routing, and to the location and configuration of line supports. The MSL DS Propulsion Subsystem testing program demonstrated robust margins over the predicted flight limit load (FLL) stress (Reference (2)), and the DS was successful during Mars Entry, Descent, and Landing (EDL). References: Carl S. Guernsey and Jeffrey M. Weiss, \u201cLessons Learned from the Development of the MSL DS Propulsion System,\u201d AAS 13-457, 23rd AAS\/AIAA Spaceflight Mechanics Meeting, Kauai, Hawaii, February 10-14 2013, p. 15-16. Darlene Lee, Gary Wang, and Zensheu Chang, \u201cMSL Prop Line Analysis Summary,\u201d April 29, 2010, p. 14. Fabrication of Propulsion Tubing for the MSL Descent Stage, NEN #14201, NASA Lesson Learned Information System (LLIS), December 2, 2014.","Lesson ID":13801}
{"Driving Event":"For Constellation, flight hardware and ground systems were designed concurrently. Initial design requirements were based on assumptions of the flight hardware configuration and on an ever-changing flight hardware design. As the flight hardware design matured, the requirements changed. However, the flight hardware design configuration changes were not effectively communicated to all the affected parties. As a result, ground systems were designing according to old configurations, word-of-mouth design changes, and incorrect design requirements. Also, ground system designs were proceeding through the 60%, 90%, and 100% design reviews before the flight hardware designs had passed Preliminary Design Review. As the flight hardware design matured, the designs and budgets of the ground systems were affected, and changes became more difficult and expensive.","Lesson ID":5006}
{"Driving Event":"Ti can be alloyed with aluminum, vanadium, and other elements to produce strong, lightweight alloys suitable for spacecraft structures. However, suspension of Ti MIL-SPECs in the late 1990s appears to have created a window of opportunity for Ti suppliers to cut corners and supply Ti that has not undergone the required material processing. Ti material that has been \u201ccut down\u201d to the desired plate thickness rather than receiving standard thermo-mechanical processing (e.g. hot rolling the material to the procurement-specified plate thickness) may not meet the specified minimum mechanical property values. Two MIL-SPECs governing aerospace\/space-quality Ti materials (MIL-T-9046 and MIL-T-9047) were replaced by approximately 55 Aerospace Material Specification (AMS) industrial standards with various provisions for processing and certification. A TiWG was formed by JPL in November 2009 to coordinate a response to released Government Industry Data Exchange Program (GIDEP) notices concerning non-conforming Ti material delivered to the aerospace supply chain. A comprehensive report was issued by the TiWG (Reference 1). A federal indictment alleged that companies were selling non-conforming, cut-down Ti billet material as forged and rolled sheet, strip, bar, and plate. (See Figure 1 for a schematic of standard wrought Ti processing.) Cutting billet material, which may be in the 5-8 inch thickness range, to thinner cross sections and selling that product as processed plate material is not standard. Concerns included that such cut-down billet might lack the minimum structural strength indicated in the material specification, and that furthermore the accompanying material certification records may not represent properly conducted tests and correctly reported mechanical test values. Figure 1. Fabrication Process for Wrought Ti Alloy. - The complex microstructures of wrought Ti alloys are developed from combined thermal-mechanical processing of as-cast ingots through intermediate to final product forms. The microstructure and hence the mechanical properties of Ti alloys are dependent on the fabrication scheme and the thermal history. Multiple cycles of \u201cwork\u201d (e.g., heating, forging, rolling, and cooling) are required to achieve the desired microstructure required for thin plate and sheet products used for flight applications. Intermediate product forms such as billets may not have been worked sufficiently to produce the microstructure necessary to achieve minimum acceptable specification-based mechanical properties across the entire cross section. (Reference 2, p. 24) The JPL TiWG developed an approach for existing JPL spaceflight projects to assess and disposition the use of Ti in their spaceflight hardware. Approximately 50 JPL spacecraft and instrument projects in various stages of development and mission operations were assessed for non-conforming Ti and ultimately cleared by a combination of refined margin analysis, component testing, and\/or redesign. During the course of the assessment, the TiWG reviewed approximately 1000 Ti certification packages. Slightly more than 10 percent of these certifications were found to contain suspicious omissions or other irregularities. Residual material associated with four such suspicious packages was located and tested, and in all four cases they failed to meet minimum specification values such as yield and ultimate strength, elongation, and\/or reduction in area. The material property non-conformances were relatively minor, and in most cases they fell within the factor of safety employed by JPL design\/analysis practices.. In some cases, additional proof testing or testing of residual material from the same heat\/lot was required to clear certain components. Non-conforming Ti was confirmed to have entered the JPL supply chain from at least two commercial suppliers. Finally, the TiWG identified protective measures that have since been implemented to prevent non-conforming material from finding its way into JPL flight hardware. These measures secure the acquisition of Ti raw material, as well as acquisition of Ti components supplied through subcontracted manufacturers and industry partners. Among the preventive measures employed is the review of material certifications by materials and process engineering specialists before JPL procures material. Some of the JPL personnel involved in the TiWG also participated in writing a NASA handbook (Reference (2)) to aid future NASA program personnel in the process of specifying and certifying Ti alloys for flight applications. References: \u201cReport of the Ti Working Group Concerning the Assessment of Non-Conforming Material as It Affects JPL Flight Projects,\u201d JPL Document No. D-69922, September 20, 2011. NASA-HDBK-6025, Guidelines for the Specification and Certification of Ti Alloys for NASA Flight Applications, April 4, 2014. \u201cCounteracting the Threat of Counterfeit Components,\u201d NEN #1832, NASA Lesson Learned Information System (LLIS), January 15, 2008. \u201cEngineering Drawing Practices, Rev. I,\u201d JPL DocID 35596, August 20, 2012, Paragraphs 3.4.1, 3.4.2, 3.4.3, and 3.4.4. ASME Y14.100M, Engineering Drawing Practices.","Lesson ID":12901}
{"Driving Event":"In the process of generating body point environments for the External Tank, it became clear that not all parties knew what the data file format was. The Space Shuttle thermal environments data (body point) file format was not well documented or understood across the full user and reviewer community. Also, it was difficult for anyone to quickly plot the environment time histories for comparison to previous environments or other data.","Lesson ID":6358}
{"Driving Event":"The DSN is a network of large antennas and communication facilities, managed by the NASA\/Caltech Jet Propulsion Laboratory (JPL) and located at Goldstone (California), near Madrid (Spain), and near Canberra (Australia), that provide uplink and downlink services to deep space missions. The geographical distribution of the three antenna complexes around the globe permits continuous communications between the ground and the spacecraft as the Earth revolves. The complexes are each isolated in somewhat remote locations (e.g., Figure 1) that, combined with local terrain features, help prevent radio frequency interference. Facility maintenance, operations, and engineering support are provided mainly by contractors at each complex. Because continuous operation of the DSN antenna complexes is critical to assuring uninterrupted spacecraft commanding and science data reception, UPS electrical backup systems are installed at each complex. Figure 1. View of the entire Madrid Complex The three UPS modules at the Madrid Deep Space Communication Complex (MDSCC) each feature a static frequency converter with 412 large, single-cell, lead acid batteries connected in series. The modules operate in parallel with the incoming commercial power feed so that, in the event of a power failure, they can power the facility until backup diesel generators start up and assume the power load. Functional redundancy derives from the ability of the UPS system to carry the maximum expected load with only two of the three modules. During the late night hours of October 15, 2014, a failure within the battery bank of Module #2 caused a fire and the subsequent loss of its battery bank (see Figures 2 and 3 and References (1) and (2)). The following timeline was established for the incident: Just prior to the fire, all three battery banks were fully charged and connected to the converter DC bus. On October 15, Battery Bank #2 began drawing excessive current. At 23:48 local time, this caused Converter 2 to start charging Battery Bank #2, which increased the voltage to Battery Bank #2 and further increased the charging rate. At 23:49 local time, the guard house detected a fire alarm originating in the battery room containing Battery Bank #1 and #2 (References (1) and (2)). The guard visited the power plant and saw flames in the battery room over Rack #10 of Battery Bank #2; multiple detonations were reported. On-site security initiated an emergency protocol that alerted the local police, National Guard, local fire department, and ambulances. At approximately 00:20 local time, the fire brigade arrived at the MDSCC. When CO2 was unsuccessful at controlling the fire, they switched to water to cool the high temperatures in the batteries and quench the fire. The local fire brigade, which may not have been familiar with fighting battery fires, also used a fire axe on some of the involved batteries until it became apparent that it was not effective in extinguishing the fire. Shortly thereafter, the backup diesel generators started and the UPS modules went off line. At 02:55 the fire brigade reported that the fire was under control, but at 03:00 local time the fire reignited in the battery room. At 03:57 local time the fire was fully contained. Figure 2. Damage to MDSCC Battery Bank #2 Two weeks prior to the fire, annual battery maintenance had been performed on all three battery banks. The maintenance contractor stated, however, that they were not able to perform several of the battery maintenance activities due to time constraints. The maintenance report mentioned that four cells had a higher temperature than others during the charging phase of the capacity test. The report said that they needed to be replaced; however, three hot cells had also been reported during the previous annual maintenance, but they were never replaced. The Battery Bank #2 cells were too badly damaged for failure analysis. But a diagnostic test of the surviving battery banks (#1 and #3) performed by the battery manufacturer found an overheating (>50oC) cell, and Destructive Physical Analysis (DPA) traced it to an internal short circuit. Further analysis revealed the direct cause of the failure to be a pre-existing DC current path from the battery line to ground through the circuitry of the converter. Figure 3. Close up of fire damage Battery Bank #2 A JPL Special Review Board (SRB) (Reference (2)) identified two root causes of the fire: Lack of a single and comprehensive written battery maintenance program, and Inadequate oversight of the converter system design and commissioning that allowed for an uncontrolled DC current path from the battery line to ground through the circuitry of the converter. This undetected ground fault then created a cascading event as the converter continued to supply power to the ground fault through the batteries. The SRB found that there were multiple contributing causes of the fire. These included: Lack of a ground fault detection circuit in the converters to shut off and isolate the converter\u2019s batteries in the event of a ground fault. Lack of an interconnection between the battery room fire alarm and the converters to shut down the system in the event of fire. Lack of a proper fire suppression system for the hazard presented by the batteries. The existing automatic fire sprinkler system did not reach listed\/designated activation temperature immediately in the early fire event. The local Fire Brigade was not familiar with the hazard presented by the battery fire and was not prepared to efficiently fight the battery fire. There was no single, site-specific, comprehensive, and clear maintenance procedure with pass\/fail criteria for converter batteries. Power plant transformer grounds, converter grounds, and the ground from the battery racks are not tied together to establish a single point grounding system. They are instead taken to separate ground fields and not explicitly bonded together. Damage from the fire included the destruction of Battery Bank #2, damage to battery supporting frames, and the possible exposure of Battery Bank #1 to high temperature and water. The overall cost was estimated to be over $360K. However, no DSN spacecraft tracking\/communications operations were disrupted, no spacecraft data were lost, and no personnel were injured. References: JPL Mishap Report No. 3148, October 15, 2014. MDSCC Power Plant Battery Fire Special Review Board Report, January 5, 2015. \u201cProvide Adequate Maintenance and Hazard Response for UPS Units,\u201d NASA Lesson Learned Information System (LLIS), NEN #12101, March 24, 2015. \u201cPoor Coordination of Routine Maintenance Spoiled an Important Test,\u201d NASA Lesson Learned Information System (LLIS), NEN #10401, August 26, 2014.","Lesson ID":12401}
{"Driving Event":"JPL Building 277 contains office space and laboratory facilities for (1) thermoelectric materials synthesis, testing, and characterization and (2) battery development, testing, and characterization. The UPS unit (UPS-1) located in the high bay area of Bldg. 277 includes batteries and control circuitry (see Figure 1) that provide continuous and conditioned electric power to critical loads. UPS-1 was purchased in 2010, placed in storage for two years, and then installed in 2012 along with a new battery bank. Since the purchase used JPL institutional funding, JPL Facilities was responsible for managing the preventive maintenance contract. Because the UPS equipment was never registered in the JPL facilities maintenance database, it was not scheduled for regular maintenance in accordance with the manufacturer recommendations. When this error was discovered two years later, a preventive maintenance contract was immediately issued with the UPS manufacturer, and a technical maintenance visit was scheduled for July 10, 2014. This first preventive maintenance for the UPS-1 and the installed batteries was performed on July 10, 2014. Management and building personnel had been briefed and were prepared for the visit. The Bldg. 277 UPS-1 system includes one battery string composed of 40 batteries (jars), with 6 cells per battery. During the maintenance inspection, no unusual occurrences with the operation of the UPS system were noted. However, in Jar 2 the battery was found to have high internal impedance and a low voltage. The bad battery was subsequently removed from the 40-battery string, and the voltage was not set to the correct value (Reference 1). On the morning of Monday July 14, 2014, overheated batteries in UPS-1 were found to be emitting a very strong odor and toxic fumes. The JPL Fire Department, and both JPL and contractor personnel in Facilities Maintenance, responded to the alarm. Subsequently, the UPS manufacturer\u2019s technician was summoned, and the technician turned the UPS battery charger off while leaving the UPS system online. 1: UPS-1 Battery System Upon further inspection, the UPS technician downloaded the UPS-1 event log to determine the cause of the overheating, and it was determined that the batteries had experienced a \u201cthermal run-away\u201d. The JPL maintenance contractor then ensured that the battery breaker was in the open position, and proceeded to secure the event log and document the UPS settings for later analysis (Reference 1). As a consequence of the battery outgassing, all building personnel were evacuated for several hours. In addition to interrupting office work, this threatened to disrupt laboratory experiments and thermoelectric and battery life tests. On July 18, 2014, the old batteries were removed and replaced. On July 23, 2014, permission was given to place the batteries on line with the charger and inspect the charging levels. At this time, the cause of the thermal runaway is inconclusive. However, a review of history log entries after the July 14 incident indicated off-nominal operation of the UPS, and it was found that the charger was set to a slightly higher-than-normal current (Reference (1)). With the bad battery removed from the 40-battery string, it was found that the charger was set to several volts higher than the specified setting. This would result in the remaining 39 batteries receiving a charge voltage of 0.132 VDC per battery higher than normal. According to the UPS manufacturer, though, this overvoltage should not have contributed to the thermal runaway. However, the battery manufacturer indicates that this ~ 0.1 V higher than the maximum recommended voltage value could have contributed to the thermal runaway. Unfortunately, further battery analysis is infeasible because they were removed and taken to the recycler the same day. References: JPL Mishap Report No. MRS 3093, July 14, 2014. \u201cUPS Module (9390-160) at Building 277,\u201d memo from Augie Brancato, August 12, 2014. \u201cPoor Coordination of Routine Maintenance Spoiled an Important Test,\u201d NEN #10401, NASA Lesson Learned Information System (LLIS), August 26, 2014.","Lesson ID":12101}
{"Driving Event":"The ambitious MSL mission presented some major design challenges for the NASA\/Caltech Jet Propulsion Laboratory (JPL) in its development of the \u201cCuriosity\u201d rover. Arriving at a successful design for the rover actuators, however, posed the one of the thorniest problems over the course of MSL development. An actuator is a complex component comprised of a motor and a gearbox. Rotary actuators are used on planetary rovers for such disparate purposes (Figure 1) as driving the rover wheels, moving the robotic arm (RA), and actuating science instrument components. Figure 1. Locations of MSL actuators The Mars Exploration Rover (MER) project that landed the previous, smaller, rover design on Mars in 2004 procured commercial off-the-shelf motors with minimal design modifications for use on the Mars surface. However, the MSL mission profile called for a rover that could operate for seven times longer than any previous planetary mission, and at the colder latitudes farther from the equator. JPL needed to acquire a total of 61 actuators and 29 stand-alone motors (90 units) for use in the MSL engineering models, test units, spare units, and in the flight model that was intended to be launched in 2009. Because the wet lubricant that had been used for the MER actuators was not suitable for usage at colder temperatures, the baseline design (Reference (1)) for most MSL rover applications called for an actuator with a titanium gearbox and dry lubricant capable of operating at -135 degrees C without a dedicated heater. By June 2007, three life tests of this design had each failed (Figures 2 and 3), and in September 2007 the MSL project switched to a heated actuator design using a conventional steel gearbox and wet lubricant actuator design that left part of the gearbox unheated (Reference (2)). This redesign was passed to the actuator supplier, but by this late date in the project development cycle, even triple shifts at this point were insufficient to produce quality actuators on schedule. By November 2008, NASA recognized that MSL was too far behind schedule to meet its October 2009 launch date (due to the problems with actuator development and production-- and other risk factors), and the mission was delayed for two years. Figure 2 Unit #3 of the dry lubricant actuator design reached only 20% of its design life before failing the life test (Reference (3)) Figure 3 Unit #3 titanium gearbox The MSL Curiosity rover\u2019s two-year primary mission ended in August 2014, and the actuators performed to expectations in the severe Martian environment. References: Mars Science Laboratory Rover Actuator Thermal Design Peer Review, January 23, 2008, p. 8. Keith Novak & Steven Hendricks, \u201cMars Science Laboratory Rover Actuator Thermal Design,\u201d Spacecraft Thermal Control Workshop, March 11 -13, 2008, p. 8-9. Richard Cook, et al, \u201cQuarterly\/GPMC Mars Science Laboratory\u201d May 9, 2007, p. 4. Rius Billing and Richard Fleischner, \u201cMars Science Laboratory Robotic Arm,\u201d 14th European Space Mechanisms and Tribology Symposium, September 28 - 30, 2011. Technical Assessment of MSL Actuators, Letter to Howard Eisen (JPL) from Dr. Christopher DellaCorte (GRC), April 2, 2009. \u201cDawn Ion Propulsion System (IPS) Lessons Learned, NEN #3396, NASA Lesson Learned Information System (LLIS), April 26, 2010.","Lesson ID":11501}
{"Driving Event":"The ISERV payload was developed to provide data and images for the SERVIR team through a downlink from the ISS. Health and status information of the ISERV system was required through the downlink also. The ISERV payload has the capability for issuing commands at predetermined times and accepts file transfers from the WORF. Specific events and obstacles encountered during the design and development of the payload provide the basis of the lessons learned. They are: There were insufficient foundational documents for the ISERV payload due to cost and schedule constraints. The introduction of COTS components and systems into projects challenged the traditional MSFC approach to designing, developing and testing flight hardware. Standard operating procedures have evolved to meet Class A and B projects. The likelihood of more COTS-based or COTS-involved flight programs (Class D) being worked by MSFC Engineering is increasing and this new reality must be integrated into our defined ways of doing work. The procedures and tools are not the same for JSC and MSFC Export Control Offices. Inputs into the Relational Database Management System (RDBMS) were required for payloads to be launched on HTV-3. The inputs were very specific and complicated. MSFC does not use this database at this time. The person coordinating this was not experienced with this process, but was able to get help from a Boeing person at JSC to walk her through. Added complications were that the manifest and Launch \/ Return \/ On-orbit Data Set (LRODS) were still being finalized when Export Control evaluation was needed, due to the shortened schedule and serial development of these products. The team was also dealing with holiday leave during December and early January, which limited the availability of personnel needed for review and approval. An MSFC Export Control Representative could not approve the inputs, so the team had to rely on the JSC Export Control Representative to approve the inputs. He didn\u2019t understand why the approval request was coming to him, which further complicated the situation. The MSFC Export Control Representatives were instrumental in working with the JSC Export Control Representatives to resolve the difficulties and get the process moving in the right direction to closure. As the project was formulating, the MSFC ISS Payloads Office had little time to review and comment on the presentation to HQ and all the affected Engineering organizations were not consulted with in preparation for the HQ presentation. Areas where the presentations needed better coordination included: a. Adequate funding allocations for manpower, materials, and testing b. Better scope of the job to be done c. \u201cReasonableness\u201d of the quote 5. Since the ISS Payload Office project and engineering teams were not included in the preliminary discussions with HQ on the proposal, the team had little knowledge of the system being proposed. In fact, due to space limitations in WORF (which is where the camera\/telescope was to reside), the hardware selection had to be changed before the team was given approval to proceed. We had to do the best with what we were given. Initial size estimates were way off of the final system.","Lesson ID":7217}
{"Driving Event":"The Astronomical Roentgen Telescope X-ray Concentrator module was assembled in a 10K clean room, including a process of bonding mirror shells into a mounting \u201ccomb\u201d, which then has a thermal housing assembled around it. A series of concentric shells are mounted into the mounting assembly, called a \u201cspider\u201d. The mounting assemblies are basically end caps, with the combs keeping the spacing of the concentric mirror shells in place. After fabrication, the modules were sent for verification and validation testing, including vibration testing. Figure 1: Concentric shells assembled into module Figure 2: Shell failed to bond adequately to comb Assemblies of modules had been fabricated in the clean room in the past and had passed vibration testing, but a shell failure occurred during vibration testing of Spider 2. An project and engineering team concluded that the failure was due to misclocking the shell in the comb. A misclocking condition occurs when the cylindrical shell is rotated or incorrectly clocked relative to the expected bond surface on the comb in the spider. The team concluded that the shell rotated such that the primed area was not in the comb during shell installation and that epoxy was applied to the unprimed surface. The team decided to disassemble the mirror to verify that it was misclocked. While Spider 2 was being disassembled, vibration testing of a different mirror assembly, Spider 3, similarly failed in vibration testing on Shell 5. Since Spider 2 was disassembled, evidence for a common cause of the failure was lost. On Spider 3, the team preserved the failure site and engaged the help of experienced failure analysts to determine the cause of the failures. Following a standard and documented failure analysis regimen, the analysis team conducted a non-destructive examination of the failure sight, obtained photographs with low magnification microscopy, optical microscopy with unique lighting, Fourier Transform infrared spectroscopy (FTIR), scanning electron microscopy with energy dispersive spectroscopy, and an inspection of the fabrication facilities. In addition, they questioned the personnel who assembled the hardware and identified differences in processing parameters for the failed shells. The failure analysis team determined that the mirror shell was not properly bonded into the mounting fixture with epoxy. The most probable cause was determined to be silicone contamination of the shell surface that prevented epoxy adhesion to the shell. Silicone sources were located in the lab, and earlier spills of silicone-containing materials had been experienced at the fabrication site. Once the in-depth failure analysis was completed, the result was an improved risk posture for future module development and increased confidence that the modules would pass vibration testing. In addition, the laboratory was cleaned, knowledge was gained about the effects of silicone, and contamination monitoring put in place. Specific corrective actions put in place by the project included: \u2022 All silicone products removed from assembly area \u2022 All assembly surfaces cleaned with several different chemicals (n-Propyl Bromide (NPB), acetone, methanol) then sampled & tested by Materials and Processes Engineering organization (EM) \u2022 EM placed optical witness samples in assembly area \u2022 No shells were allowed to be left exposed more than 1 working day \u2022 Protective barriers were placed over assembly area \u2022 An additional cleaning step was included in assembly procedure \u2022 Bond surface cleanliness levels were verified via bond pull tests on witness samples \u2022 Daily mopping of the lab floor \u2022 Weekly contamination monitoring (air samples) \u2022 Restricted access. End Result: Failure 1. Not maintaining proper housekeeping in bonding areas led to silicone contamination and bondline failures in two modules. Failure 2: Not accurately determining the cause of the first failure put other hardware at risk. The second failure resulted in loss of schedule (module was put it in the vibration test queue, which took time) and additional costs (charges for vibration table and technician time) and could have been avoided.","Lesson ID":9001}
{"Driving Event":"MSL has two lithium ion batteries that are recharged several times per day. These batteries enable the Curiosity rover\u2019s power subsystem to meet the peak power demands of Rover activities when the demand temporarily exceeds the onboard multi-mission radioisotope thermoelectric generator (MMRTG) steady output level of ~100 watts. The flight computers (labeled \u201cRCEs\u201d in Figure 1) are always shut down prior to these recharge cycles. Figure 1. MSL avionics subsystem Six months after landing on Mars (i.e., Mars sol-200), telemetry reported uncorrectable errors in the NAND flash memory (Reference (1)). Analysis revealed that several flight software (FSW) tasks had hung up, leading to an inability of the prime computer (Rover Compute Element (RCE) \u2018A\u2019) to turn off for its normal recharge session. Normally, fault protection would intervene: a watchdog timer would count down to zero and trigger a computer reboot. Instead, the watchdog timers were being reset. This could inexorably lead to a power brown-out of the Rover in three to six days: such loss of commandability that leaves the Rover discharging is a potentially mission-catastrophic event. Within 16 hours of the initial error message, mission controllers at the NASA\/Caltech Jet Propulsion Laboratory (JPL) bypassed the FSW and commanded a swap from RCE-A to the backup computer (RCE-B). Tones (i.e., \u201csignals\u201d) were subsequently received from the Rover confirming that the \u201cbackup\u201d string had become \u201cprime\u201d and had entered safe mode. Information that the new prime computer gathered from the failed computer indicated that errors in the FSW had exacerbated a hardware fault in the flash memory. The MSL Flight Team faced a situation where the Rover was effectively left with \u201csingle string\u201d avionics only 35 days prior to the Mars solar conjunction (when the spacecraft would not be commandable for 25 sols). Also, since the same FSW and flash memory were present in the new prime computer (RCE-B), the remaining string was of questionable reliability. Failure investigation indicated that a single chip in the flash memory array was generating errors during erase cycles, likely due to a connectivity problem on the circuit board, or due to infant mortality of the commercial part. (Pre-flight testing had only erased the NAND ~12 times, as compared to an additional 38 erases (Reference (2)) after launch. The NAND part should have a life of 100,000 cycles.) Spacecraft functionality was recovered by segregating the bad flash memory; a direct hardware reset then rebooted RCE-A to operate with a half-size flash file system. (Because the data storage volume was sized with substantial margin, the loss of half the memory does not impact the mission.) Also, an additional (maximum up-time) watchdog timer was added to the flight software to strengthen fault protection. However, JPL would have been unable to diagnose the problem were it not for an avionics architecture that allowed the non-prime computer to be powered and providing telemetry on its \u201chealth\u201d even when the (RAM-based) FSW was not running on it. References: \u201cDouble Bit Error was observed on NVMCAM NAND on Sol-200,\u201d JPL Incident Surprise Anomaly (ISA) No. 54013, February 27, 2013. James A. Donaldson, \u201cThe MSL Sol-200 Anomaly: \u2018The Perfect Storm\u2019 or \u2018How the MSL Avionics Architecture Enabled the Recovery of the Curiosity Rover\u2019,\u201d September 24, 2013.","Lesson ID":11201}
{"Driving Event":"The ISERV payload was developed to provide data and images for the SERVIR team through a downlink from the ISS. Health and status information of the ISERV system was required through the downlink also. The ISERV payload has the capability for issuing commands at predetermined times and accepts file transfers from the WORF. Specific events and obstacles encountered during the design and development of the payload provide the basis of the lessons learned. They are: There was a lack of clarity with the flight certification for the COTS hardware. Many agreements concerning what type and condition of hardware is acceptable to fly were verbal and limited to specific disciplines. From a Materials and Processes (M&P) point of view, COTS equipment is normally held to the same standards as flight hardware, but ISERV never had the pedigree to do that. While ISERV did not have a problem with specific materials, they experienced a failure in Electromagnetic Interference (EMI) verification testing because the camera chip emitted electromagnetic radiation. It was found that a subtier vendor had put a GPS feature on the camera chip, unbeknownst to the camera vendor. Also during EMI testing, during the troubleshooting efforts, the test team discovered that the telescope pointing mount radiated a significant amount of noise. The Principal Investigator made a request of the vendor to take pictures of the inside of the telescope mount and email them to the test team. The vendor provided the photos by the next day. These photos enabled the team to identify the source of the noise. The photos were also helpful in pointing out a potential issue that could have caused a problem during vibration testing. One of the EMI engineers identified a component (ferrite) in the telescope base that did not look to be securely mounted, which could cause damage to the telescope during vibration testing. Corrective measures were necessary before continuing vibration testing. A common assumption is that purchased COTS units are identical. This was not the case, and in general, will not be the case. Late discovery of dimensional and configuration differences surprised the mechanical designer and revealed that a planned mechanical stop would not work. The team had to wait until certain development and testing work progressed to a non-critical path intervention point before being able to take the evaluation unit apart, obtain exact dimensions, and develop a new design solution in a quick response recovery situation. Custom designed cables are often required when using COTS equipment, and custom power supplies are frequently needed. ISS requirements state that if using COTS, certain vehicle requirements must be met. The ISS requirements are intended to protect ISS assets and ensure that the COTS equipment doesn\u2019t cause problems with the ISS vehicle. The ISS requirements do not address the conditions and requirements needed to ensure that the designed system can perform its intended function on the ISS. The project team could have benefited from better guidance on specific requirements in ensuring a system performs in an ISS environment. Without having a unit for engineering to disassemble and measure dimensions, the stress analyst had to conservatively estimate part thicknesses, masses, and other structural properties. The uncertainties made the analysis more difficult to perform and added to overly conservative estimates. Interfaces between the COTS hardware and the other payload hardware were not defined and evaluated for expected conditions and interface compatibility early enough in the design cycle. The three threaded bolt holes on the COTS unit were discovered to be insufficient for testing, and another small bolt used as a stop did not function with the precision expected. Early definition of interface requirements could have suggested the need for additional analysis and hardware at these interfaces.","Lesson ID":7216}
{"Driving Event":"The six-month mission for DI to study the interior composition of the comet Tempel 1 (Figure (1)) was completed in 2005, and the spacecraft was re-tasked as the Extrasolar Planet Observation and Deep Impact Extended Investigation (EPOXI) mission to study extrasolar planets and execute a flyby of the comet Hartley 2. Including this extended mission, JPL\u2019s DI\/EPOXI science mission lasted a total of eight years and the spacecraft traveled over 7 billion kilometers. Figure 1. Collision of the DI impactor with the comet 9P\/Tempel (Tempel 1) Mission controllers lost contact with the spacecraft in August 2013, when no carrier signal was received from it during a planned downlink pass (Reference (1)). Spacecraft communications had been nominal during the previous pass several days earlier. Controllers spent several weeks trying to uplink commands to reactivate the spacecraft\u2019s onboard systems, but all attempts to regain contact with the spacecraft were unsuccessful. Although the exact cause of the mission loss is not known with certainty, the spacecraft operations team at JPL and its major contractor uncovered a potential problem with computer time-tagging that could have led to loss of spacecraft attitude control. DI\/EPOXI flight software includes a fault management function that reports and logs all onboard fault protection activities and events, such as declaring a symptom, declaring a fault, running a response, or the occurrence of a processor reset. The function computes an integer representation of spacecraft time in milliseconds by taking the spacecraft clock represented in seconds as a 64-bit floating point number, multiplying it by 10, and casting it back into a 32-bit unsigned (i.e., non-negative) integer. (\u201cFloating point-to-integer conversion\u201d is necessary in order to convert a decimal number issued by the clock into a binary value recognized by the computer.) The computation does not guard against an overflow condition where spacecraft time in milliseconds can no longer be fully represented within 32 bits. This occurred when the spacecraft clock reached 429,496,729.6 seconds, which corresponded to the date \u201cDOY 223\u201d (2013). At this point in time or beyond, the computation results in a floating point error that ultimately triggers a processor reset. This floating point-to-integer conversion error is a common failure mode present in the file systems associated with both the Computer A and Computer B flight processor units in the DI\/EPOXI flight system. Once the trigger time was passed, each processor would have reset upon the first event reported by the fault manager. This would likely have been a benign symptom notification such as loss of stars in the star tracker field-of-view. Subsequently, neither of the two flight processors would boot successfully because fault protection responses to place the spacecraft in safe mode would retrigger another reset. The spacecraft would be left in an infinite reset cycle (aka, \u201cdeadly embrace\u201d lockout) and unable to run flight software; as this includes attitude control software, the spacecraft would issue no commands to the thrusters. With this loss of attitude control, the spacecraft is unable to properly position either the spacecraft antennas for communication, or the solar arrays for generating power, until the spacecraft is no longer power positive. The battery would then discharge until the bus voltage drops below its minimum threshold, and equipment heaters would turn off, leaving the spacecraft completely inoperable. Such data conversion errors are not uncommon and can have disastrous results. The Ariane 5 rocket self-destructed during its first test flight in 1996 because a 64-bit floating point value in the control software was too large to be represented by a 16-bit signed integer (Reference (2)). A failed Patriot missile intercept of an Iraqi Scud that killed 28 U.S. soldiers in 1991 was traced to conversion of clock time into a value limited to 24 bits in length (Reference (3)). As the DI\/EPOXI approach to computer time-tagging in flight software is ubiquitous, a similar problem could exist in the software baselines of other spaceflight projects. Reference (4) is a memo that notified another 29 JPL missions of their potential vulnerability stemming from this computation within the fault management function. References: \u201cMissed communication pass,\u201d JPL Incident Surprise Anomaly (ISA) No. 55044, September 14, 2013. \u201cAriane 5 Flight 501 Failure, Report by the Inquiry Board,\u201d July 19, 1996, Paragraph 2.1, http:\/\/www.di.unito.it\/~damiani\/ariane5rep.html \u201cPatriot Missile Defense: Software Problem Led to System Failure at Dhahran, Saudi Arabia,\u201d U.S. General Accounting Office Report No. 92-26, February 1992, p. 5, http:\/\/www.gao.gov\/assets\/220\/215614.pdf. \u201cDeep Impact Flight Software Anomaly Notification,\u201d memo from Michael Sierchio, September 30, 2013.","Lesson ID":10701}
{"Driving Event":"Most spacecraft designed by the NASA\/Caltech Jet Propulsion Laboratory (JPL) have been powered by panels of solar cells that convert sunlight to electricity. The power requirements of deep space missions, however, sometimes mandate use of a radioisotope power generator such as the one now used to power the latest Mars rover. Converting heat from radioactive decay into electricity does not require sunlight, but the technology is more complex than solar cells. The Thermoelectric Conversion Technologies Testing Laboratory (TCTTL) in the basement of JPL Building 277 is a one-of-its-kind facility for thermoelectric materials synthesis and characterization. The annual preventative maintenance of the Building 277 water chillers was performed on February 1, 2014 (References (1) and (2)). This activity involved the removal of autumn leaves and other routine maintenance. As it was a Saturday when most laboratory staff would be absent, it was a convenient time for the JPL facility maintenance contractor to shut down the chiller, pump, and chilled water that services the TCTTL. However, this work was not adequately coordinated with the technicians in the lab, and critical testing equipment was not safeguarded or taken off line. The lack of chilled water caused elevated temperatures in the lab\u2019s test chambers, resulting in the failure of a brazed joint in Test Chamber #41\u2019s closed-loop water cooling system. When their work was completed, the maintenance crew restored the flow to the building\u2019s chilled water system on Saturday afternoon. Because the brazed joint cracked due to the high temperature, the chilled water leaked through the crack and entered into the test sample areas of Test Chamber #41. This caused a loss of pressure in the chamber that allowed the water to leak out of the chamber and onto the facility floor. The next morning, a research technologist entered the TCTTL to check on his experiment and discovered a half-inch of water covering the entire lab floor. He entered the room with the standing water to check for the source of water. Unable to determine the source of the leak, he called an off-duty lab technician. Once the technician arrived, they found water coming out of Chamber #41. The two JPL employees began to remove the pooled water with a wet\/dry vacuum; they also used a ceiling-mounted crane to open the leaking Test Chamber #41, releasing an additional 50 gallons of water that had been trapped inside the chamber (Figures 1 and 2). During this activity, the two employees were unaware of the possibility that the pooled water might be energized given the many live electrical cables on the floor of the lab. Figure 1. Test Chamber #41 with the top\/cover removed Figure 2. Close-up of Test Chamber #41 showing the remaining water pooled in the chamber At the time of the water leak, the life test on the 18 tellurium, antimony, germanium, and silver material samples had been running continuously in Test Chamber #41 since June 2012, and had accumulated 16,000 test hours on the samples. The purpose of the life test was chiefly to better quantify changes in thermoelectric properties over time at high temperatures to predict degradation of Multi-Mission Radioisotope Thermoelectric Generator (MMRTG) power output. The samples were being tested in six separate furnaces (Figure 2) and immersion in the leaked water quenched the samples. The water leak caused the early termination of the life test and loss of all test samples. Figure 3. Furnaces installed inside a test chamber, which operates in an argon atmosphere Figure 4. Instrumented test samples mounted on the furnace doors\/covers Other test chambers and test samples in the building, as well as Mars Science Laboratory battery cells under test in the nearby Battery Lab, could have been compromised if the chilled water had not been restored in a timely manner. In addition, there was substantial damage to TCTTL test hardware, and the facility cleanup took 50 hours. The incident was classed as a \u201cNASA Mishap Type C,\u201d in which the total direct cost of the mishap was between $50,000 and $500,000. References: JPL Mishap Report No. 2979, February 2, 2014. Naomi Palmer, \u201cBldg. 277 Water Incident: Feb 1, 2014,\u201d February 13, 2014. \u201cBan Nonessential Infrastructure Support Services That Could Disrupt Critical Mission Operations,\u201d Lesson Learned No. 2216, NASA Engineering Network, August 18, 2009.","Lesson ID":10401}
{"Driving Event":"On December 20, 2012, a KSC Construction of Facilities (CoF) subcontractor employee was injured after being struck by a 16-inch ductile steel pipe, causing the employee\u2019s ankle\/foot to become trapped between the pipe and parking lot surface of the Launch Equipment Shop (LES). The pipe, weighing approximately 1250 pounds, was being maneuvered as part of the water main revitalization project. The undesired outcome resulted when the excavator operator (EO) released the tension on the lifting sling attached to the upper section of the top-heavy pipe. The injured person (IP) attempted to secure the pipe from moving by using a 4x4 wooden dunnage board as a brace. The pipe rolled over the brace and struck the IP while the IP was attempting to run away. The IP\u2019s ankle\/foot was subsequently trapped between the pipe and the parking lot surface resulting in the presumptive diagnosis of a tibia\/fibula fracture in the area of the ankle. The OSHA\u2019s Form 301 states \u201ccrushed ankle.\u201d The IP was transported to the KSC Occupational Health Facility (OHF) by the EO in a privately owned vehicle. The IP was evaluated and subsequently transported by KSC Emergency Medical Services to an area hospital. The IP was hospitalized for inpatient care. Despite numerous attempts to schedule an interview the IP did not comply with any requests.","Lesson ID":11001}
{"Driving Event":"The MSL rover, designed and built by the NASA\/Caltech Jet Propulsion Laboratory (JPL), acts as a mobile field laboratory, measuring the abundance of various minerals on Mars to determine the environmental conditions that existed when they formed. When scientists on Earth espy an interesting formation, a sample is collected and funneled into the body of the rover. Then quantitative mineralogical analysis is performed by the Chemistry and Mineralogy instrument (CheMin), built by JPL, and analysis of carbon compounds is performed by the SAM instrument, built and operated by NASA Goddard Space Flight Center (GSFC). To collect and prepare rock samples for in situ analysis by these instruments, JPL\u2019s robotic MSL Sample Acquisition, Sample Processing and Handling (SA\/SPaH) subsystem removes material using a drill (Figure 1), collects the resulting fine powder, sieves it, and delivers it to a sample holder. Figure 1. Engineering model of MSL drill, with (removed) Drill Bit Assembly During a November 2011 drilling test conducted in the Qualification Model Dirty Testbed (QMDT) at JPL, it was discovered that the inner diaphragm seals (Figure 2) in the DBA were slipping, allowing the bearing housing to rotate with the drill bit. The resulting wear did not degrade drill performance, but it generated debris that mixed in with the drilled rock powder. The debris included polytetrafluoroethylene (PTFE) fluoropolymer seal material that, if it exited the bearing housing during Mars operations, had the potential to clog critical components or complicate X-ray analysis of the sample (Reference (1)). Figure 2. Diagram of MSL Drill Bit Assembly Further investigation of the problem (Reference (2)) determined that seal wear and PTFE debris generation during normal operation are inherent to the DBA design, and that the quantities generated will not impede the flow of rock powder samples to either instrument. It was also determined that the PTFE contamination will have a minor impact on MSL science. The level of PTFE contamination (average of 1 part per million) of rock samples is too low to affect CheMin science results. For SAM, however, the presence of PTFE may complicate sample analysis: Organic Check Material (OCM) testing on Mars may be necessary to clarify the science results if it appears Mars compounds have signal peaks that overlap with the PTFE signal peaks. JPL design processes recognize the potential for spacecraft materials to contaminate delicate instruments and sensors. Early in MSL development, both the selection of PTFE as a seal material and the tendency of the drill to shed PTFE debris into the sample were discussed by mechanical design engineers and contamination control specialists working on SA\/SPaH and on the instruments. Early tests performed at JPL and GSFC with non flight-like hardware evaluated the potential for large amount of PFTE debris to clog the DBA (Reference (2). However, the impact on SAM science of PTFE debris exceeding quantification limits could not be evaluated until such quantities were generated by the DBA life test in November 2011, several weeks prior to MSL launch. Because the mission risk from PTFE debris was shown to be acceptable, the recommended corrective action was to continue use of the DBA while minimizing the low rate-of-penetration operations that yield the largest concentrations of PTFE in the SAM. The rate that SAM generates science results on Mars is likely to be affected by the operational restrictions stemming from this sample contamination issue. Further, science results produced by other instruments flown on future JPL missions may be more severely affected by material signatures from such sample contamination. References: \u201cDBA Inner Diaphragm Seal,\u201d JPL Problem\/Failure Report No. 50492, November 2, 2011. \u201cTiger Team De-Briefing Teflon Contamination of Drill Samples PFR 50492,\u201d October 9, 2012.","Lesson ID":10801}
{"Driving Event":"During the middle of development for the 2012 LCS software delivery, a process change was implemented to start using a computer-based code collaboration tool to conduct software code peer reviews. Previously, traditional meetings were held for code peer reviews. Prior to and subsequent to implementation of the new process some key parties were not notified of the change and therefore missed out on the opportunity to participate in several code peer reviews. By the time the problem was identified and the collaboration tool was made available to the additional parties, the majority of code peer reviews had already taken place.","Lesson ID":10302}
{"Driving Event":"The Space Shuttle Main Engine (SSME) pre-valve screens were not part of the original Shuttle design and were added later. The screen was designed to prevent particles greater than 1000 microns from entering the SSMEs. The screen's effect on Net Positive Suction Pressure (NPSP) was assessed during qualification testing. However, the testing did not identify a maximum particle size that could break through the screen.","Lesson ID":6137}
{"Driving Event":"The Jet Propulsion Laboratory requested the NESC investigate the cause of intermittent electrical shorts over a period of six years on the Cassini space probe. The JPL had isolated several of the events to the CAPS analytical instrument. The NESC investigation determined the internal shorts in the CAPS instrument were most likely due to the presence of tin whiskers on tin plated metal cans of transformer components on a circuit card. Knowledge of and methods to mitigate tin whiskers have been known since before 1970 and policies are in place to address the issue. Even with these actions, the condition continues to occur within NASA systems. References: NASA Advisory on Tin Whiskers http:\/\/nepp.nasa.gov\/npsl\/Prohibited\/na-044.pdf NASA Parts Policy http:\/\/nodis3.gsfc.nasa.gov\/displayDir.cfm?t=NPD&c=8730&s=2C GEIA-STD-0005-2, Standard for Mitigating the Effects of Tin Whiskers in Aerospace and High Performance Electronic Systems NASA Tin Whisker (and Other Metal Whisker) Homepage http:\/\/nepp.nasa.gov\/whisker\/","Lesson ID":6956}
{"Driving Event":"The accelerated schedule for the OSP program necessitated that requirements development be conducted before the OSP teams ( NASA centers and the contractors) were fully staffed. This resulted in incomplete requirements that lead to later updates and changes.","Lesson ID":10001}
{"Driving Event":"There are approximately 5000 splices on high voltage power cables across KSC. Splice failures on high voltage cables result in an arc flash (i.e., explosion, flame and smoke). Mitigations to assure safety to personnel in the vicinity of the cables included either de-energizing cables or utilizing extremely cumbersome personal protective equipment (PPE). De-energizing the cables requires outages affecting a large population and often systems which support an even larger population. The number of outages required is usually difficult to manage and extremely costly in both dollars and lost productivity across all KSC activities. Also, implementing outages involves risks to others due to electrical switching and establishing generator back-up when facilities cannot be de-energized. The PPE required in the energized configuration is cumbersome, resulting in longer durations for construction and maintenance tasks and increased personnel exposure to the risk of an arc flash. Furthermore, with the reduced dexterity as a result of the necessary PPE, the construction or repair may not meet specifications or may be impossible to perform. Concern regarding personnel safety due to the potential of arc-flash (splice failure) in a man-hole environment was identified. As a result, KSC performed laboratory testing to characterize the hazard. The testing, performed in March of 2014, provided a clearer understanding of the hazards associated with an arc flash and reinforced the need to implement alternate risk mitigation(s).","Lesson ID":9501}
{"Driving Event":"The Mars Science Laboratory (MSL) rover (Figure 1) is equipped with eight low resolution (one-megapixel) Hazard-Avoidance Cameras (Hazcams) that provide three-dimensional information about the Martian terrain. The Hazcams are equipped with optically transparent lens covers to protect the cameras during descent; each cover is opened after touchdown using a one-time deployable hinged mechanism. Certain Hazcam parts, including the lens cover assemblies, are protected by a MIL-A-8625, Type II black anodic coating. t Figure 1. Hazcam locations on MSL. (The Navcams pictured do not have lens covers as they are stowed in a protective nook during descent and landing.) Following a 50-hour, high temperature, thermal-vacuum bakeout in January 2011 at the NASA\/Caltech Jet Propulsion Laboratory (JPL), flaking or spalling of the anodic coating on the lens cover assemblies and installation hardware (Figure 2) was observed (Reference (1)). A tape lift test, conducted on each part to evaluate adhesion of the coating, removed a significant portion of the coating from the surface of the parts. All of the parts that exhibited anodize flaking were made of 7075 aluminum, and they were processed in accordance with Reference (2). Figure 2. SEM images of the flaking surface showed a micro- cracking or crazing of the surface with much of the anodize removed. The anodize thickness was within specification, and SEM revealed no unusual features or chemistries. JPL convened an MSL Black Anodize Anomaly Resolution Team to determine the cause of the coating failures. Coupon tests determined that: Elevated thermal exposure, such as a Planetary Protection Bake, was required to initiate spalling. The spalling was compounded by further thermal cycling (-130 to 50 \u00b0C) Crazing, caused by a coefficient of thermal expansion (CTE) mismatch between the aluminum substrate and the anodic coating, preceded each spalling failure. But crazing was not a predictor that the anodic coating would spall with repeated thermal cycles, or fail a tape lift test. Some parts-- manufactured from the same heat lot of material, anodized in the same batch and exposed to identical environments (thermal, vacuum, etc.)-- would fail while other parts would not. A May 2011 receiving inspection of the MSL drill coupler housing, made of 7050-T7451 aluminum, found similar spalling of Type II anodize (Reference (3)). Such spalling was again found on six MSL Mars sample acquisition inlet covers after system thermal-vacuum test (Reference (4)). In each case of MSL black anodize failure, the parts were successfully reworked using a MIL-A-8625, Type III coating. More extensive coupons tests with 120 coupons traced the root cause of the failures to variations in the structure of the anodic coating, which in turn were attributable to variations in the processing parameters of the sulfuric acid bath and alloy chemistries. The coupon tests, plus literature searches (Reference (5)), hardware tests, and collaboration with industry partners, established that Type II anodize spalling is limited to the 2000 and 7000 series aluminum due to their alloy content, but that its occurrence is unpredictable. References: \u201cHazCam Cover Hardware Anodic Coating Failure,\u201d JPL Problem\/Failure Report No. 47725, February 3, 2011. MIL-A-8625F, Anodic Coatings for Aluminum and Aluminum Alloys (Type II-sulfuric acid anodizing, Class 2-dyed), September 15, 2003. \u201cLoose Black Anodize on FM Drill CS\/S Coupler Housing After Bake-out,\u201d JPL Problem\/Failure Report No. 48809, May 16, 2011. \u201cBlack Anodization Flaking from SAM Inlet Covers,\u201d JPL Problem\/Failure Report No. 48885, May 20, 2011. GOUEFON, Yann. ARURAULT, Laurent. MABRU, Catherine. TONON, Claire. GUIGUE, Pascale. Black anodic coatings for space applications: study of the process parameters, characteristics and mechanical properties. Journal of Materials Processing Technology, vol. 209, n\u00b0 11, pp. 5145-5151. ISSN 0924-0136","Lesson ID":8403}
{"Driving Event":"In preparation for testing related to the Restore Project, a test setup was assembled and a part of the test setup was constructed from excessed Space Shuttle Program hardware. This equipment was an assembly of component parts which were labeled and designated (cleaned and marked) for use with Nitrogen Tetroxide. Nitrogen tetroxide was flowed through this assembly during the testing. Prior to use, the equipment was not disassembled and inspected to ensure that all components were actually compatible with Nitrogen Tetroxide. After exposure to Nitrogen Tetroxide for approximately ten days as part of the testing, one of the components leaked. The leak resulted in elevated airborne concentrations of Nitrogen Tetroxide in the testing facility. The part that leaked was a valve assembly connected to a boss joint fitting interface. Figure 1. Photo depicting the area of valve tree boss seal area that leaked The permissible concentrations for Nitrogen Tetroxide (N2O4 vapor in a breathing zone are specified by CIP-EH-23 appendix C as a maximum of 0.2 parts-per-million (PPM) for an 8-hour exposure period. This permissible level is known as the Threshold Limit Value (TLV). The levels of N2O4 in the test facility breathing zone exceeded the TLV, which required corrective measures This incident was not classified as a safety incident because the testing facility is always cleared of personnel prior to flowing hazardous commodities and personnel are not permitted access to the facility until an Environmental Health specialist has tested for safe levels of the hazardous commodity (this is an operational control). Facility monitors for N2O4 vapor did not alarm because the concentration of N2O4 in the test facility did not exceed the facility limits. Environmental Health personnel detected elevated levels of N2O4 vapor in the facility. Inspection of the test apparatus revealed a small drip of liquid N2O4 at the leaking connection. The corrective action taken was for the Personnel equipped with Self-Contained Atmospheric Protective Ensemble (SCAPE) suit (hazmat suit) operators to change the seal and re-torque the connection. Subsequent inspection showed that the seal was made of a material that is incompatible with N2O4. Note: As part of restarting testing, two other suspect component assemblies from excessed Space Shuttle N2O4 systems similar to the leaking connection were taken apart down to the component level and no incompatible soft-goods were found.","Lesson ID":8017}
{"Driving Event":"The sole scheduled thermal-vacuum (T-V) test of a Juno spacecraft telecommunications component was being conducted in September 2008 at a facility under contract to the NASA\/Caltech Jet Propulsion Laboratory (JPL) when the test was unexpectedly interrupted (References (1) and (2)). The commercial component under test (Figure 1) was a X4 Frequency Multiplier, a small mechanical part with one internal diode on the Ka-band side of the Juno Small Deep Space Transponder (SDST). The Ka-band side of the Juno telecommunication subsystem is used for gravity science uplink and downlink via the Juno High Gain Antenna. Throughout the T-V test, data on the levels of radio frequency (RF) power flowing into and out of the X4 were being monitored by a data acquisition computer in the test facility. Figure 1. Juno Radio Frequency Instrument Subsystem (RFIS) components located in the spacecraft radiation vault. (A red oval marks the label pointing to the X4 Frequency Multiplier component.) The data acquisition computer was a typical desktop computer employing a very common commercial operating system. The test failure during the hot soak portion of the test was traced to the computer autonomously initiating contact over the computer network with the manufacturer of the computer\u2019s operating system to obtain a software update. Activating this process extraneous to the flight hardware test caused a conflict that resulted in the shutdown of the computer and the immediate termination of the test in mid-performance. Neither the flight hardware nor the support equipment controlling the environmental test were affected by the failure, but about eight hours of test data were lost due to the test interruption. This test ran for approximately one week prior to the failure, and the pre-hot soak and post-hot soak data matched. Hence, the loss of eight hours of test data was not deemed significant, and the test was not repeated. References: \u201cSDST x4 STE: Data Acquisition System Auto Off,\u201d JPL Problem\/Failure Report No. 13512, September 10, 2008. \u201cSDST x4: T-Vac Missing Data,\u201d JPL Problem\/Failure Report No. 13513, September 10, 2008.","Lesson ID":8501}
{"Driving Event":"A BOB is an item of commercial test equipment inserted between two powered electrical devices to provide ready access for probing or patching of electrical signals. BOBs are useful for identifying miswiring during safe-to-mate procedures, and they are commonly used at the NASA\/Caltech Jet Propulsion Laboratory (JPL) to support integration testing. A downside to providing easy access to cable connections that would otherwise be sealed is that inadvertent misprobing of the exposed BOB contacts may short a circuit. Figure 1. BOB configured for use in a 2008 functional test of an MSL Up\/Down Intermediate Frequency Module (UDIM) A safe-to-mate procedure was performed at JPL during integration of the Mars Science Laboratory (MSL) rover Wheel and Steering Actuator prototype into the Payload System Testbed. All measured circuit values for one encoder channel on the Rover Motor Controller were found to be within the expected ranges. However, after the system was powered off, patched to excite a different encoder channel, and the system again powered, the measured values of the second channel were found to be outside the predicted values. It was determined that mis-probing had caused a short that blew the fuse on the Rover Motor Controller Sensor. This test error by a very experienced technician was made more likely by the sensitivity of the sensor board while configured to include a BOB; similar mis-probing incidents had occurred during previous MSL safe-to-mate procedures at the subsystem level. No hardware was overstressed, and the Motor Controller Assembly team was advised to proceed slowly and carefully while in the BOB configuration. References: \u201cBlown Fuse on RMCA EM3 RMCS3 J2 Dedicated Encoder Channel,\u201d JPL Problem\/Failure Report No. 26718, June 21, 2010.","Lesson ID":8701}
{"Driving Event":"Gas and liquid sample particle count analysis failures from the GSE community led to concerns regarding integrity of the Components Refurbishment and Chemical Analysis (CRCA) facility sampling fixtures and\/or laboratory techniques. This concern prompted an internal validation of sampling and cleaning processes of pre-cleaned sampling fixtures that were staged for use. Thirty four of the unused sampling devices were inspected and seven (7) of the cleaned and staged fixtures had single particle particulate > 100 micron. These findings of 20% sample failure rate supported the conclusion that contributory contamination was occurring in the sampling\/cleaning process performed at CRCA. An Independent Investigation Team was stood-up on 01\/29\/14 and initial team findings supported concerns that the Cleanroom clean levels and maintenance were inadequate for the functions performed. CRCA Operations were suspended on Thursday, 02\/06\/14 to re-establish the Cleanroom baseline. Maintenance repairs were made to seal, adjust and replace several defective items. The Cleanroom underwent a thorough cleaning and mechanical systems were inspected, tested and verified as meeting Cleanroom requirements. Protocol procedures were reviewed and enhanced such as the processes for Cleanroom entry and gowning and gloving. Refresher training was held with the entire staff. Tools and materials to perform the cleanroom work were reviewed and new items are being provided to both improve the efficiency and quality of the work performed. Cleanroom particle counts were taken at 60 locations to establish a baseline and ensure the room meets certification requirements. To help ensure cleanroom protocols are maintained, witness plates were placed at ten (10) locations throughout the room and are being inspected frequently to determine whether any particle excursions are occurring. These witness plates are planned to be replaced with real-time particle monitoring stations equipped with local display and alarm capability to alert as contamination occurs. The CRCA Cleanroom was reopened on 02\/14\/14. Reference ISO Standard 14644 Standard for Airborne Particulate Cleanliness Classes in Cleanrooms and Clean Zones - Part 5: Operations","Lesson ID":8018}
{"Driving Event":"When NASA plans to refly existing system designs, it typically assumes that reuse of a tested or proven design will substantially reduce system development costs and mission risk. Following the 2009 launch vehicle failure of the Orbiting Carbon Observatory (OCO), NASA funded the NASA\/Caltech Jet Propulsion Laboratory (JPL) to develop and fly an identical replacement spacecraft (OCO-2). Where the single instrument aboard OCO was designed by a contractor, OCO-2 was to be developed mostly by JPL. It became clear early in OCO-2 development, however, that key OCO design knowledge was not retained to the extent it might have been if JPL had possessed foreknowledge of an OCO-2 mission. First, the OCO project had not formally updated system drawings and processes to account for all the corrections (i.e., \u201credlines\u201d). This necessitated a substantial effort by the OCO-2 project to locate the redlined information and correlate the redlines with each component. The project then had to decide whether to (1) build the corrections into the new hardware (or processes), or (2) duplicate the successive design iterations made by OCO. In duplicating the OCO processes, for example, OCO-2 added graphite to a component, and then removed it; then, because of incomplete incorporation of redlines, the project found additional places where the graphite needed to be removed. Second, the OCO design was poorly documented. The OCO contractor provided drawings to JPL in PDF format and without the redlines, and they had captured the design in disparate media (e.g., drawings, assembly and inspection data sheets, and test reports). In addition, much of the documentation (including proprietary data) had not been provided to JPL by the contractor, such as verification data at Level 3 and below. This incomplete documentation and transfer of design knowledge made it more difficult to accommodate required design changes (e.g., due to obsolescence or in response to failures on other missions) since the rationale for the original OCO design was not always manifest. As a result, JPL may have foregone some opportunities for risk reduction or cost reduction that might otherwise have followed from the reuse of a tested or proven design.","Lesson ID":8601}
{"Driving Event":"A Science Data Processing System (SDPS) is typically developed for a NASA project to accommodate the huge quantities of raw science data downlinked from instruments or experiments over the course of a mission. Sometimes referred to as a Science Data System (SDS), the SDPS converts telemetry into higher level science data products provided to the science community for research and applications. The SDPS is centered at the NASA\/Caltech Jet Propulsion Laboratory (JPL) on JPL-managed missions, where JPL is responsible for processing and distributing data products in a timely manner as required to meet mission objectives. Figure 1 depicts the science data flow to and from the science data processing function. One critical task in SDPS development is data simulation, a technique that provides visualizations of the extremely large and complicated science datasets and permits verification of the system. Figure 1. The science data processing function is depicted within the context of the entire Mission Operations System (MOS) for the Orbiting Carbon Observatory mission Legend: OSC\u2013 Orbital Sciences Corp; GSFC\u2013 NASA Goddard Space Flight Center The Orbiting Carbon Observatory (OCO), an Earth orbiting satellite mission managed by JPL, was designed to make precise, time-dependent, global measurements of atmospheric carbon dioxide (CO2). In developing the SDPS for OCO, The Ground Data System (GDS) Team (which is responsible for spacecraft and instrument monitoring and operations) did a good job of leveraging the Instrument and Observatory thermal-vacuum test output to generate datasets for system testing (Reference (1)). The team generated multiple sets of data that represented varying conditions. These data provided a good basis for OCO system testing. Unfortunately, the GDS Team was unable to generate simulated data that covered all critical operational modes. The team only generated Attitude Control System (ACS) data for the Nadir mode, and was unable to generate ACS data in the Glint or Target modes. Further, the team was not able to generate data that could run through Level 2. The Instrument thermal-vacuum tests recorded only direct solar observations, rather than solar light reflected off the surface of the Earth. The science retrieval algorithms could not work with direct solar observations. It should be noted that, despite the best efforts of the team that plans and performs an SDPS test, it is not uncommon for the SDPS test configuration and environment to be unable to generate certain characters of test data. In such cases, certain simulated data sets are generated by the science instrument during system-level testing (e.g., thermal-vacuum test), while other types of simulated data are generated by an algorithm scientist and inserted into the processing chain to exercise and validate certain science data product software executables. The Algorithm Team generated a partial orbit of spectra that simulated the spectra that they expected to see in flight. The GDS obtained that dataset, manipulated it into an OCO L1B (registered radiance at the sensor product dataset) file, and gathered the ancillary data needed to run the dataset through the Level 2 AOPD (Agent-Oriented Program & Design algorithm) PGE (Product Generation Executive). Even at launch, however, that dataset had not yet been diffused into the system testing process. For OCO, the full set of required test cases was not identified soon enough to conduct the additional planning needed for their generation. For the OCO-2 follow-on project, the full set of simulated test cases was known, and the GDS Team began early to determine which sets should be implemented and which sets the project could omit as an acceptable risk. References: P.J. Guske, \u201cOCO (Orbiting Carbon Observatory) Project Lessons Learned Document (Final),\u201d JPL Document No. D-26172, July 7, 2009, Paragraph 3.7.6.","Lesson ID":8401}
{"Driving Event":"The Kepler mission was specifically designed to discover Earth-size planets in or near the habitable zone and assess how common such exoplanets may be in our galaxy. Because the Kepler instrument required exceptional pointing stability, the spacecraft design incorporated a fixed (i.e., non-deployable) solar array (Figure 1). Figure 1. Kepler employed a fixed solar array that was partially wrapped around the photometer instrument Shortly following the March 2009 launch of Kepler, spacecraft fault protection responded to an over-voltage condition caused by the battery exceeding the specified voltage. Kepler\u2019s solar panels were hard mounted on three sides of the spacecraft. During a roll, the panels went in and out of the sunlight; this resulted in an anticipated periodicity in battery charging while the spacecraft tumbled following separation from the launch vehicle. The battery charge control algorithm was designed to adjust for the nominal roll rate during science operations. However, the over-voltage anomaly occurred because the battery charge control algorithm was not designed to manage the anticipated higher roll rate during launch operations, combined with the anticipated detumble that Kepler experienced post-separation. A Subsystem Interface Box (SIB) swap recovery contingency procedure had been vetted by an independent review team, and exercised on a testbed during operational readiness testing prior to launch. The procedure was successful in restoring the spacecraft configuration, and the battery voltage readings were nominal once detumble was completed. References: Peg Frerking, \u201cKepler SIB Swap Contingency following Auto-Initiation,\u201d March 18, 2009.","Lesson ID":8402}
{"Driving Event":"Spacecraft command file errors pose a threat of triggering an event that cannot be halted before a mission is irreversibly compromised (Reference (1)). A command file error for the purposes of this lesson learned is defined as one of the following, regardless of the effect on the spacecraft: An error in a command file that was sent to the spacecraft, An error in the approval, processing, or uplink of a command file that was sent to the spacecraft, or The omission of a command file that should have been sent to the spacecraft. Implementation of the spacecraft commanding process may vary due to project-specific attributes, such as: Commanding for deep space missions is non-repetitive, as compared to an Earth orbital mission where typical commands may be reused on a routine basis. The JPL mission operations design must be flexible to permit the exploitation of unanticipated science opportunities (e.g., Cassini\u2019s discovery of water jets venting from a polar region during a close flyby of Enceladus in 2005) by modifying planned sequences. In November 2010, a JPL Operations Working Group was formed to provide a forum for the identification, discussion, and implementation of corrective action over a broad range of operational issues across JPL institutional boundaries (Reference (2)). The initial task was to review the command file errors during 2009, identify the associated processes, and draw lessons to be incorporated back into the projects and the institution. The group met over the next three months and documented their findings. The proximate\/root causes were grouped into four major categories of: Loss of rigor (inattention to detail, complacency, inadequate review, procedures not followed, miscommunication, distraction, multitasking). Loss of situational awareness (inadequate knowledge of the spacecraft state as a function of time). Flight team work overload (stress, fatigue, rush in getting task done). Performing nonstandard activities (i.e., doing activities in different ways, first time events on the spacecraft). The themes\/findings fell into nine general categories that were subdivided into development and operations recommendations (see \u201cRecommendations\u201d). The findings and recommendations were then disseminated to projects approaching launch and early cruise operations (Juno, Gravity Recovery and Interior Laboratory (GRAIL), Mars Science Laboratory (MSL), and Nuclear Spectroscopic Telescope Array (NuSTAR)), as well as to ongoing flight missions, so they could proactively evaluate measures for reducing their overall operational error rates. References: Uplink Command Errors (A Cornerstone Lesson), \u201dNASA Lesson Learned No. 1521, April 14, 2005. Grant B. Faris and Larry W. Bryant, \u201cImproving Operations: Metrics to Results,\u201d SpaceOps 2012, Stockholm, June 11-15, 2012. \u201cEarly Involvement of Mission Ops is a Key Success Factor,\u201d NASA Lesson Learned No. 1518, November 1, 2004.","Lesson ID":8302}
{"Driving Event":"The set of six contaminated flex hoses that were found to have been damaged by the Ares I-X launch required field flushing because they contained residual hypergolic propellant. Employees were potentially exposed to hypergolic oxidizer [Nitrogen Tetroxide\/Nitrogen Dioxide (N2O4\/NO2)]. An employee was conducting cleanup operations pursuant to a Standing Work Order (SWO) and verbal direction from the supervisor. The cleanup was part of a management initiative to improve working conditions, efficiencies, and appearances at the Waste and Water Support Building (WWSB). As an employee moved a flexible stainless steel braided hose stored on the east side of the WWSB, a strong odor, similar to chlorine, and a hissing noise were noted. The employee noticed an unidentified orange-colored vapor cloud being released from one of the F\/H flanged ends, which were both capped with a metal blanking flange. Initially, the employee attempted to mitigate the situation by applying water to the flanged end of the F\/H with a garden hose.","Lesson ID":8016}
{"Driving Event":"The Propellants and Life Support Propellants North Facility, and Converter\/Compressor Facility (Bldg. K7-468), is used for the storage and transfer of compressed gasses. Tasks typically require the subcontractor safety organization's personnel to transfer compressed gasses from storage tanks to compressed gas trailers and other similar operations. Employees routinely walk to and from the office area through the Joy Compressor Room to the outside to perform these tasks. The walkway where the mishap occurred is often used for the temporary staging of incoming parts and equipment pallets. Normally the pallets are promptly unloaded and the parts\/equipment taken to their respective locations. This pallet arrived toward the end of first shift, before second shift started, and held a very heavy stainless steel valve assembly that the First Shift Lead decided could not be unloaded right away because of time constraints. Potential inclement weather was a factor in the First Shift Lead\u2019s decision not to have the pallet moved to the normal unloading location on the West end of the facility. The incident occurred while Facilities and Utilities operations were being conducted. The incident resulted in injury. The incident did not result in property damage or mission degradation\/failure. The subcontractor employee did not complete the normal work shift, but went home, and was later transported to the hospital by family members.","Lesson ID":5816}
{"Driving Event":"The Ames Research Center (ARC) was in the process of upgrading one of its buildings when some of the actions being taken by plumbing personnel resulted in a close call. A sub-contracted pipe-fitter was drilling holes in the concrete floor of the building in preparation for the installation of a gas panel. As the drill bit was passing through the concrete, the back pressure on the drill increased. In response, the pipe-fitter withdrew the drill bit and replaced it with one that was appropriate for rebar, since he believed the rebar to be the cause of the increased back pressure. With the new drill bit installed the pipe-fitter resumed drilling. However, shortly thereafter, water began to fill and drain out of the drill hole. At this point the pipe-fitter stopped his work and notified building personnel. The building personnel halted the remaining part of the job to investigate the source of the water. The immediate investigation was able to determine that a conduit housing both water pipes and three potentially lethal energized 480V AC electrical conductors was breached by the drill bit. Consequently, work was stopped, the job site secured, and measures were taken to safely complete the job. These measures included de-energizing the building; the use of lock-out\/tag-out to prevent an unintentional reapplication of the power; and the use of ground penetrating radar to locate, identify, and mark job site hazards. Later, it was also discovered that the building drawings that were used to guide the placement of the drill holes were out of date, unintelligible, and insufficiently detailed. However, the job personnel did not feel the need to acquire updated drawings because they believed that any hazards would be at least 12 inches below the floor surface, whereas the drilling would only penetrate to 10 inches. Other factors contributing to the close call included the facts that: The Center\u2019s policy regarding floor penetrations was buried in the Safety Manual appendix. The policy referenced a permit\/process that had never been developed, and therefore did not exist. Thus, the job did not receive adequate oversight and was initiated without a hazard analysis or any special precautions such as de-energizing the building\u2019s power system or the use of electronic drill stop capable bits. In essence, there were a number of uninformed decisions and inadequate processes in place that led to this close call.","Lesson ID":7156}
{"Driving Event":"In early 2004, a request was submitted to the NESC to determine the appropriate processing approach, based on technical rationale, for use of International Space Station (ISS) European-manufactured modules that did not receive post-proof weld non-destructive evaluation (NDE). Specifically, this assessment answered the main question: \u201cWhat is the likelihood of having a weld crack that either was not detected during the pre-proof NDE or was enlarged by the proof test which does not have adequate assurance of providing required life (leakage versus structural failure) in one or more of the ISS European-manufactured modules (Node 2, Columbus, and the three Multi-Purpose Logistics Modules (MPLMs)?\u201d The scope of the three-year assessment was a combination of review, consultation, and independent analyses, inspections, and tests. Specific analyses and tests ranged from limited confirmation to in-depth independent analyses and tests that were used to augment or refute boundary conditions and assumptions used in the existing leak before burst (LBB) and safe life analyses.","Lesson ID":7096}
{"Driving Event":"The 80-AS High Temperature Helium (HTH) Project was aimed at developing and operating a unique wind tunnel facility whereby high temperature helium would be the working fluid. The Project\u2019s life cycle was relatively short and had to be implemented in a very lean manner necessitating that it be implemented without either a project or systems engineer. This put the Project Manager (PM) in the position of having to perform multiple roles, each crucial to the Project\u2019s success. While the Project was highly successful, met all its technical requirements, and provided critical aerothermodynamics data for the Orion Launch Abort System (LAS), its success can in part be attributed to the surge efforts of the PM and other key members.","Lesson ID":6577}
{"Driving Event":"When GSFC audited a subcontractor on a Landsat Data Continuity Mission (LDCM) ground system element, the subcontractor was unable to identify a statement of work which flowed down requirements within the documents provided by the prime contractor. While it was later confirmed that a statement of work was in the contract documentation, it did not contain requirements for the subcontractor. The subcontractor was separately given the set of requirements for the entire ground system element, and not for the specific portion that the subcontractor was working on. The prime contractor was a small business and this was their first experience as a prime.","Lesson ID":6756}
{"Driving Event":"Initially, the Constellation program did not have a leveling system for lifting\/mating the Upper Stage to the First Stage. Later, it was determined that because of center of gravity offset, some amount of leveling was needed to counteract the negative effects of off-center loading. Because the design of lifting GSE was very mature at the time, it was difficult to add active leveling capabilities to the design.","Lesson ID":4999}
{"Driving Event":"Several different change vehicles (CRs, MCRs, DCNs, IRNs) were created by the Constellation program with the goal of expediting the change process. The DCN, for instance, was intended to push through program-level changes quickly. Instead, the multiple change methods merged into a cumbersome process that required weeks\/months before changes could be made.","Lesson ID":5125}
{"Driving Event":"The Landsat Data Continuity Mission (LDCM) Observatory was powered-up after installing the flight battery and all reported telemetry from the observatory was invalid. Following an extensive investigation, it was determined that an accidental short of the flight battery to the chassis occurred while the observatory single-point ground was lifted, allowing battery current to flow through the observatory chassis and damaging numerous components in the electrical power system boxes and electrical ground support equipment. One of the root causes of the incident was that the battery heater power harness was not properly constructed and did not isolate the battery case from the spacecraft chassis as designed. The Electromagnetic Interference (EMI) shielding in the harness was intended to be discontinuous, but it was manufactured with an unbroken run of shield connecting the backshells at either end of the harness, shorting the battery case to the spacecraft chassis. This error was identified during safe-to-mate measurements, but not immediately corrected. A supplemental work instruction was generated to correct the harness, but the work was not identified as a lien to battery integration.","Lesson ID":6758}
{"Driving Event":"The Landsat Data Continuity Mission (LDCM) Observatory was powered-up after installing the flight battery and all reported telemetry from the observatory was invalid. Following an extensive investigation, it was determined that an accidental short of the flight battery to the chassis occurred while the observatory single-point ground was lifted, allowing battery current to flow through the observatory chassis and damaging numerous components in the electrical power system boxes and electrical ground support equipment. One root cause of the incident was that the flight battery positive terminal was mated through a connector saver which was not properly insulated, causing a short to the battery case. The non-flight connector saver was provided as part of the battery delivery from the vendor. Since it was not flight hardware, it was not the subject of a government mandatory inspection point (GMIP) at receiving. The first opportunity for government quality assurance personnel to inspect the connector-saver was during the safe-to-mate to the flight battery. Neither the contractor nor government inspections identified the missing insulation on the back of the connector.","Lesson ID":6757}
{"Driving Event":"The Orion design did not take into consideration mass, volume, power, and thermal constraints to satisfy PEPC requirements and to optimize ground processing and recovery of time-critical PEPC.","Lesson ID":5010}
{"Driving Event":"The Reusable Solid Rocket Motor (RSRM) Property Disposition team was challenged with limited budget and schedule. At the end of the Shuttle and ARES Programs, limited budgets reduced the resources available for transition and retirement of property. Cancellation of the ARES program during the anticipated end of the Shuttle Program complicated the planned Shuttle transition and retirement strategy. Innovations in the transition and retirement process enabled NASA and the prime contractor to meet budget and schedule requirements.","Lesson ID":6976}
{"Driving Event":"NASA Systems Engineering Processes and Requirements, NPR7123.1 defines the System Integration Review (SIR) as: \u201cAn SIR ensures that the system is ready to be integrated. Segments, components and subsystems are available and ready to be integrated into the system. Integration facilities, support personnel, and integration plans and procedures are ready for integration\u201d. Logical options for SIR timing in a project\u2019s integration and test flow range from as early as just prior to spacecraft subsystem integration (subsystems coming together to form the spacecraft) to as late as the beginning of observatory integration (instrument integration onto the fully integrated spacecraft). The LADEE SIR was placed early in the window, prior to the first spacecraft integration. The objective of this timing was to accomplish a thorough assessment of the project\u2019s readiness for in-house assembly including procedures, processes, training and facilities. This timing was appropriate and necessary for the LADEE ARC team that was inexperienced at in-house spacecraft assembly and test. However, this placement created a very large scope for a single milestone review. The LADEE project did not pass the SIR in November 2012 due to a lack of demonstrated readiness for near term spacecraft integration activities as well as a lack of clear and executable plans for later observatory integration and testing. Following the unsuccessful November SIR, plans were emplaced to elevate key near term project integration readiness reviews, which would have otherwise been led by the project, to be chaired by the ARC Chief Engineer with participation from a subset of the Standing Review Board and other key stakeholders. These incremental detailed reviews enabled the project to proceed into spacecraft integration, preserving critical project schedule, but only after demonstrating that SIR identified deficiencies had been acceptably addressed. A fully successful delta-SIR was subsequently held in August 2012 prior to observatory integration. This approach, in effect, functioned as a staged SIR review process by breaking the scope of the review into smaller scope focused reviews that could be more easily prepared for by the LADEE project team.","Lesson ID":6996}
{"Driving Event":"According to NASA document, Draft NIST Special Publication 800-88 Rev 1, we are required to wipe hard drives that contain NASA data and verify data is removed after the sanitization process. We were instructed by local security personnel to use Darik's Boot and Nuke (DBAN) software. Several issues were encountered and workarounds were required for the freeware version.","Lesson ID":7016}
{"Driving Event":"In December 2004, the NASA Engineering and Safety Center (NESC) received a request to characterize and quantify the sensitivities of Loctite\u00ae being used as a secondary locking feature. The reliability of these compounds had been questioned due to a number of failures during ground testing. The NASA Johnson Space Center engineering community implemented a policy restricting the use of Loctite\u00ae as a secondary locking feature especially in safety critical applications due to this perceived unreliability.","Lesson ID":6937}
{"Driving Event":"The Space Shuttle T&R team was responsible for the management and disposition of a large amount of real and personal property spread across a number of NASA centers, contractors, subcontractors and vendors while identifying and satisfying many diverse environmental requirements. In a number of cases, requirements were not available or were vague and subject to interpretation.","Lesson ID":6837}
{"Driving Event":"On August 26, 2011, a fire suppression sprinkler head leaked and then failed in Building 600 at the NASA\/Caltech Jet Propulsion Laboratory (JPL), inundating several office cubicles. The initial leak was reported earlier in the day to the JPL Office of Protective Services (OPS), OPS contacted the building owner, and a maintenance crew was responding when the sprinkler head triggered the full water release. The impact of the water damage was minor. However, the affected office space shares the fire alarm system with an adjacent data center that, among other activities, supported Mars Science Laboratory (MSL) Assembly, Test, and Launch Operations (ATLO). There was no water release in the data center, but it was believed that the fire alarm system was programmed to shut down power to the data center unless the shutdown was manually countermanded within ten minutes. The data center was not staffed because August 26 was an RDO*, the security guard arrived after the ten-minute period had elapsed, and the data center suffered a power outage. Building 600 is one of the few JPL buildings that is leased from a private owner. Although the procedure for placing the data center electrical system in bypass is posted in the electrical room of the data center, subsequent investigation found that the shutdown was immediate: there is no ten-minute delay in triggering the power shutdown after the fire alarm is triggered. JPL was misinformed, and such a delay is not compatible with the fire code. To prevent a recurrence of this incident, JPL installed a double-interlock, preaction, fire suppression system to replace the existing system in the Building 600 data center. Preaction systems are suitable for water sensitive environments like data centers because (until a valve is electrically activated) they contain no water in the sprinkler piping so a sprinkler head failure does not release water. The double-interlock feature prevents flow of water until both a sprinkler head and a separate detector are triggered simultaneously. (Triggering only one of the two devices will produce an alarm, but no water flow into the system.) Because this fire suppression system is separate and isolated from the system in the Building 600 office space, an alarm in the office space will not trigger an electrical shutdown in the data center. *Most JPL personnel work a schedule that allows them an additional day off work every other Friday, and August 26, 2011 was such a Regular Day Off (RDO). References: \"B600 Power Failure,\" Incident Surprise Anomaly Report No. 49896, NASA\/Caltech Jet Propulsion Laboratory, August 30, 2011. \"DNS Server Outage Caused Loss of Uplink In MSTB During ORT2,\" Incident Surprise Anomaly Report No. 49699, NASA\/Caltech Jet Propulsion Laboratory, August 11, 2011.","Lesson ID":6776}
{"Driving Event":"To cure a large laminate structural part, the part is wrapped in layers of material that maintain a vacuum on the part and allow a portion of the resin to bleed away from the part. For this part, the stack up of bag layers is: peel ply, perforated release film, bleeder, solid release film, breather, and then vacuum bag. The function of these layers is: Peel ply \u2013 Layer of no-sticking material that allows the bagging to be removed after cure; Provides flow path for the applied vacuum Perforated release film \u2013 Allows for the appropriate volume of resin bleed by having the specified bleed holes at the specified spacing Bleeder cloth \u2013 Soaks up resin as the vacuum process pulls it from the composite structure to permit part cure Solid release film (non perforated) \u2013 Protect the vacuum bag from the resin Breather \u2013 Polyester material allows a vacuum to be maintained throughout the entire part without pinching off in any area Vacuum bag \u2013 Provide the pressure barrier between the high pressure in the curing chamber and the vacuum drawn on the part Vacuum Sealer Tape \u2013 Seals the joints in the bagging material to complete the bags. The scrapped part was the third unit of this part to be built. The part is conical in shape, so flat sheets of bagging material did not drape nicely over the part. During the original two builds, the manufacturing crew cut the bagging materials into gore sections and taped them together to achieve a good fit to the part. The criticality of cutting bagging materials into gore sections was unknown and un-documented. On the third build of this part, the manufacturing crew wrapped the flat sheets around the part then taped the one joint. During the cure of the third part, wrinkles formed when vacuum was applied to the bags. At the wrinkles areas, additional holes formed in the perforated release film and holes formed in the solid release film. These new holes in the bagging material allowed excessive resin to bleed through the perforated release film and also to bleed through the solid release film. The resin in contact with the vacuum bag cured, permitting stress concentrations to form on the vacuum bag. The vacuum bag failed at 231 minutes into the cure and at 329 deg F, causing the part to be nonconforming.","Lesson ID":6616}
{"Driving Event":"The Terrain-Relative Navigation and Employee Development (TRaiNED) project was a Class D (i.e., low cost, high risk) mission employing a sounding rocket to capture exoatmospheric and low-altitude imagery. Using the imagery to refine navigation algorithms, the payload developed by the NASA\/Caltech Jet Propulsion Laboratory (JPL) for the 41.087 mission (Dr. Martin Heyne, Principal Investigator) was intended to advance the technology for autonomous terrain-relative navigation and hazard detection, providing aerial and surface access to key sites in the solar system. The launch of the 41.087\/Heyne Terrier-Improved Orion sounding rocket (Figure 1) from White Sands Missile Range (WSMR) on December 6, 2010 was nominal, but no data was received from the JPL-furnished cameras located in the exoatmospheric section. The camera field of view was blocked by a blow-off door, which did not release early in the flight as planned. The sounding rocket for the quotHeynequot mission employed a legacy design in which the door (Figure 2) is held in place by tabs and by a single brass screw that is severed in flight by a pyrotechnic guillotine cutter. Rotational acceleration forces then act on the released door, which rotates away from the payload. ......................... Figure 1. Heyne mission sounding rocket just prior to flight at WSMR Figure 2. Close-up of the sounding rocket, with an Exoatmospheric Camera Door clearly visible on the left Review of telemetry records, inspection of the remaining door hardware, and material analysis, established that the blow-off door release (Figure 3) was actuated at the proper time in flight, but the deployment screw was only partially severed by the cutter (Reference (1)). A more common industry practice is to use high strength fasteners with an extremely high pre-load, so that the cutter only need weaken the screw to the point that the tensile load induces failure in the remainder of the material. Figure 3. A detailed diagram of the blow-off door mechanism has been redacted for International Traffic in Arms Regulations (ITAR) compliance. Although the Heyne mission failed to capture camera imagery at 120 km altitude from its exoatmospheric experiment section, the JPL payload did succeed in capturing the requisite descent imagery. References: quot41.087\/Heyne Terrier-Orion Anomaly Investigation Board Final Report,quot NASA Sounding Rocket Program Office, May 10, 2011. Donald R. Sevilla, e-mail with subject quotRe: TRaiNED AIB Final Report - Bolt Cutter Failure,\u201d July 7, 2011. \u201cMate\/Demate, Verify, and Document Connectors One-at-a-Time,quot NASA Lesson Learned No. 1619, NASA Engineering Network, August 8, 2005. Portions of the following text have been redacted, as indicated, for ITAR compliance. quotU.S. Personsquot may obtain a copy of the complete lesson learned by contacting the JPL Office of the Chief Engineer (David Oberhettinger at davido@nasa.gov).","Lesson ID":6796}
{"Driving Event":"The Orbiting Carbon Observatory (OCO), an Earth orbiting satellite mission managed by the NASA\/Caltech Jet Propulsion Laboratory (JPL), was designed to make precise, time-dependent, global measurements of atmospheric carbon dioxide (CO2). The instrument, intended to detect CO2 from orbit, employed three channel-specific spectrometers. During assembly of the OCO Optical Bench Assembly (OBA) at JPL (Figure 1), four spectrometer lenses designed to image the strong CO2 channel were bonded into mounting rings. Following a thermal-vacuum bake-out procedure performed to complete outgassing of the silicone-based quotRTVquot bonding material, visible contamination was observed on the lenses. Probable sources of the contamination included excessive curing agent in the RTV, use of a lens cleaning solvent containing aliphatic hydrocarbons and esters, use of plastic lens cases, use of gloves that had not been pre-cleaned, and parts handling procedures. The impact of the lens contamination was minimal due to the performance characteristics of the instrument, but migration of the contamination to certain focal plane components would have had a major or catastrophic impact on the OCO mission. Figure 1. Assembled OCO optical bench (The telescope aperture is covered by the red cover on the right. The flight detector assemblies attach to the three camera lens exit flanges at the middle left.) The silicone contamination was documented in the Problem Reporting System (Reference (1)). A detailed investigation was made of the contaminant species, and evaluations were made on the potential impacts to instrument performance. A Contamination Control Engineer was assigned to OCO, and a more thorough inspection and sampling program was implemented to monitor surface cleanliness and prevent further contamination. Other sources of OCO instrument component contamination (Reference (2) included: Particulates on a telescope barrel located on a clean room bench were traced to paper (an unapproved material for use on the barrel) used to wrap painted parts. Use of a silicone adhesive tape (another restricted material) to wrap a relay case during surface preparations prior to bonding, which caused high levels of silicone contamination of the relay. Large surfaces of the OBA were contaminated with molybdenum disulfide grease resulting from the failure to change gloves after lubricating screws and before handling the OBA. Significant labor was required in each case to identify the contamination source and clean the contaminated spaceflight hardware. The inspection and sampling activities implemented following the lens contamination event supported recovery and corrective actions prior to further hardware integration, and they mitigated potential cost and schedule impacts from the lens contamination. The incidents indicated unfamiliarity with general contamination control practices-- and a lack of awareness of project-specific contamination sources, hardware sensitivities, and risks-- among project personnel. References: \u201cOCO Instrument Strong CO2 Spectrometer Lens Contamination,\u201d JPL Problem\/Failure Report No. 4891, August 1, 2006. P.J. Guske, \u201cOCO (Orbiting Carbon Observatory) Project Lessons Learned Document (Final),\u201d JPL Document No. D-26172, July 7, 2009, Paragraph 3.8.1.","Lesson ID":6716}
{"Driving Event":"During the Space Transportation System (STS)-133 post-drain walk-down following the November 5, 2010 scrubbed launch attempt, an anomalous thermal protection system (TPS) crack was observed in the External Tank (ET)-137 insulation, adjacent to the intertank (IT) to liquid oxygen (LOX) tank flange. The TPS crack was subsequently determined to be the result of a structural failure of the underlying aluminum-lithium (Al-Li) 2090-T83 stringer. Later inspections detected a total of five cracked stringers. The investigation determined that the cracks originated along the bottom of the stringer feet through combined failure in multiple linked initiation locations. Failed stringer fractographic analysis indicated no pre-existing material defects, although a wavy refractive pattern that was not a surface contour condition was noted on the two lots of stringers prone to cracking. Other lots of stringers did not have the wavy pattern. The investigation determined that the material had low fracture toughness due to a microstructure evolution process, termed recovery, which occurred prior to stringer processing (i.e., material processes were changed prior to stringer processing). Recovery in the two affected lots resulted in material with higher yield and ultimate stresses, and lower fracture toughness (i.e., more brittle). The time of stringer\/TPS crack occurrence suggested a thermally induced load contribution to the structural failure. The stringers were subject to assembly strains caused by initial installation on the IT panel as well as other mechanical events. Transient thermal loading occurs as the LOX tank fills prior to launch. All configurations tests exhibited high plastic hoop strains in the stringer feet due to the transient thermal loading, especially at the first three fastener locations. Cryogenic shrinkage during tanking causes rotation of the IT flange radially inward, which loads the IT stringer feet. Analysis suggests that the strain levels in the first three fasteners\/bolt holes remain sufficiently high that a failure may occur. The bounding loading event is thermal loading. Analysis confirmed that installation of radius blocks over fasteners 2 through 7 reduces the peak hoop strain for the operational loading events, but that they have a minimal effect on the assembly strain at fastener 1. During the investigation, the history of the implementation of Al-Li use in the ET was evaluated, including selection criteria, programmatic goals, and technical assessment review. Schedule and budget concerns drove the ET Project to seek technical ways to significantly reduce the weight of the ET early in the Space Shuttle Program (SSP). In 1993, the ET Project was tasked with reducing ET weight by 10% in 48 months or less. Earlier, the weight was reduced from the Standard Weight Tank (SWT) to the Light Weight Tank (LWT; 1983-1998) by eliminating the paint, redesigning the feed system, and reducing margin of safety requirements on structural and load bearing parts wherever possible (i.e., Factor of Safety was reduced from 1.4 to 1.25 where possible). For the Super Light Weight Tank (SLWT), the primary methods for reducing weight include use of Al-Li, a lighter, stronger replacement for aluminum-copper alloys, new welding techniques, and an orthogrid structure. Although Al-Li 2195 material cost 2 1\/2 times that of the Al-Cu 2219 alloy used in the LWT, the weight savings were significant enough to justify the replacement. In addition, some areas of the ET that had low Factors of Safety were able to be modified to increase margins because of overall weight savings. The IT design verification included a combination of tests and analyses. To mitigate potential tank buckling concerns, designers maintained the structural ringframe stiffness, thrust panel material, and solid rocket booster (SRB) crossbeam design. Many of the subsystems, such as the skin stringer\/joint interface, the beaded web, and the thrust panel, were tested to failure. The skin stringer\/joint was improved to meet buckling prevention requirements. Analytical model verification was performed by comparing predicted structural load conditions to load conditions measured during test programs and by comparing the output prediction of the structural model with the output of other independent analytical models. The IT skin\/stringer\/foam interaction was never measured or modeled in the assembled state. Residual assembly stresses were never measured or modeled prior to STS-133 investigation. The lack of skin\/surface metal\/foam models was noted during the post-STS-107 accident investigation (2003-2004). For the SLWT, the risks for unintended consequences were seen as stemming from the risk of using a material, a process, and a structural design that had never flown in a launch vehicle. Confidence in the rationale against fracture issues was increased by reliance on dye penetrant nondestructive evaluation (NDE) to detect flaws. Dye penetrant NDE flaw detection was not conducted on assembled IT stringers or after TPS application. The components considered critical on the ET were the LOX tank, the LH2 tank, the feedlines and joints, the crossbeam, and buckling prevention. As was observed during the STS-107 investigation, the skin and skin\/foam interfaces were of less concern although interactions between all components led to unintended consequences.","Lesson ID":6816}
{"Driving Event":"The most current document was difficult to locate in Windchill. Windchill was slow and crashed frequently. This resulted in wasted resources and the risk of working to the wrong version of information.","Lesson ID":4579}
{"Driving Event":"The Driving Event for this effort was the requirement to track and manage all products related to the Technical Baseline within Windchill. The Technical Baseline serves as a snapshot in time of those items in the Technical Baseline. To meet the requirements of the Systems Engineering and Integration (SE&I) Technical Baseline, the following steps were required: Create a technical baseline in the GOP Windchill Library Manage the data input by SE&I in the GOP DM Project Add products to a baseline in the GOP Library Roll the current baseline to the new baseline in the GOP Library Initiate review\/approval\/release of technical baseline in the GOP Data Management (DM) Library Each time the Technical Baseline was rolled to the next revision of the Baseline in Windchill, there was no automation for this effort. All documents that were part of the Technical Baseline (and not just those products that were revised or updated) had to be manually uploaded or transferred electronically to the new baseline within Windchill. This was extremely time consuming and inefficient. Documents had to be manually moved from the Project side of Windchill to the Data Management Library side of Windchill, one document at a time. Additionally, the Technical Baseline was revised by Management Directive (MD), which was also a manual process. MDs were issued for each revision to the Technical Baseline under Constellation, which required an update to the MD each time, and presentation and approval at the Project Review Board (PRB). Once approved, the MD was manually released and uploaded to the Baseline. The MD contained a list of all those products that were revised for that revision to the Baseline. For efficient management of the Systems Engineering and Integration (SE&I) Technical Baseline, an automated tool or an additional module integrated within Windchill is required to track and maintain the Technical Baseline and requirements","Lesson ID":4588}
{"Driving Event":"The CR Pipeline tool was used to prepare a CR Look Ahead Chart for the weekly Project Review Board (PRB), research documents and for tracking and statusing flow-down of documentation and upcoming CRs. The CR Look Ahead chart is used to help the KSC Ground Operations Project plan the assessments of upcoming Change Requests. There is no history (or retention record) on each CR in the pipeline tool (i.e., dates, Change Package Manager, CR withdrawals, etc.). The lack of proper tracking of CRs in the pipeline tool results in lack of accountability for CRs, inaccurate metrics, and wasted resources due to numerous emails for inquiries, phone calls, etc. to status the CRs. The pipeline tool does not properly support the change management function.","Lesson ID":4581}
{"Driving Event":"Given the lack of guidance from the Constellation Program in the form of an Audit and Verification Plan, there was a possibility that ambiguous direction from the Ground Operations Project would hinder the verification and successful configuration of audits such as a physical configuration audit or a functional configuration audit (to be replaced by DCR and Systems Acceptance Review).","Lesson ID":4582}
{"Driving Event":"Given the lack of a Configuration Status Accounting (CSA) tool established early in formulation, there was a possibility that the Ground Operations Project (GOP) would be hindered in its ability to effectively status and account for information and configuration. The lack of accurate information may result in faulty, inaccurate data reporting. NASA Policy requires that: The Configuration Management Plan (CMP) shall describe how information is released into the CSA System including Program\/Project\/Element authorization for release, and metadata required to solicit authorization. Identification of the current approved configuration documentation and identification number associated with each Configuration Item (CI) typically consisting of the following: Records and reports the status of proposed engineering changes from initiation to final approval and implementation. Records and reports the results of configuration audits to include the status and final disposition of identified discrepancies. Records and reports the status of all Change Requests that affect the configuration of a CI. Records and reports implementation status of authorized changes. Provides the traceability of all changes from the original baseline configuration documentation of each CI. Reports the effectivity and installation status of configuration changes to all CIs at all locations.","Lesson ID":4584}
{"Driving Event":"A Mission Operations System (MOS) is a ground-based control system that commands a spacecraft flight system and spacecraft\/ground communications as needed to obtain mission science and programmatic data, while managing mission resources such as the Deep Space Network (DSN). An MOS is composed of hardware, software, people, processes, and facilities designed and implemented for a specific spaceflight mission. In the 1980s, the NASA\/Caltech Jet Propulsion Laboratory (JPL) developed the Advanced Multi-Mission Operations System (AMMOS) that provides an MOS framework and functionality (Figure 1) that can be used for multiple deep space NASA missions by adapting it to the needs of different missions. With continuous AMMOS use from decade to decade, its MOS capabilities have continued to expand to meet the needs of new missions (see Figure 2). Figure 1. Typical decomposition of an MOS into functional elements, tools, and services, indicating elements that can be provided from the AMMOS. The desire by projects to maximize spacecraft and instrument capabilities may tempt them to develop unique MOS hardware and software instead of maximizing the use of AMMOS resources. However, use of a multi-mission MOS (MMOS) like AMMOS offers the opportunity for reduced development and operations costs. Almost all deep space (and some Earth orbital) missions make use of AMMOS tools and services (Figure 2) maintained by the JPL Multimission Ground Systems and Services Office (MGSS), although the extent of use varies. Table 1 illustrates the percentage of AMMOS software that was used by several JPL projects in developing their Ground Data System (GDS), the software and hardware elements of the MOS. Only 68 percent of Mars Exploration Rover's (MER's) GDS software was obtained from AMMOS because MER had unique rover surface navigation and control needs. In contrast, Dawn is a recent project with a non-planetary mission that was able to take advantage of increasing AMMOS maturity to make extensive use of it. In addition to the software development cost savings, an AMMOS-derived GDS may feature lower recurring operations costs and risk because many anomalies that would have occurred during flight operations have already been fixed and because personnel have gained prior experience using the system. AMMOS use also promises a shorter development cycle because AMMOS adaptation takes less time than development of a unique MOS. Figure 2. List of current MGSS customers (Reference (1)). The yellow highlighted projects are JPL-managed. For heavy AMMOS users, much of the project\u2019s MOS development cost may involve the cost of customizing AMMOS capabilities: it is mostly AMMOS hardware and software that needs to be customized by a project. The Gravity Recovery and Interior Laboratory (GRAIL) project was able to customize a GDS by adapting AMMOS software at minimal cost, whereas developing a unique GDS instead would have required development of up to 10 million source lines of new code (MSLOC) at a cost of at least ten-fold. Even with the maximum use of AMMOS capabilities, however, projects still need to develop some project-specific MOS elements or tools. For example, it would not be practical for AMMOS to supply instrument-specific science data analysis software because it would have to be so heavily customized to meet the needs of the particular instrument. The recent GRAIL (Reference (2)), Stardust\/NExT (New Exploration of Comet Tempel 1) (Reference (3)), and EPOXI (Extrasolar Planet Observation and Deep Impact Extended Investigation) projects were very successful in containing MOS development costs and experienced few performance problems during the mission because they tailored their MOS needs to the established AMMOS capabilities. Despite the cost, schedule, and risk mitigation benefits, adapting an MOS to a project presents some challenges. AMMOS must provide mission operations engineering tools and services that can support a wide and increasing range of deep space mission types (e.g., orbiters, landers, rovers, penetrators, balloons). Reference (4) provides an example of the complexity of the operations and science data return planning process for a Mars rover. Novel hardware on a spacecraft may necessitate operating software, tools, and processes that are not in the AMMOS inventory. However, the present AMMOS bears little resemblance to the AMMOS of the 1980s: with each additional spaceflight project it has served, AMMOS capabilities have expanded to allow a new project to select more AMMOS elements for adaptation to their MOS. Without AMMOS, it would cost NASA approximately an additional $300M over 10 years to design and implement an MOS for each project. References: Terry D. (Dave) Linick, quotNASA's Advanced Multimission Operations System (AMMOS),quot Presentation to the NASA Director of Science and Robotic Exploration, revised November 28, 2011. Charles E. Bell, quotGRAIL Project Lessons Learned (Initial Release),quot NASA Structure Management (NSM) No. 408256, October 7, 2011, Paragraph MOS-5. Don Sweetnam, NExT Lessons Learned Project Document, July 5, 2011, Paragraph GDS-4. quotManaging Rover-Orbiter Relay Link Prediction Variability,quot LLIS #1765, NASA Engineering Network, October 6, 2006. https:\/\/llis.nasa.gov\/lesson\/1765","Lesson ID":6657}
{"Driving Event":"The quality assurance program for mission software on a NASA spaceflight project typically includes software Verification and Validation (V&V), a process that assesses whether the software system meets specifications and requirements and fulfills its intended purpose. In addition, elements of mission software that are critical to safety and mission success may also be subjected to Independent Verification and Validation (IV&V). IV&V is performed by an organization that is not directly involved in the project. IV&V examines the system concept, requirements, design, coding, testing, and operation of software to identify software defects and related risks and to suggest improvements. Following the Space Shuttle Challenger disaster, a NASA Independent Verification and Validation Center was established in 1993 in Fairmont, West Virginia, to evaluate the integrity and quality of the software system development process and products. In 2011, the NASA\/Caltech Jet Propulsion Laboratory (JPL) performed an informal assessment of the actual benefits accrued to recent JPL missions from IV&V. In 2004, the Deep Impact project was the first JPL project to receive IV&V support from the NASA IV&V Center. IV&V of Deep Impact and subsequent JPL projects has been limited to the flight software (FSW) or a critical portion of the FSW. Performed in addition to the Verification & Validation (V&V) function performed solely by the project throughout software development, IV&V is intended to produce recommendations that augment V&V and add value to project development. However, IV&V does consume project resources--particularly the time of the Project Software Systems Engineer (PSSE), software managers, and cognizant engineers in providing project documentation and software artifacts, interfacing with the IV&V team, providing annual feedback to update the IV&V plan, resolving issues reported by the IV&V team, etc. Table 1 (Reference (1)) shows that both the level of NASA IV&V staffing and the level of JPL project staffing in support to the IV&V activity are not trivial. For the NASA IV&V staffing in the fifth column of Table 1, the peak IV&V workforce levels ranged from one-third to one-half of the peak JPL staffing for FSW development (Reference (2), p. 9). Because of the additional labor costs expended by the project in support of IV&V, it is important to determine whether the IV&V process produces benefits. These benefits may accrue from actual risk reduction in preparing flight or ground software products, or verification\/validation activity sponsored by NASA at no cost to the project that the project would not otherwise have supported. Flight Project Specifics IV&V Program Characteristics Project Actuals for Supporting IV&V Interface .Project.. Project Type Project <--> IV&V Interaction Model Summary of IV&V Findings (see key) IV&V FTE Staffing During Phases C & D Software Development Team PSSE (Estimated from Entry Into Phase B Until End of Phase D) .JUNO JPL managed; spacecraft bus supplied by contractor 10 instruments with software Contractor FSW Manager preferred direct interaction and integration of the IV&V team into the FSW team.First JPL project to provide IV&V with electronic access to the project's software documentation and code. Communicated: 188Accepted: 152Resolved: 150Quality of Results: 152\/188 (80%)8 - 10 250 Hours 0.1 FTE(1200 hours) .GRAIL JPL managed; spacecraft bus supplied by contractor 1 instrument with software PSSE handled most interactions with IV&V team. An (online JPL file sharing) IV&V \"drop box\" was used. Communicated: 256Accepted: 211Resolved: 211Quality of Results: 211\/265 (80%)8 - 10 400 Hours 0.33 FTE(2700 hours) .MSL JPL managed, with in-house development of Rover 9 instruments with software The PSSE handled some interactions with the IV&V team. Often intermediary role, directing IV&V to subject matter experts on the FSW or flight system team. An (online JPL file sharing) IV&V \"drop box\" was used. Communicated: 1130Accepted: 896Resolved: 829Quality of Results: 896\/1130 (79%) 13 - 15300 hours - FSW team; 400 hours - systems team 0.5 - 1.0 FTE(10,500 hours) Table 1. NASA IV&V staffing and JPL project support staffing for recent JPL projects as of Phase E, from Reference (2), p. 9 (MSL IV&V services are continuing, so the MSL values may change.) ...Key:.....Communicated - Includes IV&V issues in States: Project Accepts Risk, Not To Be Verified, Closed, To Be Verified, Withdrawn Accepted - Includes IV&V issues in States: Project Accepts Risk, Not To Be Verified, Closed, To Be Verified Resolved - Includes IV&V issues in States: Project Accepts Risk, Not To Be Verified, Closed Quality of Results - Ratio of Accepted to Communicated Recent JPL experience with IV&V support for the Mars Science Laboratory (MSL) project suggests that IV&V can bring about explicit FSW improvements. IV&V support to MSL was limited to Entry, Descent, and Landing (EDL) software, fault protection (FP) software, and surface mobility software. Specific examples of IV&V contributions to the MSL project (Reference (2)) include: Analysis of flow-down from the functional description documents (FDDs) to MSL FSW requirements, and then to testing: Project processed engineering change requests (ECRs) to bring documentation\/code into alignment. In most cases, the code was found to be correct, so IV&V inquired whether the wrong requirement had been tested. IV&V found cases where a deleted requirement was still supported in the code. Requirements-to-code tracing: IV&V discovered cases where the MSL code was implemented incorrectly. Fatal Event Verification Records (EVRs) were identified and traced to requirements per the project policy. Code (static) analysis: Spot-checked the interim work products of the MSL FSW development team using different tools. IV&V found uninitialized variables, unused variables, buffer overruns, and violations of coding standards. (This code analysis is duplicative of the current JPL FSW development process). The IV&V team developed a database that captured the MSL FP design and facilitated checking for consistency between the FP design and the FP documentation (including cross-checks for FP requirements, FP FDD, monitors, and responses) IV&V found many inconsistencies and errors where the same stimulus would map to a different system FP response. The project found the IV&V team\u2019s database very useful, and they may adopt it as an operations tool. Table 2 lists the 512 MSL IV&V Team findings on MSL fault protection (as of December 2011) across the range of mission phases\/domains. Phase\/DomainFunctional Description Document (FDD) Total LocalOnlySystem+ LocalSystem OnlyOther Cross-Cutting Power & Power\/Analog Module (PAM)7 214 Pyro1 1 Sequencing10 2521 Telecom8 341 Thermal135 130131 Time Definition & Checks10 721 Uplink and Command3 2 EDLEDL Actuators35 35 EDL Comm1 1 EDL Sensors11 11 DedicatedFaultProtection SW1553 Bus Off-Nominal 6 24 Intercomm4 3 1 Rover Compute Element (RCE)47 3827 Remote Electronics Unit (REU) Off-Nominal 14 104 Radio Science Beacon (RSB) Off-Nominal 11 3611 System Fault Protection (SFP)1 1 Wakeup & Shutdown 15 924 LCACruise, Attitude Control System (ACS), and Propulsion 16 151 Surface-General Actuators and Motor Controller (MC)50 50 Communication Behavior (CBM)2 11 Mobility, Vol. 129 29 Surface Attitude & Position (SAPP)8 8 Surface- Remote Science Dynamic Albedo of Neutrons (DAN)3 3 Malin Space Science Systems (MSSS) Imaging 10 10 Remote Sensing Mast (RSM)3 3 Surface- SampleScience Chemistry and Mineralogy instrument (CheMin) instrument 5 5 Collection and Handling for Interior Martian Rock Analysis (CHIMRA)8 8 Drill26 241 1 Robotic Arm512 43740296 Table 2. MSL IV&V fault protection analysis findings to date (Reference (2), p. 14) The MSL IV&V team checked over 3,000 flight software requirements duplicated in three sources, identifying several inconsistencies (Reference (3)). While the inconsistencies themselves did not represent serious discrepancies, the requirements-checking aided MSL\u2019s Certification of Flight Readiness (COFR) process. The PSSEs for the GRAIL, Juno, MSL, and SMAP projects met in August 2011 to discuss their experiences with NASA IV&V. Although they could not recall any mission-critical errors averted by IV&V, they concluded that IV&V support to JPL has resulted in valuable contributions to the projects without placing excessive demands on project resources. The IV&V teams have produced significant findings, such as: FSW discrepancies (e.g., both errors like MSL fatal events that that could cause a reset, and process deficiencies such as Juno interface control diagrams (ICDs) that were not properly traced and GRAIL requirements that were not properly tested), Design inconsistencies (e.g., FP responses to the same stimulus should not differ), Requirements-to-code tracing (i.e., identifying where the FSW code responds to a requirement), Missing or misapplied requirements in the requirements flow-down. (In Phases C and D of the Juno project, the IV&V team created tools for visualizing the requirements flow-down.), Violations of coding standards (e.g., using initialized variables, defining variables but not using them, exceeding buffer limits). The open dialog with the IV&V teams was very beneficial to the JPL projects. For example, there were cases where a technical issue memorandum (TIM) would have been written, except a five-minute discussion concluded that the issue did not represent a valid problem. The collaborative environment prevented a \"false positive.\" JPL\u2019s recent GRAIL, Juno, MSL, and SMAP project experience suggests that IV&V support can add value when well managed. It is important that the PSSE assist the IV&V team in focusing their efforts in areas that will best mitigate project risk. Rather than await formal reports, the project should schedule frequent meetings with the IV&V team to discuss potential TIMs. The IV&V team should be granted early access to draft artifacts, arrive at a process for handling \u201cobservations\u201d that are not formal findings, and triage TIMs to clarify which are mandatory for corrective action, rather than merely advisory. Less favorable outcomes are likely to result from refusing or limiting IV&V services, limiting interactions with IV&V to discussions about already submitted TIMs, withholding artifacts until they are fully mature, or treating all TIMs as \u201cmust fix\u201d regardless of their severity levels. These and other lessons learned from recent IV&V activities have been documented in newly released JPL procedures (Reference (3)). References: Margaret Smith, \u201cExperiences with IV&V Services on JPL Projects, Rev. 0,\u201d JPL DocID 78609, March 29, 2012 Dave Nichols and Margaret Smith, \u201cModernizing the Project\/IV&V Interface: How Projects Are Getting the Most Value from their IV&V Services, \u201d presented December 14, 2011. \u201cSupporting the Scoping and Execution of IV&V Services on a Project, Rev. 0,\u201d JPL Document No. DocID 78586, June 26, 2012. Steve Larson, \u201cAnalysis of Phoenix Anomalies and IV&V Findings Applied to the GRAIL Mission,\u201d 2012 IEEE Aerospace Conference, March 3-10, 2012.","Lesson ID":6656}
{"Driving Event":"In-House Build The Mars Science Laboratory (MSL) spacecraft is an extremely complex system that was designed and built by the NASA\/Caltech Jet Propulsion Laboratory (JPL) and is comprised of a Rover, Descent Stage (DS), Cruise Stage (CS), Backshell (BS), and Heatshield (HS). Prior to the stacking of these spacecraft vehicles for launch at the NASA Kennedy Space Center, a final mechanical walkdown of each vehicle was performed in August 2011 (Reference (1)) to identify workmanship discrepancies that would not be discernable after the vehicle had been stacked, including: Cabling: nicks, tight bend radii, routing over sharp edges, non-staked connectors, unsupported length, etc. Multi-Layer Insulation: torn, not fully closed, ungrounded, improperly secured for bellowing, adjacent to sharp edges, etc. Structural: loose items, inverted washers, presence of non-flight hardware or material (e.g., tape, debris), cracks, dings, delamination, chipping\/cracking paint, etc. Obstacles to Spacecraft Separation: lacing cord tied across a joint, defects in critical mating\/faying surfaces (cups\/cones), deployment\/separation envelopes, and potential hazards or snag points. Close Clearances: Identify any possible unknown close clearances. Paperwork Closeout and Vehicle Readiness: review the status of open items on inspection reports (IRs), assembly & inspection data sheets (AIDS), and procedures in the ATLO hardware build books; metrology, alignment, and electrical bonding measurements; close clearance measurements; final sampling for planetary protection and contamination control, etc. The objective of this detailed examination of the spaceflight hardware in its final configuration was to assess the overall readiness to proceed with the MSL launch from an quotas-builtquot hardware perspective. The mechanical walkdown was not intended as a design review or an opportunity to question the quotas-designedquot configuration. The walkdown participants included generalists and specialists (e.g., mechanical, cabling, thermal engineering, telecommunications engineers) from the hardware-delivering organizations. The intent was to include participants who could provide a fresh look at the hardware in the Assembly, Test, and Launch Operations (ATLO) configuration. The number of participants in the Rover (Figure 1), DS (Figure 2), CS, BS, and HS walkdowns was limited to eight generalists and from three to seven specialists for each vehicle in order to: Keep the hardware safe from inadvertent contact. Provide participants with unobstructed and complete access to the hardware. Allow participants ample opportunity to ask questions of the vehicle engineers and Quality Assurance (QA). Permit the ATLO team to fully capture the details of each finding. ........................ Figure 1. Configuration of the MSL Rover for the final mechanical walkdown Figure 2. Configuration of the MSL Descent Stage for the final mechanical walkdown The final mechanical walkdown for MSL took two days to complete. At the end of each day, the ATLO team met with the participants to ensure that their notes and lists of discrepancies were accurate. To ensure closed-loop resolution of the walkdown results, each finding was documented by the ATLO Vehicle Leads and ATLO Lead QA. Accepted findings were added to each vehicle's final IR and tracked to resolution. Reference (2) is an example status report for the MSL DS. Prior to MSL, JPL did not conduct formal final walkdowns of in-house builds. Also, JPL did not produce a formal walkdown package reporting pre-stack or pre-encapsulation mechanical discrepancies, subject to closed-loop resolution. Previous JPL projects relied only on interim inspections and walkthroughs conducted during ATLO. Although MSL also performed these interim inspections and walkthroughs during ATLO, the final MSL walkdowns discovered discrepancies such as the sharp edges and close clearances listed for the DS in Reference (2). Out-of-House Build For out-of-house builds performed for JPL, like the Nuclear Spectroscopic Telescope Array (NuSTAR) project, the system contractor is responsible for vehicle readiness and paperwork closeout. To gain greater JPL project visibility into contractor preparations for spacecraft integration, an additional independent assessment step may be useful. Based on experience gained with the MSL walkdown process, walkdowns of the NuSTAR spacecraft (Figure 3) were performed by JPL during final integration at the contractor facility and at the Vandenberg Air Force Base launch vehicle integration site. Since these final walkdowns took place after NuSTAR was assembled (i.e. after the Optics Bench, Focal Plane Bench, and Bus were mated), the objective was limited to ensuring that the spacecraft was properly closed out for launch including its readiness to mate with the launch vehicle. This was accomplished by thorough inspections of the spacecraft exterior surfaces, and by randomly selected spot reviews of closeout procedures and processes. Unlike MSL, the independent final walkdown process did not include responsibility for implementation of corrective action on the walkdown findings. Figure 3. Final configuration of the NuSTAR spacecraft Although the final walkdowns of this out-of-house build were less comprehensive (i.e., scope, duration, and number of participants) than the in-house MSL project's, the independent process produced some significant findings and observations that were documented in a report (Reference (3). References: Ben Thoma, MSL Assembly, Test, and Launch Operations: Final Mechanical Walkdowns, August 25, 2011. Mark Yerdon, Descent Stage Walkdown (PHSF\/KSC August 30, 2011) report, updated September 29, 2011. Ben Thoma, Report on Final Independent Walkdowns of the NuSTAR Spacecraft, JPL IOM 352M-BLT-1201, February 27, 2012. Ben Thoma, et al, MSL Assembly, Test, and Launch Operations: Paper Closeout Status & Vehicle Readiness Rover, August 21, 2011. Ben Thoma, et al, MSL Assembly, Test, and Launch Operations: Paper Closeout Status & Vehicle Readiness Descent Stage, August 30, 2011.","Lesson ID":6636}
{"Driving Event":"While the ground systems were being designed for Constellation, the ground operations contractor was initially tasked with generating Logistics Support Analyses (LSAs) for the new systems. Unfortunately, the ground operations contractor was not able to obtain the design data necessary to generate LSAs in a timely manner because of a conflict of interest between the ground operations contract and the design contract.","Lesson ID":4881}
{"Driving Event":"Ground Operations Project (GOP) Logistics performed an integrated logistics assessment prior to the GOP Critical Design Review. Many of the questions asked in the assessment were about disciplines that affect logistics, but for which Logistics is not directly responsible. The assessment would have been easier to perform, and would have yielded more accurate findings, if responsible representatives of those other disciplines had participated.","Lesson ID":4896}
{"Driving Event":"The sparing methodology for the Constellation Ground Operations Project (GOP) did not have a complete provisioning plan or other potential cost savings features that a more comprehensive analysis-based process would provide. This wasted resources, increased costs, impacted schedule, and resulted in unnecessary procurements. At times, spares were ordered that were unnecessary because the expected operational life of the equipment exceeded the period for which provisioning was done. At other times, designs were changed last minute which resulted in the wrong spares being ordered, based on outdated data. A proper provisioning plan would ensure closed loop tracking encompassing all design changes. Conversely, development spares are typically identified when Logistics Support Analyses (LSAs) are performed at the subsystem level. Sometimes, procurements were made for a subsystem before an LSA was performed. These parts, procured too early in the design, became unnecessary and available resources were underutilized and wasteful.","Lesson ID":4936}
{"Driving Event":"The recommendations that follow are relative to ARPCS processing problems. At the start of the Shuttle Program, certification for composite overwrapped pressure vessels (COPVs) was based on an age life\u2014tanks assumed leak before burst, and reliability assumed to be greater than 0.9999 (less than 1 in 10,000 failures). The Johnson Space Center (JSC) initiated a test program to verify age on Kevlar overwrap. In 2004-2005, mid-life re-certification was performed. The NASA Engineering and Safety Center (NESC) found errors in the calculation of the stress ratio based on the Lawrence Livermore National Laboratory\u2019s (LLNL) COPV test program. In 2005-2006, a study to assess true reliability of COPVs in the Orbiter fleet began. Space Shuttle Columbia\u2019s tanks (found intact) were dissected, inspected, and tested to gain data points. White Sands Test Facility (WSTF) performed an accelerated life test on a 40-inch Orbital Maneuvering System (OMS) tank deemed to be the worst in the fleet. In 1989-1990, flow sensor problems (biased, drifting, failed sensors) in O2\/N2 flowmeters became more evident. In the early 2000s, approximately 50 percent of the sensors were unreliable.","Lesson ID":6456}
{"Driving Event":"System Thermal Test (STT) of the Mars Science Laboratory (MSL) rover was conducted during Assembly, Test, and Launch Operations (ATLO) at the NASA\/Caltech Jet Propulsion Laboratory (JPL) in March 2011. One of the components tested during this system-level, low temperature, low pressure test is the percussive drill at the end of the MSL Robotic Arm (RA), located at the front of the rover and used to take rock samples on Mars. This is a complex mechanism, with three cold-sensitive actuators in the drill, another five in the RA, and a total of sixteen in the Sample Acquisition\/Sample Processing and Handling (SA\/SPaH) subsystem. One objective of the STT is to verify at the operational temperature, by means of a Drill Force Transducer, the calibrated force applied by the RA against the drill bit. The force is verified during the test by a load cell (Figure 1) embedded in a ground support equipment (GSE) preload plate (Figure 2) that is integrated into the rover STT GSE (Figure 3). ............................ Figure 1. Load cell (i.e., single-axis force sensor) embedded in the (GSE) RA Preload Plate Assembly Figure 2. Fully assembled RA Preload Plate Assembly mounted on the STT support frame (white GSE test fixture) Figure 3. Full view of the MSL rover and the RA Preload Plate Assembly, both mounted on the rover STT support frame (white GSE test fixture) in the test chamber During the test, the RA was commanded to apply an increasing preload, in increments of 50 N, to 300 N. However, the load cell embedded in the preload plate did not register an increase in force. (Prior to delivery to ATLO, the load cell had been calibrated and its functionality verified.) The proximate cause of the test failure was the incorrect connection of the AC power leads to the amplifier unit supplied with the load cell (Reference (1)). This occurred during ATLO integration of the STT electrical ground support equipment (EGSE) hardware, and it resulted in no power being sent to the load cell. The root cause was inadequate instructions and procedures for unit assembly prior to STT. A contributing cause was that the GSE load cell functionality was not adequately verified prior to starting STT. Specifically, a step to verify the load cell was performed after it was integrated into the STT GSE in the test chamber, but the data obtained during this verification was erroneously interpreted to conclude that the load cell worked. The verification of the Drill Force Transducer at temperature was accomplished by force measurements, using the deflection of the Drill Bit Box (given its known spring constant) and the gravity vector on the drill as the turret rotated. References: quotPreload plate single axis force sensor giving erroneous readings during STT,quot JPL Problem\/Failure Report No. 48193, March 21, 2011.","Lesson ID":6696}
{"Driving Event":"Several issues have arisen where documents that were not under Level II control (i.e. Shuttle Operational Data Book, etc) were considered official documents that housed important information for analysis and flight rule calls. In addition, changes made at the element levels that impacted other elements or Level II performance were not updated in appropriate documents as the changes were not known to be of an impact to other elements.","Lesson ID":6076}
{"Driving Event":"On the day of the incident, two Orbiter mid-body technicians were tasked to remove SP1 S\/N 1003 from its test fixture (called an L-Bracket) and stow it into a shipping container for movement to another part of the Orbiter mid-body. After rotating the sensor and its mounting base several times while attempting to find the proper orientation in the container, one of the technicians noticed a small piece of the sensor, later identified as a rotation stop, lying in the bottom of the container. The technicians notified their supervisor who, in-turn, notified the OPF-3 Bay Manager and USA Safety Management of the broken stop. Figure 1: SP1 Transport Container Showing Foam That Was Removed The technicians that originally removed the SP1 and installed it on the L-Bracket removed the foam from the container. As a result of inadequate direction in the procedure, the technicians on first shift, perceived the need to remove the foam from the container to act as a support to prevent toppling of the SP1. The foam was never properly replaced into the container. The two technicians tasked with replacing the SP1 into the shipping container, having never seen the SP1 in the container, were unaware how the foam and camera should be oriented. The Work Authorization Document (WAD) provided no insight to its proper orientation.","Lesson ID":5957}
{"Driving Event":"A trade study to evaluate closeout for vehicle ordnance access while in the VAB was approved by the Operations Control Panel\/Program Review Board (OCP\/PRB).","Lesson ID":5183}
{"Driving Event":"During the post-flight reconstruction of STS-133, it was observed that the calculated aerodynamic heating exceeded the design environments for several body points on the external tank and the orbiter during second stage flight. It was determined that there had been a software error in the rarefied gas heating model used during certification that resulted in the aerodynamic heating being understated for off-nominal vehicle attitudes. The aerodynamic heating environments were updated for these vehicle elements for subsequent flights.","Lesson ID":6342}
{"Driving Event":"The Shuttle program\u2019s original specification was that all flight hardware was to be rated to survive a 200k amp lightning strike. When it came to certification testing, the flight elements applied for and were granted waivers to these requirements. It\u2019s unclear whether they would have failed the certification testing or it was too expensive to accomplish. No testing of any kind was done. Thereafter, during the major portion of the vehicles operational life, there were no fact based criteria for accessing the vehicle\u2019s flight worthiness in the wake of a direct or nearby lightning strike.Columbia Accident Investigation Board (CAIB) Report","Lesson ID":4416}
{"Driving Event":"In the specific discipline area, the project office contracted with a prime contractor to produce the necessary engineering analysis reports to verify that the hardware met the government furnished equipment (GFE) requirements at a component level. The prime contractor subcontracted the work to another company, who then assigned it to their analysis group. The analysis group already had previous experience performing analysis on similar GFE, but for a different prime contractor. Prior to a major review, the prime contractor indicated their intention to verify subsystem safety requirements at the subsystem level rather than at the component level for this particular discipline. Verification compliance was to be summarized in a single report on a single Verification Data Requirements Sheet (VDRS). At that time, it was agreed that the subcontractor would document the GFE compliance status in a section of their analysis report, and that the prime contractor would include a reference to this report in their subsystem-level integrated compliance report. This arrangement would eliminate the need for an additional set of component VDRSs. When the subcontractor analysis report was released, the subcontractor and prime contractor failed to ensure that the subcontractor's work was consistent with the agreed upon verification plan. The documentation was submitted to NASA without the agreed-upon component-level verification compliance matrix. The failure to review the product at the subcontractor and prime contractor levels resulted in a significant cost and schedule risk that threatened to delay the mission because it was identified very late in the development lifecycle. The non-compliance was discovered during a major review by the government's insight\/oversight team during final verification. Expedited and unplanned last minute effort was required to mitigate the impact to the schedule, at an unplanned cost and repetition of technical analytical work to the program. It then became the government's responsibility to perform the compliance analysis. MSFC engineers identified several discrepancies with the report, primarily the use of material design allowable properties from unapproved sources, which had to be addressed under deadline by MSFC Engineering. When the prime contractor released the subsystem's Analysis Inspection Report, it did not include a section (or even placeholder) to document the GFE component compliance. Due to the time constraints, the MSFC component SE&I team was forced to initiate a separate set of VRDSs to document the component level verification and use the VRDSs to capture the compliance analysis that had not been included in the subcontractors report. Instead of reducing the level of effort and number of documents, the agreed-upon approach resulted in additional VRDSs that added to the total number that had to be generated, reviewed, and approved by engineering and the project office.","Lesson ID":6536}
{"Driving Event":"Originally there was a requirement for the forward dome of the liquid hydrogen (LH2) tank of the Ares I Upper Stage to support the weight of the people who needed to work on it during ground processing without pressurizing the dome. This requirement was changed, and the forward dome was no longer strong enough for people to work on top of the dome unless the LH2 tank was pressurized to 5 psi. This created a hazard that had to be mitigated by applying operational controls.","Lesson ID":5004}
{"Driving Event":"In the Constellation Program, a decision was made to capture safety risks using a risk management tool. This implementation of the tool was misleading for some people. They interpreted it as meaning that safety concerns were not being captured or assessed if those concerns had not been input into the risk management tool. This led to a duplication of effort with hazard\/safety analysis that performed the same function. In addition, safety risks that were captured with the risk management tool were often misclassified as either having zero safety consequences or being catastrophic; there were no middle gradations of risk using the risk management tool for safety risks.","Lesson ID":4958}
{"Driving Event":"In the Constellation Ground Operations Project, the Ares Launch Vehicle Division was responsible for interfacing, for understanding the launch vehicle design, and vehicle configuration. However, that information was not always consistent, and not always communicated effectively to the rest of the Ground Operations Projects (GOP).","Lesson ID":4977}
{"Driving Event":"The Constellation program opted out of using a ground station for primary communication; instead, choosing to communicate directly with TDRSS for prelaunch, launch, and ascent. Communications with TDRSS from the launch pad proved to be challenging. Some of the problems experienced were data latency, voice sync difficulties between primary communications and dissimilar voice, and closing the link with TDRSS while transmitting and receiving forward\/return link communications.","Lesson ID":5188}
{"Driving Event":"Because allocating requirements for ground processing subsystems for the Constellation Program involved many tiers of responsibility and overseeing organizations, it was difficult to trace requirements to their source and to synchronize the updating of requirements at these multiple levels. For example, as the Constellation Program evolved, it was necessary to generate multiple levels of requirements from the System Requirements Documents (SRDs), Element Requirements Documents (ERDs), and Subsystem Requirements Documents (SSRDs). This created redundant work and made the requirements difficult to manage.","Lesson ID":5201}
{"Driving Event":"On 23 October 2006 at approximately 9:50 a.m., an ironworker fell from a fixed ladder on the Level 41 north side of High Bay 4, knocking another ironworker from a 4-foot square lower platform into open space. The first ironworker (IW1) descended a fixed ladder (without the use of fall protection), and was standing at the side of the base of the ladder, with one foot on the platform and the other foot on a structural beam waiting for ironworker 2 (IW2). After descending the ladder, IW1 connected a fall protection lanyard to a pre-positioned rope grab that was attached to a 5\/8-inch diameter nylon rope vertical lifeline. IW2's personal fall protection lanyard was connected directly to a steel ladder climbing device cable attached to the ladder. Earlier that morning, another ironworker (IW3) decided the knot securing the lifeline to the ladder rung was insufficient, and added an additional half-hitch to the two existing knots. (It was undetermined whether the additional half-hitch prevented the knot from untying). As IW2 transitioned from the platform to the ladder, IW2's right hand became entangled in tethers attached to the fall protection harness preventing a firm grasp of the ladder rung. IW2's left hand was not yet in contact with the ladder but IW2 continued in motion away from the platform to the ladder. IW2 fell and impacted IW1 who was standing on the small door access platform approximately 12 feet below. As IW2 fell, IW1 alerted by the commotion, looked up, stepped forward and raised his arms. IW2 struck IW1 in the chest, knocking IW1 off the platform and beam. IW1's knee was injured in the impact with IW2, and IW2 sustained injuries as a result of impacting the fixed structure including the platform, which was where IW2 came to rest. IW1's fall was arrested by personal fall protection equipment, and IW1 was suspended 450+ feet above the VAB floor.","Lesson ID":5996}
{"Driving Event":"On June 7, 2010 the IP, an employee of a subcontractor, working at Building M6-1671\/Property Disposal Facility, located on Ransom Road, severed a portion of the right thumb when two high powered magnets collided with each other. At the time of the mishap, the Injured Person (IP) was in-checking material identified as scrap metal and decided to remove two magnets attached to a discarded prototype Multiple Gas Analyzer (MGA) chassis identified as scrap. The IP removed Magnet 1 and attached it to an industrial steel shelving unit for staging. The IP then detached Magnet 2. While attempting to stage Magnet 2 to the shelving unit, the magnets collided together severing a portion of the IP's right thumb at the first joint.","Lesson ID":5877}
{"Driving Event":"During the Constellation program, ground systems and flight hardware were developed in parallel because of restrictions in the program schedule and budget. Because the Constellation systems (Mission Systems, Orion, Ares, Ground Systems, EVA, etc.) were all in different stages of development at any point, maturing requirements were developed out of sequence, causing significant rework and delays.","Lesson ID":5196}
{"Driving Event":"When project integrators (PIs) were writing requirements and verification requirements (VRs) for Ground Systems in the Constellation Program, the review teams told the PIs how to write the requirements. However, there was a lack of consistency in the direction provided by the various review team members. As a result, the requirements were not always agreed upon by all stakeholders. Too much rewriting led to weeks or months of unnecessary rework, at a time when the PIs needed to devote more time to technical integration. Also, PIs were required to flow down a requirement even though they believed the requirement itself was unnecessary. In some cases, requirements were approved and then reopened for further discussion and additional rewrites at the request of a team member that had been absent during the original discussion on the disposition of the requirement.","Lesson ID":5199}
{"Driving Event":"The Constellation Program had a very aggressive development schedule, using a fast-track method. The vehicle design for the Ares I was being developed at the same time as the ground support equipment (GSE). Changes to the vehicle design were being made frequently. Because there was a program-to-project acceptance delay (needed for communication back and forth across Centers for approval and then on to the Program office), it took a long time for the changes to be added to the program baseline. During that time, the Mobile Launcher Team was working on an older configuration while the flight hardware designers were working to the latest updates. The result was unnecessary and costly redesign and rework by Ground Operations projects. For example: (1) The distance from the launch tower to the vehicle was uncertain. If the distance between the tower and the launch vehicle was too close, there would be a greater chance that the launch vehicle would hit the tower during liftoff. (2) Uncertainty in the areas where access needed to be provided to the flight vehicle resulted in the use of flexible stairs. (Permanent stairs would be designed at a later date.) This produced a less-than-desirable design for the stairs, involving multiple transitions to reach the platform level.","Lesson ID":5200}
{"Driving Event":"During the Constellation Program, even though modeling tools were used and many long discussions occurred during the development of vehicle and integrated ground systems, the operational assumptions made by the design center, and those of the ground operations organization, did not agree. Modeling tools provided value and were needed, but they did not help the engineers communicate with each other. Full-scale mock-ups were useful in evaluating problems with operations and design, or a combination of the two.","Lesson ID":5205}
{"Driving Event":"NPR 8715.3, NASA General Safety Program Requirements, defines \u201ccritical\u201d as \u201cA condition that may cause severe injury or occupational illness, or major property damage to facilities, systems, or flight hardware.\u201d However, in ground systems development during the Constellation Program, \u201ccritical\u201d was misinterpreted as meaning \u201cimportant,\u201d which drove a great deal of unnecessary work relating to risks involving operations, maintenance, testing, logistics, and other disciplines. In addition, it affected the quality of ground and flight safety products at the Project and Subsystem level, because it did not properly communicate risks related to hazardous conditions. The root cause of this difference stemmed from the interpretation of \u201ccritical\u201d to mean \u201cimportant.\u201d","Lesson ID":4966}
{"Driving Event":"The Program requirements, CxP 70000 Constellation Architecture Requirements Document (CARD), outlines guidance for several supportability design criteria instead of developing firm requirements \u2013 For example: Commonality\/Interchangeability requirements.","Lesson ID":5061}
{"Driving Event":"Ground Systems requirements documentation lacked Design Supportability Requirements.","Lesson ID":5057}
{"Driving Event":"During requirement status reporting, we were often asked if a requirement should be characterized as green, yellow, or red. This was always a challenge because the requirements language did not specify the required probability of success to characterize a requirement as being green or being met.","Lesson ID":5117}
{"Driving Event":"During the Space Shuttle Program, it was common to lose, or partially lose, a fill material used to fill gaps between thermal protection system tiles (Ames Gap fillers). Other common issues found post flight were charred filler bar locations and missing putty repairs used to fix chips in tiles. A post flight report was published, but one flight was never really compared to the previous ones, so these issues were not immediately apparent. Post flight reports and system review presentations were archived for historical data trending purposes. Figure 1: Charred Filler Bar Locations","Lesson ID":5476}
{"Driving Event":"The following are examples of occurrences that led to this lesson. The design of the Armadillo was supposedly baselined, but GOP personnel could not verify invitation to design reviews. Approximately 20 sets of the stabilization collar and sea anchor GSE are required to ensure worldwide rescue response capability. While expected to work closely with contractor GSE designers, KSC personnel had no authority to direct contractor activities without going through Orion Project Office at JSC. Due to the absence of a formal mechanism, an informal GSE end item requirements sheet review process was established to provide a means for NASA to review and comment to contractor-provided GSE items prior to design.","Lesson ID":5044}
{"Driving Event":"The Constellation Program identified the need to tailor security controls for implementation in Orion\/Ares flight communication systems. The resulting requirements, based on NIST 800-53 controls, were inserted in Program level requirements document and levied on system designers through the Constellation Architecture Requirements Document. This resulted in designers addressing only the allocated requirements rather than assessing the applicability of the entire standard.","Lesson ID":5099}
{"Driving Event":"During the Constellation Program, each of the Ground Systems elements generated its own requirements independently, resulting in inconsistent practices for writing and allocating requirements. In addition, the language used in requirements documents was not consistent among subsystems, nor were the requirements flow schemas. Valuable time was spent trying to reconcile these discrepancies. The Mobile Launch Element generated its own requirements independently, using its own terminology. This resulted in inconsistent handling of interfaces between subsystems in regard to generating, providing, or receiving data and signals. The Command, Control and Communications Element did not have a single parent requirement for some of its major subsystems (i.e., multiple requirements were related to key pieces of subsystem functionality).","Lesson ID":5197}
{"Driving Event":"When STS environments were reviewed and used, it became apparent that some body point numbers are 3 digits long, while others are 4, 5, or even 6 digits in length. No underlying system was employed throughout the life of the program. In a few instances, duplicate body point numbers were used for elements such as the Orbiter and the External Tank. This is highly undesirable because it could cause confusion, or even misapplication of inappropriate design environments. In the worst case, this could lead to a catastrophic event if not caught during the design process.","Lesson ID":6357}
{"Driving Event":"In the Space Shuttle Program, helium was used to purge the hydrogen fill and drain line to assist in removing liquid hydrogen from between the inboard and outboard fill and drain valves prior to launch. Testing at Marshall Space Flight Center (MSFC) has shown that helium vapor is present between these two valves prior to launch. In the event the inboard valve was to not close completely (or if the relief valve were to relieve), helium would be ingested into the engines. The Space Shuttle Main Engines have not been proven to tolerate helium ingestion above the specification level, and the concern is for a potential pump over-speed and catastrophic engine failure.","Lesson ID":6142}
{"Driving Event":"STS-114 external tank and subs were plagued with the loss of the wet\/dry indication of the low level cut off sensors. This caused many launches to be scrubbed. Thinking the problem was with the sensors themselves, great effort was spent on \u2018improving\u2019 them (e.g. swage connections, x-rays, etc.), but the problem kept recurring. Finally, after much investigation (and launch scrubs), the problem was isolated to the feed through connector in the bottom of the hydrogen tank. A design change to the connector changed the orientation and surface area involved between the mating sides. When the tank was filled, moist atmospheric air was drawn into the connector. The water in the air would freeze and as the connector chilled down and contracted, the electrical connection on one or more of the pins would be lost. After the tank was drained and it heated back up, the connection would be reestablished. After the problem was isolated to the feed thru connector, the Centaur Program told of how they had the same problem with their connector and how they fixed it by soldering the external connection, rather than relying on the mechanical connection alone.","Lesson ID":6144}
{"Driving Event":"In the Space Shuttle Program, hydrogen gas vented from the External Tank (ET) hydrogen tank to the facility flare stack through the ET Vent Arm System when the ET vent valve was opened. If hydrogen leaked at the ET\/ground interface, the system was designed so that hydrogen would leak into the purged Ground Umbilical Carrier Plate (GUCP) cavity, and then out into the atmosphere through the 5-inch slit in the \u2018refrigerator gasket\u2019. If the concentration in the GUCP cavity was above 40,000 ppm in the interface cavity, a Launch Commit Criteria (LCC) violation occurred, necessitating a launch scrub even though the ET vent valve was closed for tank pressurization.","Lesson ID":6150}
{"Driving Event":"In the Space Shuttle Program, three locations exist where helium is injected into hydrogen lines several feet from the dead headed end of the line. These locations were the External Tank (ET) Ground Umbilical Carrier Plate (GUCP) location, the hydrogen high point bleed location, and the hydrogen fill and drain line location. Testing at Marshall Space Flight Center (MSFC) has shown that not all the hydrogen vapor is removed from the fill and drain line during the terminal count sequence. Residual hydrogen in the fill and drain line during the terminal count down sequence could lead to a catastrophic failure and is a constraint to launch.","Lesson ID":6149}
{"Driving Event":"Initially, the Space Shuttle Orbiter aft hazardous gas grab bottles that were installed on the 50-1 and 50-2 doors were an afterthought as Criticality 3 instrumentation, yet the need for them never went away. Grab bottles provide an indication of gas leak in specific locations in the Orbiter during ascent. The facility hazardous gas detection system continuously monitors critical areas throughout the loading process. In comparison, the flight system only takes 6 \u2018snap shots\u2019 in time to \u201cgrab\u201d (obtain) a sample of the atmosphere in the aft of the Orbiter during powered ascent. The grab bottles remain in place until after the Orbiter returns from the mission and the bottles can be removed and taken to the lab to analyze the air samples. Obtaining the data post mission does not support the need to verify the quality of the air or presence of hazardous gas leakage in the Orbiter on orbit.","Lesson ID":6148}
{"Driving Event":"As part of routine Tanking operations for STS-128, Pre-Valve (PV12) closure could not be verified at the start of Liquid Hydrogen (LH2) Topping. The launch attempt was scrubbed. During the development a flight rationale, should the next attempt give similar results, it was determined that Gaseous Helium (GHe) used to inert the T-0 Umbilical during drain assist could become trapped in the fill and drain line prior to PV11 closure. This posed a potential for GHe entering the LH2 system if the PV12 relief valve opened. A helium bubble entering the engine system could unload the pump causing an overspeed condition a possible catastrophic failure.","Lesson ID":6146}
{"Driving Event":"Early in NASA's history, human rated launch vehicles were plagued by rocket engine\/structural dynamic coupling. The Mercury\/Atlas had mild pogo problems which did not effect human performance. The Gemini\/Titan had pogo problems that were mitigated by a pogo suppressor and Apollo\/Saturn had pogo instability around S-II end burn. The Space Shuttle avoided the pogo problems by base lining a pogo suppressor in the Space Shuttle Main Engine design. All Shuttle flights to date have been free of pogo instabilities.","Lesson ID":6356}
{"Driving Event":"Preparation and execution of CoNNeCT Comm Performance and TVAC System Level Testing involved Gore SpaceWire cable, one cable stopped functioning after the flight enclosure was shipped to the vibration lab in preparation for system level vibration testing. Another cable stopped functioning after it was installed in the flight hardware, however, it had passed all tests performed during fabrication.","Lesson ID":6416}
{"Driving Event":"On June 25, 2010, at 7:38 pm, the NASA\/Caltech Jet Propulsion Laboratory (JPL) experienced a total electrical power loss due to an operator error at a public utility substation that de-energized the 66kv operating bus (Reference (1)). The supplied power for the entire JPL Oak Grove campus was unavailable for approximately 3 minutes. The Lab-wide power outage was categorized as a Class D mishap because it impacted the safety of both personnel and flight assets, including: An employee was stranded in an elevator for approximately 1 hour, 55 minutes, until JPL Protective Services forcibly opened the elevator doors with emergency extraction equipment. This was a new building, and the JPL Fire Department did not have a key to this elevator due to the requirements of a maintenance and response contract with the elevator vendor. In several buildings, emergency lights, emergency generators, and\/or uninterruptable power supplies (UPSs) did not function as designed or planned. The affected buildings included mission-critical facilities currently engaged in testing spaceflight hardware. The failures were related to: Unreliable generators, Insufficient generator capacity, A defective relay and an improperly programmed switch for automatic switchover to generator power, A tripped UPS circuit breaker, Emergency lighting fixtures that had been removing during remodeling, Inoperable emergency lighting inverters, Emergency lighting inadequate to illuminate the egress path, and Insufficient capacity of an auxiliary air conditioning system. The procedures for timely incident reporting to JPL executive management were inadequate. Because the personnel list used for notifications by the Critical Hardware and Proximate Hazard System (CHAPHS) did not include JPL senior management, the JPL Deputy Director was not notified of the incident until the next morning. The incident caused no personnel injury or illness, and damage was limited to the estimated $16,000 cost for repair to the elevator (Figure 1). Figure 1. Forcible opening damaged the elevator Reference (1) identifies the root causes of the incident as a lack of robust preventive maintenance for many emergency systems, poor configuration management of emergency systems, and a failure to activate emergency notification. References: quotJPL Investigation of the Laboratory Power Outage,quot September 9, 2010. NFPA 101: Life Safety Code, National Fire Protection Association. quotLab Wide Power Outage,quot JPL Corrective Action Notice No. 1609, June 29, 2010.","Lesson ID":6396}
{"Driving Event":"National Security Presidential Directive (NSPD) 31, the U.S. Space Exploration Policy (USEP), directed NASA to retire the Space Shuttle in 2010 and to replace it with a new generation of space transportation systems for crew and cargo travel to the Moon, Mars, and beyond. Crew transportation to the International Space Station (ISS) was planned for no later than 2014, and the first crewed lunar mission was planned in the 2020 time frame. The project was driven by a desire to reduce the Nation\u2019s human spaceflight gap, as well as to begin work on the Ares V and Altair lunar lander as soon as possible. Further contributing to the project\u2019s sense of urgency was the need to rebuild the agency\u2019s capacity as the world\u2019s recognized leader in the development of launch systems. Safe, reliable, and cost-effective space transportation is a foundational piece of America\u2019s future in space, both strategic and tactical. The Ares Projects Office (APO) endeavored to deliver operational capabilities that supported the agency\u2019s responsibility to fulfill the USEP and to help ensure United States (U.S.) preeminence in space through assured access, as outlined in the U.S. Space Transportation Policy (January 2005) and as directed by the NASA Authorization Act of 2005 and the Fiscal Year (FY) 2006 Appropriations Act for NASA. The APO, located at NASA\u2019s Marshall Space Flight Center (MSFC), was chartered to provide the new Ares I crew launch vehicle (CLV) (Figure 1-2) and Ares V cargo launch vehicle (CaLV) space transportation system. The Ares management team developed an aggressive, multiyear plan and implemented a rigorous systems engineering approach in coordination with, and guided by, the Constellation Program (CxP) and the Exploration Systems Mission Directorate (ESMD). The APO actively employed knowledge management (KM) principles and functions throughout the project\u2019s life. Team members were both active learners and knowledge contributors. The formal KM guidelines were defined in the CxP 72027, APO Knowledge Management Plan. As the project faced termination, the knowledge capture (KC) activity became urgent and resulted in the creation of this report and associated knowledge activities. This document is the summation of the knowledge gleaned from extensive capture of lessons learned during the period of time from 2006 until spring of 2011, regarding processes, procedures, and activities that worked well and those that did not meet the expectations or requirements. No prime contractor lessons learned are addressed in this report.","Lesson ID":6377}
{"Driving Event":"The deservicing GSE at KSC is not portable. It cannot be used to support a contingency at a location other than KSC. If the crew module (CM) aborts to a remote location (e.g., the Indian Ocean), there is no planned GSE available to deservice the CM at that location. Without remote deservicing, the prolonged salt exposure during transportation to KSC could damage the connectors and render the CM incapable of being deserviced.","Lesson ID":5013}
{"Driving Event":"The NOAA-N Prime Search and Rescue Antenna (SRA) inadvertently deployed during a spacecraft rotation on April 14, 2007. This rotation was part of a normal operation to configure the spacecraft for additional antenna and the solar array boom deployments. A Turn Over Cart (TOC) is used to re-orient the spacecraft from vertical to horizontal, and allows for the axial rotation of the spacecraft when in the horizontal position. This axial rotation is sometimes referred to as a \u201crotisserie\u201d motion. An Operational Hazards Assessment (OHA) and Functional Failure Modes and Effects Analysis (FFMEA) were performed for this TOC, but that analysis is primarily focused on the design and load carrying capability of the fixture, without a broad assessment of various possible spacecraft configurations. The historical Integration and Test (I&T) sequence of events, going back to Television Infrared Operational Satellite (TIROS) N, was for the SRA to be deployed with the spacecraft vertical and removed prior to rotating the spacecraft to a horizontal orientation for other deployments. To accomplish this flow for the SRA, a procedure was run by which the antenna was temporarily \u201csoft\u201d stowed with lacing cord, before being more securely \u201chard\u201d temporarily stowed with a non-flight bolt and T-nut. The \u201chard\u201d stow operation required safe placement of multiple personnel so that the antenna could be held in a partially deployed position while pyrotechnic and other hardware was removed. This operation was accomplished with the use of a \u201cBig Joe\u201d lift, which allowed three people to work side by side on the antenna. Subsequent operations to remove the SRA from the spacecraft also required the use of this same lift device. It is important to note that when the procedure was generated, the intended use of the \u201csoft\u201d stow operation was too temporarily safe the SRA until a more secure \u201chard\u201d stow could be effected, ultimately leading to the SRA being removed before the spacecraft was re-oriented to horizontal. Sometime in 2002, before similar I&T operations were run for NOAA N-Prime, Lockheed Martin lost the use of the \u201cBig Joe\u201d lift device. SRA stow and removal operations were now limited by the use of the \u201cMarklift\u201d device, which could only accommodate one person on its work platform. This change directly affected practical workflow as it pertained to deployment testing. In December of 2002, following successful deployment of the SRA, the antenna was \u201csoft\u201d stowed using lacing cord. This operation was done in accordance with the existing SRA procedure and prior experience. The \u201chard\u201d stow operation was \u201cN\/A\u2019ed\u201d in the procedure. This is permitted by the project, as the Certified Test Conductor (CTC) is authorized to make modifications to the procedures (procedural note: \u201cper CTC direction, sections of this procedure may be performed out of order as required\"). The spacecraft was then rotated to a horizontal position using the turnover cart, a position which allowed the personnel access required to remove the SRA. The SRA, however, was not removed. The plan was to continue with deployment testing of the VRA, and the UDA, which required a rotisserie rotation of the spacecraft while in the horizontal position. Doing the deployments in this sequence offered schedule efficiencies. After all deployment testing was complete, the VRA, UDA and SRA were removed. The lacing cord held, and this new sequence became the new baseline. This new operational sequence was not originally intended when the lacing cord tie procedure was written, although changes in flow were permitted at the discretion of the CTC. In any case, we now know that the lacing cord tie only worked because the technician performing the operation doubled up the cord. He apparently did this at his own discretion, and the procedure was not specific enough to ensure this would be done in the future. The measured strength of the chord was found to be insufficient to retain the SRA unless it was doubled up.","Lesson ID":6256}
{"Driving Event":"Prior to the STS-124 launch, several issues with the MSBLS 60Hz Power cables at DFRC Runway 22R caused a smoldering fire and smoke at the MSBLS primary and backup shelters resulting in part failure and equipment damage, as well as loss of power to one of the MSBLS JR System. The failure resulted in smoke in the shelter, florescent light flickering and melting of the thermal breaker monitor panel. Per Safety Assurance Analysis document SAA-00199, subsequent failure of the other system could result in possible loss of life and\/or vehicle At the time of the failure, KSC placed several phone calls to different personnel and received slightly different versions of events; however, it was clear the primary cause (as understood at KSC) was maintenance of MSBLS power cable. Although the Operations and Maintenance responsibility is split between KSC and JSC, sustaining engineering for all equipment, regardless of location is done at KSC. KSC is required to report any MSBLS issues to the Launch Readiness Director (LRD), who is at KSC. Both DFRC and WSTF had subcontracts with other companies to perform maintenance and operation. On numerous occasions, when the teams in charge of O&M had issues, not enough information about system problems was provided in order for KSC to report the issue to the LRD or to provide a solution. The Risk Review Board concluded that during STS-124, a failure to maintain configuration control, follow engineering Work Authorization Documents (WADS), and provide proper problem reporting resulted in the miscommunication. Please see attached presentation from the Risk Review Board.","Lesson ID":3636}
{"Driving Event":"Mass spectrometer leak checks performed at Palmdale during Orbiter Maintenance Down Period for OV104 exhibited several inconsistencies, leading to an investigation of the leak check processes used. The investigation found that permeability ratios and response times for equipment used did not conform to the MF0001-003 specification requirements. Equipment flow rates were also out of limits. An inspection of the equipment and procedures found that filters were not being used in the test probes, leading to contamination and blockage in the units. Leak checks performed on components with known leakages did not give correct readings with the suspect units. As a result, mass spectrometer leak checks performed at Palmdale with the suspect units were re-performed at KSC.","Lesson ID":4256}
{"Driving Event":"The Orbiter FCPs generate electrical power for the spacecraft. The Orbiter\u2019s electrical power distribution system then provides electrical power back through the AC bus electrical system to the FCPs to operate their coolant and hydrogen\/water separator pumps. During the Orbiter\u2019s post landing de-servicing operations, the FCPs load share with ground electrical power until they are powered down and all of the vehicle\u2019s electrical power is supplied by the ground power system. During two separate Shuttle post landing servicing operations, an FCP was inadvertently removed from the electrical bus while the FCP was still operating, resulting in a loss of electrical power to the FCP\u2019s pumps. With the FCP\u2019s pumps no longer operating, the cooling system also went down. Because the FCPs generate significant heat during operation, the cooling system must be operating to avoid substantial damage to the hardware. In addition, if the temperature of the coolant exceeds approximately 400 \u00b0F, it will break down into extremely toxic compounds. Fortunately, in these two instances, power was restored before any hardware was damaged. And subsequent testing showed that the coolant had not reached a temperature high enough to break down into the dangerous compounds. However, these events took a substantial amount of time, effort, and money to resolve. They also presented a significant safety risk.","Lesson ID":4056}
{"Driving Event":"The flow meter leak check methods used to perform Quick Disconnect (QD) interface integrity verifications were found to be less that adequate to verify the acceptability of the hardware under test.","Lesson ID":4218}
{"Driving Event":"Industry-standard coating systems applied to launch support facilities did not perform well in the harsh environment of Kennedy Space Center. Because these facilities are in a hot and humid seaside zone and are covered with a large amount of acidic residue during each launch, industry-standard coatings cannot protect them for more than 4 or 5 years. This made corrosion control efforts very expensive and frequently interrupted the launch schedule. Without these efforts, it was possible to have system failures that could result in unsafe conditions and delay launches.","Lesson ID":4016}
{"Driving Event":"During PFMI operations on the International Space Station (ISS), power was temporarily lost to the booster heaters. Troubleshooting revealed loose pins in the LEMO connectors on the cables supplying power to the booster heaters.","Lesson ID":1917}
{"Driving Event":"On an experiment that operated on the International Space Station (ISS), in the Microgravity Science Glovebox, two ampoules cracked during crew removal from the polycarbonate tube. This was due to adherence of the Viton plug to the quartz ampoule.","Lesson ID":1918}
{"Driving Event":"Early in the definition of the Hinode instruments, interfaces were mandated to be in undesirable locations in the middle of a subsystem in the case of X-Ray Telescope (XRT). Phase A and Phase B are both critical times for a project. Decisions made during these phases of a project define the problems and risks that will be dealt with during the later phases. Lessons Learned need to be incorporated especially during this time. Finding information about difficulties encountered during Skylab in the case of the Narrowband Filter Imager (NFI) blocking filters and during Spacelab 2 in the case of the Tunable Filter (both in the Focal Plane Package) may have allowed the in-flight difficulties with these items to be avoided.","Lesson ID":2297}
{"Driving Event":"The filter wheel design used in the X-Ray Telescope (XRT) had been used successfully on previous missions, but other considerations resulted in the part of XRT in which the filter wheel resides being operated in the lower part of its temperature range. After launch of Hinode, it was soon learned that the design had never been used in this temperature range. Furthermore, the design and construction of the heritage subsystem was that of another company. When problems were experienced on-orbit, there was little, or no, in-house experience and knowledge relating to this design and its vagaries, and the subcontractor was reluctant to share information or spend time assisting in troubleshooting and problem solving.","Lesson ID":2298}
{"Driving Event":"During the manufacturing of an x-ray optic, the sub-contractor proposed to reuse existing metrology analytical software to evaluate the in-process mirror figure. Given the mission criticality and limited budget this approach appeared reasonable. Reuse of portions of the software resulted in new interfaces between the old software elements and the new elements to be developed for the specific optics being manufactured. Without the rigor of formal software development documentation, a units mismatch was programmed into the analysis resulting in the incorrect mirror figure being fabricated. This error was realized by the contractor prior to delivery of the optic however it resulted in an extensive late delivery and cost overrun.","Lesson ID":2158}
{"Driving Event":"Due to the rigorous requirements involved in processing a manned reusable spacecraft, line-replaceable units (LRUs) are removed, replaced, or inspected far more often than related parts on a standard aircraft. The fastener receptacles quickly become worn and are often difficult to access or replace. The two primary failures are galling and the wearing out of the secondary locking feature. It has been necessary to use Loctite on most of the window fasteners. In cases where a nut plate simply fails, it has been necessary to bond studs and to use an exterior bolt to secure the fastener.","Lesson ID":3259}
{"Driving Event":"In January 2010, a characterization test was performed at the NASA\/Caltech Jet Propulsion Laboratory (JPL) on the Mars Science Laboratory (MSL) Mobility Assembly (References (1) and (2)). The assembly was stored on a ground support equipment (GSE) Mobility Cart used for storage and transportation of this Mars rover flight hardware. The purpose of the test, using only one three-wheeled side of the rover suspension, was to move the bogie pivot through its full range of motion in order to verify bogie resolver functionality and obtain resolver calibration data. MSL has six wheels, each with its own motor (actuator). Like the previous Mars rovers, the MSL suspension connecting the drive wheels to the rover body employs a quotrocker-bogiequot design that allows the rover to drive over obstacles while keeping the rover body balanced. With no axles or springs in the suspension, the three wheels on each side of the rover are connected by rockers, bogies, and pivots that distribute the load over the terrain (Figure 1). Resolvers are assemblies that sense the position of the actuator output shafts and mobility pivots; they are monitored during driving to halt the vehicle if the resolver readings fail to stay within an expected range. Figure 1. Initial MSL test configuration with the hardware mounted on the Mobility Cart and the \u201csteering wheel\u201d MGSE installed. A \u201crocker-bogie\u201d design features a two-wheeled rocker arm on a passive pivot attached to a one-wheeled bogie. During rover driving, this design allows the terrain to lift one wheel vertically while the other two wheels remain in contact with the ground. The test (Figure 2) took place in the JPL Spacecraft Assembly Facility (SAF), which is well equipped for mechanical testing. An overhead crane was used to raise the aft rocker assembly high enough off of the GSE cart that the bogie can be moved through its full range of motion without making contact with the cart. During the lift, the cognizant engineer (CogE) for the Mobility Assembly was standing at the front of the test article at the rocker deploy pivot, and a flight hardware technician was standing at the back of the test article-- also at the rocker deploy pivot. An additional mobility engineer was on hand calling the lift. Additional flight hardware technicians were stationed at the bogie pivot, on the crane, at the crane control (as the lift operator), at the aft wheel of the test article, and at the forward wheel. A quality assurance engineer and a safety engineer were also present. Because the flight harness was new to testing, emphasis was placed on watching the harness during the lift to ensure that there were no pinch points and no over stressing of cables. Figure 2. Lift configuration with lifting sling attached to the flight hardware When a soft rubbing sound was heard during the lift, the hardware CogE halted the operation and investigated. The sound was attributed to a zip tie that secured the cable service loop at the rocker deploy pivot rubbing on the quotsteering wheelquot--a mechanical GSE (MGSE) clamshell ring attached to the Mobility Assembly support stand tower (Figure 3). The CogE directed the flight technicians to cut and remove the zip tie. The lift operation was continued, the sound was heard again, and the CogE stopped the lift. This time the sound was attributed to the flight harness because the harness had not been present in previous lifts. The many service loops were checked for the location of the sound, as were the rocker deploy pivot and the bogie pivot, with no visible evidence that anything was amiss. The lift was resumed. One of the technicians noticed that the load cell read ~330 lbs., and asked if that was expected. The CogE nodded, performed a quick calculation to determine that the load was over twice the nominal reading, and began to call a halt to the lift. Just then the hardware made a loud pop and the load cell reading decreased to 150 lbs. Searching for the location of the pop, the team discovered that a nut on the back side of the latch pin that goes through the aft fitting of the rocker deploy pivot interfered with the quotsteering wheelquot MGSE (Figure 4). The pop sound and the high load resulted from the nut embedding in the MGSE, and the load was released when this nut sheared off. .................... Figure 3. Position of latch pin relative to MGSE in the flight hardware test Figure 4. Test failure, in which the quotsteering wheelquot MGSE (red fitting) has sheared the latching bolt and jammed the nut and washer, which blocked initial attempts to lower the flight hardware back onto the Mobility Cart The hardware was repaired. Stress analysis indicated it was unlikely that damage occurred outside of the localized region where the latch pin and aft fitting were in contact during the loading event. The lack of a disciplined methodology to identify potential test interferences between the flight hardware and the MGSE was an error in test preparations that contributed to the mishap. Previous bogie resolver testing on the rover chassis using the development test model (DTM) of the vehicle had been performed without the \u201csteering wheel\u201d MGSE present. The location of the interference was not clearly visible during the flight hardware lift activity and would not have been noticed unless it was disclosed during test preparations. A second error in preparing for the test was that the maximum expected load cell reading was not calculated by the CogE prior to the activity and communicated to the lift team. References: \u201cMobility Rocker Deploy Pivot Hinge Pin Failure,\u201d JPL Problem\/Failure Report No. 15868, January 21, 2010. \u201cMSL Mobility Assembly Mishap Summary,\u201d January 25, 2010. J. Waydo, \u201cMobility Rocker Deploy Pivot: Path Forward,\u201d January 25, 2010. \u201cMSL Backshell Crane Incident,\u201d NASA Lesson Learned No. 5796, NASA Engineering Network, June 28, 2011. \u201cAquarius EGSE Shipping Mishap,\u201d NASA Lesson Learned No. 2456, NASA Engineering Network, February 16, 2010. \u201cNOAA-N Prime Mishap,\u201d NASA Lesson Learned No. 1580, NASA Engineering Network, January 18, 2005. \u201cGenesis Canister Lift Incident,\u201d NASA Lesson Learned No. 0914, NASA Engineering Network, July 20, 2000. \u201cMRO Articulation Keep-Out Zone Anomaly,\u201d NASA Lesson Learned No. 2044, NASA Engineering Network, April 7, 2009.","Lesson ID":6216}
{"Driving Event":"On Tuesday, 17 August 2010, a NASA fixed-price contractor was engaged in setting pilings using a hydraulic vibratory driver \/ extractor(HVDE) and a lattice boom mobile crane atop a barge in the Indian River on the west end of Jay Jay Bridge approximately 2.5 miles north of Titusville, Florida. Several pilings had already been successfully placed earlier that day. During crane movement to position the final piling, the load on the hook exceeded the crane's capacity and caused the crane to tip over. The load landed in approximately five feet of water along with the crane's boom tip. The lattice boom impacted materials on an adjacent barge and was severely damaged. As it tipped over, the crane slid off its wood matting and came to rest on its side with one crawler track and the operator's cab up in the air. The operator sustained only minor injuries and climbed out of the cab. No other personnel were injured.","Lesson ID":5836}
{"Driving Event":"When the Space Shuttle Orbiter is powered up, the avionics and payloads on board develop heat. This heat must be removed, or damage to the equipment occurs. In orbit, cooling is provided by an on-board Refrigerant 21 system chilled by radiators, exposed to space, which are located on the Orbiter\u2019s payload bay doors. When the vehicle is at the pad, the ECLSS Pad GCS removes the heat through an on-board vehicle ground support equipment (GSE) heat exchanger whenever the vehicle needs to be powered up. During launch, the ECLSS Pad GCS chills the vehicle\u2019s on-board loop low enough to provide a thermal capacitance for cooling until orbit is achieved. The GCS also is required for Orbiter power up at the Orbiter Processing Facilities (OPFs), Vehicle Assembly Building (VAB), the Shuttle Landing Facility (SLF)\/ Secondary Landing Site (SLS), and was used at Palmdale. In 1975, Rockwell developed the S70-0508 Ground Coolant Unit. Even with some modifications, the basic S70-0508 design (heat load capacity) was still oversized and could not handle the wide range of heat loads required for launch. In late 1985, the Lockheed Space Operations Contractor (LSOC) investigated S70-0508 problems and recommended interim fixes. From 1994-1996, LSOC designed, fabricated, and installed the enhanced new GCSs for the pads. In 1996, electrical modifications were designed that almost completely redesigned the circulation unit. In 2000-2001, United Space Alliance designed and delivered the Universal Coolant Transporter System (UCTS), which supported the post Columbia Shuttle landing at Dryden Flight Research Center in 2005. Figure 1: UTCS Supporting the STS-114 See attached ECLSS Ground Coolant Systems Overview Powerpoint presentation for initial S70-0508 modifications, new GCS features, and the complete history of this lesson.","Lesson ID":6116}
{"Driving Event":"The CxP Architecture Requirements Document (CARD) contained the top-level tier of requirements for the Constellation program. Among the requirements in the CARD were requirements dictating the flight rate for the Constellation vehicles: three Ares V flights and nine Ares I flights within one year. A phased approach for achieving this flight rate was considered before the start of the CxP program. However, this approach (Spiral Development) was abandoned and a decision was made to attain this flight rate from the beginning of the program. These goals proved to be overly aggressive and led to an effort to establish an unrealistic launch capability in the near term, which may have led to budget overruns for the program.","Lesson ID":5163}
{"Driving Event":"In the late 1980's early 1990's time frame there were multiple failures of convoluted metal bellows flex hoses used in various shuttle orbiter systems. Some of these systems were critical to launch, mission success and to the health and safety of the crew. Fortunately the failures occurred and were detected during ground processing and the discrepant hoses were replaced before flight. The video below discusses this situation. Click here to view a video discussion of this lesson. Click here to view the video transcript.","Lesson ID":5479}
{"Driving Event":"As part of the development of requirements for the Constellation Program, methods were also developed to verify that those requirements were met. Verification methods were assigned early in the project life cycle; and for the most part, they were determined by teams or individuals who were not part of the design or implementation team. Later, when these methods were addressed by the engineers responsible for implementing the subsystem design, those engineers preferred different methods or found the ones originally assigned to be impractical.","Lesson ID":5203}
{"Driving Event":"Electrodynamic shaker systems are used in spacecraft test facilities to simulate the vibration, shock, and other dynamic loads that spaceflight hardware will encounter during launch and mission operations. Because large shaker tables are capable of producing dynamic impulses at levels that can damage or destroy the flight hardware, the test equipment is set and checked carefully prior to the test. Actions taken to confirm that the shaker is calibrated and operating properly include: The scheduled test is first performed on a simulated test article that has a total mass approximating that of the actual test article. This allows the test conductor to confirm that there are no equipment defects, such as table stiction (Reference (1)) due to inadequate lubrication, and that the intended energy level is actually delivered to the mass simulator. Whenever the shaker is operated, the shaker controller software automatically initiates a self-check as a standard procedure. The self-check is intended to provide a strong enough signal to produce a reliable system check, but the self-check signal level is normally considered to be of insignificant strength compared to test levels. In July 2010, an open-loop sine burst test was conducted at the NASA\/Caltech Jet Propulsion Laboratory (JPL) to exercise the three flight interface points on the High Gain Antenna (HGA) for the Juno spacecraft (Reference (2)). Prior to running any tests on the flight hardware, the shaker (Figure 1) was checked out by running a sine sweep test and a sine burst test using a simple mass simulator for the antenna. The sine burst profiles from this simulation indicated that the shaker would generate a proper test. However, the self check step of the simulation was not discussed and its input levels to the flight hardware were not examined because the self check level is not considered to be a test parameter. Figure 1. A typical test configuration for the JPL large shaker, this photo depicts Mars Exploration Rover under test) The flight hardware HGA was installed on the shaker. Prior to conducting the sine burst test at various levels, the engineering team ran a low level sine sweep survey test that confirmed that the antenna responses matched the predictions and provided a measure of confidence in the health of the antenna and test configuration. When the first sine burst test was run, however, it was found that the self check that had immediately preceded the test had excited HGA responses beyond levels expected from the sine-burst test itself. Whereas the highest response expected on the HGA during the sine bust test was 33g, the self check generated ~67g. Subsequently, a detailed inspection of bond joints found a repairable 3-inch crack in the HGA (Figure 2) that may have been caused by the aberrant self check. Figure 2. Red arrow on the HGA points to the damage site JPL typically sets shaker self check levels to be relatively high for sine burst testing (as compared to sine sweep or random vibration testing) because of the need in open-loop testing to generate a strong signal that will provide a reliable self check. Sine burst testing involves subjecting each orthogonal axis of the test item to five-to-ten cycles of a sine wave whose peak is equivalent to the qualification load level. Since the test is intended to impart a quasi-static load to the test item, the test frequency must be below the fundamental resonant frequency of the test item. Such a \u201cstrong\u201d self check signal is not ordinarily considered hazardous because it is still rather low in amplitude compared to a typical test. However, sine burst is intended as a non-resonant test (all input well below the test article first resonance), whereas the self check is a ~5 second random burst from ~10 to 400 Hz and excites all the significant modes for most test articles. Following the Juno HGA incident, JPL changed its test procedures to require the test operator to verify that the input loads due to the self check levels are set lower than the lowest level associated with the hardware test. References: \u201cHigh Energy Spectroscopic Imager Test Mishap,\u201d NASA Lesson Learned No. 0903, NASA Engineering Network, May 10, 2000. \u201cJuno High Gain Antenna Sine Burst Test - System Self Check High Levels,\u201d JPL Problem\/Failure Report No. 28952, JPL Problem Reporting System, July 14, 2010.","Lesson ID":6196}
{"Driving Event":"During Mars Exploration Rover (MER-2) system-level thermal-vacuum (STT) test, it was discovered that one of two platinum resistance thermometers (PRTs) that provide temperature calibration for the Miniature Thermal Emission Spectrometer (MTES) had failed (Reference (1)). The PRTs had been installed by the contractor using a liberal amount of a rigid adhesive that transferred the thermal strain directly to the relatively brittle ceramic body of the PRT, overstressing it to failure. The mounting method had not been sujected to Package Qualification Verification (PQV), and subsequent coupon tests showed that the mounting method was consistent with failure within a few thermal cycles. One internal calibration target PRT on each of the Mars rovers was reworked by JPL using a ribbon of RTV, a configuration that passed PQV. (The others were not replaced because it would have invalidated the calibration.) Three months after landing on Mars, 6 internal and external calibration target PRTs on Rovers MER-1 and MER-2 that were bonded using the original method failed, but the 2 reworked PRTs subjected to PQV functioned properly. The loss of a temperature sensor on the MTES could result in the loss of a major portion of the rover's science return. In an unrelated incident during an STT of MER-1 (Reference (2)), the azimuth actuator PRT failed on the Instrument Deployment Device (IDD, or rover arm). This failure occurred shortly after the IDD heaters, used at the conclusion of the test to return the spacecraft to ambient temperature, were powered off. In this case, bonding adhesive likely migrated from under the PRT body and onto the lead wires (Figure 1), and the different coefficients of thermal expansion caused the contracting platinum wire to break and open at cold temperature. [insert figure and picture] Figure 1. PRT bonded to the actuator case with excessive epoxy adhesive, covering the leads (small wire loops indicated byarrow) Also, a PRT on the MER-2 Lander Petal Actuator failed in flight (Reference (3)). Thermal sensors provide vital information on spacecraft and instrument health, and are sometimes essential to subsystem function. A 1994 study (Reference (4)) documented a trend of in-flight failures of resistance thermal devices (RTDs) on JPL, Goddard Space Flight Center, and U.S. Air Force missions. Although electrostatic discharge and radiation also caused failures, design and implementation of the sensor mounting configuration was the probable cause of most failures. For installations lacking adequate strain relief, thermal dwell or cycling may induce different expansion and contraction rates in the (internal) sensing wire (~0.0006 inch diameter), or the lead wire (~0.012 inch diameter), versus the sensor body. Fracture of an RTD wire typically resulted in erratic readings (as the wire intermittently regained contact), followed by full scale temperature readings indicating an open circuit. References: (1) JPL Problem\/Failure Report No. Z79528, February 21, 2003 (2) JPL Problem\/Failure Report No. Z79691, March 5, 2003. (3) JPL Problem\/Failure Report No. Z81188, July 10, 2003 (4) D. Oberhettinger, \"NASA Unmanned Flight Anomaly Report: Investigation of Thermal Sensor Failures Aboard Unmanned Spacecraft\" (JPL D-11377), April 1994. Additional Key Words: Mini-TES; thermistor; workmanship error","Lesson ID":1581}
{"Driving Event":"Launch Complex LC-39A was being prepared for the launch of Space Shuttle mission STS-124. Part of the preparation included protecting bare metal components on Mobile Launch Platform (MLP) Pedestals from the corrosive effects of deluge water and acid produced from the burning solid rocket boosters. Structures personnel were tasked with performing this work, including applying a lubricant known as Molykote to exposed components, then wrapping them in plastic, and securing the plastic in place with vinyl tape. While performing this protective task on 20 May 2008, at approximately 10:00 a.m., a Structures Technician Lead, hereinafter referred to as STL, fell approximately eight (8) feet from a fixed ladder on MLP Pedestal 3, to the pad surface. During the fall, STL pushed away from the fixed ladder to clear ladder obstructions below. STL\u2019s feet landed approximately six (6) feet away from the base of the ladder, onto the Crawler-Transporter (CT) trackway with the left heel striking a two (2) inch high metal tab used to secure plywood sheets to the CT trackway.","Lesson ID":5916}
{"Driving Event":"During a weekly fire pump run for the 3 diesel fire pumps located in the VAB Utility Annex one of the low side pressure reducing valves failed to regulate the pressure from 330 psig to 140 \u00b1 10 psig. The LCC fire suppression water supply loop and all the subsequent wt pipe suppression systems directly connected to the building supply loop were over pressurized in excess of 300 psig. The over pressurization of the entire LCC fire suppression system caused numerous mechanical couplings to partially fail. 28 January 2010, six-inch fire suppression supply pipe coupling separated from elbow at coupling joint in LCC Stairwell 4R99C. Smaller leaks were in LCC firing rooms, hallways, and offices. 300-500 gallons of water released in VAB Low Bay from ruptured sight glass. Immediately prior to the pipe coupling separation, smaller leaks were observed in the LCC launch control firing rooms, as well as in the nearby Vehicle Assembly Building (VAB), Building K6-848. Although no critical electronic launch equipment was damaged, facility damages were estimated at over $706,000, and this does not include repair of LCC Firex system as it was a pre-existing condition, failure was imminent. Figure 1: LCC R Stairwell, Separated Pipe, Damage to wall during separation Figure 2 Pressure Reducing Valves in VAB Utility Annex Mezzanine","Lesson ID":5936}
{"Driving Event":"To meet requirements for clearance between the Ares I launch vehicle and the launch facility at liftoff, the design of the Ares I First Stage Aft Skirt Gaseous Nitrogen (GN2) umbilical was changed to a retractable flexhose design. The new flexhose design brought an increased risk for the umbilical to make recontact with the vehicle, which could be catastrophic. To decrease the risk of recontact, the GN2 and electrical umbilicals were combined into one.","Lesson ID":5003}
{"Driving Event":"A \u201cnear miss\u201d handling incident (Reference (1)) occurred during an Aeroshell Mass Properties Test conducted at the NASA Kennedy Space Center (KSC) on the Mars Science Laboratory (MSL) spacecraft Flight Backshell. Designed and built by the NASA\/Caltech Jet Propulsion Laboratory (JPL), the MSL spacecraft (Figure 1) consists of a Cruise Stage, an Entry, Descent, and Landing System that ejects the protective Backshell immediately following Parachute Descent and just prior to Powered Descent, and the Rover. > Figure 1. Major elements of the MSL spacecraft A crane was used for the installation of the Descent Stage Simulator (DSS) into the Backshell in preparation for a Backshell to Heatshield fit-check (see Figures 2 and 3). Just prior to the incident, the DSS had been secured to the Backshell, and the system test team prepared to unload the crane and remove the rigging. A \u201cHydra Set\u201d load positioning system was used to lower the crane hook until the lifting slings went slack and the load cell read zero. The lift conductor then gave the quotdown slowquot command. The quotdown slowquot command was repeated by the crane operator, but the crane operator commanded the crane to go quotup slow.quot The team observed the tautening of the lifting slings, and the \u201cStop\u201d command was immediately issued. The crane was stopped, and then lowered. It was noted that the load cell peaked at 4,400 lbs., and it appeared that two of the legs (jacks) of the Backshell Cart were lifted slightly off the floor. Figure 2. Backshell and Backshell Cart...................................................................................................................... [The topmost note (yellow font) in the photo states, \u201cCrane pulled in up direction (while BS was attached to cart).\u201d The second note states, \u201cEssentially, a large nut plate, Descent Stage Surrogate, is attached at the flight interfaces on the bottom of the BIP (Backshell Interface Plate).\u201d The third note (red font) states, \u201cBackshell is attached to Cart at nine (9) locations.\u201d The bottom note states, \u201cRed GSE fitting straddles flight interface. GSE fitting is attached into 4 inserts on bottom of BS (Backshell) on one side and to Backshell cart on the other.\u201d] Figure 3. Backshell and Descent Stage Simulator \/ Surrogate Suspended from Spacecraft Assembly and Rotation Fixture (SCARF) [The topmost note (yellow font) in the photo states, \u201c4X size #10 inserts in Backshell Stiffening Ring used to attach the Red GSE fitting that attaches the Backshell to the Cart.\u201d The lower note states, \u201cDescent Stage Surrogate in action. Used to attach the Backshell to our rotation fixture (SCARF) by attaching to our flight like GSE LVA (Launch Vehicle Adapter) Ring.\u201d] A loads analysis of the lift incident was performed. The area of concern was associated with the GSE fittings on the bottom of the Backshell where the structure connects to the Backshell Cart, and the area near these fittings. The structure was found to have been tested to loads that provided sufficient margin against the loads imparted during the incident. Analysis, inspections, and tap tests on the Backshell conducted by the Backshell manufacturer and JPL confirmed that the flight structure was not damaged. An assessment of the incident and the root cause, performed by the project and mission assurance representatives, concluded that the team was operating in accordance with JPL guidelines and practices: The lift lead provided correct direction to the crane operator. The lift lead\u2019s command was clearly heard by the crane operator, and the crane operator properly repeated back the command. Hand signals were used as a backup due to some ambient noise in the area. The operator had appropriate line-of-sight to the floor lead. The team was using a Hydra Set in accordance with JPL standards. The team was well rested: fatigue was not a factor. The JPL crane operator received onsite training and was certified on this crane. Appropriate hardware quality assurance and safety personnel were present and participating. This ground handling incident was attributed to the following factors: The crane operator inadvertently pushed the wrong button on the crane controller (Figures 4 and 5). Standard crane operation, as specified in Reference (2), does not provide any clear mechanism for avoiding hardware damage in the event of this type of operator error. ...................... Figure 4. KSC Payload Hazardous Servicing Facility (PHSF) crane control console. Unlike the standard pendant-type controls used at JPL, this console can be wheeled around the PHSF highbay. Figure 5. Close-up detail of hoist control from Figure 4. Some possible contributing causes were identified, but were not found to be directly correlated to the event: The crane controller panel does not have a physical separator between the up and down buttons. The crane operator had completed the required certification and training; however, he had somewhat less experience on this particular crane than other operators. References: quotBackshell Crane Lift Incident,quot JPL Problem\/Failure Report No. 48883, May 20, 2011. \u201cJPL Standard for Systems Safety (D-560), Rev. D,\u201d JPL DocID 34880, September 17, 2007. \u201cMSL ATLO Response to Backshell Lift Incident at KSC\/PHSF,\u201d JPL Memo IOM 352M-BLT-1013, May 25, 2011.","Lesson ID":5796}
{"Driving Event":"Throughout the Shuttle Program, it was often necessary to send entire FCPs back to the vendor for repair of defects or for removal and replacement operations. This was expensive and time-consuming, especially when other FCPs had to be obtained because none were available in Logistics. In some instances, KSC had to bring in vendor technicians to repair FCPs onsite.","Lesson ID":5477}
{"Driving Event":"Several years into the Shuttle Program, Extended Duration Operations (EDO) pallets were added in the Orbiter mid-body for some missions. These pallets included up to four additional tanks of liquid hydrogen and liquid oxygen to support the onboard fuel cells, which generate power on orbit. This added capacity made it possible to run fuel cells for missions lasting up to 28 days. (The original Shuttle design was for a maximum of 14 days on orbit.) On several occasions (and in all instances of pallet loading), full loading of the pallet was not achieved. The consensus at the time was that the vent tubing for the EDO pallets and Tank 3 was not sized to accommodate the increased flow from additional tanks during loading. The EDO pallets were not part of the original Shuttle design. Therefore, original fill and vent tubes were not sized to accommodate the added requirements. However, if the lines had been sized with excess capacity, this modification might have been better supported.","Lesson ID":4618}
{"Driving Event":"On 03\/11\/09, GH2 leaked at the GUCA (greater than 40,000 ppm, calculated to ~61,000 ppm) during the topping portion of loading resulted in a violation of Launch Commit Criteria (LCC) and ultimately, a scrub. IPR 119V-0070 (PR SS20-1-0106) was initiated. On 06\/12\/09, STS-127\u2019s first launch attempt was scrubbed because the GUCA was leaking approximately 61,000 ppm. The vent line was demated and the GUCA QD (s\/n 9) was removed and sent out for inspection and teardown. The inspection and the teardown of the QD did not reveal any anomalies. The GUCP (s\/n 8) was realigned and the pivot assemblies were modified to allow for better alignment as follows: 0.100quot was shaved from the inboard side the left-hand pivot assembly foot, and a 0.025quot shim was installed on the outboard side of the right-hand pivot assembly (previously modified). The replacement GUCA QD (s\/n 5) was installed (the QD was rebuilt according to the post-STS-119 inspections) and the vent line was connected. On 06\/15\/09, STS-127\u2019s second launch attempt was scrubbed because the GUCA was leaking approximately 41,700 ppm. On 11\/05\/10, during reduced fast fill to topping of the LH2 tank, a leak exceeding 40,000 ppm was detected on leak detectors 23 and 25, and IPR 133V-0068 was initiated. The following was performed for the GH2 leaks for STS-119 and STS-127. A detailed disassembly plan was developed for use in determining the root cause. Dimensions were recorded step by step, and measurements were taken with strain gages and LVDTs. Borescope inspections were performed and optical measurements were taken with a Faro arm to record configurations and changes during disassembly. As a result of the disassembly and knowledge gained from the STS-119 anomaly resolution team\u2019s investigation, the following enhancements were implemented: Used a concentricity tool to verify proper alignment of the GUCP. Used higher-tolerance alignment pins (0.485quot to 0.518quot diameter) to verify that concentricity is maintained. Manufactured customized pivot assembly feet to the ET-131 geometry. Installed washers on the pivot assembly pins to limit movement. Replaced the current one-piece flight seal with a two-piece seal (used previously on STS-116 and STS-117), which improves system compliance. The GUCA QD (s\/n 5) was removed and inspected, with nominal results. The QD\u2019s probe height and concentricity were verified and found to be within the specifications and experience base. The one-piece flight seal was removed and sent to MAF for analysis. The results were similar to those from previous analyses of leaking flight seals. It was decided to install the two-piece flight seal that had been used on STS-116 and STS-117. The purpose was to improve the compliance in the GUCA and vent line systems to the normal excursions experienced during processing and loading. The team developed a concentricity tool that attached to the bolt holes of the flight seal retainer before the flight seal and retainer are installed. The tool measures the GUCP\u2019s concentricity to the ETCA QD. In addition, higher-tolerance GUCP alignment pins (ranging in diameter from 0.485quot to 0.518quot) were manufactured to replace the single-dimensioned pins (0.485quot diameter). The higher-tolerance pins helped verify that the GUCP-to-ETCA QD concentricity was maintained throughout the processing of the GUCA. Use of the higher-tolerance alignment pins and the concentricity tool allowed the GUCP (s\/n 8) to be realigned. Once the GUCP was aligned, neither the standard pivot assemblies nor the modified pivot assemblies could be used because of the positioning of the ETCA hinge brackets on ET-131. Therefore, custom pivot assembly feet were manufactured and washers were installed on the ETCA hinge brackets to limit the movement of the pivot assembly feet. The measurements of the GUCP verified concentric alignment, and GUCA QD (s\/n 5) was reinstalled. Post-QD mate measurements of the GUCP verified that concentric alignment was maintained, and the vent line was connected. Investigating the GH2 leaks for the STS-133 mission, the team observed no anomalies in the vent line assembly but did observe that the GUCP had shifted since the final measurements taken before S0007. The plate was originally offset (0.049quot) to the 8 o\u2019clock position and had shifted toward the 7 to 8 o\u2019clock position. The first concentricity value after disassembly was 0.061quot to the 8 o\u2019clock position. After the GUCA QD was removed, measurement with a Faro arm revealed that the QD\u2019s probe had an offset of 0.024quot to the 6 o\u2019clock position as compared to the QD flange center. On the probe, a witness mark of the flight seal was observed. Two minor contamination marks were also observed outside of the sealing surface. Samples were taken for analysis, but the results were inconclusive. The GUCA QD (s\/n 4) was then disassembled and inspected but no anomalies were found. The flight seal underwent tactile and visual inspections by three independent, experienced individuals. The inspections found some circumferential deformation at the 7 to 9 o\u2019clock position. In addition, the gap of the seal edge to the retainer ring appeared smaller at the 7 to 9 o\u2019clock position. These observations reinforced the initial finding that the GUCP had shifted toward the 7 to 8 o\u2019clock position. GUCP (s\/n 2) was removed and 3-D scanned. The results indicated no anomalies, and the plate met all drawing requirements. The 3-D data was used in some later modeling effort. The flight seal was removed and sent to a KSC lab for analysis (Ref. \u2013 KSC-MSL-20 10-0349). Chemical and nondestructive examination revealed no anomalies that would have contributed to the leak. Magnified visual inspection of both pieces of the flight seal (PTFE and spring) revealed no anomalies. Chemical analysis of the wipes taken during tactile examination revealed unidentified organic materials. Debris analysis from the seal removal revealed a variety of small metallic and organic particles. Analysis of the swabs taken from the QD thin film found no organic constituents. After a review of these results with the engineering team, none were determined to contribute to the leak. Dimensional analysis of the PTFE jacket found one minor dimension to be slightly undersized. Analysis of the metallic spring found its outer thickness to be slightly undersized. Additional analysis determined this observation to be consistent around the spring, indicating that the spring was not out of round. The engineering team reviewed these results and determined all observations to be insignificant. The flight seal was then sent to MAF for further evaluation and possible destructive evaluation but was later determined to be of little value since nothing was discovered at the KSC lab and the team had developed a leak mitigation strategy. The flight sealing surfaces on the ETCA were inspected and found to have no anomalies. A new two-piece flight seal was installed. The findings from the investigations revealed that the GUCA QD probe offset needed to be considered when determining the optimum system concentricity. The initial STS-133 configuration that leaked during cryogenic loading had the GUCP offset to the 7 to 8 o\u2019clock direction and the GUCA QD offset to the 6 o\u2019clock position. This was compounded by the loads from the vent lines in the 7 to 8 o\u2019clock direction. These offsets by themselves in the GUCP and GUCA QD would not have been detrimental if the offsets had been smaller. With the initial GUCP offset of 0.049quot in the 8 o\u2019clock position and the GUCA QD of 0.024quot in the 6 o\u2019clock position, the resultant GUCA offset was 0.065quot in the 7:20 o\u2019clock direction. This resultant offset well exceeded the GUCP installation concentricity requirement of 0.050quot. As stated, the load imposed by the vent line increased the misalignment. The decision was made not to use GUCP (s\/n 2) because of its significant offset (0.049quot) when mated to ET-137. GUCP (s\/n 3) was selected because it had been fit-checked on ET-137 at MAF. The concentricity was 0.011quot to the 9:00 o\u2019clock position at MAF. The final installation concentricity for GUCP (s\/n 3) at the Pad was 0.014quot to the 9:00 o\u2019clock position. Two spare GUCA QDs (s\/n 7 and 8) were measured with the Faro arm, and s\/n 8 was selected because of its probe offset of 0.025quot to the 9:00 o\u2019clock position. The GUCA QDs can be clocked during installation in 90-degree increments. Therefore, to achieve the optimum resultant concentricity, GUCA QD (s\/n 8) was clocked 180 degrees so that the QD offset was at the 3:00 o\u2019clock position. This yielded a final concentricity of 0.011quot to the 3:00 o\u2019clock position. An ETCA\/GUCP mockup was tested offline in the VAB, using similar equipment and procedures, which validated the premise of clocking the GUCA QD to optimize its probe offset (Ref \u2013 Space Shuttle External Tank Hydrogen Vent System: Ground Umbilical Carrier Plate to Hydrogen Quick Disconnect Alignment Test Plan, Rev A.; and KSC-TA-11539, ET Hydrogen Vent QD\/GUCP Alignment Investigation Team Final Report).","Lesson ID":6036}
{"Driving Event":"STS-114 experienced a very low Fuel Bias which lead to an investigation regarding possible causes. The LO2 purity at SSC where the SSME's are tested was found to be very different than the LO2 purity at KSC and not accounted for in performance predictions. In addition, the run tanks at SSC are pressurized with Gaseous Nitrogen (GN2) which introduces more contaminant in the LO2. Actions taken: LO2 purity requirements were tightened to guarantee adequate LO2 at KSC on day of launch. Additional LO2 purity sampling was implemented to every flight instead of every six months to ensure adequate LO2 on day of launch. Increased LO2 procurement requirements at KSC only. Provisions were put in place to adjust APM on day of launch should we have lower than expected LO2 delivery (but still within procurement requirements).","Lesson ID":6056}
{"Driving Event":"As part of the Space Shuttle Orbiter\u2019s redundancy management system, critical LRUs are provided with redundant power. This allows the LRU to continue to function if one of the Orbiter\u2019s electrical power busses goes down. Separate and redundant busses are wired into the LRU, where internal \u201ceither\/or\u201d circuitry allows the LRU to continue functioning when a bus fails. The OMRSD requires verification of this redundancy as part of the processing flow. This verification drives the performance of serial Orbiter Maintenance Instructions (OMIs) to manually drop the busses and verify that the critical LRUs continue to operate on redundant power. OMIs such as OMI V1161 are serial in the test flow because no other testing can take place while the busses are manually dropped. Mission visibility of critical LRU bus redundancy is extremely limited. There is no health status indication that a particular LRU has the required bus redundancy. During ground testing, the bus drop tests only verify that the required redundancy is available at the time of the test.","Lesson ID":3761}
{"Driving Event":"The Space Shuttle mission STS-80 was launched on October 31, 1996. The mission planned for two EVAs to evaluate tools that would be used for the construction and maintenance of the the International Space Station (ISS). However, when the astronauts attempted to open the outer airlock hatch, the hatch would not unlatch. The decision was made by the mission managers not to attempt the EVAs since they did not want to risk damage to the hatch or seals. When Columbia returned to the Kennedy Space Center (KSC), following the mission, troubleshooting revealed that the outer airlock hatch actuator assembly was faulty. A new actuator assembly was installed on Columbia and the outer airlock hatch opened and closed normally. Troubleshooting on the bench revealed that one of the two Number 4-40 fasteners that hold the no-back\/clutch assembly together had backed out and was lodged between a planetary gear and the ring gear within the actuator gearbox. Furthermore, the second fastener was partially backed out and was loose (no running torque). It was also found that the threaded inserts used with the fasteners were a non-locking type when the drawing specified that a locking threaded insert should be used. Additionally, the vendor drawing did not specify a torque value for these fasteners. To resolve this issue, all actuators in the fleet were reworked to install locking threaded inserts. The vendor drawing was also updated to specify a torque on the fasteners and to verify running torque during the installation. Click here to view a video discussion of this lesson. Click here to view the video transcript.","Lesson ID":4417}
{"Driving Event":"Each Orbiter fuel cell power plant (FCP) that provides electrical power to the Orbiter has two pumps as part of its balance-of-plant. These include a coolant pump that circulates coolant through the FCP to control the operating temperature and a water separator\/hydrogen circulation pump (H2O\/H2 pump) that helps remove water from the FCP and circulate humidified GH2 through the FCP. Each pump runs on 3-phase AC current provided by Orbiter inverters. The H2O\/H2 pump has a pump motor condition (PMC) sensor integrated into the motor assembly to provide insight into the H2O\/H2 pump loading as well as provide feedback when a motor stalls or there is a current phase loss. Sensor output is obtained by monitoring all three input phases as well as the common return (neutral leg) for changes in current flow. The differences are summed and then converted into a 0\u20135 VDC signal that can be monitored. Shuttle engineers have long known that Orbiter electrical equipment operating on a single-phase of a 3-phase supply (e.g., Orbiter lighting) can produce a phase imbalance that distorts readings on the PMC sensor. During several launch countdowns, the sensor picked up phase imbalances that were not caused by the FCP but made the motor suspect nonetheless. As a result, significant time and effort were spent investigating these anomalies only to determine that they were caused by normal operation of equipment external to the FCP.","Lesson ID":4057}
{"Driving Event":"In the Command and Data Simulator (CADS) room of the Space Shuttle Main Engine (SSME) Shop, two power supplies provided power for the SSME. When one of the power supplies malfunctioned, it was discovered that two power monitors were not calibrated. The power supply had been validated every year but the individual power monitoring components had not been calibrated. There were no procedures to send these items for calibration.","Lesson ID":3763}
{"Driving Event":"During Constellation Program Altair Lunar Surface Access Module design discussions, this issue was discussed as a potential method to lower cost and mass that must be carried. It was also raised as a goal during KSC FCP\/PRSD engineer discussions with engineers from other centers while working on fuel cell research projects.","Lesson ID":4058}
{"Driving Event":"On September 29, 2009, a worker fell from a flatbed trailer while unloading crates of glass windows. The incident occurred outside on the east side of the LCC adjacent to Facility K7-0901. Earlier that morning, the truck and flatbed trailer arrived at the LCC with a load of crates. The tarp and tarp tie down straps were not completely removed from the flatbed trailer or from the first row of crates to be unloaded. When the forklift operator removed the third crate from the flatbed trailer, a tarp strap that was caught on the third crate pulled the tarp into\/over four crates remaining in the row. The crates fell over and knocked the worker off of the flatbed trailer which was approximately five feet off of the ground. The worker struck the pavement and sustained injuries to the head\/face. Figure 1: Crate Unloading Apparatus","Lesson ID":5879}
{"Driving Event":"An employee of a subcontractor received second and third degree burns while working at Building 01385, also known as the Mission Control Center (MCC). This building is a Kennedy Space Center (KSC) facility on the Cape Canaveral Air Force Station (CCAFS).The Injured Person (IP) and Coworker were tasked with preparing a transformer, associated with an electrical substation, for removal as part of the MCC demolition project. The electrical substation consists of a transformer and switchgear. The transformer was slated for transport to Ransom Road for disposal after oil was removed, and the switchgear was to be demolished on site.The employees gained access to the energized switchgear in order to separate the transformer from the switchgear. During this process, an arc flash occurred causing second and third degree burns to the IP's right arm. Figure 1: Switchgear with Panels Installed Figure 2:Actor Gaining Access Into Switchgear","Lesson ID":5876}
{"Driving Event":"On September 30, 2008, a construction contract was awarded to replace seawalls along the NASA Causeway east and west of the Indian River Bridge. A quotNuts and Boltsquot safety briefing was held on November 12, followed by a Notice to Proceed (NTP) given on November 20, 2008. On the morning of August 10, 2009, contractor employees performed routine safety inspections of all heavy equipment at the job site prior to commencement of work. Also that morning, a daily safety meeting was held with members of the contractor management at an office in Titusville. A contractor inspector arrived at the work site around 1015 EDT to perform morning inspections (but never at the site of the mishap). Nothing unusual was reported. At approximately 1030 EDT, Excavator Operator #1 repositioned a 9 cubic yard quotRock-Boxquot over the river, from east to west, in order to clear the area being prepared for framing and fabric along the seawall. The Rock-Box contained a residual amount of rock bedding at that time. At approximately 1035, Excavator Operator #1 and Excavator Operator #2 used their machinery to begin setting up the geotextile frame. At approximately 1100 EDT, a contractor employee (Loader Operator-1) used a Front End Loader to add bedding rock to the Rock-Box. A few minutes later, Excavator Operator #1 began to relocate the Rock-Box west to east over the Indian River in a southerly direction. This was performed so bedding rock could be placed in close proximity of the previously applied framing. The Rock-Box struck the seawall just prior to being repositioned. Excavator Operator #1 rapidly raised the Rock-Box and dropped it on top of the seawall. The mishap occurred when the Caterpillar 330CL Excavator overturned into the Indian River with Excavator Operator #1 in the cab at approximately 1105. Figure 1: Excavator in the Indian River with Rock-Box immediately after mishap Figure 2: Amount of bedding rock in the Rock-Box after mishap","Lesson ID":5896}
{"Driving Event":"A longeron bridge cart assembly containing three longeron bridges intended for use on Orbiter Vehicle 104, fell from the bed of a flatbed truck in the Launch Complex 39 area of Kennedy Space Center. The truck was en route from the 1N12 area of the Vehicle Assembly Building to Material Service Center room 31 in Orbiter Processing Facility 101. The cart and longeron bridges impacted the ground upside-down on the gravel covered shoulder of Utility Road. Security and traffic enforcement officers arrived at the mishap scene minutes later. No injuries to personnel occurred as a result of the mishap.","Lesson ID":5897}
{"Driving Event":"The XRS uses calorimetric detectors that must be cooled to near absolute zero (operating at 60mK). This is accomplished by a multi-stage Dewar which includes liquid He and solid Ne. Dewar operations are initiated on ascent by blowing pyro valves allowing the He and Ne to vent. The Dewar was also equipped with a pyro-driven vent that exposes the Dewar guard vacuum to ambient. This design feature was intended to vent the guard vacuum to deep space once on orbit. This would allow any cryogen leakage to be effectively prevented from contaminating this volume. There is another pyro gate valve at the telescope's aperture that protects the internal detectors until on orbit. By blowing the aperture gate valve the instrument becomes fully operational and is enabled to view its entire desired spectrum. Once the XRS was on orbit it was successfully calibrated and configured for full operations (i.e. guard vacuum and gate valves blown). However, prior to opening either the aperture valve or the valve to the guard vacuum (i.e. He and Ne are venting) significant science can acquired (although only over a small spectrum) in this configuration (see LL#2116 for a related lesson). Unfortunately, the space craft design included a fatal flaw. For most missions that fly cryogens the Dewar comprises the main structural component of the spacecraft. The XRS was buried inside the spacecraft in what turned out to be a confined space. Once integrated into the spacecraft the Dewar was supposed to have been vented to the exterior of it and then overboard. The entire spacecraft exterior was covered with thermal blankets which enclosed the volume that held XRS. The venting He and Ne accumulated in the confined space. Although the confined space was not airtight the venting area provided by the blanket seams restricted the venting sufficiently enough to establish a level of atmosphere to pose a contamination issue. When the guard and aperture valves were blown the confined He and Ne were ingested into the guard vacuum shorting out the vacuum causing unacceptable heat loads on the tanks. The cryogens were rapidly depleted and a planned 3-year mission was over in 19 days with no science having been acquired. As noted earlier that Astro E-2, as the name implies, was a build to print reflight of the first Astro which also was launched on a Japanese rocket. It was identically flawed and would have failed in the same fashion but the launch vehicle failed to achieve orbit and was lost. Also notable is that the design review process failed to identify the design flaw. This lesson is limited to mission operations planning. The genesis and propagation of the original design flaw is covered in detail in the Astro E-2 Mishap Investigation Board report and LL#2116. The Astro E-2 Mishap Investigation Board (MIB) found that there were significant cultural and communications issues that contributed greatly to the program's unsuccessful execution. Moreover, the build to print philosophy leads to an unfounded confidence, which also compromised the design review process.","Lesson ID":5776}
{"Driving Event":"All five elevators in the OSB I at the KSC are proprietary, even though proprietary was not required. All other elevators at the Launch Complex 39 area had been upgraded and were nonproprietary. A minor modification to the OSB I elevators (such as installing five limit switches and reprogramming five proprietary elevators) was quoted at $35,000.00. The same work was quoted at approximately $2500.00 for nonproprietary elevators.","Lesson ID":4019}
{"Driving Event":"During the 5-year-safety slide test on the high-bay elevators in the VAB, every elevator failed the test criteria. Those criteria state that elevators must slide a certain minimum distance according to parameters stated in ASME A17.1, Safety Code for Elevators and Escalators. Elevators in the VAB were sliding short of the specified minimum distance.","Lesson ID":4021}
{"Driving Event":"The horizontal drain lines in the Shuttle Orbiter Power Reactant Storage and Distribution (PRSD) system are very long, very heavy flexhoses with a large diameter. Their quick disconnect (GHC) mates to the Orbiter PRSD system (AHC) on the outside of the Orbiter are used to drain PRSD tank commodities (GH2 and GO2) as part of the Orbiter postlanding operations. Because the hose must rotate with the fitting, it is very difficult to achieve a firm mate between the GHC and the AHC. It typically takes technicians an hour or more to accurately perform the operation. Furthermore, on occasion the mate appeared to be secure, but later inspection showed that the mate was not firm. This could create a safety concern because, in the event that predrain leak checks were not performed properly, a failed mate could cause GH2 to be vented at the connection.","Lesson ID":4059}
{"Driving Event":"Juno is a mission managed by the NASA\/Caltech Jet Propulsion Laboratory (JPL) that will equip a spacecraft with nine science investigations to peer below the clouds of Jupiter. While checking energy assembly sockets during a 2009 functional test of an anode circuit board for the Juno Energetic Particle Detector (JEDI) instrument, a transistor on the board failed. The transistor was replaced and the test repeated, and a different transistor on the opposite side of the board failed at the same step in the test. Also at this point in the second test, the tester had noticed both a decrease in electrical current and the sound of the metal snap fastener on the sleeve of the tester's lab coat (ESD smock) striking the anode board. The tester recalled hearing a similar sound during the first test. The probable cause of the failures (Reference (1)) was the all-metal surface of the fastener on the garment sleeve momentarily shorting the transistor base to ground. There was no injury to personnel, there was no overstress to adjacent board components, and new electro-static discharge (ESD) coats with elastic sleeve closures were procured for the facility. Lab coats with metal snap fasteners on the front, and one or more on each sleeve, are common. One side of the fastener may feature a small metal ring encircling a cloth covering, but the other side of the fastener is an all-metal male disk (Figure 1) that mates with a choice among another set of female metal disks to adjust the sleeve closure for wrist size. If the sleeve fastener is left unsnapped or becomes unsnapped during use of the garment, one or more conductive disks are left dangling from the sleeve. At least one metal disk may be exposed even when the sleeve is fastened (Figure 2). .................... Figure 1. Metal snaps on sleeve of ESD smock. The smock fabric contains a static-dissipative mesh. Figure 2. Even when the sleeve is fastened, at least one metal disk is exposed. The incident occurred at the JEDI instrument developer's facility, but ESD smocks that have previously been procured for use at JPL include the type with metal fasteners on the sleeves. Although these garments are still in use at JPL on a limited basis, all newly procured smocks have elastic sleeves and are suitable for use in both clean rooms and other facilities. The elastic sleeve closures are preferred because they minimize skin exposure and maximize skin contact with the dissipative fabric. References: JE-P-5: 7425-5300 - Change of current draw during functional test of Anode Board SN001, JPL Problem\/Failure Report No. 26691, June 15, 2010.","Lesson ID":5756}
{"Driving Event":"During the transition from the Asynchronous Transmission Mode (ATM) network to the Ethernet network, KSC implemented the Juniper proprietary Redundant Trunk Group (RTG) -- a seamless failover technology -- in the Juniper EX4200 switches to provide additional network reliability for specified Virtual Local Area Network (VLAN) users. When a new Juniper switch\u2019s RTG was connected into KSC network with the intention to provide a redundant link to the network and improves overall switch and network reliability, instead an un-anticipated network loop was created. The network loop coupled with routine data-link layer broadcast traffic will create a broadcast storm that floods network segments with broadcast data packets traffic while displacing or denying normal network data traffic in those segments. By design, the Juniper\u2019s network switch operating software \u201cRapid Spanning Tree protocol\u201d should have detected the network loop and placed the switch\u2019s redundant link in blocking mode to avert any network loop. Further investigation showed that the RTG not only does not detect network loops, the switch\u2019s RTG does not forward the Bridge Protocol Data Unit (BPDU) data -- a switch network topology discovery and configuration management tool -- to other network devices as a result, other switches were not able to detect or learn about the existing network loop. The combined problems caused a broadcast storm across the network and affected the VLANs on the trunked interfaces and rendered the network unable to process user traffic and thus causing the user servers and field instrumentation to lose connectivity. This inherent design deficiencies are reported back the Juniper for resolution.","Lesson ID":5656}
{"Driving Event":"During launch processing for the STS-131 mission, the Orbiter\u2019s cabin air system pressure went out of limits, which required a field adjustment of the pressure and caused a short delay before the pad could be cleared of personnel for cryogenic propellant loading. On several other occasions, system pressures deviated from limits during launch countdown, and field crews had to adjust pressure regulators late in the countdown. No launch delays occurred as a result of these adjustments, but there was the potential for a delay or for launching the vehicle with cabin pressures outside required limits.","Lesson ID":4476}
{"Driving Event":"Because the Space Shuttle Orbiter's main propulsion system is complex and has many diverse components, an efficient method of validating the system was needed. Performing internal leak checks of each component during every orbiter processing flow was not only time-consuming, but used a great deal of test equipment and required technicians to enter the vehicle on multiple occasions, which increased the opportunity for collateral damage of flight hardware.","Lesson ID":4477}
{"Driving Event":"To meet Space Shuttle launch requirements, the proportion of dissolved air in the Orbiter\u2019s hydraulic fluid must be below 1 volume percent. Early in the Shuttle program, the deaeration system that removed the dissolved air from the hydraulic fluid was found to be unreliable and could not meet this requirement. A greater proportion of dissolved air could lead to pump cavitation and excessive softness in hydraulic-actuator force versus displacement characteristics.","Lesson ID":4596}
{"Driving Event":"When changes to vehicle or GSE configurations were being considered during recent programs, the lack of an adequate program database and up-to-date high-resolution models led to stalemates and hyperconservatism in decision making.","Lesson ID":4216}
{"Driving Event":"A set of Developmental Flight Instrumentation (DFI) was installed on the first four flights of the Space Shuttle vehicle. This instrumentation augmented the Operational Flight Instrumentation (OFI) to add insight into the performance of the Shuttle\u2019s subsystems during those missions. This data was used to verify the systems were performing as designed. Once the Space Shuttle was declared operational, this instrumentation was removed. Over the course of the Space Shuttle program, the performance of Shuttle subsystems was in question a number of times. In these instances, the additional information provided by the DFI suite would have helped greatly in arriving at a solution.","Lesson ID":4217}
{"Driving Event":"A near miss (an unplanned event that could have resulted in an injury) involving the Mobile Launcher Platform (MLP) handrail system pointed out deficiencies in the existing corrosion control system at Launch Complex 39. When an employee leaned against a handrail on one of the MLPs, the handrail collapsed because of hidden corrosion, and the employee almost fell. The event led to an extensive investigation that resulted in recommendations to improve the corrosion-monitoring system.","Lesson ID":4196}
{"Driving Event":"A contractor at KSC was on a project to refurbish the outside of the VAB. The refurbishment effort includes horizontal and vertical doors in High Bays 2 and 4, the South Transfer Aisle Door, translucent panels, and upgrades to exterior siding. The contractor hired a sub to perform surface preparation and painting. On May 19, 2008, The subcontractor began their work shift and held a morning tag-up meeting with employees. Tasks were assigned and the subsequently injured painter (P1) and a co-worker (P2) were dispatched to the 41st floor of VAB High Bay 4 to prepare vertical door canopy steel beams for painting. The painters arrived at level 41 at approximately 7:30 a.m. and performed tool and equipment inspections. They then donned and checked appropriate Personal Protective Equipment (PPE) including long-sleeved shirts, goggles, hard hats with face shields, earplugs, respirators, and Personal Fall Arrest Systems (PFAS), consisting of a body harness and lanyard. They descended a ladder to their work area, a catwalk platform, level 41A. Level 41A is protected on the south side by a guardrail and on the north side by a wall. Once on level 41A, the painters used their training and experience to determine where on the platform they needed to have their Personal Fall Arrest Systems (PFAS) anchored in order to arrest a potential fall. P1 began needle-gunning a vertical member in the center of the platform and did not hook up (anchor) because protection was provided by the wall and guardrails. P2 hooked up and began needle-gunning near an unprotected edge at the east end of the platform. P1 finished the vertical member and proceeded to the west end of the platform. At this location there is a ladder access opening in the guardrail. This access is protected by chain barriers. P1 observed that the top chain was connected and concluded that no hook-up was required in this location. P1 began needle-gunning an overhead beam facing away from the ladder opening chains. Needle-gunning is a two-handed operation. The workspace between the quotSquot hook chain guard rail barrier and the structure being prepped is 13 inches. P1's buttocks periodically began to make contact with the top quotSquot hook chain guard rail barrier while needle gunning. P1 became comfortable with touching and leaning on the chain barrier while performing the task. Figure 1: Needle-gunning Performed in Tight Workspace Figure 2: Open Space in the S-hooks At approximately 8:10 a.m., P1 leaned against the chain S-hook once more, and it disengaged from its eyebolt. P1 fell through the ladder opening approximately 12 feet to another service platform, level 41B, an unguarded platform nearly 500 feet above the VAB floor. The top chain remained attached at the latch end. P2 heard a quotboom, boom, boomquot noise and looked for P1. P2 found P1 lying on level 41B. P2 yelled to P1; P1 was non-responsive and appeared unconscious. P2 went to level 41 and informed a colleague that P1 had fallen and needed help.","Lesson ID":5496}
{"Driving Event":"Two Command and Data Simulator (CADS) checkout computers located in the CADS room are attached to dedicated UPSs. During Space Shuttle Main Engine (SSME) validation, the UPS for the second CADS computer (GSE for SSME testing) was not functioning. This second CADS computer was a backup and had not been used for 2 years. Review of technical specifications revealed that the UPS batteries require full recharge cycling every 6 months in order to keep the batteries from discharging beyond the safe limit. Procedures to perform this maintenance were not in place.","Lesson ID":3762}
{"Driving Event":"Ares I-X showed the importance of concurrent engineering for large multiple-center projects. The team responsible for generating the processing procedures and for supporting on-vehicle testing should have been working with the design team early in the requirement development process. Ares I-X started using concurrent engineering late in the project and would have benefited by implementing it at the start of the project.","Lesson ID":3758}
{"Driving Event":"During a scheduled quarterly Preventive Maintenance Inspection (PMI) procedure on the Space Station Processing Facility (SSPF's) hardware receiving room, south sliding door (Work Order Report 124505, December 2006) a discrepancy was noted with the safety edge. Due to the discrepancy a Corrective Maintenance Work Order 135211 was generated to quottroubleshoot and repair door sliding (HDW south), safety edge not working properly.quot Another scheduled annual Preventive Maintenance procedure (in March 2007) was satisfactorily completed without any discrepancies noted. However, the problem from the December PMI remained open and was carried on the shop\u2019s quotto doquot list. Work Order 135211was scheduled to be worked on May 31, 2007 for the purpose of correcting the discrepancy with the door's safety edge quotnot working properly.quot Because of the nature of the problem, the contractor's Controls Engineer (CE1) was asked to assist in the event. There were some questions as to how the door's control system functions. Two technicians (T1 & T2) were assigned to the task on the morning of Thursday, May 31, 2007. Prior to beginning the troubleshooting task, technicians T1 and T2 reviewed the work order and filled out a Safe Plan of Action (SPA) assessment form which listed the hazards associated with this specific job\/task, including pinch and crush hazards. After the two technicians reviewed and discussed the SPA it was presented to their supervisor who signed and approved the safety plan. The technicians were released to begin the troubleshooting job\/task. The two technicians were scheduled to meet the contractor's Control Engineer at the SSPF Ops Desk prior to beginning the task. Both technicians arrived at the SSPF operations desk to meet CE1 at approximately 10:00 a.m. Prior to meeting at the SSPF Ops Desk, T1 had retrieved a set of door drawings from the system engineer in case the Controls Engineer had some design questions. While T1 and T2 were waiting for the Controls Engineer to arrive at the SSPF Ops Desk, T2 decided to go to the work site to make any necessary preparations. T1 remained at the SSPF Ops Desk waiting for CE1 to arrive. While T2 was at the work site waiting for T1 and CE1 to arrive, he decided to check out the door discrepancy himself prior to the others arriving. T2 enlisted the assistance of another shop technician T3 (T3 was working a different job in the same general area), to help him in re-creating the safety edge discrepancy. T2 and T3 checked the door with one technician operating the controls and the other technician tapping the safety edge on the door. They verified that contact with the safety edge would stop and reverse the door, but at some point, prior to full close, the safety edge would stop functioning. T3 went back to his assigned task, and T2 waited for T1 and CE1 on the airlock side of the mishap door. Once CE1 arrived at the SSPF Ops Desk, CE1 and T1 walked to the work site. Almost immediately upon arrival at the work site T1 decided to demonstrate the door discrepancy to CE1. T1 did not ask for assistance from T2, and T2 was unaware that CE1 and T1 were at the mishap door beginning the troubleshooting task. T1, holding a set of rolled-up drawings in his right hand, began to operate the door controls with his left hand while at the same time attempting to activate the safety edge with his right hand holding the drawings. The door continued to travel to closure before T1 realized his finger was in an impact or pinch zone and a portion of T1\u2019s right thumb was severed by the sliding door. Figure 1: Injury Site Figure 2: Top View of Injury Site and Approximate Location of Personnel","Lesson ID":5536}
{"Driving Event":"On the Constellation Program contract for reusable solid rockets, the KSC ground operations supplied ground process knowledge input to the design of the First Stage systems. During the course of the design process, KSC Ground Ops would propose processing enhancements which would affect operational sequencing, and in turn, drive vehicle configuration changes. Some of the suggestions made by the GOP were determined to be out of scope of the current contract. Conversely, some design changes made by the team were studied at length and implemented without concerns for in\/out of scope or potential KSC impacts. During design reviews, problems were discovered that might have been avoided if the KSC tasks or design changes had been included as requested. By the time the KSC changes were acknowledged it was very difficult and costly to incorporate the design solutions.","Lesson ID":4658}
{"Driving Event":"The Orbiting Carbon Observatory (OCO), an Earth orbiting satellite mission managed by the NASA\/Caltech Jet Propulsion Laboratory, was designed to make precise, time-dependent, global measurements of atmospheric carbon dioxide (CO2). Prelaunch testing of the primary instrument used to detect CO2 from orbit revealed residual image problems with two of the three focal plane array (FPA) detectors (Reference (1)). The residual image in the detector used for the 760 nm Oxygen A-band channel was found to be an intrinsic property of the detector design. The residual image in the 1610 nm Weak CO2 channel was traced to a focal plane fabrication anomaly. The residual image problems in both FPAs were remedied by developing a correction algorithm implemented in the ground data processing system used to processes the science data. An innovation that proved to be one of the most critical assets of the OCO pre-launch instrument test program was a heliostat (Figure 1) on the roof of the JPL Environmental Test Facility. This facility was installed to allow direct observations of the sun, to validate the spectroscopic calibration against a high-precision reference spectrometer. A heliostat incorporates a mirror that turns to track the sun's apparent motion across the sky and maintain a beam of reflected sunlight pointing toward a target. The OCO heliostat used a pair of mirrors to capture the sunlight and direct it though a window into the thermal-vacuum chamber and into the flight instrument (Reference (2)). While the residual image in the Weak CO2 channel was discovered and characterized using white light, heliostat observations were essential for characterizing and quantifying the detector residual image problem in the A-band Channel. Heliostat observations therefore provided the data needed to correct for its effects in post acquisition data processing. In addition, observations of atmospheric absorption lines obtained with the heliostat played a critical role in verifying the dispersion and instrument line shape function of the OCO spectrometers. It also provided an efficient means to test the throughput of the on-orbit calibration system. Observations of the moon through the heliostat provided a sanity check on the geometric calibration of the instrument, and provided a means to validate instrument slit misalignment. Figure 1. Configuration of the roof- mounted heliostat References: PFR # 6716: O2 A-Band Focal Plane Residual Image, JPL Problem\/Failure Report No. 6716, October 16, 2008. P.J. Guske, OCO (Orbiting Carbon Observatory) Project Lessons Learned Document (Final), JPL Document No. D-26172, July 7, 2009, Paragraph 3.7.4.","Lesson ID":5636}
{"Driving Event":"Early in the Space Shuttle Program's Orbiter ground turnaround processing, RF system testing was performed for every flow in the Orbiter Processing Facility (OPF). During this testing, problems resulted in the removal and replacement of discrepant Line Replaceable Units (LRUs). Had this RF system not been tested with the C&T Station, launches could have been scrubbed or missions delayed. The C&T Station also provides a third-party way to monitor the RF Systems during countdown by monitoring both signals from the vehicle and from the MILA ground station to the orbiter.","Lesson ID":3676}
{"Driving Event":"During the performance of OMI V1103.002 (EMU Functional), a significant amount of water was found in the EMU 2 upper torso in the Primary Life Support System (PLSS) sublimator. After troubleshooting and data retrieval, it was found that the Orbiter airlock power supply had caused a voltage spike, which in turn opened the EMU feed water valve and caused the PLSS sublimator to be flooded with water. This condition forced the removal of EMU 2 from the airlock starboard wall so it could be sent back to JSC for repair while another replacement EMU was being prepared to be shipped to KSC. When EMU 2 was removed, it was discovered that the CCC was installed backward in the EMU. The error was then documented on PR FCS-5-11-0265. Then the CCC in EMU 1 was found to have been installed backward as well. This error was then documented on PR FCS-5-11-0266. This raised concern that LiOH from the CCCs might have entered the EMU vent loop and that some mechanical damage might also have occurred (it takes slightly more force to latch the CCCs in place if they are installed backward). After the PR disposition was complete and the work steps were performed, it was determined that no LiOH had entered either of the EMUs and that no collateral mechanical damage had occurred. The CCCs were reinstalled in their correct configuration in the two EMUs and were flown successfully on STS-77. A review of the KSC installation procedure and JSC installation drawing revealed work steps and drawing notes that stated quotCorrectly orient flight CCC, such that the identification tag is visible when installedquot for both the EMUs. Obviously, these work steps were not performed correctly when these two CCCs were installed, and some later questioned whether the identification tag could be installed on the wrong side of the CCC, which could then lead to a similar installation error. Further research indicated that the original CCC design (P\/N SV767790-05) had two cooling water ports on the left top, which would only allow a one-way installation. The newer design (P\/N SV792600-00) did not have these two ports and the CCCs used for this installation were of the newer design. This problem was presented to the Shuttle Operational Action Group (SOAG #96-032, see attached backup material). FCS Engineering suggested to the SOAG that another check be added to the installation procedure and to the JSC drawing, as well as a Caution note to the installation procedure. The added check stated quotVerify that the back of the CCC is flush with the PLSSquot prior to zipping up the thermal cover flap covering the PLSS and CCC. The added Caution note stated quotDue to the design, the CCC can be installed backwards. The CCC should be installed with little resistance and should sit flush with the back of the PLSS when the flap is closed.quot These actions were approved by the SOAG members. Since these actions, the CCCs have been installed correctly on all subsequent Shuttle flights. Click here to view a video discussion of this lesson. Click here to view the video transcript.","Lesson ID":3697}
{"Driving Event":"After an elevator at a launch pad had been refurbished, damage caused by the launch environment during the next launch was excessive, which meant that it was likely that more FOD had been created during the launch than should normally be the case.","Lesson ID":4020}
{"Driving Event":"The Shuttle Connector Analysis Network (SCAN) system developed by the Space Shuttle Processing organization consisted of a user interface software and database system accessed by workstations throughout KSC to track an orbiter's connector configuration (mated or demated) and system retest verification. By using SCAN, the orbiter system engineers and test conductors could quickly determine the status of orbiter connector configurations. SCAN provided current listings of all demated connectors prior to system power-up. Often connector configurations would change between orbiter power-ups as a result of system troubleshooting or rework that could only be performed while the orbiter was powered down. SCAN also recorded the work authorization document that was used for performing the connector test verification after the mating of the flight hardware. The system engineer would record the system checkout for each active connector pin after the connector was mated for flight. The same process was followed if a connector was demated during ground processing (postflight mate). Ares I-X did not have a SCAN-type system, and tracking of the connector configurations before power-up was difficult. There was also no good way to verify that connector testing had been performed on a flight-mated connector. Figure 1: Graphical wire trace for path continuity Figure 2: SCAN Engineering Reports Menu","Lesson ID":3757}
{"Driving Event":"Each Space Shuttle launch erodes or damages the refractory cement of the MFD. For many years, the damaged cement was removed by hand with pneumatic tools. This method was dangerous and time-consuming, and it caused significant damage to the underlying reinforcement steel. The reinforcement steel had to be repaired or replaced after each removal process.","Lesson ID":4036}
{"Driving Event":"A technician climbed a five-foot portable ladder to the second-from-the-bottom rung in preparation for a cable pulling task at the Operations and Checkout building (O&C), at approximately 9:25 a.m. on June 17th, 2007. The task that the Technician was completing at the time of the mishap was in preparation for the cable pulling portion of Work Order (WO) 474304 \u201cInstall (2) Aggregate Switches in the O&C\u201d. Prior to pulling the cable, the Technician determined it was necessary, based on prior experience in the O&C Building, to verify that the routing path for the cable was clear of obstructions. To complete this task, the Technician had to remove a ceiling tile and look up into the area above the ceiling. Reaching the ceiling tile required the use of a ladder. The technician moved a ceiling tile in order to view the area above the ceiling. After finishing the inspection of the above-the-ceiling area, the technician began descending the ladder. While descending, the technician held the ladder side rail with his\/her right hand only. The technician stepped down one rung with his\/her left foot, then, while attempting to slide his\/her right foot off the second-from-the-bottom rung, the technician's right boot momentarily caught at the second-from-the-bottom rung. This caused the technician to pivot counterclockwise (plan view), twist away from the ladder, and fall approximately two-feet to the vinyl-asbestos tile covered concrete floor. The technician suffered injuries in the form of a laceration to his\/her forehead and a broken arm. Pre-task briefings should be conducted to raise awareness of possible safety problems and proper techniques. Figure 1: Technician 1\u2019s right boot gets caught in the second-from-the-bottom rung of the ladder","Lesson ID":5216}
{"Driving Event":"Prior to the development of the RSA system, there was no streamlined efficient method for TPS technicians or quality inspectors to formally document concerns or ideas for improving the specifications and maintenance manuals used in the day-to-day Space Shuttle processing operations.","Lesson ID":3277}
{"Driving Event":"Numerous Work Authorization Documents (WAD) have been generated due to the damage done to coldplates during system R\/R. The attached document is a WAD to repair coldplate damage in Avionics (AV) Bay 5, top side of upper shelf. This WAD is not unique. Figure 1: Avionics Bay 5 - Upper Shelf Damaged Cold plate with Dents and Scratches Figure 2: Avionics Bay 5 - Upper Shelf Damaged Cold plate with Dents and Scratches Figure 3: Avionics Bay 5 - Upper Shelf Damaged Cold plate with Dents and Scratches","Lesson ID":3696}
{"Driving Event":"The Space Shuttle ground support equipment (GSE) included remotely controlled equipment operated by the systems engineers for their respective systems. Extensive procedures were developed to establish preloading, loading, and postloading configurations for the OMS\/RCS propellant tanks and helium and gaseous nitrogen (GN2) bottles. The system engineer issued commands from a control console to perform these procedures, which were lengthy and susceptible to human error. In addition, the requirement to manually control these very hazardous operations was stressful for the operators. An incident involving the STS-2 Forward Reaction Control System (FRCS) servicing highlighted the need for automation. During the servicing for STS-2, the MD162 quick disconnect failed, causing oxidizer to spill down the side of the FRCS module. No automatic safing was available at that time, information for the operator was limited, and spill response actions were slow. This problem could be mitigated in future operations because the design of the GSE and Launch Processing System (LPS) allowed for the creation of automated functions. Automated sequencers were developed based on manual procedures and related Shuttle orbiter and GSE requirements documents. This was accomplished in incremental steps. The first sequencers were developed for automated electromechanical checks of the GSE, automated startup of the propellant flow through the GSE Fluid Distribution System (FDS,) and loading of the orbiter helium and GN2 bottles. Then, a more organized and integrated software set was developed by creating a master menu program that established a group of applications and a master set of OMS\/RCS programs. These programs could be selected by the operator and loaded into the six application slots. One application slot was always occupied by the monitor sequencer. The monitor sequencer performed a large group of automated operations such as the Storage Tank Auto Press (a program that automatically opened the storage tank pressurization valve or the storage tank vent valve to maintain a predefined value). Another example of control functions was the control of flow rate or system back-pressure. The monitor sequencer performed this function by progressively opening or closing flow control valves. Other applications contained the display drivers and the automated sequencers for functions such as loading of the propellant tanks. Autoload sequencers were first used for loading the orbiter hypergolic propellant tanks for the STS-26R post-Challenger mission. Prior to this, the OMS tank reloading operation took 6 hours and the RCS operation took 4 hours. With the development of autosequencers, loading of an OMS propellant tank could be done in just over 1 hour and an RCS propellant tank in about 30 minutes. Each propellant load was accurate and efficient and, in most cases, did not violate design requirements. Sequencers were designed to establish or verify proper configuration initially, monitor critical functions continuously, execute the required task in the prescribed sequence, and end with the orbiter in a secure, safe configuration. Each automated sequence is performed with minimal operator intervention. The sequencer design allowed the operator to stop at a predetermined hold point or to secure the operation through a predetermined securing sequence. These executed functions allow the sequencer to stop at a stable configuration for the vehicle and GSE and then continue from the point at which it was secured. In the sequencer, critical instrumentation (and instrumentation output in general) was monitored for a specific result or against a predetermined redline value. Exceeding a required value caused the execution of a securing action or a safing action that could be contained within the executing program or other automatic monitors. One such module that provides automatic monitoring and safing was the Reactive Control Logic (RCL) module. RCL, a critical monitoring and safing program assigned to specific instrumentation, uses defined redline values that will cause safing actions to be executed.","Lesson ID":3698}
{"Driving Event":"On March 14, 2008, at NASA John C. Stennis Space Center (SSC), at approximately 1750 Central Standard Time (CST), a fire occurred in Building 1100, 3rd floor, in an area that was undergoing asbestos abatement. There were no injuries associated with this mishap. The fire occurred in an unoccupied construction area following the end of a normal workday (0800-1630 hours). The SSC Fire Department (FD) serves as first responders for fire, emergency and emergency medical services (EMS) for the center and was on scene within six minutes of the first alarm. The center section of the 3rd floor was engulfed with heavy smoke upon FD arrival. The FD laid two fire hoses, one from a water hydrant located near the northeast corner of Building 1100 and one from a standpipe on the 2nd floor to the fire on the 3rd floor. The fire was brought under control within 15 minutes of the initial attack by the FD. The direct cost of damage from this mishap has been estimated at $376,000 and was classified as a Type B Mishap, IRIS Safety Incident #2008-075-00002. The proximate causes leading to the mishap are listed below. For the fire to occur, one Event and two Conditions had to be met and were identified as the three Proximate Causes: an ignition event, available fuel, and an adequate oxygen supply. Available fuel and oxygen supply were eliminated as ignition sources. A Fault Tree was developed to identify the most likely ignition source based on potential ignition sources present in the fire area. This process identified undersized and improperly routed extension cords as the most likely ignition source. These results were fed into the Events and Causal Factors (E&CF) tool for additional assessment. An E&CF Tree was generated based on the three Proximate Causes (see Figure 1, Events and Causal Factors Tree). Each Proximate Cause was developed to examine all reasonable or possible hypotheses for how the mishap might have occurred, and to systematically rule out as many alternatives as the evidence allowed. The E&CF analysis resulted in three Root Causes and two Contributing Factors. The primary proximate cause was an undersized extension cord that was improperly routed and energized, in the presence of fuels sources and adequate oxygen. Based on evidence at the scene, the fire originated in an asbestos decontamination station, which was a wood-framed enclosure covered with 6 mil plastic. The station was not in use on the day of the mishap. All elements required for a fire were present in the area: oxygen at normal levels, combustibles, and potential ignition sources that included task lighting, equipment and extension cords. Utilizing the investigative approach above, the source of ignition for the fire was determined to be undersized and improperly routed extension cords. Three Root Causes and two Contributing Factors were identified, resulting in three Recommended Corrective Actions.","Lesson ID":5456}
{"Driving Event":"Thousands of electrical connectors are used on the Space Shuttle Orbiter to allow quick connection and disconnection of electrical circuits for maintenance, modification, inspection, or troubleshooting. NLS connectors are procured according to MSFC specification 40M38277 and are similar in construction to MIL-C-38999, Series II, connectors. NLS connectors are commonly referred to high-density connectors because of their generally high number of small contacts per connector (up to 128 size 22D contacts in a single connector). From a design perspective, 128-pin NLS connectors offer space and weight advantages but are challenging from a vehicle processing perspective. First, the contacts of high-density connectors are more susceptible to bending during mating and demating than those of lower-density connectors. If the connector is damaged beyond repair, each connector contact must be depinned and repinned\u2014a labor-intensive operation. Second, demating and reworking connectors have a significant effect on system-level retesting. According to the Orbiter Maintenance Requirements and Specifications Document (OMRSD), when a connector is demated, each pin must be functionally reverified after the connector is remated before the next mission. This requirement was imposed to detect bent or recessed contacts or other anomalies that could otherwise go undetected until the function was used during flight. In addition, the OMRSD requires that all replaced connectors be continuity-tested prior to power-up to verify that they were pinned appropriately. This requirement was imposed to ensure that flight hardware was not inadvertently electrically damaged because of a missed pin. Meeting these requirements for high-density connectors can be challenging, and the retesting alone can take weeks. For example, the circuits of a 128-pin NLS connector can branch out to 15 or more other connectors. Continuity testing requires the demating of all those additional connectors, each of which carries its own retest requirements. This situation can quickly spiral into a retesting nightmare, which can have significant effects on milestones. A worst-case example of this situation is retesting of the landing gear system. As one of the last steps of the Orbiter Processing Facility flow, the landing gear is functionally tested and then stowed. The Orbiter is then taken to the Vehicle Assembly Building and mated to the External Tank and Solid Rocket Boosters. Once the Orbiter is vertical and mated, the landing gear cannot be functionally tested for the rest of the processing flow. Therefore, demating any connectors associated with those circuits must be avoided because retesting would require destacking and returning the Orbiter to the Orbiter Processing Facility.","Lesson ID":3759}
{"Driving Event":"Existing lightning instrumentation systems, the Lightning Induced Voltage Instrumentation System (LIVIS) and the Catenary Wire Lightning Instrumentation System (CWLIS), were originally assessed as noncritical (nonconfigured) systems but were later reassessed as critical. Several deficiencies were noted during the reassessment: lack of redundancy and design to satisfy a critical system requirement, inability to detect system failures, no remote health-monitoring capabilities, and lack of certification and configuration control for the software application. Because LIVIS and CWLIS provided only limited insight into vehicle systems, other labor-intensive and time-consuming processes for collecting and evaluating data were necessary to ascertain vehicle health. GLMS was developed to improve insight into the health of vehicle systems and to do so faster and with fewer resources, but it required further validation to meet KSC requirements.","Lesson ID":3640}
{"Driving Event":"The AWA would not operate during a validation test on an SMCH. The only technician available to repair the AWA had to be brought in from out of the area. The cost of parts and the downtime required for repair were not acceptable for continued use of the AWA. Because each SMCH must be validated before being installed in the Orbiter, any interruption in harness testing creates delays in all subsequent tasks in the Orbiter flow process.","Lesson ID":3641}
{"Driving Event":"The vendor was required to provide replacements for aged RMS blankets. The vendor outsourced the manufacturing and provided the subcontractor with only cartoon drawings for production. Many of the replacement blankets were not usable because attachment points for Velcro and ground wires were mislocated. The vendor never provided the templates needed for manufacturing. KSC Engineering had to initiate Problem Reports so the blankets could be adjusted for use on the RMS. Figure 1: Cartoon of CCTV Bracket without dimensions or tolerances","Lesson ID":3656}
{"Driving Event":"On December 23, 2008, a 935-gallon composite pressure vessel being tested at the Cryogenics Test Laboratory (CTL, or Cryolab) at the Kennedy Space Center ruptured, causing injury to test team personnel in the Cryolab high-bay and damage to the facility and test equipment. IRIS Case Number: S-2008-359-00002 The tank was filled with liquid nitrogen (LN2) and was being pressurized with gaseous nitrogen (GN2) to predetermined pressure levels while the test team monitored strain levels in the tank shell. During testing, the tank ruptured and the wood and aluminum enclosure did not contain the blast, resulting in LN2\/GN2 flowing into the Cryolab high-bay where 11 members of the test team were located. Personnel were injured by the initial pressure wave. Test team members came in contact with the gaseous and liquid nitrogen as they evacuated (one person fell, resulting in abrasions, fractured rib, and cryogenic burns). Seven people were transported to the KSC Occupational Health Facility (OHF) (one by ambulance), and all were released for regular duty. One test team member had further complications that required outpatient medical treatment following his return to his home out of state. Although there were no fatalities associated with this mishap, there was a significant risk of asphyxiation in this event due to the quantity of GN2 that entered the Cryolab high-bay.","Lesson ID":5396}
{"Driving Event":"Pneumatic regulation panels experience frequent pressure adjustments when the ambient temperature changes. They also require frequent corrosion-induced repairs.","Lesson ID":3297}
{"Driving Event":"On July 19, 2006, at approximately 0714, Eastern Daylight Time, a sandblasting worker was struck several times by a spinning vent pipe assembly (consisting of 2-inch galvanized-steel pipes and fittings and a 2-inch bronze vent valve) attached to a sandblast pot while preparing for sandblast operations at the Kennedy Space Center (KSC) Launch Complex 39A (Pad 39A). Security, Fire\/Rescue, and Emergency Medical Services (EMS) personnel arrived at the scene within a few minutes, and the injured worker was airlifted to a nearby medical center. The injured worker and several others involved in the sandblasting operation were employed under a subcontract to perform corrosion control, including sandblasting and painting. The mishap involved the unsafe configuration of the sandblast pot due to the following deficiencies in the initial system setup of the pressure vessel\/systems (PV\/S): No safety relief valve (SRV) in the system was set at or below the maximum allowable working pressure (MAWP) of the sandblast pot (lowest-rated component in the system), as required by the American Society of Mechanical Engineers (ASME). The sandblast pot was not equipped with a pressure gage or SRV as required by OSHA 29 CFR. Operating pressure was set higher than the sandblast pot (receiver) MAWP. The manufacturer\u2019s certification was voided by postmanufacturing welds on the pressure vessel. The SRVs on the compressor and dryer did not open at the designated settings of the valves. The compressor SRV was missing the appropriate manufacturer\u2019s identification plate. Flex hoses and other components of the dryer were in disrepair.","Lesson ID":5156}
{"Driving Event":"The Station Fire ignited in the Angeles National Forest 3 to 4 miles northwest of the NASA\/Caltech Jet Propulsion Laboratory (JPL) on the afternoon of Wednesday, August 26, 2009. The largest fire in the recorded history of Los Angeles County, the flames consumed 160,000 acres. During August 27 and 28, the fire continued to grow and move toward JPL (Figures 1 and 2) through extremely steep and inaccessible terrain (Figure 3), and approached within one meter of the JPL perimeter. Friday was a non-workday for 75% of JPL personnel; the JPL Management Operation Committee (MOC) decided to close JPL to non mission-critical personnel over the weekend and to activate the JPL Emergency Operations Center (EOC). By August 30, the flames moved to the west and east and no longer posed an imminent threat to JPL, although the air quality ranged from quotunhealthy\u201d to \u201chazardous.quot JPL remained closed on the Monday, August 31 workday, and reopened for normal operations on September 1. Figure 1. The Station Fire grew in size and intensity while moving south toward JPL. Figure 2. Detail from Figure 1 showing the JPL campus. JPL was well prepared for the Station Fire, having made steady progress in developing emergency response protocols and processes over several prior years. Fortuitously, JPL preparedness was enhanced because JPL had spent the prior 3 months planning a full scale exercise with a wildfire scenario that was scheduled to be held on September 10. Also, there were no launches or special mission-critical activities scheduled when the fire broke out. No JPL personnel were injured by the fire, and the impact to Laboratory facilities and activities was minimal. Figure 3. The JPL Fire Department supported over 190 fire fighting helicopter sorties from the Lab\u2019s Mesa helipad. Reference (1) documents lessons learned from the JPL response to the Station Fire emergency. The following JPL measures worked well: The JPL leadership, the JPL Facilities Maintenance & Operations contractor, and JPL first responders (Fire, Security, and Urban Search & Rescue (USAR) Team) were responsive, proactive, and worked well as a team throughout the incident. Providing a JPL representative at the state\/local Joint Command Center briefings kept JPL informed and involved in the overall disaster response. The planning for the JPL wildfire exercise (called off due to the real fire) helped to clarify JPL disaster response roles and responsibilities, and it contributed to the effectiveness of the Laboratory evacuation, JPL and subcontractor indoor\/outdoor air quality monitoring, and quick response efforts of the JPL USAR Team. Also effective were JPL disaster communications, including regular and frequent communication to employees, the Everbridge automated notification system, and special outreach to employees affected by the fire (e.g., those remaining onsite and those whose homes were threatened). Credit must also be given to the state and local personnel who responded to the Station Fire, which raged for a month over an area of 250 square miles. The Station Fire response pointed out the need for the following improvements at JPL: Definition and designation of \u201cmission-critical employees\u201d to facilitate evacuation of non-mission-critical staff. EOC improvements, including improved EOC staffing, equipment, and organization; training and provisioning for sustained operations; EOC documentation (development of Incident Action Plans and tracking of \u201ctickets\u201d\/calls), and better coordination with federal agencies. Continuous Lab-wide fire prevention and mitigation measures. References: Regina Phelps, \u201cJet Propulsion Laboratory Station Fire After-Action Report,\u201d November 4, 2009. \u201cStation Fire After-Action Report Recommendations,\u201d October 20, 2009. \u201cMultihazard Emergency Response Plan, Rev. 4,\u201d JPL Document No. DocID 28012, February 8, 2008.","Lesson ID":5256}
{"Driving Event":"The Wilkinson Microwave Anisotropy Probe (WMAP) was launched in 2001 and outfitted with an 11 cell CPV NiH2 battery. WMAP was designed to operate in full sun conditions. An unexpected series of discrete voltage drops began in August 2009 that were clearly traceable to the loss of one of the two individual cells contained within multiple battery CPVs. An examination of the limited telemetry available provided confirmation that each event was associated with a transient thermal load increase that occurred in conjunction with each step loss of voltage.","Lesson ID":5336}
{"Driving Event":"The Tiger team found that the primary cause of the spray\/foam releases, foam formation from the citric acid liquor and degradation of the packing material, was the foam formation caused by the decomposition of bacteria that thrives in the citric acid and that is killed when hydrazine is introduced. The packing material could block\/restrict the flow rate out of the vent stack allowing back pressure to rise and then release with a \u201cburp.\u201d","Lesson ID":3596}
{"Driving Event":"On February 26, 2010, at 2330 hours, on Complex 39 A Mobile Launch Platform 0' level, the STS-130 Final Inspection Team (FIT) began their T\u20133-hour walk down. The operator, a NASA FIT engineer, started to configure, pressurize, and power up the MacDonald, Detwiller, and Associates (MDA) Prototype Ice Detection Camera (IDC). Figure 1: Overall IDC Configuration The operator reported that the initial GN2 supply cylinder pressure reading was 2,900 psi. He then turned the IDC single-stage regulator gauge valve and observed a pressure increase to 10 psi (the nominal operational pressure setting). After adjusting the IDC rapid-exchange valve and completing the power-up sequence, he observed an immediate loss of system pressure, with the GN2 supply cylinder and pressure regulator reading 0 psi. He then turned off the electrical power, closed the GN2 supply cylinder valve, and proceeded to the pad surface to retrieve a spare GN2 cylinder. When he returned, he moved the IDC outside the west elevator at the Fixed Surface Structure (FSS) 95' level and secured the spare GN2 bottle. But because the FIT was preparing to move to the 255' level, he did not complete the gas and pneumatic connections. Upon arrival at the 255' level, the operator rolled the IDC from the elevator to the southwest corner, where he connected the GN2 gas bottle. While making the connection, he looked at the single-stage regulator gauge but did not touch or adjust it. He opened the GN2 supply cylinder valve slightly and then heard what he described as a \u201cloud whine and a pop.\u201d The panel glass had shattered (see figure 2). Figure 2: Sudden Pressure Change Shattered Display Panel","Lesson ID":4456}
{"Driving Event":"On December 23, 2008, a 935-gallon composite pressure vessel (CPV) being tested at the Cryogenics Test Laboratory (CTL, or Cryolab) at the Kennedy Space Center ruptured, causing injury to test team personnel in the Cryolab high-bay and damage to the facility and test equipment. IRIS Case Number: S-2008-359-00002 The tank was filled with liquid nitrogen (LN2) and was being pressurized with gaseous nitrogen (GN2) to predetermined pressure levels while the test team monitored strain levels in the tank shell. During testing, the tank ruptured, the wood and aluminum enclosure did not contain blast resulting in LN2\/GN2 flowing into the Cryolab high-bay where 11 members of the test team were located. Personnel were injured by the initial pressure wave. Test team members came in contact with the gaseous and liquid nitrogen as they evacuated (one person fell, resulting in abrasions, fractured rib, and cryogenic burns). Seven people were transported to the KSC Occupational Health Facility (OHF), (one by ambulance) and all were released for regular duty. One test team member had further complications that required outpatient medical treatment following his return to his home out of state. Although there were no fatalities associated with this mishap, there was a significant risk of asphyxiation in this event due to the quantity of GN2 that entered the Cryolab high-bay.","Lesson ID":4976}
{"Driving Event":"The Shuttle\/Orbiter was designed for heavy structural components, such as access doors, to be line-replaceable units (LRUs). However, no guide pins were provided for aligning the fastener holes during lifting and installation (or removal). This has caused unacceptable wear and tear on the fastener holes, resulting in surface damage and elongated holes and forcing unplanned maintenance for repairs. The Orbiter Aft Access doors, known as the 50-1 and 50-2 access doors, are a good example of this situation. When the flight doors are not installed, ground support equipment (GSE) door frames must be installed. At the launch pad, when the Orbiter Aft is being closed out for flight, the 50-1 and 50-2 doors are installed. Both the GSE door frames and the flight doors must be handled manually by technicians during their installation and removal. Installation and removal of GSE door frames and 50-1 and 50-2 doors have caused coining and surface damage to the attachment holes and adjacent areas. See the attached briefing from the Shuttle\/Orbiter Mechanisms team for documentation of the problem and five guide pin concepts for resolving it.","Lesson ID":3557}
{"Driving Event":"The HPAs were procured by NASA and a contractor as part of the Hardware Interface Module (HIM) subsystem in the mid-1990s. The actual manufacturer was another contractor. After the initial contract with the original contractor was cancelled, NASA issued a different contract for production builds of the HIMs to a third company, and as part of that contract, the second contractor was identified as a mandatory manufacturer of the HPAs. After the production contract was initiated, United Space Alliance (USA) became the Sustaining Engineering organization for the complete HIM subsystem, including the HPAs, and upon delivery of the equipment, began replacing the existing HIMs with the new units. Meanwhile, workmanship and quality discrepancies at the second contractor resulted in an Inspector General (IG) investigation and subsequent lawsuit. One of the results of the lawsuit, was that NASA was the only outside entity that could communicate with the second contractor. As USA personnel became familiar with the inner workings of the HPA during troubleshooting and repair work, numerous inconsistencies and errors were noticed in the documentation and poor product workmanship was clearly evident. NASA did work with the second contractor to procure additional documentation, but in many cases, accuracy was still an issue. As more of the HPAs were produced and placed into service, reliability issues became evident and steadily worsened over time. Within the first few years, the AC Bias and 24V Modules required modification to resolve design flaws, and with the deficient documentation, troubleshooting and repair was challenging. Additionally, the development of corrective modifications required reverse-engineering of the HPA circuits. With approximately 200 HIMs\/HPAs supporting operations in the field at KSC (Pads, Mobile Launch Platforms, Obiter Processing Facilities, Hypergol Maintenance Facility, etc.), coupled with the size and weight (90#) of the HPAs, this quickly became a significant maintenance issue. In addition, the \u2018pedigree\u2019 of the HPAs became a major concern given its role as part of the Crit 1S HIM subsystem used in direct support of launch and other hazardous operations. On 10\/16\/2003 alarms were reported from OPF room 1113. Heavy smoke was spewing from the HPA in HIM 8141A3. The responding fire crew reported flames in the air vents inside the HPA. Power was secured to all 14 HIMs in room 1113 and dry chemical was used to extinguish the fire. Due to the quick response of the fire crew, damage was limited to the HPA in 8141A3, although the adjacent HIMs did receive dry chemical overspray and had to be cleaned. A Flash Report (005017) was initiated for the incident. After the HPA was removed and inspected, extensive damage to the 5V Module was evident, and to the adjacent +\/-12V Module due to its proximity. The HPA was sent to NASA Failure Analysis to determine the root cause (Job# KSC-MSL-2003-0494-00-00). The root cause was determined to be the fuse and thermal cutoff switch for the 5V Module failing to trip prior to excessive current and heat buildup on the PC board. The specifics of this event were summarized in IPB 04-004-I on 12\/1\/03. A two-pronged approach was developed to address this safety concern. The immediate effort was titled the \u2018Safety\u2019 mod and addressed the specific failure mode on the 5V Module, resulting in an immediate workmanship inspection\/PM of the HPAs. This modification began in early 2004 and was completed in August 2004. The long-term solution was titled the \u2018Reliability\u2019 mod that re-designed the 5V Module, as it was responsible for over 80% of the HPA failures. This task was formally funded as an FY05\/06 LSE task (DP KSC-537) in October 2004 and implementation began in June 2005. No further HPA incidents occurred and once these modifications were implemented, the failure rate decreased significantly and was no longer a concern for the Launch Processing System (LPS).","Lesson ID":3041}
{"Driving Event":"Pump Operation\/Requirements: As a result of risk analyses performed on the pumps, several pump requirements were changed and pump operations were improved. Vibration analysis is now performed each time the pumps are operated During start-up and through pump start, the K5 solenoid valve (pump #1 bleed) is now left open to bleed any entrained gas from the pump #1 impeller. Minimum flow rate requirements through the pumps were instituted. Nominal flow rates, pressures, and current limits were instituted. Minimum storage tank pressures are now maintained to prevent pump cavitations during operation, which can result from low head pressure. A specialized contactor was added that is wired in to a programmable logic controller (PLC). All functions for the pump and its related hardware are controlled by the PLC, including start-up and shutdown specifications and programmed automatic shutdowns. A thermocouple was added in a drywell to monitor bearing temperature and thermal cutout was transferred to the PLC. Pump maintenance will be performed after 150 hours of run time. Pumps will be removed from the system and inspected for any off-nominal wear on the bearings and journals. Bearings will be replaced when pumps are rebuilt. The following electrical tests were instituted prior to installation and after each rebuild: grounding of all phases, phase imbalance, and resistance between phases. Technicians are required to be out of line of sight of the pumps during start-up and run time. Technicians will return to safe the area after the fluid distribution system is inspected. All of the above was performed\/instituted to improve safety and reliability of the hypergolic servicing pumps.","Lesson ID":3576}
{"Driving Event":"At the beginning of the Space Shuttle Program, most Shuttle\/Orbiter mechanical LRUs were returned to the OEMs for failure analysis and repair. Consequently, no intermediate or depot maintenance documentation was created for or made available to the Shuttle operators at KSC for mechanical hardware such as actuators and power drive units (PDUs). However, when many of the OEMs stopped supporting the Shuttle Program, the need for intermediate and depot maintenance documentation was evident. This resulted in a tremendous effort to establish locally available repair and refurbishment procedures rather than negotiating fixes with the OEMs case by case. A family of Intermediate and Depot Maintenance Manuals (IDMMs) was prepared for all of the Orbiter mechanical LRUs.","Lesson ID":3558}
{"Driving Event":"The design, development, and sustaining support of Launch Processing System (LPS) application software for the Space Shuttle Program is the driving event behind this lesson. During the later years of the Space Shuttle Program, the NASA Administrator directed that each Center's software development projects would be required to obtain a Capability Maturity Model (CMM) Level 3 rating or higher. Implementation of the CMM process for LPS software at KSC resulted in the selection and use of software metrics to provide data on project progress or status. This data was provided, for example, during regularly scheduled project management reviews. However, the selection and use of these metrics changed over time as a result of lessons learned and insight gained from experience. \"Non-value-added\" metrics were discontinued, as resources were required to collect, interpret, and report them, yet they provided no help in proactively managing the project. In this way, the use of metrics was essentially refined by trial and error.","Lesson ID":3556}
{"Driving Event":"The legacy (manual) methods for managing the implementation of software requirements for the Space Shuttle Program have had a major impact on cost and schedule over the entire software development life cycle.","Lesson ID":3377}
{"Driving Event":"During the early days of the Space Shuttle Orbiter processing, human traffic into and out of the Orbiter crew cabin was extensive. The Orbiter was a new spacecraft and equipment failures (both flight and ground) were frequent, requiring removal and replacement of many of the mid-deck avionics LRUs. The long testing hours associated with the required troubleshooting necessitated frequent ingress and egress to the Orbiter crew cabin. One notable problem occurred on January 20, 1984, when one of the GPCs failed on Orbiter Vehicle OV-099 during a DPS functional test. Subsequent troubleshooting revealed that both air inlet passages were blocked by lint and debris. The lint and debris was analyzed and found to be 90-percent fibers, typical of the lint generated by cotton fabrics used onboard the Orbiter. The analysis also found that 10-percent of the debris was particulate, containing shards of Teflon, paint chips of Koropon, aluminum chips, and epoxy and silica particulates. These blocked air inlet passages caused the GPC CPU to overheat. This failure scenario was replicated on the bench by the GPC vendor, IBM.","Lesson ID":3356}
{"Driving Event":"The Space Shuttle Orbiter Fuel Cell Systems as originally designed and developed lacked critical downlinked instrumentation that provided the health and status of each individual cell (96 cells per fuel cell, 3 fuel cells per ship set). An improvement modification was made early in the program to add a Cell Performance Monitor (CPM) to each fuel cell. The CPM provides a comparison voltage between 16-cell half-stacks for each 32-cell substack (three 32-cell substacks per fuel cell). During the STS-83 mission, one of the fuel cells exhibited a degraded substack 3 (CPM channel 3) voltage measurement, having a steady slope toward the CPM limit of 150 millivolts. Due to limited instrumentation (i.e., the ability to monitor the 96 individual cell-voltages), the abnormal readings were interpreted as a worst-case scenario, the failure of a single cell. The fuel cell was to shut down and \"safed\" approximately 48 hours into the flight, requiring the mission to be terminated early. After the early termination of STS-83, the Program designed and tested a fuel-cell monitoring system (FCMS). This system finally provided individual cell-health monitoring capability. If the FCMS had been available for STS-83, it may have precluded the shutdown of the fuel cell and may have allowed the mission to complete its planned duration.","Lesson ID":3339}
{"Driving Event":"Early in the Shuttle Program, as contamination control was being recognized as a \u201dsystem,\u201d OMRSD requirements were created for the OPF high bays. OMRSD requirements included specific temperature, relative humidity, and airborne particulate ranges that, if exceeded, resulted in an OMRSD violation. However, the normal processing activities within the OPF high bays caused temporary out-of-specification environmental conditions that resulted in OMRSD violations numerous times during every Orbiter processing flow. Examples include opening facility doors to the outside environment for hardware entry, applying waterproofing on tiles, operating overhead cranes, etc. Consequently, contamination control engineering was processing problem reports and waivers and\/or exceptions to the OMRSD requirements for every mission. Eventually, it was realized that the normal Orbiter processing activities were not causing any obvious detriment to the vehicle from a contamination perspective, and therefore, the facility OMRSD requirements were no longer warranted. In addition, these OMRSD requirements were considered unrealistic for the type of operational activities needed to process the Orbiter. Where possible, mitigation efforts were implemented to help reduce the generation or emission of contamination within the facility during certain operational activities (such as the incorporation of a captive air vent system that vented fumes from vacuum pumps and hydraulic aspirators outside of the facility).","Lesson ID":3336}
{"Driving Event":"During design efforts for a project at Vandenberg Air Force Base (VAFB) in Lompoc, CA, Best core locksets were designated for use. The Best core locksets are currently in use across the Kennedy Space Center (the center in charge of the design effort at VAFB). During construction, the Best core locksets were installed. After construction was completed, the users at VAFB realized that the locksets were incompatible with the Schlage 6 pin core lockset in use at VAFB and requested the base change the lockset. This effort to replace the locksets has been slow, and there has been discussion about using outside vendors to expedite the replacement of the Best locksets.","Lesson ID":3316}
{"Driving Event":"NASA\/SSC Facility Operating Services Contractor (FOSC) contracted with the roofing contractor to repair through replacement Hurricane Katrina damage to B 1201 roof. The prime contractor then subcontracted the work to a sub-tier contractor, notifying the FOSC of his action. The sub-tier contractor further subcontracted the work to a third-tier subcontractor; FOSC was not notified of this last action. FOSC was not aware of a third-tier contractor on site as the workers' information for access badges was provided as though they were the second-tier contractor's labor force. Contractual and notification information that normally flows to sub-tier contractors did not reach the third-tier contractor. The third-tier contractor did not know to notify FOSC of the anomalous condition at the roof site.","Lesson ID":4236}
{"Driving Event":"Anti-static bags-- plastic envelopes coated with a metallic film-- are used to ship electronic parts and assemblies that are prone to damage from electrostatic discharge (ESD). After the shipped items are received, they are often stored in the bags for protection against ESD damage incidental to handling. A digital processing circuit board, destined for use as flight equipment for the Gravity Recovery and Interior Laboratory (GRAIL) project, failed the initial power-on test procedure during assembly functional testing at the NASA\/Caltech Jet Propulsion Laboratory (JPL). A visual inspection (Reference (1)) revealed that a fine piece of copper wire debris, similar to No. 2 solder braid, had created a short circuit (Figure 1) from a memory pin to an adjacent data pin (Reference (2)). Since the test was conducted in a clean room, the contamination is believed to have resulted from placing the board into a quotusedquot anti-static bag for storage. It has been documented (Reference (3)) that anti-static bags are frequently reused in JPL shops and labs and may accumulate rosin and other contaminants. Figure 1. Arrow indicates location and approximate size of copper debris Analysis determined that the stress to the components resulting from the short was minimal. However, because the data pin connects to a field-programmable gate array (FPGA) and a microprocessor, the short could instead have caused mission-critical latent damage to these components. Following this incident, the GRAIL project banned the reuse of anti-static bags and purchased a supply of new anti-static bags. References: Conductive debris on FM103, JPL Problem\/Failure Report No. 15446, September 21, 2009. PFR 15446 - MMFL16016604S-C-MS Stress and Risk Mitigation, JPL IOM 335-JAD-20091015-016, October 15, 2009. Manufacturing Processes and Procedures for Assembly and Wiring of Electronic Equipment and Assemblies, Revision I, JPL Document No. DocID 35514, July 20, 2004, p. 435.","Lesson ID":4176}
{"Driving Event":"Constraints are heavily used in Shuttle processing. A constraint is when one work item must be completed before another can be started. For example, a repair must be completed inside a cavity before the area is closed out for flight. The Space Shuttle electronic work control system automatically identifies constraints, but they are then manually entered onto the work document that needs to be held up. During Ares I-X processing a new electronic work control system, Collaborative Integrated Processing System (CIPS), was brought online and used. However, little thought was given to handling constraints. The old system was not used, and constraints were manually tracked by Planning & Scheduling with an expectation that the engineer would enter them in the electronic document later. (The electronic documents were often not released to the floor until the last day or two before they were worked). Several constraints were missed early in the Ares I-X implementation for Solid Rocket Booster (SRB) processing. The CIPS team is working on an automated method to replace the manual method.","Lesson ID":3338}
{"Driving Event":"After 11 years of spaceflight and the conclusion of a successful primary mission, the NASA\/Caltech Jet Propulsion Laboratory (JPL) discovered that the dual string Stardust\/NExT (New Exploration of Comet Tempel 1) spacecraft flight system had been flying single string. An established JPL practice (Reference (1)) is to strictly avoid in-flight switches to backup units (e.g., for aliveness checks) as long as the prime unit continues to serve mission needs. Nine months prior to the NExT spacecraft encounter with Tempel 1, however, a switch from the Side A flight system to the identical Side B flight system was commanded due to concerns that the Side A gyro laser had degraded over the 11 years. Since Side B had not been used during the spacecraft's Stardust mission or NExT extended mission, its attitude control gyro's laser was known to retain enough intensity for continuous use through the comet encounter. When the switch to the Side B flight system computer was commanded by ground controllers, an undetected timing issue between fault protection software and Safe Mode sequence commands prevented Side B from completing the cold boot from an unpowered state. Autonomous fault protection caused the flight system to dead-end on Side A, and Side A functionality was restored when the computer completed a cold start and nominal reboot. The root cause of the redundancy switching failure was a very late change (i.e., 3 weeks before launch) to the Safe Mode command file (Reference (2)). Two attitude mode commands were inserted to address a Rate Mode configuration issue identified during system-level test (ATLO). When these commands were executed during the side swap, the Attitude & Articulation Control System (AACS) mode software started issuing thruster commands before the Propulsion Valve Drive Module (PVDM) board was in nominal mode. This resulted in Data Storage Interrupt errors that triggered execution of fault protection and the dead-end on Side A. The late command change was not tested on the spacecraft as it was being integrated on the launch vehicle, opting instead to test it on the system testbed. However, the testbed simulation of the PVDM did not include simulation of redundancy switching, and therefore did not detect the failure mode during testing of the change. The failure mode was never detected in flight prior to the May 2010 side swap because it only occurs when the computer is booted from an unpowered state; except for an earlier solar flare incident (Reference (3)) that masked the side swap defect, the spacecraft had never been cold booted after the pre-launch change to the Safe Mode file. The ability of the spacecraft to switch to the secondary string (Side B) was enabled in June 2010 through uplinked changes to the onboard fault protection software. However, if the Side A flight system had failed at any time during the 11 years following launch, the unavailability of Side B would have doomed the mission. References: \"Design, Verification\/Validation and Operations Principles for Flight Systems (Design Principles),\" JPL Document D-17868, Rev. 3, December 11, 2006, Paragraph 9.4 (\"Prime\/Redundant Hardware Usage\"). \"S\/C failed to boot on Side B,\" JPL Incident Surprise Anomaly (ISA) No. 25926, May 6, 2010. [no title], JPL Incident Surprise Anomaly (ISA) No. Z70478, November 10, 2000.","Lesson ID":3716}
{"Driving Event":"Many times, blind fasteners were found to be improperly installed. One in particular was detected during the removal of a thermal carrier panel. Loss of this panel would likely result in loss of the vehicle during reentry. When this carrier panel was removed, it was found that some fasteners did not have enough threads engaged. On one fastener, only a single thread was engaged.","Lesson ID":3260}
{"Driving Event":"On May 17th, 2010 at approximately 10:00 am, the start-up battery on Generator #1 (not due to start-up) exploded for no apparent reason. This fault (root cause is unknown) has not been determined at this time however, something caused the battery shell to break leaving acid and fragmentation in the area around the generator. Technicians cleaned up the acid and washed all contaminated equipment. The service vendor was contacted immediately to remove and replace the damaged battery. There were no injuries as a result the battery failure due to the fact that no personnel were in the generator room at that time of the incident.","Lesson ID":2876}
{"Driving Event":"During a lithium-ion (Li-ion) battery test on October 20, 2009, the battery overheated, caught fire, and detonated within an enclosed steel locker in a bunker attached to a multi-story, office\/laboratory building at the NASA\/Caltech Jet Propulsion Laboratory (JPL) (References (1) and (2)). The bunker was specifically designed for the purpose of containing the effects of such a battery failure. An adjacent locker, containing an identical battery in a controlled test configuration (i.e., the control battery) began to experience sympathetic heating conditions due to the initial fire, such that a portion of it deflagrated and was partially consumed by fire. The 30V, 15Ah-rated Li-ion battery, designed as a workhorse (test) battery, was not destined for use on a specific spaceflight project. Instead, it was being tested under ambient conditions to establish performance characteristics when used with high frequency, high-current ripple, power systems typical of many low Earth orbit (LEO) spacecraft. The test batteries were placed inside sheet metal lockers, similar to a typical gym locker, with a ventilated hinged door (Figure 1). The lockers were arranged on the facility floor in sets of six, with wiring routed through an opening punched into the back of the locker (Figure 2). The incident occurred after the batteries had been under the same test setup and conditions for eighteen months and exhibiting nominal behavior. .............................. Figure 1. Battery test facility following the fire Figure 2. Close-up of metal lockers used for battery test When the battery fire erupted, smoke detectors actuated the fire alarm. The building occupants immediately evacuated the building without injury. There was no collateral fire damage because the JPL Fire Department provided a timely and effective response using a Metal-Ex fire extinguisher appropriate to dowsing a lithium fire. Because of the proximity of the battery bunker to the building ventilation air intake, smoke and toxic fumes from the combustion of Li-ion cell materials were vented into the rest of the building. The entire building was inaccessible for several days until air quality samples could be analyzed and hazardous materials remediated throughout the building. The battery fire was caused by a faulty measurement of the battery terminal voltage, sent to the support equipment that controlled battery charging and discharge, that was intermittent instead of continuous (Reference (3)). Loss of this measurement resulted in continuous charging of the test battery until the temperatures and internal pressures within the 80 small individual cells led to detonation and fire. A JPL failure investigation attributed the root cause to inadequate knowledge and training of test personnel. Contributing causes were use of faulty EGSE and inadequate battery thermal protection. A proximate cause of the contamination of adjacent facilities was the design of the facility ventilation and air intake systems. References: JPL Mishap Report No. 1984, October 21, 2009. NASA Incident Report No. S-2009-293-00007, October 20, 2009. Stephen S. Greenberg, quotJPL Investigation of the [name omitted] Lithium Ion Battery Fire - Test Failure Analysis Technical Report,quot JPL Document No. D-64869, April 2, 2010. quotJPL Standard for System Safety (JPL D-560),quot Rev. D, JPL Document No. 34880, September 17, 2007. quotProcess for Ensuring Personnel\/Facility\/Operational Safety During Research and Development Testing,quot JPL Corrective Action Notice (CAN) No. 1597, March 25, 2010. quotProcedures and Processes for the Testing and Storage of Various Type of Cells and Batteries,quot JPL Corrective Action Notice (CAN) No. 1594, March 25, 2010. quotOperation of Exhaust and Ventilation Systems to be Assessed for the Safe Exhausting of Products in the Event of a Battery Fire in Labs 277-120, 125 and B25\/26,quot JPL Corrective Action Notice (CAN) No. 1595, March 15, 2010.","Lesson ID":3516}
{"Driving Event":"Location of the check valve in the hydraulic filter module prevented ground supply pressure being applied to supply flex hose. This supply flex hose is between the filter module and the hydraulic main pump outlet. The intent of the check valve is to prevent spinning the pump during ground hydraulic testing using ground support equipment (GSE).","Lesson ID":3221}
{"Driving Event":"During Orbiter Processing Facility (OPF) open bay periods the Orbiter Maneuvering System (OMS) pod handling fixture was proof loaded to 20,000 lbs. This required extensive setup, working at heights, working with suspended loads, and the setup of safety clears for two days. The 20,000-lb weights were raised to the handling fixture and then transferred from the crane hook to the handling fixture. The load was then translated full travel path both east and west. Any type of a failure at this point would have caused extensive damage.","Lesson ID":3197}
{"Driving Event":"It was believed that outages and excursions would occur infrequently and would be addressed by waivers to the ECS requirements. The problem was that, because the ECS purge was being supplied 24 hours a day, 7 days a week for months at a time, the likelihood that a purge outage or excursion would occur increased dramatically, and numerous waivers were being written, sometimes more than once per flight. A general requirement with a broader range but a shorter time span was developed to accommodate short excursions outside the acceptable parameters for temperature, flow rate, and humidity. The general requirement also allowed short-duration purge outages as long as certain environmental conditions were met. This new general requirement was implemented in 1988 after 25 outage\/excursion waivers were generated in 1987. Initially, the general requirement addressed a limited number of purge outages and excursions; but by 2002, it encompassed all purge outages and excursions.","Lesson ID":3157}
{"Driving Event":"The rotator is part of a lifting fixture used during OMS pod installation or removal. The 73D010016-1003 OMS pod rotator was bent on three occasions: In 1991, the rotator was overdriven against the Orbiter deck, causing the screw shaft to bend. In 1992, the rotator was overdriven against the hydraset, causing the screw shaft to bend. In 2004, the lifting-fixture jack screws were overdriven against the rotator, causing the screw shaft to bend.","Lesson ID":3116}
{"Driving Event":"In addition to soliciting lesson learned throughout the program and project life cycle, the NASA\/Caltech Jet Propulsion Laboratory (JPL) has established a practice of collecting project lessons learned at system-level technical reviews of flight projects-- major project milestones. Launched on December 14, 2009, the Wide-Field Infrared Survey Explorer (WISE) carries an infrared-sensitive telescope that will image the entire sky, creating a cosmic clearinghouse of hundreds of millions of objects throughout the universe. The JPL project conducted a Post Launch Assessment Review (PLAR) on January 26, 2010 during which the lessons learned from the 4-month WISE launch campaign (August 14 - December 14, 2009) were discussed in detail. The PLAR (Reference (1)) characterized the WISE launch campaign as very successful despite some major challenges. This success was attributed partly to the WISE project's decision to initiate detailed planning of launch campaign operations at Vandenberg Air Force Base (VAFB) more than a year before launch. This proved necessary because WISE launch operations were faced with the unusual challenge of safely operating the cryogenic payload involving large quantities of hazardous liquid\/solid hydrogen and gaseous\/liquid helium. In addition, the extra time was needed because commercial and military customers were sometimes given a higher priority at the launch site and because the advertised launch facility resources available to the WISE project did not always prove adequate. WISE had time to identify and resolve well ahead of time potentially launch-delaying issues, such as inadequacies in ground support equipment (GSE) resources, scaffolding for cryogen processing (Figure 1), launch pad workspace\/access (Figure 2), and hydrogen supply dewar storage. The extensive WISE launch campaign preparations permitted the Spacecraft Team and Payload Team to respond successfully to unplanned external events-- a wildfire at VAFB, temperature and relative humidity excursions caused by an air-conditioning unit malfunction in the Payload Processing Facility (PPF), and an extended power outage on the launch pad. Even with the full year of launch preparations, these teams still exploited a delay from the original November 1, 2009 launch date to perform risk reduction tasks. The launch delay was related to the availability of the Western Test Range (VAFB) and the readiness of the Delta II launch vehicle. .............................. Figure 1. New scaffolding built for WISE cryogen operations in the PPF. (Available scaffolding did not prove sufficiently robust once potentially hazardous 24\/7 cryogen operations began.) Figure 2. Cryogen operations on the launch pad are also conducted 24\/7, and last-minute problems cropped up related to GSE access and workspace limitations. A number of observations may be drawn from the PLAR that are generally applicable to launch campaigns for robotic, as well as crewed, spacecraft missions. Once the spacecraft arrives at the launch facility, the project manager may be chiefly concerned with: Overall schedule and contingencies, Major decisions and mission risk assessment, and Facility health. Launch preparations took place in an environment that changed rapidly and continually, often beyond the WISE Project Manager's control. However, close attention to the following management considerations helped the WISE project achieve the desired on-site team performance: Mitigate the risks of extended operations. The 4-month extended WISE launch campaign was dominated and complicated by the 24\/7 hazardous cryogenic operations, which required an adequately staffed team that was trained to operate safely and to respond to contingencies. The spacecraft and payload teams did not expect the launch facilities to always perform as needed; they prepared a contingency plan and practiced the planned responses. Launch-on-time risks were managed separately from mission risks. The WISE project held repeated sessions to practice countdown procedures. Actively manage uncertainties. Launch campaign uncertainties included the launch vehicle availability and readiness, work rules, and personnel availability. Having key JPL specialists (e.g., dynamicists) available to provide a second opinion proved invaluable in resolving conflicts between the flight project and VAFB, NASA Kennedy Space Center, and contractor launch support personnel involving launch facility problems that could affect payload safety. Nevertheless, the most significant uncertainty that drives a need for contingency planning may often be the launch weather (Figure 3). Figure 3. Adverse weather predicted for the launch location and time presents a risk for which no mitigations may be practical, but contingency planning is essential. Manage logistic challenges. Staff resources were assigned in advance by the WISE project to meet unanticipated logistic challenges arising shortly before launch. For example, console seating and other facility resources were needed for the media and JPL project management, but other project staff and their families and friends also participated in activities at VAFB in the days prior to launch. Other last-minute logistic needs include coordinating with Range security, United Launch Alliance, KSC, and JPL; a photo-op event at tower roll-back for WISE team members, their family, and friends (Figure 4); promptly disseminating launch delay status to all team members on console; etc. Figure 4. VAFB visitors during tower rollback at 11:00 pm on L-1 day Anticipate differences in culture and engineering practices. Both the launch vehicle processing personnel and the flight project personnel responsible for the payload being processed, constitute a launch team that promotes the successful execution of the spaceflight mission during a risky phase of the mission. Anticipate that the launch vehicle processing staff will have a different approach to evaluating risks and solving problems than the flight project personnel. Because of the launch operations (Figure 5) time frame, for example, launch personnel place greater reliance on analysis than on simulation and test. On-site WISE flight project representatives maintained vigilance and insight into launch campaign developments to identify off-nominal performance that may have indicated emerging technical issues. JPL technical divisions provided analytical help, as requested by the project, to further evaluate launch risk. Figure 5. Installation of the Delta II payload fairing around WISE in the White Room at VAFB Space Launch Complex 2 Establish organizational and person-to-person communication. As the WISE launch campaign involved multiple contractor and NASA organizations, as well as the U.S. Air Force, it was important to maintain daily communications with all personnel across the organizations. Specifically, each key decision was communicated to everyone on the floor and supporting the overall mission, with care given to dispelling rumors. Manage launch anxiety. There was a noticeable increase in personnel edginess as the WISE launch date approached. In this environment, it became essential to ensure that personnel interactions remained professional at all times. One anxiety-reducing measure was to assure that each team member in a key position had a backup team member assigned. The team members were cross trained to be able to fill in for each other as needed. WISE encountered last-minute problems as anticipated-- a Delta-II second stage tank 'dimple', spacecraft telemetry indicating jumps in inertial measurement unit (IMU) and reaction wheel rates, and a Delta-II vernier engine slew rate anomaly-- but the launch preparations proved adequate to assure a successful launch. References: Fengchuan Liu, quotWISE Launch Campaign Performance and Lessons Learned,quot JPL presentation, January 26, 2010.","Lesson ID":3496}
{"Driving Event":"The Main Propulsion System (MPS) for the Space Shuttle consists of the three Space Shuttle Main Engines (SSMEs) and the fluid lines and components that connect the SSMEs to the External Tank and the ground systems. During the Flight Readiness Firing (FRF) of the orbiter Challenger, OV-099, at KSC before its first flight, the Hazardous Gas Detection System (HGDS) detected a massive hydrogen concentration spike while the SSMEs were running. This leak was large enough to exceed the flammability limits established for the orbiter\u2019s aft compartment during flight. STS-6, Challenger's first flight, was put on hold until the source of the leak was found and the leak corrected. The Helium Signature Test, initially developed to find the source of this leak, works by pressurizing the MPS propellant systems with helium and sampling the aft fuselage atmosphere using the HGDS. Any helium leaking from the MPS would mix with the air in the aft fuselage and be detected as an increase in the helium concentration in the aft fuselage. By measuring this change in helium concentration and knowing the air purge flow rate for the aft fuselage, a total system leak rate can be calculated in standard cubic inches per minute (scim). The Helium Signature Test was later refined to be an important preflight leak test.","Lesson ID":3177}
{"Driving Event":"The value of closeout photos was discovered during the Columbia accident investigation, but the limited coverage and image quality of the photos left a lot of unknowns. Figure 1: Photo taken to document inspection of the Space Shuttle for the STS-127 Mission","Lesson ID":3202}
{"Driving Event":"Dynatube sealing surface defects and subsequent polishing from multiple disconnections\/connections resulted in the need for a mitigation technique to prevent surface defects.","Lesson ID":3220}
{"Driving Event":"After its September 2007 launch, the Dawn spacecraft employed a solar-powered ion propulsion system (IPS) to gain the additional velocity needed to reach Vesta and Ceres, and it will use the IPS to spiral to a low altitude orbit around these asteroids. Compared to chemical rockets, ion engines make very efficient use of onboard fuel because the propulsive energy is derived from the sun. Solar electric propulsion (SEP) technology for navigation beyond Earth orbit was successfully demonstrated from 1998 to 2001 by the Deep Space 1 (DS1) mission, and Dawn planned to use the same IPS design (Figures 1 and 2). .................... Figure 1. Deep Space 1 is lifted from its work platform at NASA Kennedy Space Center, providing a close view of the IPS Figure 2. Hot fire test of the Deep Space 1 IPS The development of the Dawn IPS by the NASA\/Caltech Jet Propulsion Laboratory (JPL) proved much more difficult and expensive than expected. The principal unanticipated problem was a degraded ability to manufacture the DS1-legacy components, principally the ion thrusters and the Power Processor Units (PPUs) (References (1) and (2)). The inherited DS1 components had evolved through informal engineering processes more typical of experiments than development of configuration-controlled flight hardware. Although the Dawn IPS contractor for the ion thrusters and PPUs was the same company that had built the DS1 hardware, and the Dawn thrusters and PPUs were proposed as build-to-print copies of the DS1 designs, the contractor encountered significant management and process problems in delivering the Dawn flight hardware. The contractor problems, which likely were exacerbated by the 6-year lag between these two projects, included: JPL efforts to negotiate a fixed-price or incentive-based contract with the Dawn IPS contractor failed. The resultant cost-plus-fixed-fee contract was overrun by almost 100 percent, and the flight hardware was delivered 8 months late. The Dawn IPS contractor for the ion thrusters believed it could reproduce the assembly processes for the DS1 thrusters, but major cost escalation during fabrication, assembly, and testing of the Dawn IPS revealed that the time lag between the two projects had degraded their capabilities. Also, the vendor that fabricated the DS1 ion thruster plasma screen was no longer in business, and the vendor that performed chem-etching of the DS1 thruster grids did not bid on the Dawn thruster grids. No shock testing of the DS1 thruster had been performed except at the less critical spacecraft level. The DS1 PPU assembly procedures and other information needed to reproduce the hardware had not been adequately documented or retained. Over the 2-1\/2 years of the Dawn IPS build, the IPS contractor for the ion thrusters and PPUs cycled through four general managers and four Electric Propulsion department managers. Each upper-level manager in the contractor's corporate unit was fully aware of a pending sale of the unit by the parent company. These managers were motivated to please their parent company's customers, and there were frequent delays due to reassignment of Dawn resources to these other projects. A total of 40 IPS component and subsystem design reviews, plus the hardware reviews, produced a huge number of action items-- 630. The number would have been more manageable had the required documents-- technical requirements documents (TRDs), interface control drawings (ICDs), mechanical interface control drawings (MICDs)-- been completed on time. The Dawn IPS interface with the spacecraft was complex. Assembly, Test, and Launch Operations (ATLO, aka spacecraft Integration & Test) was delayed pending receipt and installation of the thermal hardware because responsibility for thermal hardware (e.g., heaters, blankets, and platinum resistance thermometers (PRTs)) attached to the IPS components was divided between JPL and the Dawn spacecraft system contractor. Two test-as-you-fly exceptions went undetected prior to launch and were only identified because of problems encountered during the initial spacecraft checkout activities. The latch valve masking should have been installed for the second phase of spacecraft thermal-vacuum testing, and a gimbal problem was not identified due to insufficient testing of the gimbals with the spacecraft prior to launch. These management problems affecting the Dawn IPS development were accompanied by many IPS design implementation, fabrication, and test technical problems with the ion thrusters, grids, cathode magnets, PPUs, digital control and interface units (DCIUs), xenon tank (Reference (3)), and xenon feed system (XFS). References: John Brophy, quotDawn IPS Lessons Learnedquot presentation, December 4, 2007. John Brophy, quotDAWN Ion Propulsion System: Project Element Manager's Report on the Development of the Dawn Ion Propulsion System,quot JPL Document No. D-41251, May 29, 2008. quotCOPV Propellant Tank Failure on the Dawn Spacecraft,quot NASA Lesson Learned No. 1777, NASA Engineering Network, March 7, 2007. https:\/\/llis.nasa.gov\/lesson\/1777 quotInterface Control and Verification,quot NASA Lesson Learned No. 0569, NASA Engineering Network, October 9, 1997. https:\/\/llis.nasa.gov\/lesson\/569","Lesson ID":3396}
{"Driving Event":"The Cassini-Huygens spacecraft's four-year initial tour of the Saturnian system that ended in July 2008 was an extremely ambitious and successful mission. The spacecraft (Figures 1 and 2) stood 22 ft. in height, weighed over 2 tons (6 tons with fuel), and carried 12 instruments (plus another 6 in the Huygens probe) capable of gathering high quality science data. Mission operations (ops) was accomplished by a 500-person team located across the U.S. and 18 other countries, and involved over 16 sub-teams, 9 time zones, and information exchange limitations mandated by International Traffic in Arms Regulations (ITAR) (Reference (1)). ................. Figure 1. The Cassini spacecraft (minus-Y side) Figure 2. The Cassini spacecraft (plus-Y side) The ability of Cassini-Huygens to maximize science data return from this wealth of instrumentation was constrained by the extreme complexity of the mission (Reference (2)): Figure 3. Cassini remote science operations (from Reference (2)). The 12 science teams are located across the country and in England and Germany. Cassini spacecraft. With the high precision scan platform deleted from the final design as a cost-saving measure, the instruments had to be fixed-mounted to the body of the spacecraft. This complicated ops by introducing pointing incompatibilities between instruments, and it required the entire spacecraft to point toward science targets and then point back to Earth to transmit the science data and receive commands. Other spacecraft resource limitations that impacted ops included the need to actively manage the limited power available for the instruments, constantly manage telemetry rates due to limited onboard data storage capacity for science data and commands, and increase ground management of reaction wheel resources when lifespan issues arose. To develop, check, and validate the integrated science and engineering command sequences, the Cassini project used a variety of tools, including essential ad hoc tools developed by the science planning team to effectively check and validate plans and to identify conflicts among shared spacecraft resources. Planning for science opportunities. Many labor-years were required to develop the command sequences that would permit the precise (yet adjustable) timing of unique observations, plus special observations such as crossing the plane of Saturn's rings and the flyby of Titan. This advance planning was further complicated by the widely distributed locations of instrument teams and instrument operations centers (Figure 3). Also, there was an intense competition between scientists for both allocation of available observing time and control of pointing when unique observation opportunities conflicted. Extensive ground software was needed to validate command sequences and enforce complex flight rules for the protection of sensors, instruments, and consumables. To preserve the overall science plan and mitigate reintegration due to observation timing changes that can result over an extended period, the Cassini project developed special sequence constructs, flight system capabilities, and special ground processes, such as ground moveable blocks, live movable blocks, and live updates, to improve the flexibility and adaptability of the science sequences. Communications challenges. Uplink and downlink availability and data volume were limited by the need to point away from Earth to make science observations. Because Cassini operated in the outer solar system, it also could not fully exploit each pass because of the one-way light time that exceeded one hour. (For example, when uplinking commands, a portion of the communication window was consumed by the delays awaiting message confirmation.) The Cassini project implemented data policing measures to manage data volume, enforce allocations, and protect critical data against transmission failures. Distributed operations. The training and qualification of ops personnel were complicated by the geographical dispersion of the instrument teams. Also, with the instruments hard-mounted to the spacecraft, instrument operators had to be cross-trained in sequence development as spacecraft operators. Each instrument team had to be familiarized with the range of actions that could harm neighboring instruments or degrade their science data. Providing worldwide access to the evolving science plan across time zones and within ITAR restrictions required sophisticated and costly information solutions. The need to provide functionality to the distributed ops sites, as well as at JPL, resulted in ground system redundancy and complex interfaces that inhibited development and update of the ops system. To enable distributed operations, Cassini invested several million dollars on developing the Cassini Information Management System (CIMS), a web-based interface to the Cassini planning and sequencing database providing the science instruments and flight team with immediate access to the evolving science and engineering plan. Mission Operations System (MOS). Development of the Cassini ground system was spread out over 10 years and was not completed until well after launch. Deferred funding also delayed the training of ops personnel and the acquisition of needed tools. Before a typical 40-day Cassini sequence could be uplinked, all the detailed science and engineering commands for the sequence had to be planned, developed, integrated, and validated for the shared spacecraft subsystems-- a lengthy and highly iterative process. The ops impact of requirements changes caused by deletion of the scan platform was not fully understood until years after the design change; this was due to the fact that no project resources were applied to planning software development during Phase C\/D to evaluate the ground and flight system requirements and capabilities. The need to add additional capabilities in support of ops during the tour was constrained by further cuts after Saturn encounter that reduced staffing of the development team. The Automated Sequence Processor (ASP) tool was developed to give the science instrument teams the ability to uplink internal instrument commands while sequences are executing without involving the JPL ops team. This was feasible because of the design of the CDS flight software and because most instruments had significant internal memory to store their command sequences. The Cassini project implemented a range of flight system, ground system, and programmatic measures for mitigating these challenges to meeting science return requirements of the mission (Reference (3)). These included implementation of complex commanding constructs and compensation for inadequate spacecraft resources with additional ground resources. References: quotActively Manage Flight Project Risks During the Mission Operations Phase,quot NASA Lesson Learned No. 1411, NASA Engineering Network, February 1, 2003. Brian G. Paczkowski, JPL presentation on quotManaging Complexity to Maximize Science Return: Science Planning Lessons Learned from Cassini,quot February 19, 2010. Brian G. Paczkowski, Barbara Larsen, and Trina Ray, quotManaging Complexity to Maximize Science Return: Science Planning Lessons Learned from Cassini,quot IEEE Aerospace Conference, March 2009, pp. 9-11.","Lesson ID":3436}
{"Driving Event":"As a result of a hardware failure in the KSC facility power system on 2 April 1990, it was realized that the potential existed for a total loss of the LPS. It was determined that a loss of LPS after T-31 seconds would result in unfavorable vehicle configuration: Overboard LOX bleed valve PV19 closed. This configuration requires that the LOX drain be established within 9 minutes or a catastrophic LOX feedline geyser could occur. Because of the LPS power loss, a normal LOX system drain could not be performed via hardwire safing switches. Specifically, the helium transfer line purge could not be turned on prior to drain flow being initiated into the empty tail service mast because no hardwire safing switch for that purge existed. A plan to activate the purge at T-1:20 was agreed upon, and a procedural change was implemented to the S1003 procedure. Because of late discovery of this issue, the new procedure was not verified against the math model.","Lesson ID":2816}
{"Driving Event":"After years of use and improvements, to both the hardware and the related departmental internal processes (testing, repair, and certification), PMS had matured, realizing a high degree of reliability. The main reason to replace PMS with GMS was to eliminate its limited resolution and minor susceptibility to ground-induced noise. The new GMS design also opened the potential for a shared technology initiative to work with private industry.","Lesson ID":2956}
{"Driving Event":"At approximately 0200 on January 11, 2010, a GHe relief valve in Orbiter Processing Facility (OPF) High Bay 3 relieved due to a failed regulator in the Forward Reaction Control System (FRCS) monomethylhydrazine (MMH) ground servicing panel. GHe vented to the atmosphere for approximately 13 hours before the leak was found and isolated. The cost of the GHe loss alone was approximately $50,000.","Lesson ID":2976}
{"Driving Event":"During return-to-flight processing for STS-26R, STS-27R, and STS-28R in the late 1980s, a huge number of Thermal Control System (TCS) components were removed from each vehicle. During this time, the misreading of part IDs resulted in numerous problem reports, time-consuming paperwork, and lost man-hours to correct the discrepancies. This occurred in 10 to 20 percent of all TCS removals. To deal with this problem, in 1989 the TCS tracking system was put into use under the Shuttle Processing Data Management System II (SPDMS2). It was enhanced in 1992 to support the first Orbiter Maintenance Downtime Period (OMDP) for the Shuttle Orbiter Discovery (OV-103) at KSC and reduced processing rates to 33 TCS blankets in 15 minutes, with a program savings estimated at $90K per flow. In 2006, a conversion from the LSOC1 program to Oracle brought many more enhanced features. This upgrade was a catalyst for improving the tracking and status features of other systems, such as the Carrier Panel Tracking System. This single program greatly enhanced processing of over 35,000 parts in the TCS inventory, both in the vehicles and in Logistics. The bar coding of parts and their locations prior to removal saves time and money and is a user-friendly system for shop employees, planner\/schedulers, and managers.","Lesson ID":3016}
{"Driving Event":"There were several major implications as the result of not providing better diagnostic test capability internal and external to the LRU such as: A failure during system functional testing normally required personnel and equipment to enter the orbiter to isolate the failure. The inability of the LRU to provide fault isolation capability had several consequences: Major impact to flight processing schedule to access the LRU for fault isolation. There were areas that were not accessible while fully integrated to the external tank (vertically stacked) and required the orbiter to be de-stacked to isolate the cause of the failure. Minor impacts to flight processing schedules to access an area closed out for flight to perform LRU fault isolation. Limited or no option to accept a failure for flight (Accepted Risk) without performing on vehicle testing. Intrusive on vehicle fault isolation resulted in many instances of collateral damage to flight hardware. Functional testing of internal LRU circuitry required connection of Ground Support Equipment (GSE). The following issues resulted from this method: Installation of GSE resulted in many instances of collateral damage to GSE and flight hardware. GSE adds a potential failure mode for the LRU testing. GSE was the cause of many LRU testing failures and resulted in extensive troubleshooting to isolate the failure to the GSE.","Lesson ID":2916}
{"Driving Event":"Flight processing time could have been reduced if individual wire identification sleeves had been applied to each wire. The use of wire identifications (IDs) would have helped in the following areas. Wire Damage: Damage to wiring occurred during wire harness installation or as the result of collateral damage from work being performed in the area. ARES I-X had long wire harness runs; therefore, the primary method to address wire damage was to repair in place because of the time and manpower required for wire replacement. The repair option was hindered by not having wire IDs. Wire repairs in some cases were intrusive and required electrical checkout post repair (continuity, isolation, hipot testing, and functional retest). The wire function would have to be determined and required one of the following: Trace the wire to a downline connector. The wire harnesses were helicoiled and made tracing the wire to a connector termination point. Continuity checks to determine the function of a damaged wire. Multiple connectors would have to be demated for this check and in some cases this invalidated previous functional flight tests or required access to areas already closed out for flight. This method could result in impacts to ground processing milestones. Connector Rework: The wire harnesses were fabricated in accordance with engineering drawings but there were many cases where the wires were improperly pinned by errors in the design drawings. Wire IDs would have aided in the repining process. Wire Safing: A damaged wire that had the potential to short to ground or another wire would result in vehicle power down until the wire function could be determined. The wire short could result in damage to flight electrical components. This resulted in an impact to ground testing to electrically safe the damaged wire.","Lesson ID":2917}
{"Driving Event":"During return-to-flight processing after the Columbia accident, the Orbiter Boom Sensor System (OBSS) was added to allow on-orbit inspection of the Thermal Protection System. The boom is supported by an MPM on the starboard side of the payload bay that deploys and stows the boom. A similar MPM is also used to support the Remote Manipulator System (RMS) on the port side. New hardware for the starboard MPM was manufactured and sent to KSC. There were some design changes and tighter tolerances levied on the new hardware to increase the margins. The drive linkage over-center stop bolt had to be set so that there was a 0.026 +\/- 0.001 inch gap when the linkage was on-center. The activation points of the limit switches also had to be adjusted within a few thousandths of an inch. In order to accomplish this, instrumentation (strain gauges) had to be used during the adjustment process to be able to accurately determine the on-center position of the linkage. Some special tooling was also developed by the tooling\/shop aid design group to assist in taking the measurements. The mechanisms engineering team spent months bench rigging and installing the hardware and had numerous issues during the process. Also, during some of the first flights, there were in-flight problems with the performance of the limit switches.","Lesson ID":2837}
{"Driving Event":"The failure of one of the jackscrews used to raise and lower the gaseous oxygen (GOX) vent hood was traced to wear of the drive nut threads. This wear caused the threads to strip under use and allowed the hood to fall to its lowered position during raising operations. The cause of the wear was traced to the keyed shaft, coupled with a bend in the shaft itself that allowed the keyway to function as a lathe and remove a portion of the threads with each traverse of the shaft through the drive nut. The wear of the drive nut or the straightness of the shaft were not checked regularly, and there were no instructions to do so. The use of a keyed shaft also added to the accelerated wear observed.","Lesson ID":2896}
{"Driving Event":"During STS-121 ascent, the Xo 378 bulkhead delta-pressure transducer showed higher than normal pressure differential across the bulkhead. Following the STS-121, ground borescope inspections on FRC3 showed that TCS blankets in the FRCS module were very close to the vents, and were not installed under the Purge Vent Drain (PVD) lines. Design intent is to install the V070-361995-024 Left Hand (LH) and V070-361995-025 Right Hand (RH) Multilayer Insulated blankets (MLI) under PVD drain lines in the FRCS. The blankets contain existing cutouts and cutlines, allowing installation under these lines. When properly installed, the blankets are restrained by the PVD drain lines and cannot billow into the Xo 378 vent areas. Using templates to simulate a Xo378 vent port, TCS Engineering determined that blockage of the vent ports can occur when blankets are installed on top of the drain lines. Improper installation of the TCS blankets was determined to be the cause of the vent anomaly.","Lesson ID":2716}
{"Driving Event":"The Ground Umbilical Carrier Plate\u2019s main quick disconnect (GUCP QD), originally a two-piece casting, was modified into a one-piece casting. The difference in form\/fit\/function was thought to be minor enough that integrated testing of the QD with the overall assembly and connection with the ET hydrogen vent line would not be necessary. During STS-114 return to flight, there was significant interest in the formation of ice on umbilical interfaces. Camera views and inspection of the External Tank (ET) GH2 Vent Arm System\/GUCP revealed that vapor was leaking from the GUCP's ice suppression shroud. Observations indicated that the vapor was cryogenic liquid flash-evaporating as it contacted the air surrounding the shroud. Initially it was suspected that liquid air was forming around the umbilical, a potentially hazardous situation. After careful analysis, testing, and investigation, the cryogenic fluid was found to be liquid nitrogen, which was supplied from a heated nitrogen purge line that feeds an annular shell around the shroud. A gap at a telescoping interface on the shroud and low pressure inside the helium-purged inner section (which contacted the \u2013420 \u00b0F GUCP QD surface) allowed nitrogen to leak into the inner shroud and condense into liquid on the QD surface. This liquid then pooled on the bottom of the shroud, leaked out, and flash-evaporated. After a rigorous test program and significant analysis, the ground shroud and GUCP QD were modified to prevent the nitrogen from liquefying through insulation and to prevent the nitrogen gas purge from reaching cryogenically chilled surfaces. These modifications controlled the helium and nitrogen purges so they could be properly contained and vented.","Lesson ID":2856}
{"Driving Event":"During the Columbia accident investigation and return-to-flight processing of OV-103 for STS-114, concerns were raised about whether the environmental seals for the landing gear were being compressed adequately. An investigation revealed that the compression was less than required by the certification. One reason for this was that the seals had been compressed over time and were no longer the correct height. Moreover, the landing gear doors were not closing as far as intended in the original design. Review of the procedures from the original rigging at Palmdale and the KSC rerigging performed in the early 1990s revealed that there were problems complying with the spec. The mechanism could not be adjusted to allow the landing gear doors to be closed flush to the adjacent structure within the required 0.030 inch. This was caused by the loads applied to the doors by the environmental seals and thermal barriers around the perimeter of the doors.","Lesson ID":2838}
{"Driving Event":"The electro-mechanical actuators for several of the orbiter mechanical systems have exhibited torque output degradation over the life of the shuttle program. In some cases, even serviceable spares that had been in logistics storage showed significant degradation, despite the fact that they had not been operated and had been maintained in a controlled environment. This resulted in the need to periodically test and trend the performance of some of the actuators installed in the Orbiters, to ensure the torque output level was sufficient to operate successfully in flight. In some cases, Ground Support Equipment (GSE) had to be developed to enable the test to be done with the actuator still installed in the vehicle. It also resulted in unplanned work when the actuator needed to be replaced, and often required additional re-rigging of the system after the replacement actuator was installed. These actuators all contain torque limiters and motor clutch\/brake assemblies, which were usually the cause of torque output degradation.","Lesson ID":2839}
{"Driving Event":"The ground cooling unit was experiencing regular failures, and was consuming many engineering hours identifying and resolving problems. Also, constant vigilance was required because it was difficult for the operator to control to the desired cooling set points.","Lesson ID":2736}
{"Driving Event":"The Space Shuttle orbiter is an intricate machine, with various embedded subsystems in proximity to one another that need careful scrutiny when being refurbished for the next flight. As such, it requires extensive processing during turnaround. This causes a proportional increase in manpower and physical resources that has a direct affect on the recurring cost of the Space Shuttle.","Lesson ID":2616}
{"Driving Event":"The mechanic failed to adjust anti-torque pedals as the throttle was advanced above Flight Idle. The mishap investigation revealed there was no requirement to advance the throttle above Flight Idle for the engine wash\/dry procedure.","Lesson ID":2576}
{"Driving Event":"At the time of the mishap, the injured worker and a co-worker were removing 277\/480 volt electrical kilowatt-hour meters for calibration. The meters are associated with the building power distribution system serving Building 4400. Unfortunately, while performing the meter removal task, the affected employee installed the metal cover of a meter panel enclosure onto electrically energized knife switches located within the enclosure. This action caused an electrical short resulting in the arc flash that injured the worker and also caused damage to the meter panel assembly. The worker was not wearing the PPE gloves required to perform the task, (i.e., the worker installed the cover with bare hands.)","Lesson ID":2696}
{"Driving Event":"During the Ares 1-X Flight Test Vehicle Project the mass properties function was viewed as a reporting activity after the design activity occurred rather than reviewed as an integral part of the design process.","Lesson ID":2276}
{"Driving Event":"After the missions were conducted and the data review indicated science instrument failure, University of Iowa personnel investigated the issue and tried to recreate the problem in their laboratory. The problem manifested itself as a failed op-amp in the feedback control circuitry when the high voltage supplies were placed in vacuum and powered on. The feedback control is achieved through a resistor divider circuit on the output of the supply utilizing a 100Mohm and 100kohm resistor to provide a divide by 1000. This monitor of the output is the input of the drive controlling op-amp (the op-amp that would fail). The 100MOhm resistor was an OHMITE Maxi-Mox series resistor, which is rated for >10kV. Note: The failure never occurred on the bench in atmosphere, only during vacuum conditions. After multiple tests and a detailed review by a space flight high voltage power supply expert it was pointed out that the Maxi-Mox series resistor was hollow. This resistor uses a hollow ceramic core for the mechanical support in the resistor; the core is hollowed in order to decrease the weight of the resistor. In atmosphere there is sufficient standoff of the voltage between the two ends of the resistor; however, as the ambient pressure decreases the standoff voltage decreases and ultimately could break down. This results in the full voltage of the supply output, 2.5 kV, directly inputting into the feedback op-amp and damaging the op-amp. This failure mode was verified in testing 6 Maxi-mox resistors in vacuum, by setting up a test resistor divide network similar to the supply implementation, applying a set 2.5kV across the resistor network and measuring the voltage at the divide point. Five of the resistors arced and resulted in the full 2.5kV at the divide point. One resistor showed no indication of arcing. This was attributed to either the sealing around the core of the resistor being either very tight or very loose; the resistor either never reached the corona point or quickly pumped out past the corona point.","Lesson ID":2496}
{"Driving Event":"Mars Reconnaissance Orbiter (MRO) was launched in August 2005 with a mission to study the Martian climate, identify water-related landforms and aqueous deposits, characterize potential landing sites for Mars landers, and provide UHF relay for science data produced by these future missions. One of 6 science instruments on MRO, the High Resolution Imaging Science Experiment (HiRISE) camera, is designed to image the Martian surface at up to five times the resolution previously available. Three months after launch, a spacecraft thruster calibration activity placed the spacecraft in an attitude that caused the temperature of the HiRISE sunshade (Figures 1 and 2) to unexpectedly drop to -136 degrees C (References (1) and (2)). This exceeded its lower temperature limit of -110 degrees C. established during qualification test. Because this attitude blocks data downlink to Earth, mission controllers did not detect this anomalous condition until the calibration activity was complete and the sunshade had returned to its nominal temperature. The resulting thermal stress raised the concern of potential structural damage to the sunshade during this temperature excursion. ............. Figure 1. Diagram of HiRISE configuration Figure 2. Sunshade configuration is depicted in photo of HIRISE under construction Initial thermal analysis had predicted in-flight temperatures well within the allowable flight temperature (AFT), and the in-flight thermal performance to date had been consistent with the original thermal model. However, an investigation of the temperature excursion anomaly found that the validity of the spacecraft thermal model was compromised by two factors: Although the sunshade is always exposed to the sun during nominal operations, it was shaded during the thruster calibration activity. One of the materials in the multi-layer insulation (MLI) thermal blanket had a coefficient of thermal expansion (CTE) that was high enough for the shaded blanket to contract and contact the underlying sunshade, forming an unanticipated thermal short. Design changes had been made to the thermal blanket, but due to budget pressures the HiRISE contractor did not update the integrated spacecraft thermal model to reflect the as-built thermal blanket. Because the behavior when shaded was unexpected, and because the sunshade is always exposed to the sun during nominal operations, updating the blanket model was not considered a high priority. When the contractor subsequently updated the thermal model and ran it against the thruster calibration sequence, the results were in close agreement (within 1 degree C) with the flight actuals. A structural analysis indicated a positive stress margin for the sunshade during the event; the absence of sunshade damage is also supported by instrument telemetry and image quality that show no signs of degradation in instrument performance or thermal properties. Future maneuvers have been modified as necessary to minimize sunshade shading. References: HiRISE Sunshade Temperature Exceeded Qualification Level During Thruster Cal, JPL Incident Surprise Anomaly (ISA) No. Z87738, November 3, 2005. HiRISE Sunshade temperature Exceeded Qualification Level During Thruster Cal, JPL Problem\/Failure Report (PFR) No. Z87818, November 22, 2005.","Lesson ID":2536}
{"Driving Event":"The X-38 Program was originated in 1995 as a technology demonstrator project at the Johnson Space Center (JSC). It was quickly focused to demonstrate technology and concepts for a Crew Return Vehicle (CRV) for the International Space Station (ISS). During the course of the program, the X-38 evolved from technology demonstrator to CRV prototype to its ultimate configuration as a demonstrator that would be modified after its initial test flight into the first operational CRV. The program was in the process of issuing a prime contract for 2 \u201cbuild to print\u201d operational CRV\u2019s to follow the test flight when the program was cancelled. All work on X-38 ceased June 1, 2003. The X-38 schedule changed frequently due to the change in scope of the final spaceflight vehicle and ISS budget woes. Several significant yearly budget cuts were taken to help solve overall ISS budget problems. The X-38 program utilized a concept referred to, within the project, as \u201cbuild a little, test a little\u201d. This concept allowed the program to mitigate risk by testing technologies and concepts early in the project and then learning from both the positive and negative outcome of those tests.","Lesson ID":2596}
{"Driving Event":"Flight scripts are modules of software code used to automate many flight software development and test processes that were previously done manually and repetitively. Because flight scripts are considered to be \"development support\" software (Class D), they are not placed under configuration management (CM) control as early as mission software classified as Class C (Mission Support) or Class B (Mission-Critical). This timing may be appropriate because instituting Mission System Change Control Board (MCCB) control of the scripts too early may impede the flight system development process, but very late initiation of formal control may result in excessive software iterations and may compromise test-as-you-fly fidelity or test procedure accuracy. The solution proven on several recent spaceflight projects is to institute change management of flight scripts prior to Operational Readiness Test (ORT). The Orbiting Carbon Observatory (OCO) project found that the process of flight script development continued for too long (Reference (1)). Given the multiple script authors and the potential impact of changes, the Flight Operations Team should have been in control of the scripts prior to the start of mission rehearsals (i.e., ORT). The Mars Exploration Rover (MER) project should have placed more emphasis on management of the variety and the versions of flight scripts. Developers became accustomed to preparing scripts on their own computer, exchanging them with others, and independently making changes. Hence, the scripts that were run out of home directories were not always sourced in a dependable way to MER workstations. With different versions of scripts found on different workstations-- some of which would not work properly-- processes were not repeatable between workstations. Reference (2) may be a typical example. Because this caused operational issues for MER during Assembly, Test, and Launch Operations (ATLO, aka \"Integration & Test\"), a procedure was successfully implemented during ORTs in which these scripts were delivered to CM, installed on Mission Support Environment workstations, and notification sent to Flight Operations Team support personnel. Accordingly, procedures for the Juno (Reference (3)) and GRAIL (Reference (4)) projects place Class B, Class C, and Class D software under configuration control prior to ORTs. References: P.J. Guske, \"OCO (Orbiting Carbon Observatory) Project Lessons Learned Document (Final),\" JPL Document No. D-26172, July 7, 2009, Paragraph 3.2.5. \"Confusion with upper and lower case letters,\" JPL Problem\/Failure Report No. Z77058, August 7, 2002. \"Juno Project: Mission System Configuration Management Plan, Preliminary Release,\" JPL Document No. D-49338, September 30, 2009, Paragraph 5.6, Page 18. https:\/\/pdms.jpl.nasa.gov\/CMTOOLS\/DocProperties.aspx?objid=tjEvitaempirepdmpdsu-Wqi \"Grail Project Software Management Plan,\" JPL Document No. D-38908, October 9, 2008. http:\/\/charlie-lib.jpl.nasa.gov\/docushare\/dsweb\/Get\/Document-280353\/GRAIL_D38908_Initial_2008-10-09.doc","Lesson ID":2476}
{"Driving Event":"The Network\/Radio Frequency (RF) Compatibility Test was run to prove that the NASA ground network would work with the Hinode (Solar-B) satellite. At the time of the test, it was thought that the best way to prove the NASA ground stations would be able to communicate with the Japanese-built satellite was to use the GSFC testing equipment designed specifically for this scenario. Typically, the test racks are packed, sent to wherever the satellite is being built, and tested there. In this case, testing took place in Japan. This resulted in a number of problems: During the test preparation timeframe, it was difficult to obtain information on the status of the test. The shipment of the testing racks and power converters was coordinated very late, leading to confusion and frustration. The power converters may have played an important part in subsequent anomalies during the testing and should have been more thoroughly researched. The testing racks were antiquated, leading to difficult situations during the testing. Changes were made to the test requirements without a discussion being held with the entire group; and consequently, they did not reflect the correct Solar-B requirements. A Test Procedure Review was conducted the night before the test, and only after the MSFC Project Office insisted. The test procedures should have been placed under configuration control and followed during the testing. At the test site, the time given for configuration and verification of the test hardware was inadequate; and the racks were taken apart and re-integrated using photographs. Because there were no setup and verification procedures to follow, setup problems led to a loss of 2 days of testing time. Uplink commands for the RF Compatibility Test were not loaded beforehand for efficiency. Loading the commands during the test wasted the engineers\u2019 time. Troubleshooting during the testing did not follow standard engineering practices or another type of logic flow. During the troubleshooting, the engineers were unable to return the test racks to a known configuration because the configuration changes had not been tracked as the troubleshooting progressed. As the testing and troubleshooting progressed, and even after the testing was complete, no one accepted responsibility for the schedule delays, problems during the test, or failure of the test. After the failed test, another test was performed, this time using a flight satellite with the same transponder and telemetry system as the one being tested on the ground station. The MSFC Project Office had originally suggested this test, but it was rejected. This test was easily passed with no complications.","Lesson ID":2157}
{"Driving Event":"Throughout the development and test of spaceflight projects, the NASA\/Caltech Jet Propulsion Laboratory (JPL) uses a popular commercial software application-- the market leader-- for the definition and management of project requirements. Use of this requirements management database promotes design compliance and facilitates design verification, and JPL sharing of the database with contractors and partners greatly aids engineering collaboration and communication. It allows the project to organize requirements into a standard structure that can be shared between organizations. In addition, without such a tool, the task of accurately tracing complex and frequently changing project design elements to the sponsor\u2019s performance requirements would be even more daunting. The benefits of sharing the requirements management database with contractors and other stakeholders may not be fully realizable if the partners lack a common level of knowledge and experience in using the tool and in exchanging\/linking\/maintaining data between remote servers. For example, the large, geographically dispersed, Mid Infrared Instrument (MIRI) for the James Webb Space Telescope (JWST) involves collaboration between JPL, contractors, a consortium of European partners, and an international science team. The MIRI solution was for each partner to maintain a subset of the MIRI document modules and regularly exchange data using principally Excel spreadsheets for commonality and to ease importing, exporting, and manual editing. Data are updated at each respective location using redlines from the \"higher level\" document, and it is then often easiest for a partner to identify changes by means of manual comparison. This has permitted JPL to build and verify its requirement modules and deliver them to a partner who integrates them into the modules for which that partner is responsible, and on down the line. Each partner can use local tools and practices and maintain link information within their database. Because the JPL Orbiting Carbon Observatory (OCO) project was not as widely dispersed geographically, JPL decided that all the OCO modules would reside on a JPL server and the system contractor would access the database remotely. However, the contractor viewed remote access as too slow, and maintained local versions of the modules; JPL did not recognize the need to re-establish links between those requirements and the requirements within the JPL-maintained modules. The modules on the JPL server soon became obsolete. The solution was to frequently archive the contractor modules and inter-module links in an online JPL engineering library so that JPL could retrieve current data. References: P.J. Guske, \"OCO (Orbiting Carbon Observatory) Project Lessons Learned Document (Final),\" JPL Document No. D-26172, July 7, 2009, Paragraph 3.1.1. \"Verify CAD\/CAM Software Compatibility Between Organizations Before Proceeding to Hardware Fabrication,\" NASA Lesson Learned No. 0577, NASA Engineering Network, November 17, 1997. http:\/\/www.nasa.gov\/offices\/oce\/llis\/imported_content\/lesson_0577.html.","Lesson ID":2316}
{"Driving Event":"On April 12, 2006 six pulse width modulator circuit card assemblies (PWM CCAs), valued at $150,000 each were inadvertently excessed by the International Space Station program to the KSC excess property storage area. The PWM CCAs were attached to holding fixtures, and were spares for the ISS battery charge discharge unit. The PWM CCAs and their holding fixtures were subsequently purchased as scrap metal by a local salvage company. The PWM CCAs and holding fixtures were exposed to the weather at the KSC excess property storage area and in the salvage company's outside storage yard for approximately 11 months. The holding fixtures and not the attached PWM CCAs were identified and processed as excess equipment. The PWM CCAs were flight hardware and remained undetected throughout the entire excessing process.On August 9, 2006, the fixtures and PWM CCAs were sold at an auction as part of a miscellaneous lot to a local salvage company. On January 11, 2007, the Contractor conducted an inventory of items worth $100K or more that revealed the six PWM CCAs were missing. After research and analysis by the Contractor, the PWM CCAs were located, re-purchased and retrieved from the salvage yard on March 9, 2007. After being excessed and stored outside for several months, the PWM CCAs were no longer flight worthy resulting in a loss of $900,000. The mishap was classified as a Type B.","Lesson ID":2037}
{"Driving Event":"In May 2009, a wheeled shipping crate containing an electrical ground support equipment (EGSE) rack for the Aquarius project fell off the lift gate of a contracted commercial transportation van while being unloaded. The van was parked adjacent to the receiving dock at the NASA\/Caltech Jet Propulsion Laboratory (JPL). After the crate was moved to the rear of the vehicle for unloading, the van driver\/operator manipulated the incorrect control on the powered lift gate (Reference (1)). (Figure 1 illustrates the lift gate control system's susceptibility to operator error.) This caused the lift gate to tilt instead of lower. The crate rolled off the lift gate and struck the ground, damaging the hinges and breaking off the lid. Only the crate directly contacted the ground, and the EGSE rack with its 2-inch thick foam padding remained secure within the crate. The shipping crate had four casters, but the locks on the two downhill casters were unlocked during the operation. Figure 1. Lift gate control panel on the truck that was unloading Aquarius EGSE. The diagram below the image shows that the control panel is not well designed to deter operator error. (The yellow label indicates that the dial on the right is a \u201cSlider\u201d control that positions the gate horizontally.) The EGSE rack was being removed from the vehicle because it had not been approved in the final manifest for support equipment to be transported to Argentina for Aquarius integration and test. Since a need to unload the EGSE shipping crate had been not identified to the project until just prior to the incident, there was insufficient time to coordinate and plan the EGSE off-load. Quality Assurance was present during the incident, but System Safety was not notified of this unplanned unloading of Aquarius EGSE. Two individuals were injured as a result of this incident. The first struck his head on the pavement when he fell backward while avoiding the falling equipment. The other suffered a muscle strain while trying to restrain the EGSE rack as it rolled off the tilted lift gate. The container and lid were then moved into the Spacecraft Assembly Facility (SAF) airlock for visual inspection. Visual inspection did not detect any equipment damage other than the detached shipping container lid, and the damaged shipping crate was replaced. The personnel were treated with basic first-aid, and then they returned to work (Reference (2)). The test equipment required recalibration, full functional test, and internal visual inspection. Due to a lingering concern about possible damage, however, replacement EGSE was obtained for use with Aquarius flight equipment (Reference (3)). There exists some residual concern by the Aquarius project due to the risk posed by plans to move JPL Critical Items (JCI) from Argentina to Brazil, and from Brazil to the Vandenberg Air Force Base launch site. JPL has recently revamped the process of preparing and reviewing transportation plans. The process is now reflected in the formal procedures of JPL Security, and preparation of a transportation plan is now a contractual requirement to be added to JPL subcontracts (Reference (4)). Also, the JPL Project and Engineering Management Committee (PEMC) has approved adding a transportation plan requirement to the next release of the JPL Flight Project Practices. (See Recommendation #4.) Documentation in a previous lesson learned (Reference (5)) of damage to JPL flight hardware during international transit led to a security plan requirement (Reference (6)) for shipments outside the continental U.S. References: JPL Mishap Report No. 1887, May 28, 2009. JPL Mishap Report No. 1886, May 28, 2009. quotAquarius EGSE Shipping Mishap,quot JPL Problem\/Failure Report No. 15044, May 28, 2009. quotTransportation Documentation,quot JPL Data Requirement Description (DRD) No. TE-004, April 17, 2009, in quotSubcontract Plans and Documentation for SDRL and DRDs, Rev. 0,quot JPL Document No. DocID 78172, September 15, 2009, p. 132. quotExercise Strict Controls in the Packaging and Oversight of Critical Hardware Shipped by Third-Party Courier Services,quot NASA Lesson Learned No. 1849, NASA Engineering Network, April 1, 2008. quotOff-Site Transportation of Flight Hardware, Rev. 1,quot JPL Document No. DocID 69052, July 8, 2009, Paragraph 2.2. quotShipments of Deliverable Hardware, Rev. 1,quot JPL Document No. 64352, update pending.","Lesson ID":2456}
{"Driving Event":"Following the successful 2008 landing of Mars Phoenix, the NASA Office of the Chief Engineer and the NASA Aeronautics Research Mission Directorate commissioned a reconstruction of the Entry, Descent, and Landing (EDL) data telemetry. By improving NASA's understanding of Phoenix flight performance (i.e., comparing the actual flight performance against the pre-entry predictions of flight dynamics, aerodynamics, and aerothermodynamics), the sponsors sought to improve the accuracy of the prediction tools and environmental models and address some questions that arose following Phoenix EDL. The downlinked data available to the analysts included channelized engineering telemetry; non-channelized gyro, accelerometer, and radar data; navigation data on the spacecraft entry state; the landing location coordinates; and radiometric data on EDL communications. Although EDL is typically the highest risk phase of Mars surface missions managed by the NASA\/Caltech Jet Propulsion Laboratory (JPL), Phoenix EDL was very successful. Based on the data reconstruction (References (1) and (2)), the vehicle performance during the EDL sub-phases may be characterized as follows: Cruise Stage Separation. The spacecraft state was nominal up to cruise stage separation, and the vehicle performed well upon atmospheric entry. There was no indication of lander recontact after separation from the cruise stage. Hypersonic Entry. During hypersonic entry, it was observed that Phoenix trimmed at a higher total angle of attack than simulation had predicted. Consequently, the vehicle flew a slightly lifting trajectory. Second, since the vehicle was aerodynamically stable, a decision had been made to widen the Reaction Control System (RCS) deadbands throughout the hypersonic regime to mitigate the predicted risk of control reversal. As no thruster activity was recorded during the period from HYPER2 transition through parachute deployment, there was no chance of Phoenix thrust reversal. Third, the vehicle experienced large aerodynamic torques during the deceleration pulse that exceeded the available Z-axis thruster torque, further vindicating the decision to widen the RCS deadbands. Parachute Deployment & Descent. Parachute deployment and inflation met the design requirements. Deployment of the parachute 6.4 seconds later than predicted is consistent with the indications of a lifting trajectory, the times for line stretch and first-peak-load-from-mortar-fire were slightly shorter than predicted, and the estimated parachute peak load was well below the flight load requirement. Heatshield Separation. Quite unexpectedly, the Phoenix heatshield separation event was seen in an image captured from the HiRISE camera aboard the orbiting Mars Reconnaissance Orbiter spacecraft. The heatshield can actually be observed falling away, 47 seconds after parachute deployment and about 9.2 km above the Martian surface. Based on the HiRISE pixel and image angle, the heatshield was estimated to be about 340 meters below the lander. This may be compared to a pre-entry heatshield separation analysis that predicted a mean separation distance of 395 meters with a 1-s dispersion of 66 meters. Hence, the model-based mean prediction may have been quite accurate as it was less than 1-s from the image-based estimate. There was no indication of a major heatshield recontact incident during separation. Terminal Descent. Overall, the actual descent trajectory matched the prediction quite closely. No anomalies were encountered during terminal descent, with the radar performance nominal and all touchdown requirements met: The lander separation from the backshell was nominal, as was the \"tip up\" rotation used to clear the backshell and align to the gravity turn attitude. The Backshell Avoidance Maneuver planned to prevent the backshell and parachute from landing on the Phoenix lander was not needed and was not implemented. The gravity turn and constant velocity were nominal. The touchdown deceleration was within 50 percent of the maximum allowable, the final landing pose tilt\/azimuth errors were well within requirements, and the touchdown dynamics met expectations. All three touchdown sensors tripped after the lander legs deployed, and the full leg compression needed to register touchdown lasted almost 3 times longer than required. The back pressure caused by ground effect (that causes a slight slowing of the lander just before touchdown) was observed to begin slightly closer to ground than shown in simulations, but because the onset was slightly faster, the total deceleration was effectively the same. Several questions arose following the Phoenix landing (Reference (1)): Why did Phoenix land long? Due to cancellation of the sixth trajectory correction maneuver (TCM-6) during the Cruise phase, the predicted landing location was updated and re-centered 17 km uptrack of the original target landing location (Figure 1). However, the vehicle landed 21 km downtrack and 5 km crosstrack from the newly predicted site, or a straight-line distance of 21.6 km. The primary cause was the higher than predicted angle of attack during hypersonic entry. When this error is combined with the reconstructed atmospheric density and high-altitude winds, and with the very small navigation entry state error (i.e., error in knowledge of position, velocity, or entry time) the propagated landing site is within 2 km of the newly predicted landing site (and well below 1\u03c3). Why did Phoenix have an unexpectedly high angle of attack during Hypersonic? A difference in the angle of attack prediction will result in different aerodynamic forces and torques than predicted. The effects of this difference are particularly significant during the hypersonic entry, when there is still a long time to landing. A number of candidate causes of the high angle of attack have been identified (Reference (2)). However, the likely cause is a combination of a larger-than-expected radial offset in the capsule center-of-gravity location than pre-entry measurements, and a slight overestimate of the capsule hypersonic aerodynamic stability. But there is insufficient data for the EDL reconstruction to conclusively identify the cause. Figure 1. Phoenix landing ellipse showing actual landing site (green dot) 21.6 km downtrack of the updated predict (white dot) Why did Phoenix roll during Hypersonic? Phoenix experienced a roll torque of 0.5 Nm at peak deceleration. This induced a 0.7 deg\/second roll rate that continued through parachute deployment. Roll rate reconstruction showed that bounded aerodynamic instability and a center of mass radial offset could produce the observed roll rate. But the EDL data reconstruction did not conclusively determine the cause of the roll. Were there any indications of the thruster efficacy issue? Thruster jet interactions with the structure (Figure 2) during EDL can alter the pressure on the backshell, resulting in different control moments than intended. RCS pitch authority may be degraded and yaw authority may be low to non-existent, posing a risk of control reversal. Furthermore, this may cause a large attitude error at parachute deployment that leads to excessive wrist mode dynamics that impact radar performance. However, since Phoenix did not fire thrusters during the descent, relying instead on the inherent capsule stability to traverse the flight regimes, thruster efficacy was not an issue. Figure 2. EDL thruster efficacy issue How did the radar perform? The Phoenix radar design was inherited from the Mars Polar Lander and Mars '03 projects. Modifications for the Phoenix mission included a lower minimum altitude, high resolution Doppler mode, new antenna design and configuration, new antenna switch design, lower pulse repetition frequency (PRF) for range ambiguity protection, and numerous firmware updates. The Phoenix radar worked well in the environment for which it was tuned (flat terrain, near vertical descent), and the overall altitude and velocity performance was consistent with simulations and with field testing at NASA Dryden Flight Research Center. One unexplained (but not unexpected) anomaly was seen in the altitude data just prior to touchdown, but well after the system ceased using radar data to control the landing. (Some of the radar performance data discussed in Reference (1) has been omitted here to ensure conformance with International Traffic in Arms Regulations (ITAR) restrictions.) Was there a plasma blackout? Communications may be attenuated or interrupted when a spacecraft enters an atmosphere due to the ionized sheath of plasma and high electron density caused by the compression and heating of surrounding air. Phoenix was equipped with a transmitter capable of both recorded and real-time downlink via both Mars orbiter relays and direct-to-Earth. EDL downlink was maintained from 2 minutes prior to Entry until 1 minute after touchdown. Phoenix telemetry suggests that there may have been a short communications brownout or blackout during the period of peak heating during planetary entry. Was there any fault protection activity or anomalies during EDL? All high-level and component-level fault protection counts during EDL were either expected or understood. These included 315 X-axis attitude control error counts during parachute descent (expected), 531 radar reliable counts (expected), 1 Fast Fourier Transform (FFT) Frozen count (understood) and 1 FFT Done count (understood). There were no other EDL anomalies. References: Erik Bailey, et. al., Presentation on \"Phoenix EDL Reconstruction,\" October 7, 2008. Desai, P. N., Prince, J. L., Queen, E. M., and Grover, M. R., \"Entry, Descent, and Landing Performance of the Mars Phoenix Lander,\" Journal of Spacecraft and Rockets, to be published.","Lesson ID":2516}
{"Driving Event":"Hypergolic fluids are toxic liquids that react spontaneously and violently when they contact each other. These fluids are used in many different rocket and aircraft systems for propulsion and hydraulic power including: orbiting satellites, manned spacecraft, military aircraft, and deep space probes. Hypergolic fuels include hydrazine (N2H4) and its derivatives including: monomethylhydrazine (MMH), unsymmetrical dimethylhydrazine (UDMH), and Aerozine 50 (A-50), which is an equal mixture of N2H4 and UDMH. The oxidizer used with these fuels is usually nitrogen tetroxide (N2O4), also known as dinitrogen tetroxide or NTO, and various blends of N2O4 with nitric oxide (NO). Several documented, unintentional hypergolic fluid spills and fires that occurred in support of the Apollo Program, the Space Shuttle Program, and several other programs from approximately 1968 through the spring of 2009 have been studied for the primary purpose of extracting the lessons learned. Hypergolic rocket propellants have proven to be a highly reliable asset in manned and unmanned spaceflight; however, their maintenance on the ground has proven to be relatively difficult. Do the operational risks from possible human errors or hardware failures causing a catastrophic incident outweigh the usefulness of hypergols even though they have been used for the last 50 years of manned and unmanned spaceflight? One would have to say probably not, since hypergols are so widely used in the space industry currently and are being proposed to be used on many vehicles in the future. Therefore, ground operations on hypergol systems have become increasingly scrutinized for possible unknowns, and rightfully so. The data shown in this report are not an example of why we should not be using hypergolic propellants on spacecraft and launch vehicles, but rather illustrate what we can and should do to mitigate possible unforeseen ground operation and\/or design problems.","Lesson ID":2196}
{"Driving Event":"Coil fins on chillers in the VAFB area (Lompoc, CA) corrode quickly because of exposure to sea air. For this reason, a specification was written for a special coating to extend the life of the coils. When corrosion was spotted on the newly installed coils, it was watched closely to see if it continued. The installing subcontractor, coil manufacturer, and coater were notified of the situation. When the corrosion was observed to be spreading, a meeting was held and the parties involved made an inspection at the site.","Lesson ID":2356}
{"Driving Event":"Aquarius is a satellite project managed by the NASA\/Caltech Jet Propulsion Laboratory designed to measure variations in global sea surface salinity for Earth climate studies. The primary instrument components, the Radiometer and the Scatterometer, share a single antenna subsystem that includes a 2.5-meter diameter reflector (Figure 1). The Aquarius reflector was damaged during acoustic testing in the JPL acoustic test chamber (Figure 2) on May 23, 2007 (References (1) and (2)). The specific acoustic test that resulted in the over-test incident was Test Run #4, which had planned test level settings of -12dB, -9dB, and -6dB (from the quotfullquot or 0 decibel sound pressure level). The run was aborted by the system during the first (-12dB) run when the sound pressure exceeded limits. Figure 1. Drawing of Aquarius instrument................. (Reflector depicted at top of image.) Figure 2. Test article suspended in the acoustic chamber prior to test. For the acoustic tests, JPL served as the facility operator, and the reflector contractor performed the role of test conductor (as part of their qualification program). Nominal results were obtained from a pre-test of the empty acoustic chamber at the 0 dB level, and also from Test Run #1. Test Run #2 produced an anomaly with the control microphones, but the test conductor decided to proceed to Test Run #3 with further changes to critical control parameters from those recommended by the vendor of the acoustic control software (controller). The anomaly troubleshooting and control parameter change was improperly performed because the flight hardware remained in the test chamber. During Test Run #3, the -9 dB run was aborted by the controller software after 7 seconds. A decision was made to increase the compression rate so acoustic levels would come up slower and better enable the controller. However, the final test-- Test Run #4 at -12 dB-- was manually aborted after a 2-second over-test. Visual inspection of the reflector assembly indicated 9 areas of damage around the periphery of the reflector (Figure 3). The damage apparently resulted during Test Run #4 when the acoustic chamber turned on at itsquotfullquot level (>155dB), which was significantly higher than the 0 decibel level intended for this reflector. This sound pressure level massively over-tested the reflector, and a replacement reflector had to be procured at a cost of approximately $2M. Figure 3. Extent of damage to Aquarius reflector. The cause of the over-test incident was attributed to anomalous behavior of the acoustic test facility due to a deviation from the normal JPL acoustic test procedure (Reference (3)). The test operator accidentally pressed the quotrunquot button on the controller prematurely while adjusting control system displays. The initiation of the data recorder and gas turn-on alerted the operator that the system had entered quotrunquot mode, so he pressed thequotstandbyquot button. The operator then executed the missed steps in the test procedure and then purposely pressed thequotrunquot button again. The test personnel recognized the incipient over-test condition by the sound level, and the operator pressed the quotabort.quot Subsequent investigation showed that the controller did not perform the expected safing checks and responses to protect the test article after the operator failed to follow the correct procedure (Reference (4)). In addition, the controller software used in the JPL test facility had not been upgraded to the most recent version (Reference (5)), and subsequent mishap simulations with updated software successfully triggered the Test Run #4 abort. References: quotAquarius Reflector Damage - Acoustic Environment,quot JPL Problem\/Failure Report No. 6277, May 24, 2007. quotAquarius Reflector Acoustic Testing,quot JPL Problem\/Failure Report No. 6412, June 28, 2007. quotAQUARIUS Radar Reflector Incident, Special Review Board (SRB) Briefing, Rev. 2,\" July 12, 2007. quotMishap Safety Alert 1 - Abort Feature of the Acoustic Chamber Control System Software,quot Aquarius Reflector Mishap Investigation Board, December 6, 2007. quotMishap Safety Alert 2 - Outdated Version of the [vendor\/product name redacted] Acoustic Control Software,quot Aquarius Reflector Mishap Investigation Board, December 6, 2007.","Lesson ID":2419}
{"Driving Event":"Mars Phoenix, which featured a suite of instruments mounted on its top deck that was designed for a previous mission, landed in May 2008 in the north polar region of Mars. Phoenix featured a robotic arm designed to deliver soil or ice samples to cells in the Thermal Evolved Gas Analyzer (TEGA) instrument. The TEGA cells are arranged in 2 rows on either side of the instrument with 4 cells apiece (Figure 1). Each cell has a pair of spring-loaded protective doors released by a pin puller device. The first command to open the doors of a cell (Cell #4) was issued in early June, but the doors opened only partially as shown in Figure 2. When a second set of doors (Cell #5) was commanded open in mid-June, they opened only marginally to about 25 degrees each (Figure 2). Figure 1. TEGA assembly Figure 2. Cell #4 and Cell #5 with partial door opening Based largely on the evidence provided by a photograph (Figure 3) taken after cell assembly, a failure investigation attributed the probable proximate cause of the anomaly to a mechanical interference (Reference (1)). The configuration of the TEGA\u2014 which included hinged cell doors, rails for magnetic attachment of an outer cover, rail attachment brackets, and bracket stiffeners that had a raised profile\u2014 resulted in the stiffeners impeding the opening of the 6 inboard cell doors. The outboard doors did not have a bracket adjacent to them and could open without impedance. Figure 3. Side of TEGA housing Cells Nos. 0, 1, 2, and 3. Outer cover has not been installed. Close-up image shows the lower rail: arrows highlight the stiffener on each of 3 rail attachment brackets. The root cause of the anomaly is attributed by Reference (2) to a breakdown in the design, verification, and validation processes. Testing of the cover release and door opening on an Engineering Qualification Model (EQM) revealed this failure mode, and the instrument contractor modified the EQM lower rail to avoid the interference. A set of change drawings was provided to the subcontractor for modifying the flight unit in accordance with the EQM fixes. However the lower rail modification was not annotated or dimensioned for change, and the subcontractor drawings only incorporated the changes that had dimensions called out or annotated. The contractor's development process does not generate any other documentation of the problem, and a quottest-as-you-flyquot exception excluded their full, post-assembly testing of the flight doors in a flight assembly. Ground testing with the robotic arm demonstrated that soil samples could successfully be delivered to the TEGA oven despite the partially opened doors. References: quotTEGA TA #4 Sol 8 Partial Door Open,quot JPL Incident Surprise Anomaly Report No. Z92683, June 3, 2008. B. Goldstein & D. Sabahi, quotTEGA Door Opening Anomaly Report,quot JPL IOM, July 11, 2008.","Lesson ID":2336}
{"Driving Event":"Prior to initiation of solar thermal vacuum (STV) testing of the Mars Science Laboratory (MSL) spacecraft at the NASA\/Caltech Jet Propulsion Laboratory (JPL), a post-acoustic health check was conducted to assure that the system had suffered no damage during the prior system-level acoustic testing. The results of the check showed excess radio frequency (RF) signal loss for both the uplink and downlink radio signals (Reference (1)). The measured values exceeded the analytically predicted loss, and they were also significantly higher than the end-to-end telecommunications (telecom) system path loss values previously measured for the spacecraft in the Spacecraft Assembly Facility. When the STV test was conducted in the solar simulator (Figure 1), certain high power RF components were left unpowered due to concern that the spacecraft acoustic test had damaged RF hardware and caused the apparent increase in dissipative or radiated losses. Figure 1. MSL spacecraft in JPL STV chamber prior to STV test A detailed investigation concluded that the telecom hardware was healthy with no residual risk of latent damage, and the actual signal losses were within specification. JPL system-level test is a very mature process that has proven effective on a range of missions, but the standard RF test approach alone was insufficient to adequately verify this complex system without additional measurement uncertainty analysis of the results (i.e., boundary conditions, GSE calibration, test configuration, etc.). The initial anomalous readings were attributed to an application of the system-level test process in which the uncertainties exceeded the signal loss to be measured. References: quotTelecom Post STV Loss Calibration Anomaly,quot JPL Problem\/Failure Report No. 14479, January 9, 2009. R. Roland Liou, quotMSL ATLO Telecom Testing Lessons Learned,quot April 20, 2009.","Lesson ID":2337}
{"Driving Event":"The LRO transmitter needed a high-power amplifier with a 40 W output at 25.65 GHz. Fortunately, a 180 W traveling wave tube amplifier had just been developed and space-qualified for a mission-of-interest. Prior to that development, the state-of-the-art had been a 10 W traveling wave tube built for the Cassini spacecraft in the early 1990s, which is still flying successfully. A traveling wave tube amplifier (TWTA) meeting the LRO requirements was developed by L-3 Communications Electron Technologies, Inc. under oversight of the Glenn Research Center.","Lesson ID":1862}
{"Driving Event":"Previous NASA missions required TWTAs that operated in either the X-band or Ka-band. However, the TWTA for the LRO mission needed to operate in the intermediate K-band. Although the WR28 waveguide used for Ka-band TWTAs would have worked at 25.65 GHz, waveguide losses would have been increased. In addition to its better performance, the WR34 waveguide will also work at lower frequencies than the WR28, frequencies that NASA plans to use in future near-Earth missions. Using WR34 waveguide connections also allows larger and thicker quartz windows to be used for the seals inside the amplifier, which reduces the danger of multipaction and corona.","Lesson ID":1861}
{"Driving Event":"Eight days before the May 2008 arrival of Mars Phoenix Lander at the north polar region of Mars, the Phoenix Project at the NASA\/Caltech Jet Propulsion Laboratory (JPL) was preparing a final trajectory correction maneuver (TCM-5) to guide the spacecraft on its navigated course. A final TCM is a mission-critical event in which an error, or non-performance of the maneuver, can result in mission loss (Reference (1)). Due to the criticality of this spacecraft command sequence and the limited time available to prepare it, the Phoenix Mission Manager imposed a Level 2 facility freeze for the Phoenix Navigation Mission Support Area (MSA) on the 6th floor of Building 264. A Level 1 configuration control freeze is requested by a flight project, and it restricts changes to the configuration of multiple JPL facilities during a critical event. In contrast, the restrictions associated with a Level 2 freeze are limited to a specific facility or service. The project notifies a facility manager of the Level 2 freeze, and a printed tag is placed at the facility entrance. Access to the MSA is restricted by an electronic badge reader that operates the door lock. An upgrade to the badge reader system in Building 264 was scheduled for May 2008, which happened to be on a Saturday during the Level 2 freeze for TCM-5 sequence development (Reference (2)). Contractors arrived during the freeze, and started work on the reader even though the Phoenix Mission Manager explained that there was a critical event in progress. The upgrade work involved removal of ceiling tiles directly above the MSA and work in the crawl space without regard for the computer equipment directly below. No drop cloths were placed over the sensitive computer equipment being used to prepare the TCM, and the contractor intrusion disrupted the work of the navigation team. A phone call to JPL Security halted the badge reader work for the day, with the badge readers restored to the previous configuration. The JPL practice is for infrastructure organizations such as JPL computer and network services to consult the Interplanetary Network Directorate (IND) Critical Activities Schedule and defer planned activities in accordance with any scheduled freezes (Reference (3)). IND also holds a weekly planning meeting to discuss scheduled freezes and other concurrent activities. However, it is the JPL facilities and infrastructure services that have the responsibility to consult these resources to ensure that their plans do not conflict with critical project activities. References: \"Inadequate MCO Contingency Maneuver Planning,\" NASA Lesson Learned No. 0916, NASA Engineering Network, May 4, 2000. http:\/\/www.nasa.gov\/offices\/oce\/llis\/imported_content\/lesson_0916.html \"Badge Readers Being Changed On The 6th Floor During Level 2 Freeze,\" JPL Incident Surprise Anomaly (ISA) No. Z92597, May 17, 2008. IND Critical Activities Schedule, http:\/\/dsnprocess.jpl.nasa.gov\/icas\/","Lesson ID":2216}
{"Driving Event":"The Orbiting Carbon Observatory (OCO), an Earth orbiting satellite mission managed by the NASA\/Caltech Jet Propulsion Laboratory, was designed to make precise, time-dependent, global measurements of atmospheric carbon dioxide (CO2). On February 24, 2009, OCO failed to reach orbit aboard a Taurus launch vehicle, and the OCO payload and mission were lost. The proximate cause of the mishap was the failure of the Taurus payload fairing (Figure 1) to separate during ascent (Reference (1)). A standard component of expendable launch vehicles, a payload fairing is a clamshell-shaped cover that encloses and protects a payload on the pad and during early flight. The fairing is jettisoned when the launch vehicle has achieved an altitude where aeroheating of the payload is no longer a factor. The fairing should have been jettisoned shortly after Stage 2 ignition, but it remained attached for the remainder of the flight. Failure to shed the fairing mass prevented the satellite from attaining the orbital velocity needed to reach its planned orbit, resulting in atmospheric reentry and loss of the $260 million mission. Figure 1. Taurus Launch Vehicle References: quotOverview of the Orbiting Carbon Observatory (OCO) Mishap Investigation Results For Public Release,quot MyNASA, July 16, 2009, http:\/\/www.nasa.gov\/pdf\/369037main_OCOexecutivesummary_71609.pdf.","Lesson ID":2257}
{"Driving Event":"To minimize mass, designers of aerospace systems are reducing the wall thickness for metallic pressure vessels, such as the Mars Science Laboratory (MSL) propellant tank and COPV liners that will be used in future Constellation Program vehicles. This reduction in wall thickness produces higher net section stresses, for a given internal pressure, resulting in smaller critical initial flaw size (CIFS). These smaller crack sizes are approaching the limitations of penetrant NDE. Failure to adequately demonstrate the capabilities of penetrant inspection methods over the required range of crack aspect ratios may lead to the failure to detect a critical flaw resulting in a catastrophic tank failure. The current standards governing aerospace metallic pressure vessels (AIAA S-080) and COPV liners (AIAA S-081) require that fracture analysis be performed to determine the CIFS for cracks having an aspect ratio ranging from 0.1 to 0.5. They further require that NDE methods have a demonstrated capability of 90 percent probability of detection with a 95 percent confidence (90\/95 POD) for the CIFS determined by this analysis. Previously, NASA demonstrated this capability by testing at only a single aspect ratio and then used an equivalent area approach to extend the results to the required range of aspect ratios. However, there is insufficient data to support this approach and it may break down for smaller CIFS. Testing is needed to demonstrate the capability of penetrant inspection for smaller CIFS over the full aspect ratio range, or it may be necessary to demonstrate and implement alternative inspection techniques.","Lesson ID":2256}
{"Driving Event":"Solar-B had an expected X-Band data rate of 4.2 Mbps and an estimated daily volume of 24-30 Gbyte\/day (uncompressed). This estimate was going to result in ~10 Tbyte total of science data per year. The original data management plan called for the science data to be transferred from the control center in Japan to the remote sites in the U.S. and U.K. via CDs or tapes. However, through prior knowledge from another program, it was realized that the Internet would be a much more efficient method of data transfer, while still maintaining data integrity and security. Site-to-site testing conducted successfully. External users can access the science data thru the remote site data bases. Data is now available at Remote Sites very quickly much quicker than using CDs or data tapes.","Lesson ID":2156}
{"Driving Event":"NASA relies on an extensive network of contractors and suppliers whose manufacturing processes and products must meet contractually-defined NASA requirements. To assure contract compliance with NASA safety and mission assurance (SMA) related requirements, the NASA Contract Assurance Services (NCAS) organization assigns certified inspectors to participate in surveillance and onsite inspections at facilities operated by prime contractors, sub-tier suppliers, and universities. The objectives of these facility audits and assessments are to validate supplier quality systems and processes, identify and manage the risks of noncompliance before a mishap can occur, and support the assurance activities of NASA Center programs and projects. NASA seeks to schedule onsite audits of major NASA prime contractors at least once every 24 months, in addition to assessments of other suppliers. A problem arose from the lack of coordination between NASA Centers: a supplier would host an NCAS audit team from one NASA Center, only to be followed shortly after with a visit from representatives of another NASA Center. The suppliers found such frequent audit visits by different NASA customers to assess the same processes and products to be disruptive and unnecessarily burdensome. Both suppliers and NASA may achieve significant efficiencies by hosting joint audit visits where representatives from multiple NASA Centers attend the same meetings and participate in the same inspection visit. The NASA Joint Audit Planning Committee now maintains a master schedule of NCAS audits for all the NASA Centers (References (1) and (2)). Where program and project representatives from more than one NASA Center plan to visit a supplier, the master scheduling permits them to coordinate the dates such that the supplier need not respond to requests for multiple audit visits. A Center Technical Liaison (CTL) works with the NASA program and project managers, NCAS representatives, subject matter experts, and CTLs from other NASA Centers to prepare audit plans that will concurrently meet NASA procurement SMA objectives. References: NASA Joint Audit Planning Committee (JAPC) website, https:\/\/secureworkgroups.grc.nasa.gov\/japc NASA Audit Management Team (NAMT) charter, http:\/\/supplychain.gsfc.nasa.gov\/2008\/SC2008-Crenshaw-Ceritelli.ppt","Lesson ID":2217}
{"Driving Event":"NASA\u2019s Facilitated Access to the Space Environment Technology Development and Training Program (FAST) is designed to incorporate new technologies into NASA\u2019s flight programs and other commercial space applications. FAST provides an opportunity to demonstrate the performance of emerging technologies in the zero-gravity environment of Earth orbit or the reduced gravity environment of the Moon or Mars. Six KSC projects were selected for reduced-gravity flights the week of August 10, 2009. Projects were responsible for preparing their test equipment to meet the requirements of flight, transporting their experiments to the flight location, and staffing the experiment as required during the actual flights. Personnel wishing to fly underwent medical exams and training prior to taking part in the reduced-gravity flights. The flight experiments were carried out successfully. Although participants were very pleased with the overall process, some opportunities for improvement were identified during post-flight discussions.","Lesson ID":2176}
{"Driving Event":"The engineering of flight software (FSW) for a typical NASA\/Caltech Jet Propulsion Laboratory (JPL) spacecraft is a major consideration in establishing the total project cost and schedule because every mission requires a significant amount of new software to implement new spacecraft functionality. FSW development is performed concurrently along with the design and development of (1) the spacecraft with its many mechanical, electronic, and computational elements, (2) the instruments that comprise the spacecraft\u2019s payload, and (3) the testbed software that simulates the spacecraft, its payload, and the extreme operational environment of space. This is extremely challenging because the complete and accurate spacecraft hardware design documentation needed to complete the design and test the FSW and develop the simulation software is typically unavailable until late in the software development lifecycle. Because FSW engineers cannot test their software against mature hardware (that reflects the actual behaviors and performance characteristics of the hardware that will operate in space) until they gain access to flight-like testbeds, a significant amount of software testing is usually performed after the spacecraft has launched, during the relatively benign cruise portion of the mission. Software changes are then uploaded to the spacecraft prior to critical mission events-- like landing on Mars. These endemic constraints to FSW design and test impact project cost and schedule and pose a risk to mission success because the FSW must be integrated with the flight system hardware. In addition, FSW is suffering accelerating growth in size, complexity, and difficulty to understand and verify (Reference (1)). These factors complicate project cost and schedule estimation\/performance in a functional area where an in-flight fault may cause an unrecoverable error. FSW errors had a role in the loss of the Mars Polar Lander and Mars Climate Orbiter missions (Reference (2)), in the Mars Global Surveyor loss of contact (Reference (3)), and in recoverable in-flight failures such as the Mars Exploration Rover flash memory anomaly (Reference (4)). References: \u201cNASA Study of Flight Software Complexity,\u201d NASA Lesson Learned No. 2050, NASA Engineering Network, May 5, 2009. http:\/\/www.nasa.gov\/offices\/oce\/llis\/imported_content\/lesson_2050.html \u201cReport on the Loss of the Mars Polar Lander and Deep Space 2 Missions, JPL Special Review Board, JPL D-18709, March 22, 2000. \u201cMars Global Surveyor (MGS) Spacecraft Loss of Contact,\u201d NASA Lesson Learned No. 1805, NASA Engineering Network, September 4, 2007. http:\/\/www.nasa.gov\/offices\/oce\/llis\/imported_content\/lesson_1805.html \u201cMER Spirit Flash Memory Anomaly,\u201d NASA Lesson Learned No. 1483, NASA Engineering Network, August 23, 2004. http:\/\/www.nasa.gov\/offices\/oce\/llis\/1483.html Ronald Kirk Kandt, \u201cFlight Software Engineering Lessons,\u201d Proceedings of the 15th Americas Conference on Information Systems (AMCIS 2009), August 06-09 2009, San Francisco. [URS208276]","Lesson ID":2218}
{"Driving Event":"Pro-Engineer CAD software and Windchill configuration management software were used in combination to create and manage CAD files. We migrated to Windchill half way through the project and later found that Windchill uses a large amount of computer memory to track files. The design team also lacked large assembly file management skills. We needed more powerful computers; however, only some of the employees received them in a timely manner. On ARES 1-X USS, model and drawing file sizes grew very fast after the conceptual stage passed. Designers struggled to complete assembly drawings. Computer power and file management techniques were lagging as the schedule pressure continued. Much time was spent waiting for frozen computers to update so the next change could be made. Internal CAD support was insufficient to address our productivity issues. Additional CAD support was not funded.","Lesson ID":2051}
{"Driving Event":"GSFC built an X-Ray Spectrometer (XRS) which was integrated in Japan with 3 other instruments into the Astro E-2 spacecraft and launched it aboard a Japanese rocket from Japan. The XRS was the primary instrument for this mission which was managed by the Japanese Space Agency (JAXA). Astro E-2 was renamed Suzaku once orbit was obtained as is customary for Japanese missions. The XRS uses calorimetric detectors that must be cooled to near absolute zero (operating at 60mK). This was accomplished by a multi stage Dewar which includes liquid He and solid Ne. Dewar operations are initiated on ascent by blowing pyro valves allowing the He and Ne to vent. The Dewar was also equipped with a pyro driven vent that exposes the Dewar guard vacuum to ambient environment. This design feature was intended to vent the guard vacuum to deep space once on orbit. This would allow any cryogen leakage to be effectively prevented from contaminating this volume. There is another pyro gate valve at the telescope's aperture that protects the internal detectors until on orbit. By blowing the aperture gate valve the instrument becomes fully operational and is enabled to view its entire desired spectrum. Once the XRS was on orbit it was successfully calibrated and configured for full operations (i.e. guard vacuum and gate valves blown). However, prior to opening either the aperture valve or the valve to the guard vacuum (i.e. He and Ne are venting) significant science can acquired (although only over a small spectrum) in this configuration. Unfortunately, the space craft design had a fatal flaw. For most missions that fly cryogens the Dewar comprises the main structural component of the spacecraft. The XRS was buried inside the spacecraft in what turned out to be a confined space. Once integrated into the spacecraft the Dewar was supposed to have been vented to the exterior of the spacecraft and then overboard. The entire spacecraft exterior was covered with thermal blankets which enclosed the volume that held XRS. The venting He and Ne accumulated in the confined space. Although the confined space was not airtight the venting area provided by the blanket seams restricted the venting sufficiently enough to establish a level of atmosphere to pose a contamination issue. When the guard and aperture valves were blown the confined He and Ne were sucked into the guard vacuum shorting out the vacuum causing unacceptable heat loads on the tanks. The cryogens were rapidly depleted and a planned 3 year mission was over in 19 days with no science having been acquired. It should be noted that Astro E-2, as the name implies, was a \"build to print\" reflight of the first Astro which also was launched on a Japanese rocket. It was identically flawed and would have failed in the fashion but the launch vehicle failed to achieve orbit and was lost. Also notable is the design review process failed to identify the design flaw. This lesson is limited to mission operations planning. The genesis and propagation of the original design flaw is covered in detail in the Astro E-2 Mishap Investigation Board report. There are broader issues with respect to communications and program execution.","Lesson ID":2116}
{"Driving Event":"During contract negotiations for the Lunar Reconnaissance Orbiter (LRO) Traveling Wave Tube Amplifier (TWTA), NASA subject matter experts provided the following modifications to the requirements; 1. The input drive power range cannot be predicted well for a new TWTA design, so the range was widened from +\/-1dB to +\/-3dB. 2. Since the TWTA would be operated only on the ground (for testing) and in space, there was no need to use resources to conduct corona, arcing, and multipaction tests at partial vacuum. 3. Methods for testing hot output Voltage Standing Wave Ration (VSWR) did not exist and attempts would endanger the TWTA; however, it was known that the hot VSWR was close to the cold VSWR when the TWTA was transmitting. 4. The phase non-linearity specification was in conflict with other specifications.","Lesson ID":1859}
{"Driving Event":"The objective of the NASA\/Caltech Jet Propulsion Laboratory (JPL) Ocean Surface Topography Mission on the Jason-2 satellite (OSTM\/Jason-2) is to measure ocean surface topography including changes in the global sea level. The Advanced Microwave Radiometer (AMR) instrument aboard the satellite measures radiation from the Earth's surface to determine atmospheric water vapor so that radar altimeter instrument time delay errors caused by the water content can be corrected with great accuracy. A vapor deposited aluminum (VDA) coating was applied during fabrication of the AMR Reflector Structure Assembly (RSA) (Figure 1) to provide the reflector with the desired surface properties. Subsequent JPL tests of VDA witness coupons in June 2006 (Figure 2) revealed a significant deficit in the surface conductivity of these samples that could affect AMR performance (Reference (1)). The low conductivity was traced to surface roughening of the reflector surface, performed prior to VDA deposition, that caused discontinuities in the composite and resin surface on a micron level (Figure 3). Most of the surface roughening resulted from grit blasting, but hand abrasion using green nylon mesh pads also caused degraded surface conductivity. Roughening was performed to reduce specular reflectance (specularity) that could cause damage in the event of anomalous direct pointing at the sun. Figure 1. AMR RSA Figure 2. RF resonant cavity measurement of effective 7.17 GHz conductivity for AMR RSA coupons Figure 3. SEM image of AMR coupon sample (basket-weave woven composite, no wash coat, aggressive grit blast) showing surface discontinuities The AMR process specification for VDA was approved based on analyses by the project and by independent reviewers and based on a history of use on such JPL flight instruments as the Microwave Limb Sounder (MLS) and Cloudsat. Examination of the anomalous, VDA-coated, AMR RSA coupon cross-sections with a scanning electron microscope showed that the samples with the most roughening appeared to have the most discontinuities in the VDA coating and exhibited the poorest surface conductivity (Reference (2)). The root cause of the discontinuities has not been established, but it is believed to be uneven aluminum deposition due to the shadowing effect of surface features created by the roughening process, which is poorly controlled. The anomalous AMR results, as compared to MLS, may be attributable to differences in composite weave characteristics and grit blasting parameters. The OSTM\/Jason-2 project relaxed the specularity requirement so that surface roughening of the AMR reflector would not be required. A modified VDA process that did not include surface roughening was developed and validated using coupon tests. The AMR RSA was reworked, with chemical stripping of the VDA coating and reapplication using the modified process. Low-abrasiveness white nylon mesh pads were used-- not to reduce specularity but because coupon tests had shown that their use improved adhesion of the VDA. Microwave cavity tests of coupons coated using the new process repeatedly yielded nominal surface conductivity. References: AMR RSA - VDA Anomaly, JPL Problem\/Failure Report No. 5388, October 26, 2006. Amarit Kitiyakara, AMR Reflector Structure Assembly (RSA) - VDA Anomaly Summary, October 25, 2006.","Lesson ID":2057}
{"Driving Event":"On March 17, 2006, a crew of three (two workers and a superintendent) construction workers began to work on the roof of Building M6-794. Before working on the roof, however, the crew needed to wait on an aerial lift that was transporting materials to the roof for panel installations. The three construction workers began replacing the panels on the roof after the aerial lift delivered the supplies necessary. They started at the northwest corner of the building to replace roofing at that location and then moved to the southeast corner. As the employees continued to work on the roof, only the Safety Monitoring System was used as fall protection. The Safety Monitoring System alone would have been an acceptable form of protection if the width of the roof of Building M6-794 was less than 50 feet; however, this roof had a width of more than 50 feet which conflicted with OSHA standards. According to OSHA 29 CFR 1926.502(h)(1)(ii), safety monitors are intended to warn the employee when it appears that the employee is unaware of a fall hazard or is acting in an unsafe manner. According to OSHA 29 CFR 1926.501(b)(10), safety monitoring alone is allowed without a Warning Line System on roofs less than 50 ft wide. After the installation of a second panel, the crew took a break for lunch at which point the two employees left the site while the superintendent remained. Upon their return from the break, they resumed work and began installing the last roofing panel. While working on the third panel, the superintendent violated the requirements set by OSHA 29 CFR 1926.502(h)(1)(v) as he acted as the superintendent, safety monitor, as well as one who helped replace the third roofing panel. It was while the crew was working on the final when the employee lost his footing, released the panel that was held in his hands, and fell from the roof of the building. He fell approximately 10 feet, struck an air-conditioning unit with his head, and feel and another 7 feet to the loading dock. The worker passed due to severe head injury later that day.","Lesson ID":2056}
{"Driving Event":"Fault management is the capability of a spacecraft system to detect, isolate, and recover from in-flight events that may hinder nominal mission operations. Autonomous fault management (aka quotfault protection,quot quotFault Detection\/Isolation\/Recovery,quot quotsafing,quot etc.) is especially critical for deep space and planetary missions where the lightspeed communications delay may prevent timely intervention by ground control. However, increasingly challenging science objectives imposed upon deep space missions are taxing the ability of onboard spacecraft resources and control logic to manage in-flight fault events. Technical reviews of spaceflight missions by NASA and its contractors encounter pervasive fault management architecture, design, and verification\/validation (V&V) problems, including: Fault management design changes required late in the life-cycle (that often necessitate secondary changes elsewhere in the system), Insufficient project insight into the required system-level fault management testing, and unexpected test results that require resolution, Spacecraft operational limitations because restrictions are placed on the use of untested functions (in compliance with the quotfly-as-you-testquot principle). In addition, complex fault management subsystems are subject to in-flight anomalies like those described in References (1) through (6). Fault management requirements definition, design, and test practices used by NASA, the Department of Defense, and government contractors are not consistent or well defined. The terminology, engineering processes, tools, and training for fault management are not standardized. An industry-wide Spacecraft Fault Management Workshop was held in April 2008 to characterize fault management practices, identify trends, and provide a roadmap for improvements. For example, the workshop affirmed the benefits of ingraining fault management into the system architecture instead of the more common practice of attaching the completed fault management code to the flight software. Reference (7) summarizes the findings and recommendations from the workshop. References: quotAutonomous Transfer to Reaction Wheel Control May Lead to Safing Instability,quot NASA Lesson Learned No. 2048, NASA Engineering Network, April 14, 2009. (This lesson was archived and is no longer available) quotMRO Articulation Keep-Out Zone Anomaly,quot NASA Lesson Learned No. 2044, NASA Engineering Network, April 7, 2009. https:\/\/llis.nasa.gov\/lesson\/2044 quotMRO Spaceflight Computer Side Swap Anomalies [Export Version],quot NASA Lesson Learned No. 2041, NASA Engineering Network, December 16, 2008. https:\/\/llis.nasa.gov\/lesson\/2041 quotMars Global Surveyor (MGS) Spacecraft Loss of Contact,quot NASA Lesson Learned No. 1805, NASA Engineering Network, September 4, 2007. https:\/\/llis.nasa.gov\/lesson\/1805 quotErroneous Onboard Status Reporting Disabled IMAGE's Radio,quot NASA Lesson Learned No. 1799, NASA Engineering Network, July 10, 2007. https:\/\/llis.nasa.gov\/lesson\/1799 quotAnomalous Flight Conditions May Trigger Common-Mode Failures in Highly Redundant Systems,quot NASA Lesson Learned No. 1778, NASA Engineering Network, March 6, 2007. https:\/\/llis.nasa.gov\/lesson\/1778 Lorraine M. Fesq, quotWhite Paper Report: Spacecraft Fault Management Workshop Results for the Science Mission Directorate,quot Planetary Sciences Division, NASA\/Caltech Jet Propulsion Laboratory, March 2009.","Lesson ID":2049}
{"Driving Event":"The Ocean Surface Topography Mission features an Advanced Microwave Radiometer (AMR) instrument, built by the NASA\/Caltech Jet Propulsion Laboratory (JPL), which measures water vapor in the Earth's atmosphere. Following vibration test of the AMR at a contractor facility, inspection revealed a small region of de-bonding between a titanium fitting and the graphite composite skin of the radar Reflector Structure Assembly (RSA) (Reference (1)). After a bakeout of the AMR RSA that occurred 3 weeks later, inspection found a similar delamination between a pair of RSA pallet fittings and the graphite composite skin of the pallet (Figure 1). Thermal stress analysis traced the failures to thermal stresses induced during thermal cycling, which then propagated during subsequent vibration testing and thermal vacuum testing (Reference (2)). Figure 1.Inspection at JPL of RSA de-bond\/crack area. (On right side fixture, disbond\/crack observed that moved under slight load; on left side fixture, disbond\/crack observed that moved under load.) Figure 2.Close-up of right side fixture (circled in Figure 1) with 1 mil shims inserted into micro-crack area. (No shim would fit into left side fixture.) The failure mechanism was a mismatch in the coefficients of thermal expansion (CTE) for the bonded joints between the titanium fittings and the graphite structure at low temperature. [The remainder of this paragraph describes the inadequate inspection methods performed after the first delamination and the results of the 80x bondline inspection, ultrasonic imaging, and finite element method (FEM) thermal stress analysis used to characterize the damage after the second incident. It has been redacted for International Traffic in Arms Regulations (ITAR) compliance. U.S. Persons may obtain a copy of the complete document by contacting the JPL Office of the Chief Engineer (David Oberhettinger at davido@nasa.gov).] The RSA flight hardware was reworked, with titanium bolts added to secure all metallic-to-composite bonded joints. In addition, JPL has added institutional design rules (References (3) and (4)) that specifically require projects to design flight structures with specified safety factors for thermally-induced loading over the allowable qualification\/flight temperature ranges. These structural design rules are more specific about the required safety factors to use for structural design when it comes to analyzing different CTEs of the structure. References: OSTM AMR RSA S\/N 001 Local De-Bond Around ESS Fitting, Problem\/Failure Report No. 4481, July\/July Jet Propulsion Laboratory, May 3, 2006. OSTM AMR RSA S\/N 001 Local Dis-Bond Around Pallet Fitting, Problem\/Failure Report No. 4579, July\/July Jet Propulsion Laboratory, May 26, 2006. Design, Verification\/Validation and Operations Principles for Flight Systems (Design Principles), JPL Document D-17868, Rev. 3, December 11, 2006, Paragraph 4.2.5.7. Design, Verification\/Validation and Operations Principles for Flight Systems (Design Principles), JPL Document D-17868, Rev. 3, December 11, 2006, Paragraph 4.2.5.5.","Lesson ID":2038}
{"Driving Event":"Since 1968, the flight software (FSW) used aboard NASA human and robotic spacecraft has grown in size by a factor of ten every ten years. The primary FSW for the NASA Crew Exploration Vehicle (Orion) and the Mars Science Laboratory (MSL) are each expected to exceed one million lines of code (LOC). The growth trend is expected to continue because of increasingly ambitious mission requirements and because of the advantages (e.g., zero mass, flexibility) of situating new functionality in software or firmware rather than in hardware. An increase in FSW size is often accompanied by an increase in FSW \"complexity\"-- defined as a state in which the FSW is difficult to understand and verify-- and an increase in risk. Problems with FSW during a variety of NASA spaceflight missions, like those recently reported in References (1) and (2), led NASA to conduct a study (Reference (3)) of the engineering activities-- from requirements development through operations-- that lead to growth in FSW size and complexity. The final report from the study attributes NASA's lack of control over these FSW characteristics to cultural factors such as: Cost and schedule pressures that lead FSW managers and developers to reduce or eliminate activities where the benefits are not as easy to quantify as those from the production of code. Lack of enforcement of FSW standards and local best practices. Pressure to re-use software from a previous mission because it is \"flight-proven\" and presumed to be of lower risk. Emphasis on the flight project at hand, with few programmatic incentives for project management to contribute to infrastructure and process improvements that benefit future missions. The NASA final report's findings in the areas of systems engineering, software architecture, testing, and project management are summarized in the Lessons Learned section below, and its corresponding recommendations are summarized in the Recommendations section. References: \"MRO Spaceflight Computer Side Swap Anomalies,\" NASA Lesson Learned No. 2041, NASA Engineering Network, December 16, 2008. http:\/\/www.nasa.gov\/offices\/oce\/llis\/imported_content\/lesson_2041.html \"MRO Articulation Keep-Out Zone Anomaly,\"NASA Lesson Learned No. 2044, NASA Engineering Network, April 7, 2009. http:\/\/www.nasa.gov\/offices\/oce\/llis\/imported_content\/lesson_2044.html \"Final Report: NASA Study on Flight Software Complexity,\" NASA Office of Chief Engineer, March 5, 2009 \"NASA Systems Engineering Handbook,\" NASA SP-2007-6105, December 31, 2007. \"Improving Fault Management for Spaceflight Missions,\" NASA Lesson Learned No. 2049, NASA Engineering Network, April 21, 2009. http:\/\/www.nasa.gov\/offices\/oce\/llis\/imported_content\/lesson_2049.html","Lesson ID":2050}
{"Driving Event":"A battery lift adapter manufactured to support ground processing for the HST Servicing Mission 4 failed during proof testing. A failure occurred in a critical weld which propagated to other welds as the failure progressed and the load path changed. A failure analysis of the welds showed that although the welds were produced in accordance with accepted design and manufacturing standards, the welds had subsurface cracks that propagated under load and caused the failure. The cracks were caused by insufficient filler material being introduced into the weld as it was formed. For 6000 series aluminum, filler material is required to dilute the base alloy into an alloy that will weld without cracking. The weld was specified as a 1\/8\" fillet weld. The small weld size contributed to the degree of difficulty in producing a weld with sufficient filler to prevent cracking, and yet meet the size specification.","Lesson ID":1860}
{"Driving Event":"The internal protective devices (PTC and CID) used in the most common commercial-off-the-shelf (COTS) Li-Ion cells (cylindrical 18650's) have been extremely reliable at a single-cell level and have resulted in total prevention of the cell reaching a hazardous condition. However, test programs have indicated that batteries built with cylindrical COTS cells in multi-cell configurations (series and\/or parallel) have experienced thermal runaway under various test conditions.","Lesson ID":2046}
{"Driving Event":"Four spacecraft propulsion system pyrovalve quotno-firequot failures were investigated by the NESC (NASA Engineering and Safety Center). In all four cases, a normally closed pyrovalve failed to actuate during tests in which simultaneous firing of dual initiators failed to ignite the booster charge. In each failure, a common aluminum Y-shaped PCA (Y-PCA) manufactured by CONAX was used to mechanically accommodate the two initiators and to direct the individual output products of each initiator towards the booster charge. Booster charge ignition is intended to generate sufficient pressure to actuate the pyrovalve. Testing of both single and dual initiators revealed important design characteristics affecting pyrovalve device performance. They include Primer Chamber Assembly (PCA) geometry and material properties, as well as operational effects on combustion product flow, and resulting energy transfer to the booster.","Lesson ID":2045}
{"Driving Event":"Environmental Monitors on Station (EMOS) is a NASA program to design, build, and test a series of environmental monitors for installation on the International Space Station (ISS). The Vehicle Cabin Atmosphere Monitor (VCAM) is a rack-mounted EMOS instrument for monitoring the air in the ISS. VCAM's pre-concentrator, gas chromatograph and mass spectrometer will detect trace amounts of organic molecules. Internal software will perform the identification and quantification. VCAM is delivered with an Orbital Replacement Unit (ORU), a delivery system for the consumable gases (i.e., a carrier gas and calibrant mixture) required for VCAM operation. Each ORU (Figure 1) is designed for 12 months of operation, followed by on-orbit replenishment. Figure 1. VCAM ORU In accordance with a standard JPL cleaning procedure, isopropyl alcohol (IPA) was used liberally on ORU parts, both prior to and during fabrication and integration. The flow of helium gas at a slightly elevated temperature through the ORU units during a purging procedure was expected to remove any IPA residue. Instead, while testing the VCAM with an ORU installed, excessive levels of residual IPA were detected in both the carrier and calibrant gases (Reference 1). Due to the high sensitivity of the mass spectrometer, the IPA residue requirement calls for less than 200 parts per billion (ppb), whereas the detected concentration was in the double and triple-digit parts per million (ppm) range. This high level of residual IPA interferes with the VCAM Level 1 requirement to detect hazardous concentrations of IPA within the range of 1 to 10 ppm in the ISS cabin air. VCAM measurements verified that IPA adsorbed onto soft goods and having filled small volumes would not likely be removed by the standard purging protocol. IPA measurements made following standard purging trials (e.g., bakeout) indicated that the IPA continued to desorb. Thermal-vacuum purging was needed to reduce the residual IPA concentration below the 200 ppb requirement. In this ORU-specific case, placing the unit in thermal-vacuum at 10 -5 torr and 80 degrees C for 150 to 200 hours proved adequate after other alternative methods were tried without success. Follow up testing confirmed that IPA levels remained at less than 200 ppb, and further desorbing of IPA was not observed. References: quotIsopropyl Alcohol Residue,quot JPL Problem\/Failure Report No. 13449, September 5, 2008. quotGeneral Cleaning Requirements for Spacecraft Propulsion Systems and Support Equipment, Detail Specification for,quot Jet Propulsion Laboratory (JPL) Spec No. FS504574C, May 28, 1974.","Lesson ID":2043}
{"Driving Event":"Mars Reconnaissance Orbiter (MRO) was launched in August 2005 with a mission to study the Martian climate, identify water-related landforms and aqueous deposits, characterize potential landing sites for Mars landers, and provide UHF relay for science data produced by these future missions. The MRO spacecraft is furnished with two redundant onboard computers (i.e., two Command & Data Handling Subsystems, or C&DHs), referred to as Side A and Side B, that share continuously updated state and sensor data. One computer remains active, while the second serves as a quotcold backupquot that can boot in tens of seconds. In March 2007, 4 months after beginning the science phase of its mission, telemetry alerted the operations team at the NASA\/Caltech Jet Propulsion Laboratory to two successive timeouts of the spacecraft's heartbeat watchdog timer (Reference (1)). The first timeout prompted onboard fault protection (FP) software to order a warm reset of Side A. The second timeout triggered an autonomous switch or quotside swapquot to the Side B computer. After the booting of Side B, FP autonomously configured the vehicle into safe mode. This prompted an intensive investigation that failed to determine the root cause and rule out a permanent failure of Side A. Eleven months later, MRO performed another unrequested warm reset followed by an unrequested side swap-- this time back to Side A of the C&DH (Reference (2)). Since Side A was now functioning properly, it was clear to JPL investigators that the fault on Side A which caused the first swap was cleared by the power cycling of Side A, allowing them to rule out a permanent hardware failure. This prompted JPL to re-open the investigation. In the course of this, they revisited information on a defect (quotPPCI Erratum 24quot) in the Power Peripheral Component Interconnect (PPCI) bridge Application-Specific Integrated Circuit (ASIC) in the RAD750 Spaceflight Computer (SFC) that was first reported in 2006 by the RAD750 vendor (Reference (2)). Under very specific conditions, this ASIC defect can cause the memory controller (Figure 1) to halt operations, resulting nominally in a warm reset of the computer that clears the condition. Figure 1. Block diagram of the RAD750 SFC with the memory controller highlighted This reported defect had not raised much JPL concern in 2006 because of the event's rarity and the belief that it would result merely in a warm reboot of the computer. However, the MRO project did not fully understand the low level details of RAD750 operation and its interaction with the MRO system design configuration. Specifically, ... The remainder of this paragraph describes the failure mechanism experienced by the MRO project specific to its design implementation of the RAD750 Spaceflight Computer. The text has been redacted for International Traffic in Arms Regulations (ITAR) compliance. quotU.S. Personsquot may obtain a copy of the complete lesson learned by contacting the JPL Office of the Chief Engineer (David Oberhettinger at davido@nasa.gov). Unintended C&DH side swaps and spacecraft placement into safe mode may interrupt telemetry downlink and, under some circumstances, threaten the mission. In October 2008, the MRO project implemented a vendor-recommended workaround, involving commanding a change to a parameter and a setting within the PPCI bridge ASIC, that should prevent further MRO side swap incidents. References: quotMRO Side Swap to Side B,quot JPL Incident Surprise Anomaly (ISA) No. Z90507, March 14, 2007. PPCI Bridge ASIC Master Errata List, BAE Document # A13917 Revision (-) Version 1.3, Errata List for PPCI ASIC P\/N 244A907 (Bridge Chip). quotExcess Latency in SPS Safe Mode Predicts Delivery,quot JPL Incident Surprise Anomaly (ISA) No. Z90508, March 14, 2007. quotFinal Report on the Mars Reconnaissance Orbiter C&DH Side Swap #1 and #2 Anomalies,quot JPL Document No. D-37650 (MRO Report No. MRO-36-747), October 16, 2008.","Lesson ID":2041}
{"Driving Event":"Mars Reconnaissance Orbiter (MRO) was launched in August 2005 with a mission to study the Martian climate, identify water-related landforms and aqueous deposits, characterize potential landing sites for Mars landers, and provide UHF relay for science data produced by these future missions. The spacecraft features three articulated, motorized, appendages: one High Gain Antenna (HGA) that tracks Earth to downlink science data and two Solar Arrays (SA) that track the Sun to supply spacecraft power. Their pointing is controlled by flight software (FSW) that limits each appendage's acceleration\/deceleration and rate of motion, in each axis, toward the final inner and outer gimbal angles needed to point the appendage at the target. All FSW pointing commands must pass through a Keep Out Zone (KOZ) algorithm that constrains each appendage's motion within a swept volume that prevents inadvertent contact with the spacecraft structure, another appendage, or the payload field-of-view. The MRO KOZ, instead of being defined as an inviolate area, was defined as a space where appendage motion would be arrested and reversed. A KOZ boundary that was somewhat flexible-- often referred to as a quotreaction zonequot-- was implemented so that appendage motion could be safely constrained without incurring sudden stops and jitter that could degrade high resolution imaging. The KOZ algorithm's control parameters limited the depth of penetration into this area to a fraction of the distance between the boundary and any possible physical contact. Such an implementation, rather than inviolate boundaries with the familiar 'hard' and 'soft' stops on the actuators, was chosen for implementing the movement of the two-axis gimbal called upon to execute MRO's complex coordinated motions. Keeping the penetrations small and benign was accomplished by setting appropriate control parameters. The allowed spaces (Figure 1) were determined through pre-flight analysis and were verified by testing. Figure 1. Three shaded areas depict the geometry of MRO two-axis gimbal management In November 2007, one year after MRO began science operations, an anomalously large SA appendage KOZ violation occurred, resulting in actual appendage contact with a thermal blanket (Reference (1)). Mechanical resistance by the blanket caused motor rate errors that onboard fault protection interpreted as failure of both redundant gimbal motors, and fault protection commanded a warm reset of the flight computer and entry into safe mode. The SA contacted the spacecraft because the appendage motion needed to reach the targeted gimbal angles placed it near a quotkinematic singularity.quot 1 Travelling at the maximum allowed rate, the appendage's maximum allowed deceleration was insufficient to arrest the appendage's motion after it penetrated the KOZ and before it resulted in contact. The parameters for the combination of maximum rate and maximum acceleration had been set pre-launch to values that were incorrect for KOZ enforcement. The interactions between these critical parameters were not well-documented, and their effect on KOZ penetration escaped detection in the pre-launch verification and validation process. The non-standard implementation approach for the KOZ was exacerbated by miscommunications caused by imprecise terminology, and by staff turnover. Hence, the elastic nature of the boundary and the potential for a kinematic singularity were not widely understood throughout the MRO flight system team (Reference (2)) or by the FSW developers responsible for the algorithm implementation. The project failed to write and verify a spacecraft system-level design requirement that completely defined all potential combinations of appendage movement directions and rates in order to prevent inadvertent contact. There were also no requirements for back-up measures to prevent collisions. The KOZ violation and spacecraft contact by the SA caused no detectable damage, but science operations were halted for two months until it was determined that the mission could safely continue. The MRO project has implemented corrective actions that have greatly reduced the residual risk of future MRO appendage collisions. 1Two-axis gimbal systems can be used to point anywhere in three-dimensional space, except when the inner gimbal axis (fixed to the spacecraft body) becomes aligned with the desired target vector. In this case the inner axis becomes useless for pointing control. This is known as a quotkinematic singularity.quot Near the singularity, small pointing changes require that the inner axis moves a very large amount at very high speed (in the limit it must move 180 degrees at infinite speed). References: quotMRO Reboot on 2007-311T15:20:59,quot JPL Problem\/Failure Report No. Z92078 (ISA Z91824), January 15, 2008. quotMars Reconnaissance Orbiter Articulation Keep-Out Zone Anomaly Final Report,quot JPL Document Nos. MRO-565-86 and JPL D-37648, October 27, 2008. Todd J. Bayer, quotSystems Engineering Lessons Learned from the Mars Reconnaissance Orbiter Mission,quot NASA\/Caltech Jet Propulsion Laboratory, December 2, 2008. Robert D. Rasmussen, Gurkirpal Singh, David B. Rathbun, and Glenn A. Macala, quotBehavioral Model Pointing on Cassini Using Target Vectors,quot Proc. SPIE 2803, 271 (1996), DOI:10.1117\/12.25342. http:\/\/spiedl.aip.org\/getpdf\/servlet\/GetPDFServlet?filetype=pdf&id=PSISDG002803000001000271000001&idtype=cvips&prog=normal","Lesson ID":2044}
{"Driving Event":"A SUBSA ampoule contained a lithium chloride\/potassium chloride salt encapsulant with an indium antimonide sample. During a gradient freeze processing run, the encapsulant caused the sample to undercool and undergo non-directional solidification; consequently, breaking the quartz ampoule.","Lesson ID":1919}
{"Driving Event":"During the operation of the PFMI investigation, the motors became erratic. Troubleshooting revealed that the motor constants had been altered due to radiation exposure.","Lesson ID":1916}
{"Driving Event":"The Tunable Laser Spectrometer (TLS) is one of three instruments that make up the Sample Analysis at Mars (SAM) instrument suite within the Mars Science Laboratory (MSL) spacecraft payload. In developing and operating the MSL TLS, the NASA\/Caltech Jet Propulsion Laboratory (JPL) seeks to understand Martian atmospheric and geophysical processes by measuring methane, water, and carbon dioxide abundances in the Martian atmosphere and soil with unprecedented accuracy. For any TLS, the backscattering of the instrument's primary laser beam from reflective internal component surfaces produces secondary laser beams, and pairs of these scattering surfaces can set up quotoptical standing waves.quot When combined with the primary laser beam at the detector, this interference can reduce the sensitivity of these instruments to a level below performance requirements. Because its compact design places various internal surfaces in close proximity, the JPL TLS design is especially vulnerable to standing wave contamination or quotfringes.quot Using the TLS Development Model (DM) as a testbed (Figure 1), JPL employed a systematic approach to assessing the potential impact of each optical surface on standing wave amplitudes. Realignment of optical elements within the DM was successful in attenuating optical standing waves to acceptable levels. Figure 1. The JPL TLS DM unit provided an ability to adjust and realign optical elements to optimize instrument performance. When the flight unit of the MSL TLS opto-mechanical system was first integrated and performance-tested in August 2007, however, optical standing waves were observed that greatly exceeded those previously observed in the DM unit (Reference (1)). This threat to mission performance was mitigated by adding mylar sheet material to the MSL flight TLS foreoptics that attenuated the amplitude of the fringes. The reduction of standing wave fringe amplitudes in tunable laser spectrometers is typically accomplished by making small adjustments in instrument alignment after the system integration. On the JPL TLS flight unit, however, the optical elements (that were adjusted in the DM unit) had been staked and bonded prior to integration and test (I&T) (Reference (2)). Although staking of flight units is useful in preventing unintentional shifts in component alignment, it greatly restricted the ability to make any optical alignment adjustments at the laser\/foreoptics end of the instrument after system integration. References: quotTLS Science Standing Waves,quot JPL Problem\/Failure Report No. 6617, August 17, 2007. Robert T. Menzies, quotReport on the TLS Standing Waves Tiger Team Activity: Findings & Recommendations,quot December 7, 2007.","Lesson ID":2036}
{"Driving Event":"Because there was intense public and Congressional interest in the NAOMS data, NASA promised the Congress initial release of data (called phase 1) by the end of 2007. In a memorandum dated November 19, 2007, the NASA administrator directed the Chief of the Office of Safety and Mission Assurance to lead an effort to release as much NAOMS survey information as possible by the end of 2007. The task was executed soon thereafter with the initial posting of NAOMS information on the NASA website on December 31, 2007. Phase 1 was completed on February 6, 2008, with a more comprehensive web posting of NAOMS information. Some people and organizations outside of NASA have said that the necessary data redaction for Phase 1 was overly conservative, that more data could have been released. After the Phase 1 postings, NASA initiated another review of all the NAOMS survey responses in order to allow for further release of information. A project team was selected to implement the recommendation from the NASA Information Release Advisory Panel (2008) relating to an additional release of NAOMS Phase 1 information by the end of the year (2008). This effort is referred to as Phase 2 of the NAOMS information release. The objective of the NAOMS Phase 2 information release was to redact the raw NAOMS survey responses using a redaction release strategy that: Releases the maximum amount of survey information, but - Does not release commercial confidential information -Meets NASA's obligation for survey response participant confidentiality as defined by the NAOMS Information Release Advisory Panel (2008) - Minimizes the threat to participant anonymity NASA intended to protect pilot participant identity and never planned to publish NAOMS raw data. NASA had to engage in an optimization process by releasing as much of the NAOMS data as possible, yet still maintain the anonymity and confidentiality of the pilots who were the participants in the survey (Phase 2 data). In retrospect, the NAOMS data release project required extensive efforts to release phase 2 data. These included, planning, redaction, quality assurance, risk analysis, and validation efforts. The cost of NAOMS phase 2 was approximately $1.1M. NAOMS Phase 2 Release Executive Summary dated September 30, 2008 states that NAOMS survey responses and the methodology used to acquire them have not been peer-reviewed. In addition, no product of the NAOMS project, including the survey methodology, the survey responses, and analysis of the responses, should be viewed or considered as having been validated. Listed below are examples of inconsistencies from the survey responses: Example #1: Some \"Fokker\" aircraft identified as \"Poker\" aircraft Example #2: Boeing 737-300 aircraft identified by the following descriptions: B 737-300 B\/737-300 B-737-300 B 737 300 Bowing 737 300 Many more combinations of example #2 exist Example #3: There are two subsets with the title Weather Diversion Example #4: Some free text truncated after 252 characters. Example #5: There are 25,763 records in the .mdb file and 25,105 records in the SAS files. Example #6: Over 400 AC survey responses misfiled in the GA surveys. Example #7: Total number of records, as compared to Phase 1, do not match Example #8: Joint Implementation Measurement Data Analysis Team missing free text responses Example #9: Not all Phase 1 data was supplied for Phase II","Lesson ID":2016}
{"Driving Event":"A. The pressure to demonstrate progress on approximately 2-week intervals lead to: 1.Adoption (Premature commitment) to a Bayesian model for Probability of matching records before understanding the entire scope of the problem. 2.Setting aside the Success-Tree development for the Global scenario and re-visiting it after the decision to post had been made. (Finally, there was time to think about it.) 3.Setting aside the preliminary White paper on the Bayesian analysis methodology, resulted in not locking-down critical definitions and understanding of the Bayesian (MCMC) methodology. Some explanation of the methodology was changing right up to the time of our presentation to the National Academy of Sciences. 4. Calculating probabilities before calculating and examining the protection metrics. 5.Lack of time to derive the relationship between distance-Metrics and probability of defeating redaction. B. Consultation with the National Academy of Science should have been the first step. It was nearly the last step. This consultation would have provided a better understanding of the problem and provided recommendations on methodology early on in the project. C. Pressure to demonstrate progress (early on in the project) to management caused crude results to be presented due to the fact that the unique problem was not understood. More time was needed to mature the process. D.Throughout the project any lower risk values were suspect to the risk team. Certain members of the team fell toward a higher degree of belief for the worst- case: the belief that if something can happen, it has happened or will happen.","Lesson ID":2017}
{"Driving Event":"Technical standards capture lessons learned and new technology, provide a common base for interoperability, and facilitate engineering excellence. These include standards published by NASA, other government agencies, standards developing organizations (SDOs), and international bodies. Standards, specifications (specs), and handbooks published by NASA are particularly valuable as they provide direction that is specific to the space environments and other design challenges that are faced solely by NASA missions. However, federal government policy (Reference (1)) explicitly discourages the preparation of new NASA standards and handbooks where existing industry standards are technically adequate. Although this has the salutary effect of minimizing the maintenance of duplicative standards, it also means that a NASA system operating in the vacuum of space has had to justify non-use of a grease specification intended for army tank tracks. Another extreme-- but real-- example is the designation of a paint specification for naval ships for use in spacecraft coatings. Clearly, general-use industry standards and specs may not be optimal for spaceflight applications where, for example, the out-gassing properties of lubricants and paints must be rigorously controlled. Furthermore, many specs have recently been rewritten to require the use of recycled and commercial-off-the-shelf (COTS) materials in the production process. Requirements have been eliminated that have called for (1) customer notification of changes in product materials and processes and (2) testing to re-qualify the product over the full range of properties. The U.S. Office of Management and Budget (OMB) requires NASA and other federal agencies to report how many government standards were eliminated and how many industry voluntary consensus standards (VCS) were adopted each year, but projects have not been required by the OMB to assess the risk of applying non-optimal requirements. To minimize this risk, NASA has pioneered the preparation of application notes that add NASA-specific cautions or caveats to a number of industry standards adopted by NASA. The purpose of the application notes is to identify provisions in a document that may be widely applicable to general industry or even to the aerospace industry, but may be incorrect or misleading when used in the design of NASA spaceflight systems. The application notes are prepared by the NASA Engineering Standards Panel (NESP) and made available, along with the full text of the industry documents, in the NASA-maintained standards repository (Reference (2)). A pyrovalve (pyrotechnic device) specified for use as a backup in the Mars Reconnaissance Orbiter (MRO) Propellant Isolation Assembly (PIA) provides an example of the need for an application note. The material used to fabricate the primer chamber component was flagged as susceptible to stress corrosion. Inspection of a previously activated unit (Figures 1 and 2) showed failure due to stress corrosion cracking of the primer chamber body (PCB) (Reference (3)). The Materials Identification and Usage List (MIUL) for the pyrovalve identified the PCB as fabricated from 7075 aluminum alloy with a T651 temper. AMS-QQ-A-225\/9, the industry spec adopted by NASA and DoD for procurement of this material, states that, quotThis alloy is intended for use where high strength and good corrosion resistance are requiredquot (Reference (4)). In this application, however, the 4000 psi of high chloride combustion gas pressure to which the material is subjected upon firing of the booster charge causes stress corrosion cracking. ............ Figure 1. Scanning electron microscope (SEM) image shows evidence of stress corrosion cracking of the MRO PIA backup pyrovalve. Figure 2. Effect of stress corrosion cracking on the MRO PIA backup pyrovalve. An application note in the NASA standards repository would alert NASA users of Reference (4) to the circumstances under which Paragraph 6.1 (Intended Use) is misleading in regard to stress corrosion resistance. The application note would point NASA users to MSFC-SPEC-522B for rating of resistance to stress corrosion cracking, and would provide guidance on the threshold crack propagation stress for NASA applications. References: OMB Circular A-119, quotFederal Participation In The Development And Use Of Voluntary Consensus Standards And In Conformity Assessment Activities,quot February 10, 1998 NASA Standards and Technical Assistance Resource Tool, http:\/\/standards.nasa.gov quotValves Corrosion,quot JPL Problem\/Failure Report No. Z85547, January 21, 2005. AMS-QQ-A-225\/9, quotAluminum Alloy 7075, Bar, Rod, Wire, and Special Shapes; Rolled, Drawn, or Cold Finished,quot Society of Automotive Engineers (SAE), Paragraph 6.1: Intended Use, July 1, 1997.","Lesson ID":1997}
{"Driving Event":"The Mars Science Laboratory (MSL) flight spare heatshield was mishandled in August 2008 during ground handling following a characterization test at a contractor facility (Reference (1)). The mishap occurred while technicians were manually rolling the vacuum-bagged heatshield, mounted on its Nose-Up Fixture (NUF), out of the oven on two guided tracks. The tracks form a ramp from the oven entrance to the floor below. One of the two tracks has a guide slot that matches the grooves on the NUF's steel casters. As the heatshield mounted on its fixture rolled out of the oven, the two rear casters jumped the ramped tracks, resulting in a fall of 6 to 7 inches to the concrete floor (Figure 1). To determine the extent of damage to the heatshield from the fall-induced shock, the contractor performed visual inspection, a coin tap to identify any delaminations in the carbon composite material, and X-rays to assess any deformation of the core. No defects were identified by these inspection techniques, and the disposition of this production process anomaly was to use the flight spare heatshield as-is. Figure 1. Arrow points to one of the two rear casters that each sat left of its track after the fall. This ground handling incident was attributed to the following factors: An inadequate work procedure that did not provide moving instructions. Grooved track casters that had been rotated 180 degrees from the planned direction of travel when inserted into the track slot. Casters not set to the direction of linear travel causes a tendency for the casters to swivel during movement, and the momentary lateral direction during this swivel can direct the fixture off the tracks. Steering sticks, T-bars, and jacks were not used to constrain and guide the casters on the tracks. Contributing causes were also identified: The NUF is considered a tool, and Functional Failure Mode & Effect Analysis (FFMEA) is not typically performed on tools. The hardware drawing did not list a steering stick and a T-bar as accessories. There was no cognizant engineer providing oversight during the operation. Appropriate skills training was not up-to-date, and the curriculum to be used in learning plans was not clearly defined. The ground handling crew had no experience with the NUF tool, and it was the first time it had been placed in the oven. References: (1) Heatshield Structure #1 (Flight Spare) Handling Drop, JPL Problem\/Failure Report No. 13366, August 27, 2008.","Lesson ID":1996}
{"Driving Event":"To better address the need for improved high angle of attack capabilities, NASA formed a High Alpha Technology Program (HATP). The focal point of this program was selected to be a highly modified F-18 airframe.","Lesson ID":1604}
{"Driving Event":"On the morning of Monday, November 28, 2005 personnel of the NASA Dryden Communications Facility at building 4824 discovered that antenna support pole number 2 had fallen to the ground sometime over the preceding weekend. It had broken at about two feet below grade. Visual inspection revealed wood decay at the location of the break. In its fall it stripped off most of the antennae from the North side of pole number 1, which it narrowly missed hitting directly. Before reaching the ground, it also impacted an extendable quad-yagi antenna. No one was injured. Within the potential reach of the 78 ft. tall pole was all of B4824 with its human work spaces, and many other communication assets. Root causes for the pole failure are: 1. Inadequate original pole preservative treatment that allowed wood decay. 2. Suspected unusually high local wind possibly due to mountain wave activity. 3. No requirement for periodic pole inspection and maintenance.","Lesson ID":1734}
{"Driving Event":"The Lunar Reconnaissance Orbiter needed low levels of Electromagnetic Interference from its components. Preliminary measurements indicated that the traveling wave tube amplifier (TWTA) would not meet the requirements. Therefore, the input filter on the electronic power conditioner (EPC) was redesigned, giving excellent EMI rejection in the breadboard. However, when the protoflight unit was tested, the EMI was slightly worse then the preliminary measurements. This was found to be due to RF paths created when the unit was packaged in its metal box. An external filter was designed which reduced the EMI by more than 30 dB, allowing the TWTA to be integrated with the LRO satellite passing all system tests.","Lesson ID":1864}
{"Driving Event":"NASA Glenn Research Center was a pioneer in the computer aided design of TWTs, and successfully transferred the technology to the commercial TWT industry and to DOD. The use of computer modeling allowed the LRO TWTA program to obtain two space qualified TWTAs with two TWT builds. In the Communication Technology Satellite program, done before any computer modeling was introduced, 32 builds were needed before a successful TWTA was obtained.","Lesson ID":1863}
{"Driving Event":"The International Space Station (ISS) Program uses fiber optic cabling extensively in the audio, video, and high rate data subsystems. KSC accepted fiber that was sub par because we did not have a process to properly inspect and verify the quality of work from the manufacturer.","Lesson ID":1876}
{"Driving Event":"Electronic, switch-mode, DC-to-DC (DC-DC) converters convert one direct current (DC) voltage level to another by storing the input energy temporarily and then releasing that energy to the device's output at a different voltage. Over the past 20 years, there have been few NASA flight projects that have not experienced problems or failures with these complex assemblies (Figures 1 and 2). Although there have been a few suspected in-flight failures (e.g., Gravity Recovery and Climate Experiment (GRACE), International Space Station, Hubble Space Telescope), most problems and failures have occurred during subsystem and system development and test (Reference (1)). Figure 1. Front, back, and side views of a typical DC-DC converter Figure 2. Internal views of typical DC-DC converters DC-DC converters are hybrid devices that are difficult to characterize, and most anomalies have been attributed to part misapplication. The primary source of device specifications for the subsystem designer is the manufacturer's product data sheet, but this source does not typically list all the needed information. In addition, many spacecraft applications place the device under a low load, an application that is not usually reflected in the product data sheet specs. If the subsystem application differs from the device's optimal electrical parameters, the DC-DC converter tends to suffer a very sharp decline in performance. This makes even a carefully selected DC-DC converter vulnerable to design changes over the course of flight system development, and because spacecraft power converters often arrive late in the development of a flight system the selected power converter may no longer be suitable. DC-DC converters also pose quality and reliability challenges. Several spaceflight projects have experienced failures during Destructive Physical Analysis (DPA), radiation test, or life test (e.g., Jason, Space Infrared Telescope Facility, Mars Exploration Rover, Materials Science Research Rack), or due to poor device workmanship (Figure 3) or vulnerability to bench test or environmental test environments (i.e., Cloudsat, Active Cavity Radiometer Irradiance Monitor, Hubble Space Telescope). Even for spaceflight-rated (Class K) devices, many of the provisions in the military specification for hybrids (MIL-PRF-38534, Reference (2)) are inadequate to achieve flight system reliability. Because spaceflight requirements are more stringent than those for typical military applications, MIL-PRF-38534 requirements are inadequate for NASA applications in such areas as capacitor test, hybrid electrical derating and Worst Case Analysis, and low radiation dose rate and single-event effects limits. Additionally, the document does not require requalification of the device after some types of design changes. Sometimes designers have tried to save costs by using the cheaper Class H or lower class devices instead of Class K, only to later incur Integration & Test costs far outstripping the initial savings. Figure 3. Optical photograph of the generally poor workmanship for this device. Recognizing that DC-DC converters may rank as the most troublesome recurring NASA design problem after Field Programmable Gate Arrays (FPGAs), the NASA Engineering Safety Center (NESC) initiated a study to provide guidance to NASA users of DC-DC converters. Electrical testing was conducted to derive test methods that would reduce the risks of device application in NASA spaceflight systems-- both crewed and robotic. A NASA guidance document was prepared to assist flight projects with selection, purchase, and testing of these devices, and it documents lessons learned from device use. Four NASA Centers (GSFC, JPL, MSFC, and JSC) participated in this study, and the draft document (Reference (3)) is already in use by JPL spaceflight projects. References: R. Lloyd Keith, Linda Facto, Shavesha Rutledge, NESC Task Summary: Guidance for Off-the-Shelf DC\/DC Converter Users, April 7, 2008. MIL-PRF-38534, General Specification for Hybrid Microcircuits, Rev. F, April 12, 2006. NASA Guidelines for the Selection & Application of DC-DC Converters, May 1, 2008. DC-DC Converter Applications, NEN #0603, NASA Lesson Learned Information System, October 28, 1998.","Lesson ID":1879}
{"Driving Event":"A radio frequency (RF) waveguide transfer switch failed five months after the insertion of Mars Reconnaissance Orbiter (MRO) into Mars orbit. The likely cause was debris-induced RF breakdown that pyrolized a polyimide tape window in the switch, injecting additional debris that jammed the switch. The NASA\/Caltech Jet Propulsion Laboratory (JPL) published a lesson learned (Reference (1)) that describes this August 2006 incident and offers recommendations for materials design, mission design, and reconsidering exemptions to the JPL single-point failure policy. The source of the debris that triggered this chain of events is not known and was not central to the findings of this 2007 lesson learned. However, the most likely contamination source to have produced the conductive particle and resultant high voltage breakdown was flaked silver plating from either the rigid or flex portion of the X-band RF waveguide. Previous NASA and Department of Defense missions have experienced silver plating anomalies on waveguides, and it may be a continuing problem. In late 2006 and early 2007, the Solar Dynamics Observer (SDO) spaceflight project had issues with a silver-plated rigid and flexible Ka-band waveguide obtained from the same vendor as the MRO waveguide. Incoming inspection at NASA revealed evidence of incorrect plating procedures (Figure 1) and varying levels of contamination or corrosion (Figure 2). Figure 1. Peeled silver plating in the SDO waveguide S\/N 004. Figure 2. Evidence of surface contamination on the inside of a newly purchased MRO waveguide. Destructive Physical Analysis (DPA) performed by JPL in 2007 on the rigid and flex portions of flight spares obtained from the same source confirmed the presence of contamination, flaking, and corrosion (Reference (2)). This included a Phoenix flight spare manufactured in 1999 that showed surface stains similar to Figure 2. Chemical analysis of a white powdery substance inside the rigid portion of a MRO waveguide purchased in 2007 showed the presence of silver carbonate and silver oxide, with traces of chlorine, titanium and hydrocarbon oil. Spectral analysis of corroded areas (Figure 3) within the above waveguide provided evidence of sodium, chlorine, calcium, magnesium, and silicon contamination, as well as peeling silver plating (Figure 4). Figure 3. Corroded area in newly purchased MRO waveguide. Figure 4. Evidence of peeling silver plating in newly purchased MRO waveguide. The results of the 2007 study documented in Reference (2) suggest that poorly plated RF waveguides pose a low to moderate risk of corona or arcing in NASA spacecraft that are presently in operation or under development. References: quotMRO Waveguide Transfer Switch Anomaly,quot NASA Lesson Learned No. 1796, NASA Engineering Network, May 29, 2007. Eric Archer, quotDPA Results on Waveguide,quot October 22, 2007.","Lesson ID":1878}
{"Driving Event":"A continuing challenge facing spacecraft designers is that vendor-supplied materials data sheets often cannot be relied upon and do not cover materials properties throughout the ranges of extreme environmental conditions found in spaceflight. Even when the acceptable environmental range is clearly defined in the supplied document, poor information on the boundary conditions and margins around the qualified limits may result in material failure. When the susceptibility of selected materials to temperature, radiation, vacuum, etc. is subsequently detected during testing, the required redesign and retest can significantly impact project cost and schedule. This issue has arisen on recent NASA\/Caltech Jet Propulsion Laboratory (JPL) spaceflight projects. For example: The major design problem that befell the CloudSat project over its development history was the mission-critical failure of its high voltage power supply during thermal-vacuum test (Reference (1)). A value for the thermal conductivity of a potting compound (in watts\/meter-Kelvin), obtained verbally from a vendor, was found to be inaccurate by an order of magnitude. The thermal conductivity of two silver-filled conductive epoxies used in the Mars Science Laboratory (MSL) landing radar was specified in the material data sheet as 7-10 watts\/meter-Kelvin (W\/m-K) range whereas when tested in the MSL application the epoxies were found to have a conductivity of only approximately 1 W\/m-K. Over many years, JPL has retained extensive amounts of materials data obtained during characterization, testing, and flight, but it has resided mainly in the personal files of individuals and has not been available for institution-wide use. When a search for data on a material measured at JPL has not been fruitful, time and money has been spent performing duplicate measurements. To improve the availability of historical materials data and mitigate the risk of using incorrect data, JPL has developed an online Spacecraft Materials Database (Reference (2)). The database presently holds 168 datasets on 88 materials in the following formats: Both raw and plotted materials data measured at JPL, including data from Differential Scanning Calorimetry (DSC), Thermal Mechanical Analysis (TMA), Dynamic Mechanical Analysis (DMA), Thermogravimetric Analysis (TGA), etc. Data measured by manufacturers or vendors Material safety data sheets (MSDSs) Technical papers in journals, etc. Vendor datasheets (including data that may not be applicable for spaceflight use) Of 17 polymeric materials listed in Reference (3), for example, the online database has glass transition temperature (Tg) and coefficient of thermal expansion (CTE) data on 8 of these measured by JPL using DSC and TMA, and JPL plans to characterize the remainder. Users are invited to archive their materials property data so it can be shared across the institution. Along with new data that is automatically forwarded by the JPL analytic chemistry laboratory, this uploaded data is then organized by a materials database librarian. A governing board is being formed to establish official JPL materials property parameter values. A planned upgrade to the system will permit engineers to automatically generate Materials Identification and Usage Lists (MIULs) from the materials database. References: (1) Thermal Vacuum Run #, HPA 102-Diode Thermal Runaway,a\u0302\u00bf\u00bf Problem\/Failure Report No. Z82336, Jet Propulsion Laboratory, November 3, 2003. (2) JPL Spacecraft Materials Database, http:\/\/matdb.jpl.nasa.gov. (3) JPL Standard for Spacecraft Electronic Packaging\/Cabling Design and Fabrication, Rev. Ka\u0302\u00bf\u00bf JPL Document No. DocID 35120, December 27, 2007.","Lesson ID":1858}
{"Driving Event":"Following the recommendations from the X43A Flight 1 MIB, the Pegasus actuator system was redesigned to accommodate the need for greater hinge torque. The analog-based legacy actuator system was redesigned for digital drive of the power output stage to the actuators, an additional actuator was incorporated to provide the necessary torque including margins, and the power supply was increased to provide the required 80+ amps, instead of the previous 40 amp capability. The decision to re-utilize, as much as possible, of the existing legacy actuator drive system is not necessarily a poor choice. However, one must understand that significantly increasing the performance requirements will stress all components in the (sub)system. The effects of the \u201cpassive\u201d components of the (sub)system - motherboards, printed circuit boards, cabling - are often under appreciated. Instantaneous demands of digital circuits can be many times their steady-state values, and this misunderstanding can lead to design decisions that can have significant impact upon project schedule\/mission success later in the project.","Lesson ID":1617}
{"Driving Event":"International partnership and cooperation is essential to NASA's mission. For example, more than 5,000 people from 17 countries have participated in the JPL-led Cassini\/Huygens mission, which arrived at Saturn in 2004. NASA anticipates depending on Russia to ferry all astronauts and materials to the International Space Station for a 5-year period following the retirement of the Space Shuttle, unless commercial launch\/orbital services companies can handle a portion. Ambitious plans for space utilization and exploration suggest that multinational partnerships will continue to offer advantages to the partners. However, the challenges of coordinating highly technical work within teams and between teams are often magnified by cultural and language differences. In the case of the Huygens probe, for example, the European Space Agency (ESA) misinterpreted an ambiguously phrased requirement specifying the memory location of probe science data (Reference (1)).Dr. Toshifumi Mukai, the Senior Chief Engineer of the Japan Aerospace Exploration Agency (JAXA) recently discussed lessons learned from U.S.-Japan space science collaboration (Reference (2)). Almost all JAXA science spaceflight missions are U.S. or European partnerships that take advantage of complementary resources (e.g. workforce, infrastructure) and technologies. GEOTAIL, a satellite launched in 1992 to study the Earth's magnetosphere, is a typical joint mission: JAXA provided the spacecraft and about two-thirds of the scientific instruments, and NASA provided the rest of the instruments, a launch vehicle, and tracking support. For this and other missions, however, cultural differences were a major hurdle for the participants: Language (probably the most significant difference) Decision making styles and procedures Formality of Japanese documentation Formality of Japanese meetings Transoceanic communications The respective funding systems Legal issues (cross-waiver of liability, export control, etc.) For example, English was the language standard on GEOTAIL, but few Japanese participants spoke English fluently, and even fewer Americans were conversant in Japanese. Even knowing some shared terminology, differing idioms and sentence structure could at times make accurate communication difficult. To illustrate, word order in English is Subject-Verb-Object, with the subject generally required, but with word order in longer sentences being relatively flexible. The basic Japanese sentence, in contrast, is strictly [Topic\/Subject]-Object-Verb, with the implicit topic and\/or subject frequently omitted. Along with other differences, such as the honorifics and extensive grammatical system used to express politeness and formality, this can contribute to misunderstandings.Despite these obstacles, NASA\/JAXA collaborations over the past two decades have been very successful, and Dr. Mukai attributes it primarily to mutual esteem for each other's culture. Overcoming these difficulties require first that both parties clearly recognize the differences between the two cultures and traditions and how they affect teamwork. This recognition is a prerequisite to the mutual esteem and resultant trust that proved to be the critical project success factor. Despite the project's standardization on the English language, both parties always recognized the high probability of misunderstanding at any given time. Repetition, paraphrasing, speed reduction, and frequent confirmation were practiced during communications. To gain an understanding of international engineering practices, more than 200 JAXA engineers attended lectures given by Americans and Europeans at JAXA in 2007 on systems engineering and project management, and JAXA engineers have attended NASA courses. References: \"Consider Language Differences When Conveying Requirements to Foreign Partners,\" NASA Lesson Learned No. 0608, NASA Engineering Network, January 21, 1999.Dr. Toshifumi Mukai, \"Challenges to Successful International Projects,\" presentation at the NASA Project Management Challenge 2008, Daytona Beach, FL, February 26-27, 2008.","Lesson ID":1856}
{"Driving Event":"The APD detector assembly failed during the Satellite Thermal\/Vac test. A tantalum polarized capacitor was installed, improperly, such that it was reverse biased. Cost\/schedule impact of more than four months, and increased risk due to the required extensive disassembly and rework: (1) Recovery involved: de-integration of the Payload and Platform for removal of the detector assembly, extensive repair rework (the detector assembly was encapsulated in potting compound), full qualification testing of the repaired assembly, reinstallation and optical alignment of the detector, and re-integration of the Payload and Platform. (2) To minimize the cost and schedule impact of the recovery, the risk was accepted of reintegrating the Payload and Platform without repeating all qualification testing (the re-integration was verified through inspection, acoustic test, and functional test). This risk acceptance paid off.","Lesson ID":1840}
{"Driving Event":"The plethora of NASA missions transmitting science data to Earth via the NASA Deep Space Network (DSN) is challenging the capability of the aging DSN facilities to help fulfill mission requirements. The DSN is a network of very large antennas placed 120 degrees apart around the globe to provide telecommunications linkage with deep-space (and some Earth-orbiting) spacecraft and observatories. One such DSN customer that has addressed this issue is the Spitzer Space Telescope project, an infrared telescope that orbits the Sun to return science data on stars, galaxies, and planetary discs. The Spitzer mission has a typical Level 1 requirement for downlink telemetry of 98 percent of observations (i.e., percentage of planned downlinks) and 99 percent of science data (i.e., percentage of data generated onboard the spacecraft). However, the globe-spanning DSN facilities are very complex; DSN anomalies and planned downtime that interrupt communications are not infrequent (Reference (1)). Furthermore, Spitzer cannot always utilize the available DSN uptime because: Some data is lost by the spacecraft Command and Data Handling (C&DH) subsystem due to software faults, commanding errors, and procedural anomalies. DSN linkage is also used to uplink commands to the spacecraft, and a missed telemetry pass could place Spitzer in safe mode and interrupt downlink. Reference (2) characterizes 330 DSN anomalies during normal operations affecting Spitzer downlink over 3 years of Spitzer mission operations. Most of the outage times ranged from 1 to 1-1\/4 hours. The faults are varied: the most common are attributed to Transmitter or Downlink Channel Control Processor failures (each accounting for 15 percent of the anomalies), but DSN operators are not always able to determine the root cause. DSN services are likely to remain fully subscribed for the foreseeable future because: DSN resources are strained by the large number of missions competing for fixed DSN assets. Figure 1 depicts the 26 missions utilizing DSN downlink on the day this lesson learned was approved. Demand for DSN services is subject to significant peaks. For example, Spitzer has increased its daily DSN usage as the spacecraft has moved farther away from Earth, requiring either larger antennas or more antennas. The number of Mars missions has increased, and they consume more DSN resources than Spitzer because of the very low data rates from Mars. Other spacecraft will sometimes receive priority over Spitzer for DSN services, e.g., spacecraft in safe mode requiring Spitzer to give up a downlink pass or a portion of a pass. Demand peaks may also occur when spacecraft conduct Entry, Descent, and Landing (EDL), or when spacecraft perform intensive operations such as Phoenix's 3.5 months of Mars surface operations. In addition, all operating Mars missions are simultaneously in view of the same complex and may share a single antenna for downlinks, preventing use by other missions. NASA faces a major challenge in maintaining and upgrading the 45-year old DSN facilities. It is difficult to obtain replacements for DSN components such as the special high capacity transformers and circuit breakers. Figure 1. DSN\/NAV Real Time Tracking Data Monitor (http:\/\/rmdc.jpl.nasa.gov\/trkmon.html) Lacking significant leverage to solve such endemic DSN resource constraints, the Spitzer project sought post-launch to optimize the Spitzer mission design by: Many of these measures were accomplished post-launch via on onboard patch of a global variable, or by blind uplink commanding (i.e., when no downlink can be detected). Flight projects can also mitigate DSN availability and throughput limitations through spacecraft design measures, such as adding onboard data storage to accommodate periods when downlink is not available. References: Downlink-by-downlink tracking of predicted data volumes versus actual data volumes and downlink performance. Data volume predictions are used to extrapolate from the most recent report of Spitzer onboard data storage and to determine (1) if the Mass Memory Card will be completely filled and (2) how long it will take to clear the onboard data backlog. Early analysis of data volumes. This allows Spitzer to determine when large predicted volumes might compromise single-fault tolerance and how many passes it would take to clear the resulting backlog. Spitzer also adjusts the predicted data volumes to more closely match the observed data volumes, an issue discussed in detail in Reference (3). Early deletion of data. Ground controllers typically command the deletion of science data from on-board storage on the pass following the downlink. The Spitzer project has the ground capability to command deletion of at least a portion of the data one pass earlier than normal-- during the same pass that the data were downlinked. Spitzer uses this capability to mitigate the effects of large predicted data volumes, and during recovery from downlink anomalies. It frees space early, helps to recover to a single-fault tolerant state sooner, and reduces the impact should a second fault occur. On-board free-space checking. Before each science observation is run, the Spitzer spacecraft checks that there is enough free memory space to hold the predicted data volume. This reduces the risk of a skipped science observation due to insufficient memory space resulting from entry into standby mode. Spitzer practice is to reserve two days memory consumption to provide a margin so that engineering data will not overfill on-board storage. Using a second ground antenna for backup downlink. If Spitzer misses a significant portion of a downlink pass, a second ground antenna provides redundant downlink capability and mitigates the risk of filling on-board memory storage. However, opportunities for this mitigation are now limited because the Spitzer downlink margins require use of a 70-meter antenna. Using a second ground antenna for backup uplink. If Spitzer misses a significant portion of an uplink, a second ground antenna can also provide redundant uplink capability and mitigate the risk of filling on-board memory storage. Unlike the downlink example above, this mitigation is usually feasible since Spitzer operations can uplink with a 34-meter antenna. During each pass, Spitzer uplinks commands to delete data from on-board memory that were received during the previous pass. Reduction of the downlink bit rate by real-time commanding. To mitigate the risk of failure of Spitzer's assigned antenna, DSN is sometimes able to provide a smaller antenna as backup. Should the primary antenna fail, then Spitzer can reduce the downlink data rate to receive a portion of the planned downlink rather than miss the entire pass. Scheduling antenna arrays. When Spitzer can gain access to arrays of smaller antennas, the project achieves uplink redundancy and a more graceful degradation of downlink resources. Making numerous improvements to the Mission Control and Analysis tool used to build sequences to delete on-board data. Fixing bugs and adding functionality to the ground-based tool have made it easier to operate and more robust. quotNASA's Deep Space Network: Current Management Structure is Not Conducive to Effectively Matching Resources with Future Requirements,quot Report No. GAO-06-445, U.S. General Accounting Office, May 22, 2006, http:\/\/www.gao.gov\/htext\/d06445.html. quotCharacterization of Spitzer DSN-related Discrepancy Reports (DRs) and Interrupt\/Surprise Anomalies (ISAs),quot Spitzer Project, NASA\/Caltech Jet Propulsion Laboratory, November 29, 2007. quotManaging Rover-Orbiter Relay Link Prediction Variability,quot NASA Lesson Learned No. 1765, NASA Engineering Network, October 6, 2006. quotGalileo Scan Platform Anomaly at Ida Encounter,quot NASA Lesson Learned No. 0560, NASA Engineering Network, May 6, 1997.","Lesson ID":1843}
{"Driving Event":"Following EMC testing at the NASA\/Caltech Jet Propulsion Laboratory (JPL), spaceflight hardware was transported from JPL in Pasadena, California, to the Canadian Space Agency in Toronto, Canada, using a JPL-designated, third-party (independent) courier service. The hardware was an engineering qualification model (flight spare) of the Mast for the Meteorological Experiment (MET), an instrument aboard the Mars Phoenix spacecraft launched in August 2007. The MET Mast is a tubular structure mounting science instruments\/sensors that positions them above the Phoenix spacecraft after landing on Mars. Upon arrival of the package at its destination, the recipient discovered that all shock sensor pairs (20G, 30G, and 50G) mounted to the hardware were tripped, indicating that the hardware was subjected during shipment to shock loadings equivalent to at least 50G. In addition, at least one shock sensor cap was displaced and the shock sensor broken loose from its mounting (Figure 1), allowing the steel balls and springs to roll around inside the carrying case. Figure 1. MET Mast photographed in the shipping container following delivery. The shipped item was a bare mast without mounted science sensors. Reference (1) concluded that the shipping company did not handle the package to prevent excessive shock. The item was mounted to a rigid handling fixture (to which the shock sensors were mounted), which was enclosed in foam within an aluminum shipping container (similar to a golf club hard case), packed within a cardboard box that was badly damaged in transit. It was not skid-mounted for protection during transport and handling, and the tripping and detachment of the shock sensors strongly suggests that the package was not fastened in place during transport. Other JPL projects have experienced problems with unescorted transportation of flight hardware. Following this Phoenix incident, JPL flight projects instituted a practice of preparing a Critical Hardware Handling Plan (CHHP). This planning was initiated on the Phoenix project but was first formalized on the Mars Science Laboratory (MSL) project (Reference (2)). Reference (2) is applicable to the movement and storage of MSL Critical Items (MSLCI) at JPL, and to or from JPL and its suppliers during all phases of development, including pre-launch activities at Kennedy Space Center. The document provides very specific guidelines that apply when MSLCI is to be shipped by independent carrier services instead of being hand-carried to the destination. Reference (2) calls out the requirements of relevant JPL standards, specifications, and procedures governing critical item shipping, including References (3), (4), and (5). Also, the JPL Transportation Survey Form (Reference (2), Appendix A) was updated following this incident: it must be completed to assure that items of concern are addressed before MSLCI is shipped. References: quotShock Sensors Tripped During Transportation (50g),quot Problem\/Failure Report No. 3584, NASA\/Caltech Jet Propulsion Laboratory, January 10, 2006. quotMars Science Laboratory Critical Hardware Handling Plan,quot JPL Document No. D-34659, August 10, 2006. JPL Standard for Systems Safety (D-560), Rev D, JPL Document No. DocID 34880, Paragraph 4.2 quotTransportation and Handlingquot, September 17, 2007. JPL Engineering Specification 501492, quotSafety Requirements for Mechanical Support Equipment for JPL Critical Items Equipment, Rev G,quot JPL Document No. DocID 35412, Section 12.0: Shipping Containers, July 27, 2000. JPL Quality Assurance Procedure QAP 61.10, quotHandling, Movement, Storage, and Shipment of JPL Critical Hardware,quot JPL Document No. DocID 38112, October 4, 2007.","Lesson ID":1849}
{"Driving Event":"During the unit level vibration testing of the BEO of the LIDAR instrument of CALIPSO Satellite, the composite structure spider legs supporting the BEO secondary mirrors failed catastrophically. After the initial analysis of the BEO, several small design changes to the structure were made, each of which was so minor, with so little impact on the overall design margin, that the structural analysis was not updated. However, the combined effects of these modifications consumed all design margins, leading to failure during qualification testing. Loss of all flight hardware, plus increased cost, schedule and risk: (1) To save cost and schedule, the original two flight BEOs were vibrated together (mounted on the same shaker plate) . Both units failed in the same manner, so the failure destroyed both flight BEOs. There were no flight spares of the structure. (2) To save cost and schedule, the flight opticsa\u0302\u00bf\u00bfthe most expensive and longest lead-time components of the assembliesa\u0302\u00bf\u00bfwere vibrated as an integral part of the structures1; when the structures failed, both sets of flight optics were also destroyed. There was only one set of spare optics. (3) To minimize the cost and schedule impact of the recovery, the risk was accepted of redesigning and rebuilding the BEOs in parallel with the Payload-level qualification testing, such that the BEOs were not tested as an integral part of the Payload until Satellite-level testing; this risk acceptance paid off and very little schedule was lost.","Lesson ID":1839}
{"Driving Event":"At the Orbiter Space Plane (OSP) System Design Review there was a lack of evidence that Human Factors contributions were being made to all applicable areas within the System, in particular, ground operations. Contractor products did not adequately consider Human Engineering functions. Even though the development was in the early stages, proposed tools and methods used for developing tasks analysis and usability testing between operators and hardware should have been presented. For example, Human Engineering methods to evaluate access to the spacecraft were not shown, both in the way of platforms for hard to reach areas of the spacecraft and access to the spacecrafts individual subsystems for repairs and testing. Addressing these simple Human Engineering aspects of spacecraft processing would have given some indication that they were planning on integrating Human Engineering into a systems approach. Integrating Human Engineering methods into a systems approach at the beginning of the design development is vital to making the operations safer and easier for the maintainer and operator, as well as improving turnaround time and processing.","Lesson ID":1831}
{"Driving Event":"Reuse of NASA hardware, software, or designs that have been inherited from previous projects and proven in testing or spaceflight may help NASA to control programmatic and technical risk. However, a formal Inheritance Review (Reference (1)) is necessary to verify that the inherited product is acceptable, reliable, and compatible with current spacecraft requirements. Best scheduled at the earliest feasible time prior to the equivalent level Preliminary Design Review (PDR), the Inheritance Review (IR) assesses the potential risk associated with product use and the need for modification or additional testing. JPL hopes that Mars Phoenix, the first in NASA's Scout series of highly innovative and relatively low-cost missions, will be the first lander to physically examine water on Mars. Launched in August 2007, the spacecraft features extensive inheritance (blue-shaded components in Figure 1) from the JPL Mars Surveyor 2001 Lander (MSP01) project that was cancelled in May 2000, which itself was based upon the Mars 98 Polar Lander (MPL). As 70% of the MSP01 lander hardware had already been built, the hardware was moved by the system contractor to cleanroom storage. Available documentation was also stored, although the MSP01 design was largely drawn from the faster-better-cheaper era that limited the extent of engineering documentation. Figure 1. Phoenix Flight System\/Payload Heritage Because Phoenix was subject to different and additional requirements beyond those of MSP01, an ambitious IR program was conducted from October 4, 2004 to January 21, 2005 (Reference (2)). Phoenix IR was facilitated by the fact that the Phoenix spacecraft system contractor had also served in the same role for the ill fated Mars 98 Polar lander project and for the follow-on MSP01 lander project. The IR program focused on the complete range of Phoenix spacecraft subsystems-- Power; Telecomm; Propulsion; Structures; Mechanisms; Guidance, Navigation, and Control; Flight Software; Simulation Software; Command and Data Handling; Harness; Thermal; ATLO (Integration & Test); Support Equipment; and Mission Operations. In planning the subsystem IRs, JPL sought to exceed the minimum level of design penetration needed to prepare for the March 2005 PDR by: Soliciting the participation of the spacecraft system contractor in evaluating the system compatibility of the inherited or commercial off-the-shelf (COTS) product functionality with project Level 1 and Level 2 requirements. Conducting a mission assurance review and system engineering review in concert with the subsystem IRs. Utilizing a mission assurance checklist that provided acceptance criteria to validate the flight worthiness of each subsystem. The checklist was derived from the form (Hardware Review & Certification Record) that JPL uses to assess the risk to flight hardware posed by mechanical or electrical integration with the system (Reference (3)). Providing the project with a recommended course of action (e.g., modification or additional testing) in cases where a subsystem did not meet the checklist's acceptance criteria. The Phoenix project found the IR format to be very useful in addressing mission assurance and system engineering needs. For example: Cognizant engineers were very forthright and candid about their hardware's pedigree, and the detailed checklist forced them to actively seek out and review MSP01 and MPL documentation. Break-away splinter sessions at the spacecraft system contractor facilities to review archived MSP01 documents such as drawings, build records, test data and material reviews (MRBs) were very useful in assessing the pedigree of the Phoenix hardware. Although the Phoenix IR plan was well conceived, preparation for the reviews presented difficulties. Collecting all of the MSP01 and Mars 98 documentation (i.e., parts lists, waivers, anomaly reports, MRBs, GIDEP, reliability analyses) and analyzing material storage life proved time-consuming. Planning for the IR schedule was inconsistent with the system contractors Phase B workforce ramp-up, and the contractor had to prepare for the reviews at a time when they were focused on expediting long lead-time procurements. Closing action items (e.g., assessment of waivers, anomaly reports, environmental qualification, etc.) in time for subsystem Critical Design Review imposed a substantial workload on the Phoenix system contractor cognizant engineers. Certain action items identified by IR, like design changes or additional testing, may necessitate expensive late modifications to the system contract. References: (1) quotSubsystem Inheritance Review,quot NASA Preferred Practice for Design & Test No. PD-ED-1262, NEN # 0789, http:\/\/www.nasa.gov\/offices\/oce\/llis\/0789.html. (2) quotPhoenix Flight System Inheritance Review Lessons Learned,quot Glenn Tsuyuki, March 4, 2005. (3) quotDelivery Review-- Hardware Review Certification Record,quot Jet Propulsion Laboratory procedure, JPL Document DocID 67515, December 15, 2005.","Lesson ID":1807}
{"Driving Event":"Reference (1) describes the pervasive and increasing problem of counterfeit electronic components and the countermeasures being employed by the Jet Propulsion Laboratory (JPL) and the aerospace industry. According to the JPL article, counterfeit parts include: Components with original component manufacturer (OCM) markings that were stolen and are being sold without testing. Dummy components with no die or wires inside, but marked as authentic. (Figure 1). Scrap stolen from the manufacturer, but marked as good product and sold at the normal price. Re-branded parts from a low-quality manufacturer, marked with the logo of a high-quality manufacturer and sold at a premium price. Recycled component sold as new. Blacktopped and re-marked integrated circuit (IC) (Figure 2), with a: Newer date code, Bogus part number, Commercial part re-marked as up-rated or up-screened without any assessment or testing, or Recycled, reclaimed, pulled, or salvaged piece part marked as new. Obsolete product pulled from stock of old boards and sold as new. Figure 1. X-ray image of dummy component with no die inside and no wires, although outside markings appear authentic. Figure 2. Device made by one manufacturer was blacktopped and overprinted with the markings of another manufacturer. Counterfeit goods represent approximately 5 to 7 percent of world trade; since 1982, the value of bogus goods traded globally has increased from $5.5 billion to approximately $600 billion annually (Reference (2)). Several factors contribute to the targeting of the electronic component market by counterfeiters: Device obsolescence has caused an increase in the scarcity and price of critical components used in military and civil aerospace systems. The flow of information through internet product search engines (IPSEs) facilitates finding obsolete or hard-to-find devices, and obtaining delivery overnight or within a few days. But internet purchases may provide no traceability or complex part sourcing history, minimal warranties, and no certainty of replacements or refunds. With the increasing sophistication and complexity of component technology, it may be more difficult to detect fakes. Testing of incoming items has decreased over the years, resulting in a reliance on the suppliers' Certificate of Compliance as proof of authenticity and compliance. Unauthorized gray market channels for legitimate products can facilitate distribution by counterfeiters. Gray market distributors cannot determine whether a high volume influx of a product is a counterfeit or a legitimate OCM product that has been redirected from the source. Subcontract assemblers and manufacturers may not report suspect devices in order to protect their reputation for quality. The best practice for obtaining legitimate electronic components designated for flight hardware is to buy them directly from OCMs (first-tier suppliers) or their authorized distributors (second-tier suppliers). Because this option may require the purchase of large quantities (minimum buys) or long lead times, projects may resort to independent distributors (i.e., gray market third-tier suppliers) for non-flight hardware-- breadboards, prototypes and engineering models. For schedule or cost-constrained projects, the rapid delivery of smaller quantities may offset the risk from limited or missing component traceability data. However, purchase from a third-tier supplier will increase the risk of receiving counterfeits, and it may not be feasible to mitigate this risk if the engineering model is later upgraded to a flight unit. JPL has formed a working group, with representation from the procurement, quality assurance, parts engineering, and technical infrastructure organizations, to address and mitigate the threat of counterfeit electronic components populating hardware assemblies. An action plan based on current industry best practices includes the JPL-wide measures for counterfeit awareness, prevention, detection, and response listed in the Recommendations section below. References: Philip Zulueta, quotCounteracting the Threat of Counterfeit Components,quot Assurance Technology Program Office (ATPO) Newsletter, NASA\/Caltech Jet Propulsion Laboratory (JPL), Issue 4, October 2007. quotGet Real- The Truth About Counterfeiting,quot International Anti-Counterfeiting Coalition (IACC), http:\/\/www.iacc.org\/. quotThe NASA ASIC Guide: Assuring ASICs for Space,quot Section Two, Vendor Evaluation and Section 4, Part Acceptance, http:\/\/parts.jpl.nasa.gov\/asic\/title.page.html#A0.","Lesson ID":1832}
{"Driving Event":"As part of the Constellation Program's review of human spaceflight lessons learned, NASA hosted a July 20, 2007 panel discussion with a group of engineers who were members of the Apollo Lunar Module Reliability and Maintainability (R&M) Team. The team members are retired employees of Grumman Corporation, the prime contractor for the Lunar Module (LM). One set of lessons learned that was discussed focused on the Apollo approach to reliability engineering (Reference (1)): The Apollo approach of shared NASA\/contractor responsibility for achieving LM reliability (Reference (2)) strengthened efforts to incorporate reliability features into the design. As indicated by Figure 1, reliability was infused into the design relatively early in the project life cycle, with part of the achieved reliability captured by design requirements by the release date of the NASA Request for Proposal (RFP). Because NASA issued a brief RFP that stated only functional requirements, and the Grumman program plan (Reference (3)) accepted by NASA committed only to these high-level requirements, Grumman retained substantial freedom to make LM design tradeoffs. Had NASA allowed discipline experts to impose detailed design requirements in the RFP without a full understanding of system-level impacts, some requirements might have detracted from mission success and crew safety. Figure 1. Apollo LM reliability growth (approximation performed in 2007 for use in Reference (1)) The Systems Reliability Group at Grumman placed heavy emphasis on assuring their early involvement in evaluating design alternatives, such as allocating mass to fuel vs. to payload and allocating functions to hardware vs. software. The LM system had only 10,000 lines of code, and the panel discussion suggested that functional requirements implemented in software instead of hardware might decrease weight at the cost of reliability. Decisions on the system configuration were heavily influenced by early weight vs. reliability trade studies that made effective use of flight simulation, and used math models to compare configurations. In retrospect, if NASA and their contractors had made these trades at the integrated system level (Reference (4)), they could have obtained the best reliability increase per pound added to the Apollo booster\/Command Module\/LM system. For example, if a few extra pounds for an additional battery had been added to the Apollo LM, it might have provided the power needed to make the LM a more comfortable lifeboat during the Apollo 13 return trip. Redundancy was employed extensively in the effort to minimize the number of potential single point failures. Apollo LM designers in cross-functional, reliability-oriented teams sought to provide extensive redundancy by dissimilar means. For example, the secondary abort system employed hardware and software that was different than that used in the primary guidance system. Component redundancy (e.g., use of dual valve regulators) was employed where feasible. Parallel technology development, such as the simultaneous development of both fuel cells and batteries as alternative power sources, was also used to mitigate the system reliability risk. Because the test program design was based on a lunar environment that was unknown and a mission profile that was then uncertain, it evolved over time. Developmental flight hardware was stressed to failure, well beyond the environmental uncertainty factor of 1.5 used to set the qualification test levels. This provided an additional environmental margin that accommodated design changes later in the LM project. In contrast, International Space Station (ISS) developmental hardware was not tested beyond qualification levels, and during ISS operations certain necessary flight orientations exceeded these design limits (Reference (5)). The actual Apollo LM flight hardware was tested to flight environmental levels with continuous operation to screen design and workmanship failures. All failures were subjected to very rigorous root cause analysis, and corrective action plans were approved at the NASA level. Although reliability prediction per MIL-HDBK-217 was then in common use by aerospace engineers, the methodology provided very limited benefits to the LM project. The designers were driven by the need to eliminate single-point failures (SPFs) that could impede mission success or harm the crew. Hence, changes were required for designs that contained SPFs even if a calculation predicted a low probability of failure. Failure Mode and Effects Analysis (FMEA) performed at the system and functional levels was very effective in identifying failure modes (including failures of other contractors' interfacing hardware) and evaluating design modifications. In hindsight, though, performance of FMEAs at an even lower tier (i.e., the subcontractor level) would have revealed problems (like solder balls floating in switches) earlier. But careful analysis would not have sufficed without tenacity by the Grumman Systems Reliability Group in forging the necessary design modifications to ensure mission success and crew safety. The Apollo 13 near-disaster revealed the importance of obtaining operations data in real time to support safety-related decision making. For example, the triggering of a CO2 alarm at the warning system engineer's console in Houston alerted the mission to the need to take extraordinary measures to save the crew. Mission success requires mission operations staff to expect the unexpected. This requires the generous allocation of flight instrumentation and telemetry resources to the system for timely identification of problems during mission operations. In addition, real time simulations conducted on the ground to evaluate proposed corrective actions proved their worth. References: Gerry Sandler (Ret.), Presentation on Apollo\/Lunar Module Reliability, Apollo Lunar Module Reliability and Maintainability Team, Apollo Lunar Lander Team Lessons Learned Workshop, July 20, 2007. quotCapture of Apollo Lunar Module Reliability Lessons Learned: Program\/Engineering Management,quot Lessons Learned No 1806, NASA Engineering Network, September 25, 2007. quotLEM Program Plan,quot Grumman Aircraft Engineering Corporation, Report No. LPL 13-1A, July 1, 1964. David Oberhettinger telephone conversations with Gerry Sandler, Apollo Lunar Module Reliability and Maintainability Team, October 4-5, 2007. Dr. Bette Siegel, quotLessons Learned from the Apollo Lunar Module Reliability Team Meeting,quot NASA Exploration Systems Mission Directorate, July 20, 2007.","Lesson ID":1835}
{"Driving Event":"The primary Geosynchronous Imaging Fourier Transform Spectrometer (GIFTS) sensor is an imaging interferometer with two large area Focal Plane Arrays (FPAs). Each FPA contains over 16,000 pixels. The pixel data - in the form of electrical signals - experiences large amplitude variations as the interferometer approaches the point of ZPD. The data compresses poorly in the ZPD region because of the large dynamic range and the large frame size of the data. Near real-time compression is difficult, since the data backs up (slows down) while waiting to be compressed. Thus, the data compression scheme used for GIFTS had localized issues that were harder to resolve than a simplified approach of just taking a frame of data and compressing it.","Lesson ID":1594}
{"Driving Event":"After 6000 hours of nearly continuous in-flight operation aboard Mars Reconnaissance Orbiter (MRO), the Ka-band circuitry in the primary Small Deep Space Transponder (SDST-1) experienced an abrupt increase in power consumption. It abruptly decreased three hours later, permanently disabling the Ka-band downlink (References (1) and (2)). This was likely due to an internal short circuit within the metal-semiconductor field-effect transistor (MESFET) hybrid amplifier used to derive the Ka-band signal within the SDST, which in turn raised the junction temperature and caused an open circuit in the hybrid. The X-band hybrid amplifier in SDST-1, as well as the X-band hybrid amplifier in the backup SDST-2, may also have been overstressed. A possible cause of the short circuit is a poor or failed eutectic bond between the hybrid device and the copper-molybdenum carrier. The process of mounting a semiconductor die\/chip to a substrate or package is known as die attach. Methods include eutectic bonding (soldering) on ceramic or metal substrates, adhesive bonding, and glass bonding. However, soldering is preferred for high power devices because of its good thermal\/electrical conductivity and ability to accommodate thermal expansion. A eutectic bond is formed by heating two or more materials in a joint such that they diffuse together to form a (eutectic) alloy. Manufacturing technology has not eliminated voids and disbonds in the bonding layers that can increase the likelihood of die cracking, increase the chip operating temperature, and weaken the die bonds. This hybrid device failure mode is a risk for other SDST builds, and some flight hardware for the Kepler and Juno missions may be replaced. The primary method for non-destructive evaluation (NDE) of die attach fabrication is high resolution X-rays. Following the MRO failure, the eutectic (AuSn solder) bond X-rays used to screen the parts were reexamined and revealed no voids between the die and the package (Reference (3)). Subsequently, JPL employed an ultrasound inspection technique known as C-mode Scanning Acoustic Microscopy (CSAM). Unlike X-rays, which depict the integrated density of material between the X-ray source and detector, CSAM technology can examine a specific layer. This distinction is particularly important when looking for disbonding defects such as non-wetting of surfaces or delamination. Figure 1 is an X-ray of a spare MRO hybrid die; it shows 3 void areas on the left side of the chip, as well as an unfilled via, but does not show areas of poor die attach. In the corresponding CSAM image (Figure 2), the 3 large void areas are clearly visible, as well as some smaller ones. The CSAM ultrasound image provides enough detail that, after conversion to a digital image (Figure 3), a more quantitative assessment can be performed that states the total area of disbonds and voids as a percentage of the total die area. Figure 1. Microfocus X-ray of hybrid amplifier die (S\/N D209) with lid Figure 2. CSAM image of hybrid amplifier die (S\/N D209) with lid Figure 3. Binary image converted from a CSAM image of hybrid amplifier die (S\/N D221). The white boxes identify the most critical (i.e., the FET active) regions The MRO failure investigation suggests that to assure adequate NDE of critical flight hardware, die attach X-rays may need to be supplemented with acoustic images. X-ray imagery can determine that the proper amount of AuSn solder is present between the die and the carrier, but it cannot determine whether the solder has actually wetted the surfaces. Where there is a complete lack of solder, (i.e., a void) the two imaging methods should give similar results. References: (1) quotTransponder DC input current and power increased for ~3 hours on DOY 14,quot Jet Propulsion Laboratory Incident Surprise Anomaly No. Z88615, May 31, 2006. (2) quotSDST - 3 Hour Power Surge,quot Jet Propulsion Laboratory Problem\/Failure Report No. Z88763, June 30, 2006. (3) MRO Small Deep Space Transponder Ka-Band Exciter Anomaly Final Report, Jet Propulsion Laboratory Document No. JPL D-31195, March 16, 2007.","Lesson ID":1803}
{"Driving Event":"This lesson learned is based on Reliability Practice number PD-ED-1212, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Benefit: The practice of designing and analyzing electronic circuits for worst case environments and part variations maximizes the probability of mission success by assuring that all assemblies meet their mission electrical performance requirements at all times. Implementation Method: Worst Case Analysis (WCA) evaluates factors that may cause hardware to degrade or perform out-of-specification based upon a variety of input factors. For electronic circuits, the analysis generally includes the effects of temperature, initial tolerances, aging, radiation, and other effects as appropriate. The analyst derives part parameter variations for the environments and life of a specific mission and combines them with the initial tolerances of the parts as procured to produce a worst case part variation database for each mission or project. Applying classical circuit analysis techniques, the analyst can determine if each circuit and each assembly meets its specified performance attributes over the most extreme but realizable combinations of part variation sources. Technical Rationale: Classical reliability practice is generally associated with minimizing catastrophic failures of parts. Of equal importance, however, is assuring that the desired essential mission controls and scientific measurements are made with the intended accuracy, fidelity, and stability. To this end, a uniform, disciplined, systematic approach to performance design verification is essential. Uniformity is achieved by use of a common part variation database by all analysts on a specific project. Discipline is achieved by a common analysis containing qualitative and quantitative circuit performance attributes which are traceable to the assembly, subsystem, and system requirements. Also required is a stated or implied level of statistical confidence which results from the use of either an EVA (Extreme Value Analysis) or an RSS (Root Sum Squared) approach to the circuit performance variation at some statistical level, usually 2\u00bf or 3\u00bf. Another statistical approach is the Monte Carlo (MC) method of repeated trials with randomly selected combinations of part variations. Table 1 compares the relative merits of these three approaches and summarizes the differences in input and output formats and information content. It is generally recommended that the EVA be applied as the required method for non-serviceable hardware because of its extreme conservatism. The RSS and MC methods are considered approximately equal to each other if utilized at the same statistical level. Both methods can be safely employed for serviceable or recalibrateable equipment, but are considered the lowest level of confidence allowable for non serviceable (i.e. satellites, spacecraft, etc.) hardware. Both the RSS and MC methods should be accepted only as a formal waiver to the EVA process. Any circuit which does not meet its attributes at 3\u00bf extremes cannot be considered high reliability in the functional sense. To achieve the project benefits from performing a WCA, the commitment must be mission wide to prevent any quotweak linksquot in the performance chain. For critical circuitry, preliminary analyses may be required to validate a conceptual design approach at Preliminary Design Review (PDR). For maximum benefit, the WCA is typically conducted concurrently with detailed design and completed in advance of, and in support of, the Critical Design Review (CDR). Impact of Nonpractice: Early designs of electronic circuits were either empirical or considered initial part tolerances only. This proved to be inadequate in that equipment often failed to remain within specifications at extreme temperatures or over prolonged life. More disciplined approaches followed, but analysts functioning independently were inconsistent in their part variation assumptions. The number of test and field failures fell, but still remained intolerably high, and large systems suffered from inconsistent risk levels. Since WCA first came into practice around 1965, its systematic use by a competent circuit designer has been found to increase the probability of the output design passing all WCA criteria. The absence of a structured WCA activity jeopardizes the long term integrity of the initial design. The probability of failing a hardware qualification test and subsequently needing design modifications is greatly increased. Using inherited hardware designs in environments which are different from the original adds an additional degree of jeopardy if there is no documented WCA from which to extrapolate. Reference: 1. JPL Publication D 5703, quotReliability Analysis Handbookquot, July 1990.","Lesson ID":1804}
{"Driving Event":"Click Here to download the Windows Media Player version of the video. Click Here to download the Quicktime version of the video. References: (1) quotDesign, Verification\/Validation and Operations Principles for Flight Systems (JPL Design Principles),quot JPL Document D-17868, Rev. 3, December 11, 2006. (2) quotIf You Don't Understand an Environment, Provide `Well-Margined' Capabilities to Encompass the Worst Case,quot NASA Lesson Learned No. 1712, NASA Engineering Network, December 16, 2005.","Lesson ID":1797}
{"Driving Event":"Contact was lost with the Mars Global Surveyor (MGS) spacecraft in November 2006-- ten years into its mission to map the surface of Mars and study the atmosphere and interior of the planet. At the beginning of a prescheduled, routine contact, the spacecraft reported alarms indicating that one solar array drive had temporarily been stuck and that the spacecraft had automatically switched to the redundant drive controller (Reference (1)). At the next scheduled contact 2 hours later, the normal spacecraft signal was not detected by the Deep Space Network (DSN), and all subsequent attempts to command the spacecraft and reestablish communication were unsuccessful. The mission loss was attributed to a High Gain Antenna (HGA) positioning command sent by the spacecraft operations team five months earlier that, in the process of updating several parameters, created a bad memory load (Reference (2)). The command was mistakenly written to the wrong memory address in the spacecraft's onboard computers, corrupting two independent parameters and introducing two separate faults. The first parameter error caused a fault in which one solar array was driven against its hard stop; system fault protection incorrectly interpreted the indication as a stuck solar array gimbal and placed MGS into Contingency Mode. In Contingency Mode, the spacecraft alternates between the Sun-Comm-Power Mode (SCPM) control state (commanding an attitude consistent with thermal control of the spacecraft bus and communications with Earth), and the less conventional Sun-Stuck-Gimbal (SSG) control state (favoring a spacecraft orientation to the sun optimized for battery charging, even at the risk of violating thermal limits). Because the spacecraft attitude directly exposed one of the spacecraft batteries to the sun during each SSG period (Figure 1), the temperature of the exposed battery continued to rise. The onboard power management software interpreted the battery overheating as an overcharge condition and kept reducing the charge rate. Since the remaining battery could not support the full electrical load, and the attitude during each SCPM period eclipsed one solar panel, both batteries became critically depleted. The second parameter error caused a fault that induced the HGA to point away from the Earth, disrupting downlink communications such that ground controllers remained unaware of the need to correct the mission-critical thermal and power situation. After 5 to 6 Mars orbits in Contingency Mode, the spacecraft batteries became completely discharged, disabling attitude control and the spacecraft subsystems. Figure 1. MGS in Sun-Stuck-Gimbal (SSG) control state MGS was an overall mission success, having completed its primary mission in January 2001. MGS had a solid record of accomplishments (e.g., use of aerobraking, global mapping, science results, lander mission support), and operated longer than any other spacecraft sent to Mars. References: (1) quotMGS SAM Gimbal and BUS Swap,quot Incident Surprise Anomaly (ISA) No. Z89435, NASA\/Caltech Jet Propulsion Laboratory, November 7, 2006. (2) quotReport on the Loss of the Mars Global Surveyor,quot Mars Global Surveyor Operations Review Board, NASA Goddard Space Flight Center, July 2, 2007.","Lesson ID":1805}
{"Driving Event":"The Geosynchronous Imaging Fourier Transform Spectrometer (GIFTS) Project was supposed to use on-board processing to autonomously determine where to point the instrument. This capability proved costly and was later de-scoped to one of recovering the pointing knowledge using ground processing. But with the loss of on-board attitude pointing knowledge, GIFTS could not meet the latency requirement for generating the Navy\u00bbs imaging product. Thus, the team went through another round of requirements iteration to resolve issues, inter-agency goals and objectives, and to properly allocate new and\/or modified requirements to the subsystems. The de-scope and the requirements iterations had impacts on the instrument design, often causing the team to change course and throw away work.","Lesson ID":1592}
{"Driving Event":"A scheduled inspection of the Rudder\/Speed Brake actuators on Space Shuttle orbiter OV-103 revealed fretting corrosion, micropitting, wear and discoloration of the lubricant Braycote 601. A decision was made to replace the actuators with the existing spares, a single ship set which had been in controlled storage for the past 17 years. Data did not exist on the lubricity of Braycote 601 grease after extended storage. Testing and analysis were undertaken to investigate two key issues: Issue 1: Oil separation of grease into its component oil and thickener is known to occur in storage. Its effect on lubricity is not known. Issue 1 Results: Lubricity testing was performed on aged grease, and grease that exhibited oil separation obtained from several sources, including grease that had been removed from the OV- 103 actuators. Three test protocols were used: (1) Falex Block on Ring; (2) Spiral Orbit Tribometer (SOT); and (3) Wedeven Associates Machine (WAM) testing. In all cases, no detrimental effect on lubricity was observed due to storage and\/or grease that experienced oil separation. Issue 2: Chemical reactions involving the grease and the gear\/housing material, 9310 steel, could lead to formation of Lewis acids, resulting in corrosion, pitting, and cracking. The degree to which the chemical reactions were occurring in the actuators was unknown. Issue 2 Results: Investigations into potential chemical reactions of the grease with the actuator steel were addressed in three ways: (1) an extensive literature review; (2) WAM testing to duplicate the conditions observed in the used actuators; and (3) Thermodynamic analysis, using Thermal Gravimetric Analysis (TGA), to bound the amount of degradation\/mass loss that might occur during 17 years of controlled storage. The literature review revealed that absent tribological action, i.e., no stress on the lubricant, no significant mass loss should occur below 190C. The WAM testing was successful in duplicating the fretting corrosion and micropitting effects observed on OV-103 by high frequency low amplitude wear testing, thus reinforcing the results reported in the literature for similar material\/lubricant combinations. The TGA testing and thermodynamic analysis predicted no significant corrosive effects from static, controlled storage for 17 years. Based on testing data, there is no significant difference in lubricity due to separated or degraded grease and no evidence that the grease will degrade at steady state in ambient.","Lesson ID":1798}
{"Driving Event":"The NASA Imager for Magnetopause-to-Aurora Global Exploration (IMAGE) spacecraft became non-responsive to ground commands in December 2005, after almost 6 years of successful on-orbit operation. Designed for a two-year mission, IMAGE was the first satellite dedicated to imaging the Earth's magnetosphere. The only likely cause of the IMAGE failure is a Single Event Upset (SEU) induced quotinstant tripquot (i.e., from a short duration, high current transient) of the Solid State Power Controller (SSPC) that supplies power to the single-string Transponder (Reference (1)). Because the SSPC device that powers the satellite Transponder (receiver\/transmitter) also performs a circuit breaker function, the instant trip severed both uplink and downlink communications. An SSPC trip should have been reported in its status telemetry lines that are continuously monitored by onboard Error Detection and Correction (EDAC) logic in the Power Distribution Unit (PDU). This allows the PDU EDAC to command the SSPC to close, reapplying power to the Transponder. However, due to a design oversight in the device, instant trip events are not reported in the status telemetry lines (see Figure 1). This allowed the circuit breaker to be in an open state while still reporting a closed state. The result is that the Transponder remains OFF because the EDAC logic detects the SSPC to still be closed (due to the erroneous status line indication). Figure 1. Simplified schematic of the circuit breaker (SSPC). The circuit breaker protects itself against a current spike (e.g., caused by shorting or an SEU) by means of a trip function that directly turns the MOSFET (1) off. Because the design improperly allows the trip function to sidestep the status line (2), fault detection logic mistook the breaker as ON and would not force a reset. The SSPC hybrid device could be susceptible to radiation-induced upsets, depending on the year of manufacture, and the ones used on this cost-constrained project were not screened. In September 2001 (well after IMAGE was launched) it was learned that the lack of proper status reporting following instant trip events was actually inherent in the part's design, but had not been reflected in any SSPC part documentation provided to SSPC users (Reference (2)). This prevented the PDU EDAC designers from incorporating a logic design that could compensate for this device characteristic. (By design, the PDU software is not patchable in flight.) With the inability of EDAC to detect and reset the tripped breaker, secondary failure recovery measures that would have saved the satellite were not available: The loss of uplink triggered an automatic quotwarm rebootquot of the flight computer, but a warm boot does not reset the breaker. If the designers of the onboard fault recovery logic had wished to provide for a complete reset (quotcold bootquot) of the computer after several unsuccessful restart attempts, the circuit breaker would have been commanded to ON. Manual ground commanding of a reset was not feasible because the satellite's receiver was already disabled, and IMAGE lacked a redundant Transponder. Prior to the IMAGE mishap, three on-orbit SEU-induced instant trips of this SSPC part series from the same manufacturer occurred aboard the Earth Observing 1 (EO-1) and Wilkinson Microwave Anisotropy Probe (WMAP) satellites. Recovery by means of ground-commanded resets was successful because the EO-1 and WMAP configurations did not permit an SEU-disabled breaker to cut power to the command receiver. None of these three anomalies resulted in issuance of a GIDEP report or a NASA Alert. Reference(s): IMAGE Failure Review Board Final Report, Flight Programs & Projects Directorate, Goddard Space Flight Center, September 19, 2006, http:\/\/image.gsfc.nasa.gov\/publication\/document\/IMAGE_FRB_Final_Report.pdf EO-1 Anomaly Resolution Report for the Attitude Control Electronics (ACE) Anomaly of September 14, 2001, http:\/\/eo1.gsfc.nasa.gov\/new\/validationReport\/Technology\/Documents\/Tech.Val.Report\/EO-1%20ACE%20Anomaly%20of%209-14-01%20Resolution%20Summary%20as%20of%2011-18-01.doc","Lesson ID":1799}
{"Driving Event":"This report was written with the objective of researching, reviewing, and consolidating NASA failures that would potentially be of interest to the LRO and LCROSS project teams for consideration. By reviewing previous failures and mishaps the LRO and LCROSS projects may increase their ability to achieve mission success.","Lesson ID":1795}
{"Driving Event":"There was a continual struggle for acceptance of Human Engineering, during the evolution of the SLI and OSP programs. The status, visibility, responsibilities, resources, and authority of Human Engineering vacillated. At the end of the OSP cycle, the Human Systems Office had achieved a seat at the table. This allowed human factors engineers voices to be heard and resulted in human factors engineering being integrated into other systems of the OSP. However, many decisions were being made about OSP that initially ignored the human as the primary reason for the mission, and then tried to retrofit the human into the physical and dynamic parameters that remained in the trade space. Even though the human was emphasized in Level I requirements and in Request for Proposals (RFPs), both NASA and the contractors had to be frequently reminded that the human is an essential driver for requirements and deliverables for human spaceflight. Placing human system requirements last in priority will result in higher costs for training and operational work-arounds in order to accommodate. We know from ISS crew debriefs that there are interface issues that lead to continual workarounds; interfaces are in conflicting designs. If NASA would do a life cycle cost analysis, then the impacts to training and operations costs would become very apparent. The root causes of Human Factors Engineering requirements being deemed of low priority center around three phenomena: (1) hardware and software short-term schedules and cost concerns often lead to decisions to ignore Human Factors Engineering requirements with the rationale that the human is malleable and can adjust to the design, (2) some project managers, decision makers, and designers think that because of their human experiences they are human factors experts, and (3) claims that a human can endure or accomplish almost anything with the proper motivation or rationale.","Lesson ID":1801}
{"Driving Event":"The cause of the power loss was a failure of Florida Power & Light (FPL) 115KV line feeding the Orsino Substation.","Lesson ID":1779}
{"Driving Event":"Jet Propulsion Laboratory (JPL) mission design principles place a high value on maintaining communications with Earth at all times when the spacecraft is not occulted (Reference (1)). The Mars Reconnaissance Orbiter (MRO) flight system achieves this for both the uplink and downlink radio frequency (RF) signals by antenna swaps accomplished by actuation of RF switches. (In contrast, some JPL spacecraft meet this goal using redundant RF amplifiers and transponders.) For the downlink signal, MRO employs a Waveguide Transfer Switch (WTS), an electromechanical device that allows RF energy entering through one port to be routed during spaceflight to one of several output ports (Figure 1). This switching allows a 100 watt microwave downlink signal to be sent from one of the two available amplifiers out to one of two different radiating antennas. Figure 1. Traveling Wave Tube Amplifier (TWTA) Panel Layout Five months after the insertion of MRO into Mars orbit, a WTS failed to actuate. The onboard software maintained the commanded downlink configuration by commanding a switch to the redundant X band amplifier. Telemetry indicates that the switch is stuck between its two nominal positions, causing the switch rotor (visible in the center of Figure 2) to partially block the RF energy passing through the switch. This has resulted in a downlink RF power loss (of about 1 dB), and a temperature increase (of about 15 deg C) caused by absorption and dissipation of the reflected energy (Reference (2)). The most likely root cause of the switch failure has been identified as conductive debris (perhaps from flaked plating) floating in the zero gravity environment. This debris may have eventually come into contact with one of the polyimide tape windows at Port 1 or 2 of the WTS during MRO aerobraking (Reference (3)). These windows are used as a contamination barrier on the WTS RF ports, but they may have contributed to the severity of the anomaly. Vent holes in the windows can admit contamination, adhesive on the inward-facing side of the tape can entrap it long enough to initiate RF breakdown, and the breakdown can cause the polyimide tape itself to pyrolyze (see Figure 3), injecting a large amount of polyimide debris into the switch and causing it to bind. Polyimide films or tapes are widely used in aerospace applications due to their light weight, durability, and performance in extreme temperature environments. The design of polyimide RF contamination barriers varies across JPL projects: they vary in thickness and type (i.e., tape vs. film), and MRO may have been unique in using vent holes. Also, the somewhat unusual MRO operational practices of (1) frequently switching antennas (720 times) to maintain communications during the orbit, and (2) using a switch to change antennas instead of powering alternating amplifiers, may have transformed a minor debris problem into a stuck switch. Figure 2. Post-failure tests showed that materials like polyimide tape or paper (shown here) could block rotation of the switch rotor and jam the switch. Figure 3. Testing showed that, under RF power, foreign object debris (half-inch long aluminum sliver) on or near the polyimide tape window could induce RF breakdown, destroy the window, and produce additional debris. The WTS had been exempted from JPL's policy prohibiting designs with single-point failures because a quotstuck between normal positionsquot switch failure mode was not considered credible. Although the failure has decreased the downlink margin (from an available margin of at least 3 dB), neither the RF power loss nor the temperature increase poses a threat to the mission, and the system is performing as it would had the WTS failed in a nominal position. However, movement of the root cause debris could cause additional RF breakdowns and damage to other components, and movement of the WTS to a fully blocked position could cause loss of mission \u2014 both low likelihood events. References: (1) quotDesign, Verification\/Validation and Operations Principles for Flight Systems (JPL Design Principles Standard)quot, JPL Document No. D-17868, Rev. 3, Paragraph 3.1.2 (quotCommunications During Mission-Critical Eventsquot), December 11, 2006. (2) quotS\/C Swap to TWTA 2,quot Incident\/Surprise Anomaly (ISA) Report No. Z89130, Jet Propulsion Laboratory, August 16, 2006. (3) quotMars Reconnaissance Orbiter Waveguide Transfer Switch Final Report,quot Jet Propulsion Laboratory Document No. JPL D-31194, March 30, 2007. (4) quotFlight Project Practices, Rev. 6,quot JPL Document No. DocID 58032, March 6, 2006.","Lesson ID":1796}
{"Driving Event":"Recent mishaps have brought added focus on the concept of \"grandfathering\" new requirements in evolving codes and standards. One product of this added scrutiny was a briefing put together by JSC Safety's support contractor on this concept as used in the National Fire Codes etc. which constituted an excellent insight into this concept. General lack of knowledge on the subject of NASA and NFPA code retroactivity contributed to confusion as to applicability of code prescriptions in existing NASA facilities.","Lesson ID":1770}
{"Driving Event":"Following the recommendations from the X43A Flight 1 MIB, the Pegasus actuator system was redesigned to accommodate the need for greater hinge torque. The analog-based legacy actuator system was redesigned for digital drive of the power output stage to the actuators, an additional actuator was incorporated to provide the necessary torque including margins, and the power supply was increased to provide the required 80+ amps, instead of the previous 40 amp capability. Multiple failures during qualification testing, and the subsequent technical investigations, proved the lack of understanding between the ideal circuit operation and the impact of system implementation.","Lesson ID":1603}
{"Driving Event":"A deflagration and fire occurred in 2005 at the NASA Glenn Research Center in Building 124. The building contained a series of storage tanks designed to hold combustible turbine oil (Class IIIB). The tanks were wide and flat so that liquid levels did not fluctuate highly when the oil was pumped out and into the turbine system. On one given day the oil level was low and a deflagration occurred in the storage tank room, emanating from the fill port of the tank. Three operator\/mechanics were in the room at the time. The deflagration threw a fireball out of the fill port which collapsed back into the tank once the atomized fuel was spent. The bedplate of the tank was greatly deflected as a result of the pressure during the deflagration and pre-heating. The immersion heater was exposed for a time and superheated the surface oil, essentially cracking the oil into light hydrocarbons. The immersion heaters were not required when the unit was to be installed within a building.","Lesson ID":1766}
{"Driving Event":"The JPL Stardust project proved very successful in accomplishing its objective of returning a sample of cometary material. This was due in part to its innovative use of programmatic resource management techniques, and to its firm commitment to managing the work against cost-to-complete (in contrast to merely managing actual costs against planned). NASA budgetary constraints, and a mandate to accomplish more with fewer resources, led in the mid-1990s to a faster, better, cheaper (FBC) paradigm and competitive mission selections. Where NASA-funded spaceflight projects were previously requirement-driven and open-scope, successive JPL projects became severely cost and\/or schedule-constrained. With NASA demonstrating a resolve to cancel projects that fail to demonstrate budget and schedule discipline, managers of essentially fixed-price flight projects have been pressed to exercise tight budget and schedule control. Although there were some significant successes under this new paradigm, problems with balancing project resources and risk led to a number of mission failures (e.g., Mars Climate Orbiter, Mars Polar Lander, Wide-Field Infrared Explorer, Contour). Achieving this culture change for planetary exploration and space science required processes and procedures for implementing quotdesign-to-costquot and quotmanage-to-budget.quot Lessons from JPL flight projects initiated in the 1990s demonstrate that the flight project manager (PM) must maintain a buffer of reserves that will be sufficient to overcome the problems endemic to the latter stages of complex, high risk, system development. Consistent and rigorous reserve management is a preventative practice that assures that the project remains on track. In contrast, it is likely that a PM who spends too much too soon, or delays until no amount of reserves can salvage the project, will be unable to recover from adverse developments. Stardust may have been unique among these flight projects in completing development (Phase D) with the proposed reserve. Stardust project management practices and results may serve as a model for PMs who wish to understand (1) whether project reserves established by a proposal team competing under very tight cost constraints are sufficient, (2) how to develop a plan and criteria for release of reserve, and (3) how to integrate the releases with an earned value management (EVM) system (Reference (1)). Specifically, the Stardust experience provides guidance on how the PM may: 1. Determine the adequate reserves buffer, 2. Develop a plan for expending the reserve in the context of risk, 3. Integrate the reserve plan with EVM and scope, and 4. Control reserve on quotcost-to-goquot (i.e., cost to complete the baseline plan). The Stardust PM implemented a reserves management plan early in Phase B to (1) derive a set of affordable flight system capabilities that matched the prioritized requirements, (2) produce a risk-adjusted scope of work, and (3) generate a work plan based on earning value (Reference (2)). This established a planned cash flow inside the time boundaries to defeat known threats to mission success. Metrics were identified and criteria were pre-determined that would trigger the timely application of additional reserves to mitigating major risks (Figure 1). Planning the allocation of the reserve pool recognized that the risk scenario was only an estimate: some expected problems did not occur, while some expected and unexpected problems did. Implementing the plan in 10 key steps, Stardust: Figure 1. This Stardust performance assessment metric (PAM) plots the accomplishment of monthly earning events (baseline vs. actual) on the left ordinate as both raw counts and a ratio of actual to baseline. The curves (bottom plot) provide the cumulative picture of baseline (green \/long dashes) and critical path events (red\/alternate dash-dot), with the actual (blue\/solid bottom curve) accomplishment falling between. The middle (black\/dashed) curve projects moving the actual progress off the critical path and recapturing schedule slack. If the actual cannot be returned to the baseline within the target schedule completion, the project will fail the schedule and cost (time=$) success criteria. (That is, the schedule must slip, the baseline job cannot be completed as agreed, and cost will certainly increase, resulting in loss of control over the scope.) To avoid this and achieve the baseline (top curve) job, Stardust planned to have adequate schedule and budget reserve. Figure 2. Stardust used a Budget Change Log to translate the project reserve into hard liens (authorized to debit reserves) and from soft liens (not yet authorized to debit reserves). Legend: R\/R = risk reduction; C\/S = change in scope; O\/R = overrun Documented in an agreement (project plan or Mission Definition and Requirements Agreement) co-signed by the customer a clear and unequivocal definition of mission success. The definition included measurable success criteria so that the PM could later prioritize the commitment of reserves. Stardust established a quotperformance bufferquot by defining a three-level project scope hierarchy\u2014primary, secondary, and tertiary. The primary category represents the minimal success statements that make the project worthwhile. The secondary category houses baseline-scope criteria where the achievement of most of them is acceptable. The tertiary category, also in the baseline, contains those criteria that are important but would be the first to be de-scoped in response to unforeseen events. Reviewed the design capabilities against the requirements to determine whether modifications to the existing design (or design of new elements) may be needed to capture the full baseline, and whether such changes can be made within the targeted cost and schedule. A trade study was performed to assess reserves needed to accommodate the uncertainty and to force any necessary de-scope decisions. This resulted in a Stardust review called a Capability vs. Requirements Review (CRR) that assessed the ability of the project to design-to-cost. The initial Significant Risk List (SRL) was generated from the threats and probabilities identified at the CRR. Populated the Work Breakdown Structure (WBS), assessing and adjusting the constituent, low level task plans for risk and the estimated reserve required for each WBS item. The negotiated margins were weighted to reflect the probabilities identified at the CRR, and then summed to produce a risk-adjusted, justifiable, reserve pool. Loaded the integrated schedule network software to determine the critical path and any slack in the project. Added the schedule reserve at the end, protecting the quotschedulequot success criterion. Fully aligned and checked links, paths to deliverables, key events, etc. Next, Stardust loaded the financial software to apply current manpower cost rates, overheads, etc., to produce the time-phased baseline budget (costing plan) and the baseline Earned Value (EV) structure. They performed a quotGoldilocksquot validation to ensure they had a quotjust-rightquot number and spacing of earning events. (Not so few events that the project wouldn't know when it was in trouble, and not so many as to micromanage the activity.) The EVM system was set up early in the preliminary design phase (Phase B) and used to clarify and capture the baseline work plan and validate its consistency with the constrained cost and schedule. This preparation provided the control infrastructure for success in Phase C\/D. Using the results of Step 3, the SRL was updated to include the latest information on probabilities and mitigation options, and to assess the cost-to-mitigate for major risks. Rough-order-of-magnitude (ROM) estimates were prepared for incorporation as quotsoft liensquot into the Budget Change Log used in Step 7. A Budget Change Log (Figure 2) was implemented as the control discipline for release of reserves, ensuring that task plans, contracts, networks, and the EV system were updated expeditiously and were consistent. For JPL subcontracts, the incentive-fee structure and the events that were to earn fee (e.g., risk reduction, change in scope) were clearly designated. The reserve strategy was implemented, getting timely (days, not a week) information from the EVM system on the effectiveness of reserve expenditures in mitigating threats. Swept the project regularly for threats and opportunities to avoid trouble (i.e., to use reserves effectively on risk reductions, changes in scope, or overruns). Updated the SRL and Budget Change Log accordingly. Managed the unencumbered reserves against the cost-to-go. To maintain project control and assure that an acceptable product is delivered on time and within budget, it is essential to continuously monitor remaining costs to the conclusion of the project (cost-to-go). Stardust released reserves both proactively and reactively using the Percent Reserve on Cost-To-Go metric as a quotgovernor.quot Figure 3 provides an example of this index. Note that a 10 percent floor was set as a minimum reserve level, not to be broken until it became clear (e.g., late in development) that the project could be completed within this reserve for quotunknowns.quot A metric like Percent Reserve on Cost-To-Go provides a current picture of the reserve pool's strength against the cost to complete the baseline plan. Figure 3. An example trend in percent Stardust reserves against cost-to-go. This example depicts an initial growth in the percent reserves on cost-to-go, perhaps resulting from favorable early experience where some anticipated risk mitigations were not required. The February 1997 drop after reaching the 20 percent reserves level indicates the project either (1) decided to preemptively address some threats by releasing reserve to mitigate or retire them, or (2) discovered a set of risks that demanded action, such as realizing that a major task element was underbid in the baseline. This drop may prompt a recovery action, such as a de-scope, to increase the pool. The post-April 1997 growth in the index indicates that the project is not being aggressive enough in releasing reserve to mitigate threats, or that it is saving reserve to address an expected need. Absent this level of programmatic resource management discipline, it is not likely that Stardust could have completed development (Phase D) with the original project reserve. The CRR process demonstrated by the Stardust project has been adopted by the ongoing Juno flight project, and the 1996-1999 Stardust approach to managing the work against cost-to-complete is being incorporated into JPL's emerging strategy for cost effective implementation of cost-capped flight projects performed in-house. References: 1. quotEarned Value Management System Description,quot JPL Document No. DocID 67032, November 3, 2006. 2. Kenneth L. Atkins et al, quotStardust: Implementing a New Manage-to-Budget Paradigm,quot Proceedings of the Fourth IAA Conference on Low Cost Spacecraft, Johns-Hopkins University, May 2-5, 2000, also recorded in Acta Astronautica 52 (2003) pp. 87-97, available on-line at http:\/\/www.sciencedirect.com 3. Kenneth L. Atkins, quotHow to Plan and Manage Reserves Effectively,quot IEEE paper #1292, 2004 IEEE Aerospace Conference, March 8-12, 2004, Big Sky, MT. 4. quotNext Generation Launch Technology (NGLT): Clearly Establish Reserves, Schedule Margin, and Spending Profile Early,quot NASA Lesson Learned No. 1527, NASA Engineering Network, July 1, 2004.","Lesson ID":1780}
{"Driving Event":"In support of the Cassini spacecraft's mission to map the surface of Titan with its RADAR imaging instrument, the RADAR instrument testbed was used in 2005 to test operational sequences. System backups of these simulations on the testbed were performed periodically using magnetic tape. The testbed Instrument Ground System Engineer (IGSE) is responsible for the maintenance and upgrade of the testbed hardware for their instrument. The testbed employs a Remote Terminal Interface Unit (RTIU) to connect the RADAR engineering model (EM) to the ground support equipment (GSE) software, sending commands to the EM and returning telemetry. Following a November 2005 failure of the RADAR RTIU hard drive, the RADAR IGSE attempted to restore Instrument Expanded Block (IEB) files to the RTIU from a backup copy. (IEB update files are uplinked to the Cassini spacecraft to support science sequences.) This file restoration from the backup tape failed, and it was discovered that this backup tape created in 2004 was missing three of the four data partitions (Reference (1)). Examining the script that runs the backups, a coding error was found that had caused the partitions to be overwritten and the backup data lost. Because of this failure, the sequence IEBs were uplinked to Cassini without the benefit of a testbed run. The data backup failure caused only a minor loss of instrument simulation fidelity, but this minor loss might have had a major impact in the event of a Cassini spacecraft or instrument flight anomaly. Failures of other more critical NASA ground system or flight system data backups (using the same or different recording media) may occur, and they may escape detection unless a computer failure prompts a need to retrieve the backups. References: 1.\"Cassini RADAR Testbed Has Dead Disk with No Valid Backup Tape,\" Incident\/Surprise Anomaly (ISA) Report No. Z87842, Jet Propulsion Laboratory, December 1, 2005.","Lesson ID":1781}
{"Driving Event":"The JPL Dawn spacecraft design uses ion propulsion to obtain the velocity to reach two of the solar system's largest asteroids, Ceres and Vesta, during a nine-year voyage. The electric propulsion system ionizes xenon (Xe) gas, which is stored in a pressurized Composite Over-wrapped Pressure Vessel (COPV) tank. The Dawn COPV tank is composed of a titanium liner, made from two welded domes, that is then over-wrapped with a graphite fiber-based composite. Figure 1 shows the flight tank just prior to integration with the spacecraft. Figure 1. Flight Xe tank prior to blanketing and installation Two anomalies occurred during fabrication and testing of the initial, or development tank (S\/N 002). First, tank distortion was caused by each of two unsuccessful annealing cycles, and each time the liner was pressurized to return it to its original shape. Second, the tank failed a leak check following six proof cycles, and the liner had to be coated with polymer sealant to permit development testing to continue. However, the tank design was viewed as successful because (1) liner welding without annealing was believed to be adequate and (2) the eventual burst of the tank at over 3000 psig significantly exceeded the design burst pressure. Note, however, that this development liner had actually been annealed twice, making it non-representative of the flight liners, which were not annealed. The planned progression from fabrication and testing of the development tank, then a qualification tank, and finally two flight tanks (one flight tank and one flight spare) was changed to accommodate the redesign of the tank skirt. The tank skirt was redesigned because after fabrication and testing of the development tank it was discovered that the mounting bosses used to attach the tank to the core spacecraft structure had been located incorrectly by the spacecraft vendor. It was determined that the most appropriate and least expensive way to fix this problem (in terms of acceptable performance, funding, and schedule) was to redesign the xenon tank skirt to accommodate the incorrectly placed core spacecraft bushings. This change caused a five-month delay in the availability of the flight tank, but only if the flight tank would be fabricated ahead of the qualification tank. This decision was viewed as an acceptable risk based on the apparently successful results of the development tank. The flight tank (S\/N 007) was fabricated and passed all acceptance tests. The flight spare (S\/N 009) was subsequently fabricated and failed during its first pressurization to the proof pressure (Reference (1)). The qualification tank (S\/N 008) was then fabricated and subjected to the full qualification test program. This qualification test included four times the maximum number of pressure cycles that the flight tank is expected to see at each pressure level. The qualification tank was subjected to 12 cycles to 2188 psig, 16 cycles to 1750 psig, and 24 cycles to 1250 psig. After the pressure cycling the tank successfully passed a leak test at 1250 psig. The tank passed the qualification quasi-static proof load and vibration tests. The tank assembly was installed in a flight-like mechanical structure for the dynamics testing. The last test necessary to complete the qualification testing was to demonstrate capability in excess of a minimum burst pressure of 2625 psig. The tank did not reach this pressure, but instead burst at 2453 psig, 6.5% below the required minimum burst pressure (Reference (2)). Post failure photographs of S\/N 009 and S\/N 008 are provided as Figures 2 and 3, respectively. Figure 2. Post-failure condition of the S\/N 009 tank. Note: Label reads, quotLocal Over-wrap Damage Due To Internal Leakagequot Figure 3. S\/N 008 tank after burst at 2453 psig. Many low-angle helical fibers failed in the dome region, well away from the weld area. The skirt was broken into five large pieces. The root causes of the Dawn xenon tank failures have been attributed in Reference (3) to: 1. Weld process did not include vacuum annealing. In welding the tanks, the liner manufacturer was unable to control the annealing process, and the tanks would collapse. To avoid the cost and schedule impact of finding another liner manufacturer, the Dawn project decided to omit the annealing step. This decision was supported by the large margins identified by the Finite Element Analysis, and it was verified in the testing of the developmental tank. Not annealing the liner results in higher residual stresses in the weld and in the heat affected zone (HAZ). 2. The ductility of the weld HAZ was lower than expected. The welding caused hourglass distortion of the liner due to radial sinking at the weld (Figure 4). This also resulted in low ductility in the HAZ. Although no heat specifications were furnished to the liner manufacturer, all of the liners used in the Dawn tanks met the hour-glassing specification. However, strain-to-failure measurements made during the failure investigation indicated that the HAZ cannot tolerate nearly as much strain as suggested by the material handbook. Figure 4. Liner hour-glassing 3. There was a never-bonded region between layers of the composite over the weld. The low-angle helical composite wrap was not well bonded to the hoop wrap in the region directly over the weld. This may have been a result of the hoop wraps inadequately filling in the liner hour-glassing. The low-angle helical wraps control the axial strain in the liner. If these wraps are not adequately bonded to the hoop wraps, the axial strain control of the liner in the weld region can be compromised, resulting in larger-than-expected liner strain in this region. The larger-than-expected axial liner strain, combined with the less-than-expected liner strain capability, resulted in the failure of the S\/N 009 tank shell and the failure of the S\/N 008 qualification test. The flight tank (S\/N 007) will be used as is with a reduced propellant load and reduced temperature limits (Reference (4)), having been assessed as low risk for the duration of launch plus 250 days (and very low risk after that). Neither the qualification xenon tank (S\/N 008) nor the flight spare (S\/N 009) will be used in flight. References: (1) Dawn S\/N009 Acceptance Proof Test Failure, Problem\/Failure Report No. Z85933, Jet Propulsion Laboratory, March 10, 2005. (2) Dawn Qual Tank Burst Test Failure, Problem\/Failure Report No. Z86896, Jet Propulsion Laboratory, June 21, 2005. (3) Dawn Project Xenon Tank COPV Flight Tank SN007 Disposition Independent Review Team Final Report, March 17, 2006. (4) Xenon Tank Derating, Engineering Change Request No. 104740, Jet Propulsion Laboratory, May 31, 2006.","Lesson ID":1777}
{"Driving Event":"The Jet Propulsion Laboratory (JPL) employs several different design approaches for assuring that spacecraft computational assets are fault tolerant. The Mars Exploration Rover and Mars Pathfinder flight system designs feature a single flight computer capable of rebooting in tens of seconds. Because Mars Science Laboratory is especially sensitive to loss of control during landing, it (like the Cassini and Galileo spacecraft) employs two active processors, with a capability for the primary computer to relinquish control (i.e., hot swap) to the secondary in less than 2 seconds. Mars Reconnaissance Orbiter (MRO), along with Phoenix, Stardust, Genesis, and Mars Odyssey, has dual processors that share updated state and sensor data \u2014 one processor active, and a second cold backup that can boot in tens of seconds. Despite the functional redundancy provided by this third design arrangement, following launch the MRO project detected a potential common C&DH failure mode. The MRO Command and Data Handling (C&DH) subsystem maintains a File System (FS), a 2 Mbit image of the flight software, for use in the reboot sequence should the spacecraft go into safing mode and autonomously determine that a computer reboot is required. Active redundancy is used to protect the critical flight data in the FS needed for a reboot, as shown in Figure 1. That is, there is one C&DH Module Interface Card (CMIC) in each of the two redundant C&DH strings, each CMIC has one static random access memory (SRAM) multi-chip module (MCM), and each MCM has two FS images stored on different SRAM dies, for a total of four redundant FS images. Cross-strapping (via a high speed link, a synchronous serial interface (SSI) cable) and cyclic redundancy checks (CRCs) ensures that both flight computers maintain identical and error-free FSs recording their operational state. If any radiation-induced single event upsets (SEUs) are detected before the FS is used in a reboot sequence, the MCM's second FS image is checked; if that image is also found to be corrupted, the spacecraft switches to the redundant string CMIC in search of a pristine FS image. Figure 1. Each MRO C&DH string has a single CMIC, which in turn has a single 2 MB SRAM piece part that is logically partitioned into 8 segments. The redundant File Systems are stored in SRAM Segments 2 and 4 on each CMIC. Realtime checkpoint and fault protection data are stored in Segments 3 and 6. The RAD750 flight computer accesses its CMIC via a cPCI bus and accesses the other computer's CMIC via a synchronous serial interface (SSI) cable. After MRO launch, spacecraft telemetry revealed some correctable CMIC memory errors (Reference (1)) that prompted analysis of MRO radiation exposure. This post-launch analysis identified a significant risk that solar energetic particle (SEP) events associated with a solar flare later in the mission could corrupt all four FS images (Reference (2)). That is, given the high likelihood under nominal conditions of particle strikes causing SEUs in a certain block of memory, there is a high likelihood during large solar flares of many more strikes damaging multiple blocks of memory. Since the radiation flux would also increase the likelihood of a computer reboot, FS corruption during the Mars aerobraking maneuver could have posed an unacceptable risk to the mission. Radiation analysis (Reference (3)) also revealed a 7 percent probability that a large flare will occur and that the resulting SEUs will impact all four FS data images during the 2-year MRO primary mission. In addition, the analysis showed a 14 percent probability of data corruption (due to entry into a period of increased solar activity) during an extended mission. This analysis showed that for large solar flares, the probability of SEUs is so high that even an increase in redundancy to 16 FSs would not bring a significant risk reduction during the primary mission. This is because the probability of all images being corrupted is driven mainly by the probability of encountering a large flare. Shielding is somewhat effective against solar protons, and the proton flux decreases with distance from the sun, but shielding does little to block high energy particles, and they pose an SEU risk throughout a planetary mission. The MRO mission risk has been mitigated by uplinked changes to flight software, and by ground procedures such as daily monitoring of solar activity forecasts. Also, the mission risk was limited by the minimal number of solar sunspots (solar min) that occurred during MRO aerobraking maneuvers. Reference(s): (1) quotCMIC Memory CRC Error,quot Problem\/Failure Report No. Z87764, Jet Propulsion Laboratory, November 8, 2005. (2) M. Ratliff, quotProbability of Corrupting Four MRO CMIC File System Images in One Day,quot Jet Propulsion Laboratory IOM No. 5132-06-013, February 17, 2006. (3) M. Ratliff, quotProbability of SEUs in MRO CMIC SRAM File System,quot Jet Propulsion Laboratory IOM No. 5132-06-100, December 7, 2006. (4) quotFlight System Fault Tolerance, Redundancy, and Cross Strapping (Draft),quot Jet Propulsion Laboratory Guideline No. DocID 60492, February 7, 2007.","Lesson ID":1778}
{"Driving Event":"A metrology laser is used within the interferometer to measure the interferometer\u00bbs OPD position and change rate so that the FPA collection frames and the corresponding integrations times can be controlled. However, the frames coming out of the ROICs are typically resynchronized with time. Imaging interferometer sensor systems are offering broader capabilities and performance characteristics through the use of large field of view and data throughput. But system performance can easily be compromised by FPAs and ROICs that are not fully compatible with operational capabilities and performance requirements of the interferometer. The FPAs and ROICs should be designed, fabricated, and tested to meet the spectral, spatial, temporal, radiometric, control, and stability requirements needed to achieve the specified performance of the interferometer. FPA technologies can be overstressed by over-extending the longwave spectral cutoff point. This is especially true of long wave FPAs. Keeping the cutoff as short as possible can significantly improve FPA yield and performance and can reduce the cooling requirements for currently available technologies. Thus, the recommendation is to choose FPAs with the shortest cutoff wavelength that will still accomplish the desired science measurements.","Lesson ID":1595}
{"Driving Event":"Procedural deficiency: The metal to metal surface of the weight and the metal pallet without strapping the weight in place. Review of data verified that the tilt testing is a contractual requirement outlined in NASA-STD-8719.9 and has to be performed.","Lesson ID":1732}
{"Driving Event":"No signal was ever received from the joint British\/European Space Agency Beagle 2 lander, carried on the Mars Express spacecraft, after its scheduled landing time in December 2003. The following year, the Beagle 2 Commission of Inquiry identified a number of lessons learned. One lesson (Reference 1) stated the need for positive means of assuring that separated items (e.g., covers, main parachute) do not collide. The potential for separated items to regain contact and damage the spacecraft has also posed a significant risk to recent, current, and planned JPL missions. The system and mission designs have responded to this concern with positive measures to assure that items separated in flight will not regain contact: Genesis The Genesis Sample Return Capsule (SRC) design (Figure 1) was subjected to extensive analysis to ensure that separated items would not regain contact. When Genesis returned to Earth, SRC descent was to be arrested by a sequence in which a small aluminum mortar disk (sabot), a drogue chute, and then the main parachute were expelled from the SRC (Figure 2). Flight testing of this sequence and analysis of the resulting video demonstrated an adequate separation that increased with time, and showed that the deployed components could be tracked with ground cameras and radar. A change in the helicopter loitering duration further helped to ensure the safety of the mid-air helicopter capture of the SRC. Because the sabot follows in the wake of the rapidly inflating drogue chute, analysts also had to determine that the risk of the sabot penetrating and damaging the drogue was acceptable (Reference 2). Although the drogue parachute on the SRC failed to deploy during the mission due to an unrelated system failure, prior testing and analysis had successfully verified that there was little chance of collision. Figure 1. Diagram of Genesis SRC Figure 2a. Genesis SRC Parachute Deployment Sequence Figure 2b. Genesis SRC Parachute Deployment Sequence (Cont.) Deep Impact The Deep Impact mission required an unprecedented feat of navigation requiring an Impactor spacecraft to separate from a Flyby spacecraft and then fly in tandem under independent guidance to encounter a comet. A sophisticated model of the separation dynamics was created that allowed for the rapid implementation and analysis of multi-body dynamics. Even when the worst-case kinematics associated with a failed separation spring was combined with a worst-case off-nominal flight system performance, the analysis demonstrated adequate clearance between the two spacecraft and little chance of collision (Reference 3). MER During the Mars Exploration Rover (MER) entry into the Martian atmosphere, the heat shield, parachute, and lander were separated from the cruise stage, and the parachute deployed, at a descent velocity of 450 meters\/sec. Careful analysis assured the eventual success of a sequence in which (1) the heatshield was released using six separation nuts and push off springs, (2) the lander was lowered from the backshell on a 20-meter bridle, and (3) the separation rate was controlled by a Descent Rate Limiter-- a friction brake and steel tape that was deployed with the bridle. Phoenix & Mars Science Laboratory (MSL) Backshell or parachute recontact with the lander was one of the scenarios posed to explain the Mars Polar Lander mission loss in 1999 (Reference 4). Mars landing simulations for Phoenix Mars Scout and MSL revealed a similar risk that the backshell could overtake the lander after the engines fire to slow the landers' vertical descent. This risk was taken into account in the Phoenix and MSL designs. They feature a backshell avoidance maneuver in which a 6-axis descent control system will allow the descent stage to scoot sideways and avoid contact with the descending backshell\/parachute. Like a skycrane helicopter, the MSL descent stage will also use a tether to lower the lander to the Martian surface and then fly away from it. References: quotBeagle 2 ESA\/UK Commission of Inquiry, Joint United Kingdom\/European Space Agency Beagle 2 Commission of Inquiry,quot April 5, 2004, p. 30 (Recommendation No. 18). quotSabot Recontact with Drogue Chute and SRC, JPL Incident Surprise Anomaly (ISA) No. Z84100,quot Jet Propulsion Laboratory, June 11, 2004. quotOff-Nominal Separation System Performance and Clearance Analysis, Systems Engineering Report No. DI-IMP-MEC-005,quot Ball Aerospace & Technologies Corp., June 14, 2002, p. 1. quotReport on the Loss of the Mars Polar Lander and Deep Space 2 Missions: JPL Special Review Board, JPL Document D-18709,quot March 22, 2000, p. 43.","Lesson ID":1771}
{"Driving Event":"Information in this section of the lesson learned is controlled under the International Traffic in Arms Regulations (\"ITAR\") by the U.S. Department of State. If you are authorized to review the content, a copy can be obtained from David Oberhettinger at the Jet Propulsion Laboratory.","Lesson ID":1756}
{"Driving Event":"By relaying data to Earth through one of the spacecraft orbiting Mars, the two Mars Exploration Rovers (MER) were able to transmit science data at a higher rate than by direct links from the Martian surface to the Deep Space Network (DSN). However, these surface-to-orbiter relay links (via the UHF frequency band) are known to be less predictable in total data volume as compared to direct-to-Earth links (via X-band transmission). The data volume received during orbiter overflights has exhibited nominal variations of 75 to 125 percent of the volume predicted, and extremes of 50 to 150 percent of the predicted volume are occasionally experienced. Reference (1) is a very recent statistical study that for the first time documents MER data volume variations over 186 recent overflights. The study found that 11 overflights achieved less than 75% of the predicted volume and 78 passes exceeded 125% of predicted. Additional statistical studies are underway. Tactics such as changing a rover\u00bfs heading to facilitate communications after a day of driving and science activities have sometimes been necessary to attain an MER data return goal of 30 megabits per rover per quotsolquot (Martian day). Because there are multiple contributors to relay link variability, it is hard to identify and quantify the factors that contribute to the difference between the predicted and received data volume on a specific overflight. This is true even after engineering analysis of available rover and orbiter telemetered data, leaving mission planners with uncertain expectations as to actual performance. The impact on mission operations has been an inconsistent flow of relay link data during Mars surface operations. This has caused the following problems for the MER science team (Science Operations Working Group): When a UHF data relay pass yields a data volume that is less than 30 megabits, the science team may lack sufficient information (i.e., pictures of the rover\u00bfs surroundings) on the current sol\u00bfs drive to safely plan the next day\u00bfs drive. In contrast, larger than anticipated data volumes may represent a lost opportunity for the science team. Had they known, the team would have planned for more activity by rover instruments or higher image resolutions so that the extra telemetry capacity would not have been wasted. (See Reference (2).) The inability to consistently and accurately predict actual relay pass data volume is not an MER design or operational anomaly. It is an anticipated result of a telecommunications system constrained by the spacecraft mass and configuration, project budget, development and testing schedule, and operational factors, including: The UHF antenna pattern on MER is highly variable and not completely understood, even after extensive preflight mockup tests and post landing data collection. The UHF antenna pattern is further modified by local geologic surroundings which change the multipath signal phase and signal power. Geologic changes variables include proximity to a hill, proximity to a crater, proximity to a large rock, and changes in the electromagnetic properties of the underlying soil\/rock as the rover changes location. Rover tilt impacts antenna pattern. Predicted rover tilt is only known to a few degrees, and the relationship between tilt and antenna gain pattern is not modeled. Rover yaw angle is set to one of 20 steps, with the data volume computed based on the gain value for the step. Thus there is uncertainty in the gain pattern and in the resulting data volume due to this quantization. In addition, the gain pattern may be further changed by deployment or retraction of a rover appendage. The Mars orbiter UHF antenna gain pattern is also variable based on the pointing angle to the rover. It may further change with variations in orbiter solar panel orientation. The Mission Operations Team has limited insight into which of these design and operational factors apply, and the extent to which they apply, on a given relay pass. Constrained by mass, cost, and schedule, the MER lander project and the Mars orbiter projects elected to use omni directional UHF antennas mounted in the midst of a crowded science deck. This resulted in highly variable and unpredictable antenna gain patterns (Figure 1). Due to the same program constraints, testing of the antenna patterns was limited to model mockups which have limited fidelity. Thus much of the UHF link performance variability and uncertainty resulted from engineering and programmatic decisions with known consequences. (a) Drawing of an MER-like rover with a monopole UHF antenna with a radiation pattern having many lobes and nulls. A quotmeterquot indicating link predictability to an orbiter overhead displays a moderate reading. (b) Same as Drawing (a), except the MER-like rover is tilted and overhung by a crater lip. The meter reads at the low end of the scale. (c) Same as Drawing (b) with tilt and crater, but now a hypothetical future rover sports a high gain, steered UHF antenna that aims a single lobe toward the orbiter. The meter reads at the high end of the scale. Figure 1. Effect of antenna design on link volume predictability The majority of MER overflights have produced data volumes reasonably close to predictions. UHF data has totaled about 90 percent of the science data returned from the rovers. Use of the Proximity-1 protocol has assured that virtually all data actually returned is error free (Reference (3)). References: Andrea G. Thomas, Mars Exploration Rover UHF Data Return Statistics, JPL Memorandum No. 337H-06-001, September 21, 2006. https:\/\/mars03-lib.jpl.nasa.gov\/docushare\/dsweb\/View\/Collection-26375 quotProvide In-Flight Capability to Modify Mission Plans During All Operations,quot Lessons Learned No. 1480, NASA Engineering Network, June 21, 2004. quotMars Exploration Rover Telecommunicationsquot (Article 10, Deep Space Communications & Navigation Systems (DESCANSO) Design and Performance Summary Series), J. Taylor, A. Makovsky, A. Barbieri, R. Tung, P. Estabrook, A. Thomas, October 2005, p. 73, http:\/\/descanso.jpl.nasa.gov\/DPSummary\/MER_article_cmp20051028.pdf Additional Key Words (JPL metadata field): downlink; telemetry rates; data rates; relay passes; telecommunications performance; link performance; antenna performance; telecommunications accuracy; UHF design; UHF data return; UHF data volumes; error detection; error correction; operations phase; mission operations; operations design; occlusion; antenna pointing angle; antenna field of view; antenna field-of-view; antenna FOV; link margin; relay link planning","Lesson ID":1765}
{"Driving Event":"The supplier delivered squeegees that tested positive for trace amounts of silicone despite clear specifications prohibiting it. The supplier believed it had met this requirement because no silicone was used in the material used to form the squeegee. However, an investigation determined that the supplier had used a silicone-based release agent to ease squeegee removal from the manufacturing molds. Click here to view the lesson learned video. Click here to view a QuickTime version of the video. (Longer download time)","Lesson ID":1759}
{"Driving Event":"Click here to view the lesson learned video. Click here to view a QuickTime version of the video. (Longer download time)","Lesson ID":1760}
{"Driving Event":"Click here to view the lesson learned video. Click here to view a QuickTime version of the video. (Longer download time)","Lesson ID":1727}
{"Driving Event":"Click here to view the lesson learned video. Click here to view a QuickTime version of the video. (Longer download time)","Lesson ID":1758}
{"Driving Event":"Workers were in the process of renovating an area when they uncovered a 4 metal pipe which went through the ceiling of the room. There was no identification on the pipe and there was no indication of pipe on as-built drawings. The facility manager told the employees that it was a pneumatic tube pipe that had been part of the pneumatic dispatch system that was no longer used as he had been told by other facilities users. There were other personnel in the building that told the foreman the same thing. The workers took the facility managers word and started to cut through the pipe using a electrical band saw while on a 12 A frame ladder. When the bandsaw had cut through approximately three-quarters of an inch deep, there was a loud boom and sparks. There were 3 cables inside the pipe (conduit) with electrical power. The blade on the bandsaw was broke and a breaker had been tripped. There was no other damage. The breaker did not feed any equipment. The power had been terminated from its original equipment but not from the transformer & breaker. The employee was not hurt as he was on a fiberglass ladder.","Lesson ID":1757}
{"Driving Event":"Design issues included non-standard coordinate systems, different processing algorithms, and different data architectures. The team eventually resolved the timing interfaces and the end-to-end data flows, but the development of the attitude determination software took longer than expected.","Lesson ID":1593}
{"Driving Event":"An electrician suffered burns from an electrical arc\/blast when a pre-existing condition in a power distribution panel ultimately led to a ground fault in a 3-phase 480-volt power supply. The pre-existing condition was believed to be an access panel fastener that had penetrated conductor insulation. A contributing factor to this incident was the lack of work access history. This was tracked ultimately to the loss of maintenance data during support contract turnover. Maintenance schedules and data were not routinely obtained by the Government at contract termination. While JSC has been in existence since the mid-1960s, only the past two and a half years of maintenance history were readily available. The only record of past testing of the breaker was a test certification sticker from the time of installation ten years before the mishap. Records were not available to indicate preventative maintenance had been performed on this breaker. During a ten-year period, there were two occasions when the cables would have been disconnected from the breaker, so that the main breaker could have been removed for testing. As part of these Two opportunities for maintenance, the incoming cables where the fault occurred would have been recognized and corrected (moved and\/or repositioned), increasing the likelihood that any insulation damage would have been prevented. Specific transformer maintenance records indicate that five-year preventative maintenance was performed 14 months before the mishap on the primary building transformer. However, there was no work order was issued to perform maintenance on the main breaker of the power distribution panel.","Lesson ID":1718}
{"Driving Event":"During Mars Exploration Rover (MER-2) system-level thermal-vacuum (STT) test, it was discovered that one of two platinum resistance thermometers (PRTs) that provide temperature calibration for the Miniature Thermal Emission Spectrometer (MTES) had failed (Reference (1)). The PRTs had been installed by the contractor using a liberal amount of a rigid adhesive that transferred the thermal strain directly to the relatively brittle ceramic body of the PRT, overstressing it to failure. The mounting method had not been subjected to Package Qualification Verification (PQV), and subsequent coupon tests showed that the mounting method was consistent with failure within a few thermal cycles. One internal calibration target PRT on each of the Mars rovers was reworked by JPL using a ribbon of RTV, a configuration that passed PQV. (The others were not replaced because it would have invalidated the calibration.) Three months after landing on Mars, 6 internal and external calibration target PRTs on Rovers MER-1 and MER-2 that were bonded using the original method failed, but the 2 reworked PRTs subjected to PQV functioned properly. The loss of a temperature sensor on the MTES could result in the loss of a major portion of the rover's science return. In an unrelated incident during an STT of MER-1 (Reference (2)), the azimuth actuator PRT failed on the Instrument Deployment Device (IDD, or rover arm). This failure occurred shortly after the IDD heaters, used at the conclusion of the test to return the spacecraft to ambient temperature, were powered off. In this case, bonding adhesive likely migrated from under the PRT body and onto the lead wires (Figure 1), and the different coefficients of thermal expansion caused the contracting platinum wire to break and open at cold temperature. \/> Figure 1. PRT bonded to the actuator case with excessive epoxy adhesive, covering the leads (small wire loops indicated by arrow) Also, a PRT on the MER-2 Lander Petal Actuator failed in flight (Reference (3)). Thermal sensors provide vital information on spacecraft and instrument health, and are sometimes essential to subsystem function. A 1994 study (Reference (4)) documented a trend of in-flight failures of resistance thermal devices (RTDs) on JPL, Goddard Space Flight Center, and U.S. Air Force missions. Although electrostatic discharge and radiation also caused failures, design and implementation of the sensor mounting configuration was the probable cause of most failures. For installations lacking adequate strain relief, thermal dwell or cycling may induce different expansion and contraction rates in the (internal) sensing wire (~0.0006 inch diameter), or the lead wire (~0.012 inch diameter), versus the sensor body. Fracture of an RTD wire typically resulted in erratic readings (as the wire intermittently regained contact), followed by full scale temperature readings indicating an open circuit. References: JPL Problem\/Failure Report No. Z79528, February 21, 2003 JPL Problem\/Failure Report No. Z79691, March 5, 1003. JPL Problem\/Failure Report No. Z81188, July 10, 2003 D. Oberhettinger, quotNASA Unmanned Flight Anomaly Report: Investigation of Thermal Sensor Failures Aboard Unmanned Spacecraftquot(JPL D-11377), April 1994.","Lesson ID":1739}
{"Driving Event":"An aircraft (DC - 8) containing Life Support equipment (Life Raft) was received at the Center and a review of possible applicable GIDEP reports was not performed. The Life Raft, after being overhauled, was located in a storage area and had an inadvertent inflation. It was later determined that the Life Raft contained a valve, for which an applicable GIDEP report had been issued that recommended that the valve be replaced. Although the exact root cause of the inadvertent inflation could not be identified, the fact that the valve should have been replaced was identified as a contributing factor.","Lesson ID":1623}
{"Driving Event":"An electrician suffered burns from an electrical arc when a pre-existing condition in a power distribution panel ultimately led to a ground fault in a 3-phase 480-volt power supply. The pre-existing condition was believed to be an access panel fastener that had penetrated conductor insulation. Power distribution panel designs must allow sufficient internal space within the panel enclosure to route the conductor cables away from fasteners. In the case of this mishap, it appeared that the conductor cables were routed close to the front access panels and dead front where there are multiple fasteners capable of penetrating the cable insulation. A combination of too small a panel plus overcrowded cabling ultimately resulted in fastener penetration of conductor insulation. Control of the cables was complicated further by the sinuous, unrestrained routing of the cables from the floor to the breaker connections (see picture). Periodic power surges (such as by operating high-voltage breakers or by operating pre-programmed power line surge control devices such as reclosures) can physically jar cables (much like a water or air hose experiencing a sudden pressure increase), moving them incrementally closer to fasteners. Short and straight runs of unrestrained cables would not experience this type of response. Repeated removal and reinstallation of the fasteners for panel access due to construction and maintenance activity may have jeopardized the integrity of the electrical cable insulation. Each removal and reinstallation cycle may have further penetrated the insulation.","Lesson ID":1716}
{"Driving Event":"The Mars Exploration Rover (MER) project was extremely successful despite the largely single string flight system, which included such single string elements as the flight computer and the panoramic camera (Pancam). The lack of backups for many mission-critical system functions was largely due to spacecraft mass limitations. Constrained project resources were also responsible for other design tradeoffs (Reference 1) that increased the risk to mission success. The following 7 design features or program provisions (Reference 2) mitigated the risks posed by MER's design constraints: Effective Risk Management. The MER risk management approach involved the identification of risks and failure modes at project inception and their continuous modeling throughout development. For example: MER probabilistic risk assessment (PRA) included development of high level fault trees for the entry, descent, and landing (EDL) event that were completed for the Project Mission, System Design, and Cost Review (PMSDCR). Subsequent preparation and refinement of event trees and lower level fault trees were performed, not to pass reviews, but rather to understand system vulnerabilities and threats to EDL success. Significant failure modes were checked against contingency plans and reported at mission readiness reviews. The Mars Polar Lander (MPL) 1999 mission failure encouraged MER project management to impose a healthy skepticism towards success. The project continuously demanded proof that the system would work, rather than assuming that risks were acceptable unless shown to the contrary. Ample Fault Tolerance. The MER design featured extensive fault tolerance to allow full or degraded operation in the presence of a fault. Examples of this approach include: The MER design did not include a backup flight computer, but multiple EPROMs provided redundant copies of the boot code and of the flight software. The MER flight system design was tolerant to nearly all transient errors (e.g., power-on-resets) during EDL or on the Martian surface. The Heat Rejection System, which provided active cooling during the Cruise phase, featured a single coolant filter that could become clogged. However, a check valve permitted the coolant to bypass the filter if the coolant pressure reached a threshold value. The Pancam cameras were effectively single string as both needed to be operational to permit stereoscopic imaging, and both the failure modes, effects and criticality analysis (FMECA) and the PRA identified failure of a camera as a major risk to rover mobility. JPL planned for a degraded operational mode that could acquire an image from a single working camera, shift the rover several centimeters, take a second picture with the camera, and use ground software to combine the two images into a stereo image. A software commanding error could power a warm-up heater during the Mars daytime when it was not normally powered, and cause overheating. Hence, thermostats were added for fault mitigation. Flight System Flexibility. MER featured a very flexible design that, though it resulted in a very complex vehicle, permitted flaws to be corrected after launch: The MER PRA identified EDL as the most risky mission phase. Arguably, this held true for the Genesis and Stardust missions, which hard wired the EDL sequences such that they could not be changed after launch. In contrast, MER retained an ability to update critical EDL parameters during the latter stages of encounter and EDL. (See Reference (3).) This included both a flight system capability to uplink software updates during entry, and the operational plan, process, and tools for ground personnel to prepare the updates. Rover egress from the lander required the removal of various launch locks by firing pyrotechnic cable cutters and pin pullers in a predetermined sequential order. The firing of the pyro to permit deployment of the rover robotic arm had been timed to mitigate the risk that the arm might encounter higher than expected dynamic forces during egress. After launch, extensive analysis of the sequence revealed a yet greater risk that another, earlier, pyro firing to cut the final rover-lander cable could enable a sneak circuit that could be triggered by any subsequent pyro events. (see Reference (4)). So a decision was made to reorder the deployment sequence to release the rover arm before the final rover-lander cable cut to prevent activating any sneak circuits set up by the rover-lander cable cutter. Experienced Personnel. The lead engineers in each area had an unusually high level of experience, and were in many cases drawn from other current flight projects. These individuals were well acquainted with the MER mission failure space, and recent JPL mission failures had negated any complacency about mission risks. The JPL line\/project matrix organization facilitates such project access to key personnel. With JPL's reputation at stake, the MER project made sure that each critical failure mode was fully understood and the risk mitigated before the risk item was retired. (See Reference (5).) Ample Stress Testing. Significant resources were devoted to testing flight system robustness. MER utilized multiple flight system testbeds that were very flight-like. Compared to a project like Stardust that had only pieces of certain subsystems, the MER testbeds were hardware-rich and were not as dependent on simulators. (See Reference (6).) Long after launch, the project continued to perform system-level stress testing to identify system performance margins. Just prior to EDL, for example, a decision was made to enable all pyros. This posed a risk of premature pyro firing, but the additional test data indicated a higher risk that the safeties might inhibit a pyro during the firing sequence. Mars Program Synergy. Despite the short MER development schedule, the MER project was able to take advantage of the avionics concept and rover designs developed for the 1999 version of the Mars Sample Return project architecture. In-House Project. Because the MER flight system was largely an in-house development, the designers and testers understood how the subsystems worked. Although some items like the radar altimeter and solar arrays were procured, JPL's lesser dependence on major subsystems provided by other organizations or countries permitted the same rigorous approach to fault protection to be employed at all hardware levels. References: Rob Manning, \"MER Project: Stealing Success from the Jaws of Failure, Video Presentation AVC-2005-200,\" September 23, 2005. David Oberhettinger, \"Mitigation of Risks Associated with MER Single String Architecture,\" OCE DJO 05-001, November 28, 2005. \"Provide In-flight Capability to Modify Mission Plans During All Operations, NEN No.1480,\" NASA Engineering Network (NEN), June 21, 2004. \"Plasma Arcs from Pyro Firing May Cause Prolonged NSI Shorts,\" NEN No.1412, NASA Engineering Network (NEN), April 19, 2004. \"If You Dont Understand an Environment, Provide 'Well-Margined' Capabilities to Encompass the Worst Case,\" NEN No. 1712, NASA Engineering Network (NEN), December 16, 2005. \"The Risk Reduction From 'Two-fers' (Multiple Sister Spacecraft) May Outweigh the Incremental Cost,\" NEN No.1485, NASA Engineering Network (NEN), May 17, 2004.","Lesson ID":1743}
{"Driving Event":"This lesson learned documents a NASA Preferred Practice for Design and Test that was drafted shortly before the cancellation of the Preferred Practice task. Hence, the draft was not subjected to review by the NASA field centers and should not be viewed as a formally accepted NASA-wide practice. Practice Prepare and implement an institutional plan for the comprehensive assessment of NASA critical facilities and equipment that includes: An inventory of critical facilities and equipment. Comprehensive assessment of failure modes for critical equipment. Establishment of appropriate Reliability Centered Maintenance (RCM) methods. Acquisition of necessary Predictive Testing and Inspection (PT&I) equipment. Implementation of RCM using a Computerized Maintenance Management System (CMMS) and appropriate performance metrics Center-wide training in RCM and Critical Facilities Maintenance Assessment procedures. Benefit Critical Facilities Maintenance Assessment (CFMA) was first implemented by NASA following the March 2000 High Energy Solar Spectroscopic Imager (HESSI) spacecraft overtest incident. Inadequate maintenance of the test equipment was one of the principal causes of the major structural damage sustained by HESSI during this JPL test. Subsequently, other incidents have occurred at NASA centers such as contamination in an assembly facility that housed a spacecraft due to rainwater from a leaky roof. CFMA identifies inadequacies in ground facility readiness that could affect the safety of the public, the NASA workforce, flight hardware, and other critical equipment and property. Implementation Method To simulate the extreme environments of space, test equipment may subject spaceflight hardware to stress levels that approach the test article's limits. Often with repeated test-analyze-and-fix cycles and few or no flight spares, it is essential that testing be conducted with high reliability and fidelity. The potential cost and schedule impact of a test failure or facility failure increases disproportionably with proximity to the system's launch date. The March 2000 HESSI spacecraft overtest incident alerted NASA to the substantial risks of utilizing aging industrial facilities for the development of high value, one-of-a-kind products. The assessment and management of these programmatic risks, as well as safety risks, require data on the facilities' condition, characteristic failure modes, and maintenance practices. Hence, NASA initiated a review of all critical ground facilities at each of the NASA centers shortly after the HESSI mishap. A comprehensive program was begun to define RCM gaps, complete a critical facility inventory, perform failure assessments, define and document maintenance procedures, and implement a CMMS. This process is depicted in Figure 1. NASA Policy Directive NPD 8831.1, Maintenance of Institutional and Program Facilities and Related Equipment (Reference (1)), was revised to require self-assessments of facilities' maintenance programs and utilization of accepted standards as a guideline to determining facilities' maintenance funding requirements. Figure 1. NASA Vision for Asset Management CFMA is conducted on NASA facilities only. However, given the opportunities for damage to NASA flight systems in facilities owned by system contractors, contractor proposals and operations should be reviewed for the maturity of their maintenance practices. For on-site contractors, opportunities for collaborative use of maintenance resources (e.g., sharing FMEA data) should be pursued. Facility Inventory and Audit: CFMA should be conducted by a working group composed of maintenance specialists competent to review the health of the center's current maintenance programs and identify any needed improvements. The CFMA Working Group (CWG) should also include those individuals responsible for key facilities such as major integration and test laboratories, with support by reliability engineers and other specialists as needed. The first task for the CWG is to complete a comprehensive inventory of equipment and facilities that are critical to the mission of the center. Critical equipment may be defined as quotequipment, which if not operated or maintained correctly, could endanger the operating personnel or the product being processed.quot The inventoried items are then ranked in order of relative criticality. Technical equipment with primary functions related to flight system development and operation are identified and ranked separately from non-technical, general-purpose equipment such as HVAC facilities. The purpose is to separate civil engineering related items with well-understood failure modes and maintenance needs from specialized engineering facilities that are candidates for failure mode analysis and RCM. Technical equipment that processes flight hardware, defined as quotproduct items deliverable to a customer or deliverable to a significantly high-level of integration,quot is given a high ranking. High ranking items are given priority for further assessment within the CFMA process, and this prioritization may also impact capital equipment improvement plans and other institutional processes. Once the critical facilities are identified, they are audited for compliance with maintenance policies and procedures. The following information is elicited from facility operators through interview or survey (i.e., questionnaires) techniques: NASA and center-specific policies and procedures are adequate to provide the necessary level of protection, and they are currently in use by the facility operator for the inspection, calibration, maintenance, repair, and control of technical equipment. Procedures for quotcontrolquot include those issued to ensure proper operation, industrial safety, system safety, emergency response, etc. Statutory and regulatory requirements that must be complied with-- including safety, environmental, physical security, and information technology security-- and NASA and center-specific compliance policies and procedures tailored to these requirements. Practices employed independently by operators to remain current on regulatory requirements. Schedule of third-party ISO audits, internal audits, self-assessments, and other continuing activities in use to monitor that policies and procedures are understood, adhered to, and effective. Formal training provided to center staff on policies, requirements, and procedures affecting facility maintenance and operation. Training provided to staff on maintenance techniques, including RCM. The audit also includes CWG visits to the facilities to observe activities, examine procedures and records, observe housekeeping conditions, and interview facility managers and personnel. The results of this audit are evaluated by the CWG to determine whether there is sufficient objective evidence, including maintenance and training records, to verify compliance with maintenance policies and procedures. Deficiencies and remedial plans are documented in an institutional closed-loop corrective action system such as JPLquots Corrective Action Notice (CAN)\/Preventive Action Notice (PAN) system. The CWG issues a report that documents the facility inventory and audit, and summarizes the current maintenance programs used by the Field Center to assure that critical facilities and equipment are kept in a good state of repair. Failure Mode Assessment for Critical Equipment: Each Field Center conducts an informal assessment to determine and document the principal latent failure modes and the consequences of failure for the inventoried facilities. Identification of failure modes and failure causes resembles a high-level fault tree, annotated to indicate the potential impact of maintenance. The purpose is to identify the principal failure modes of concern, the likely cause of failure, the possible types of damage to flight hardware, and the extent to which the failure modes are preventable by maintenance. Hence, test facilities that are intended to apply calibrated levels of stress to flight hardware would be prime candidates for assessment. Table 1 illustrates this summary level of failure mode assessment for such a candidate. Table 1. Failure Mode Assessment for a Large Space Simulator Particularly for facilities and equipment that have implemented an RCM process, the recent reliability performance of candidate facilities should also be reviewed to identify the facilities and failure modes to be included in the informal assessment. This initial assessment is intended to identify major areas of concern and does not cover all GSE, review failure modes in great detail, penetrate to root causes of failure, or assess the statistical likelihood of failure. Such comprehensive failure analysis is the province of RCM, which seeks to optimize the distribution of maintenance resources by application of standard reliability analysis techniques to determine where the greatest benefits may accrue. Over the course of an RCM program, Failure Mode and Effects Analysis (FMEA) will be conducted to identify lower tier equipment failures that could cause catastrophic failure of critical equipment and facilities. In tandem, root cause analysis will explore all possible causes for a postulated machine failure. Because these techniques are labor-intensive and conducted over the life cycle of the facilities, the CWG may propose equipment candidates for FMEA and Root Cause Failure Analysis (RCFA) based on their criticality and failure history. Establishment of RCM Methods: NASA policy promotes the use of RCM techniques to assure that maintenance resources are applied cost-effectively and where they can best mitigate mission risk. CFMA evaluates the extent to which RCM and PT&I practices are being incorporated into the development, improvement, operation, and maintenance of critical facilities and equipment to minimize life-cycle maintenance and repair costs, maintain facilities and equipment at the desired level of reliability and availability, and maximize safety. More information on RCM methodology is available in a related preferred practice (Reference (3)), 'Preventative Maintenance Strategies Using Reliability Centered Maintenance (RCM)'. The NASA RCM Guide (Reference (4)) serves as the basis for the NASA RCM assessment process. This NASA RCM guide suggests specific components (see Reference (4), Chapter 3) for benchmarking the maturity of an organization's RCM program within each of the following seven program elements: Maintenance Philosophy Program Organization Performance Measurements and Indicators (Metrics) Proactive Maintenance Predictive Test and Inspection (PT&I) Technologies Preventive Maintenance Training and Personnel Development The CWG, as part of the CFMA audit but with specialized assistance as required, assesses the current status of the RCM program within each maintenance organization that is responsible for critical facilities. Interview or survey questions based on the above seven program elements are prepared, facility documentation is reviewed, and the results are evaluated to identify organization-specific RCM and PT&I capabilities and potential applications. A report is prepared that benchmarks each organization's progress (and the overall progress of the Field Center) in implementing each of the RCM program elements, as shown in Table 2. The report also contains a tabulated summary of the RCM improvement opportunities available to the critical facility maintenance programs, and it provides recommendations to the organizations for complying with the NASA baseline RCM program components. Table 2. Critical Facility RCM Status Summary Other RCM program developments to be assessed and reported by the CWG include: An estimate of RCM implementation costs and the potential return-on-investment (ROI) for each critical facility maintenance organization. This may be based on the systems being maintained, equipment condition, maintenance histories and processes, and the extent to which RCM tools and techniques are currently being used. A plan of action and milestones for implementing an RCM program for each applicable maintenance organization, with goals for continuous improvement. This includes plans to incorporate applicable RCM requirements into service contracts. Significant lessons learned from implementing RCM programs. Also RCM best practices, with emphasis on the areas of test equipment maintenance and calibration, policies and procedures, and on-line tracking of personnel training and qualifications. Establishment of PT&I Technologies: Predictive Testing & Inspection (PT&I) can in some cases provide an alternative to scheduled periodic maintenance by using non-intrusive tests, visual inspection, and performance data to assess machinery condition and determine when maintenance is necessary. Using the following PT&I technologies, a maintenance alert is issued when a deviation from acceptable values is detected: Vibration Monitoring & Analysis Infrared Thermography Ultrasonic Noise Detection Lubricant and Wear Particle Analysis Electrical Condition Monitoring Non-Destructive Testing However, specialized equipment may be required such as vibration transducers, low mass accelerometers, sound discs, infrared thermographers and temperature probes, ultrasonic noise detectors and sources, leak detectors, integrated motor circuit analysis testers, data loggers, and multi-channel analyzers. A full set of, for example, electrical testing equipment for a facility can cost in excess of $100,000. Maintenance personnel also need to be trained in such esoteric PT&I techniques as motor current signature analysis. The CWG conducts a review of PT&I technologies currently in use across the Field Center, and identifies other opportunities for their application, as part of the CFMA audit. The review includes an inventory of PT&I capabilities, including equipment and personnel in critical facilities that are dedicated, or could be dedicated, to PT&I purposes. Implementation of RCM using a CMMS and Appropriate Performance Metrics: A Computerized Maintenance Management System (CMMS) is needed to monitor an effective and modern NASA maintenance program and link the equipment inventory with data on equipment condition, maintenance activity, and operational history. Having all critical equipment maintainers using a common CMMS that records all PM and PT&I tasks assists the Field Center in coordinating maintenance, certifications and validations, PT&I applications, and other RCM-based initiatives. A systematic and formalized process for updating and validating equipment inventories is necessary to ensure that the CMMS contains accurate equipment information. Development of a standard set of maintenance metrics should be among the first RCM efforts conducted by a critical facility maintenance organization. NASA and these Field Center organizations should derive a set of RCM performance measurements and indicators that reflect the health of their critical facility maintenance programs-- not merely the metrics indicating the level of service being provided by the contract. Standardization of maintenance tasks through maintenance procedure documentation and training will aid both the maintenance programs and the collection of metrics. The CFMA assesses the metrics in use to determine whether: Definition. Valid metrics exist and are properly defined. Ownership. Staff involved in collecting metrics are concerned about the accuracy, timeliness and consistency of the data reported. Utilization. The metrics are used as performance indicators. They are used for trend analysis to identify improvement opportunities and to evaluate accomplishments. Communication. The metrics are clearly communicated to customers and management. Center-Wide Training in RCM and CFMA Procedures: Education and training of individuals who operate and maintain critical facility equipment is critical to evolving from ad hoc maintenance practices into efficient modern programs. The qualitative CFMA should include assessment of RCM and PT&I training and training needs throughout the Field Center. Where applicable, develop a formal center-wide plan for skill evaluation and training that is based on the NASA RCM Guide and provides familiarization with RCM principles and FMEA analysis. Priority for RCM training should be given to quotRCM championsquot within each maintenance organization, reliability engineers, maintenance managers, and craft and administrative support personnel. Existing PT&I programs should be enhanced by providing PT&I training to technicians and analysts assigned to facilities that are not presently covered. In-house seminars on best maintenance practices, RCM, and PT&I should be a regular feature of in-house maintenance programs. The training program should also support continuous CFMA through training individuals in the facility assessment process. Training records should be kept for both NASA and contractor personnel. Important training administrative tasks include maintaining the training requirements, schedules, records, formalized levels, certifications, expenditures, and budgets. Tracking of center personnel training and qualifications is best conducted on-line over a web-based system that provides center-wide oversight and management of training and certifications. If incorporated into center-wide human resource operations, it will facilitate individualized tracking of each employee and contractor's compliance with training requirements. Such a center-wide process eliminates unnecessary paperwork and supports consistent training management throughout the Field Center. Technical Rationale: CFMA provides a systematic methodology for evaluating the upkeep of high value NASA assets. Its implementation and follow-up responds to lessons learned in which the use of conventional ground support equipment has caused significant damage to important NASA products. CFMA employs techniques such as RCM and PT&I to assure that the maintenance of critical NASA facilities and critical ground equipment is consistently performed and modern methods for managing maintenance data are used. Information on the current status of CFMA, including a Major Facilities Inventory, RCM guidance, sample maintenance specifications, and web-based training courses is available from NASA (Reference (4)). References: NASA Policy Directive (NPD) 8831.1C, Maintenance of Institutional and Program Facilities and Related Equipment, May 29, 2002. (NPD 8831.1, Rev. D, was issued on June 19, 2003.) Report of the NASA Critical Facilities Maintenance Assessment (CFMA) Panel, December 15, 2000. Maintainability Technique No. PM-4, quotPreventative Maintenance Strategies Using Reliability Centered Maintenance (RCM),quot NASA Lesson Learned No. 0891, NASA Engineering Network, December 1, 1994. NASA Reliability Centered Maintenance Guide for Facilities and Collateral Equipment, February 2000. NASA Facilities Engineering and Real Property Division website, http:\/\/www.hq.nasa.gov\/office\/codej\/codejx\/jxdocuments.html.","Lesson ID":1764}
{"Driving Event":"There is no requirement, policy or procedure governing the use or disposition of altered ordnance. The original test program, 90PLN-043 Engineering Plan (Effects of Aft Separation Bolt NSI Ejection on SRB Aft Strut External Tank Clevis End Energy Absorber) did not address the disposition of unexpended ordnance. Work Authorization Documents (WAD) do not contain closed-loop accountability for left-over, unused ordnance. Neither the unused unexpended ordnance nor the ammo can in which it was stored were appropriately marked to indicate the altered state of the NSI. Also, the altered condition of the NSI was not easily detectable. A First Article Review was not performed per Shuttle Engineering Directive T35R6. The CAIB NSI Ejection Tests were performed in August 2003 using a strut assembly with clevis installed, which may have given the technicians and engineers a false sense of altered ordnance acceptance. The test conducted within the struts masked the power of an uncontrolled ejecting NSI.","Lesson ID":1582}
{"Driving Event":"When the navigation camera (Navcam) power was switched on during integration and test (I&T) of the Mars Exploration Rover (MER) spacecraft, voltage measurements showed no power or data signals within the Navcam circuits. The Navcam had worked properly when tested prior to an earlier removal and re-installation of the Rover Power Distribution Unit (RPDU). An investigation revealed an un-mated connector on the Nonvolatile Memory and Camera Interface Board (NVMCAM) within the Rover Electronics Module (REM) (Figure 1). The assembly procedure called for the mating of this connector, and the mate\/demate log indicated that the connector had been mated. The root cause of the workmanship error was attributed to the failure of a technician\/ engineer to pause after each mate\/demate operation to enter it in the log, and to obtain Quality Assurance (QA) verification. A high connector density and an obstructed view within the REM make it difficult to verify the status of a single connector once multiple connectors have been mated. MER also has other high-density connection areas such as the Rover bulkheads (Figure 2). Although the impact of this error was minor, de-integration and rework to re-mate a connector in a highly integrated system like MER can pose a major risk to flight hardware. After this incident, the Assembly, Test, and Launch Operations (ATLO) manager mandated a \u201cone at a time\u201d practice of QA verification after every MER connector mate\/demate, and it did not permit mate\/demate of multiple connectors prior to obtaining QA support. References: JPL Problem\/Failure Report No. Z79107, January 20, 2003. Crimping, Interconnecting Cables, Harnesses, and Wiring, NASA-STD-8739.4, February 9, 1998. Magellan Battery Fire, LLIS No. 0386, NASA Lesson Learned Information System (LLIS), February 23, 1995. Mismate of Identical Connectors, ASTROS Project, 1988, LLIS No.0431, NASA Lesson Learned Information System (LLIS), September 14, 1995. Electrical Connectors, LLIS No.0444, NASA Lesson Learned Information System (LLIS), July 30, 1993. Electrical Connectors - Scout Program, LLIS No.0470, NASA Lesson Learned Information System (LLIS), July 22, 1994. Additional Key Words: connector mating, connector demating, QA procedure, blind mate","Lesson ID":1619}
{"Driving Event":"The Project, which was aimed at developing space flight hardware for biological research, included many contractors and other institutions distributed around the world. Therefore, the Project frequently shifted from an oversight to an insight role such that its limited mission assurance resources were used efficiently and effectively. The decision to stress oversight or insight involved several factors including travel, telecommunications, national culture, and the vendor\u00bbs in-house QA processes and track record. However, the main factor was the influence an activity (design, fabrication, test) had on the Project\u00bbs overall success criteria. Those activities deemed high risk received increasing oversight while those deemed low risk received increasing insight.","Lesson ID":1575}
{"Driving Event":"After a Mars Exploration Rover (MER) landed, but before the vehicle could rove the Martian surface, the rover had to be deployed from its compact mechanical configuration. This included the flight software-triggered firing of pyrotechnic cable cutters to sever restraints that had been placed on articulating assemblies. One such assembly was the Instrument Deployment Device (IDD), a mechanical manipulator mounted on the rover that carries the in-situ science instruments and positions them upon selected Martian terrain features. During pyrotechnic shock (pyroshock) and deployment testing of the IDD, a bright flash was observed, accompanied by a loud report (Reference (1)). Examination of a high speed video recording of the test (Figure 1) revealed flame and sparks discharged from the target aperture end of the cutter assembly. This is indicative of excessive leakage or blow-by of combustion products past the seals within the pyrotechnic device (pyro). Some blow-by had been noted earlier during testing of similar cable cutters used to release the MER solar array and airbags. Following the IDD incident, all MER test and flight cable cutters were reworked to incorporate a JPL change to the pyro design that significantly reduced the leakage. Figure 1 - Blow-by from IDD cable cutter during 8\/9\/02 pyroshock test check Video Some blow-by (due to design tolerances) is typically considered inherent for pyrotechnic devices, the leakage is difficult to characterize or to measure, and it may be exacerbated by workmanship errors in their manufacture. Leakage is more pronounced at low temperature (Reference (2)). Post-incident examination and testing revealed no damage to the flight hardware, including the Rock Abrasion Tool (RAT) instrument that had been installed on the IDD for the test, and no evidence of contamination on any of the adjacent surfaces. There was no hazard to personnel because the testing was done remotely. However, had the optical flight instruments been attached to the IDD during the pyroshock test, significant contamination might have occurred. References: (1) Excessive Blowby\/Leakage During Deployment & Pyroshock Exposure Testing of the [MER] IDD, JPL Problem\/Failure Report (PFR) No. Z77205, August 21, 2002. (2) Mars Exploration Rover (MER) Pyrotechnic Test Damage, Lesson No.1316, NASA Engineering Network, November 1, 2002. (3) Pyrovalve Blow-by May Interact Violently With Propellant, Lesson No.0591, NASA Engineering Network, May 14, 1998. (4) VO'75 Pressure Regulator Leakage and Work-Around Procedures, Lesson No. 0420, NASA Engineering Network, May 22, 1978.","Lesson ID":1725}
{"Driving Event":"GIFTS suffered from a lack of \u201censemble suite\u201d requirements (joint ensemble performance metrics). GIFTS started out with no project-defined, Level 1 scene requirements. Instead, scene requirements were derived from the individual technologies. For these reasons, it became difficult to establish measurement criteria for the ensemble suite. This hampered the allocation of requirements to lower levels. This led to too many \u201cimplied\u201d requirements left open to interpretation by the implementers. GIFTS could have benefited more by assessing how the individual technology scene requirements either helped or hindered the ensemble suite requirements. More work was needed to refine the scene requirements so that requirements could be allocated and flowed down. More work was needed to define verifications that could be measured and tested.","Lesson ID":1596}
{"Driving Event":"During a test by a contractor on the heater circuitry in a Thermal Interface Board (TIB) for the Deep Impact Impactor, a ground support equipment (GSE) switch stuck in the closed position. This caused an opto-isolated field effect transistor (FET) switch (Figure 1) to fail in the ON condition (Reference (1)). The TIB controls the heaters for the spacecraft panels, NiH battery, and thrusters, and it is located in the Remote Interface Unit (RIU), an assembly (Figure 2) responsible for engineering telemetry collection and remote subsystem control. Figure 1. Destructive physical analysis showed electrical overstress damage (indicated by arrow) to the Deep Impact TIB FET die. Figure 2. Installation of the flight Remote Interface Unit (RIU) on the Deep Impact Impactor spacecraft. The GSE switch was a momentary switch mounted on a GSE test box. Its purpose was to short the output of the FET switch to ground to verify that the heater over-current detection circuitry and the field programmable gate array (FPGA) could detect a short and shut off the heater. A defect in the GSE switch is suspected to have caused repeated cycles of intermittent contact that kept the input voltage above the over-current sense voltage level that would have caused the FPGA to trigger a shutdown of the FET switch. In-flight failure or unintentional turn-off of an FET switch (optocoupler) in the TIB controlling the heaters could cause severe under-temperature conditions with catastrophic results. Both the TIB over-current detection circuit and the test configuration were poorly designed by a subcontractor to the JPL system contractor. There was very limited oversight by JPL, with an average of less than one JPL engineer's time assigned to monitoring development and test of the Command & Data Handling Subsystem. In addition, a detailed technical review of the circuit schematic performed by engineers with the appropriate expertise would have identified the design error, and a failure mode and effects analysis (FMEA) of the test configuration (Reference 2) would have shown the absence of current-limiting GSE to protect the flight hardware. The value of detailed technical reviews at the assembly and subsystem levels was well established by the JPL Mars Pathfinder project, and JPL took corrective action several years later to require mandatory peer reviews (Reference 3) and contractor surveillance (Reference 4) in the wake of the JPL Mars Climate Orbiter mission loss. References: JPL Problem\/Failure Report No. Z79614, February 27, 2003. Flight Hardware Damage Due to Inadequate Test Planning and Insufficient QA Involvement, NEN No. 1201, NASA Engineering Network (NEN), January 1, 2002. JPL Corrective Action Notice No. Z66277, MCO-JPL\/SRB Finding #4.11 (Technical Reviews), November 23, 1999. JPL Corrective Action Notice No. Z69129, IG Report\/Stephenson Report: Subcontractor Performance, April 28, 2000. Current Limitation is Necessary for All Uses of Power Supplies, NEN No. 1358, NASA Engineering Network (NEN), July 29, 2003.","Lesson ID":1711}
{"Driving Event":"A Factory Compatibility Test (FCT) was performed on the NASA CloudSat spacecraft to provide a baseline for comparison of payload function and performance after transportation to and installation at the launch pad. In May 2005 a Launch Base Compatibility Test (LBCT) was performed at Vandenberg Air Force Base (VAFB). The LBCT ground support equipment (GSE) configuration differed significantly in complexity from that of the FCT (as described below). The LBCT was performed in the payload processing facility (PPF) to verify the compatibility of CloudSat radio frequency (RF) signals with the Air Force Satellite Control Network (AFSCN) ground system. Examination of the LBCT results showed that approximately 5 percent of the science data frames downlinked from the Cloud Profiling Radar instrument aboard CloudSat failed to reach the Vandenberg Tracking Station (VTS). After significant resources were expended troubleshooting this problem under launch schedule pressure, the anomaly was traced to the test configuration differences between the FCT and the LBCT. For the spacecraft RF signal to reach the VTS, it must pass through a series of GSE coaxial cables, couplers, and attenuators in the PPF. Subsequent modifications to match the FCT configuration resulted in an increase in signal strength of 10-20 dB, and the number of lost science data frames was reduced significantly below specified levels. An effective industry practice is to duplicate the launch control at the factory or at the system-level spacecraft test, or Assembly, Test, and Launch Operations (ATLO), facility. This is done with sufficient fidelity and configuration control to assure that anomalous conditions encountered at the launch site may be efficiently and thoroughly analyzed and resolved during integration and test (I&T). Highly successful space programs, including some recent JPL missions, have taken further steps to assure launch and deployment success by conducting primary launch and\/or deployment operations at the \"factory,\" or within the ATLO facility itself. The operations facilities at the launch site are then reserved for use only as a backup. References: (1) \"LBCT CPR Data Loss,\" JPL Incident Surprise Anomaly (ISA) No. Z86739, June 10, 2005. (2) CloudSat Mission Readiness Review, \"Spacecraft\" section, September 1, 2005. (3) \"End-to-End Compatibility and Mission Simulation Testing,\" NASA Reliability Preferred Practice for Design and Test No. PT-TE- 1437 (NASA Lessons Learned No. 0726), February 1, 1999.","Lesson ID":1713}
{"Driving Event":"An electrician suffered burns from an electrical arc\/blast when a pre-existing condition in a power distribution panel ultimately led to a ground fault in a 3-phase 480-volt power supply. The pre-existing condition was believed to be an access panel fastener that had penetrated conductor insulation. The response of local emergency resources to the mishap was exemplary, but would have been delayed if the injured worker had not just done his own safety task analysis just before the mishap. The safety task analysis included among other things locating fire alarm pull boxes and extinguishers; who to call in case of an emergency; what hazards were in place in the work area; etc. This safety task analysis is routinely performed before each task to ensure that risks are minimized prior to start of work. Because the worker pulled the alarm box within ten seconds after being injured, emergency response teams responded and were at the scene within 3 minutes of the event. Response was initiated before detectors triggered alarms at the Emergency Operations Center and the fire station. The employee was already showing signs of shock upon arrival of fire protection specialists who administered first aid until the paramedics arrived a couple minutes later. The patient was transported to a downtown hospital\u00bfs burn unit and arrived within 40 minutes of the emergency. At the same time first aid was being administered, additional fire protection specialists began to fight the small fire in the building. The fire was extinguished immediately with a dry chemical extinguisher and before the fire suppression system was triggered. Damage\/loss of mission-critical equipment and facilities was averted. The reported community standard for emergency response is for resources to arrive at the scene within 30 minutes of notification. Without a working fire suppression system in place, total building involvement would have occurred. The presence of onsite resources plus the pre-established response by the employee reduced response time to 3 minutes. Because everything was in place \u00bf employee response, systems in place, and resources ready - the injured employee was stabilized rapidly and the damage incurred was restricted to the failed equipment.","Lesson ID":1721}
{"Driving Event":"The mission of the Genesis spacecraft was to collect solar wind samples and return those samples to Earth for analysis. In September 2004, the spacecraft approached Earth and fired pyros that jettisoned the Sample Return Capsule (SRC). After entering Earth's atmosphere, the SRC was expected to open a drogue parachute, followed by release of the main parachute and the mid-air capture of the SRC by a helicopter. Instead, the pyro event to release the drogue chute did not occur, and the SRC struck the Earth at high speed. This resulted in a loss of some of the science return, but the integrity of the sample collectors was maintained sufficiently to achieve mission success. Failure analysis determined that four gravity switches (g-switches)-- two switches mounted on each of the two relay modules (Figure 1), each within an SRC Avionics Unit (AU)-- were phased incorrectly. That is, they were assembled according to the drawings, but the design placed the switches on both relay boards in the wrong orientation relative to the deceleration force during atmospheric entry (Reference (1)). This orientation prevented the switch mechanism (Figure 2) from closing during the deceleration of the SRC. G-switch closure was required to trigger the critical events needed for the SRC's safe return. The switch design error resulted from modifications to the heritage Stardust Avionics Unit that changed both the orientation of the circuit boards and the orientation of the switches as they were mounted on each circuit board. These apparently minor design changes constituted a departure from design heritage that necessitated testing. Indeed, the centrifuge test that was performed for Stardust would have detected the Genesis design error, but the test was not performed because of (1) an erroneous view of the Genesis AU design as Stardust heritage and (2) a 4-month schedule slip in the delivery of the AU for test and verification. The multiple Genesis g-switches within the duplicate Avionics Units provided hardware redundancy, but not functional redundancy. Hardware redundancy was provided in that both switches needed to close in only one of the AUs. However, an independent pressure switch to sense altitude, or a countdown timer that started when the SRC was released from the spacecraft, would have added a backup function for triggering drogue chute deployment during the entry, descent, and landing (EDL) phase. Figure 1. G-switch function requires an appropriate orientation (polarity) on the SRC Relay Module. The g-switches are mounted (per print) with the flared end containing the fixed contact (see Figure 2) positioned toward the top of the photo. Figure 2. G-switch views. The X-ray shows a moving contact and spring for sensing deceleration in one direction only. References: (1) Genesis Failure Investigation Report (JPL Failure Review Board, Avionics Sub-team), JPL Publication 2005-2, July 2004. (2) Genesis Mishap Investigation Board Report, National Aeronautics and Space Administration, November 30, 2005.","Lesson ID":1733}
{"Driving Event":"An electrician suffered burns from an electrical arc\/blast when a pre-existing condition in a power distribution panel ultimately led to a ground fault in a 3-phase 480-volt power supply. The pre-existing condition was believed to be an access panel fastener that had penetrated conductor insulation. The history of circuit breaker trips despite repeated trouble shooting suggested that there was an unstable system with an unexplained anomaly. This requires that the entire system be considered suspect form a safety standpoint and normal work practices would not apply. However, it is also recognized that the anomaly does not conclusively indicate a problem with a pre-existing condition in the upstream main distribution panel; all reasonable scenarios suggest otherwise. The anomaly and the pre-existing condition are likely unrelated. If there were any reasonable relationship, such recognition would have resulted in management intervention and cautions and warnings. A hazard analysis, inspections or findings during preventive maintenance might have identified this pre-existing condition.","Lesson ID":1719}
{"Driving Event":"Attitude control for the Cassini spacecraft, launched in October 1997, is accomplished during the Tour phase of the mission with a set of three reaction wheels (RWAs) (with a fourth provided as a backup). During most of the inner and outer Cruise phases of the mission, spacecraft attitude was controlled by reaction control thrusters. Beginning in October 2002, after two and one-half years of operation, a bearing cage instability trend developed in at least one of the two bearings in Cassini reaction wheel assembly No. 3 (RWA-3) (Reference (1)). The Cassini reaction wheels were first used for spacecraft attitude control in March 2000; after the trend was identified, they were used only when needed for precise and stable science-pointing. Cassini Bearing Cage Instability Timeline The problem was detected because Cassini reaction wheel performance has been continuously tracked via in-flight drag torque characterizations. When the data showed a 9-month period of intermittent RWA-3 bearing cage instability, this reaction wheel was replaced with the backup (RWA-4) in July 2003. Although the performance of the remaining three operational reaction wheels has been nominal, their identical bearing and lubricant design suggests that they too could be subject to the cage instability observed on RWA-3. Hence, the Cassini project has taken the following steps to control reaction wheel performance degradation: Kept RWA use to an absolute minimum during the outer Solar cruise phase to ensure RWA availability for science operations during the primary mission. Uses a JPL-developed Reaction Wheel Bias Optimization Tool (RBOT) to analyze optimal RWA bias rates so that the total RWA dwell time inside the problematic low-rpm region can be minimized. The deleterious effects of low-rpm operation are discussed in References (2) and (3). Continues to monitor and trend the performance of the reaction wheels (including RWA-3, which now serves as the backup). Bearing cage instability is typically heralded by audible noise, a significant spontaneous increase in the bearing drag torque, and excessive drag torque \u201croughness.\u201d The failure mechanism promotes energetic vibration of the retaining cage that leads to localized heating and polymerization of bearing lubricant (i.e., \u201cgelled\u201d oil) and, ultimately, premature bearing failure (Reference (3)). As bearing cage instability in spacecraft reaction wheels is not uncommon (Reference (4)), it is likely that similar persistent problems may be experienced by future missions that use reaction wheels for attitude control. References JPL Incident Surprise Anomaly No. Z78007 (Cassini), October 22, 2002. \u201cCassini RWA Flight Anomaly Due to Extended Use at Slow Speed,\u201d Lesson Learned No. 1416, May 28, 2004. Allan Lee, Gene Hanover, & Sam Sarani, \u201cCassini RWA Status at Launch +8 Years,\u201d Presentation to JPL SCO AACS Team, July 2004. Tungseth, A.E., \u201cDSP Wheel Recent Experience,\u201d Proceedings of the 17th Annual AAS Rocky Mountain Guidance and Control Conference, Keystone, Colorado, February 2-6, 1994, pp. 593-606. Additional Key Words: bearing failure, momentum wheels, excessive torque, torque instability, lubricant loss, tribology","Lesson ID":1598}
{"Driving Event":"Following the recommendations from the X43A Flight 1 MIB, the Pegasus actuator system was redesigned to accommodate the need for greater hinge torque. The analog-based legacy actuator system was redesigned for digital drive of the power output stage to the actuators, an additional actuator was incorporated to provide the necessary torque including margins, and the power supply was increased to provide the required 80+ amps, instead of the previous 40 amp capability. Multiple failures during qualification testing, and the subsequent technical investigations, proved the lack of understanding between the ideal circuit operation and the impact of system implementation.","Lesson ID":1607}
{"Driving Event":"Following the recommendations from the X43A Flight 1 MIB, the Pegasus actuator system was redesigned to accommodate the need for greater hinge torque. The analog-based legacy actuator system was redesigned for digital drive of the power output stage to the actuators, an additional actuator was incorporated to provide the necessary torque including margins, and the power supply was increased to provide the required 80+ amps, instead of the previous 40 amp capability. Multiple failures during qualification testing, and the subsequent technical investigations, proved the lack of understanding between the ideal circuit operation and the impact of system implementation.","Lesson ID":1609}
{"Driving Event":"The Project was aimed at developing an X vehicle for space flight. However, its Contractor was predominantly a ballistic missile developer with little expertise in space flight. Therefore, the contractor\u00bbs original approach to heat transfer issues when designing the thermal protection system was based on analogy to atmospheric flight and focused on one specific type of heat transfer. NASA\u00bbs experience indicated this was the wrong approach and that a different type of heat transfer was the dominant effect for space flight. Because there was a close working relationship with the contractor, the Agency was able to steer the contractor in the right direction. NASA provided appropriate design tools, which were based on detailed physics instead of just engineering correlations, to address the real heat transfer mechanism. NASA also had the expertise and detailed tools for verification, neither of which the contractor had, and used these to do detailed analysis of selected test cases. This incident touches on an unresolved question within the Agency, which is critical in such situations -- what should be the Government\u00bbs role in interaction with contractors? The Agency has periodically changed between insight and oversight for this relationship.","Lesson ID":1606}
{"Driving Event":"Following the recommendations from the X43A Flight 1 MIB, the Pegasus actuator system was redesigned to accommodate the need for greater hinge torque. The analog-based legacy actuator system was redesigned for digital drive of the power output stage to the actuators, an additional actuator was incorporated to provide the necessary torque including margins, and the power supply was increased to provide the required 80+ amps, instead of the previous 40 amp capability. Multiple failures during qualification testing, and the subsequent technical investigations, proved the lack of understanding between the ideal circuit operation and the impact of system implementation.","Lesson ID":1608}
{"Driving Event":"A senior individual with experience in many space flight projects, including several X-vehicles, had several observations regarding the relatively low priority (as compared to the science data) the Agency places on engineering data and instrumentation. The observation is that most missions do not include sufficient instrumentation for engineering. Thus, much data that could contribute to the understanding of margins and strengthen future designs (or even improve the current mission design) is never captured. Because little engineering data is available, it\u00bbs not possible to use analogy confidently in new designs so NASA must start over each time. Worse, post mission analysis does not have sufficient data to determine the contributing factors to either the mission\u00bbs success or failure, meaning lessons learned and knowledge capture is inadequate. Many factors contribute to the failure to collect engineering data. Usually, the engineering data needs of future missions have not yet been defined and thus are not a requirement to the current mission. Contractors are resistant to include more instrumentation for engineering data due to the additional weight, power requirements and complexity; scientific data collection and performance are given priority.","Lesson ID":1610}
{"Driving Event":"Following the recommendations from the X43A Flight 1 MIB, the Pegasus actuator system was redesigned to accommodate the need for greater hinge torque. The analog-based legacy actuator system was redesigned for digital drive of the power output stage to the actuators, an additional actuator was incorporated to provide the necessary torque including margins, and the power supply was increased to provide the required 80+ amps, instead of the previous 40 amp capability. Multiple failures during qualification testing, and the subsequent technical investigations, proved the lack of understanding between the ideal circuit operation and the impact of system implementation.","Lesson ID":1602}
{"Driving Event":"STS 90\/Neurolab was a Spacelab module mission focusing on the effects of microgravity on the nervous system. The mission was flown abroad the Columbia and launched on the 17 of April 1998 and lasted 17 days. The goals of Neurolab were to study basic research questions and to increase the understanding of the mechanisms responsible for neurological and behavioral changes in space. The mission was a joint venture of several space agencies and U.S. research agencies including the National Institutes of Health, the National Science Foundation, and the Office of Naval Research, as well as the space agencies of Canada, France, Germany, and Japan, and the European Space Agency. While the Neurolab mission was an overall success, it experienced several on-orbit hardware failures and problems that could have been minimized or prevented had adequate crew training been accomplished. In fact, the crew had not been used several of the flight system configurations until on-orbit.","Lesson ID":1613}
{"Driving Event":"STS 90\/Neurolab was a Spacelab module mission focusing on the effects of microgravity on the nervous system. The mission was flown abroad the Columbia and launched on the 17 of April 1998 and lasted 17 days. The goals of Neurolab were to study basic research questions and to increase the understanding of the mechanisms responsible for neurological and behavioral changes in space. The mission was a joint venture of several space agencies and U.S. research agencies including the National Institutes of Health, the National Science Foundation, and the Office of Naval Research, as well as the space agencies of Canada, France, Germany, and Japan, and the European Space Agency. While the Neurolab mission was an overall success it experienced several on-orbit hardware failures and problems that could have been prevented had adequate functional performance verification been accomplished. In fact several of the conditions that the systems experienced on-orbit could have been achieved on ground but were not due to inadequate requirements with regard to what environmental conditions were needed.","Lesson ID":1614}
{"Driving Event":"The slight waviness of nosecone surface variation in the vicinity of the FADS pressure port 3 causes the local pressure measurement to be lower than the other ports. Since the FADS pressure port measurements are used to compute the incoming flow angles, this results in an extra 1 degree of apparent flow angle at transonic speeds.","Lesson ID":1599}
{"Driving Event":"On December 13, 2004, the load pad bonding structures, placed below and above the right wing of the E-2C, were being moved to the left wing. The Overhead Crane Operator, who was also acting as the Operation Leader, conducted a quick Safety Briefing with the crew members to explain the activities planned for the operation. The first task was to remove the under-wing structure and move it to the left side of the aircraft. To achieve this task, nylon straps were utilized to support the \u201cH\u201d-Beam structure upright while the forward cable guides were removed from the \u201cH\u201d-Beam structure. The straps were used in a \u201cchoker\u201d fashion around the upper corners of the \u201cH\u201d-Beam structure and the Overhead Crane Operator took up the slack with the Overhead Crane and reported that the straps looked to be tight. The two forward cable guides were then removed. The \u201cH\u201d-Beam structure at this point was supported by the two aft guide cables, the floor bolts and the nylon straps attached to the overhead crane. The under-wing structure was then moved safely to the left wing of the aircraft. The next task was to remove the over-wing structure from the right wing and move it to the left side of the aircraft. The Overhead Crane Operator instructed the Lab Mechanic to remove the bolts that secure the \u201cH\u201d-Beam structure to the floor. After the floor bolts were removed, two electronics technicians (technicians were utilized due to a shortage of mechanics) proceeded to loosen and remove the aft cable guides without the knowledge of the Overhead Crane Operator who was distracted at the time. The outboard-aft cable guide was removed first, and then the inboard-aft cable guide was removed. As soon as the inboard-aft cable guide was removed, the structure started leaning outboard due to the cable guides being removed and the slack in the \u201cchoker\u201d loops of the nylon straps. The outriggers that were above the wing and attached to the \u201cH\u201d-Beam structure came in contact with the top of the wing before the slack in the nylon straps was taken up. The impact with the wing was low due to the \u201cH\u201d-Beam structure being supported by the overhead crane and nylon straps. The result of the wing contact was scraped paint and two minor scratches in the aluminum skin of the wing right above the main wing spar. There were no injuries as a result of this incident.","Lesson ID":1597}
{"Driving Event":"STS 90\/Neurolab was a Spacelab module mission focusing on the effects of microgravity on the nervous system. The mission was flown abroad the Columbia and launched on the 17 of April 1998 and lasted 17 days. The goals of Neurolab were to study basic research questions and to increase the understanding of the mechanisms responsible for neurological and behavioral changes in space. The mission was a joint venture of several space agencies and U.S. research agencies including the National Institutes of Health, the National Science Foundation, and the Office of Naval Research, as well as the space agencies of Canada, France, Germany, and Japan, and the European Space Agency. While the Neurolab mission was an overall success it experienced several on-orbit animal habitat hardware failures and problems. In addition, the mission\u00bbs approach to problem resolution of this type depended heavily on crew intervention. This approach proved to be unrealistic given the complicated nature of the mission since the crew\u00bbs time was already limited.","Lesson ID":1615}
{"Driving Event":"Each team brought their own \u201crequirements culture\u201d to the mix. The process suffered from requirements that were vaguely definable at Level 1, and thus could not be properly allocated and flowed down to lower levels. Some Level 1 requirements were unfunded, too. Some requirements were specified with verifications that could not be tested. The end result was a GIFTS instrument being designed and built to requirements we had, but not to the requirements we wished we had.","Lesson ID":1591}
{"Driving Event":"The Rover Power Distribution Unit (RPDU) on Mars Exploration Rover (MER) contains over 140 power switches controlling rover loads (e.g., heaters) and relays. During MER system integration and test, errors were discovered in the fabrication of two Rover Electronics Module (REM) heater circuits. The primary heater circuit for the REM was mistakenly wired to short the output from an RPDU switch to ground, immediately blowing a fuse. The backup REM heater circuit was also defective, but was miswired to produce no heat. The test incident caused no damage to the heaters or thermostats, but it demonstrated the need for an additional test to screen short circuits and other electronic fabrication defects that could stress flight hardware powered during Assembly, Test, and Launch Operations (ATLO). (A) MER ALTO test configuration (B) Configuration is a test point were added that would permit validation of the circuit (by bypassing the normally open thermostats) Figure 1. Thermostatically Controlled Heater Design However, performance of this step was inhibited by a lack of adequate test points in the circuit design. Because the thermostats only close when heater output is required, an ohmmeter placed across the connector input power pin and the return pin will always show an open circuit when tested at room temperature (Figure 1A). If the design had provided a pin (top of Figure 1B) on the connector that bypassed the thermostats, ATLO personnel could have directly measured the circuit resistance and determined that the wiring was incorrect. The cost of adding additional test points during circuit design is much less than the cost of dismantling the flight hardware to fix a flaw during ATLO. References JPL Problem\/Failure Report No. Z77947, October 16, MIL-HDBK-2165, Testability Program for Systems and Equipments,July 31, 1995, Para 202.2.4. MIL-HDBK-2165, Testability Program for Systems and Equipments, July 31, 1995, Para 202.2.4. Additional Key Words: design-for-test; test-induced failure, Manufacturing\/ Engineering","Lesson ID":1618}
{"Driving Event":"After solid rocket motor ignition, the hot rocket exhaust gas traveled through the rocket chamber pressure transducer port and impinged directly on the stainless steel sensing diaphragm, causing the pressure measurement to be erroneously high for about 2 seconds.","Lesson ID":1621}
{"Driving Event":"The servicing hose was not secured (safety lanyards or sandbagged) nor connected to the aircraft when it was charged with gaseous nitrogen.","Lesson ID":1622}
{"Driving Event":"The engines were not preserved and cost the project over $100K and around two months of schedule slip. Our engines need to be preserved and rotated every six months. After a year, they need to be run. This is in accordance to Pratt and Whitney's maintenance procedures. After they found out we did nothing to preserve them or rotate them, the management at Pratt and Whitney insisted that we needed to tear them down for inspection and that we would definitely find rust on our main bearings. Their initial recommendation was to tear down every component and send each one to its respective manufacturer for teardown and inspection. In fact, in the engine documentation it states that these bearings are highly susceptible to corrosion. At this point, the project could have ended because of the lack of replacement engines and the excessive costs incurred by following this recommendation. After further discussions with Pratt and Whitney, they determined that inspections to a few key components, like the main bearings, followed by an extended engine run with oil samples was sufficient as long as nothing off-nominal was detected. The inspections took place and the engines were run, with no signs of corrosion. It should be noted that engineers and technicians with a lot of engine experience at Dryden felt that none of this was necessary and that Pratt and Whitney did not understand the non-corrosive environment that the engines were kept in. But to reduce risk, we followed the manufacturer's advice.","Lesson ID":1624}
{"Driving Event":"In Novermber, 2003, routine checks of the Spacecraft Engineering Daily Plots showed a disturbance in the pointing stability just before 16:00 UT on 2003:319 (Figure 1). Detailed analysis of spacecraft telemetry showed that Chandra was likely impacted by a micrometeoroid. The investigation ruled out all internal causes. The disturbance occurred during the yearly Leonid meteoroid shower. Since analysis ruled out a cause internal to the spacecraft for the disturbance, it was hypothesized that the spacecraft was struck by a Leonid or other micrometeoroid.","Lesson ID":1709}
{"Driving Event":"The problem was related to the aircraft sitting for such a long time without being operated. There were multiple problems bringing 837 back up to flight status, none of which were related to the unique configuration of the aircraft. They included multiple hydraulic leaks and a Generator Failure. Since we did not have engines there was a limited amount of operations that could have been done on the aircraft to lubricate seals and operated components, but a plan that identified what could have been tested in the state that the vehicle was in, could have reduced the time required to bring the aircraft back up.","Lesson ID":1625}
{"Driving Event":"Late in the afternoon on Thursday, 17 June 2004, while in the process of performing a small modification to the left wing of the X-43A, the left rudder collided with the left horizontal wing. Visual inspection shows a small dent in the rudder and the wing at the point of impact. In addition to this, there is an offset in the rudder, approximately 3 degrees. On the evening of June 16, the Operations Engineer and the Systems Engineer had discussed planning activities for the X-43 for the following day, which included the possibility of performing the left wing leading edge. Electrical pre-mating activities were to be conducted. If time permitted during those activities then the left wing trimming activities would be worked into the schedule. They discussed the process of how they were going to perform the trimming activity. Normal process for moving an individual surface would be via using a break out box and isolate the surface following a set of procedures or checklist. However, due to the integration testing for the electrical pre-mating activities, using a break out box would break the continuity between the research vehicle and the adapter. The Systems Engineer suggested running and stopping the Built-In-Test (BIT) to move the wing into the proper position. The System Engineer stated that he would need to think about how to move the left wing up to perform the trimming work and write up some procedures to move the wing into the proper positions. The Operations Engineer discussed that this activity would be briefed with a Test Readiness Review before performing the activity. On the morning of June 17, at the daily 7:15 a.m. morning meeting, activities were discussed for the day's aircraft activities. Most of the activities involved the integration check out with the electrical pre-mating. The left wing leading edge trimming was also discussed as a possibility if time permitted. The priorities of the day were to finish the electrical pre-mating activities. Electrical pre-mating activities progressed throughout most of the day. In the early to mid afternoon, there was an informal meeting between the Operations Engineer, Systems Engineer, and others whose identities is unclear due to inconsistent testimonies. The meeting discussed status of the day's activities and as a result of it; the decision to postpone the left wing leading edge trimming until the next day and possibly into the next week to allow ample time to complete the electrical pre-mating activities. Soon thereafter (late afternoon), the ATK contractors requested the assistance of the X-43 Lead Avionics Technician in implementing the modification to the left leading edge wing. In order to perform the modification on the left leading edge wing, the wing had to be rotated leading edge up in order to allow access for the trimming. The approval process required to proceed with this activity is unclear due to inconsistent testimonies. There was no Test Readiness Review or pre-brief prior to this activity. There was no engineering direction to start the work. There was no test conductor conducting the activity nor were there written procedures used. The Avionics Technician positioned the wing by powering up the ship with 28V, followed by 150V, and then turning on the ground version of the surface built-in-test (BIT). The flight control computer commanded the left rudder to full sweep, returned it to zero, followed by the right rudder, and then the left wing. Once the left wing rotated to the correct position, the BIT was stopped and all power to the vehicle was turned off. The ATK contractor performed the leading edge trim work and requested that the wing be returned to the zero position. The Avionics Technician proceeded to power up the vehicle 28V, then 150V and then commanded the ground BIT. At this point the flight control computer zeroed the left rudder, commanded to full sweep (inboard then outboard), at which time the rudder surface struck the left wing, which was still at its leading edge up position. Once the left rudder completed its full sweep, the right rudder was commanded through its sweep. The BIT continued and the left wing was returned to zero. At that point the Avionics Technician stopped the BIT and turned off all power. The left rudder surface was at a slight inboard position when it should have been at the zero position.","Lesson ID":1626}
{"Driving Event":"The entry and descent of Mars Exploration Rover (MER), and its landing on Mars, were accomplished with limited knowledge of local environmental conditions. Reference (1) discusses our poor insight into Mars atmospheric density, and touts the flexible MER flight system and mission design features that successfully responded to new, crucial density data received during the latter stages of Mars Encounter. MER designers faced a similar knowledge deficit in regard to Martian wind velocity and effects. The estimate of Martian winds used in the July 1997 entry, descent, and landing (EDL) of Mars Pathfinder was based upon the altitude-specific historical record of daily winds and atmospheric pressure at Kennedy Space Center in Florida. This Earth data was considered to be conservative, and it was the most comprehensive dataset available. Seven years later, MER EDL planning benefited from new models of the local effects of known Mars terrain features on various postulated Martian wind conditions. However, these models had never been validated with actual Martian weather. Figure 1 - RAD and TIRS (small horizontal plume) test stand firing. + View Video Figure 2 - Animation depicting RAD (and TIRS) firing to decelerate Spirit and correct drift. + View Video Figure 3 - Image of the Gusev Crater taken by the DIMES camera as the Spirit lander descended to Mars. If wind shear in the lower Martian atmosphere were to tilt the descending lander from the vertical, the concern was that the firing of the Rocket Assisted Descent (RAD) rockets that slow its descent could propel it sideways and cause the lander to graze the terrain at a high lateral speed. Ground drop testing had demonstrated that the ability of the airbags to survive a rock strike at even a small horizontal velocity was marginal. To counteract such tilt, the MER design evolved early to include a Transverse Impulse Rocket System (TIRS), composed of three additional small rockets mounted on the lander backshell. The three TIRS rockets were designed to fire in any combination needed to right the backshell and reduce the lander's horizontal motion during RAD rocket burn (Figure 1). To control TIRS and to also cancel wind-induced drift, a decision was made only 1.5 years before launch to add a Descent Image Motion Estimating System (DIMES). This camera took a series of three photos that determined the lander's horizontal speed in the seconds prior to landing. TIRS\/DIMES provided a capability to compensate for relatively mild winds, and its criticality to the success of the planned MER landings could not be proven. The MER Opportunity lander did not encounter windy conditions at its Meridiani Planum landing site, so Opportunity did not fire the newly designed TIRS system. However, the MER Spirit lander's DIMES detected strong winds in the Gusev Crater and fired the TIRS. A video simulation (Figure 2), based on actual MER data, looks north and shows the TIRS rockets canceling the ground drift from a westerly wind. Without TIRS and DIMES working in tandem, the lateral motion across the rugged incline of the Gusev Crater (Figure 3) would likely have torn the airbags and threatened the mission. References: (1) quotProvide In-flight Capability to Modify Mission Plans During All Operations,quot Lessons Learned No. 1480, NASA Engineering Network, July 13, 2004. (2) Robert M. Manning, quotMER Project: Stealing Success from the Jaws of Failure,quot Video Production No. AVC-2005-200, September 23, 2005.","Lesson ID":1712}
{"Driving Event":"Sparks from construction welding ignited a fire inside the wall of a truck lock.","Lesson ID":1578}
{"Driving Event":"Employees were removing items from a building under renovation. There were five cylinders (2 CO2 & 3 Halon 1301) outside on the wooden back porch. One of the cylinders containing pressurized Halon 1301 discharged and hit the employee on the left leg, causing skin damage and a broken femur bone.","Lesson ID":1579}
{"Driving Event":"Flooding in an electrical vault caused by the failure of both sump pumps.","Lesson ID":1576}
{"Driving Event":"An employee was pulling new electrical cables through a newly installed conduit from a UPS room to the electrical vault in another location. He noted several strands of copper wire on the floor and picked the aire up to dispose of it. A strand of the copper came in contact with the metal trough on the battery rack, designed to collect any fluids from the lead-acid battery cells. His wrist came in contact with the metal doorknob and formed an electrical circuit between the wire in contact with the trough and the grounded doorknob. Electrical shock was the result. There were no injuries as a result of this shock.","Lesson ID":1577}
{"Driving Event":"The X-45A Unmanned Combat Aerial Vehicle (UCAV) had a requirement to hot refuel, (refueling with engine running) the vehicle in order to complete its Block 4 flights. Per Air Force T.O. 00-25-172 (Ground Servicing Of Aircraft and Static Grounding\/Bonding) this type of refueling requires the approval of the MAJCOM (Major Command) of the activity involved.","Lesson ID":1600}
{"Driving Event":"During an approved test procedure, an additional effort was undertaken in the hopes of saving time, and expediting a modification. This modification was not approved as part of the test configuration. Not fully understanding the sequence of the test routine, the wing and rudder came into contact resulting in minor to moderate damage to both. Though an engineering solution prevented the need to replace the rudder, the schedule impact was not trivial while determining the extent of the damage and adequacy of the solution.","Lesson ID":1601}
{"Driving Event":"A UAV was landed at a speed well above the design speed for the landing gear. The left main gear collapsed and the UAV veered off of the left edge of the runway while tumbling and shedding parts of the airframe, resulting in extensive damage to the vehicle. The pilot experienced time pressure to land the UAV as he though it was about to run out of fuel (typically resulting in a crash in this type of UAV). The UAV actually had triple the flight time that the pilot thought was available. The pilot was unable to adequately manage the UAV's energy throughout the entire flight and ultimately landed at 35 knots above the design speed for the gear, resulting in landing gear failure. The pilot did not know and was not briefed on the design speed limit for the landing gear. The flight crew, standing unprotected at the runway edge, could have been injured if the UAV had landed sooner and the right main gear had collapsed.","Lesson ID":1714}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number OPS-04 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. This practice greatly reduces the possibility of a vent line fire and\/or explosion during H2 venting operations. It is impractical to supply the large quantities of GHe required to create a non-flammable H2 \/He mixture during H2 venting operations. The upper flammability limits of a gaseous H2\/air mixture is lower with no GHe present. This technique also provides substantial safety benefits. This technique recommends initiating a GHe sweep purge to evacuate air from a vent line prior to venting a H2 system. After the initial venting operation is complete, a second GHe sweep purge should be conducted to evacuate the vent system of residual H2. The upper flammability limits of a gaseous H2\/air mixture is lower with no GHe present (see Figure 1). A flapper valve or check valve used on the vent line will prevent air intrusion into the line during low or intermittent flow conditions. [D] This practice should be included in all new systems operating procedures and changes initiated to applicable existing procedures. System design should be reviewed to include the following as recommended by NASA TM X-52454 (Lewis Research Center): Include a check valve\/flapper valve or other suitable mechanism to exclude air from vent stacks at low or intermittent flow conditions. Extend vent stacks 15 ft. above a building roof. Discontinue use of ordinary hydrocarbon flame arresters which are incapable of quenching a H2 flame. Provide a minimum of a 3-volume exchange (pulse purges) to sweep system prior to introducing hydrogen. Five to 10 volume exchanges to purge a vent system is a commonly acceptable industry practice. Reference: H. Hannah, LSOC 32-30, FCSS Hazardous Commodity Purge Study, dated September 1991","Lesson ID":851}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number OPS-02 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Moisture collects in the bag when the double-bag-and-seal method is used. This can lead to corrosion of the connector or possible electrical shock when the connector is reused. The use of plastic caps or manufacturer's covers will prevent moisture buildup, thus alleviating potential hardware damage or injury. This practice can be implemented in two ways: Provide instructions in operations and maintenance documents for protecting the connector after use. (A step should be included to inspect the connectors for corrosion\/debris and provide direction for corrosion\/debris removal, if necessary.) If ESD is a concern, do not use generic plastic caps as they can be ESD generators. ESD-approved caps should be used. Provide placard or tag on or near connector, stating method to leave connector after use. Reference: Guide for Design Engineering of Ground Support Equipment. KSC-DE-512-SM, Rev. B","Lesson ID":850}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number OPS-06 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Use of solid state controls instead of magnetic amplifiers can improve system restoration time in the event of a failure. Features such as fault detection, modular construction, and packaging can be easily employed. Diagnostics for system health status and problem resolution can also be readily provided. Incorporation of these features can result in improved system performance and availability. The use of solid state assemblies for control functions represents a great improvement over previous control methods. Historically, the first method of obtaining adjustable speed using DC motors was the constant potential DC supply using field adjustment. This provided a small range of adjustment. This method was followed by the rotating M-G system of Ward Leonard patented in the 1890's. This drive used an AC motor driving a DC generator to convert AC to DC power. The motor and generator may be combined in a single frame and use a common shaft, or separate coupled units (See Figure 1). The output DC voltage is controlled by adjusting the field excitation of the DC generator. Depending on the accuracy required, armature voltage or a tachometer may be used as a feedback signal in a closed loop system. An important aspect of this drive is that power flow is reversible. The motor acts as a generator, driving the generator as a motor, which drives the AC motor which then pumps power back into the AC lines. This ability, called regeneration, is a useful feature in decelerating large inertias or holding back overhauling loads. This is a very important consideration when replacing the M-G with a conventional packaged silicon-controlled rectifier (SCR) drive. [D] In the late 1940's, electronic tube drives began to replace M-G drives. These used vacuum, thyratron, excitron, or ignitron tubes for armature circuit control. They had limited acceptance because of tube life limits and water cooling requirements on larger ratings. By the early 1960's the tubes were replaced with the solid state thyristor drives. Magnetic amplifier drives were developed in the mid-1950's when silicon diodes became popular. They were never as widely used because of difficulties of reactor design and acceptable response rate. However, they were rugged and highly reliable once in satisfactory operation. During the early 1960's the thyristor or SCR became readily available. This device is similar in operation to a thyratron tube. Today it dominates the direct current drive field. Special circuits enable the SCR to regenerate and reverse readily. Larger and less expensive SCR's have extended the range to well over 1000 HP. Figure 2 illustrates a controlled rectifier drive. Note that the gateing control and SCR bridge have replaced the M-G set of Figure 1, resulting in reduced rotating machinery. [D] Solid State Operation Figure 3 shows the assemblies comprising a solid state control system for DC drives. A single phase thyristor power converter supplies up to 200 volts positive or negative at 20 amperes to the generator field. A closed-loop controller (speed regulator) provides for armature voltage with IR drop compensation or AC\/DC tachometer feedback speed control and linear acceleration and deceleration. A firing circuit provides an isolated gate drive to the power converter. A bi-directional adapter used in conjunction with the firing circuit assembly provides bi-directional current to the field of a DC generator for contactorless reversing or to regulate to zero output voltage in the presence of residual magnetism of the DC generator. Protective circuitry includes a voltage sensing relay for safety interlocking and an isolator for isolated armature current feedback. [D] Reference: KSC Electrical Drawing for VAB 250 Ton Cranes, 250-69-K-L-11388. KSC Electrical Drawing for VAB 175 Ton Crane, 175-67-K-L-11348.","Lesson ID":853}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number OPS-09 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Design of a pneumatic systems using vented pressure regulators offers the following maintainability advantages: Requirement for a separate relief valve in the pilot-loading circuit is eliminated. Logistics support requirements (materials, parts, tools) are decreased by elimination of additional relief valves. System availability is increased by elimination of additional components and their maintenance\/downtime requirements. Elimination of components enhances maintainability and increases reliability. Overall life cycle costs are improved by decreased maintenance and downtime requirements, and increased system availability. Pressure in pneumatic systems must be controlled. Primary points of control are downstream of the source (compressor) and the system receiver (tank). Control of pressure is required downstream of the compressor for system safety and downstream of the receiver to maintain a steady pressure source for efficient operation of other system components. Pneumatic systems use pressure regulators to provide this control. For those systems using standard dome-loaded (pilot-operated) regulators, this practice requires use of separate vented regulator for loading the pilot operated regulators. Figure 1 shows a regulator system with separate relief valves. A venting type regulator limits downstream pressure to a level lower than that of the upstream (receiver) pressure. It also acts as a relief valve for its leg of the circuit in the event of pressure build up. This method eliminates the need for a separate relief valve in the dome-loading circuit. Figure 1 also shows an example of a vented system which illustrates this method. [D] Reference: KSC-SD-Z-0005A, Standard for Design of Pneumatic Ground Support Equipment. Parker-Hannifin Corp., Bulletin 0225- B1, Fluid Power.","Lesson ID":854}
{"Driving Event":"During the construction of a Mod and Rehab project an unforeseen field condition was encountered when an abandoned piece of ductwork insulated with asbestos was found. Prior to construction, in the design phase, an environmental investigation was conducted and the contract drawings were marked up accordingly to what environmental hazards were found.","Lesson ID":920}
{"Driving Event":"A feedthrough condition occurs after most JPL spacecraft launches during initial acquisition of the downlink signal. The station's downlink signal performance indicators are affected by feedthrough from the uplink to the downlink. This feedthrough source may be uplink transmitter noise or, if there is ranging modulation, it may be components of the uplink ranging channel. In current link designs, the condition does not noticeably degrade the telemetry or ranging signals processed from the downlink for delivery to the project. Feedthrough occurs because of the extremely strong uplink signal over a distance of just a few thousand kilometers; this has the effect of reducing the station's reported value of downlink carrier power or of telemetry signal-to-noise ratio. Saturation effects in the station's receiver software algorithms contribute to the indications of signal degradation. This saturation causes the indicated signal-to-noise ratio to top out at a particular value even when the expected level may be tens of dB higher. One variation on this problem was experienced by both Mars Exploration Rover (MER-A) and Mars Odyssey. The initial acquisition downlinks from both missions experienced post-launch downlink saturation effects that produced lower-than-predicted downlink levels. In this case, uplink ranging data power harmonics feedthrough caused a \"pedestal effect,\" effectively raising the noise floor in the station receiver and degrading a key estimator (Symbol Signal-to-Noise Ratio). A related problem was documented in a lesson learned written on the Voyager mission. Voyager experienced command feedthrough problems because the uplink command modulation index (carrier suppression) that was optimal for commanding tended to degrade X-band telemetry. Link accommodations were successfully implemented by the Voyager mission. The problem described in Reference (1) has since been \"designed out\" with the 16 kHz command subcarrier frequency used by modern transponders in place of the Voyager-era 512 Hz. None of these strong-signal receiver nonlinearities affect the ability of telemetry subsystems to support ongoing activities. However, the apparent downlink signal degradation tends to elicit consternation in a critical phase of the mission if these expected effects have not been thoroughly coordinated between the Flight Project and the Deep Space Network, or if the Flight Control Team (FCT) has not yet become fully familiar with this idiosyncrasy of the mission operations system. References \"Command Feedthrough Problem on Voyager X-Band Downlink,\" NASA Lesson Learned No. 0418, March 7, 1979 Additional Key Words: Communication Link, Spacecraft Commanding; Signal Acquisition; RF Compatibility; RF Interference; Downlink Degradation; RF Interference; Radio Frequency Subsystem; Communications","Lesson ID":1531}
{"Driving Event":"The broken transmitter was mounted on the rocket's parachute harness. However, its antenna was not secured. During the parachute deployment, the forces and accelerations that occurred caused the antenna to break off from the transmitter. As a result, the transmitter ceased transmitting, and the rocket was found using the radio signal from the remaining operative transmitter.","Lesson ID":1533}
{"Driving Event":"Vacuum testing of the Mars Reconnaissance Orbiter (MRO) telecommunications subsystem at JPL included a multipaction test of the diplexer, which is conducted with the equipment powered. (\u201cMultipaction\u201d is a phenomenon that occurs when radio frequency (RF) transmit power accelerates electrons in a vacuum, causing a corona discharge and possible RF system failure.) During this test, an accurate indication of the power output of the test equipment was not provided to the test monitoring software. This caused the test monitoring software to command the test equipment to increase the transmitter output to a potentially harmful level. Analysis showed that the GSE power meter stopped taking measurements, possibly due to an AC power anomaly. The test monitoring software then interpreted the zero reading from the power meter as a loss of power, and responded by increasing the drive level of the X-Band Synthesizer to a level sufficient to drive the Traveling Wave Tube Amplifier (TWTA) to maximum output power. To prevent a recurrence, an attenuator or limiter was inserted to maintain the RF output below a specified level, preventing the TWTA from providing more power than the maximum rating of the test article should the power measurements fail. References: (1) Jet Propulsion Laboratory Problem\/Failure Report No. Z82462, November 12, 2003. (2) LLIS #0573, \u201cPower Bus\/GSE Sneak Paths May Energize Spacecraft in the Ground Test Environment\" (3) LLIS #0583, \u201cTest Contingency Planning Should Consider Facility Power Interruptions,\u201d February 19, 1998. Additional Key Words: facility power, test failure, test-induced failure, power limits, test software, fault protection, RF breakdown, RF test, test overstress, High Power RF Breakdown Facility","Lesson ID":1529}
{"Driving Event":"GIFTS did not have an instrument co-registration requirement, except that the co-registration be measurable and be determined from the ground data. The GIFTS test plans did not include solar simulations in a chamber to establish the co-registration characteristics prior to flight.","Lesson ID":1530}
{"Driving Event":"The main chute bag is retained inside the rocket by the main parachute retention line and the main chute's electronically controlled release device. The drogue chute pulls on the main chute pack when the drogue chute is deployed. The excessive length of the main chute retention line causes the main chute to be pulled out of the rocket airframe when the drogue chute is deployed at apogee during the first rocket launch. During the second rocket launch, the main chute retention line was shortened in an attempt to solve this problem. However, it still contained enough slack to cause the main chute bag to exit the rocket airframe and become entangled with the retention line, preventing deployment of the main chute.","Lesson ID":1534}
{"Driving Event":"The Tropospheric Emission Spectrometer (TES) is an Earth observing instrument with focal plane arrays that are mechanically cooled to 63 degrees K. to reduce the instrument thermal background. During ambient performance testing of the instrument (Reference (1)), several major assemblies violated the upper-limit Allowable Flight Temperature (AFT) and Protoflight (PF) operational temperatures specified by the Environmental Requirements Document (ERD). The ERD (Reference (2)) is the JPL document that specifies the environments the mission will encounter; it serves as the basis for the environmental design and test of JPL subsystems and systems, including the specification of test levels and durations. [D] It was determined that the ground test had been performed at an appropriate temperature. The hot operating temperature limit imposed by the ERD was found to pertain solely to the extreme low temperature science data collection periods. The ERD did not specify environmental limits for ambient, \u201cnon-science\u201d operating conditions such as the ground environment that was the subject of the test. An ERD typically specifies allowable ground conditions as well as characterizing the spaceflight environment. References: JPL Problem\/Failure Report No. Z77843, October 8, 2002. JPL Environmental Assurance Standard (D-14040), Rev. 3, JPL DocID 35491, November 23, 2004. Additional Key Words: Thermal Model; Test Error; Mission Environments; Environmental Assurance Plan; Environment Definitions; Environmental Design Requirements; Environmental Analysis; Environmental Test; Environmental Verification; Environmental Compliance; Environmental Requirements Engineer (ERE); Maximum Expected Flight Level (MEFL); Environmental Margins","Lesson ID":1532}
{"Driving Event":"While testing the original dynamic inverse controller with locked stabilator failure simulations, significant lateral acceleration (ny) and angle of sideslip (Beta) excursions as a result of lateral stick inputs were noted. One inch of roll stick input would cause lateral accelerations of -0.5g and Beta values as high as 5 degrees. Because subsequent re-designs of the neural network were not able to modify this behavior and pilot comments from simulation sessions continued to be negative, it was decided that the research controller be modified so that the lateral and directional axis would be de-coupled in the research controller. This was accomplished by using a Beta-dot classical controller for the yaw axis, while continuing to use the original dynamic inverse control for the pitch and roll axes.","Lesson ID":1525}
{"Driving Event":"In-flight commanding errors-- even when detected early-- may trigger events that cannot be halted before a mission is irreversibly compromised. A history of commanding anomalies experienced by the Mars Global Surveyor (10 command errors within 1009 command files radiated), Stardust (4 within 665), Mars Odyssey (22 within 2379), and Genesis (5 within 975) missions prompted JPL to perform a comprehensive review of the command uplink process. Although no anomalies proved critical to the success of these missions, the review found three distinct types of errors: Directly related to real-time, on-console, processing of a command file for radiation via the Deep Space Network (Reference (1)). Traceable to an uplink process that wasn't followed correctly, or an error that should have been detected by the process (Reference (2)). Where the uplink process was adhered to, but the command produced unexpected spacecraft or instrument behavior (Reference (3)). The proximate causes of these command errors may be attributed to: Each newly assembled flight team's initial inexperience with the flight system. Inadequate review of command products to assure that all checks were performed. An incomplete command uplink process (e.g., missing procedural steps). The root causes of in-flight commanding errors include the erosion of Flight Team technical expertise upon the transition from completed projects to new missions, limitations in testbed capability and fidelity, and the tendency to short-cut established processes under schedule pressure. Following this 2002 review, a number of command uplink process improvements were implemented by the flight projects to prevent commanding errors. This resulted in a decrease in the rate of command errors on JPL missions. References: JPL Incident Surprise Anomaly (ISA) Nos. Z71855 (07\/09\/01), Z72385 (10\/15\/01), Z71679 (05\/31\/01), Z71804 (06\/20\/01), Z72699 (11\/08\/01). JPL ISA Nos. Z71476 (04\/26\/01), Z71900 (07\/20\/01), Z72363 (10\/08\/01), Z72421 (10\/19\/01), Z71269 (03\/27\/01), Z72235 (09\/13\/01), Z71810 (06\/20\/01), Z72053 (08\/16\/01), Z72354 (10\/05\/01), Z72525 (10\/28\/01), Z73216 (12\/21\/01), Z73247 (12\/29\/01), Z72062 (08\/16\/01). JPL ISA Nos. Z70999 (02\/16\/01), Z71572 (03\/23\/01), Z71817 (06\/26\/01), Z72046 (08\/06\/01), Z71947 (07\/31\/01), Z72166 (08\/29\/01), Z71323 (04\/09\/01), Z71529 (05\/08\/01), Z72587 (10\/15\/01), Z73207 (12\/21\/01), Z71543 (05\/10\/01), Z71547 (05\/10\/01), Z71690 (05\/30\/01), Z71750 (06\/12\/01), Z71934 (07\/26\/01), Z71981 (08\/08\/01), Z72043 (08\/13\/01), Z72063 (08\/16\/01), Z72194 (08\/31\/01), Z72455 (10\/25\/01), Z72072 (08\/20\/01), Z72073 (08\/17\/01), Z73021 (12\/06\/01). Grant Faris, \u201cMMO Command Anomaly Working Group Status Report (Draft),\u201d February 15, 2002. \u201cOperation of Uplink Process,\u201d Rev. 2, JPL Doc ID 27232, July 19, 2002. \u201cDuplicate Transmission of Operational Command,\u201d JPL Lessons Learned No. 7-122, January 26, 2004. \u201cTake CM Measures to Control the Renaming and Reuse of Old Command Files,\u201d JPL Lessons Learned No. 1481, July 13, 2004. \u201cEarly Involvement of Mission Ops is a Key Success Factor,\u201d JPL Lessons Learned No. 1415, November 1, 2004. Additional Key Words: mission operations, operations procedures, erroneous commanding, operations training, operations assurance, flight team anomalies, command failures","Lesson ID":1521}
{"Driving Event":"The Rocket Based Combined Cycle (RBCC) Project consisted of a consortium of prime contractors. Responsibilities were distributed throughout the consortium, but suppliers would only discuss issues with key decision makers, leaving the expediters and coordinators out of the information loop. In a multi-contractor consortium, the team eventually developed a set of core values: trust, teamwork, and critical knowledge; unfortunately, this came late in the program. A system that encourages team behaviors and discourages divisive behaviors should have been developed and matured earlier.","Lesson ID":1513}
{"Driving Event":"During welding operations at the E-Complex in support of the Full-Volume RP Construction Project at Stennis Space Center, a fire occurred as a result of welding\/cutting operations being performed on Level 5 of the E-1 Test Stand. The Mishap Investigation Team concluded that the proximate cause of this Type C incident was hot welding slag igniting combustible material under and near the vicinity of the welding\/cutting operation. Contractor failure to follow procedures associated with hot work permits due to schedule pressure contributed to the incident, as well as lack of training and overburdened supervisory personnel.","Lesson ID":1517}
{"Driving Event":"The QMI furnace required custom-designed Type C Thermocouples (TC) to meet the scientific requirements for the hardware. In implementing the custom requirement set and associated verification testing for these TCs notable anomalies\/problems were encountered in two areas. The primary problem was the discovery of contamination (mostly Carbon deposits) on the inner surfaces of the TC that led to acceptance test failures. This problem occurred during the calibration phase of the TC acceptance testing and specifically when the TC was brought up to operating temperature (900degC for this application) and temperature held for stabilization and data gathering. The start of the deposits most probably began at a lower temperature (~400degC) and began to build up so that isolation resistance failed test specifications. Investigation led to the conclusion that the Alcohol-based cleaners used on each of the piece parts (sheath, insulator, wire) making up the TC was to blame. The Alcohol-based cleaners left deposits on some materials and were absorbed into the insulators. When the assembled TC was brought up to temperature during calibration testing the Alcohol-based substance was baked out and a Carbon residual remained which was conductive. A secondary problem was caused by attempting to maximize the TC wire size yet limiting the overall TC sheath diameter leading to assembly problems of each TC. The assembly of each of the TC units took an unusually long time due to the limited clearances of the parts to be assembled including: thickness of wire, diameter of insulator, length of TC, required thickness of insulator and over all diameter of TC sheath.","Lesson ID":1512}
{"Driving Event":"The Teflon thermal control surfaces plus the high elliptical orbit resulted in severe spacecraft charging and electrostatic discharge environment, which necessitated an aggressive Electrostatic Discharge (ESD) test and circuit protection effort at a cost of over one million dollars.","Lesson ID":1514}
{"Driving Event":"The Mars Exploration Rover (MER) Flight Control Team (FCT) was fully formed only one month prior to the June 2003 launch of the first rover and did not participate in the development of the Mission Operations System (MOS) and the Ground Data System (GDS). Had the team been involved at the beginning of Phase C (Design and Build phase), critical software engineering and operations management problems, that were accepted as known risks, might have been avoided: Late Formation of the Ops Team. The FCT was not trained and certified in time for launch operations, and it had insufficient time to become familiar with the spacecraft and project procedures. The FCT was staffed too late to provide input or effect change to critical processes and project developed tools. For example, when MER held its first Operations Readiness Test (ORT), the FCT was funded at a one-half person level, and that person was too busy writing team procedures to participate in the ORT. Also, additional personnel who joined the ops team just prior to the launch date lacked user accounts on the workstations used for spacecraft command and control. Command File Format. During development of the MER command files, the test engineers changed the naming convention to a longer 20 to 50-character format. Because the length of the file names exceeds the width of the FCT displays, the controllers have to call out each character of the file name over the voice net prior to transmission to the spacecraft. This increases the risk that the FCT may send erroneous commands to the spacecraft. The FCT was not involved in the decision to change the naming convention, and a return to the preferred shorter format would require MER to rebuild and revalidate the command files. Additional Key Words: Deep Space Telemetry, Tracking and Command System (TTC)","Lesson ID":1518}
{"Driving Event":"An Operations Storage Server (OSS) capable of supporting both Mars Exploration Rover missions (MER-A and MER-B) was implemented, but only after early server hardware failures that necessitated major re-planning. In 2002, during Phase C (Design & Build) of the MER project, plans were proposed to acquire a high performance, centralized, project server to rapidly process the high volumes of science data expected of the Ground Data System (GDS) during operations on the Martian surface. The Mission Operations System (MOS) funding in Phase D (integration & test), however, was inadequate to support full implementation of the recommended OSS system. The less expensive OSS that was deployed experienced repeated failures during pre-launch test, post-launch test, and launch\/cruise operations. This included major server hardware failures lasting for days that occurred only weeks prior to MER-A launch in June 2003, and several weeks prior to Entry, Descent, and Landing (EDL) activities in January 2004. Contributing issues included: Late procurement of a server system comprised of low-end, poorly integrated hardware incapable of meeting mission requirements for speed and reliability. OSS design engineering involvement in the OSS was significantly reduced (from ~1.5 FTE to 0.25 FTE) prior to final OSS implementation. Very limited testing prior to operational use because the original OSS was not installed until late in system integration and test (ATLO). Major changes to the system architecture from a single isolated server assigned to each MER mission, to three servers networked between two buildings, multiple floors and four subnets, plus backup servers. Reliability concerns prompted the MER project to scrap this OSS design late in 2003, and procure a turnkey system that was installed by the vendor just prior to EDL. The project was then able to use components of the original system to provide a backup server capability. This cluster system has successfully supported both rover missions without a major failure. Additional Key Words: Data Acquisition System, Distributed Computing Environment, Ground & Mission Operations, Multimission Data Services, Mission Data System, science data processing, server architecture","Lesson ID":1519}
{"Driving Event":"In a scenario that is most likely to occur on severely time-constrained flight projects, testing is interrupted and test time is lost because of unreported changes to the testbed configuration. During subsystem integration and test (I&T) of Mars Exploration Rover (MER), for example, a software test operator spent two hours at a keyboard preparing for a special MER flight software (FSW) test case. When the test began, the system crashed, and extensive troubleshooting disclosed that the test operator had been unaware that the previous shift had removed the Rover camera from the testbed. Other similar incidents might stem from a loose cable caused by an equipment swap. This problem is exacerbated for projects like MER where system development continues even while testing is underway in dual work shifts. JPL flight system I&T programs typically implement the following steps to minimize lost test time: A meeting is held at the beginning of each I&T shift to brief the incoming team on changes to the testbed configuration. A startup procedure, maintained for each testbed, is continually updated to reflect the current testbed configuration. An on-line reporting tool is used to capture the activities of each test shift, document hand-over instructions to the next shift, report changes to the testbed configuration, and provide links to problem\/failure reports generated during the shift. A spreadsheet reports the status of connectors and cables that have been mated or demated. A walkthrough of the testbed configuration prior to each work shift would likely have prevented the MER test errors. They were not feasible for MER, though, because there were several hundred connectors in each testbed, and not all of them were visible to the operator. References: System Test and Launch Operations (STLO) Guide Executive Summary, Rev. 2, JPL Doc ID 31335, September 18, 2000, Para. II E. Subsystem Integration and Test for PPS, C&DH, and GN&C Subsystems, Rev. 0, JPL Doc ID 65633, December 12, 2003, Paras. 5.11, 6.8. Additional Key Words: subsystem test, test configuration, test bed, test procedure, test plan, ATLO, assemble, test, and launch operations","Lesson ID":1520}
{"Driving Event":"Significant flaws existed in OSP's implementation approach resulting in a misunderstanding of the S&MA organizational authority","Lesson ID":1511}
{"Driving Event":"Changes in risk systems, a shortage of risk experts, and ineffective application of risk management systems.","Lesson ID":1500}
{"Driving Event":"(1) a lack of a disciplined, well communicated, Level 1 requirements development process, (2) open or architecture-free Level 2 requirements, and (3) contractor-developed Level 3 requirements (system specification)","Lesson ID":1501}
{"Driving Event":"Recognize that as a combined set, human rating requirements present program risk, because they have never been fielded into a System design.","Lesson ID":1502}
{"Driving Event":"For the Apollo Block I\/II development, the contractor was provided a NASA report containing statistics for inflight winds over Cape Canaveral without the required specific design wind values being specified for use. The result was an extensive re-do of the analyses and design work to meet the vehicle mission requirements. The ISS contractor utilized an in-house Orbital Density Model for on-orbit analyses which differed from the NASA model specified for use. This resulted in different calculations for ISS response analyses by the various groups involved. Both of these issues were resolved by recognition and establishment of a single Control Point with responsibility for focus on natural environment definitions and control of requirements for the Space Shuttle and ISS. In addition, this provided a common source for interpretation of the natural environment requirements for the design of these vehicles.","Lesson ID":1494}
{"Driving Event":"The Deep Space 1 (DS1) mission successfully demonstrated the use of an ion engine as a primary spaceflight propulsion system. A few minutes after startup in November 1998, DS1&apos;s xenon ion engine shut down unexpectedly. The problem was believed to be a \"grid short,\" a common problem in ion propulsion. Repeated attempts to restart the engine that same day were unsuccessful.Solar electric propulsion (SEP) imparts a small thrust by passing ions through two closely spaced, charged grids (Figure 1). Should a loose conductive flake bridge the gap between the positive and negative charged grids, it could short the grids leading to automatic shutdown of the engine. Molybdenum flakes commonly peel off the grids late in the ion engine&apos;s life. Given the early occurrence of the DS1 anomaly, however, it is possible that a conductive contaminant was introduced during assembly or launch operations.*************************** Insert Image here with text Descriptor [D] ************************************ Insert tile underneath: DS1 Xenon Ion Engine ******************************Ion propulsion systems in commercial satellites incorporate a \"grid clear circuit,\" like a patio bug zapper, that is believed to be capable of clearing grid shorts by producing a brief high current that eliminates the conductive source. DS1 was designed with a relatively low power version of this circuit. After the anomaly, DS1 operators executed preplanned low risk contingency evaluation procedures. It was decided not to take the risk associated with the immediate use of the \"grid clear circuit.\"Approximately two weeks after the engine shutdown anomaly, an engine start planned for evaluation purposes resulted in successful engine operation. Activities during this two-week period are believed to have induced thermal cycling of the grids which removed the short. Since this early anomaly, engine operation has been normal.Additional Keyword(s): debris, contamination, fault protection, New Millennium, short circuit, NSTAR, Mission Operations","Lesson ID":1687}
{"Driving Event":"With the advent of on-orbit reprogrammable remote sensing instruments, the need for high fidelity hardware capable of executing an identical copy of flight software or firmware for Field Programmable Gate Arrays (FPGA)- based designs to verify and validate flight software changes prior to implementation on orbit has become a necessity. An engineering model or spread system (engineering hardware spread-out on a table) created to support the development for the Halogen Occultation Experiment (HALOE) proved to be an extremely useful tool used to support flight software changes made early in the mission (Upper Atmospheric Research Satellite, 1991). Subsequent flight projects such as the Stratospheric Aerosol and Gas Experiment (SAGE III) project addressed this requirement directly by adding a statement of work requirement for a deliverable high-fidelity engineering model as part of the program specifically to support on-orbit flight software maintenance and ground-based anomaly troubleshooting. The SAGE III high-fidelity engineering model was developed by Ball Aerospace and Technologies Corporation, the SAGE III instrument prime contractor. The prototype was constructed using flight-design electronics using commercial parts, engineering model mechanisms, and executed identical flight software to the flight instrument. The system was integrated using lower fidelity mechanical parts and left over flight hardware from the SAGE II program.","Lesson ID":1489}
{"Driving Event":"The SAGE III Project was unique in that it incorporated groups from NASA Langley, Ball Aerospace, Russian Space Agency, NIIEM (Russia), K. B. Yuzhnoye (Ukraine), and ILS (Kazakhstan). Most projects that are strictly domestic in nature have no problems with gaining an agreement and understanding of test facilities and contamination control. SAGE III basically had to re-invent this understanding with our foreign partners. Our Russian partners had worked the Total Ozone Mapping Spectrometer (TOMS) Project and had an understanding of particle contamination, but did not understand molecular contamination (NVR). Many Technical Interchange Meetings (TIMs) were required to gain a mutual understanding of the contamination control requirements that had been established by the US side. Ball Aerospace initially created a contamination control plan for the project, but NASA-Langley had to roll this into a Contamination Control Procedure and a Cleaning Specification for the Russian side. Ball was a participant in negotiations with our foreign partners, but only NASA could represent the government in our contract with our foreign partners. This was accomplished through TIM's and a Contamination Control workshop held in Florida for our foreign (Russian, Ukrainian and Kazakhstan) partners. This was not just a technical job, but required walking a very sensitive cultural\/political tightrope so as not to offend anyone. The workshop also served to provide the US side an opportunity to inspect the launch facilities at the Baikonur Cosmodrome and the rocket manufacturing plant K. B. Yuzhnoye, which had been denied previously. Test facilities at NIIEM Electromechanics Research Institute (Russia) and the Baikonur Cosmodrome (Kazakhstan) were initially inspected and found not to meet the US requirements. Assembly and Test facilities at K. B. Yuzhnoye (Ukraine) were inspected and found to be good, but did not meet the US requirements. Working closely with all of our partners, the US side provided contamination control equipment (clean tents, garments, gloves, cleaning supplies, etc.) and recommendations for facility upgrades. The Russian, Ukrainian and Kazakhstan partners formed contamination control groups and many upgrades were performed. Test and Assembly Facilities at NIIEM (Russia), K. B. Yuzhnoye (Ukraine) and Baikonur (Kazakhstan) were improved under the direction and guidance of the NASA Langley I & T Team. The response from our foreign partners in making changes to their facilities, initially reluctant, improved as they learned more about contamination control and the effects on spacecraft hardware. The end results of both the US and foreign partners joint efforts were that the facilities were improved, the foreign partners gained a good understanding of contamination control and requirements for this project were met.","Lesson ID":1490}
{"Driving Event":"Initial testing produced destructive events on each of the two boards tested. Both boards had non-functional DSP chips, even though they had not been directly exposed to the beam. It is believed that stray protons in the test room caused the DSP chips to fail. Follow-up testing was performed on two additional boards. The first board had a DSP chip failure caused by stray protons (1\/1,000 to 1\/10,000 the rate of full beam exposure and energy on the order of 100 MeV) during beam tuning. The board was replaced by the spare board and one of the DSP chips exposed to the beam. The chip failed after 0.31% of the total intended fluence of 1 E 10 p+\/cm2, with an over-current condition detected on the 3.3V supply line. This equates to a 5.5 day MTBF for one chip or 1.5 day MTBF for the whole board in the US Lab radiation environment The COTS board manufacturer was asked to modify the Digital Signal Processor (DSP) based Data Acquisition board to provide over-current protection. Four of the prototype Digital Signal Processor (DSP) based Data Acquisition boards were tested as before. Preliminary results of these tests indicate that typically one to three recoverable current trips occur before the DSP chip fails. In 7X7 convolution mode, which has the highest current draw, the MTBF for destructive events was calculated to be 35.6 days per chip or 8.9 days per board. FCF designer's research has not found a DSP based technology chip that will meet the needed performance criteria that is not ionizing radiation susceptible. The FCF project is looking into other alternatives to the Digital Signal Processor (DSP) based Data Acquisition boards, such as FPGA based technology.","Lesson ID":1488}
{"Driving Event":"Shortly after the commencement of science activities on Mars, the \u201cSpirit\u201d rover lost the ability to execute any task that requested memory from the flight computer. The rover operated in a degraded mode until 15 days later, when normal operations were restored and science activities resumed. The root cause of the failure was traced to incorrect configuration parameters in two operating system software modules that control the storage of files in system memory (heap) and flash memory. A parameter in the dosFsLib module permitted the unlimited consumption of system memory as the flash memory space was exhausted. A parameter in the memPartLib module was incorrectly set to suspend the execution of any task employing memory when no additional memory was available. Task suspension forces a reset of the flight computer, and it is never supposed to occur. The initial reset event was triggered by the creation of a large number of files associated with MER instrument calibration that overburdened flash memory, and then system memory. The reset did not clear flash memory because flash memory is non-volatile by design. Although the reset did delete the files in system memory, the total size of the file system structure is determined not by the number of current files but rather by the maximum number of files that has ever existed. Since neither memory was cleared by the initial reset, a cycle of repetitive computer resets and flight software re-initializations ensued. The effects of overburdened flash and system memory were not recognized nor tested during system level ground testing. Mission Operations recovered the mission by manually reallocating system memory, deleting unnecessary directories and files, and commanding the rover to create a new file system. Because revision of flight software was considered too risky, operational changes were implemented for both MER vehicles to improve oversight of rover file management. References JPL Incident Surprise Anomaly Report (ISA) No. Z83174, January 29, 2004. Glenn Reeves, Tracy Neilson & Todd Litwin, \u201cMars Exploration Rover Spirit Vehicle Anomaly Report,\u201d Jet Propulsion Laboratory Document No. D-22919, May 12, 2004. Mars Exploration Rover Project Library, Collections 13788 and 13664. Additional Key Words: flight software architecture, flight software design, flight software requirements, file system corruption, shutdown failure, autonomous shutdown, system memory space, repetitive resets, avionics, system reboot","Lesson ID":1483}
{"Driving Event":"At the end of Mars Exploration Rover (MER) Phase A development in July 2000, the cost of a single rover was estimated at $445.5 million, including 20 percent budget reserves. The following month, JPL committed to a two-rover mission with an estimated cost of $243 million for the second rover. In addition to potentially doubling science return from Mars and mitigating the program impact were a rover to fail, this \u201ctwo-fer\u201d approach proved helpful in controlling development risks. Having two rovers under development provided enhanced flexibility to the Integration & Test process (referred to as \u201cATLO\u201d at JPL). ATLO (Assembly, Test, and Launch Operations) began in late February 2002 for MER-1, and in early May 2002 for the second rover. Experience with MER-1 permitted an abbreviated ATLO for MER-2 and the availability of the additional MER-2 hardware in ATLO helped to isolate problems experienced by MER-1. The MER-2 funding also covered procurement of extra spare assemblies. Schedule risk was mitigated by this \u201chardware-rich\u201d ATLO test environment, and was also alleviated by parallel development using four main testbeds run by separate teams. [D] The complex rovers were developed under major schedule risk. The MER schedule provided for only 34 months from program approval in July 2000 to the opening of the launch window in May 2003. The Aerospace Corporation (Reference (1)) rated MER as having a complexity comparable to traditional NASA missions such as Cassini and Galileo. The shortest of these traditional, large scale projects took 80 months to develop. The development of dual rovers helped improve the system-level test program and helped to mitigate the risk associated with the compressed MER development schedule. References M.A. Dornheim, \u201cCan $$$ Buy Time: Complex Rovers Were Developed in a Dangerously Short Period,\u201d Aviation Week & Space Technology, May 26, 2003, p.56. Additional Key Words: integration and test, flight spares, schedule margin, schedule constraints, system testbed, test bed","Lesson ID":1485}
{"Driving Event":"The NESC performed independent tests and analyses to assess and resolve the flowliner cracking problem. Reliable and credible data must be collected from the Program in order to perform the assessment. In several cases the NESC found it difficult to collect those data in a reliable and credible format.","Lesson ID":1486}
{"Driving Event":"Early in the Mars Exploration Rover (MER) design phase, and in all modeling for operations and mission science return, planners assumed that each rover would be inoperable every third day, on average, due to problems. MER\u00bbs daily command cycle and 90-day prime mission lifetime requirement were factors in deciding to make this assumption. The benefit of making allowances for these hypothetical \u201cdown days\u201d was that it provided: Enough margin in the planned mission return to accommodate losses such as the roughly two-week data loss due to the Spirit flash memory problem, and A benchmark against which to compare actual lost days of operation. This helped JPL to determine whether it was on track to meet mission and science return criteria and contributed to meeting full mission success. This mission design assumption enabled a cautious approach during surface operations when responding to detection of anomalies and when planning the execution of high-risk maneuvers by the MER operations team. Spirit, the first of the two MER rovers, was delayed in its \u201cdrive-off\u201d of the lander when airbags hampered the preferred egress path (Figure 1). Later, Spirit experienced a problem with its flash memory for ~2 weeks. The operations team for the second rover, Opportunity, spent several days determining the safety of entering the crater Endurance. During these and other surface mission events, operations personnel were not under undue pressure to return to science operations, but instead took sufficient time to gain confidence in their understanding of the situation before taking action. [D] Additional Key Words: operational margin, operations margin, mission planning, operations design","Lesson ID":1484}
{"Driving Event":"In May of 2002, three cracks were found in the downstream flowliner at the gimbal joint in the LH2 feedline at the interface with the Low Pressure Fuel Turbopump (LPFP) of Space Shuttle Main Engine (SSME) #1 of orbiter OV-104. Subsequent inspections of the feedline flowliners in the other orbiters revealed the existence of 8 additional cracks. No cracks were found in the LO2 feedline flowliners. A solution to the cracking problem was developed and implemented on all orbiters. The solution included weld repair of all detectable cracks and the polishing of all slot edges to remove manufacturing discrepancies that could initiate new cracks. Using the results of a fracture mechanics analysis with a scatter factor of 4 on the predicted fatigue life, the orbiters were cleared for return to flight with a one-flight rationale requiring inspections after each flight. OV-104 flew mission STS-112 and OV-105 flew mission STS-113. The post-flight inspections did not find any cracks in the repaired flowliners. Even though the flowliner repair solution appeared to be successful, the NASA and contractor engineering team continued to investigate the problem. This continuing investigation was motivated by the fact that the actual cause of the original cracks had not been conclusively established. As part of the continuing investigation, two engine hot fire test series were conducted at Stennis Space Center to characterize the LH2 feedline flow physics and to measure the flowliner vibratory response. The test results were somewhat alarming because the vibratory strains recorded by strain gages mounted directly to the upstream and downstream flowliners were considerably higher than anticipated. The strain gage data were used conservatively to develop a loading spectrum to represent the \u00bfworst-case\u00bf nominal flight. An updated damage tolerance analysis of the flowliner was then conducted by the Boeing Company based on the inspection crack detection limit of 0.075 inches adopted in 2002. The predicted values of residual fatigue life were only 0.8 missions for a circumferential crack in the upstream flowliner and 1.4 flights for the downstream flowliner. These new results cast doubt on the validity of the flight rationale developed in 2002. Subsequently, the Orbiter Program Office sponsored an extensive effort to resolve this problem.","Lesson ID":1487}
{"Driving Event":"Both the Mars Exploration Rover (MER) flight system and mission designs had the flexibility to react to unexpected events. The MER flight system provided an in-flight capability to revise Entry, Descent and Landing (EDL) parameters by coding them in flight software. The MER mission design provided an operational plan, process, and tools permitting JPL to perform EDL parameter updates over a span of several days during final approach to Mars and up to six hours before landing. [D] The ability to update EDL parameters was critical to the success of the MER mission. Updated data on Martian atmospheric pressure received from the Thermal Emission Spectrometer (TES) instrument on the Mars Global Surveyor (MGS) spacecraft during final approach (see figure) indicated a lesser atmospheric density than expected. Left uncorrected, the actual lesser atmospheric density could have caused MER to sense its dynamic pressure target at a lower altitude than planned, and to trigger its parachute deployment too near the ground. Because the flight team had the processes for changing EDL parameters, and the ability to modify these parameters after launch, the timing of the MER parachute release was successfully accomplished. References: \u201cMars Exploration Rover (MER) Flight Operations Report,\u201d NASA Engineering and Safety Center Report No. RP-04-04\/03-004-I 2003 Mars Exploration Rover Final Navigation Peer Review, February 3, 2003 Additional Key Words: Mars lander, Mars probe, mission failure, signal loss, flight constraints, communications lag, continuous telemetry","Lesson ID":1480}
{"Driving Event":"Reentry of spacecraft into earth's atmosphere at end of life.","Lesson ID":1479}
{"Driving Event":"The roles of the Aerospace Safety Advisory Panel (ASAP) and the National Transportation and Safety Board (NTSB) are not clearly established in NASA accident investigations. Both organizations were called upon to play a limited advisory\/data source role in the Columbia accident investigation.","Lesson ID":1441}
{"Driving Event":"Disassembly inspection of the Space Shuttle Orbiter OV-103 Rudder\/Speed Brake (R\/SB) actuators revealed corrosion, pitting, and wear to varying degrees, along with degradation of the lubricant, Braycote 601. A program decision was made to replace the actuators in OV-103 with the existing spares, a single ship set which had been in controlled storage for the past 17 years. An assessment was performed to address the following two issues, which had been raised within the Program Control Review Board process: Issue 1. Grease separation into its component oil and thickener is known to occur in storage. Its effect on lubricity is not known. Issue 2. Chemical reactions involving the grease and the gear\/housing material, 9310 steel, could lead to formation of Lewis acids, resulting in corrosion, pitting, and cracking. Issue 1 was addressed directly by performing lubricity testing using aged and separated grease obtained from several sources, including grease that had been removed from the OV-103 actuators. Issue 2 was addressed by measuring the thermodynamic characteristics of the corrosion process - the rate constants and activation energy - for the particular material\/lubricant combination. Both issues were shown not relevant with respect to flight safety, and the spare R\/SB actuators that had been installed on OV-103 were declared to be flight worthy. However, the existence of hardware which had exceeded its service life, within the spares inventory, as well as the actuators that had just been replaced in OV-103, raised a concern with respect to maintenance and refurbishment practices within the aging Space Shuttle fleet. This concern is the subject of an ongoing study, and the Lesson Learned is documented herein.","Lesson ID":1478}
{"Driving Event":"Several service outages occurred early in the implementation. The first case involved expiration of a software license associated with the Neoterris box (February 14 - 48 hours). The second involved failure of a mother-board on the Dell application server (March 5 - 2 hours). Unknown cause (March 13 - 3 hours). GRC firewall outage (March 18 - 1.5 hours). Inadvertent cable disconnect (April 2 - 15 minutes). A separate hardware issue involved large-file load time from certain web-browser applications. Considering all of the above, from February 13 to May 13, 2003 the system total downtime was approximately 90 hours - this includes 24 hours for scheduled maintenance and upgrades and a \u201cdown time penalty\u201d to account for less than optimum performance. This represents an operational availability of approximately 96%.","Lesson ID":1465}
{"Driving Event":"To make information readily available to investigators and members, the Columbia Accident Investigation Board (CAIB) used existing JSC computers, networks, and communications infrastructure resident in Regents Park III. However, to remain independent, the CAIB concluded that all CAIB generated work product and data be housed on a server, connected to the JSC network, but exclusively managed and administered by CAIB IT support staff. Consequently, an independent CAIB Database Server was deployed approximately six weeks into the investigation and authorized users were granted access to independently store, view, and share files.","Lesson ID":1469}
{"Driving Event":"During the re-installation of a piece of hardware at the 8-Foot High Temperature Tunnel (8'HTT), several grade 8 high-strength cadmium-plated hex head bolts failed as technicians were tightening the bolts with a torque wrench. The failed bolts used for the re-installation of the hardware had been through numerous thermal cycles during testing at the 8'HTT. Analysis of the failed bolts indicated that the bolts met all metallurgical specifications. Failure patterns suggested a fatigue fracture where the head of the bolt meets the body.","Lesson ID":1426}
{"Driving Event":"An electrically-initiated fiber optic cable cutter in the lower pod of an aircraft unintentionally functioned during a 60-day armament functional check. Fortunately, this event caused no personnel injuries or equipment damage. What we learn from a close call like this can prevent a serious accident in the future.","Lesson ID":1427}
{"Driving Event":"For example, a relief valve line violently deformed during operation as a result of improper design and installation. Had personnel been close to the vent line when this event occurred, serious injury could have resulted. Other examples include tubing that separated from a fitting while under pressure, because it was improperly swaged and failure of a pressurized fitting due to improper assembly.","Lesson ID":1430}
{"Driving Event":"The mishap occurred when a tank located in a section of pipe used to drain water from a 4,300 psi air compressor ruptured. The tank is isolated from the high-pressure air by a manual drain valve. A pipe that exits the bottom of the tank is directly open to the atmosphere. For the past 40 years, operators have been opening the drain valve to drain oil and moisture collectors without incident. On the day of the mishap, an operator drained the system as usual, but when the valve was closed, a very small amount of debris in the valve seat allowed high-pressure air to leak into the low-pressure drain collector tank.","Lesson ID":1428}
{"Driving Event":"First, it is very important to have a containment screen, which will keep all the debris within the cooling tower. Consequently, debris did not become projectiles that could cause personal injury. A second important feature is an operational vibration switch. The mishap investigation determined that the vibration switch was not working properly. Also, a review of several other cooling towers discovered inoperable vibration switches and switches that have been moved from periodic maintenance to the run-to-failure maintenance list.","Lesson ID":1429}
{"Driving Event":"A mishap occurred at the 8'HTT when a team of construction contractor personnel was preparing to perform a pneumatic flushing of debris from high pressure air lines by use of a low pressure, high velocity air. The blank flange was removed from air lines perceived to have been un-pressurized. Removal of the flange, under pressure, resulted in serious injury to two of the personnel involved in the operation.","Lesson ID":1432}
{"Driving Event":"CPV-type unions are comprised of two flat-faced fittings with an O-ring seal that are joined together with a union nut. They are used to provide a separable connection in pipe and tube systems and are available in pipe sizes up to two and a half inches. CPV-type unions are used extensively in piping systems. Reported problems have included blown O-rings, stripped threads, excessive torque requirements, and cracked nuts. As a result of these problems, some unions have experienced failures including loose fits, leaks, and separation. The Pressure Systems Committee has investigated the cause of these failures and concluded that problems with this type of union stem from their sensitivity to piping misalignment and to bending loads applied to the joint.","Lesson ID":1431}
{"Driving Event":"The vendor selected to produce the aluminum parts in question was audited as part of the \"Supplier Audit Pre-Selection Process\", and was found to have an adequate Quality Management System. Their selection of sub-contractor to perform post-processing plating operations was not part of the pre-selection process, therefore no knowledge of this specific sub-contractors capability was realized.","Lesson ID":1423}
{"Driving Event":"Three years after the launch of Cassini, a higher-than-normal drag was detected on one of the reaction wheels employed in rotating the spacecraft. The excessive friction at one reaction wheel likely resulted from a reduction in lubrication after prolonged operation at a slow speed approaching zero rpm (Reference (1)). Excessive drag torque resulting from the frequent speed oscillations around zero rpm may also have contributed to the anomaly (Reference (2)). The problem caused a 9-day suspension of scientific observations and an extra workload to prevent recurrence of the conditions. Operating the wheel at higher speeds apparently restored the proper dispersal of the lubricant and eliminated the drag. The Cassini flight team also established procedures for avoiding prolonged operation of the reaction wheels at relatively slow speeds. Bearing and lubrication systems are the primary determiners of reaction wheel assembly (RWA) life. It is difficult to analytically predict the failure of bearings in space mechanisms from lubricant starvation, and life testing provides the only accurate predictions. However, accelerated life testing does not accurately model the effects of bearing speed and temperature on bearing life. Hence, reliability predictions are commonly based on past flight experience with similar RWAs. References: JPL Incident Surprise Anomaly (ISA) No. Z70706, January 4, 2001. JPL Incident Surprise Anomaly (ISA) No. Z70716, January 8, 2001. A. Lee, B. Shogrin, J. South, \u201cCassini RWA Operations Analysis and Recommendations,\u201d JPL Presentation, March 1, 2001. Additional Key Words: bearing failure, lubricant failure, momentum wheels, SBA, excessive torque, torque instability, lubricant loss, tribology, low-RPM dwell, prolonged drag torque, COBE RWA","Lesson ID":1416}
{"Driving Event":"The GSFC\/LaRC Integrated Program Management Council co-chair, William Townsend (Deputy Center Director at GSFC) requested the NASA Engineering and Safety Center to review three personnel hazards associated with the CALIPSO satellite Proteus propulsion bus: 1-hydrazine leakage from the five threaded A\/N fluid fittings, 2-hydrazine leakage through the thrusters and 3-inadvertent firing of the thrusters. These personnel hazards exist only during the period when the system is filled and pressurized until launch (approximately 36 days). The pre-ship review of the instrument (supplied by Ball Aerospace and integrated into the spacecraft by Alcatel Space Industries) was the driving program milestone that precipitated this review and subsequent lesson learned. At the time of the independent assessment, the spacecraft had been through its critical design review and the Proteus bus was already fabricated. The choice of mechanical A\/N fittings instead of welded joints provided an area of concern for leakage of hydrazine propellant during ground processing. The use of a tank isolation valve for the hydrazine system (absent on the Proteus bus) would have provided improved safety during ground operations, but both mechanical fittings and a system without an isolation valve can be made safe by adhering to assembly and processing procedures. A thorough risk assessment in the design phase would have probed and documented the rationale for these design decisions and perhaps resulted in a different flight configuration.","Lesson ID":1491}
{"Driving Event":"The CALIPSO program involved NASA GSFC, LaRC, KSC Launch Services, CNES, and the Vandenberg Air Force Base Range Office. CNES contributed the Proteus hydrazine-fueled propulsion bus as part of their in-kind contribution. This bus was designed and built by Alcatel Space Industries under subcontract to CNES. Several personnel hazards associated with the Proteus bus formed the basis of the NESC assessment (leakage of hydrazine from threaded A\/N fittings, inadvertent thruster firings and leakage of hydrazine through the thrusters). It was accepted by all that the Air Force Eastern and Western Range (EWR) requirements applied (ref. CALIPSO-Tailored Eastern and Western Range 127-1 Safety Regulations, Doc. TP2.LB.0.AQ.1836 ASC dated October 21-22, 2002), but there was confusion over whether NASA Procedural Requirement NPR-8715.3, \u201cNASA Safety Manual\u201d; applied as well. Both documents contain sections related to fault tolerance requirements and there was debate over whether the fault tolerance requirements of either document were satisfied because of ambiguous wording. Even further, an unrelated but similar range safety document (ref. GSFC Wallops Flight Facility Range Safety Manual, RSM-2002) contained wording that seemed to conflict the GSFC engineering and safety offices' position that threaded fittings are zero fault tolerant.","Lesson ID":1493}
{"Driving Event":"Mars Exploration Rovers Spirit and Opportunity successfully landed on January 4 and 25, respectively, each with a primary mission duration of 90 days. Ground controllers of the MER vehicles have primary operational responsibility 24 hours per day for the health, safety and commanding of the two rover vehicles. They play the central roll in successful implementation of the mission plan. The work schedules of these individuals are directly locked in to the length of a Martian day - 40 minutes longer in duration than an Earth day - and thus constantly shift in start and stop time, relative to a clock keeping earth time. The long shift duration (10-12 hours), coupled with loss of synchronization with the daily pattern of events outside the work place can result in fatigue and personal stress which pose potential risks to work performance and ultimately to mission success. This was the subject of consultation by NESC Human Factors experts to the JPL MER Project. Although the MER Project took many effective steps to mitigate these risks, neither they nor the NESC experts were aware at the time of the existence of NASA Procedural Requirement 1800.1 (2002) that sets specific standards for work time limits for critical operations across the Agency. The need for such specific Agency-wide standards has been recognized going back at least to the Challenger accident. It is very important that the existence of these new standards by communicated effectively across the Agency and that they be implemented.","Lesson ID":1404}
{"Driving Event":"On two occasions during the ULYSSES mission, a mission controller erroneously performed a duplicate transmission of an operational command. Each incident resulted in storage of the duplicate commands aboard the spacecraft, overflow of a data buffer, and rejection of subsequent spacecraft operational instructions. Erasing the onboard instruction set and reloading the original instruction set restored operational commanding. The problem was determined to be imprecise execution of existing command procedures. Had it occurred during a more critical phase, this error could have resulted in the loss of an instrument or the spacecraft. References: Jet Propulsion Laboratory Incident Surprise Anomaly (ISA) No. Z78791, \u201cMission Controller Procedural Command Error,\u201d December 17, 2002. Jet Propulsion Laboratory Incident Surprise Anomaly (ISA) No. Z80269, \u201cProcedural Re-Transmission of Command,\u201d April 17, 2003. Additional Key Words: mission operations, operations procedures, erroneous commanding, operations training, operations assurance","Lesson ID":1415}
{"Driving Event":"Passivation is a phenomenon that can affect the performance of lithium batteries. Under no-load conditions, a passivation layer of lithium chloride (LiCl) forms on the surface of the lithium anode and protects the cells from discharging. This effect is responsible for the battery\u00bbs long shelf life, but the high resistance of the passivation layer may cause the cell's voltage to dip during use when a load is applied. As the battery discharges, the passivation layer dissipates and allows the cell to reach a peak voltage value. Passivation increases along with time and temperature; if the circuit cannot accommodate a voltage delay, the battery pack should be depassivated prior to use. [D] A simulated brownout during testing of the Entry, Descent, and Landing (EDL) flight software caused repetitive rebooting of the Mars Exploration Rover (MER) flight computer. A drop in the bus voltage during the simulated transition from the solar arrays to the primary batteries in the MER Lander caused the software to erroneously assume that the batteries had failed. The Lander contains five primary (non-rechargeable) lithium sulfur dioxide (LiSO2) batteries to support EDL and initial landed operations. The problem was traced to a passivation layer inhibiting the Lander batteries from producing full power during the transition (Reference (1)). Neither the MER circuit design nor the in-flight battery management procedures allowed for an initial output from the primary batteries (about 25 volts) that was significantly less than the 30-volt bus voltage. (Passivation is not usually a concern for secondary (rechargeable) spacecraft batteries because they are in continuous use.) A similar brownout during a mission critical event, such as EDL, could cause power on reset (POR) transients leading to corrupted memory, repeated reboots, and possible loss of mission. References: Jet Propulsion Laboratory (JPL) Problem\/Failure Report No. Z79633, February 28, 2003. Additional Key Words: battery passivation, battery depassivation, RAD6000, VME, battery chemistry, power\/pyro subsystem","Lesson ID":1410}
{"Driving Event":"During instrument integration, a GSE power harness seriously damaged SWIFT heater control electronics. This mishap occurred on the Burst Alert Telescope (BAT) Power Control Board (PCB). The failure investigation identified the root cause as a manufacturing error (miswire) in the GSE power interface harness. The PCB GSE harness was built and tested with a 28-volt reversed polarity in the power interface. The SWIFT Project desired to expedite the hardware I&T schedule. As a result, the PCB GSE power harness was accepted \u201cas is\u201d from the harness fabrication and test facility, without the proper documentation and QA review. At the time, it was rationalized that the Safe-To-Mate procedure would verify compliance to the Interface Control Document (ICD) and the safe flight hardware integration activities. As another time saving approach, review and sign-off requirements for SWIFT integration work orders were reduced to accelerate schedule. This approach eliminated the need for system and discipline engineering signatures. Changing work order signature authority is inconsistent with GSFC policy for the control and authorization of flight hardware work orders. Following the PCB power-on fault, the GSFC policy was reinstated with signatures from quality assurance, systems engineer and flight hardware leads. During the GSE electrical integration to the SWIFT PCB, the Safe-To-Mate procedure was performed, but not completed due to problems with a separate flight component, the Image Processor. To accelerate the integration schedule, the SWIFT Image Processor was being integrated in parallel with the PCB. Confusion ensued between the two integration procedures, and the PCB, GSE electrical Safe-To-Mate was not entirely finished. As a result of the application of reverse power, the SWIFT flight PCB sustained significant damage, which required a component rework cycle and a 4-month project schedule delay. There were several important situations and conditions, which resulted the SWIFT PCB power-on fault. These circumstances are the basis of the lessons learned. Each of these situations contributed to the PCB flight hardware damage, and individually, each could have prevented the failure condition. Overall, a disciplined and careful system engineering and quality assurance approach can preclude damage to flight hardware electronic during power interface harness testing.","Lesson ID":1398}
{"Driving Event":"Mars Exploration Rover Spirit successfully landed on January 4, 2004. Prior to the scheduled landing of the twin Rover, Opportunity, on January 25, an Entry, Descent and Landing (EDL) team at JPL carried out a reconstruction of the EDL performance of Spirit in order to determine if any quotlessons learnedquot could be used to modify the planned EDL sequence for Opportunity in order to improve its chances for a successful landing on Mars. An independent EDL quotRed Teamquot oversaw and assessed the work of the MER Project Reconstruction Team, to assure that the reconstruction was the best that could be done. The NASA Engineering and Safety Center (NESC) sent two EDL experts as independent participants on the quotRed Teamquot. Both Spirit and Opportunity deviated from their expected trajectory profiles\/timelines. An important conclusion drawn by the quotRed Teamquot and strongly endorsed by the NESC experts states, quotRelative to atmospheric reconstruction, it is suggested that the Project was remiss in not flying pressure and temperature sensors for use during terminal descent and on the ground. Such sensors, with a likely mass of hundreds of grams, would have allowed separation of the density and drag coefficient error sources, something for which the Reconstruction Team could only speculate. It is suggested that these sensors be added to the EDL reconstruction requirements of future landed systems.quot","Lesson ID":1402}
{"Driving Event":"The X-43A is a prototype, hypersonic aircraft mounted on a modified Pegasus booster rocket that accelerates the X-43A to its test speed and altitude. The modified Pegasus\/X-43A (or Hyper X Launch Vehicle) stack is launched from the NASA B-52B aircraft. The initial X-43A flight resulted in a mishap and loss of vehicle and mission. Subsequent return-to-flight activities conducted by the program to prepare for the 2nd flight test resulted in a dissenting opinion being submitted. NESC involvement was initiated by receipt of the dissenting opinion through e-mail. The dissenting opinion raised three potential overarching transonic aerodynamics issues that were not being addressed sufficiently by the program during return to flight activities. 1) Incomplete aerodynamic analysis of Flight 1 (a failure to quantify all contributing factors); 2) The need to develop and\/or validate scaling laws for ground test to flight databases supporting Flight 2; and 3) The need to correct known errors & deficiencies in ground based experimental & computational data sets. The NESC Director negotiated with the X-43A Return-to-Flight (RTF) Manager to have these issues addressed through the existing independent X-43A Flight Readiness Review (FRR) process with NESC monitoring and evaluation.","Lesson ID":1413}
{"Driving Event":"The CALIPSO program involved NASA GSFC, LaRC, KSC Launch Services, CNES, and the Vandenberg Air Force Base Range Office. CNES contributed the Proteus hydrazine-fueled propulsion bus as part of their in-kind contribution. This bus was designed and built by Alcatel Space Industries under subcontract to CNES. The Memorandum of Understanding (MOU) between NASA and CNES placed the responsibility for design of the propulsion bus with CNES yet did not explicitly state which safety requirements applied. Several personnel hazards associated with the Proteus bus formed the basis of the NESC assessment (leakage of hydrazine from threaded A\/N fittings, inadvertent thruster firings and leakage of hydrazine through the thrusters). It was accepted by all that the Air Force Eastern and Western Range (EWR) requirements applied (ref. CALIPSO-Tailored Eastern and Western Range 127-1 Safety Regulations, Doc. TP2.LB.0.AQ.1836 ASC dated October 21-22, 2002), but there was confusion over whether NASA Procedural Requirement NPR-8715.3, \u201cNASA Safety Manual\u201d; applied as well.","Lesson ID":1492}
{"Driving Event":"On September 11, 2003, at approximately 2:16 PM, the steam line on the Large Altitude Simulation System (LASS) suffered a catastrophic failure of the 24-inch expansion loop located adjacent to the Test Stand 401 steam ejector exhaust duct. The LASS was being operated to verify its readiness to support an altitude firing of the 4th stage of a Minuteman ICBM scheduled for September 25, 2003. The failure occurred approximately 16 seconds after the LASS was commanded to go to full steam, and resulted in a rupture of a portion of the line that dislocated several pieces of the 24-inch pipe in various directions away from the test stand. The proximate cause of the event was pipe wall corrosion that led to selective thinning of the wall, which resulted in the pipe rupture under pressure. The investigation resulted in the following observations and conclusions: Piping insulation, if not properly installed and maintained, can trap moisture on the exterior of the pipe and accelerate corrosion. If moisture is not removed from \u201cnon-continuous use\u201d steam lines between use, the corrosive environment during the down time can be worse than during active use. Elevated levels of carbon dioxide in steam system water can lead to excessive amounts of carbonic acid which is highly corrosive to carbon steel piping. Post implementation problem solutions must utilize a \u201csystems approach\u201d in order to avoid creating other design issues beyond the immediate problem being corrected.","Lesson ID":1392}
{"Driving Event":"On September 11, 2003, at approximately 2:16 PM, the steam line on the Large Altitude Simulation System (LASS) suffered a catastrophic failure of the 24-inch expansion loop located adjacent to the Test Stand 401 steam ejector exhaust duct. The LASS was being operated to verify its readiness to support an altitude firing of the 4th stage of a Minuteman ICBM scheduled for September 25, 2003. The failure occurred approximately 16 seconds after the LASS was commanded to go to full steam, and resulted in a rupture of a portion of the line that dislocated several pieces of the 24-inch pipe in various directions away from the test stand. The proximate cause of the event was pipe wall corrosion that led to selective thinning of the wall, which resulted in the pipe rupture under pressure. The investigation resulted in the following conclusions and observations: Piping containing high mass flow rates must be examined for the capacity to withstand the forces generated during a pipe wall failure, and potential moment arms must be kept short enough that the pipe strength is not exceeded during a failure. Piping designed to \u201cleak-before-burst\u201d capability that has experienced wall thinning will ultimately transition to a \u201cburst-before-leak\u201d situation if the wall thinning is not arrested. Instrumentation data sample rate and data quality must be high enough to catch the possible events that the transducer might measure, not just the expected events. System operational capability, such as design life, must be established and documented at the initial design to allow appropriate decisions as the system approaches its capability limits.","Lesson ID":1393}
{"Driving Event":"A mission-critical error was discovered in the communications link between the Cassini spacecraft and its Huygens probe when it was determined that the radio frequencies would not adjust for Doppler effect. With Doppler effect, the motion of a transmitter relative to a receiver causes the received frequency to differ from that sent from the transmitter. The effect on a probe-to-orbiter uplink may be especially severe in times of rapid velocity changes such as during planetary flybys and Saturn orbit insertion. An extensive in-flight end-to-end telecommunications test conducted in February 2000 (3 years after Cassini was launched) revealed anomalous characteristics of the Huygens-Cassini communications link. Extensive ground testing of the link subsequently confirmed that Doppler shift would cause unanticipated 10dB degradation in the link margin, resulting in a major loss of data during probe descent and landing. This parameter was not isolated during the pre-launch verification process. The baseline mission profile has been changed to increase the strength of the data signal and restore the Huygens mission. References \u201dHuygens Communications Package Under Investigation,\u201d ESA Press Release, October 5, 2000. \u201dEnsure Test Facilities Can Accommodate 'Test-As-You-Fly',\" Lessons Learned No. 1335, March 31, 2003. \u201dTest As You Fly, Fly As You Test, And Demonstrate Margin,\u201d Lessons Learned No. 1196, January 24, 2002. JPL Incident\/Surprise Anomaly (ISA) report no. Z70967, February 14, 2001. Additional Key Words: international partnering, telecommunications design, uplink design, link analysis, telecommunications subcarrier, subcarrier test, design margin, flight readiness, test and integration, telecommunications failure modes, fault tolerance, RF simulations","Lesson ID":1390}
{"Driving Event":"The WSTF Propulsion Computer Engineering section was given a task (via Space Act agreement) to develop, validate and implement a very challenging rocket engine control software module for use in initial developmental ground testing operations. This custom control and monitoring software was to be used for safely establishing the closed loop startup and shutdown profiles of a liquid propellant rocket engine with a gas generator powered turbo-pump propellant feed system. There were several critical pressures and turbo-pump vibration parameters that had to be monitored while valves were being cycled to allow safe buildup of gas generator pressure, turbo-pump speed, manifold pressures, and combustion pressure. At any time during the startup or main stage process, if any of these critical parameters deviated from predetermined nominal limits, then a sequence of commands had to be issued for safely shutting down the engine. The design and code generation for the control and limit shutdown algorithms was relatively straight forward, but the challenge was to ensure it would all work correctly prior to firing up a developmental rocket engine for the first time. A process was needed to ensure that the software and hardware involved would correctly respond to all critical control parameters. This process had to simulate failures during all stages of operation while providing simulated feedback for the closed loop startup, main stage, and shutdown modes. A rocket engine simulator was required to validate the control system for this one-of-a-kind developmental engine. This simulator would then have to be implemented in a system that could provide not just mathematical values, but electrical signals for communicating pressure values and vibration monitoring events back to the control system. High fidelity modeling of rocket engine processes is very complex and to develop a math model that runs in real-time is even more complex. In previous projects of this type, actual hardware components electronically similar to the rocket engine valves, actuators, and pumps had to be assembled into a crude engine breadboard. All these components then had to be individually connected to the data acquisition and control system for validating the monitor and control algorithms. In addition, time delay relays and signal generators would have to be integrated with the breadboard components to provide enough precision for validating the fast, time critical, transient response requirements. The facility where this rocket engine was to be tested already had a programmable logic controller (PLC) in place for controlling some test facility support functions. Although not fast enough to control or provide high fidelity real-time engine simulation it was ideally suited for issuing signals back to the engine control system in response to the control system program output commands. It could also be used to sequence various failure simulation signals for validating correct responses to possible engine problems during all stages of operation. The complexity of designing a complete real-time breadboard or math model simulation of the rocket engine was replaced using simpler PLC ladder logic. It was used to provide feedback defined by the engine designers for the critical control points in the power up and power down staging process. This in essence allowed using a very simple empirical model of the engine for our validation simulator. It was then also possible to easily inject simulated failures at various critical times to ensure safe operation of all control and emergency shutdown algorithms. This technique could be applied to many dynamic process algorithms on systems that have a few fairly well defined critical control points.","Lesson ID":1395}
{"Driving Event":"NASA has issued a Government Industry Data Exchange Program (GIDEP) ALERT, #H1-A-04-01 regarding the Weller\u00ae Model TCP12P Soldering Iron. Due to a mechanical temperature control switch which works based on a ferromagnetic sensing action, two previously undocumented failure modes were observed with this model. The failures were observed in a laboratory setting with minimal damage. The worst of these two modes involves the switch sticking in the quotFull Onquot mode. If this occurs, the soldering iron will go into a quotThermal Runawayquot condition, which will allow the iron to reach temperatures of approximately 1200\u00b0 F, at the heater\/tip interface. Obviously, this could result in possible fire, injury, and\/or damage to any article being processed. This temperature estimate is based on the mass and length of the soldering iron tip, and may vary depending on which tip is installed at the time the failure occurs. A tip with larger mass and greater length will lower the maximum temperature possible during the quotThermal Runawayquot condition. A tool holder that surrounds the heated portion of the soldering iron is available, and with this holder in place, the overheat condition should be generally harmless to the working environment. The second additional failure mode is more minor, involving the Ferromagnetic Switch sticking in a quotFull Offquot mode, which means the tool will not heat at all.","Lesson ID":1389}
{"Driving Event":"On September 11, 2003, at approximately 2:16 PM, the steam line on the Large Altitude Simulation System (LASS) suffered a catastrophic failure of the 24-inch expansion loop located adjacent to the Test Stand 401 steam ejector exhaust duct. The LASS was being operated to verify its readiness to support an altitude firing of the 4th stage of a Minuteman ICBM scheduled for September 25, 2003. The failure occurred approximately 16 seconds after the LASS was commanded to go to full steam, and resulted in a rupture of a portion of the line that dislocated several pieces of the 24-inch pipe in various directions away from the test stand. The proximate cause of the event was pipe wall corrosion that led to selective thinning of the wall, which resulted in the pipe rupture under pressure. The following observations came from the investigation: During the mishap investigation, evidence of rust scale deposits around steam line drains (or \u201cexhaust ducts\u201d) was observed. This is an indicator that internal corrosion and erosion is taking place in the system. External corrosion products on the pipes were also observed, especially where external insulation trapped water from environmental sources. In piping subject to corrosion, it is difficult to determine the location of old pipe wall thinning in complex installations without 100% surveying. At the same time, Non-Destructive Evaluation techniques for determining steam pipe wall thickness were found to be inconclusive due to the detritus from internal corrosion remaining in place primarily on the inside of pipe walls. In this particular case, an alternative method to assess system integrity - hydrostatic pressure testing of old or modified fluid handling lines - was not an effective means of verification of long-term pressure integrity.","Lesson ID":1391}
{"Driving Event":"The Dryden Flight Research Center's Learjet Model 24, call sign NASA 805, sustained substantial damage during a planned \"touch and go\" landing at the Southern California Air Logistics Base (formerly George Air Force Base), near Victorville, CA on June 7, 2001. There were no injuries to the pilot, co-pilot, or the observer in the course of this event. The Learjet was used on an infrequent basis as a research testbed. The aircraft had just returned to flight status from an extended period in flyable storage. This type of usage did not permit the assigned aircrew to maintain currency. The flight was a scheduled recurrency flight. There was inadequate guidance in the areas of piloting duties, crew pairing, recurrency requirements, and restrictions to carrying passengers. The daily flight supervision process was inadequate to mitigate the lack of DOP-0-300 guidance. The supervisory process did not provide adequate policy, procedures, nor oversight and insight for aircrew conducting flights to ensure significant qualifications, training and currency were met. The direct causes of this mishap were identified as: Over control of the aircraft by the copilot (pilot flying) leading to an aggravated roll oscillation, hard landing, loss of control, and subsequent impact. A significant factor was the copilot's limited total piloting experience, particularly in high performance jet aircraft and in the Learjet. Failure of the pilot in command (pilot not flying) to recognize the deteriorating situation in time to recover the aircraft. A significant factor was the pilot in command's lack of currency in the Learjet, and his low overall experience in the Learjet. The combination of an inexperienced copilot flying an aircraft with a pilot in command who was not current in the aircraft and who had relatively little time in type.","Lesson ID":1377}
{"Driving Event":"An employee received an electrical injury after coming in contact with an energized electrical circuit while wiring a relocated emergency generator; the employee subsequently died of the injury. Finding A: Employees must personally verify, prior to starting work on a potentially energized system, that the system is de-energized and their personal lock and tag are in place. Do not take the word of a co-worker or supervisor. If the employee leaves the work site for any reason, re-verify the system is still de-energized before resuming work. The following evidence supports this finding: At the beginning of the day, the foreman improperly checked the voltage at the junction box where the mishap occurred. The improper check was a result of using a painted surface as a ground reference. After this initial check by the foreman, the circuit was not re-checked by any of the electricians working on the generator circuits. All the electricians working at the site assumed the circuits were de-energized. The contractor did not pursue understanding of the circuits or request NASA assistance in identifying circuit breakers that would de-energize circuits. The NASA-delegated safety and quality inspectors on the site throughout the day did not question whether the circuits associated with the generator had been de-energized, locked, and tagged. Finding B: It is unacceptable to work on any energized system without proper permits and personal protective equipment (PPE). One of the causes of this mishap was a risk-taking decision based on past experience and the perception of a low risk situation. Managers should verify that their employees know and are implementing the applicable safety policies and procedures. The following evidence supports this finding: It is a common practice for some electricians to work on energized circuits without PPE and without the proper permits. Both NASA and the contractor have policies that prohibit work on energized circuits, except for a few circumstances that were not applicable in this case. Although the contractor has adequate policies and procedures, implementation is weak or lacking. For example, LO\/TO training for contractor employees consisted of a contractor-provided \u201cElectric\u201d brochure handed out to each employee explaining the company's policy and procedure; the employee was expected to sign in the back of the brochure indicating that the employee had read the booklet.","Lesson ID":1378}
{"Driving Event":"The incident response team secured the site immediately and performed an excellent preliminary investigation. The junction box was de-energized and circuit breakers were locked and tagged by the JSC center operations support contractor. In addition, the junction box was locked to preserve the circuit configuration and the key was impounded and turned over to the MIB. The area of the mishap was \u201ctaped off\u201d; and a security guard posted until released by the MIB. Interviews with personnel on the scene at the time of the mishap were conducted within hours of the incident. All the above actions served to ensure an effective mishap investigation by the formal board.","Lesson ID":1379}
{"Driving Event":"A mishap occurred in a large (18' X 20') autoclave at MSFC on August 13, 2002 resulting in damage to government property of approximately $23K. Two to four minutes into pressurizing the autoclave, operators noted that vessel pressure was not following the set-point value. Operators heard a loud noise outside the building and sent personnel to investigate. Bystanders outside indicated the noise came from nearby construction. Approximately 5 minutes later, another loud noise was heard coming from the nitrogen pressure regulating assembly of the autoclave. Other than the noise, no system warning or error indicators were encountered. The cycle was aborted and appropriate safety personnel were notified. A checkout of the facility revealed a failure of the purge blower. Equipment damage resulted from the mishap. Damaged components included the purge blower assembly, purge valve solenoid assembly (solenoid in green), purge valve (below the solenoid assembly) and the entire purge line from the blower to the autoclave pressure vessel. A piece of fan blade sheared from the shaft, ripped through the blower housing and hit the purge valve solenoid just before it came to rest on some nearby nitrogen supply piping. The investigation revealed the purge valve had remained open during pressurization of the autoclave allowing pressurizing gas (nitrogen) to back-flow into the purge blower and spin it in reverse until it failed due to excessive load. Debris (probably caused by a mud wasp) had obstructed the vent sufficiently to prevent proper closure of the valve thus ultimately causing the blower failure. The Mishap Board recommended the following corrective actions be implemented prior to facility activation: Install screens over all autoclave pneumatic outputs to prevent debris from clogging lines. Install a position indicator switch on the purge valve. Link this position indicator switch into the autoclave's programmable logic control (PLC) software so that the \u201call systems ready\u201d interlock prevents operating the autoclave until the valve is properly closed. Install a one-way \u201ccheck\u201d valve in the purge line to prevent back flow of nitrogen from the pressure vessel into the purge blower in the event of a purge valve failure. This valve shall be installed between the purge valve and the purge blower so it is outside the autoclave's pressure boundary.","Lesson ID":1383}
{"Driving Event":"The employee used rags saturated with IPA obtained from an open IPA container to clean the three thermal vacuum chambers. After use, the rags were left on the chamber floor. No supplemental ventilation or personal protective equipment (PPE) was utilized resulting in unsafe levels of IPA vapor within the chamber. The cumulative effects of prolonged exposure without sufficient breaks were not considered.","Lesson ID":1382}
{"Driving Event":"In the Integrated Equipment Assembly IEA dolly ring removal process, it was noticed that the inner ring has no lifting point, two 4-ft web straps were used to lift it; one was choked around the apex, and the other was shackled to it (which seems superfluous if two web straps are going to used).","Lesson ID":1388}
{"Driving Event":"During thermal ambient testing of Mars Exploration Rover (MER) Rover Electronics Module (REM) (Reference (1)), condensation formed inside the test chamber and upon the flight article. This test consisted of a 2-hour 25 deg C soak with a dry nitrogen purge rate of 2 SCFM, then a ramp to -55 deg C (with a rate of 2 deg\/min), and a final soak at -55 deg C for 2 hours. Once the chamber temperature reached -55 deg C, frost (ice crystals) was observed on the cables inside the chamber. After the final 2-hour soak, the frost had thickened and the area inside the chamber pass-through was also frosted over. The condensation is the likely cause of damage that was observed on the flight avionics backplane after the REM boards were removed and inspected following the test. The cause appears to be inadequate sealing and improper purging of the chamber during test. References (2), (3), and (4) report similar chamber control problems at JPL during this time period. The Jet Propulsion Laboratory's primary thermal-vacuum test chambers for use on flight equipment are operated with oversight by the JPL Environmental Test Laboratory (ETL) organization. However, as many as 50 pressurized and non-pressurized thermal chambers used chiefly for experiments, hardware development, and special purposes are maintained by various JPL laboratories. Although these facilities were sometimes used to test flight and other critical hardware, many (including the chamber in question) were not certified by the ETL. References Jet Propulsion Laboratory (JPL) Problem\/Failure Report No. Z77001, August 1, 2002. Jet Propulsion Laboratory (JPL) Problem\/Failure Report No. Z76596, July 2, 2002. Jet Propulsion Laboratory (JPL) Problem\/Failure Report No. Z77229, August 22, 2002. Jet Propulsion Laboratory (JPL) Problem\/Failure Report No. Z78119, October 30, 2002. Lessons Learned No. 0622, Use of Obsolescent Test Facilities Pose Risk to Hardware, May 24, 1999 Jet Propulsion Laboratory (JPL) Corrective Action Notice No. Z77321, August 29, 2002. Additional Key Words: test-induced failure, test damage, facility certification","Lesson ID":1376}
{"Driving Event":"The Comet Nucleus Tour, CONTOUR, was designed and built by Johns Hopkins University with specialized support from NASA as a part of NASA's Discovery series of solar system exploration satellites. Launched on July 3, 2002, CONTOUR was intended to encounter at least two comets to perform a variety of analyses on comet material. However, sometime after the solid rocket motor (SRM) intended to move the satellite out of eccentric earth orbit was fired, the satellite was lost. Mission design did not allow for observation or telemetry coverage during SRM burn, so the mishap investigation board was unable to determine with certainty the cause of the failure. However, a number of possible root causes were documented, along with recommendations for corrective actions. The following probable proximate cause was identified: Overheating of the spacecraft by SRM exhaust plume The following alternate proximate causes were identified: Catastrophic failure of SRM Collision of spacecraft with debris or meteoroids Loss of dynamic control of spacecraft","Lesson ID":1385}
{"Driving Event":"Scaffolding in support of Payload processing is typically configured per payload instead of per task which causes limited and\/or awkward access several tasks required to be performed on the payload. Scaffolding is built up in accordance with OSHA but does not take into consideration human factors criteria including anthropometric data for work access (height) and reach. The results are awkward postures and the high potential for back injury.","Lesson ID":1387}
{"Driving Event":"DFRC had a dozen large diameter (20\"+\/-) fire water sectional valves located in large vaults around the flight line. The requirement was to backfill these vaults with earthen materials, and remove the top of the vaults, and pave flush around them for minimal impact to the flight line area. The problems of doing this with \"dirt\" included working down in deep confined spaces, substandard compaction, hazards and probabilities of using power compactors around critical facility pressurized piping, and possible pipe damage resulting in flooding and drowning hazards. The simple solution arrived at was to \"pour\" in pea gravel, that flowed in like water and achieved near-100% compaction.","Lesson ID":1373}
{"Driving Event":"Following is an excerpt from the Mishap investigation report: Finding A: Construction contractors are treated as \"transient\" employees for the purpose of meeting safety requirements. They are not required to participate in the NASA Close Call system. They are not required to provide safety metrics. They are not required to participate in training required for onsite, permanent employees, e.g., Safety Through Everyone's Participation (STEP), Hazards Communication, etc. There is no \"closed loop\" tracking of observed safety deficiencies. Specifically, (4a) There is no provision for \"real time\" feedback to contractor management of safety violations. (4b) Formal written evaluation of firm fixed price construction contractors is only provided at job completion. Finding B: NASA and NASA-delegated oversight and \"quality and safety\" inspection processes lack rigor to assure contract provisions are being adhered to. The following evidence supports this finding: Contractor's failure to submit required submittals did not stop the job. NASA\/JSC did not conduct or require the contractor to conduct mandatory safety inspection points to assure through independent verification that systems had been de-energized. Insufficient number of NASA\/JSC delegated safety inspectors performing random inspections to assure contractor compliance with contract provisions. No \"task readiness review\", outlining work to be performed, was conducted. NASA\/JSC did not take adverse action against this contractor even though they had a history of violating non-electrical safety policies and procedures (procedures for adverse action are in the contract).","Lesson ID":1375}
{"Driving Event":"Finding A: The available drawings did not include circuit details to the level necessary to readily identify which circuit breakers would isolate the circuits involved in the mishap. Identifying the appropriate circuit breakers without adequate drawings is a time consuming process adding to the probability that the contractor might take shortcuts. The following evidence supports this finding: The construction drawings by the Architect\/Engineering (A\/E) firm did not include any circuitry associated with the generators. The facility drawings did not include all the circuits associated with this job. NASA\u00bbs configuration management of facility drawings is not adequate; drawings are not promptly updated, plus one-line (red-line) drawings do not always contain all electrical circuits. The existing facility drawings were not provided to the contractor. Find B: Project submittals from the contractor to the government are a requirement. NASA needs to ensure the required submittals have been delivered, reviewed, and accepted before allowing the work to proceed. The following evidence supports this finding: The contractor failed to develop and submit a point-to-point schematic to NASA prior to \u201cdemolition\u201d of existing wiring, as required by the construction drawings. NASA did not confirm delivery of the point-to-point schematic required by the construction drawings. The contractor had no formal or organized process to plan or review its day\u00bbs work.","Lesson ID":1374}
{"Driving Event":"Cassini is one of the first major JPL missions to successfully conduct a risk management program during the Mission Operations and Data Analysis (MO&DA) phase, in addition to the normal system development program. When the risk management program was revived 3 years after the 1997 launch, the Mission Operations System (MOS) Team viewed it as a new and challenging practice. Implementation was complicated by the distribution of the 500-person MOS Team across the U.S. and Europe, involving over 16 sub-teams, 9 time zones, and information exchange limitations mandated by International Traffic in Arms Regulations (ITAR). [D] To plan the risk management process for MO&DA, training workshops and tutorials were held during 2000, and a risk management plan and schedule were issued in early 2001. Subsequent brainstorming sessions produced a Significant Risk List (SRL), risk items were sorted by mission phase, and they were documented in an on-line tool and categorized according to likelihood and impact. A Risk Team met quarterly to review the project\u00bbs risk posture, add risk metrics to the on-line tool, and brief the MOS Team and NASA. The risk posture was a standard briefing topic at Cassini readiness reviews and monthly management reviews. A key to the success of this program was deferring wider participation until the risk management process was well established and understood by the JPL MOS Team. JPL did not solicit European Space Agency (ESA) and Instrument Team participation until late 2002, when the on-line tool, initial SRL, and risk performance metrics had already achieved a measure of acceptance at JPL. With these tools in place, changes in the project risk profile became easily visible to the MOS Team and Cassini project management. References: Robert T. Mitchell, \u201cCassini: An Overview of Lessons Learned,\u201d NASA Risk Management Colloquium IV, September 4, 2003. JPL Risk Management Process Implementation Guideline, JPL DocID 57312, August 16, 2002. \u201dMars Exploration Rovers (MER) Human Factors Management Action Plan\u201d, December 12, 2003, as part of \u201cMars Exploration Rovers (MER) Safety Plan\/Requirements for Visitation and Media Coverage for MER Landings\u201d. Mona M. Witkowski, \u00bfCassini Risk Management during Mission Operations and Data Analysis \u00bf Application & Lessons Learned,\u00bf 2003 IEEE Aerospace Conference, March 10, 2003. Additional Key Words: risk assessment, mission risks, operations risks, risk drivers, failure mode, risk impact, risk likelihood, risk training, international partners","Lesson ID":1411}
{"Driving Event":"During integration and test of Mars Exploration Rover (MER-A), the 6-amp, Single Point Ground (SPG) fuse-located on the Rover Electronics Module (REM) chassis was found to be blown. The JPL MER SPG Fuse was part of a system design that provided a grounded power bus (through the fuse) while safely allowing for the fault condition of a high-side power bus short-to-chassis by blowing the fuse and operating in a quotdegradedquot mode (floating bus). (Since the NSI power source return was connected through the fuse to chassis, plasma short currents went through it.) The blown fuse was in turn attributed to the firing of six pyros four weeks earlier to permit removal and rework of a circuit board. Electrical overstress analysis and tests cleared MER-A to fly with the embedded blown fuse, but the failure investigation revealed a previously unrecognized \u201cplasma effect\u201d failure mechanism for NASA Standard Initiators (NSIs). [D] Figure 1 - NASA Standard Initiator (NSI) [D] Figure 2 - Cutaway View of NSI [D] Figure 3 - Diagram of Plasma-Induced Discharge and Preferential Deposition of Molten Residual By design, NASA pyro devices such as cable cutters, pin pullers, and separation nuts incorporate two NSIs. NSI firing always generates some conductive plasma, and MER firing circuits were designed to withstand a pin-to-pin or pin-to-case plasma arc lasting around 5-6 milliseconds after the NSI bridgewire opened. However, designers were unaware that a prolonged NSI pin-to-case short could result due to deposition of molten NSI residual. Thus, the number and magnitude of plasma shorts\/ hard shorts on MER were much higher than expected. Pin-to-case metal deposition occurs after the plasma arc is extinguished, due to zirconium fragments forming a conductive path across the ceramic charge cup. The MER investigation revealed that the path resistance will increase after NSI cool-down, but the resistance will remain too low to safely limit current until the firing relay opens (32 milliseconds) or until the SPG fuse blows. The results may damage circuit components because the firing circuit current is significantly higher during the short, and the circuit elements are not sized to withstand this higher current for a full 32 milliseconds. Later bench tests showed that, depending on circuit parameters, ground fault currents of as much as 15-20 amps for 32 milliseconds were possible. This incident led to a JPL-wide search for all NSIs fired during ground test on flight hardware. They were examined to verify that their resistance, as measured from the \u201chigh side\u201d to the case, post-fire, exceeded 100 kilohm, indicating little shorting effects. These shorting effects do not affect whether the NSI will fire properly since they occur after the firing. Once the NSI fires (within the first millisecond), its job is done and what happens to the remaining circuit components afterwards is moot. The real problem is firing NSIs during test. That is when circuit components may be damaged to the point where the circuit will fail to fire the next time (the actual operation). And, the reason that components may have been damaged on MER was that the pyro power bus was grounded through the fuse to chassis, allowing the short current to flow for up to 32 milliseconds. The SPG fuse blowing actually saved the circuit components by limiting the time of the impressed current on them. References: JPL Problem\/Failure Report No. Z80623, May 12, 2003. Linda Facto & Joe Savino, MER Pyro Circuits Lessons Learned, Internal JPL Presentation, August 6, 2003. NASA Lessons Learned No. 0348, \u201cMagellan AACS RAM Upset During SRM Pyrotechnic Initiation,\u201d October 25, 1994. NASA Lessons Learned No. 0448, \u201cFusing Element Failure resulting from Test Integration, Test, Pyrotechnic Devices, PYRO, Electrical Explosive Devices, EED, Command Circuit, Drive Circuit,\u201d September 12, 1996 Additional Key Words: test-induced failure, sneak circuit, smart NSI, pin-puller, cable cutter","Lesson ID":1412}
{"Driving Event":"The Space Shuttle program began flying atmospheric flight navigation units in 1993, in support of Shuttle avionics upgrades. In the early 1990s, it was anticipated that proven in-production navigation units would greatly reduce integration, certification and maintenance costs. However, technical issues arising from ground and flight tests resulted in a slip in the Shuttle GPS certification date. A number of recommendations were developed concerning the adaptation of atmospheric flight navigation units for use in low-Earth orbit. They are applicable to any use of a navigation unit in an application significantly different from the one for which it was originally designed. Flight experience has shown that atmospheric flight navigation units are not adequate to support anticipated space applications of GPS, such as autonomous operation, rendezvous, formation flying and replacement of ground tracking systems. Space Shuttle Tactical Area Navigation (TACAN) Replacement with GPS In 1990, the Shuttle Program began to investigate the use of GPS, based on the anticipated phase-out of TACAN starting in the year 2000. The Shuttle Program desired a receiver that was in mass production and had an existing logistics base. Anti-jam and anti-spoofing capabilities were also desired. A trade study conducted in 1993 chose the five channel Miniaturized Airborne GPS Receiver (MAGR), which entered production in 1994. The MAGR\/Shuttle, or MAGR\/S, was procured as a TACAN replacement and for use as a source of state vectors while on-orbit. There were no requirements for the MAGR\/S to be used for applications involving high accuracy orbit determination, such as ground radar and Tracking & Data Relay Satellite (TDRS) tracking replacement or spacecraft rendezvous. The MAGR\/S will be certified to serve as a TACAN replacement in both keyed and unkeyed configurations. No requirements were levied on the vendor to change the MAGR\/S Kalman filter, which was designed for use on a variety of aviation platforms without modification. An orbital state vector propagation algorithm was added to support satellite acquisition after a GPS outage. A pre-production MAGR, called the 3M, was flown seven times on the Shuttle Endeavor from December 1993 to May 1996. The first flight of a production MAGR missionized for the Shuttle application (MAGR\/S) occurred in September of 1996. By the fall of 1997, five test flights of the MAGR\/S on the Space Shuttle had occurred. At that time, the Shuttle Program decided to replace the three TACAN units on Atlantis with three MAGR\/S units. The first \"no TACAN, all GPS\" flight was scheduled for January 1999 (STS-92). By June of 1998, the first flight of Atlantis with three string GPS had changed to STS-96 (May 1999), due to changes in the International Space Station (ISS) assembly schedule. While on-orbit during STS-91 (Discovery, June 1998), the final Shuttle-Mir mission, a MAGR\/S firmware problem and several flaws in the Space Shuttle computer software that communicate with the MAGR\/S were discovered. Certification of the MAGR\/S was postponed. MAGR\/S firmware and Shuttle software issues were resolved, and additional MAGR\/S firmware versions, ground and flight-testing were planned. Certification of the MAGR\/S for operational use occured in 2002. However, it is not known when the Shuttle Program will decide to replace the TACAN units with the MAGR\/S receivers. With the start of TACAN phase-out delayed until 2010, it is expected that the Shuttle Orbiters will fly with three TACAN units and one MAGR\/S receiver for some time. Three Shuttle flights (STS-81, -84 and -86) carried Embedded GPS\/INS (Global Positioning System\/Inertial Navigation System), or EGIs, from two different vendors to collect data for the X-33 program. In 1996, NASA began a project to eventually replace the MAGR\/S receivers and the High Accuracy Inertial Navigation System (HAINS) Inertial Measurement Units (IMUs) with a space-missionized EGI, known as a Space Integrated GPS\/INS (SIGI). SIGI was envisioned as a \"common NASA navigator\" that could be used on a variety of manned and unmanned vehicles. The Shuttle SIGI flew on seven missions between September of 1997 and December of 1999 for data collection. Since the HAINS IMUs are projected to be operational through 2010, replacement of the HAINS IMUs and MAGR\/S units by SIGIs has been deferred.","Lesson ID":1370}
{"Driving Event":"Electrostatic discharge (ESD) arcing occurred during Mars Exploration Rover (MER) integration and test following handling of the Rover Equipment Module (REM) serial number 101. The custom shipping container holding the REM flight hardware had just been rolled from one room to another for mass properties measurements. A small spark was seen and heard by a technician as he installed a facility ground strap to the REM chassis prior to removing the REM from the container. Subsequent tests verified that moving and opening the container induced a charge on the surfaces of the container and onto the attached REM chassis. As the facility ground strap was attached, an electrical discharge arced across the gap separating the strap from the REM chassis. The ESD properties of the container were assumed to be acceptable. A field potential meter was not used to inspect surfaces of the container prior to attaching the facility ground strap. References JPL Standard for Electrostatic Discharge (ESD) Control (JPL D-1348) JPL Problem\/Failure Report No. Z77146, August 15, 2002. \u201dPacking and Unpacking ESD Sensitive Hardware,\u201d JPL Quality Assurance Procedure QAP 61.12, February 26, 2003. JPL Corrective Action Notice No. Z77277, August 27, 2002. Lesson Learned No. 1317, \u201cESD: An Enduring and Insidious Threat to Flight Hardware (A Cornerstone Lesson),\u201d January 14, 2003. Lesson Learned No. 1315, \u201dIncreasing ESD Susceptibility of Integrated Circuits,\u201d December 9, 2002. Additional Key Words: ESD damage, ESD effects, ground handling, ground transportation","Lesson ID":1371}
{"Driving Event":"During Mars Exploration Rover (MER) integration and test, there were two safety incidents where un-insulated, braided traveling ground straps came into contact with exposed facility power terminals during movement of connected flight hardware. The two traveling ground straps each exceeded 25 feet in length. The resulting electrical shorts caused visible sparks and partial melting of the ground straps and power connectors. [D] Subsequent circuit analysis showed that neither the star scanner (Reference (1)) nor the Rover Equipment Deck (Reference (2)) was damaged. References JPL Problem\/Failure Report No. Z77937, June 26, 2002 JPL Problem\/Failure Report No. Z78131, October 31, 2002. JPL Corrective Action Notice No. Z78250, November 7, 2002. JPL Standard for Systems Safety, D-560 (Rev. C), March 9, 1999. Additional Key Words: short circuit, electrical grounding, ground wire, test-induced damage, test error, bare wire","Lesson ID":1372}
{"Driving Event":"While working on a lighting system in a JSC building, it was determined that a circuit breaker that had been properly locked and tag out in the de-energized (open) position, had been repositioned to its energized (closed) position, with the lockout device still installed. INVESTIGATION FINDINGS: It was determined through experimentation that the breaker lever could be thrown to the energized (closed) position with the lock out device installed. Later investigations of TFE and TED breakers also found that another similar breaker thumb-screwed type lockout device had fallen off after it had been properly installed and locked & tagged out on a breaker.","Lesson ID":1369}
{"Driving Event":"An employee received an electrical injury after coming in contact with an energized electrical circuit while wiring a relocated emergency generator; the employee subsequently died of the injury. Finding A: Employees must personally verify, prior to starting work on a potentially energized system, that the system is de-energized and their personal lock and tag are in place. Do not take the word of a co-worker or supervisor. If the employee leaves the work site for any reason, re-verify the system is still de-energized before resuming work. The following evidence supports this finding: At the beginning of the day, the foreman improperly checked the voltage at the junction box where the mishap occurred. The improper check was a result of using a painted surface as a ground reference. After this initial check by the foreman, the circuit was not re-checked by any of the electricians working on the generator circuits. All the electricians working at the site assumed the circuits were de-energized. The contractor did not pursue understanding of the circuits or request NASA assistance in identifying circuit breakers that would de-energize circuits. The NASA-delegated safety and quality inspectors on the site throughout the day did not question whether the circuits associated with the generator had been de-energized, locked, and tagged. Finding B: It is unacceptable to work on any energized system without proper permits and personal protective equipment (PPE). One of the causes of this mishap was a risk-taking decision based on past experience and the perception of a low risk situation. Managers should verify that their employees know and are implementing the applicable safety policies and procedures. The following evidence supports this finding: It is a common practice for some electricians to work on energized circuits without PPE and without the proper permits. Both NASA and the contractor have policies that prohibit work on energized circuits, except for a few circumstances that were not applicable in this case. Although the contractor has adequate policies and procedures, implementation is weak or lacking. For example, LO\/TO training for contractor employees consisted of a contractor-provided \u201cElectric\u201d brochure handed out to each employee explaining the company's policy and procedure; the employee was expected to sign in the back of the brochure indicating that the employee had read the booklet.","Lesson ID":1368}
{"Driving Event":"A maintenance worker was ascending a fixed ladder when one of the tools he was carrying fell to the ground. The worker needed multiple specialty tools requiring multiple trips on the ladder to do some overhead work. In this particular case, the worker tried to carry all the tools he needed on one trip. Not all the tools were secured, such as in a tool bag or tied-off to the worker.","Lesson ID":1364}
{"Driving Event":"On July 10, 2003, a mechanical technician came into contact with an energized electrical circuit at the LC-39, Pad A Oxidizer Storage Area. A control cabinet had been removed and the circuit breaker feeding the bare conductors had been locked out in the electrical switchboard. Another contractor was modifying the electrical distribution system. The LOTO device was improperly removed and the circuit was later re-energized.","Lesson ID":1365}
{"Driving Event":"Background: In October 2001 the Payload Safety Review Panel (PSRP) conducted the phase III flight safety review for the Microgravity Science Glovebox (MSG) payload. During the safety review, the PSRP discovered that one of the MSG client payloads, a vibration attenuation device, did not address touch temperature hazards in the event of degradation or loss of an ISS critical service - cooling by the ISS Moderate Temperature Loop (MTL). The client payload was mounted inside the MSG work volume and utilized the ISS Moderate Temperature Loop (MTL) for cooling. The payload organization's (PO) thermal analysis did not cover the MTL failure scenario. The PSRP directed the PO to perform additional thermal analysis for the MTL failure case. The new analysis revealed that the client payload's baseplate could reach a maximum temperature of 68 deg Celsius (154 deg Fahrenheit) which exceeded the NSTS\/ISS 18798B Interpretation Letter (MA2-95-048) maximum allowable temperature (49 deg C) requirement for intentional crew contact. The client payload was therefore not \u201dsafe without services\u201d as required per the NSTS 1700.7B ISS Addendum. In order to protect the crew, the PO added a temperature strip and caution-warning sticker to its payload to serve as the second control of the touch temperature hazard. The MTL was the first control. With the addition of the temperature strip, the client payload now satisfied the NSTS 1700.7B ISS Addendum fault tolerance requirement for a critical hazard. The PO updated its standard payload hazard report to reflect the updated thermal analysis and new second control. In February 2002, the PSRP approved the client payload for flight (STS-111\/UF-2). Root Cause: An integrated approach to the analysis, which would have included the potential for failure of critical services from outside the payload, was not thoroughly performed. The client PO did not include loss of services (MTL degradation or failure) in their original thermal analysis. This omission left a potential touch temperature hazard uncontrolled after a single point failure.","Lesson ID":1367}
{"Driving Event":"Two (2) finger injuries illustrate an important principle for personal protection - when it should begin and end. A team member was climbing down off a flat bed truck when his wedding ring caught on a side railing. The second incident occurred when a team member who, in starting to survey a work area, suffered a cut when he placed his left hand on a box as he was stepping down a small step. In both of these cases, the team member luckily only received non-permanent minor injuries, even though it is easy to see that severe permanent injuries could have occurred. Both of these team members are known to consistently wear their Personal Protective Equipment (PPE) and gloves, but one employee had just taken his gloves off and in the other case the employee had not put his gloves on yet.","Lesson ID":1361}
{"Driving Event":"The Project was already in its implementation phase and had developed various methods and processes to identify and manage risks before the Agency's Continuous Risk Management (CRM) course was available. Additionally, based on its existing RM processes and experiences the Project felt that CRM was not suitable for their activities. In particular, it was felt the CRM \"quantitative\" risk assessments (such as weighted risk factors and discrete risk values) would have been forced, misleading and therefore undermining to the existing albeit \"qualitative\" process. Thus, while the Project did complete the CRM training, its formal structure was not incorporated into its RM processes.","Lesson ID":1363}
{"Driving Event":"Chandra silverized teflon MLI layers are degrading faster than pre-launch predictions, allowing the spacecraft to reach hotter temps earlier in the mission than predicted. In its first 3 years on orbit, the Chandra X-Ray Observatory (CXO) has witnessed higher than expected temperatures across the sun facing side of the vehicle. It is now believed that these elevated temperatures are due to the better insulating properties of its Multi Layer Insulation (MLI) and a higher than expected degradation of its Silverized Teflon thermal surfaces. It is believed that the Radiative Heat Transfer Efficiency (e*) has decreased by 0% to 20% of its predicted value and that the solar absorptance coefficient (a) has increased by 40% of predicted and could potentially reach a value of 0.6 (worst case) at 15 years. The original assumption was that the solar absorptance would not exceed 0.25. The most likely cause of the higher than expected degradation is due to the more severe CXO radiation environment. An extensive thermal analysis was performed to examine the thermal observations made by the Flight Operations Team. References 1, and 2, contain the results of the detailed study. History: In January of 2000, it was first noted by the Chandra Flight Operations Team that temperatures on the -Z side of the spacecraft were warming at a higher than expected rate. In the Fall of 2001, the Electron Proton Helium Instrument (EPHIN), Chandra's primary radiation sensor, housing temperature began a steep upward trend and, by December, was nearing the original survival limit of 86 deg F. Also, in the Fall of 2001, the -Z facing propulsion line temperatures began a steep upward trend nearing original qualification limits of 120 deg F. In addition, in January 2002, the Fine Sun Sensor bracket temperatures reached within a few degrees of original 5 year predictions. Both EPHIN and the Fine Sun Sensors are located on the top of the -Z spacecraft panel. In November 2001, TRW requested an analysis be performed to attempt to correlate the on-orbit data with the original models. There were three items that needed to be addressed: Reason for discrepancy with original predictions Understand mechanism of the temperature increase Be able to predict future temperatures, from which operational changes could be recommended The Chandra X-ray Observatory effectively has four types of thermal surfaces that degrade at different rates: 5-mil thick SST (MLI outer layers) Second-surface quartz mirrors (SSMs, on radiators) Mosaic of 2-mil thick SST and SSMs (Fine Sun Sensor Bracket) Mosaic of SSMs and 2-mil thick Second-Surface Silvered-FEP Teflon (SST) (EIO) 5-mil thick Second-Surface Silvered-FEP Teflon dominates the Chandra thermal design From 1974 through 1977 TRW performed extensive testing of metallized flexible materials in the space radiation environment. Testing simulated the Geosynchronous (GEO) environment in a vacuum chamber by bombarding samples with electrons, protons and ultra violet (UV) radiation simultaneously. Over time, absorptance degradation slows and was assumed to stabilize slightly after 4 years. Chandra was designed to the test data obtained from this study. Model Correlation: Thermal material solar absorptance is most accurately measured by optical methods. However, it can also be estimated by correlating thermal math models of an on-orbit system to flight data. To accomplish this, TRW Thermal engineers performed the following steps: Based on hand-calculations, a degraded absorptance value for each surface-type and for each data case (i.e. time-on-orbit) was selected. Environmental heating rates were then calculated for the Spacecraft and Telescope for each data case using TRASYS-format geometric math models. Next the predicted temperatures and heater duty-cycles were compared to the measured values to determine if the solar absorptance selected for each surface-type met the correlation goals: >90% of Spacecraft and propulsion temperatures agree within ~5\u00b0F >90% of Spacecraft heater duty-cycles agree within ~10% for each heater circuit >90% of Propulsion heater duty-cycles agree within ~20% for each heater circuit Telescope temperatures agree within ~2\u00b0F for Optical Bench Assembly (OBA) and Telescope Forward Thermal Enclosures (TFTE) heater zones Telescope heater powers agree within ~3% for aggregate of OBA and aft TFTE Where applicable, the MLI e*, radiative heat transfer efficiency, was adjusted to correlate both temperature and heater duty-cycle to the observed data. Finally, the process was iterated until all cases converged. Each case required several iterations to converge on the absorptance and e*. Correlation of the spacecraft model was quite good with 100% correlation within +\/- 11 deg F. A similar analysis was performed for the Telescope with results of 100% correlation within +\/- 2 deg F. After preliminary correlation of any changes in MLI e*, the solar absorptance values for the various types of thermal surfaces in the Spacecraft -Thermal Math Model (TMM) and Telescope-TMM were adjusted to the flight temperatures and heater powers to the flight data. Each data set was correlated to provide a relationship of surface solar absorptivity versus months on-orbit for each type of thermal surface. Many iterations were required for each data set to obtain the best fit. Results: Radiative Heat Transfer Efficiency - Using the Effective Emittance (e*) values correlated from the Chandra systems-level thermal vacuum test data, did not allow for an accurate correlation of any of the Spacecraft or Telescope on-orbit data sets. Changes in the MLI e* were necessary to correlated both temperature and heater duty-cycle to the observed data. An on-orbit reduction in MLI e* could be attributed to the significantly lower vacuum on-orbit (>10-12 Torr) which may allow for more complete venting of the MLI versus the partial venting achieved in the thermal-vacuum test pressure environment (>10-6 Torr). Spacecraft equipment panel MLI e* decreased by 20% Spacecraft structure MLI e* decreased by between 10% and 20% Spacecraft-propulsion MLI e* did not appear to change Telescope Optical Bench (OBA) MLI e* decreased by between 10% and 20% Solar Absorptance - Assessment of the correlated absorptance trends was that the degradation rates were faster than expected. The slope of the SST degradation trends are approximately parallel to the SST design-curve, their slopes appear to be decreasing (i.e. leveling off). Although the additional UV exposure will increase degradation, the additional +0.1 delta-absorptance is more than can be attributed due only to additional UV exposure. TRW- thermal engineering performed a simple exponential curve-fit to the data to extrapolate out to 5-years, then applied the tangential slope at the 5-year point out to 15-years. TRW Materials believes this extrapolation is conservative, and asserts that Teflon materials will not degrade to more than 0.60 absorptance. As a caveat, no reliable method exists to accurately extrapolate degradation trends out over a period of 6X the data domain. Conclusion: It is clear from this analysis that surface properties of Chandra MLI and Silverized Teflon are not as predicted at this point in the mission. The changes in surface properties are having a large impact on the thermal characteristics of the satellite, specifically in elevated temperatures across the vehicle. At this point, it is unclear as to the mechanism of the degradation although it almost certainly due to a combination of solar UV exposure and on-orbit radiation. It is assumed that the difference between the CXO orbital environment and that experienced at GEO is mainly responsible for the degradation seen to date. These values will continue to be trended and monitored for future predictions. References: For more specific data, the following two documents should be referenced. Chandra Life Extension Study, Thermal Control Subsystem, May 2002, P. Knollenberg Kodak alpha_study_slides_17jun2002-rev2a, June 2002, K. Havey","Lesson ID":1359}
{"Driving Event":"In early February 2003, JPL and NASDA reported gaps in Level 0 data products received from the Wallops and Alaska ADEOS-II Data Processing Systems. Gaps in the SeaWinds product were characterized by JPL to be intermittent in nature, of variable size, and located at irregular intervals in the data products. Reprocessing of the raw data by NASDA yielded 100% data recovery. Thus, while there was 100% data capture, data gaps were introduced by the DS resulting in approximately 8% data loss in the Level 0 product (i.e. 8 out of every 100 minutes of data was not included in the Level 0 product). These gaps were undetected at the processing station until reported by JPL and NASDA.","Lesson ID":1351}
{"Driving Event":"In early February 2003, JPL and NASDA reported gaps in Level 0 data products received from the Wallops and Alaska ADEOS-II Data Processing Systems. Gaps in the SeaWinds product were characterized by JPL to be intermittent in nature, of variable size, and located at irregular intervals in the data products. Reprocessing of the raw data by NASDA yielded 100% data recovery. Thus, while there was 100% data capture, data gaps were introduced by the DS resulting in approximately 8% data loss in the Level 0 product (i.e. 8 out of every 100 minutes of data was not included in the Level 0 product). These gaps were undetected at the processing station until reported by JPL and NASDA.","Lesson ID":1353}
{"Driving Event":"In early February 2003, JPL and NASDA reported gaps in Level 0 data products received from the Wallops and Alaska ADEOS-II Data Processing Systems. Gaps in the SeaWinds product were characterized by JPL to be intermittent in nature, of variable size, and located at irregular intervals in the data products. Reprocessing of the raw data by NASDA yielded 100% data recovery. Thus, while there was 100% data capture, data gaps were introduced by the DS resulting in approximately 8% data loss in the Level 0 product (i.e. 8 out of every 100 minutes of data was not included in the Level 0 product). These gaps were undetected at the processing station until reported by JPL and NASDA.","Lesson ID":1352}
{"Driving Event":"In early February 2003, JPL and NASDA reported gaps in Level 0 data products received from the Wallops and Alaska ADEOS-II Data Processing Systems. Gaps in the SeaWinds product were characterized by JPL to be intermittent in nature, of variable size, and located at irregular intervals in the data products. Reprocessing of the raw data by NASDA yielded 100% data recovery. Thus, while there was 100% data capture, data gaps were introduced by the DS resulting in approximately 8% data loss in the Level 0 product (i.e. 8 out of every 100 minutes of data was not included in the Level 0 product). These gaps were undetected at the processing station until reported by JPL and NASDA.","Lesson ID":1356}
{"Driving Event":"In early February 2003, JPL and NASDA reported gaps in Level 0 data products received from the Wallops and Alaska ADEOS-II Data Processing Systems. Gaps in the SeaWinds product were characterized by JPL to be intermittent in nature, of variable size, and located at irregular intervals in the data products. Reprocessing of the raw data by NASDA yielded 100% data recovery. Thus, while there was 100% data capture, data gaps were introduced by the DS resulting in approximately 8% data loss in the Level 0 product (i.e. 8 out of every 100 minutes of data was not included in the Level 0 product). These gaps were undetected at the processing station until reported by JPL and NASDA.","Lesson ID":1349}
{"Driving Event":"In early February 2003, JPL and NASDA reported gaps in Level 0 data products received from the Wallops and Alaska ADEOS-II Data Processing Systems. Gaps in the SeaWinds product were characterized by JPL to be intermittent in nature, of variable size, and located at irregular intervals in the data products. Reprocessing of the raw data by NASDA yielded 100% data recovery. Thus, while there was 100% data capture, data gaps were introduced by the DS resulting in approximately 8% data loss in the Level 0 product (i.e. 8 out of every 100 minutes of data was not included in the Level 0 product). These gaps were undetected at the processing station until reported by JPL and NASDA.","Lesson ID":1357}
{"Driving Event":"In early February 2003, JPL and NASDA reported gaps in Level 0 data products received from the Wallops and Alaska ADEOS-II Data Processing Systems. Gaps in the SeaWinds product were characterized by JPL to be intermittent in nature, of variable size, and located at irregular intervals in the data products. Reprocessing of the raw data by NASDA yielded 100% data recovery. Thus, while there was 100% data capture, data gaps were introduced by the DS resulting in approximately 8% data loss in the Level 0 product (i.e. 8 out of every 100 minutes of data was not included in the Level 0 product). These gaps were undetected at the processing station until reported by JPL and NASDA.","Lesson ID":1350}
{"Driving Event":"In early February 2003, JPL and NASDA reported gaps in Level 0 data products received from the Wallops and Alaska ADEOS-II Data Processing Systems. Gaps in the SeaWinds product were characterized by JPL to be intermittent in nature, of variable size, and located at irregular intervals in the data products. Reprocessing of the raw data by NASDA yielded 100% data recovery. Thus, while there was 100% data capture, data gaps were introduced by the DS resulting in approximately 8% data loss in the Level 0 product (i.e. 8 out of every 100 minutes of data was not included in the Level 0 product). These gaps were undetected at the processing station until reported by JPL and NASDA.","Lesson ID":1354}
{"Driving Event":"In early February 2003, JPL and NASDA reported gaps in Level 0 data products received from the Wallops and Alaska ADEOS-II Data Processing Systems. Gaps in the SeaWinds product were characterized by JPL to be intermittent in nature, of variable size, and located at irregular intervals in the data products. Reprocessing of the raw data by NASDA yielded 100% data recovery. Thus, while there was 100% data capture, data gaps were introduced by the DS resulting in approximately 8% data loss in the Level 0 product (i.e. 8 out of every 100 minutes of data was not included in the Level 0 product). These gaps were undetected at the processing station until reported by JPL and NASDA.","Lesson ID":1355}
{"Driving Event":"Most of the components that comprise the NASA Ground Network that supports the ADEOS-II mission were provided to the NGN as contributions from operational entities under the management of various NASA organizations. This approach presented both opportunities and challenges during the ADEOS-II NGN development and early operations. The one lesson learned in this regard with respect to component re-use is summarized below. It should be noted that ADEOS-II is a international partner mission, with the Japanese Space Agency (NASDA) as the mission lead. NASA provided NGN ground system support through an MOU with NASDA.","Lesson ID":1347}
{"Driving Event":"The Project was required to develop and deliver a major scientific instrument for a project and had used both research grants and contracts to acquire services\/products from their vendors. The vendor funded through a grant, which was closely aligned with a University, was paid up front and did not have any other risk or incentive to meet the Project's requirements. The vendor's priorities changed and the Project had no recourse or control over them. As a result the hardware being funded through the grant was delivered years late. On the other hand, the Project also had a formal contract with a different vendor, not associated with a research institution or University, to deliver another piece of hardware. This procurement gave the Project options to deal with vendor non-performance. In addition, the vendor was a relatively small business with lots of motivation to establish credibility with its customers. As a result of this, the products delivered by this vendor were on time, on budget, and within all technical requirements.","Lesson ID":1343}
{"Driving Event":"The Project underwent several significant transitions including going from a proposal team to an implementation\/project team; Principal Investigator (PI)lead academic or science team to a Project Manager (PM)lead hardware development\/delivery team; and PM to PM. Within these transitions the Project struggled with two issues that were major obstacles to implementing a \"project\" oriented environment. First, the Project had difficulty recognizing the incoming PM as an authority over the PI, who in this case was a well-known and respected scientist that germinated the Project concept. The Project team's loyalty to the PI coupled with the abruptness with which PM's were assigned lead the project team to view the incoming PMs as outsiders unfamiliar with the Project's purpose or style who insisted on unfamiliar and time-consuming operating requirements\/processes. Second, the Project, which had originally been a small scientific research team, had difficulty establishing and applying formal\/rigid project management processes. Thus, the inadequate PM involvement during the proposal stage coupled with the un-facilitated\/unmanaged transitions never allowed the team to mature into an integrated project. The result was that the Project's initial planning was off (as described in a companion LL on cost estimating) and the subsequent attempts to redirect it through formal PM processes were unsuccessful.","Lesson ID":1345}
{"Driving Event":"The purpose of the Standard Autonomous File Server (SAFS) is to provide automated management of large data files without interfering with the assets involved in the acquisition of the data. It operates as a stand-alone solution, monitoring itself, and providing an automated level of fail-over processing to enhance reliability. The successful integration of COTS products into the SAFS system has been key to its becoming accepted as a NASA standard resource for file distribution, and leading to its nomination for NASA's Software of the Year Award in 1999.","Lesson ID":1346}
{"Driving Event":"Most of the components that comprise the NASA Ground Network that supports the ADEOS-II mission were provided to the NGN as contributions from operational entities under the management of various NASA organizations. This approach presented both opportunities and challenges during the ADEOS-II NGN development and early operations. The one lesson learned in this regard with respect to managing the contribution of system components by various organizational entities is summarized below. It should be noted that ADEOS-II is a international partner mission, with the Japanese Space Agency (NASDA) as the mission lead. NASA provided NGN ground system support through an MOU with NASDA.","Lesson ID":1348}
{"Driving Event":"On March 20, 2003, a 128,500 lb. LOX dewar was being transported from the Kennedy Space Center (KSC) to the Cape Canaveral Air Force Station (CCAFS). A commercial carrier\u00bbs trailer was used for the operation. The particular trailer used was selected by the commercial carrier. The commercial carrier was a second-tier subcontract to the NASA prime contractor activating the Advanced Technology Development Center at Complex 20 on CCAFS. During the move, the dewar, trailer, and tractor rolled to the left, with the dewar ultimately breaking free from the trailer and coming to rest in the ditch. The dominant root cause of the mishap was the selection and use of a trailer which was undersized for the application. The trailer was overloaded approximately 200%.","Lesson ID":1339}
{"Driving Event":"Space Shuttle Main Engine (SSME) test 901-0674 was conducted on November 6, 1991 at 11:31 am CDT. The scheduled 400 second test was terminated by the Command and Data Simulator (CADS) at engine start plus 3.72 seconds when the Low Pressure Fuel pump (LPFP) discharge pressure sensor was disqualified by exceeding its maximum qualification limit of 300 psia. The controller responded by issuing a Major Component Failure (MCF) which initiated the CADS cutoff. The main objectives of test 901-0674 were: reacceptance of flight engine 2032 with replaced oversized piston ring seal wave spring, facility flow meter calibrations, and the greenrun of the following flight hardware: Controller U\/N F48, High Pressure Fuel Turbopump U\/N 2226, Low Pressure Fuel Turbopump U\/N 4018, Low Pressure Oxygen Turbopump U\/N 2035, and Chamber Coolant Valve Actuator (CCVA) S\/N 037-71008. The propellant system chilidown and prestart engine conditioning phase of the test was normal. Post test inspections indicated no external engine or facility damage. Internal borescope inspections revealed heavy erosion of the High Pressure Fuel Turbopump (HPFTP) first stage nozzle and turbine blades. No other internal damage was noted. Post test inspection of the CCV\/CCVA assembly revealed the coupler which links the CCVA to the CCV was missing. Inspection of the CCV also revealed the valve to be fully closed throughout the test.","Lesson ID":1340}
{"Driving Event":"On Monday, April 15, 2002 at approximately 5:45 PM the following incident occurred on the Stennis Space Center A1 test stand, level 5 upper engine work deck. Subsequent to the removal and replacement of a High Pressure Fuel Pump the upper engine deck extension piece was rolled away from the main upper engine deck with the pump lifting\/handling device still on the upper engine deck extension piece. The pump lifting device fell off the upper engine deck pinning a quality inspector between it and the upper engine deck handrail. The arm of the pump lifting\/handling device was moved enough for the employee to be moved away and the deck was cleared. The device was secured in the as-rested position and the deck was cordoned off. The employee was able to walk on his own to inside the test stand. The employee was transported to a local hospital for an examination as a precaution. Photographs were taken of the area and equipment involved (contact Michael McDaniel, 228-688-2233). An investigation\/preventive action team was formed by management on the morning of Tuesday, April 16, 2002 to investigate, find the root cause, and make corrective action recommendations. The A1 test stand had been recently reconfigured from a previous test program to a different test program after a 5 year period. The test team had moved from the A2 test stand to the A1 test stand. The test team did not feel this was a factor due to the similarities between the two test stands. The normal configuration for all pump removals is to use a roll-around work deck extension piece secured to the main work deck via turnbuckles.","Lesson ID":1338}
{"Driving Event":"The propellant tanks on the Genesis spacecraft were filled with isopropyl alcohol (IPA) prior to modal and acoustic vibration testing in order to obtain the proper spacecraft dynamic response. IPA was used as a referee fluid in place of the hydrazine propellant because of its similar mass, as well as for safety reasons. When the Genesis tanks were drained about ten days later, levels of particulate and non-volatile residue (NVR) were found that significantly exceeded the cleanliness specification. Both the particulate levels and the NVR were brought back into specification by filling the tank with IPA and draining it several times, followed by vacuum drying. A cleanliness demonstration test was subsequently performed on an Atlas Centaur propulsion system hydrazine tank that was of a design similar to Genesis'. The Atlas tank was also found to be out-of-specification with respect to particulate contamination. After the tank was exposed to the IPA cleaning fluid for about a day, it was also found to be out-of-specification on NVR. A total of 16 Atlas tanks were subsequently returned to the vendor. The Genesis tank is a titanium sphere with a diaphragm fabricated from AF-E-332 rubber material. The diaphragm is incorporated to ensure gas-free propellant expulsion. When empty, the diaphragm conforms to the lower wall of the tank. As the tank is filled, the diaphragm reverses toward the upper dome of the tank. The tank is cleaned at the piece-part level and subjected to a final cleaning at the assembly level. The ability of cleaning fluids to remove particulate from the assembled tank during this final cleaning may have been limited by the fact that the vendor used only 1 liter of IPA for this procedure. Furthermore, the vendor has asserted that transportation of a \"clean\" tank may result in particulates being released from the faying surfaces near where the diaphragm is attached to the wall and\/or in generation of particulates due to rubbing of the diaphragm on the tank wall. It is likely that the out-of-specification particulate seen in the Genesis and Atlas tanks was a result of imperfect cleaning and\/or this self-generation mechanism. Further materials testing verified that the NVR contamination was a substance leaching out of the rubber diaphragm material following prolonged exposure to IPA. This AF-E-332 diaphragm material has been used in this application since 1974, and contact with hydrazine does not produce degradation of the material or performance problems in propulsion systems. Exposure to IPA for periods of over 4 hours, however, can produce excessive NVR. Similar tank vendor cleaning processes were used on the Deep Impact project, but it was found that conservative propulsion system filter sizing mitigated the threat of high particulate levels. References: Genesis Tank NVR Contamination Interim Report, (contractor document), September 15, 2000. Additional Key Words: cleanliness verification, decontamination, environmental test, alcohol flush","Lesson ID":1334}
{"Driving Event":"During integration of the Genesis spacecraft, many flight and ground support equipment (GSE) cables were found to be electrically incompatible with spacecraft systems although they matched the cable wiring diagrams. Several times, testing had to be halted and the system analyzed for possible electrical overstress caused by power having been applied to the wrong pins. Eventually, spacecraft testing was stopped long enough to perform a pin-by-pin comparison of the cable wiring diagrams to the latest unit and system schematics. Once this was completed, errors were identified, the cables were reworked, and the problems were resolved. The accuracy of cable wiring diagrams was a continuing problem on Genesis. Typically, cables are built by cable harness shops to the specifications provided by cable drawings and cable wiring diagrams. Cable design and fabrication may take place concurrently with the design of spacecraft black boxes. As a system design evolves and pin-out requirements change, there is a time lag before the interface control drawing (ICD) is updated and the changes flow back to the cable design and documentation. Should the cables be built to an outdated document, the first powering of a given spacecraft may cause major damage. Since the connectors still mate with their assigned receptacles, the electrical mismatches may not be apparent. Validating the cable harness configuration against unit and system schematics is a very time-consuming activity. If it is delayed until integration and test has already commenced, the task can impact the project schedule. References: JPL Lesson Learned No. 1201, \u201cFlight Hardware Damage Due to Inadequate Planning and Insufficient QA Involvement,\u201d April 25, 2002. JPL Lesson Learned No. 0573, \u201cPower Bus\/GSE Sneak Paths May Energize Spacecraft in the Ground Test Environment,\u201d October 22, 1997.","Lesson ID":1336}
{"Driving Event":"Flight qualification testing of the Mars Exploration Rover 2 (MER 2) Ultra High Frequency (UHF) Transceiver in duplex mode, utilizing an air link, failed to attain carrier lock in a JPL screen room. The duplex mode for MER 2 had been successfully tested earlier for EMI\/EMC in the same screen room via a hardline link. This extra air link test was added as an afterthought in accordance with the test principle of \"test-as-you-fly.\" Many staff hours were spent trying to isolate the failure cause, which was finally traced to RF reflections into the UHF receiver from the non-anechoic walls of the test chamber. This failure mode was not seen during the 1990s test of the Pathfinder Rover because (1) Pathfinder used less output power than MER and (2) the Pathfinder Rover was small enough to fit into an existing test chamber lined with RF energy absorbing material. This problem of RF reflections would not occur during operations on Mars, but the incident illustrated the need for JPL to utilize an appropriate test chamber lined with ferrite anechoic absorbing material. The incident was a test facility failure -- not a system failure -- and it did not damage flight hardware. References: Problem\/Failure Report No. Z78182, Jet Propulsion Laboratory, November 4, 2002. Additional Key Words: test-induced failure, radio frequency test, Radio Frequency Subsystem, communications, RF leakage","Lesson ID":1335}
{"Driving Event":"The Physics of Colloids in Space (PCS) experiment was launched on ISS Flight 6A in April 2001, was activated in EXPRESS Rack 2 on May 31, 2001, and was successfully operated on the International Space Station (ISS) until February 24, 2002. On February 24, 2002, at the onset of a scheduled operational run on ISS, the PCS flight system computer (within the PCS Avionics Section) failed to boot up. On-orbit recovery efforts were undertaken but were unsuccessful. The Avionics Section was removed and brought back on ISS Flight UF-2.","Lesson ID":1331}
{"Driving Event":"The Physics of Colloids in Space (PCS) experiment was launched on ISS Flight 6A in April 2001, was activated in EXPRESS Rack 2 on May 31, 2001, and was successfully operated on the International Space Station (ISS) until February 24, 2002. On February 24, 2002, at the onset of a scheduled operational run on ISS, the PCS flight system computer (within the PCS Avionics Section) failed to boot up. During the March 20, 2002 attempt by the Expedition 4 crew to access and modify corrupted computer settings, a very complex procedure, the Payload Developer (PD) had no direct contact with the crew member, no ISS video services, and heard very little crew positive reporting.","Lesson ID":1329}
{"Driving Event":"Differential electrical charging of the spacecraft surface due to its interaction with charged plasma particles may present unrecognized hazards with non-conductive surface materials such as non-metallic and ceramic-metallic composites. Although graphite\/polymer composites were thought to be immune to space plasma charging because the material is electrically conductive, it may actually retain a significant charge. Laboratory testing with multi-kV electron beams has found substantial charging to occur. Spacecraft structures made of graphite\/polymer composites have proven capable of significant weight savings while maintaining structural performance requirements. Their excellent thermal performance has led to applications in spacecraft solar arrays, radiator panels, space telescope structures, and mirrors. For these reasons, this material is widely used in the structural components of the Space Interferometry Mission (SIM) spacecraft. A surface resistance measurement of graphite composites made using an ohmmeter and flat probes would likely show zero resistance. The individual graphite fibers that penetrate the surface provide the conductive path between the probes. However, the non-conductive cyanate ester resin can be shown to accumulate voltage potentials in excess of 2000 volts when exposed to a wide-angle electron beam. Preferential charging occurs at locations within the composite matrix where the weave permits the resin to pool. References: A flash animation of spacecraft charging and its effects may be found at http:\/\/holbert.faculty.asu.edu\/eee460\/spacecharge.html Additional Key Words: spacecraft materials, bulk dielectric charging, radiated electromagnetic interference, conducted electromagnetic interference, internal electrostatic discharge, IESD, conductive surfaces, dielectric materials","Lesson ID":1330}
{"Driving Event":"The Physics of Colloids in Space (PCS) experiment was launched on ISS Flight 6A in April 2001, was activated in EXPRESS Rack 2 on May 31, 2001, and was successfully operated on the International Space Station (ISS) until February 24, 2002. On February 24, 2002, at the onset of a scheduled operational run on ISS, the PCS flight system computer (within the PCS Avionics Section) failed to boot up. On-orbit recovery efforts were undertaken but were unsuccessful. The Avionics Section was removed and brought back on ISS Flight UF-2.","Lesson ID":1333}
{"Driving Event":"The Physics of Colloids in Space (PCS) experiment was launched on ISS Flight 6A in April 2001 was activated in EXPRESS Rack 2 on May 31, 2001, and was successfully operated on the International Space Station (ISS) until February 24, 2002. On February 24, 2002, at the onset of a scheduled operational run on ISS, the PCS flight system computer (within the PCS Avionics Section) failed to boot up. Once the Expedition 4 crew member had unsuccessfully executed the procedures on March 20, 2002, there was no discussion held with him to ask his opinion on the procedure and if he felt it worthwhile to retry the procedure. Also, the decision by the Payload Operations Director to terminate the recovery procedures and tear down the setup came quickly, with very little room for the PD to appeal. The Project found during post-flight face-to-face discussions with the astronaut that he would have been willing to retry the procedures when he had time later.","Lesson ID":1332}
{"Driving Event":"The KSC provided Rack Insertion Device (RID) weight and CG end effector interferred with the MicroGravity Science Glovebox (MSG) payload rack umbilical launch restraint. Due to the interference, the MSG rack could not be installed onto the end effector and therefore delayed installation into the Multi-Purpose Logistics Module (MPLM), until the interference could be resolved.","Lesson ID":1323}
{"Driving Event":"Unclear what the PD did to the hardware due to lack of communication and\/or inadequate documentation provided to KSC project management. Numerous KSC PRACA reports were generated as a result of not knowing what the PD did during off-line operations.","Lesson ID":1325}
{"Driving Event":"Due to the number of deviations (changes) and hardware and software complexities within the procedures, the practitioners' written testing procedures constantly change until it is rather difficult for the next shift practitioners to comprehend practical knowledge of the task.","Lesson ID":1327}
{"Driving Event":"During Payload test and checkout System (PTCS) testing of flight hardware, steps in the testing procedure to verify a certain configuration was inconsistent with actual payload labeling.","Lesson ID":1328}
{"Driving Event":"Due to the scheduling impact, based on the Microgravity Science Glove Box (MSG) payload rack requiring on-line to off-line support by the payload provider, there was a potential that testing in the Payload Test and Checkout System (PTCS) would slip other payload missions from testing in PTCS.","Lesson ID":1324}
{"Driving Event":"During a materials science investigation process run within the MSG on-board ISS on 7\/23\/02, the SUBSA Eurotherm Controller (Zone 1) on the Process Control Module (PCM) would not take a command to raise the Thermal chamber main heater setpoint above 825 degrees C. Files were uplinked to query setpoint limits in the Eurotherm Controller; a local Mod Bus setpoint limit of 825C was found and confirmed why the anomaly occurred. SUBSA's Investigation Control Software (ICS) was reconfigured to route Zone 1 setpoint temperature commands to Mod Bus 160 instead of Mod Bus 24 in the Eurotherm Controller. The Mod Bus 160 command address does not have a local setpoint limit. The desired setpoint of 845 degrees C was properly configured. After these steps, no further problems were encountered prior to the completion of all on-board experiment processing.","Lesson ID":1319}
{"Driving Event":"An onsite maintenance and operations contractor was tasked to erect scaffolding inside of a wind tunnel test section so that a heavy gas door seal could be replaced. The test section floor is level until it opens into the tunnel where the floor slopes downward. The portion of tunnel that slopes down from the test section is called the contraction wall. One end of the scaffold had to be placed on the down slope. In order to secure the scaffold, three pads were welded onto the test section floor which had a pivoting vertical tube attached to it. The vertical scaffold legs were slid into the tubes. Safety straps were attached to the test section floor because an outrigger section, which extended out over the contraction wall, was installed on the main scaffold. After the completion of work, the onsite maintenance and operations contractor began to take down the scaffold. Four workers were tasked to disassemble the scaffold. Due to the uniqueness of the scaffolding arrangement, the workers were told to wait for their supervisor to coordinate the effort. The workers took it upon themselves to disassemble the scaffold. During the disassembly, with the outrigger section still in place, the safety straps were removed. Two employees were on the scaffold when the straps were removed. As they continued to disassemble the scaffolding, the center of gravity shifted over the outrigger. This caused the scaffolding to topple over since the straps had been removed. Both employees rode the scaffolding to the bottom of the contraction wall. One employee sustained no injuries. The second employee told his co-workers to call 911. He was taken to a local hospital and released with minor injuries. All employees involved had received training on the assembling and disassembling of scaffolding. The crew lead was one of the employees working on the scaffolding. Under normal conditions, the crew lead would supervise the work, but the crew supervisor told the crew lead to not begin disassembly until he was present to supervise the work. The crew lead ignored this request and began disassembly. Because the crew lead was actively involved in the take down, he did not see his error in removing the straps. He only saw the straps as being in his way of removing scaffolding pieces.","Lesson ID":1318}
{"Driving Event":"Electrostatic discharge (ESD) remains an insidious threat to the integrity of flight hardware despite extensive NASA and industry experience with controlling ESD and its effects. ESD-induced damage during the latter stages of spacecraft development (e.g., system integration and test or launch vehicle integration) may be difficult to detect\/analyze and expensive to repair. While the following NASA lessons learned do not define the total magnitude of the industry wide problem, they illustrate a sample of ESD-related issues: On two occasions during integration and test of Mars Exploration Rover (MER), a braided ground strap being dragged across the floor contacted a facility power outlet, causing visible sparks and partial melting of the ground straps and power connectors. [LLIS # 1372] Nitrogen tetroxide flowing through a flex line during Galileo spacecraft propellant loading caused an electrostatic discharge that perforated the flex line. The resultant leak of this highly toxic and corrosive substance posed significant risk to launch personnel and flight hardware. [LLIS # 0217] The fire and destruction of a Pershing II stage I missile motor was attributed to unreliable tests that indicated that the solid propellant was not sensitive to ESD. [LLIS #0328] Discrepancies reported with shipment of Robotic Work Stations pointed out the need for formal handling, packaging, and shipping processes to preclude improper ESD packaging. [LLIS #1211] Electrostatic discharge from an ungrounded radiation \"spot\" shield may have caused an anomaly during the Voyager I Jupiter encounter. This prompted a recommendation that metal spot shields and other metal masses on circuit boards should be grounded even if they are inside equipment housings. [LLIS #0384] After an integrated circuit was damaged during installation of a discrete capacitor, it was determined that capacitors can accumulate a residual charge through normal handling and storage that is sufficient to destroy an integrated circuit. [LLIS #0297] The continually decreasing feature size within integrated circuits makes modern electronic devices increasingly susceptible to ESD induced damage during handling and use. In addition, the effectiveness of ESD protection circuits tends to decrease with decreasing device dimensions. [LLIS # 1315] During receiving activities, a spark was observed upon the attachment of a facility ground strap to the Mars Exploration Rover (MER) Rover Electronics Module (REM). This re-emphasized that ESD is an issue cutting across JPL hardware activities (Reference 1). [LLIS # 1371] Some modern materials (e.g. certain composites) thought to be conductive have instead been found to be susceptible to surface charging. Use of such materials can allow ESD energy to be transmitted internally from exterior spacecraft surfaces and damage flight electronics. [LLIS # 1330] References: (1) Jet Propulsion Laboratory Corrective Action Notice No. Z77277, August 27, 2002. Additional Key Words: ESD Control Plan, ESD requirements, ESD sensitive devices, ESD sensitivity, personnel safety, system safety","Lesson ID":1317}
{"Driving Event":"In a complex rover separation event after a Mars landing, pyrotechnic devices are used to release the Mars Exploration Rover (MER) Warm Electronics Box (WEB) from the lander basepetal. If the separation does not occur, the rover does not release and cannot escape the lander. The WEB design called for each separation nut to be free and un-restrained after release, without considering any possible impact damage. The 8 \u201csep nuts\u201d on each rover were fired successfully during system test. Each was rapidly expelled from the basepetal to strike a rock protection cup located 7 mm beneath the sep nut. [D] In testing of both MER1 and MER2, the impact resulted in severe damage to the pyro cables attached to the bottom of the nuts. The pyro cabling was damaged sufficiently to cause multiple shorts to chassis that could have over-stressed the pyro system electronics. Redesign efforts to apply padding to the sep nut backshells were complicated by the configuration of the adjacent hardware. References Jet Propulsion Laboratory Problem\/Failure Report No. Z78969, January 9, 2003. https:\/\/problemreporting.jpl.nasa.gov\/cgi-win\/VB2FPDDE.exe?T: \\PFOCPROD\\PROJECTS\\WEBALL\\ALL_PVB.INI~s3 \u201dWEB Separation Pyro Cable Protection Redesign Test Results,\u201d JPL document D-25477, February 3, 2003. Additional Key Words: pyro test, ATLO, structural interference, structural modeling, deployment mechanisms, test induced damage, system safety","Lesson ID":1360}
{"Driving Event":"Non-flight test heaters located on each of the three non-flight, inert TIRS (Transverse Impulse Rocket System) motors were powered during system thermal test of the Mars Exploration Rover (MER 1) to accelerate return of the test chamber to ambient conditions. Post-test inspection of the TIRS assembly revealed that the heaters had burned through the heater Kapton insulation (Figure 1) and severely damaged the surrounding flight MLI (multi layer insulation) blanket (Figure 2) on all three units. The failure was caused by the lack of a current limit specification on the controlling GSE (ground support equipment) power supplies. Test temperature sensors were located 4-5 inches from the heater; this was too far away to detect the high temperature due to the low thermal conductance of the TIRS motor case. [D] The only flight hardware damaged by the test heater failures were the three flight TIRS MLI thermal blankets. These were refabricated because failure to correct the damage might have been mission catastrophic. References JPL Problem\/Failure Report No. Z78893, December 30, 2002. Eric Sunada, Inert TIRS Motor Test Heater Failures during System Thermal Test 1, JPL internal memorandum 353\/ES\/02-047.MER, December 26, 2002. Additional Key Words: system test, integration and test, ATLO, overheating, test-induced failure, test damage, overtest, overtemperature, current-limiting, excess current, thermal-vacuum test, T-V test, heat transfer","Lesson ID":1358}
{"Driving Event":"Parts were unexpectedly ejected with explosive force during a test of the Mars Exploration Rover (MER) dynamic test model (DTM), shown in Figure 1. The MER High Gain Antenna (HGA) pyrotechnic release mechanism was fired in order to assess the shock loading on adjacent Rover components. Two NASA standard initiators (NSIs) were mounted on the pin puller (Figure 2) that releases the HGA for deployment. When they were fired, the pin impacted the retaining cap of the puller housing, shearing the threads holding the aluminum cap to the aluminum housing (Figure 3). This caused both the pin and cap to be ejected explosively from the back of the mechanism. [D] The device failure was attributed to shearing of the end cap and\/or housing threads, also shown in Figure 3. It is possible that thread damage occurred in the failed device during its initial firing in an earlier MER pyroshock test and\/or during the refurbishment process. This device was refurbished by disassembly and ultrasonic cleaning, and was reassembled without a formal written procedure or mandatory QA inspection. The design of the failed pin puller differs from that of the MER flight design, which uses a higher strength aluminum alloy for the housing and a stainless steel end cap. [D] The ejected cap and pin ricocheted off the Pan Cam Mast Simulator and then gouged the concrete clean room wall. Although only critical test personnel were present in the clean room during this hazardous test and they complied with existing safety procedures, they were narrowly missed by these projectiles. No one was injured, though the Pan Cam Mast Simulator suffered superficial damage. Also, this anomaly released combustion products, which damaged a strip heater on the HGA, requiring replacement of the heater. A failure of this nature during flight operations could lead to significant loss of mission objectives. References: JPL Problem\/Failure Report No. Z76911, July 26, 2002. JPL Incident Report, quotMars Exploration Rover (MER) Project Design Test Model (DTM) Rover, Pin Puller Incident,quot Ronald T. Welch, July 2002. Additional Key Words: pyrotechnic shock test, test mishap, test failure, test hazard, pyro hazard, system safety, occupational safety","Lesson ID":1316}
{"Driving Event":"Electrostatic discharge (ESD) susceptibility remains a pressing reliability issue in integrated circuit (IC) design. The continually decreasing feature size associated with modern electronic devices now makes them increasingly prone to ESD induced damage during handling and use. To obtain greater processing speed and to pack more circuitry into small packages, average feature sizes for IC packages today are about half the size of those in 1995, and they are expected to decrease by 50% again by 2007. As the size of features and the width of conductors shrink, the decreased spacing in the circuitry reduces electrical isolation. A discharge of only a few volts can produce enough heat to burn through microelectronic features on the order of 0.1 micron. In addition to microcircuits, many discrete semiconductor devices (e.g., transistors, diodes) are vulnerable to voltages that are much lower than human sensory perception thresholds (~3,000 volt static charge). The ESD control measures that are in general use by industry involve (1) preventing ESD from occurring by employing proper grounding and handling procedures during manufacturing and use, and (2) installing on-chip ESD protection circuitry. However, the effectiveness of ESD protection circuits also tends to decrease with decreasing device dimensions. Industry is employing \"ESD event modeling\" and associated physics-of-failure analyses during the design process for development of more robust ICs. References: \"JPL Standard for Electrostatic Discharge (ESD) Control\" (D-1348), Rev. E, June 20, 2001. Lesson Learned No. 0297, \"Integrated Circuit Damage due to Capacitor Residual Charge.\" Additional Key Words: integrated circuit reliability, ESD sensitive devices, electrical overstress (EOS), EEE parts, electronics packaging, parts selection, approved parts list, fault protection, ESD Control Plan, ESD requirements","Lesson ID":1315}
{"Driving Event":"The Project was responsible for developing and operating a flight vehicle that would demonstrate several new technologies and capabilities. While the new technologies and capabilities being incorporated into the vehicle had been tested and analyzed independently and separately using wind tunnel and computational methods, it would be the first time they would be integrated together. Therefore, the Project had a significant level of risk characteristic of flight demonstration\/test activities. However, several factors that can best be described as a \"risk and safety culture\" ensured the Project addressed risks appropriately. These factors were: The Project team had lots of experience with high-risk flight test programs. The Project decided to build two fully functional test vehicles as opposed to one with built in redundancy (note: those items deemed critical to safe operation were redundant) but treated each vehicle like it was a unique irreplaceable asset. The Project took pride in delivering two fully functional vehicles and sought risk mitigation solutions independent of having two vehicles prior to solutions dependant on a two asset Project. Thus, in terms of developing risk mitigation strategies, the solution for loosing some or all capability in the first vehicle, namely \"having a backup or second vehicle,\" was considered last. To further reduce risk, as well as cost and schedule, the Project elected to control the vehicles remotely. However, the team took great pride in demonstrating the new flight new technologies and capabilities safely such that their accomplishments could be transferred into new flight vehicle designs. Thus, the Project treated each flight vehicle as a member of the team and was committed to their safety as if they were manned. All Project members viewed risk management as their own responsibility and took measures to identify and minimize risk.","Lesson ID":1312}
{"Driving Event":"The project, which focused on technology demonstration, needed to decide whether to use a full size or scale model aircraft to achieve its research objectives. The decision would determine the complexity, cost, time, and test procedures necessary to achieve the objectives. The project used several factors to determine the final outcome. Several of particular importance were: Most of the technology had been researched and developed in previous and extensive bench or wind-tunnel studies. The project would only be integrating them into a flight vehicle A manned flight vehicle was not a requirement The project would be tested in a remote and unpopulated flight test area","Lesson ID":1290}
{"Driving Event":"In order to mitigate the risk associated with flying a high-performance technology demonstrator, the Project chose to build two aircraft (a primary and a backup) and operate them remotely. While this approach reduced the risk to an acceptable level with respect to the Project's established risk threshold, upper management and other stakeholders remained uncomfortable. Thus, the Project's risk management approach had not been communicated to all stakeholders in sufficient detail, especially with respect to one of its most significant risk. Therefore, a decision was made to add a parachute recovery system to the aircraft that could operate autonomously or remotely in case standard flight controls were lost. Unfortunately, the decision to incorporate the parachute recovery system was made after the aircraft design was baselined and had to be \"reverse engineered\" to fit into a bay on the aircraft. This resulted in an increase in size, weight, and development time of the aircraft.","Lesson ID":1293}
{"Driving Event":"Some unanticipated modifications were necessary to some heritage hardware and software.","Lesson ID":1308}
{"Driving Event":"The following occurred at a non-NASA facility and is provided as a courtesy because what happened here can happen anywhere. A pedestrian was walking within a marked walkway adjacent to a material handling staging area and a roadway outside a building. The forklift was traveling in the same direction and was in the process of traversing from the roadway, across the pedestrian walkway, to the material handling staging area. The pedestrian was struck and his right leg was severely injured. The investigation determined the equipment operator was traversing his forklift across the pedestrian walkway into the Material Handling staging area to pick up freight. As he made a shallow right turn, he heard a thump, saw the pedestrian falling and stopped immediately. The operator stated he never saw the pedestrian prior to striking him with the forklift. Key Findings The forklift had no mechanical problems and the speed control governor was functioning properly. The forklift was traveling below the posted speed limit of 15 mph. There is no indication that the forklift operator was physically impaired. The pedestrian was within the marked pedestrian walkway when he was struck. Weather and pavement conditions were not factors. When a forklift makes a shallow turn across an adjacent walkway the risk of a collision with anyone or anything in the pedestrian walkway is increased. In the incident area, the adjacent and parallel walkway configuration created a situation where pedestrians were in a moving blind spot and could be obscured from the operator's field of view for a prolonged period of time. The configuration of the forklift cab and lifting mast obstructed the operator's field of view between 9 and 18 degrees on either side of the forklift centerline: at 25 feet, the blind spot is 4 feet wide on each side. The position and motion of pedestrians could extend the amount of time they are in the operator's blind spot. See figure 1. In an industrial environment pedestrians need to be aware of their surroundings at all times, even when in the marked walkways and crosswalks.","Lesson ID":1309}
{"Driving Event":"Rigorous peer reviews of spacecraft bus software resulted in good on-orbit performance. A lack of rigorous peer reviews of the instrument software have resulted in numerous on-orbit patches and changes.","Lesson ID":1294}
{"Driving Event":"A positive experience from rigorously maintaining a well-defined on-line risk management system.","Lesson ID":1296}
{"Driving Event":"An incomplete systems error budget resulted in confusion about test success criteria in the test cycle.","Lesson ID":1299}
{"Driving Event":"An electrical test, performed at a contractor facility during acceptance test of the Space Infrared Telescope Facility (SIRTF) propulsion subsystem, caused the failure of 6 pressure transducers. These transducers are used to sense the pressure in propellant lines. The incident occurred when a 500-volt insulation\/isolation resistance test intended for the propellant line heaters and tank heaters was mistakenly applied to all electrical connections in the subsystem. Applying 500 volts to the entire subsystem caused the transducer damage. The transducer circuitry should have been tested at a maximum of 50 volts. The test failure was traced to an error in the acceptance test procedure (ATP). A careful, detailed review of the ATP by the lead propulsion engineer would likely have detected the circuit compatibility error. Additional Key Words: test induced failure, test error, over voltage, excess voltage, voltage rating","Lesson ID":1300}
{"Driving Event":"The signed Memorandum of Understanding (MOU) was needed repeatedly throughout the mission development process. The mission had a complete and timely MOU in place far in advance of needs, which may have caused delays otherwise.","Lesson ID":1306}
{"Driving Event":"Some systems requirements were not rigorously tracked and controlled, resulting in some confusion during the test cycle about success criteria.","Lesson ID":1298}
{"Driving Event":"The satellite simulator became an invaluable tool for software testing, flight operations crew training, and on-orbit software change testing.","Lesson ID":1307}
{"Driving Event":"On February 19, 2002, an incident occurred during the hot-fire testing of the Army vortex thrust chamber assembly at MSFC Test Stand 115. This was the fourth hot-fire test of the hardware, but the first test flowing both LOX (liquid oxygen) and RP-1 fuel as the main propellants and GOX (gaseous oxygen) and GH2 (gaseous hydrogen) for the torch igniter. The first three tests, which were successfully completed, were hot-fire tests of the GOX\/GH2 torch igniter only. For these tests, gaseous nitrogen was flowed through the main injector. The fourth test was to characterize start up transient conditions. The objectives of the vortex chamber testing were to demonstrate the feasibility of vortex chamber technology for a liquid hydrocarbon\/liquid oxygen system, demonstrate several ignition techniques (torch, laser and combustion wave), demonstrate two rocket plume measurement methods (emission\/absorption and Raman scattering), and characterize the chamber performance by means of thrust measurements and species uniformity in the plume flow field. At approximately 5.3 seconds into the automated firing sequence, a catastrophic failure occurred to the test article. A redline cut initiated shutdown at that time. The facility proceeded to follow the normal shutdown sequence, which initialized the safeguarding of the facility and test article. The area was immediately roped off with quality monitoring activities. Once the facility safeguarding was completed, it was determined that there were no injuries to personnel, and damage to the test facility was minor. Most of the test article pieces were recovered and provided important information in the investigation and analysis of the incident. A timeline was constructed from the high-speed video film, control sequence data, and both the low and high-speed instrumentation. Due to the lack of a time stamp on the high-speed video, there were some inherent inaccuracies in correlating the instrumentation data timing with the video. Although all data systems were operational at the time of the incident, the over pressurization\/detonation occurred very rapidly and as a result there was limited evidence of the over-pressurization in the collected data. The test article failed at the mounting bolts as well as the injector and spacer, and hardware was recovered over a large area of the test facility and nearby fields\/woods. The scenarios developed by the incident investigation team pointed out that three significant events occurred during the start up transients: 1) surface burning of the chamber head end hardware, 2) surface burning of the injector module hardware, and 3) accumulation of propellants in the chamber. The primary cause of the incident was the propellant accumulation in the chamber during the ignition delay. The first two events are not believed to have caused the eventual over-pressurization.","Lesson ID":1310}
{"Driving Event":"During the Project's technology transfer efforts, difficulties arose because the NASA software distribution policies and export control approval processes changed. The situation was made more difficult because each agreement had to be negotiated through multiple NASA organizations that experienced a significant turnover in personnel. Thus, there seemed to be an insufficient amount of corporate knowledge regarding these complicated processes. Many of the Project's resources were spent to address these issues with less than complete satisfactory results. In addition, the goals for technology transfer often changed as the technology matured and was proven successful.","Lesson ID":1279}
{"Driving Event":"Due to resource constraints and a past history of success with a specific commercial vendor the Project decided to reduce the amount of in-house Quality Assurance (QA) activities. Thus, there was a reduction of QA with regard to items the Project owed the vendor (design drawings) and deliverables the vendor owed the Project (hardware). Unfortunately, this reduction of in-house QA combined with the unknowns associated with one-of-a-kind or cutting edge technology lead to problems being discovered late and\/or items having to be accepted with waivers for non-conformance.","Lesson ID":1278}
{"Driving Event":"Often Programs\/projects, especially highly visible ones, must deal with the reality of being accountable to multiple entities, such as Center Senior Staff, Headquarters\/ Enterprise Management, External Partner Management (FAA, DOE, NSF, etc.) who may have conflicting requirements. In addition, the Program\/project has the main responsibility of fulfilling customer requirements, which may not be entirely compatible with the direction levied by these other \"bosses.\" Programs\/projects must balance the requirements of these bosses with that of their customers. It is in the best interest of the Program\/project if the customer requirements take priority over all others.","Lesson ID":1285}
{"Driving Event":"In order to minimize cost and schedule, the project, after a trade-off analysis, decided to build two fully functional test vehicles as opposed to one with built in redundancy (note: those items deemed critical to safe operation were redundant). The test vehicles were of identical design but manufactured in sequence. Thus, while test vehicle number one was being flight tested, test vehicle number two was being built. The primary drivers for this approach were that the test vehicle was to be unmanned, have an emergency recovery parachute, and be operated in a very controlled and unpopulated area. The risk of losing one vehicle was minimized by the imposition of these stringent test flight constraints. While it was the project's intention to complete the second vehicle as if it were the first and only, its main purpose was for risk reduction (the project's success meant vehicle number two was tested through ground taxi only). The second vehicle was also viewed as a source of parts for vehicle number one.","Lesson ID":1288}
{"Driving Event":"Flight element testing is very necessary but expensive; program schedule pressures typically mandate performing the minimum set of tests possible. The paper\/documentation process associated with troubleshooting problems and\/or performing detailed investigations of unexpected test results can significantly add to the time required to perform detailed tests on flight hardware\/elements. In this particular event, a minimum amount of pre-planning (i.e. insufficiently defined test requirements) resulted in power quality test implementation at KSC on the ISS Flight Node 1 that required replanning\/rescoping the tests \"on the fly\" at KSC. Compounding the event was unexpected test results from the Russian to American Converter Unit (RACU) that forced the onsite test team along with support personnel from Boeing Canoga Park to perform detailed troubleshooting which further delayed the formal testing progress. Due to the unplanned, excessive time spent on Node 1 Power Quality Testing, valuable schedule reserves for the Flight Node 1 were lost. In addition, the NASA & Boeing Power AIT were forced to fly technical personnel and hardware to and from KSC, JSC and Boeing CP in order to support the Node 1 testing. Further, at risk was the opportunity to obtain all of the necessary data to both verify the Node 1 power system and to validate the electronic models necessary to verify the end to end power system functionality.","Lesson ID":1274}
{"Driving Event":"Problems encountered late in the test cycle on some articles, due to lack of rigorous peer review","Lesson ID":1276}
{"Driving Event":"The UTMC UT69R000 (aka ut69r, r000) microprocessor has several known problems that users must be aware of.","Lesson ID":1273}
{"Driving Event":"A critical cable connection fault was not observed during final checkout at the pad, due to insufficient flags in the ground support equipment. The problem resulted in a loss of a prime side instrument.","Lesson ID":1277}
{"Driving Event":"On 20 February, a latch locating tool (approximate weight = 500 lbs.) and its handling fixture (dolly) were loaded on a stake bed truck, strapped down, and transported to a subcontractor in Goleta, CA. During shipment one end of the latch locating tool (drill platform) slipped from the dolly and landed on the truck floor. Upon arrival at destination, the subcontractor refused the shipment due to its apparent faulty shipping condition and the platform and dolly were returned to the point of origin. One of the roller subassemblies was discovered to be missing. Tool Fabrication was able to replace the roller subassembly. A subsequent tolerance check of the tool determined that it was within tolerance and the tool was re-certified. The complete tool was then properly packaged and re-dispatched to the subcontractor. Root cause: Successful teamwork requires that the team include all appropriate personnel\/contributors. Also, a small amount of additional information in the right place on key documents can greatly reduce confusion and chance for error. The following details describe a systemic breakdown in the process. Engineering originated a Work Release Order (WRO) to ship the Mobile Transporter latch locating tool to the subcontractor. The latch locating tool consists of two parts: Part 1 (Drill Structure for prismoid holes: approximate size 5 x 8 feet), and Part 2 (Drill plate for sensor strips @ approximate size 6 x 10 inches) The drill structure has a dedicated storage container (tool engineering considers this a part of the tool.). Instead of shipping the two parts in their respective storage containers, the drill structure was shipped along with its handling fixture (dolly) and Part 2 was left behind. The handling fixture has two locking bolts to secure the drilling structure during ground handling. The drill structure was not properly restrained by the locking bolts. The bolts were to be installed in the \"V\" between the front rollers, instead they were installed aft of the front rollers, thus not providing any horizontal movement restraint until the rear rollers reached the locking bolts, allowing the front end of the tool to slip out of the holding fixture and strike the bed of the truck. Finding 1: Tool was not properly identified by Tool Control. Drill structure and handling fixture were shipped. The drill plate was left behind. Tool Control has the responsibility to: Identify the tool to be shipped (ensure the tool is complete) Prepare the tool for shipment (package\/containerize as required) Prepare Request for Shipment form (RFS, MDM - 0625) Send \"RFS\" to Shipping Department (when tool is ready for shipment) After shipment, receive \"Packing Sheet\" and update inventory log, to indicate the tool has been shipped. Finding 2: Tool was not properly packaged for shipment: dedicated container was not used, resulting in drill structure not being properly secured in the handling fixture. Finding 3: WRO did not state (nor was it required to provide the detail) that the tool consisted of 2 parts. It did not explain that the handling fixture is not to be included in the shipment. Finding 4: WRO did not have signature block (nor was it required to provide the detail) for department responsible for tool shipment, namely Production Control. Finding 5: RFS did not state (nor was it required to provide the detail) that the tool consisted of 2 parts. It did not explain that the Handling Fixture was not to be included in the shipment. Finding 6: PHS&T (Packaging, Handling, Storage & Transportation) signed the WRO which tasked them to provide \"technical support and coordination for major shipment per NHB 6000.1\". PHS&T did not get involved in tool shipments. Tool shipment preparation responsibility is entirely within Manufacturing Production Control (Tool Control). Finding 7: QA (Receiving and Shipping Inspection) failed to detect that what was being shipped was incorrect.","Lesson ID":1272}
{"Driving Event":"After the STS-83 mission metallic particles were found in several locations of the SpaceLab module floor. This FOD was determined to be from the Express Rack Flight experiment, which included a Space Station International Standard Payload Rack. The source of the FOD was determined to be metal particles entrapped in inaccessible areas of the rack. All of the metal particles were trapped in the Spacelab module subfloor so there was no crew exposure to floating metal particles. The incident occurred after Boeing Huntsville had already taken steps to correct the processes that were generating the FOD so there was no impact on the factory operations. While actions to control the FOD in the assembled rack were taken prior to the flight, they were not 100% effective due to the restricted access to the rack interior once the flight experiment was assembled. Based on this incident it is apparent that extraordinary efforts will be required to ensure and maintain the cleanliness of the ISS interior hardware. There are many inaccessible areas where an inspection to ensure \"visibly clean\" will require more than a simple visual inspection.","Lesson ID":1275}
{"Driving Event":"The JPL Galileo project used automatic orbital arc welding to join spacecraft propulsion system tubing, despite a recognized risk to sensitive spacecraft hardware. An orbital arc welding system utilizes a weld head that clamps around the tubing to be butt-welded. The weld electrode is controlled to rotate around the tubing, with the weld current synchronized with the rotation of the electrode. This automated process can provide a quality weld that is not subject to the irregularities of hand welding. Such welding on the Galileo Rocket Propulsion Module (RPM) tubing in the late 1980s, as described in Reference (2) below, led to concern that this high voltage process may pose a risk to spacecraft electronics. Initiation of the weld arc uses starting voltages as high as 40,000 volts, with resultant stray voltages on the tubing in excess of 400 volts. This could propagate at significant levels across interfaces into electronics. Some spacecraft electronic devices (e.g., detectors) may be sensitive to stray voltage levels, even as low as a fraction of a volt. References Electric Welding Hazard to Spacecraft Electronics (Click on title for .pdf file), A.C. Whittlesey and J.M.Lumsden, Proceedings of the International Symposium on Electromagnetic Compatibility, 8\/18-20, 1981, Boulder, pp. 224-228. quotGalileo Arc Welding Anomaly,quot NASA Lesson Learned No. 0399, June 7, 1995. Additional JPL Key Words: EEE parts electrical overstress, transient voltages, short circuit, sneak circuit","Lesson ID":1267}
{"Driving Event":"Several unplanned post-launch tests were run on a mission in the post-environmental test timeframe, which, in fact, uncovered several important problems, which needed correction.","Lesson ID":1268}
{"Driving Event":"While testing at Mach 0.8 in the 16-ft Transonic Tunnel, a full-scale F-15 inlet model separated from the sting. The model traveled downstream and impacted the catch screen and turning vanes. The impact resulted in total loss of the model and damage to the screen. Some debris got through the screen and damaged the wind tunnel blades. The sting was also damaged. An investigation team concluded that the aerodynamic loads on the model resulted in sting loads that exceeded the ultimate strength of the sting. Possible reasons the large loads occurred are: operating at a Mach Number not in the original test envelope, F-15 cowl traveled past intended angle, sting deflection, and dynamic loads. THERE ARE 6 LESSONS IN LLIS FOR THIS DRIVING EVENT.","Lesson ID":1265}
{"Driving Event":"While testing at Mach 0.8 in the 16-ft Transonic Tunnel, a full-scale F-15 inlet model separated from the sting. The model traveled downstream and impacted the catch screen and turning vanes. The impact resulted in total loss of the model and damage to the screen. Some debris got through the screen and damaged the wind tunnel blades. The sting was also damaged. An investigation team concluded that the aerodynamic loads on the model resulted in sting loads that exceeded the ultimate strength of the sting. Possible reasons the large loads occurred are: operating at a Mach Number not in the original test envelope, F-15 cowl traveled past intended angle, sting deflection, and dynamic loads. THERE ARE 6 LESSONS IN LLIS FOR THIS DRIVING EVENT.","Lesson ID":1263}
{"Driving Event":"While testing at Mach 0.8 in the 16-ft Transonic Tunnel, a full-scale F-15 inlet model separated from the sting. The model traveled downstream and impacted the catch screen and turning vanes. The impact resulted in total loss of the model and damage to the screen. Some debris got through the screen and damaged the wind tunnel blades. The sting was also damaged. An investigation team concluded that the aerodynamic loads on the model resulted in sting loads that exceeded the ultimate strength of the sting. Possible reasons the large loads occurred are: operating at a Mach Number not in the original test envelope, F-15 cowl traveled past intended angle, sting deflection, and dynamic loads. THERE ARE 6 LESSONS IN LLIS FOR THIS DRIVING EVENT.","Lesson ID":1264}
{"Driving Event":"While testing at Mach 0.8 in the 16-ft Transonic Tunnel, a full-scale F-15 inlet model separated from the sting. The model traveled downstream and impacted the catch screen and turning vanes. The impact resulted in total loss of the model and damage to the screen. Some debris got through the screen and damaged the wind tunnel blades. The sting was also damaged. An investigation team concluded that the aerodynamic loads on the model resulted in sting loads that exceeded the ultimate strength of the sting. Possible reasons the large loads occurred are: operating at a Mach Number not in the original test envelope, F-15 cowl traveled past intended angle, sting deflection, and dynamic loads. THERE ARE 6 LESSONS IN LLIS FOR THIS DRIVING EVENT.","Lesson ID":1266}
{"Driving Event":"While testing at Mach 0.8 in the 16-ft Transonic Tunnel (16 TT), a full-scale F-15 inlet model separated from the sting. The model traveled downstream and impacted the catch screen and turning vanes. The impact resulted in total loss of the model and damage to the screen. Some debris passed through the screen and damaged the wind tunnel blades. The sting was also damaged. An investigation team concluded that the aerodynamic loads on the model resulted in sting loads that exceeded the ultimate strength of the sting. Possible reasons the large loads occurred are: operating at a Mach Number not in the original test envelope, F-15 cowl traveled past intended angle, sting deflection, and dynamic loads.","Lesson ID":1262}
{"Driving Event":"A glass container of chemical waste exploded when disposing of a new metal etching waste solution (mixed organic\/acid chemical) using a 1-gallon glass container designated only for mixed waste acid and loosely fitted the cap. The waste solution was incompatible with at least one of the acids (Nitric, HNO3) in the waste container. A few minutes later, the employee heard a hissing noise and the container exploded. The explosion cast glass shrapnel and chemical waste across the laboratory, causing damage to laboratory equipment. Fortunately, the employee was not around the explosion and evacuated the laboratory without injury. This was a routine process. However, The new chemical etching solution (hydrochloric acid, ethanol, and copper chloride), was disposed of without review by the laboratory's chemical hygiene officer or the safety representative. There was no pre-use hazard analysis, which may have prevented the mixing of incompatible chemicals. Mixed waste acids were stored in a glass container (still a common practice in some chemical laboratories) instead of a compatible plastic container. This created the potential for additional hazards from a failure or explosion.","Lesson ID":1259}
{"Driving Event":"On 24 April 2002, 7:35 a.m. (CST) two employees, working in a Clean Room configured for glass inspection and assembly, were rotating a Flight Cupola Trapezoidal Debris Pane as part of a planned event to setup for the final glass inspection prior to assembling the pane into the frame. During the rotation, the glass made contact with the aluminum table which caused a shatter mark internal to the glass, approximately .300\" X .500\" at the edge. The incident was reported to the Quality Assurance and S&MA managers and all glass handling activities in the shop was suspended pending a detailed investigation and corrective action. DCMA was en route to the inspection room when the incident occurred. Non-Conformance #17817 was also initiated to document the incident. Lesson Foundation\/Root Cause: The following were determined to be the root causes of the glass damage incident and suggested areas for improvements: The glass teetered on the foam blocks used to support the glass during rotation causing the corner of the cupola glass Trapezoidal debris pane to impact the table. Improvements to the foam blocks used for the rotation and other glass shop aids need to be implemented. The impact of the glass on the anodized aluminum table surface caused the glass damage. Softer materials for the glass work surfaces need to be evaluated. There was a miscommunication between the 2 technicians handling the glass and what to do with the corner blocks. Improved methods of communication between the glass handlers and the task leaders need to be evaluated.","Lesson ID":1260}
{"Driving Event":"A wire harness was installed on a flight unit for a fit check. Subsequent manufacturing operations were continued through several steps until it was realized that the wire harness was meant to be a temporary installation only. Production time was lost to back out and remove the harness so that it could be returned to its manufacturer to complete its detail manufacturing sequence and final test. This incident caused a slight impact (delay) to subcontractor's internal schedule, but had no effect on overall Program schedule. Root cause: During the Manufacturing process it is very important to flag and control \"temporary installations\" to avoid wasting time or, in the worst case, building in sub-assemblies that are incomplete and\/or untested.","Lesson ID":1258}
{"Driving Event":"During a cross-range flight test mission of the Global Hawk (UAV) from Edwards AFB, CA through the adjacent range operated by NAWC-WD, China Lake, CA, the nominal vehicle inadvertently received the arm and destruct commands from an uninvolved range. Flight vehicle No. 2 was lost as a result. The vehicle crashed without fire (all fuel was expelled from the wingtips) within the restricted area of R2515 with no injuries to personnel or other property.","Lesson ID":1253}
{"Driving Event":"At approximately T+55 seconds the flight of the Strategic Target System (STARS) missile was terminated due to an inadvertent destruct action that occurred during an attempt to transfer control of the Flight Termination System (FTS) command receiver from the ground transmitter site, located at the Kodiak Launch Complex (KLC, Alaska) to the downrange off-axis airborne transmitter aboard a P3 aircraft. This resulted in total loss of the vehicle and the loss of the anticipated data required to meet the mission objectives. At the time of the destruct action, there were no safety problems with the missile or its trajectory. The vehicle was flying nominally and in control until the moment of destruction, and was within all prescribed safety boundaries and corridor limits for debris impact.","Lesson ID":1254}
{"Driving Event":"Orbiter wiring inspections have uncovered redundant wiring in the same wire bundles.","Lesson ID":1241}
{"Driving Event":"Excessive unincorporated Engineering Orders (EOs) to Orbiter drawings.","Lesson ID":1242}
{"Driving Event":"Lack of visual or aural warning that caution and warning functions have been inhibited.","Lesson ID":1247}
{"Driving Event":"Part shortages, late engineering changes, and manufacturing difficulties have resulted in a number of minor differences between the structural test article (STA) and the ensuing flight article. Initially, the engineering intent was that the structural subassembly of these two vehicles would be identical from an engineering drawing standpoint. At the last minute, part shortages required the use of acceptable substitutes for the test article. These last-minute changes carried over to the flight articles, resulting in engineering configuration changes \/ part number changes for major subassemblies late in the manufacturing cycle, causing delays as the planning\/manufacturing paperwork was reworked. Additionally, non-conforming detail parts that are acceptable for the STA only require additional engineering documentation to control their usage to test only if the next assemblies do not account for specific part number differences between flight and test. This again has caused delays in getting acceptable hardware installed on schedule. Root cause: Failure to carry part number differences between the flight article and test article early in the design and planning phase.","Lesson ID":1225}
{"Driving Event":"Elements of the Shuttle systems upgrades portfolio may be delayed or deferred necessitating a need to ensure adequate long-term logistics planning for mature systems.","Lesson ID":1232}
{"Driving Event":"Current policy for classification of mishaps, and hence mishap investigation procedures is done by dollar value of loss or injury severity.","Lesson ID":1237}
{"Driving Event":"International Space Station Command & Control Computer crashes due to common cause failure mode.","Lesson ID":1240}
{"Driving Event":"Improvements needed to locate fires and leaks, as well as improvements needed in procedures and tools to control these hazards.","Lesson ID":1246}
{"Driving Event":"Funding cuts threaten the viability of the orbital debris project.","Lesson ID":1249}
{"Driving Event":"The basis of the Z1 ITS modeling strategy in the preliminary and conceptual design phases was a simplified beam element representation of the primary structure bulkheads and panels. This facilitated rapid, automated beam based stress analysis of the primary structure and decreased the design cycle time as well as manpower loading. The same model was used for both (1) the design dynamic-coupled load analysis and (2) the pre-test model and static test prediction analyses. The pretest model analysis model produced poor correlation with the model test data. The correlation was improved by remodeling critical bulkheads and panels in greater detail using shell elements for the basic web and shell\/beam elements for the upstanding ribs & flanges. Solid elements were also used where \"plate\" proportions did not exist. The increased fidelity of the post-test model led to improved correlation with the static test as well. However, the changes made to the model have forced a re-evaluation of the internal stresses both because of the change in model response and\/or load paths. This re-evaluation came long after the design of the hardware was finalized and manufacturing completed. Any adverse findings from this re-evaluation could lead to costly retrofits or undesired limitations on hardware use during operations.","Lesson ID":1223}
{"Driving Event":"A manufacturing engineer found that sixteen fasteners were not installed on Flight Wing 1 (Solar Array Assembly) two (2) days prior to shipment. Investigation revealed deficiencies and\/or breakdowns in several discrete process. Root cause: Engineering design error; fastener was too short. Failure to adhere to manufacturing control processes: Fasteners were not installed and informal notification of fastener size error was done in lieu of formal discrepancy report (DR) documenting incorrect fastener size and lack of fastener installation. Inspection\/Manufacturing failure to verify completion of operation at documentation buyoff (Inspection buyoff indicated bolts were installed, but bolts were not actually installed). Operation had Operator & inspection stamps indicating installations actually occurred, which is a process violation. Planning incorrectly posted a Manufacturing Change Notice; the design change adoption process was not followed. When an engineering change initiated to correct the fastener size was processed, planner did not flow the change down to the initial assembly, only subsequent assemblies. Subsequent Engineering\/Manufacturing\/Quality Assurance hardware reviews (\"shakes\") failed to identify missing bolts: \"Shakedown\" verification process inadequate.","Lesson ID":1227}
{"Driving Event":"Specifications are written to control the baseline requirements to which the Space Station is designed, constructed, verified, and delivered. A common practice within most specifications is to reference documents (know as applicable documents) with the specification as a source of requirements. Early in the development of the specifications the undesirable practice of \"circular\" referencing of documents infiltrated the specifications within the Space Station Program. Circular references is, in general, a condition by which a specification or document at a low level of the specification (or document) tree hierarchy references a specification of document at a higher level in the specification (or document) tree hierarchy. The following example illustrates the impact of \"circular referencing.\" Within the Space Station Program the top level specification is the System Specification (SSP 41000). SSP 41000 references numerous documents. Among the referenced documents in SSP 41000 are SSP 30558 and SSP 30559. The SSP 30558 and SSP 30559 documents, in turn reference SSP 41000 (completing the \"circle\"). Other specifications within the Space Station Specification \"Tree\" referenced SSP 30558 and SSP 30559. Because 41000 is an applicable document in 30558 and 30559, a lower level specification with the spec tree (for example, the United States Lab (USL) Spec) was placed in the posture of inadvertently being subjected to all requirements within the System Specification. There are two undesirable results caused by this practice: Obviously the USL was not intended to fulfill all requirements as defined in the System Specification. The USL, however, under this structuring could have been construed as needing to meet all System Spec Requirements. Maintenance of the \"applicable document\" section of each individual specification becomes tangled and interwoven to the point that nonapplicable requirements must be verified. For example a modification to SSP 30559 would result in a required document change of every specification within the Space Station Specification Tree. Root cause: Failure to establish guidelines that define the purpose, use, and relationships of applicable documents. (Center Data Manager's note: The confusion over applicable documents arises quite often from an author's perceived need to justify or establish authority for a document versus identifying documents that, when cited as applicable, will aid in document implementation. The two purposes are quite different but in a poorly defined process both can be considered as meaning \"applicable.\")","Lesson ID":1228}
{"Driving Event":"Orbiter logistics supportability challenges due to parts obsolescence, business closures, etc.","Lesson ID":1243}
{"Driving Event":"A 5-ton mobile A-Frame was being used to lift a 8450 No. piece of research hardware from a lower floor level to the wind tunnel floor through a slot in the wind tunnel floor. Due to the constrained operational space and complex geometry of the hardware, the lift was not through the C.G. of the hardware. During the lift operation, the C.G. rapidly shifted causing the lift line to fall outside of the A-frame base dimension. This caused the A-frame to rapidly topple over and inflict fatal injuries to a bystander. This same lift had been successfully completed on a previous occasion using lateral movement restraints, but there appeared to be no loading on these restraints; therefore, they were not used for this lift. During the mishap investigation, an observation was made that the wheels were only rated for 3000 No. each which implies that all four wheels must be equally loaded to safely support the 10000 No. rated load. If the lift line moved from a vertical position (e.g. load swinging during transit) the wheels would be unequally loaded and the load could exceed the wheel rated loading.","Lesson ID":1221}
{"Driving Event":"Galling of threaded fasteners was experienced in the qualification test program of the Z1 Truss. Fasteners intended to be removable on-orbit galled during test. The fasteners were installed in locking threaded inserts (\"KEEN\" type). Root cause: The inherent effect of the \"Keen\"-type, upset thread design is to bite hard into the fastener. After repeated installation and removal, the fastener will gall. These inserts work best engaged once, and are excellent in this application.","Lesson ID":1222}
{"Driving Event":"Terrorist attacks of 9\/11 have reinforced the need to protect NASA network and communications resources from intrusion.","Lesson ID":1250}
{"Driving Event":"The description that follows will demonstrate that pre-flight troubleshooting relied on history of a similar failure and did not check the actual configurations of certain subsystems or their components. Because troubleshooting did not go \"outside the box\", there was no attempt to think beyond historical failures. This was compounded by a design that did not provide a way to directly verify power was being delivered to the specific component - in this case specific channels to an electronic card. During the STS-88 (Flt 2A) Node 1 ECLSS equipment checkout, the Node 1 Sample Distribution System (SDS) forward and starboard valves failed to change position when electrically commanded from the ground. Due to a previous failure history, it was incorrectly assumed that the SDS valve failures were attributed to internal binding. A subsequent troubleshooting and repair activity was authorized for STS-96 (Flt 2A.1) to try to repair the valves. This activity was unsuccessful. However, it was determined from data reviews post STS-96 procedure that the Remote Power Controller (RPC) was open rather than closed during all previous tests. The RPC provides power to the Solenoid Driver Output (SDO) card channels controlling these SDS valves. Analysis has determined that the RPC power feed to the SDO had not been closed for the FWD and STBD SDS valves. Previously, the NADIR and SELECTOR SDS valves had been commanded on both the 2A and 2A.1 missions, with success both times. It turns out that these SDS valves are connected to an SDO card in which the RPC is always kept closed due to SDO card requirement to power the Multiplexer \/ Demultiplexer (MDM) heaters. A subsequent test conducted at GMT 320\/1999 verified that the valves could be commanded to change position from the ground if power was applied to the appropriate SDO card. Flight Note EFCN934 SDS Valve Checkout - Inc B provided the proper power configuration. This problem is documented in PR# 988. Root cause: An analysis has determined that an RPC power feed to the SDO card had not been closed for the Node 1 FWD and STBD SDS valves preventing the valves from actuating by command. This was due to an oversight of the ISS 2A Operations Checklist to verify that the correct power configuration was enabled to perform the SDS valve checkout procedures. The Operations Checklist indicated what command would be sent to change the position of the SDS valve and the initial \/ final valve position indications, but no additional commanding to power the appropriate SDO cards. This appears to be a cross-subsystem problem where the ECLSS engineering knew how to command the valves and the EPS engineering knew which RPCs were open or closed, but in the Flight Operational Readiness (FOR) review of these documents, this issue was missed by both.","Lesson ID":1219}
{"Driving Event":"During processing of flight 2A element at the KSC SSPF, hardware that had previously been configured for test or closed out for flight was inadvertently deconfigured \/ disassembled by teams working parallel tasks on the same system or hardware. An assembly or test team working to an approved work authorization document (WAD) would configure a system or hardware for an upcoming test or for flight. Later, a different assembly or test team, also working to a valid work document, would dissemble or reconfigure that hardware for a different task. This at times caused a loss of known configuration, which necessitated the release of unplanned event paperwork to document the restoration of the hardware to its original state of completion, and caused delays to already tight schedules. Example: Inter-module ventilation (IMV) port caps had been configured for flight (installed and leak tested). The team testing the IMV\/ECLSS system, needing to connect air ducting to these ports, removed the caps and proceeded with their tasks, negating the previously certified hardware configuration. Root cause: Element processing schedule compression and overlapping assembly and test activities resulted in procedural and schedule disconnects.","Lesson ID":1224}
{"Driving Event":"Qualification test failures of RM2679 transformers were discovered after vibration screening. Post-test analysis of the failed transformers revealed there were gaps between internal contacts. Further analysis revealed that wires had broken off where the transformer coil wire is soldered to larger terminals. Root cause: Nicks were discovered on the coil winding wire near its attachment point. Further investigation determined that assembly personnel were using mechanical strippers to strip the coating off the ends of the wire. These nicks became stress concentrators leading to subsequent failure during vibration testing.","Lesson ID":1226}
{"Driving Event":"While performing electrical checkout of a newly manufactured electronic component, erratic high-current measurements were noticed. Some technicians in the area believed they also occasionally smelled something burning. While a drawer was removed for other troubleshooting, it was noticed that the wires connected to a contactor were loose. After removing the contactor cover, overheating of the lugged wires and nut\/bolt connection was obvious; there was discoloration typical of high temperatures. The contactor cover was also slightly melted and burned. This high-resistance connection caused overheating when large currents were flowing. The wire lugs were welded to the bolt and the nut could not be removed (or tightened). The contactor had to be replaced and the wires re-lugged. Root cause: Nut tightness check was missed during in-process assembly inspection. The company that assembled the console did not tighten the contactor wires. The nut was spun on to the bolt, but it was not even finger tight.","Lesson ID":1229}
{"Driving Event":"During dimensional inspection of orbital tube welds involving 316L tubing, it was found that 8 of 8 welds failed because of weld mismatch. The weld joints were located between two bends that formed a \"S\" bend. There was approximately 1 inch of straight tubing from each bend to the joint of the weld. The mismatch in this case is not to exceed 25% or 0.010 inch which ever is less. Root cause: Tube bending \/ shaping typically causes the tube to take an oval shape, creating matching problems during weld fitting. Engineering drawings provided insufficient length for oval \/ runout to occur of the shaped \/ bent tube prior to welding of the joint.","Lesson ID":1230}
{"Driving Event":"Potential slide or cancellation of Cockpit Avionics Upgrade for the Orbiter.","Lesson ID":1239}
{"Driving Event":"Possible deferral of Orbiter Major Modification periods which include significant safety upgrades.","Lesson ID":1244}
{"Driving Event":"While testing at Mach 0.8 in the 16-ft Transonic Tunnel, a full-scale F-15 inlet model separated from the sting. The model traveled downstream and impacted the catch screen and turning vanes. The impact resulted in total loss of the model and damage to the screen. Some debris got through the screen and damaged the wind tunnel blades. The sting was also damaged. An investigation team concluded that the aerodynamic loads on the model resulted in sting loads that exceeded the ultimate strength of the sting. Possible reasons the large loads occurred are: operating at a Mach Number not in the original test envelope, F-15 cowl traveled past intended angle, sting deflection, and dynamic loads. THERE ARE 6 LESSONS IN LLIS FOR THIS DRIVING EVENT.","Lesson ID":1261}
{"Driving Event":"A functional test was being performed at one of the subcontractors on Pressure Transducers. The physical setup consisted of a supply pressure bottle connected to a pressure manifold (with 4 pressure transducers installed) and to a test console. The objective of the functional test was to ensure that at various pressures the pressure transducers were within allowable tolerance. The system was to be pressurized to 400 psi (line pressure), then a 40 psi differential pressure applied to the transducers. The technician applied 15 VDC voltage to the pressure standard. This is below required voltage. Next, he increased the line pressure expecting an indication from the pressure standard. However, as the pressure increased, the input voltage to the pressure standard dropped from 15 VDC to 11 VDC. At 11 VDC the standard is not able to function due to the low voltage and therefore no increase in pressure was indicated. The technician had no indication that pressure buildup was exceeding the allowable limit for the transducers. Overpressurization damaged the diaphragms in the pressure transducers. Root cause: Human error. Technician applied incorrect input voltage to the pressure standard. As a result the pressure standard failed to indicate the actual line pressure. Technician failed to limit the source pressure. He failed to set the bottle pressure regulator to 440 psi. This would have ensured that the transducers could not be subjected to a pressure exceeding their proof pressure. Contributing Causes: Inadequate training in use of test equipment. Although the technician had received on-the-job-training in test procedures and use of lab equipment, the technician was unaware of the hazardous consequences should the pressure standard be starved for current. Adequate failure tolerance (Can't Fail) was not required to be built into the procedure. Required input voltage was not readily available. Since this incident the input voltage requirements for the pressure standard have been added to the calibration sheet with a warning to the technicians. In addition the input voltage requirements have been stenciled, as a warning to technicians, in large red letters, directly to the standard.","Lesson ID":1208}
{"Driving Event":"Technicians were trimming composite material using a table saw with a diamond-cutting blade. After trimming the employees took a break. When returning they discovered smoke in the room which appeared to be coming from inside the table saw. One technician disconnected the main power switch, while the other pulled the Fire Alarm. There were no injuries to personnel or damage equipment. Root cause: An investigation found that the composite dust had accumulated in the base of the table saw. There was a failure found in the machine dust collection system, which would not allow the removal of dust\/material during cutting. The smoke was ignited by heat or spark during the cutting process.","Lesson ID":1209}
{"Driving Event":"During the performance of closed hatch environmental control \/ life support system (ECLSS) test, Boeing Engineering authorized a deviation to the pre-approved hazardous procedure. The task and procedure to configure the oxygen supply system was to be performed by a subtask document written by a Boeing ground contractor. The subtask document specifically performed the setup, leak check, oxygen supply and shutdown of oxygen systems. The deviated procedure failed to utilize the steps from the subtask document and could have potentially subjected an in-line flex hose lined with Polytetrafluoroethylene to adiabatic compression caused by pneumatic impact. Teflon-lined flex hoses can ignite from pneumatic impacts from tremendous heat build-up. The subtask documents written steps avoid this potential by specific valve configurations and slow system pressurization rates. The written deviation did however; specify the slow delivery of oxygen to the U.S. Lab. No damage occurred to the flight hardware or GSE as a result of operations performed per the deviated procedure. Root cause: Deviation from approved written hazardous procedure","Lesson ID":1210}
{"Driving Event":"The initial runs of an On-Orbit Constraint Test (OOCT) at KSC ran into a number of anomalies. These initial runs were the first attempts (or \"pathfinder\" event) in a series of OOCT from which lessons learned would result in smoother, more efficient OOCTs prior to future flights. The OOCT are a series of tests that emulate one side of an element to element interface using test aids. These Test Aids are set up in a test configuration with the flight element to be tested. The flight crew actually comes to KSC to conduct the test on the flight hardware. The OOCT is considered training for the crew as well as a checkout of the on-orbit procedure with the actual flight hardware. Both Extra-vehicular Activities (EVA) and the Inter-vehicular Activities (IVA) are subject to the OOCT discipline. In an OOCT, connect cables, fluid ducts and umbilicals on the flight are run in a test configuration so that routing, mating\/de-mating of the flight hardware, clocking, length of lines, stress\/strain or twisting of cables and potential obstructions to be encountered can be evaluated. This pathfinder OOCT occurred for Flight 3A where Node 1 was emulated (Node 1 is on-orbit) and with PMA3 (Flight 3A) which had been delivered (DD250) to NASA. The PMA3 configuration actually encountered during the test set-up was different than envisioned from review of the drawing package from which the test aid alignment data and test procedure had been generated. The test procedures are generated from the on-orbit operational sequences being built by mission planners (in this case, in JSC's Missions Operations Directorate, or MOD). Because of the misunderstandings documented in the root causes below, the test alignments, setup of the test aids and the actual conduct of the tests exceeded the planned test timeline. While the test was completed successfully, a regression test will have to be conducted to repeat parts of the test because of insufficient \/ incorrect data available for the test procedure. Root causes: Setup and Alignment Data for the Test Aid was insufficient, incorrect and misunderstood by the KSC support teams responsible for the test aid setup and alignment of the test configuration. There was no tabletop review of this data with KSC prior to these pre-test activities nor was the data formally released prior to pretest activities. The On-Orbit Constraints Meeting was not utilized as a requirements gate review. Since this was the initial test, this meeting was process oriented and lacked specific implementation requirements to be agreed to and baselined. Hardware fit interference - overhanging of PMA3 by EVA test aid - was not anticipated. It was a surprise to the test team. With appropriate configuration control processes, this would not have occurred. Scaffolding and protective padding was applied to the element. Undocumented mating targets were applied to mating \/ sealing surfaces because target locations identified were not on same planar surface as expected. Because the test technicians had done similar exercises before, the targets were applied successfully prior to test. N2 and O2 lines were incorrectly called out in the test procedure. Test Procedure was written to the PMA3 to Node3 ICD that is the correct data source. This was questioned prior to TRR and PMA3 Flight Element team provides a sketch of the lines which was also incorrect. The running of the test identified several errors including this one.","Lesson ID":1216}
{"Driving Event":"During functional test of the Qualification Model of the Mobile Transporter (MT) Linear Drive Unit (LDU), mounted on the Functional Test Fixture (FTF) a power surge followed by a facility power outage occurred. A sequence of events began that resulted in two incidents. Incident #1: When power was restored, the Special Test Equipment (STE) console and data acquisition systems (computers) were restarted. For the STE, the operator selected the appropriate program to power up the fixture motors to warm them up, in preparation for the start of the Fixture Characterization Procedure. Unexpectedly the X-axis motor started, raising the carriage until the screw securing the load cell contacted the lower end of the motor ball screw, causing the flexible coupling to be sheared off. Investigating of the uncommanded movement revealed that several Test Console electrical\/electronic components were defective, most likely as a result of the power surge. The fixture motor controller PMAC card, the X-axis motor servo amplifier and the Y-axis motor relay were removed and replaced. The flexible coupling was also removed and replaced. Incident #2: Under the assumption that the motor was still disconnected from the X-axis ball screw, the system check-out was started. The motor drove the X-axis to the lower end of travel at which point the kill switch was activated to disable the unit. During the uncontrolled motion the LDU qualification unit bogie wheels contacted the lower flange of the test rail and became loaded (no damage found, only superficial scratch) but damage was incurred by the STE X-axis load cell and related hardware. Root cause: Incident #1: Primary Cause: Failure to properly check out the electronic equipment following a known power surge\/power outage. Contributing Causes: The ball screw mechanism was not disconnected from the actuator (motor) to guard against inadvertent\/unintended motion. An Uninterruptible Power Supply was not installed. Incident #2: Primary Cause: The safety of personnel and hardware was jeopardized when two different groups worked on the hardware simultaneously and without proper coordination. Contributing Factor: It should have been confirmed first that the motor was still disconnected from the test fixture before the motor system checkout was performed .","Lesson ID":1212}
{"Driving Event":"The trunnion covers used to support Extra-vehicular activity (EVA) were reportedly altered late in the flow of STS-88 preparations. The modification included the addition of a tether point and changing a part number. The part number was used in the EVA checklist to allow the crew to properly determine on which cover to install each trunnion; the changed part number was not picked up for the checklist. This change resulted in confusion during EVA-2. Additionally, the tether point was not included in the NBL mockups. While implementing this Lessons Learned, it was further reported the change to the trunnion covers developed out of a fit check done at KSC with a VITT representative from the Crew Office in attendance. Velcro was added to the cover to make it fit better per ECP BHE 1780 (Note: the tether points have been in the design of the trunnion covers since June of 1997 although they were not included in the NBL mockup). Additionally, as part of the coordination on this change, photographs of the before and after covers were taken in the Huntsville shop and sent to Houston. This information further underscores the breakdown in the configuration control processes within the program.) Root cause: Lack of configuration control processes for changes that do not require Program level change requests.","Lesson ID":1213}
{"Driving Event":"\"Hi-Lite\" (similar to Hi-Lok) pin and collar fasteners are widely used on ISS Power Module structural assemblies. As part of an internal sharp-object-damage (SOD) identification and mitigation activity, it has been noted that small burrs are present on most installed collars. When accessible to an astronaut's EMU external surfaces, these burrs pose a sharp object hazard with risk of damage to the EMU outer fabric. Root cause: As part of \"Hi-Lite\" fastener installation, a wrench is applied to a drive nut integral with the fastener collar. At a given torque, the drive nut shears from the collar body; the drive nut is then scrapped. This shearing action typically leaves burrs on the collar surface.","Lesson ID":1217}
{"Driving Event":"A contractor reported that there had been some discrepancies with the shipment of the Robotic Work Stations (RWS). The preliminary discrepancies were lack of shock indicators, improper Electrostatic Discharge (ESD) packaging, and improper packaging of the shipment. A formal investigation was conducted to determine the root cause and corrective actions. Root cause: The following root causes were identified by the investigation: Packaging instructions for the RWS assemblies were not being followed, as noted through review of the documentation which showed the personnel handling RWS assemblies several times (to correct packaging discrepancies) prior to being accepted by customer. Specifically, the units were not disassembled into components and the cables were not properly coiled and secured. Adequate packaging interface data, information, and description of hardware was not provided in the packaging instructions. Packaging engineering was not informed of names of authorized personnel for coordinating the activities related to packaging engineering, plus the instructions from the vendor were not provided to the packaging engineer. No formal process was established for the organization having custody of the hardware\/software to maintain the Acceptance Data Packages (ADP) for the contractor-furnished equipment (CFE) and government-furnished equipment (GFE) in its possession, although the data required to maintain the ADP was generated in this case. The packaging instructions were subject to interpretation by the user. For example a contractor's receiving inspection documented that temperature monitoring equipment and shock recording equipment were not present upon opening the container. Per the contractor's packaging procedure, these items are not required in the shipping containers but were assumed by the contractor to be required since they are required per NHB 6000.1D for mission critical equipment.","Lesson ID":1211}
{"Driving Event":"After completion of the rotation of the Z-1 truss segment using a cab-operated 30-ton overhead bridge crane, the lifting device down rods were disconnected from the flight hardware. The task leader instructed the crane director on the floor to move the crane hook up to clear the trunnions. The crane director relayed the instructions over walkie-talkie radio to the crane operator in the cab. The crane operator inadvertently commanded the hook to move in the down direction causing the lifting device down rods to make contact with the trunnions on the Z-1 truss. The operation was stopped. After examination by the task team, the crane hook was moved up and the crane was placed in the parking area and impounded. There was evidence that all four trunnions received metal-to-metal contact from the down rods. A damage assessment is being conducted. There was no damage to the lifting device or Hydra-Set and no personnel were injured. Root cause: The root cause was determined to be human error caused by a combination of less than optimum design of the crane cab controls; inadequate communications and understanding of hoist speeds; and the failure of the emergency stop-button operator to actuate the emergency stop.","Lesson ID":1215}
{"Driving Event":"Prior to flight 1A\/R and 2A the International Space Station Program (ISSP) and the Space Shuttle Program (SSP) was found to have two separate certification requirements that required the hardware providers to furnish a delta certification on operational hardware with flight heritage and a good pedigree of performance. It was found that this was causing additional work, expense, and schedule problems as we got closer to flight time. This problem was identified in an EA presentation to the program on 10\/29\/98 and a process for resolution was formulated in a letter from Director Safety, Reliability, Maintainability, and Quality Assurance (SRM&QA) on 12-8-98 (REF NA-98-085). This letter formed a \"Common Hardware Assessment Panel\" now known as the \"Grandfather Board\" to define the process and provide the disposition for each hardware certification. Root cause: The root cause of the problem was that two independent programs established certification requirements for their vehicles. Since the vehicles serve different purposes and function differently it should have been expected that different certification requirements would be developed. Even with these differences it was found that the differences were minor and could be overcome with proper analysis and compromise.","Lesson ID":1207}
{"Driving Event":"The high Program visibility of Multi-Element Integration Test (MEIT) warrants the need for detailed daily status. Unfortunately, the process for obtaining and providing status proved disruptive to real-time Test Team operations at KSC. Several times during the day people from different organizations would come to the control room in search of information for test status or forward planning assessments. This had a negative impact on control room discipline and seriously affected the ability of the Test Directors and Project Engineers to maintain focus on test implementation. Root cause: Lack of pre-established reporting protocol and schedule for disseminating MEIT information to ISS Program Office.","Lesson ID":1206}
{"Driving Event":"During the Flight 2A (STS-88) mission, the crew was required to install rack pivot pins on the starboard re-supply\/stowage rack (RSR). During the operation, the mid-bay pivot pin wedge\/fitting assembly on the forward pivot pin was pushed through behind the rack resulting in lost hardware inside the ISS Node (refer to ISS PRACA PR# 1000). A setscrew on the track that receives the pivot pin wedge\/fitting assembly was not installed because the RSR was installed before the setscrew was installed. The purpose of the setscrew was to prevent such a loss. Because the setscrew could not be installed without removing the RSR, the assembly order could not be completed and the engineering was revised to delete the setscrew. MOD was informed of the deletion and advised that the crew would have to hold onto the wedge\/fitting assembly when loosing the bolt on the assembly for installation of the pivot pin. Root cause: MOD procedures included a warning to the crew to hold onto the pivot wedge\/fitting assembly while loosing the bolt, however, the format of the procedure was such that the warning was included after the step that loosened the bolt and wound up an the following page. As a result the crew did not see the warning until too late.","Lesson ID":1204}
{"Driving Event":"During recent Multi-Purpose Logistics Module (MPLM, S\/N FM1) operations, loose debris generated by rivets from the Personnel Access Floor (PAF, S\/N 002) was discovered. The suspect Foreign Object Debris (FOD) material are rivet collars that are metallic and approximately 0.3 mm - 5 mm in diameter and weigh approximately .04 grams. Root cause: It was determined that when the Personnel Access Floor was installed into the MPLM, foot traffic (clean room boots) were snagging the rivet collars and dislodging them. The rivet collars were carefully inspected, it was determined that the rivet collars were not thoroughly ground down flush during manufacturing and the remaining raised material was snagging the clean room garments. An extensive search was conducted in MPLM (FM1) by three technicians using hand held lights; one rivet collar was found. The following day, the MPLM was rotated 180 degrees, a post rotation inspection was performed on the interior of the MPLM and no rivet collars were found. The MPLM is currently in the passive configuration with no racks installed, the Y and Z panels are accessible, the interior of the MPLM has been thoroughly inspected and no rivet collars have been found. This MPLM configuration is the optimum configuration for cleaning and performing inspections. MPLM (FM1) current schedule indicates over a year of ground processing in which interior cleanings and inspections are scheduled, furthermore this anomaly was detected within very short time of GSE installation into the MPLM and it is highly unlikely that any rivet collars remain in the module. The following MPLM engineering groups were notified: Electrical Power Distribution (EPD), Command & Data Handling(C&DH), Environmental Control and Life Support (ECLS), Alenia KSC representative, Huntsville PAF design group, Boeing and NASA quality organizations.","Lesson ID":1205}
{"Driving Event":"A battery charger design was reported to have experienced catastrophic component failure during vibration testing, resulting in fractured and broken component leads of heatsink-mounted power devices. A photograph of the failed assembly (Fig. 1) clearly showed a pattern of damage consistent with repeated movement and flexure of the components. The primary cause of the unwanted movement was attributed to a design decision, in which the heatsink was allowed to \"float\" with respect to the printed wiring assembly. A design change, which mechanically bonded the heatsink and the printed wiring assembly together, significantly reduced the incidence of component lead failures during vibration tests. A visual examination of sample components supplied to JSC suggested that the use of unapproved tooling and processes during the component lead forming process was a contributing factor to the observed fractured and separated leads, with numerous sample components exhibiting leads with cracks (Fig. 2). Discussions with the vendor indicated that metallic tools (including a screwdriver) were employed to form the leads. Subsequent improvement in tooling and processes resulted in smoothly formed lead bends, without fractures or significant tooling marks.","Lesson ID":1202}
{"Driving Event":"During the 1 A\/R and 2A ISS assembly missions there were a number of occasions where funnies and\/or problems were discovered, and the solution of some of these required input from the Russian operations or engineering teams. This information was requested via Mission Action Requests, otherwise known as \"Chits\". Those chits requiring information from Russia were transmitted from the Houston Mission Control Center to the Moscow Mission Control Center via the Houston Support Group (HSG), a group of JSC employees located within the Moscow Mission Control Center complex. The HSG is primarily operations-oriented and is staffed accordingly and with an operations mindset. Obtaining timely responses to Chits has proven to be an issue. Root cause: It has been observed that the Russians are reluctant to provide American requests for information without considerable encouragement via direct contact. The lack of an American\/JSC engineering presence within Moscow Mission Control Center complex inhibits the direct and continuing contacts with the Russian engineers.","Lesson ID":1203}
{"Driving Event":"During dynamometer testing of Mars Exploration Rover (MER) motors, position indication circuitry (within the encoder portion of the motor) was damaged. A test cable connector used to supply power to the motor brush leads was damaged prior to the first motor test. Its use resulted in inadvertent and improper powering of the encoders. Ultimately, damage occurred to at least one encoder channel on each of the first 44 motor assemblies that were tested. These commercial motors are used on MER for such purposes as Airbag Retraction Actuators, and they are long lead-time acquisition items. Several errors contributed to the test failure: A special GSE power supply\/monitor had been subjected to failure modes and effects analysis (FMEA) and approved for use on the motors. However, it was intentionally not used during dynamometer testing in order to avoid powering the encoder. Instead, an auxiliary power supply was directly connected with a two-wire cable. The two-wire power cable had one connector with an improperly crimped shell. The cable was not properly inspected and tested prior to use on this critical hardware. There was no test plan or test procedure written for the dynamometer test operations. Results of the Operational Safety Survey (OSS) required an approved test procedure and Assembly Instruction Data Sheets (AIDS) prior to test commencement. Although step-by-step AIDS were prepared and approved by QA, they contained no safe-to-mate provisions for attachment of the power connector. Although QA witnessed some of the dynamometer tests, they did not witness the test of the first motor. Encoder function was not verified following dynamometer testing since there was no intention to power the encoders during these tests. Hence, the damage was not detected after test of the first motor, and 43 more motors were damaged in the same manner. References: Jim Newell, \u201cMaxon Motor Encoder Damage - Mistakes, Recovery Plan and Lessons Learned,\u201d Internal JPL Memorandum 510-01-076, December 6, 2001. JPL Problem\/Failure Report No. Z72981, December 3, 2001. \u201dHigh Energy Spectroscopic Imager Test Mishap\u201d, LLIS #0903. Additional Key Words: connector mating, electrical test, functional test, ground support equipment, quality assurance oversight, safe-to-test, test error, test incident, test induced damage, test oversight, test safety","Lesson ID":1201}
{"Driving Event":"At the Kennedy Space Center on August 11, 1992, in Vehicle Assembly Building (VAB) High Bay #1, the 250 Ton crane #1 was stacking the left forward Solid Rocket Motor (SRM) segment for STS52 at 0009 hours EDT. While moving the segment north, crane #1 trolley suddenly and unexpectedly accelerated. The crane operator reacted and brought the segment to rest without contacting any structure or work platforms. During the incident the segment was estimated to have attained a maximum velocity of 50 feet per minute and moved 7 feet to the north over a period of 17 seconds. Had the segment moved an additional 6.5 feet, it would have contacted the work platform. This type of mishap is defined as a close call because no personnel injuries or damage to hardware was sustained. The crane operation was being performed by a contractor in support of SRM mating operations which were being performed by another contractor. Both contractors are members of the Shuttle Processing Contractor (SPC) Team at the Kennedy Space Center.","Lesson ID":1187}
{"Driving Event":"During post launch bench thermal testing of the Deep Space 2 (DS-2) telecommunications subsystem (TS), it was discovered that the DS-2 transmit frequency was out of specification when the flight spare electronics was exposed to low temperatures (~ -80 \u00b0C). Upon investigation, a previously unknown hardware-software interaction was discovered. [D] In the design of the TS, the flight software commands a temperature measurement of the master crystal oscillator. This measurement is made to adjust the oscillator frequency to compensate for previously characterized, temperature induced, frequency drifts. The software then refers to a lookup table, and applies the appropriate compensation needed to keep the oscillator frequency within specification over the flight allowable operational temperature. Troubleshooting indicated that, due to a programming error, the software fails to power a sensor ASIC during the period when temperature should be measured by the device. This error was not apparent during ambient testing because the software defaults to a fixed level of compensation at room temperature. During assembly and test of the DS-2 flight hardware, a decision was made to delete TS bench thermal testing because of tight schedule constraints. Previous bench thermal tests of the flight subassembly hardware were believed to have been adequate and to have measured performance representative of the final delivered subsystem. The subassembly tests, however, did not exercise the flight software. Because the final subsystem test was deleted, an important hardware-software interaction was missed. The frequency drift was sufficient to cause a 0.5dB degradation of the DS-2 downlink signal from Mars Global Surveyor-an inconsequential effect given the large design margin in the downlink budget. Reference: Jet Propulsion Laboratory Problem\/Failure Report No. Z50019, February 4, 1999. Additional Key Words: telecomm subsystem, power-on testing, software test, frequency excursion, end-to-end test","Lesson ID":1197}
{"Driving Event":"During routine maintenance, employees discovered a telephone junction box under a raised flooring area that was sparking and smoking. An investigative team has determined that the root cause of the event is a design flaw in some telephone system power supplies, which can result in a negative ground fault. During previous maintenance under the raised floor, a telephone cord was partially severed and the positive feed was shorted to ground. When combined with the negative ground fault associated with the power supply design flaw, the shorted cord resulted in a complete circuit with highest resistance at a small junction box located between the power supply and the telephone. Tests have indicated that at least 7.5 amps must be sustained for several minutes in order to burn the junction box. Although the power supplies have 5 amp fuses, most are wired in parallel with booster power supplies also containing 5 amps fuses resulting in a current potential of over 10 amps under the right circumstances. The design flaw has been traced to a specific version of circuit boards from a specific manufacturer. See Government - Industry Data Exchange Program (GIDEP) SAFE ALERT H9-S-02-01","Lesson ID":1188}
{"Driving Event":"On a number of different projects, NASA personnel were denied access to designs for NASA spacecraft. This made review of the adequacy of the design and the resolution of problems either more difficult or impossible.","Lesson ID":1190}
{"Driving Event":"Several days prior to the launch of the GOES-M\/Atlas II mission in July of 2001 a discontinuity was identified regarding what the spacecraft response would be to specific lightning protection phase announcements as compared to the launch vehicle response during launch countdown operations. A potential for a launch countdown scrub existed which was not fully understood by the community until very late in the processing flow.","Lesson ID":1194}
{"Driving Event":"Due to tight funding constraints and a streamlined approach to project development by JPL and their industrial partners, both the Mars Polar Lander (MPL) and Deep Space 1 (DS1) projects were staffed by lean management and technical teams operating with ambitious schedules. For the unsuccessful MPL, many key technical areas were staffed by a single individual with little or no technical backup. In addition, line management review and oversight was minimal compared to prior JPL projects. The DS1 mission was successful well beyond mission objectives. Much of this was due to the extraordinary efforts of the small project team throughout the mission life cycle. However, for many project development and mission operations functions, unique and critical knowledge resided solely in a single individual. Two examples that stand out are: during development, the death of a key project staff member (who had no backup) caused delays in the delivery of crucial hardware, and 2) during operations, the team was so small that some members covered multiple ops functions. Any vacation, sick leave, or other absence constituted a serious threat to mission success, particularly in the event of a critical developmental or operations activity or problem. References: Report on the Mars Polar Lander and Deep Space 2 Missions, JPL Special Review Board (Casani Report), JPL Document D-18709, 22 March 2000, Section 3.1.1.1. \"Deep Space 1 Lessons Learned,\" JPL internal presentation, David H. Lehman, December 1, 2000. JPL Corrective Action Notice No. Z69155, Mars Program Investigation Results: \"Program\/Project Implementation\", 1 May 2000, Recommendation No. 2. Additional Key Words: management and planning, project management, programmatic constraints, risk assessment, technical oversight, workload","Lesson ID":1195}
{"Driving Event":"The principle of \"test-as-you-fly\" means that ground tests and simulations should accurately reflect the planned mission profile, plus margin and the appropriate off-design parameters. Although the system level test and verification process for Mars Polar Lander (MPL) was well planned and executed, there were deficiencies in the test program for the parachute, terminal descent, and touchdown phases. MPL test deficiencies included: The touchdown sensing software was not tested with the lander in the flight configuration, leading to the probable cause of the MPL mission loss. (See Lesson #0938) Fault-injection testing of the flight software was not thorough enough to detect all logic errors in post-landing fault-response algorithms. (See Lesson #0939.) The thermal design of the propulsion subsystem was incorrectly characterized in system thermal-vacuum test due to an error in the thermal model, causing major errors in the propulsion thermal design that went undetected until after launch. The test and verification process for the Deep Space 2 (DS2) probe, which was co-launched with MPL and did not survive Mars Encounter, also departed from the test-as-you-fly principle in end-to-end testing and analysis: A decision was made to not conduct a system-level impact test of the probe with aeroshell. The risk of structural failure from the dynamic interaction between the aeroshell and the probe was recognized and accepted. Though DS2 was designed to strike the Martian surface at a velocity of 200 meters per second, there was no impact test of an electrically powered, complete system. The flight battery lot was not subjected to impact tests. Testing performed on an 8-cell predecessor flight-like lot did not provide statistical confidence as it resulted in one structural failure. Adequate system margins were not demonstrated during the MPL terminal descent control system testing. These margins were subject to erosion from propulsion system dynamics (impulse variations due to water hammer or thermal effects), propellant center-of-mass migration, the lack of a high-fidelity fuel slosh model, and nonlinear pulse-width modulation effects. The true margins of the system were not fully characterized in the presence of these effects. References: Report on the Mars Polar Lander and Deep Space 2 Missions, JPL Special Review Board (Casani Report), JPL Internal Document D-18709, 22 March 2000, Sections 3.4 and 5.2. JPL Corrective Action Notice No. Z69164, Mars Program Investigation Results: \"System Engineering\/Risk Management\/Error Detection,\" 1 May 2000. JPL Corrective Action Notice No. Z69165, Mars Program Investigation Results: \"Verification and Validation Process,\" 1 May 2000. Additional Key Words: Entry, Descent, and Landing (EDL), Environmental Test, Fault Protection, Integration and Test, Risk Assessment, Robust Design, Simulation Accuracy, Software Testing, Spacecraft Test, Technical Margins, Test and Evaluation, Test Errors, Test Fidelity, Test Planning","Lesson ID":1196}
{"Driving Event":"JSC SR&QA was tasked with performing a quarterly visual weld inspection of the Motion Base Simulator (MBS) located in the Shuttle Mission Simulator facility. The MBS is a dynamically loaded large aluminum structure with over 300 welds, of which approximately 80 welds have exhibited cracking over the past ten years. The 80 welds had been repaired, but many continue to exhibit cracking after a short time due to repetitive dynamic loading resulting from motion and vibration. As a result, these problem welds require continued inspection\/evaluation. Previously it took 3 certified welding inspectors (CWI) 6+ hours to locate, access and inspect the 80 welds. Even though the welds were marked with labels, the configuration of the MBS prevented most welds from being readily located. The CWI's spent approximately 4+ hours locating the welds and 2 hours to perform the inspections. Inspection personnel divided the MBS into five separate areas and took high-resolution digital photographs of each area. On each photograph the weld locations were labeled with the appropriate weld number and an arrow pointing to the exact location. A trial run was conducted and all of the welds were located in less than 30 minutes. During subsequent quarterly weld inspections the overall inspection time for three inspectors has been reduced to less than 3 hours. The result is a more than 50% savings for each inspection cycle.","Lesson ID":1189}
{"Driving Event":"Early on Saturday, April 21, 2001, a pipe in the secondary water system failed in the basement of Building 8 at the NASA Goddard Space Flight Center. The primary asset damaged by the resulting flood was the NASA photo archive, located immediately below the location where the pipe failed. It took 2 hours to isolate the secondary water system and several more hours for the system to drain through the failed pipe. As a result, much of the basement flooded to a depth of 1-2 inches. Personnel who were working in the building that morning were exposed to an electrocution hazard and had no protective equipment or proper training. No one in the clean-up or recovery crews was authorized to clear the building. Although floods are identified as a significant hazard\/threat in the Goddard Emergency Management Plan, the emergency console had no guidance or preparation for dealing with the hazards presented by this flood.","Lesson ID":1192}
{"Driving Event":"On July 26, 1990, 14:06 EDT, a Payload Hazardous Servicing Facility (PHSF) fire alarm indication was received at the Protective Services Control Center (PSCC) in the Launch Control Center (LCC). Fire services responded and found no alarm indications at the facility. Initial troubleshooting by EG&G Fire Alarm (F\/A) technicians indicated the trouble was on the communications pair between the PHSF and the PSCC. At 17:48 EDT, a communications technician was dispatched to the PHSF, to support troubleshooting of the problem. The technician arrived at the PHSF Control Building and checked the signal pair at Frame 102. Indications were that the problem was at the Service Building end of the line. He then proceeded to the Service Building and, upon entering, heard an audible alarm. Reporting the alarm, via radio, to the trouble desk at the Communications Distribution & Switching Center (CD&SC), he proceeded to the other side of the facility to find someone to ask about the alarm. Meanwhile, the security guard having reported the audible alarm to the PSCC, via radio, performed a perimeter sweep of the building and encountered the LSOC technician. After some discussion the technician resumed his troubleshooting and the guard continued the sweep. Fire Services responded to the facility and found a Fire Alarm Indication for Zone 19, indicating the Water Deluge System had been activated. Checking showed that the ARM valves had been activated, which caused the Fire Alarm indication. However the ACTIVATE valves were still closed and no water was flowing. The Gamma Ray Observatory spacecraft was located in Zone 1 of the Service Building highbay. The Water Deluge System for Zone 2 had been armed. Water flow from Zone 2 would not have caused direct impingment on the spacecraft but could have caused extensive water damage requiring retesting and repair. Analysis of the system uncovered several design and implementation deficiencies that could have contributed to the close call, but no positive evidence was found to explain the anomaly. Possible causes: Manual activation of pushbutton by an unknown party. Inadvertent short of terminals by the LSOC technician. Intermittent short in cable plant. A rash of recent false alarms at the PHSF uncovered a problem with the underground cable plant. Due to a malfunction with the air dryer, water was being pumped into the cables along with the air purge, which caused numerous shorts. A similar set of circumstances could explain the July 26, close call. Several recommendations have been made in this report to correct these deficiencies and ameliorate the possible causes. Other facilities with similar system configurations should also be reviewed.","Lesson ID":1198}
{"Driving Event":"On February 25, 1992, at approximately 0930 hours, two NASA contractor employees had been instructed by their foreman to proceed to the Locomotive Maintenance Facility, K6-1844, area to pick up four railroad switch plate kits and take them to the Wilson comer area. The two employees proceeded to load the kits, which were in palletized crates, using a National N-45 articulating boom crane mounted on the rear of a 1978 Ford truck. One of the employees operated the crane from the operator position atop the crane mast. This same employee loaded one crate into the forward area of the truck bed and while loading the second crate, the crane broke at the welded interface between the rotating turret and upright mast. Upon failing, the crane boom fell, throwing the operator to the ground. As the operator was thrown to the ground and away from the crane, he\/she landed on his\/her right leg causing it to break. When the mishap occurred, the other, uninjured employee ran to the Maintenance Facility Office area and asked personnel inside to call for help. He\/she then returned to assist the injured employee. Emergency personnel stabilized the injured employee and transported him\/her to the hospital.","Lesson ID":1186}
{"Driving Event":"On October 3, 1990, at approximately 0940 hours at the Vertical Assembly Building Transfer Aisle, the OV-104 Orbiter was being rotated toward the vertical position when three loud, thud noises were heard emanating from the Orbiter. IPR 38V-0182 was documented to investigate cause of the noise. The three (3) thuds occurred in succession, not simultaneously. Discussions were held with Engineering, Operations, Technicians, and Quality personnel to determine possible causes of the noise. A management decision was made to proceed with the soft mate of Orbiter to External Tank, visually inspect to verify Aft external tank attach nuts were in place prior to mate, mate Orbiter, remove weight of Orbiter from the attach sling (sling weight only on crane), open the Aft section and look for possible cause of noise. All of the mate functions were accomplished and Aft Section 50-1 and 50-2 doors were removed to gain access to the Aft Compartment. An avionics platform beam (G070-502677-001) was observed in the Aft Compartment. Preliminary inspection indicated flight hardware had been damaged. Photographs were initially taken of the beam location and surrounding areas. As sufficient platforms were installed, additional photos were taken to document damage. Beam G070-502677-001 was installed in the OPF by JC V35-00001 on August 15, 1990. This beam was verified as removed by Tech\/Quality on October 1, 1990, prior to close-out of the Aft compartment to support roll-over from the OPF to the VAB for mating operations.","Lesson ID":1199}
{"Driving Event":"On June 4, 1990, in High Bay 1 of the Orbiter Processing Facility (OPF) at the Kennedy Space Center (KSC), the aft bridge of the Payload Bay Bridge and Hoist System was moved approximately 78 inches aft of its set position for Payload Bay Door (PLBD) operations. The right-hand PLBD Zero-G System was configured to support a scheduled PLBD closing operation on first shift, June 4, 1990, except the Zero-G weight baskets were left pinned to their weight cages. The right Payload Bay Door (PLBD) was supported by the Zero-G cabling (not pinned to the platform). Movement of the bridge put the Zero-G cabling into tension and at an angle sufficient to shear a portion of the weight basket pulley \"V,\" fray the Zero-G cabling, move the weight basket off its track, and deflect the C-hook approximately 2 to 3 inches. Since the weight basket was pinned, the aft movement of the bridge also caused the right PLBD aft portion to rise approximately 31 to 33 inches (calculated).","Lesson ID":1200}
{"Driving Event":"On August 26, 1991 a 2.75 inch Folding Fin Aircraft Rocket (FFAR) with a French Payload aboard was being prepared for launch at the Rocket Triggered Lightning Site (RTLS), KSC. Preparations were in process using Procedure Rocket Triggered Lightning Project (RTLP) Technical Operating Procedure (TOPS) 2 Rev B dated 8\/20\/91. Two French scientists\/engineers were working on the rocket making the final payload adjustments. One French scientist was standing on the launcher assembly checking the lanyard connector, which disables the field mil motors. It was at this time that the rocket motor inadvertently ignited and launched. The time was approximately 1:11 p. m. EDT. The rocket exhaust and flame was deflected by the concrete launch pad into the left pant leg of the flame retardant white cotton coveralls reportedly causing first and second degree burns from the ankle to the knee on the shin area. Injured person was transported to Jess Parrish Hospital in Titusville, FL, was treated and released, and later returned to the launch site. The payload and rocket are not intended for recovery; however, since no data was retrieved, the launch was a total loss. Attempts to recover the payload for investigation were unsuccessful. The investigation team reviewed the RTLS operation procedures and witness statements. Key personnel from the RTLS and U.S. Air Force personnel working at the site were interviewed. In addition, the team consulted various people with expertise on the 2.75 inch FFAR, including personnel at NASA Wallops Flight Facility. Laboratory support was provided by the Materials Science Laboratory (MSL) personnel and KSC Electromagnetic Analysis (EMA) Group.","Lesson ID":1185}
{"Driving Event":"On August 12, 1991, starting at approximately 3:58 a.m. EDT, two of the three fuel cells installed on Orbiter Atlantis, OV104, were possibly damaged when inadvertently left connected to the orbiter main busses for 16 hours and 36 minutes without water removal capability. The accumulation of water has the potential for severe damage to the fuel cells. Atlantis landed at the Kennedy Space Center (KSC) on August 11, 1991, at 8:24 a.m. EDT after completing the STS-43 mission. The vehicle was undergoing deservice and safing operations in the Orbiter Processing Facility (OPF) High Bay 2 as part of the turnaround activities for its next mission, STS-44. The work effort was being accomplished by a NASA contractor. The mishap occurred when helium was inadvertently ingested into the fuel cell oxygen (02) supply causing a sudden performance loss by Fuel Cells 2 and 3 resulting in the loss of power to orbiter busses B and C. This necessitated the implementation of the Emergency Power Down Procedure. The Emergency Power Down Procedure consisted of 6 crew module switch actions and was intended to electrically isolate the fuel cells from the orbiter main busses. The Emergency Power Down Procedure did not address the loss of multiple fuel cells with no vehicle ground power and, therefore, did not accomplish the required isolation of Fuel Cells 2 and 3 from the orbiter main busses. Emergency power down procedures have been used many times during shuttle processing, most often due to loss of orbiter cooling. The Emergency Power Down Procedure did not include the provision that the only functioning bus should be the last commanded off. Since it did not address this, there was no power available to drive the Fuel Cell 2 and 3 to main bus motor switches to the open (isolate) position. During first shift and early second shift on August 12, 1991, there were reports of occasional alarms and noises, such as fans operating, emanating from the \"powered down\" orbiter. These reports, at first discounted, were investigated and determined to be resulting from the power generation of Fuel Cells 2 and 3 which were still connected to the Orbiter Main Bus B and Main Bus C respectively. The fuel cells were removed from the busses at approximately 8:34 p.m. EDT August 12, 1991 by use of ground power through the Orbiter ground umbilicals.","Lesson ID":1184}
{"Driving Event":"On April 4, 1990, at approximately 9:05 a.m. EDT, one of the three fuel cells (#3) installed in the Orbiter Atlantis, OV-104, was damaged while an attempt was being made to vent the fuel cell prior to its removal and replacement. Atlantis returned to the Kennedy Space Center (KSC) on March 3, 1990, after successfully completing the STS-36 mission. The vehicle was undergoing processing in the Orbiter Processing Facility (OPF) in preparation for the STS-38 mission in July of this year. Testing and processing was being accomplished by the Shuttle Processing Contractor (SPC) at KSC. The Fuel Cell Single Cell Voltage Test was accomplished on March 30 and 31, and the analysis of the test results indicated there were two degraded internal cells. A decision to remove and replace the fuel cell was subsequently made on April 2 by the Orbiter Project Manager. The accident occurred while attempting to vent the fuel cell with the Orbiter hydrogen (H 2) purge vent port capped. This allowed the H2 pressure to exceed the oxygen (02) pressure in the fuel cell, 2 side of the fuel cell. The Potassium Hydroxide (KOH) was found at the 02 purge port of the fuel cell indicating the ninety-six internal cells, the regulator, and the accumulator would have to be replaced due to the corrosive qualities of KOH. No one was injured and damage was limited to fuel cell #3.","Lesson ID":1182}
{"Driving Event":"The Orbiter Processing Facility (OPF) Bay 2 Firex Deluge Zone 3 Viking arm valve AV1.3-2 was leaking, and on September 21, 1989, Problem Report (PR) number PV-6-140247 was initiated to replace defective parts. During system leak check operations following valve repair, water flow from zone 3 (directly over the Orbiter) occurred in OPF Bay 2. The time of first flow was established as 10:28 AM on September 24, 1989, as recorded by OPF Water Pump House instrumentation due to diesel pump startup. The Zone 3 water flow over the Orbiter was at a reduced rate, with only a partial nozzle discharge pattern. Shuttle Processing Contract (SPC) Water Systems technicians were cycling the manual arming and firing valves while leak checking the system. Only a few minutes had passed from the time they cracked open (2 turns) the system manual supply valve until they heard about the water flow problem in Bay 2. The SPC Lead Water Systems technician ran into the OPF to see what was wrong and noted the deluge flow. He returned to the manual activation station behind the OPF and found that two SPC ground support equipment (GSE) technicians had opened the manual arming and firing valve to Zones 1, 2, 3, 4, and 5. (It is presumed Zone 3 did not flow additional water and had been deactivated by this time.) The Lead Water Systems technician then closed all the open manual arming and firing valves, as well as the manual supply isolation valves to stop all Bay 2 water flow. The scenario that lead to the two GSE technicians being at the deluge system manual flow control valve station is as follows: After the flow from Zone 3 occurred, the SPC OPF Bay 1 Site Division Manager asked a GSE technician to find someone who could turn the system off. This GSE technician, accompanied by a co-worker, proceeded to the manual activation station behind Bay 2. Upon arrival, they proceeded to position the manual arming and firing valves to Zones 1, 2, 3, 4, and 5 to the \"on\" position, thinking they were turning the firex system off. This turned on deluge system Zones 1, 2, 4, and 5 (Zone 3 had already been deactivated) to the \"full on\" mode. The Lead Water Systems technician then returned to the manual valve panels, proceeded to turn the manual arming and firing valves to the \"off\" position, and then helped his technicians close the manual supply isolation valves to Zones 1 through 5, which stopped all water flow.","Lesson ID":1183}
{"Driving Event":"During the first test firing of a flight laser, after an electronic card repair, it was noticed that there was no visible laser light observed in a television screen used for monitoring the laser. At the same time a power meter only registered .3 watt, well below the 4.4 watts expected. Upon shutting the laser down it was discovered that the laser had been firing directly into an aluminum lens cap that had just been added to the laser configuration. The existence of the lens cap was unknown to the personnel running the test. After the cap was removed, the laser was tested and it was found that no apparent damage had occurred.","Lesson ID":1179}
{"Driving Event":"The TDRS-H was launched on June 30, 2000. The satellite is the first of a new series of Tracking Data Relay Satellites. The satellite incorporated a number of new communication technologies including the Single Access Springback Reflector Antenna, transmitters and receivers operating at Ka-band and the S-band microstrip patch antenna elements used in the Multiple Access (MA) phase arrays. During In-Orbit Test (IOT), performance deficiencies were observed in the MA forward (MAF) and return (MAR) channels. The MA phase array system is complex in design and relies on both hardware and software to perform the on-board beam forming to track user satellites. Based on analysis of test data, a few minor deficiencies were corrected through changes to the software (sign error) and calibration error (phase shift settings). However, the MAR formed beam G\/T performance remained significantly below predicted performance. Performance testing of individual return array elements was initiated revealing widely divergent gain and axial ratios for the elements when compared to pre launch factory measurements. In one case, the performance of a single element was seen to degrade significantly in a 12-hour period. BSS initiated a comprehensive anomaly investigation incorporating: 1) On-orbit testing of TDRS-H; 2) Laboratory performance investigation of flight MA antenna elements; and 3) Factory satellite system level MA testing using the TDRS-I then undergoing integration and test. Ultimately, BSS determined that the most probable cause of the observed performance was due to the MA array sunshield (thermal blanket) coming into contact with the antenna array elements. Such contact creates a dielectric loading of the microstrip patch radiators and transmission lines altering the phase relationship of the radiators and shifting the resonant frequency of the elements. Altering the phase relationship causes the element gain pattern to \"squint\" or move off axis by some 8 degrees. The peak directivity, resistive loss and VSWR (Voltage Standing Wave Ratio) performance of the MA antenna elements degraded as a result of the close proximity of the sunshield. The sunshield is held in contact with the elements by electrostatic force created by deep charging of the dielectric materials used in the construction of the antenna elements. In response, a negative \"image\" charge appears in the sunshield (since it is conductive and grounded), and the electrostatic attractive force field is created.","Lesson ID":1180}
{"Driving Event":"Inadequate Planning Horizon for Shuttle Which Will Most Likely Fly Through 2020","Lesson ID":1160}
{"Driving Event":"Implementation of NASA Agency-Wide Computer Security Plan","Lesson ID":1149}
{"Driving Event":"Agency-Wide Computer System Vulnerabilities","Lesson ID":1150}
{"Driving Event":"Poor Flight Operations Definition of Roles and Responsibilities for Stratospheric Observatory for Infrared Astronomy (SOFIA) Program","Lesson ID":1157}
{"Driving Event":"International Space Station (ISS) Multiplexer-Demultiplexer (MDM) Central Processor Unit (CPU) Utilization Design Limit","Lesson ID":1177}
{"Driving Event":"During a Pegasus launch from Kwajalein Island on October 9, 2000 the stage 1\/2 interstage did not initially fully separate causing the launch vehicle to yaw significantly.","Lesson ID":1145}
{"Driving Event":"Lack of an Adequate Crew Escape System for the Orbiter for Launch Through Insertion","Lesson ID":1161}
{"Driving Event":"Scheduled Deployment of Neutron Dosimetry Aboard the International Space Station (ISS)","Lesson ID":1178}
{"Driving Event":"NASA Initial Planning to Migrate Some Shuttle GPC Functions to New Mission Computer(s)","Lesson ID":1152}
{"Driving Event":"Lack of International Partner Elements Software Source Code","Lesson ID":1153}
{"Driving Event":"Current SOFIA 747-SP Aircraft Cannot be Rated for International Flight Without Avionics Upgrades","Lesson ID":1159}
{"Driving Event":"Aging Ground Processing and Launch Infrastructure at Kennedy Space Center (KSC)","Lesson ID":1164}
{"Driving Event":"Inadequate Flight Operations Oversight of Stratospheric Observatory for Infrared Astronomy (SOFIA) Program","Lesson ID":1168}
{"Driving Event":"Potential Inadequate International Space Station (ISS) Downlink Encryption","Lesson ID":1148}
{"Driving Event":"NASA Pursuit of Shuttle Avionics Upgrades","Lesson ID":1151}
{"Driving Event":"Potential Common Mode Failure Potential for Hydraulic Lines in Close Proximity to Each Other","Lesson ID":1162}
{"Driving Event":"Portable Computer System (PCS) Software is Not Developed Concurrently With Primary International Space Station (ISS) Flight Software Leading to Inadequate Multiple Element Integrated Testing (MEIT)","Lesson ID":1165}
{"Driving Event":"Potential for X-38 Design Knowledge Transfer will be Inadequate When Contractor Selected to Build the Crew Return Vehicle (CRV)","Lesson ID":1167}
{"Driving Event":"Need to Upgrade International Space Station (ISS) Command and Data Handling (C&DH) Components as Soon as Possible","Lesson ID":1129}
{"Driving Event":"Crew Return Vehicle (CRV) Schedule Requirement for ISS Crew Greater Than 3","Lesson ID":1141}
{"Driving Event":"Potential Unauthorized Access to Checkout and Launch Control System (CLCS)","Lesson ID":1127}
{"Driving Event":"Compromising of the current Data Encryption Standard (DES)","Lesson ID":1133}
{"Driving Event":"Lack of Plan to Maintain Commercial Off the Shelf Software Development Tools","Lesson ID":1128}
{"Driving Event":"Workforce Downsizing Impacts on Critical Skills at Office of Space Flight (OSF) Centers","Lesson ID":1134}
{"Driving Event":"Radiation Research and Protection Implementation Planning at NASA","Lesson ID":1142}
{"Driving Event":"Lack of Source Code for International Partner Elements of Space Station","Lesson ID":1130}
{"Driving Event":"Consistent User Involvement in Software Development Process","Lesson ID":1132}
{"Driving Event":"Utilization of Russian-Built SFOG May Pose a Safety Hazard Aboard International Space Station (ISS) Given Past Problems With the Solid Fuel Oxygen Generator (SFOG)","Lesson ID":1143}
{"Driving Event":"On 8\/28\/97, the last working day before Labor Day weekend, a Contractor's was installing a 3\" copper underground compressed air line into a trench approximately 18\" wide and 3 feet deep. After having completed about 100 feet of pipe, the Contractor's crew began a pressure test of the 3\" pipeline for acceptance. The test was performed prior to installation of a secondary fiberglass pipe to cover the 3\" copper pipe and backfill the trench. The specified working pressure of the 3\" copper compressed air line was 125 PSI. The specified test pressure was 188 PSI. While the 3\" copper line was still under pressure test, the crew began to install the secondary fiberglass pipe to encase the 3\" copper primary pipe. As the crew was lowering the pipe into the trench, approximately 2:45 PM, the crew heard the sound of a \"pop\" and then the sound of leaking air coming from a pipe joint coupling. While the 3\" copper line was still under pressure, one worker went into the trench attempting to check the location and the extent of the leak. While the worker was checking the position and direction of the leak from the pipe coupling, the soldered joint failed and the pipeline de-pressurized explosively. An 84-foot section of the pipeline that lead from the bottom of the trench to ground level was propelled approximately 8 to 9 feet longitudinally along the edge of the trench. Air from the explosive depressurization blew sand and soil on the worker in the trench. The sand abraded the worker's arms, chest, and abdominal. The pipe also struck the worker in the left knee and groin area. The worker was taken to the Edwards AFB Hospital for treatment. The worker was released from the hospital after treatment that evening. The worker was wearing personal protective equipment (PPE) including a hardhat, boots, safety glasses, and gloves at the time of the accident.","Lesson ID":1096}
{"Driving Event":"The STS-88\/2A mission had around 150 Chits written requesting information from the Mission Evaluation Room (MER), Flight Control Team, or Moscow. The ISS MER Chits did not require Safety concurrence prior to closure by the MER Manager. Many Chits had safety implications; approval without Safety concurrence might have negatively affected Hazard Controls, Flight Rules, or Critical Items. Users of Chits may not be aware of existence of Safety concurrence or disapproval of Chits.","Lesson ID":1097}
{"Driving Event":"There were a number of different organizations involved in the processing of the 2A hardware and each organization had its own set of work rules. This often caused confusion among the different organizations and KSC personnel that were required to work on the hardware. There were also policies and work practices that were new to the organizations and were not documented for a consistent implementation. These policies and rules ranged from topics like tool control and access control to topics such as scheduling and test readiness reviews. The confusion with the rules and policies often led to work delays and the loss of a team atmosphere. Root cause: Integration of multiple players was not factored into program planning at the lowest levels.","Lesson ID":1098}
{"Driving Event":"Crew Involvement in Integration Testing","Lesson ID":1106}
{"Driving Event":"Initial Operational Capability of Crew Return Vehicle (CRV)","Lesson ID":1107}
{"Driving Event":"Safety Implications of Extravehicular Activity (EVA) Training in the Russian Hydrolab","Lesson ID":1116}
{"Driving Event":"Validation of Flight Software for X-34 and L-1011 Carrier Aircraft Flight Separation","Lesson ID":1122}
{"Driving Event":"Lack of NASA Range Safety Authority for X-33 and X-34 Programs","Lesson ID":1123}
{"Driving Event":"Outmoded Design of Space Shuttle General Purpose Computer (GPC) Limit Software and Hardware Upgrades","Lesson ID":1124}
{"Driving Event":"On August 19, 1999, contractors were removing concrete from around steam lines with a jackhammer. These steam lines should have been de-energized prior to commencement of the work but one line was found to still be pressurized with 100 psi steam. Background: The pressurized steam line incident occurred in and around Building 24, the Goddard Space Flight Center (GSFC) Central Power Plant (CPP), Steam Manhole (STW # 30 and an excavated hole outside of the north side of the CPP. A work request (#8002) was submitted in June 1998 to reroute the Condensate and High Pressure Drip (HPD) lines entering Building 24 at the north wall into the blow-down pit. The corrosive atmosphere in the pit was degrading the pipes so plans called for rerouting them above ground and bringing them through the wall above the pit. The plans developed to complete this task would include excavation of the site to expose the lines and the cutting and rerouting of the lines above ground. Detailed drawings and plans for this task were developed and in April 1999 the work commenced. After excavation of the site, it was discovered that the concrete kicker that held the pipes in place was much larger and closer to the wall than anticipated. This required a Field Change Request (#8002-1) to allow for jackhammer removal of the concrete kicker surrounding the condensate and HPD lines so that the necessary modifications could be made. The Project Manager (PM) for the re-routing project submitted a Utility Outage Request (UOR) to de-energize the condensate, the HPD and the adjoining High Pressure Steam (BPS) line prior to removal of the concrete. Note that the concrete kicker in question surrounded all three pipes. The contractors never intended to jackhammer the concrete around the HPS line but requested it to be de-energized as a precaution. The UOR submitted for de-energizing the condensate, HPD and BPS line requested the outage for 7:00 a.m. on August 19, 1999 through 3:30 p.m. August 20, 1999. Securing these three lines required actions on the part of the Mechanical Maintenance Shop (MMS) and the CPP. The back of the UOR is the Utility Outage Safe Clearance Plan (UOSCP). One section of the UOSCP is reserved for the organization with the action to fill out what procedure is necessary to complete the outage. This section for the subject UOSCP was filled out by the MMS supervisor and included a brief statement about what action was necessary by CPP personnel. A CPP representative did not fill out the CPP procedure portion of the form, despite a note from the MMS supervisor requesting the CPP supervisor to review the section and sign off. The correct method for de-energizing the BPS line consists of closing the appropriate valves in STMH #30 and closing valves #1 through #3. After all valves are closed, the line must be \"blown down\", that is, a pressure relief valve should be opened in the blow-down pit to allow the existing steam to escape. Contractor personnel involved in the excavation and pipe re-routing project were the Construction Manager (CM), the Project Manager (PM), and the excavators, jack-hammerers, and pipe fitters. Personnel that were responsible for de-energizing the steam lines being worked on were civil servants from the MMS and the CPP. The following incident description describes the sequence of events that happened August 19, 1999 as best as the Mishap Investigation Board (MIB) could reconstruct from witness testimony. Although many events were described by more than one witness as having occurred, the timeframes and order in which they occurred were often in conflict. The MIB felt that the descriptions of events were more accurate than the times associated with them by individuals' memories and therefore based this incident description on the most common version of events. On the morning of August 19, 1999, the contractor began preparations to commence jack-hammering the concrete kicker. Preparations included clearing debris from the excavated hole, setting up an air compressor to power the jackhammer and talking with CPP personnel about the UOR. The contractor's on-site supervisor and the CPP Maintenance Leader walked around inside the CPP identifying which valves needed to be shut off. Testimony is conflicting on whether or not they discussed the need to secure the HPS line at this time. Around the same time, MMS workers entered STMH #30 and closed, locked and tagged out (LOTO) the appropriate valves. After the valves were secured a MMS worker entered the CPP to inform them that the valves under MMS control were closed. While in STMH #30, MMS personnel discovered a leaking valve gasket on the line going from STMH #30 into building 4 that needed repair. This leaking valve gasket had no impact on the section of line being de-energized. MMS personnel then proceeded to STMH # 15 to secure valves so that the gasket could be repaired later in the day. This is a common procedure in the MMS known as a 'piggy-back' job, where the MMS takes advantage of an already existing UOR to complete some of their work. At some time on the morning of August 19, 1999, the CPP Maintenance Leader, an Operations Leader and a Boiler Operator began the task of closing valves. According to testimony, the Maintenance Leader was leading the task and instructing the Boiler Operator in which valves to close. The condensate and BPD lines were reportedly secured without incident. Due to the complexity of the main north header lines, the lack of \"as built\" CPP drawings, the lack of a procedure for securing the north side of the CPP and the lack of valve labels, closure of the BPS line required that the personnel involved trace the north header line down to identify the valves that needed to be closed. The first valve closed was Steam System Valve (SSV)-003. The second valve closed was SSV-0 17. While CPP personnel were in the process of closing the HPS valves, MMS personnel returned to STMH# 30 to replace the leaking valve gasket going into Bldg 4. They noticed the HPS line was still hot. It should have cooled off by this time if the line had been properly secured in the morning per the UOR. The MMS Shift Leader testified that they also noticed that the subcontractor was jack-hammering at this time. The MMS workers went to the CPP to investigate. This is believed to have occurred just before 1:00 p.m. In approximately the same time frame, the contractors also noticed that the BPS line seemed hot. They notified the CM, who came to the site to investigate. He also went into the CPP to investigate. Both the MMS workers and the CM confronted the CPP Maintenance Leader to find out why the HPS line had not been de-energized. When the MMS and CM confronted the CPP Maintenance Leader and he realized the BPS line was still pressurized, he directed the CPP workers to close the third valve, SSV-007. The MMS workers and Boiler Operator then entered the blow-down pit in the CPP and set up the blow-down to de-energize the HPS line. Once the blow-down was set, the MMS workers left. The CM also left the CPP and informed the contractor that the line was now secured. Later in the day, CPP personnel noticed that the blow-down was still going on after it should have been completed. The CPP Maintenance Leader consulted with the MMS Shift Leader and they concluded that it was likely that one or more of the valves previously closed was leaking through. They suspected valve SSV-0 17 since it had not been replaced during the recent renovations. As it was time for a shift change (approximately 3:00 p.m.), the Maintenance Leader requested that the second shift Operations Leader have one of his workers close the fourth valve, SSV-0 16. The MIB notes that SSV-0 16 is extremely difficult and hazardous to reach and that this fact may have influenced the CPP personnel's decision not to attempt to close it earlier. It is also documented in the Operations Leader's Log that the first shift Operations Leader asked the second shift Operations Leader to \"chain lock the North Main Header Valve\" (i.e., lock out the valve). The CPP LOTO log does not have an entry for any LOTO on valves for that day, August 19, 1999. This implies that the BPS line valves were not locked or tagged out at the time they were closed. Once these tasks were completed and the line was completely blown down, it could be considered de-energized and safe for the contractors to begin jack-hammering concrete. Follow on Events: The MMS Shift Leader realized that the sub-contractors jack-hammering in the vicinity of a pressurized HPS line was a hazardous event and therefore reported these events to his supervisor. The MMS supervisor reported them to the General Foreman, who is in charge of both the MMS and CPP operations. The General Foreman called a meeting the next day between MMS and CPP personnel involved so that they could determine exactly what happened and how to prevent it from happening in the future. The primary result of that meeting was the establishment of a new policy for future outages involving the MMS and CPP. The new policy calls for a face-to-face meeting between the workers executing the outage to work out what needs to be done and verify that it has been done. An action was given to write a Standard Operating Procedure (SOP) documenting that policy. Testimony conflicts as to who actually received that action. The MIB could find no evidence that it had been done. The Board notes that face-to-face meetings did in fact occur between MMS and CPP personnel during this outage; however, these meetings did not prevent the close call from occurring. Therefore, the proposed corrective actions generated by this meeting did not adequately address the cause (s) of the close call. The MMS Shift Leader also contacted the GSFC Safety and Environmental Branch and informed the Occupational Safety and Health (OSH) Manager of the incident. The OSA Manager requested that the MMS Shift Leader write down his recollections of the events. The MMS Shift Leader did this and handed it over to the OSH representative, expecting them to investigate the incident. Representatives from OSH testified that they decided at this point not to investigate but rather to wait for Code 220 to officially notify them of the close call via a NASA Mishap Report form (1627 form). They wanted to see if a new close call reporting initiative instituted by Code 220 would work. A Mishap Report form was not submitted by Code 220, the MMS or the CPP immediately following the incident so nothing was done for approximately 2 months. When Code 205.2 received word that this MIB was being formed to investigate this close call they assisted Code 227 in writing a Mishap Report form. This form does not accurately reflect the written witness statement previously provided to Code 205.2 nor do the corrective actions listed fully address the incident root causes.","Lesson ID":1084}
{"Driving Event":"During pre-operations for the 5A US Lab Closed Hatch Environmental Control & Life Support System\/Thermal Control System (ECLSS\/TCS) testing, a water separator fault occurred in the Common Cabin Air Assembly (CCAA). The inlet ORU was pulled and found to be wet inside. Three to four ounces of water were noted on the rack floor under the separator\/heat exchanger. A small amount of water was found inside the separator but not enough to touch electronics. Water was also found in other areas (hydroflow fitting and coupler of the inlet hose and the inside of the inlet). Root cause: The Test Procedure (TP) and Test Preparaton and Restoration Document (TP&RD) were not synchronized. The TP&RD placed a valve in series between the water separator and the GSE collection tank. The TP&RD also, appropriately, had the valve closed to keep water in the line after it was filled and before water separator was started. The TP did not open the valve before initaiation of water separator operations. The TP&RD & TP WERE NOT carefully reviewed for complete integration.","Lesson ID":1091}
{"Driving Event":"The Center has an existing campus complex of modular buildings fed by a main distribution panel (MDP) with 120-208 volt\/3 phase power output. A recent project added 3 more buildings to the complex, each having its own 120-208 volt\/3 phase power panel. The mechanical engineer specified HVAC units by specific brand name and numeric catalog number, \"or approved equal\". Embedded in that catalog number was a letter code that denoted the specific voltage for the HVAC equipment motors. In this case it denoted 480 volt power. The electrical drawings and specifications (provided by NASA) showed 120-208 volt power supply. Therefore, the mechanical subcontractor furnished and installed exactly what NASA specified and approved during product submittals. It was only when the HVAC equipment was actually installed in the field, and the electrical subcontractor tried to connect up the 208 volt circuit feeder that anyone realized that there was insufficient voltage to power the specified 480 volt HVAC motors. NASA had several options: (1) Remove the 480 volt equipment and replace them with new 208 volt equipment. (2) Run new 480 volt circuits back to the campus main switchgear. (3) Install new additional step-up transformers for each of the 3 HVAC units. Due to constructability, cost and schedule impacts, option #3 was selected.","Lesson ID":1095}
{"Driving Event":"The High Powered Amplifiers for the Early Communications Projects (ECOMM) provided by a prime contractor's supplier failed to meet performance and quality requirements (defective soldering workmanship) resulting in schedule impacts. Root cause: The procurement process for Criticality 3 (non-critical) hardware, by JSC contractors, has in some cases not received the same quality assurance rigors as the procurement process involving critical hardware. The quality assurance activities to be performed at source by, the prime contractor, should be predicated on risk and proven ability of a subcontractor to supply conforming items. In this case the decision to forego source activities was based solely on the criticality of the hardware and did not take into consideration the complexity of the hardware and lack of subcontractor historical data. Deficiencies were noted in the following areas for this particular procurement: Inadequate supplier selection process. A site survey was not performed to verify subcontractor capabilities. Inadequate contract monitoring of supplier performance and progress. Source inspection was not performed by the prime.","Lesson ID":1100}
{"Driving Event":"Several items of EVA hardware were lost during the EVAs on STS-88. Impact to immediate mission is loss of availability of needed tools. Lost tooling, when unretrieved, also adds to on orbit debris. The flight support equipment (FSE) for the EVA installable slidewire and an on-orbit installed worksite interface (OIWIF) with an attached retractable tether were lost on EVA1. One of the trunnion pin covers was lost on EVA2. Two of the safety tether hook guards were also lost during the EVAs. There is no identified common hardware cause for the lost hardware. The EVA Project Office chartered a team to investigate the issue and make recommendations for corrective action. Root cause: Slidewire Carrier - inconclusive, most probable cause is inadvertent opening of Tool Stanchion bayonet. On orbit installed WIF\/retractable tether - inconclusive, most probable cause was the hardware was tethered to another end item and was released when that end item was removed from the mini workstation. Trunnion pin cover - was not properly tethered due to a lack of a tether loop on the mockup\/trainer. Tether hook clips - inadequate restraint in design.","Lesson ID":1101}
{"Driving Event":"Thorough Risk Assessment and Testing Program for the Crew Return Vehicle (CRV)","Lesson ID":1108}
{"Driving Event":"Reduction in the Annual Limit for Radiation Exposure","Lesson ID":1109}
{"Driving Event":"Lack of Sufficient Operational Assets to Procure Necessary Safety Hardware","Lesson ID":1113}
{"Driving Event":"On December 26, 1998, two employees were left working in an electrical manhole unattended in violation of confined space entry requirements. The Electrical Manhole incident occurred in and around Electrical Manhole #PM-70 (labeled as a Telephone Manhole) which is located on the south side of Building 13 at GSFC. All Personnel involved in this incident were civil servants from the Electrical Distribution Section (Code 227. 1). A call came in to the GSFC emergency console at approximately 5:30 a.m. on December 25, 1998 that there was a loss of power on feeder 7 in buildings 3\/13\/14. Electricians worked throughout that day and into the next to isolate and identify the problem. It was determined to be a fault on phase A feeder B-7 located in manhole PM-70. By the end of the 1' shift\/beginning of the 2' shift on December 26, the four workers involved in the incident began working together to fix the problem. The four workers (two from the 1' shift and two from the 2' shift) arrived at PM-70 and began setting up to complete the task. The workers informally discussed the task prior to commencing work. One of the V shift workers assumed the lead although there was no 'official' task leader. Testimony is conflicting on whether or not proper confined space entry procedures were followed. Although there was some testimony that a gas\/air check was completed prior to workers entering the manhole (MH), there is no documentation to support that assertion. The investigation did not reveal a confined space entry permit, a gas\/air check log book entry or evidence that a work life station was established per the GSFC Facilities Maintenance Division (FMD) (Code 220) Policy and Operational Procedures for Confined Space Guidelines or OSHA Standard 1910.146 requirements (References C and D, respectively). The two 1' shift workers entered the manhole and commenced work (now referred to as the MH workers) and the two 2' shift workers remained above ground (now referred to as the AG workers). The MH was very small so the AG workers removed the ladder to give the MH workers more room. While the MH workers were working in the MH, one of the AG workers (now referred to as AG 1) left the area to do the east sub-station checks. The second AG worker (now referred to as AG 2) remained as safety monitor above the MH. No one informed the MH workers that AG I had left. The MH workers requested that AG 2 get them a specific tool. AG 2 informed the MH workers that the tool was not at the worksite and he would have to retrieve it from the shop (located in Building 24). The MH workers acknowledged that AG 2 would be leaving the site. Since they did not know AG I had left, they were unaware that AG 2 leaving left them in the MH unattended. AG 2 believed that retrieving the tool would only take a few minutes and that AG I would be returning shortly, probably before he returned. The MH workers discovered they were alone when they called for AG I and got no response. One MH worker stood on the shoulders of the other to peer out of the MH and saw AG I in his truck. The MH workers immediately proceeded to exit the MH and confront AG 1. The MH workers believed that AG I was in the truck to stay warm rather than monitoring the MH. At approximately the same time, AG 2 returned to the site and observed the MH workers were angry at having been left unattended in hole. Testimony does not indicate that the four workers cleared up what exactly had transpired at this time. Testimony indicates that the time the MH workers were left unattended was from 1 to 5 minutes. The workers continued to work on the task after this incident occurred (the job was not completed for several days).","Lesson ID":1085}
{"Driving Event":"During the launch of the Pegasus\/SCD 1 on February 9, 1993, an incident occurred in the final minute of the countdown where an abort was initiated by the Wallops Flight Facility (WFF) Range Safety Officer (RSO); however, the operation continued with the launch of the Pegasus vehicle. At T minus 0:59, the WFF\/RSO initiated an abort due to an apparent momentary dropout of the Command Destruct Receiver (CDR). The abort call was picked up by the WFF Test Director (TD), who immediately enunciated the abort, at T minus 0:56 and T minus 0:47. The countdown clock was stopped at T minus 0:52 seconds and was not restarted until Pegasus release at T minus 0:00. A contractor Test Conductor (TC) announced the abort at T minus 0:44, and the abort was passed by NASA 1 to the B-52 at approximately T minus 0:34. The B-52 crew replied that the fin batteries were on and that they understood the abort. Following this discussion, the contractor TC rescinded the abort call, and NASA 1 passed the negative on the abort to the B-52 at T minus 0:22. The Pegasus vehicle was then dropped from the B-52 near T minus 0:00 time. Key WFF personnel in the Range Control Center (RCC) were not expecting the drop due to the abort call. However, the drop was observed on video, the alert was sounded that Pegasus had been launched, and all supporting personnel and stations responded immediately. Their timely response allowed the successful completion of this mission. At no time during the flight was the ability to destruct the Pegasus jeopardized.","Lesson ID":1090}
{"Driving Event":"Use of High-Fidelity Simulations of On-Orbit Components in MEIT","Lesson ID":1105}
{"Driving Event":"Joint Training for Backup ISS Crewmembers","Lesson ID":1112}
{"Driving Event":"Redundancy of Safety-Critical Flight Systems","Lesson ID":1120}
{"Driving Event":"On Sunday March 8, 1992 the TOPEX\/POSEIDON Spacecraft was being prepared for thermal vacuum (T\/V) testing by a test team in Building 10 of the Goddard Space Flight Center (GSFC). As part of the procedure, the T\/V Fixture Assembly consisting of the spacecraft, thermal test shrouding and instrumentation mounted on the Spacecraft Horizontal Support Structure (SHSS), suspended by four vertical cables from an H-frame spreader bar was lifted and positioned above the T\/V chamber. At approximately 11:25 a.m., during final north \/ south crane positioning maneuvers, the suspended assembly began a slow overturning rotation. The assembly rotated approximately 135 degrees from horizontal before being halted by the entanglement of one of the four suspension cables with the SHSS. After some bouncing and jostling, it came to rest at approximately 115 degrees. While resting in this anomalous position (+X end up), the Test Team visually determined that the H frame spreader bar assembly had sustained considerable damage during the rotation and might fail. A decision was made by the Spacecraft Manager to remove the vertical load from the overstressed and damaged H frame spreader assembly as quickly as possible by lowering the spacecraft and test fixture to the chamber floor. Within ten minutes of the overturning incident the Test Team, augmented by personnel from a GSFC contractor, lowered the rotated assembly to the chamber floor where it was temporarily secured. During the subsequent visual inspection of the secured assembly it was noted that sections of the thermal test shroud and support fixturing had partially yielded. However, no apparent damage to the spacecraft or to the lower frame of the SHSS could be seen. An on site \"failure review board\" of civil servant and contractor personnel was convened to review and discuss the situation. A decision was made by the board that the Spacecraft\/SHSS assembly should be removed and reoriented to a horizontal position outside of the chamber to minimize any further yielding of the supporting structures. A rigging crew was on the scene at this time, and was given the go ahead by the board to proceed with the removal of the Spacecraft\/SHSS assembly from the chamber. The damaged H-frame spreader bar and the four suspension cables were removed. A pair of nylon slings were attached from the +X end of the SHSS to the crane hook and the Spacecraft\/Thermal Shroud\/SHSS assembly was raised vertically out of the T\/V chamber and moved directly adjacent to it. The assembly remained there suspended a few inches above the floor while the team attached additional slings from the -X end of the SHSS to a forklift positioned on the -Z side of the load. By alternating operations of the crane and the forklift, the spacecraft and fixture were reoriented horizontally and lowered to the floor. At approximately 6:51 p.m. the operation was completed with the Spacecraft\/SHSS assembly safely on the floor in the normal attitude. A video recording of both the anomaly and the recovery operation was made and is available from the TOPEX Project office for viewing.","Lesson ID":1089}
{"Driving Event":"The Project had several Government partners and each had a their own rules of engagement with regard to agreements and sharing of responsibilities. While some of these differences were cultural, many were driven by higher-level requirements such as treaties and other international agreements. The Project's unfamiliarity with these differences lead to difficult negotiations and un-necessary uncertainty in several of the Project's data requirements.","Lesson ID":1094}
{"Driving Event":"Space Vision System (SVS) targets have become an undue burden during EVA. The requirement to restrain cables away from SVS targets added 45 minutes to 1 hour EVA time and will change during the mission. The EVA community has been informed that the targets can be easily damaged by EVA loads, yet the targets are in or near translation paths. A better understanding of the criticality of keeping the targets free of obstructions and the sensitivity of the targets to EVA contact is required. The SVS community must understand the EVA environment and not place unrealistic constraints on the conduct of the EVA. The EVA Project Office is working with the SVS community to resolve these issues. Root cause: Insufficient coordination and understanding between the SVS and EVA communities.","Lesson ID":1099}
{"Driving Event":"Use of Hardware Before Qualification Testing and the Use of Software Before Verification and Validation","Lesson ID":1104}
{"Driving Event":"Use of \"Fire-Evident\" Pyrotechnic Initiators","Lesson ID":1111}
{"Driving Event":"Lack of Dependency Matrix for I-Load Recalculation","Lesson ID":1125}
{"Driving Event":"The Deep Space 1 (DS1) mission included breakthrough technologies that were critical to mission success and had not been proven in space flight. Although DS1 exceeded its overall technology demonstration objectives, certain important technologies under development never achieved flight readiness. Specifically, the Three Dimensional Stack (3DS) flight computer was deferred to a subsequent mission, and the Remote Agent Flight Software was downgraded to an in-flight experiment. A set of technology readiness \"gates\" had been established for evaluating the flight readiness of the breakthrough technologies. However, these gates were poorly defined, and the Integrated Product Development Teams and the Program Office did not fully commit to them. Further, the development schedules for these advanced technologies were too short. Plans were in place for backups for some of these technologies (but not all) should their development prove unsuccessful. Certain technologies were coupled such that problems with one could hinder the successful development of another. In-flight demonstration of the autonomous onboard optical navigation system (AutoNav) was required for mission success, yet its use depended on the performance of the Miniature Integrated Camera\/Spectrometer (MICAS). Both AutoNav and MICAS involved new technologies: there was no backup for MICAS in the event its development proved unsuccessful. MICAS performance problems during both development and flight significantly compromised the in-flight demonstration of AutoNav, forcing major software modifications. References: \"Deep Space 1 Lessons Learned,\" JPL internal presentation, David H. Lehman, December 1, 2000. \"Controlling Risk on Cost-Capped, Schedule-Driven, Technology Validation Projects\", NASA Lessons Learned \"Reference Lesson #1033\" Additional Key Words: Autonomous Navigation, Flight Qualification, Management and Planning, Technology Plan, Technology Readiness Level","Lesson ID":1087}
{"Driving Event":"The Project chose a commercial vendor to build a unique piece of hardware for a one-shot NASA launch mission. In addition to its contract with NASA, this vendor had several repeat high volume customers. Therefore, as commitments to other customers taxed the vendor's resources, the vendor demoted NASA's requirements to a lower priority and were not able to meet schedule or cost. An alternate vendor had to be brought in to help in the recovery and the Project was forced to accept additional risk in the flight hardware.","Lesson ID":1093}
{"Driving Event":"Validation of Extravehicular Mobility Unit (EMU) Planar Hard Upper Torso (HUT) Capability","Lesson ID":1114}
{"Driving Event":"Modification of Prebreathe Protocol for Extravehicular Activity (EVA) Operations","Lesson ID":1117}
{"Driving Event":"Increasing Extravehicular Mobility Unit (EMU) Shielding to Reduce Crew Radiation Exposure","Lesson ID":1118}
{"Driving Event":"Extravehicular Mobility Unit (EMU) and Orlan Suit Criterion","Lesson ID":1119}
{"Driving Event":"Flight Support Motor (FSM) Test Intervals","Lesson ID":1077}
{"Driving Event":"Effects of Radiation Exposure on ISS Expedition Crews","Lesson ID":1071}
{"Driving Event":"Safety Mishap on the KC-135. An experiment rig that is flown on the KC-135 utilized a quick-release V-band to seal a pressurized chamber. The chamber was used to conduct combustion experiments during the KC-135 flight. The v-band was implemented in order to permit quick and easy access to the chamber interior in order to change samples and access interior components and instrumentation. During the KC-135, the V-band was released when the chamber was still pressurized. Once the V-band was released, the chamber lid was propelled off the chamber and across the plane's cabin area. The lid just missed one of the experiment operators and caused damage to one of the plane's interior lights. The experiment operation procedures had steps to identify relief of pressure, but those were skipped, and the V-band and chamber lid design contain no other lid retention element.","Lesson ID":1069}
{"Driving Event":"Increased Cannibalization Trends","Lesson ID":1074}
{"Driving Event":"Increased Space Shuttle Main Engine (SSME) Power Setting for Intact Aborts","Lesson ID":1078}
{"Driving Event":"Increased Space Shuttle Main Engine (SSME) Power Setting for Intact Aborts","Lesson ID":1079}
{"Driving Event":"Shuttle Spares Support Will Likely Decline With an Increased Flight Rate","Lesson ID":1068}
{"Driving Event":"Line-Replaceable Unit (LRU) Restoration and Upgrading","Lesson ID":1076}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1238; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Designing and testing flight harnesses in accordance with the requirements of the GSFC Design and Manufacturing Standard (Ref. 1) for Electrical Harnesses enhances the probability of mission success (Reliability) by ensuring that harnesses meet high standards of quality as well as the electrical and environmental requirements of space flight missions. The occurrence of early failures is minimized. Implementation: Flight electrical harnesses are designed in accordance with the requirements and specifications of the GSFC Design and Manufacturing Standard for Electrical Harnesses (reference 1) which establishes the minimum requirements for the design and fabrication of space flight harnesses. Parts and materials are used as specified in the harness standard that can perform satisfactorily in the environments to be encountered. Fabrication methods and techniques are used as defined to ensure high quality electrical harnesses. The GSFC Design and Manufacturing Standard for Electrical Harnesses incorporates and references applicable requirements from a wide range of Federal, Military, and NASA specifications, standards, and publications. Maximum current-carrying capacity is defined for wire sizes ranging from size AWG 12 to AWG 24 to ensure that the total temperature of wire does not exceed the operating temperature ratings of the wire. The total temperature of the wire includes the ambient space temperatures and the temperature rises due to current flows. The maximum voltage drop between power supplies and loads due to the impedance of wire and ground return paths are specified for various power supply voltage levels. The minimum size of individual wires used in harnesses is AWG 24 except for power harnesses where the minimum size of wires is limited to AWG 22. A number of EMI design and construction techniques are used to minimize electromagnetic coupling between wires within harness assemblies. These techniques include isolation of different signal types such as high level and pulse signals from low level and continuous wave signals by using separate harnesses and connectors where possible. When these signal types must be included within the sane harness, the best possible isolation is obtained by grouping wires of similar signal types within the harness and on connectors. Other methods include shielding of individual wires or groupings of wires within the harness and using separate connectors where possible. Twisted pair leads, shielded when necessary, are used for power and balanced signal circuits. RG type RF cables terminated at both ends with coaxial connectors are used for RF signals. A number of physical parameters and limitations are used as defined in the Design and Manufacturing Standard for Electrical Harnesses. The diameter of the harness is kept to a minimum and limited to one inch in diameter consistent with requirements for routing, installation, and handling. The Design and Manufacturing Standard for Harnesses contains information and a method for estimating the diameter of a harness. The lengths of harnesses are made to provide enough additional wire length for reworking connections at least one time. Minimum bend radiuses, location and support of wire breakouts, shielding and termination of shields are followed as defined in the harness standard. Harnesses are secured with lacing tape or tie wraps and movement is controlled by means of cable clamps or tie wraps. Electrical connector types including protective covers, sealing grommets, wire splices, and potting compounds are selected and fabricated as required by the harness standard. Probing or testing flight harnesses or connectors is always accomplished via connector savors or breakout boxes. Mate\/demate logs are maintained and connector inspections are instituted once the connector mate\/demate count reaches 15 and inspected every 10 mates\/demates thereafter. Connector hardware is staked with an approved epoxy after torquing. The staking is an indication that the hardware has been torqued and that it has not been disturbed. A number of quality assurance provisions are followed as defined in the Design and Manufacturing Standard for Electrical Harnesses. Visual inspection includes harness documentation, materials used, design and fabrication methods, identification of components, and workmanship. Harness assemblies are tested for point to point electrical continuity in accordance with applicable wiring diagrams or wire lists. Values, within a connector bundle of the same conductor size and wire length, must be consistent within 10%. Insulation resistance is measured between each conductor and every other conductor and each conductor and shield. The insulation resistance must be greater than 100 megohm at an applied voltage voltage of 500v dc for a maximum of one minute. Essentially all harnesses have strict contamination control and certification requirements. To meet these requirements shielding braids are ultrasonically cleaned with an approved solvent and wires and cable are wiped with clean lint free cloths and an approved solvent before fabrication into the harness. After harness fabrication is complete and certified, the complete harness is cleaned with an approved solvent, inspected with both black and white light. Technical Rationale: The proper design, fabrication, testing, and certification of electrical harnesses significantly reduces the probability of spacecraft failures due to harness material deterioration in space, wire and connector failures due to current overloading, excessive stresses, and crosstalk and arcing between wires and harnesses. The use of appropriate materials and cleaning technique's during and following fabrication of harnesses controls contamination that can cause deterioration and failure of spacecraft hardware particularly many types of scientific instruments. References Design and Manufacturing Standard for Electrical Harnesses, Document No. GSFC-733-HARN-01","Lesson ID":722}
{"Driving Event":"The X-33 STA tank was sent from Marshall Space Flight Center (MSFC), Huntsville, Alabama, to NASA Glenn Research Center, Cleveland, Ohio via commercial ground carrier. The carrier and the project team at GRC planned the route and coordinated it with the Department of Transportation of every state the carrier was to pass through. The truck carrying the tank left on June 24, 1999. On Sunday, June 27, 1999 the truck failed to clear an underpass in West Virginia. The tank was hit on the upper corner on the driver's side. Some insulation was damaged and some bolts were sheared. At the time of the incident, the truck was following a lead truck with a frame that simulated the configuration of the tank in the main truck. The vehicles were traveling at 5 miles per hour at the time of impact. This particular underpass was not considered a problem in the original plan. Based on the information collected by the investigation team, it is the team's conclusion that the driver of the main truck failed to follow the lead vehicle in a manner that would allow it to clear the underpass safely.","Lesson ID":1056}
{"Driving Event":"Line-Replaceable Unit (LRU) Restoration and Upgrading","Lesson ID":1051}
{"Driving Event":"Lack of Systems Engineering in ISS Caution and Warning (C&W) System Design","Lesson ID":1063}
{"Driving Event":"Shipment of Hardware to KSC Before Qualification Testing","Lesson ID":1054}
{"Driving Event":"Effects of Radiation Exposure on ISS Expedition Crews","Lesson ID":1057}
{"Driving Event":"Maintenance of Software Development Tools","Lesson ID":1061}
{"Driving Event":"International Space Station (ISS) Software Development Schedule","Lesson ID":1062}
{"Driving Event":"Increased Cannibalization Trends","Lesson ID":1053}
{"Driving Event":"Independent Verification and Validation (IV&V) of Checkout and Launch Control System (CLCS)","Lesson ID":1059}
{"Driving Event":"International Space Station (ISS) Computer Hardware Upgrades","Lesson ID":1060}
{"Driving Event":"A contractor employee was working on an energized electrical sub-panel.(480v) While removing cover from above the busses the employee dropped the cover shorting out the busses. An arch and flash occurred slightly burning the employee's hands. The main breaker tripped causing an uncontrolled shutdown of the equipment. The interior of the panel was damaged requiring replacement of interior parts.","Lesson ID":1043}
{"Driving Event":"Certification of the Super Light Weight Tank (SLWT)","Lesson ID":1048}
{"Driving Event":"Increased Space Shuttle Main Engine (SSME) Power Setting for Intact Aborts","Lesson ID":1049}
{"Driving Event":"Flight Support Motor (FSM) Test Intervals","Lesson ID":1050}
{"Driving Event":"In order to mitigate pilot seal extrusion-related failures of the Primary Reaction Control System (PRCS) pilot-operated valve (POV), effort were made to develop a redesigned POV (RPOV) pilot seat assembly. The POV controls the flow of hypergolic liquid propellants to the Space Shuttle Orbiter attitude control thrusters. During the redesign, specific factors were found to be essential in fabricating a dimensionally stable pilot seal. Seal Extrusion. Seal extrusion (Figure 1) is caused by thermal expansion mismatch between adjacent PTFE and metal parts in the POV or RPOV, and is potentially aggravated by: excessive internal stress or internal stress gradients in as-fabricated pilot seals low seal exit area relative to entrapped seal volume thermal cycling during seat assembly (e.g., retainer welding) vacuum bake-outs during periodic thruster maintenance heat soak-back after thruster firing, especially multiple sequential burns or long burns any presence of oxidizer vapor close to a fuel pilot seal Data on semi-trapped PTFE specimens simulating a POV seal configuration show that extrusion is: incremental and irreversible increases with the size of the thermal excursion decreases with successive thermal cycling (stress relief) is accompanied by gap formation in the seal cavity The above factors must be considered when developing a viable pilot seal. [D] Figure 1. Impression replica profiles of an extruded Shuttle Orbiter PRCS POV pilot seal (left) and an unextruded, unused POV pilot seal (right) (63 \u00b4 magnification) Seal Recession. Seal recession (Figure 2) is characterized by a loss of seal proud height around the circumference of the seal. Recession deprives the sealing interface of material thus leading to possible leakage. Recession arises from negative internal stress during differential thermal contraction of seal and surrounding metal. Although recession was observed after valve level acceptance testing of RPOVs, it is conceivable that recession could also be caused by overheating during fabrication, or use of too small of a PTFE preform. [D] Figure 2. A sectioned RPOV pilot seat assembly showing seal recession (within boxed region) after initial valve level acceptance testing. The seal has receded into the cavity by approximately 0.050 mm (0.002 in.). PTFE Susceptibility to Oxidizer. When exposed to oxidizer (dinitrogen tetroxide), PTFE undergoes significant yet reversible changes in mass, hardness, density, and crystallinity [1]. The effect of fuel (monomethylhydrazine) on PTFE properties is negligible by comparison (Figure 3). [D] Figure 3. Mass uptake and desorption data for PFTE Teflon 7A exposed to liquid oxidizer (solid symbols) and fuel (open symbols). Reference: Pasternak, R. A., Christensen, M. V., Heller, J., Macromolecules, 3, 366 (1970).","Lesson ID":1040}
{"Driving Event":"In order to mitigate seal extrusion-related failures in the Primary Reaction Control System (PRCS) pilot-operated valve (POV), an effort was undertaken to develop a redesigned POV (RPOV) pilot seat assembly. The POV controls the flow of hypergolic liquid propellants to the Space Shuttle Orbiter attitude control thrusters. Specifications and selection assistance from suppliers were found to be inadequate for choosing an appropriate grade of PTFE for seal material without further testing. The two PTFE resins under consideration had similar properties per current material procurement specifications. For example, the dimensional stability, tensile strength, and percent elongation requirements were virtually the same. Meaningful properties such as dimensional stability under load (creep), retention of properties at higher operational temperatures, and chemical resistance to propellants were not covered. Resin selection design assistance from commercial resin suppliers for specific applications such as a thruster valve seal was found to be lacking. Resin candidates were also hard to distinguish by most laboratory tests, but each candidate was later found to exhibit unique physical and mechanical properties that made the difference between fabricating a viable versus non-viable seal. Initial RPOV seal fabrication efforts focused on using a pre-sintered, free-flowing extrusion molding PTFE grade per AMS 3658 [1], sold under the trademark of Algoflon(r)-E2 [2]. Seals made from Algoflon-E2 exhibited significant splotchiness, microcracking, and fibrillation after the hot-forming assembly process and seal recession after valve testing. To resolve these issues, an as-sintered, non-free-flowing compression molding PTFE per AMS 3660 [3], sold under the trademark of Teflon(r)-7A [4], was used. [D] Figure 1. Redesigned pilot seal showing overall splotchy appearance and fibrillation around seal id and od after trimming Given the limited utility of material procurement specifications, a squeeze test which allowed the compressive strain to be varied from 15 to 90 percent was devised to better differentiate between resins. Specimens made from the pre-sintered, free-flowing Algoflon-E2 resin produced a lower strength PTFE that was more susceptible to fracturing (Figure 2, bottom). Since Algoflon-E2 consists of coarse, agglomerated particles, fracturing was attributed to adhesive failure along resin particle boundaries. By comparison, a specimen made from the as-sintered, non-free-flowing resin gradually transitioned from fully opaque to translucent material without any evidence of fracturing or splotchiness. [D] Figure 2. Polytetrafluoroethylene squeeze test specimens: Teflon-7A (top, 1 piece) and Algoflon-E2 (bottom, 2 pieces). Notice the fracturing in the Algoflon-E2 specimens. References: Aerospace Material Specification 3658, Revision C. Polytetrafluoroethylene Extrusions, Premium Strength, Sintered and Stress-Relieved Radiographically Inspected. Society of Aerospace Engineers, Warrendale, PA, July 1993. Algoflon(r) is a registered trademark of Ausimont Montedison Group, Milan, Italy. Aerospace Material Specification 3660, Revision C. Polytetrafluoroethylene (PTFE) Moldings, General Purpose Grade, As Sintered. Society of Aerospace Engineers, Warrendale, PA, February 1994. Teflon(r) is a registered trademark of E. I. DuPont and Nemours and Company, Wilmington, DE.","Lesson ID":1039}
{"Driving Event":"At approximately 10:30 a.m. on August 26, 2001, gaseous nitrogen (GN2) was erroneously connected to the Gravity Probe-B (GP-B) guard tank vent line as the GP-B Science Payload (Figure 1) was readied for transport from Stanford University (SU) to Lockheed Martin (LM) in Palo Alto, California. At approximately 2:30 p.m. (after the GP-B Science Payload arrived at LM), the error was recognized and the GN2 was disconnected. Gaseous helium (GHe) was the intended gas to be connected instead of GN2. Since the guard tank is at a much lower temperature than the freezing point of GN2, concerns arose over the possible detrimental effects of frozen nitrogen (N2) in the vent line and\/or the guard tank itself. The purpose of the move was to transfer the GP-B Science Payload from SU to LM for later integration with the spacecraft. The move was uneventful except for the discovery of the connection of the incorrect gas to the guard tank. The immediate cause of the incident was the inadvertent connection of the GN2 to the guard tank instead of utilizing the required GHe. A procedure to check the guard tank vent line impedance was executed on September 15, 2001. The data showed significant but not total blockage of the vent line with frozen N2. The procedure added heat to the guard tank and flowed gas through the vent line until there was no further indication of N2 in the tank or line. There is no reason to believe that damage to the hardware had occurred since the vent line was only partially blocked. There was an impact on the schedule due to the recovery time, and there will be an associated cost based on the schedule impact.","Lesson ID":1041}
{"Driving Event":"The Primary Reaction Control System (PRCS) pilot-operated valve (POV) controls the flow of hypergolic liquid propellants nitrogen tetroxide (oxidizer) and monomethylhydrazine (fuel) to the Space Shuttle Orbiter attitude control thrusters. The POV has experienced numerous in-flight and ground turnaround failures, including leakage and failure to open upon command. Corrosion in the oxidizer valves and seal extrusion in the fuel valves have been implicated in most failures. The desire to mitigate corrosion and seal extrusion led to an effort to develop a redesigned POV (RPOV) pilot seat assembly. Machining of polytetrafluoroethylene (PTFE) pre-forms for the RPOV pilot seals was found to be a demanding art requiring special tooling, support equipment, and practice. For example, the need to machine PTFE to close tolerances can be thwarted by slight temperature changes. Given the small size of the machined parts (Figure 1) and the close tolerances required (Figure 2), it was essential to see and accurately measure the article being machined. [D] Figure 1. RPOV seat assembly piece-parts (Left: MP35N seat, Middle: PTFE preform, Right: MP35N retainer) [D] Figure 2. Final RPOV seat assembly design configuration Also, proper cutting tool size, shape, material, cutting angle, nose radius, sharpening technique, cutting speed, and coolant were important considerations in obtaining desired tolerances and surface finish.","Lesson ID":1037}
{"Driving Event":"The Primary Reaction Control System (PRCS) pilot-operated valve (POV) controls the flow of hypergolic liquid propellants, nitrogen tetroxide (oxidizer) and monomethylhydrazine (fuel), to the Space Shuttle Orbiter attitude control thrusters. The POV has experienced numerous in-flight and ground turnaround failures, including leakage and failure to open upon command. Corrosion in the oxidizer valves and seal extrusion in the fuel valves have been linked to most of these failures. The desire to mitigate corrosion and seal extrusion led to an effort to develop a redesigned POV (RPOV) pilot seat assembly. Preform Size. Semitrapped PTFE seals, such as the PRCS POV pilot seal, will undergo coldflow during service [1]. This phenomenon can help to replenish lost material at a sealing interface or heal seal imperfections [2]. However, if the preform used during fabrication is too small, gaps may form in the seal cavity during fabrication that will cause the seal to recede into the seal cavity during qualification testing or service, causing loss of seal-to-poppet contact and ultimately leakage. Conversely, if the preform is too large, the compressive yield point of the PTFE can be exceeded during interference fitting of adjacent metal and plastic parts, resulting in irreversible plastic deformation and associated property loss. In general, the compressive yield strain of thermoplastic polymers such as PTFE is of the order of several percent. The interference fit used during initial attempts to fabricate a RPOV pilot seal (17 to 26 percent) exceeded the yield point of PTFE by a factor of about 5 to 7, resulting in the formation of translucent PTFE in regions of highest internal stress (Figure 1). [D] Figure 1. Sectioned initial attempt RPOV seal made with Algoflon E-2 polytetrafluoroethylene showing translucent (plastically deformed) and opaque regions (normal appearance). By comparison, the interference fit used in POV and final RPOV pilot seal fabrication (7 percent) exceeded the yield point of PTFE by a factor of about 2. The use of an overly large seal preform can have another adverse consequence. Excessively oversized preforms give rise to higher levels internal stress within semitrapped parts. This frozen-in-stress will relieve over time or during thermal cycling, and could be manifested as unacceptable extrusion during service. Preform Shape. If the preform is shaped incorrectly relative to the metal cavity dimensions (producing non-uniform squeeze within the seal), an internal stress gradient within the semitrapped PTFE seal can result. Depending on the magnitude and direction of the gradient, either recession or extrusion of the seal could result. The use of correctly shaped seal preforms that minimize the squeeze gradient within the seal is recommended. This could be accomplished in the RPOV by maintaining equivalent radial and axial seal squeezes during fabrication. Exit Area\/Volume Ratio. A lower seal exit area\/entrapped seal volume (A\/V) ratio was present in the initial and final RPOV designs (A\/V = 0.22 mm-1) compared to original POV design (A\/V = 0.35 mm-1). A differential expansion model for an annular, semitrapped seal like that in a POV configuration showed that twofold reduction in the A\/V ratio will result in double the extrusion during heating [3]. Therefore, the highest practical A\/V ratio should be used in semitrapped seal design. Unoptimized Design Consequences. Evidence of undesirable structural and morphological changes was obtained during initial RPOV seal fabrication. Machined PTFE seals had a mottled, splotchy appearance in areas where the greatest amount of seal squeeze had occurred. This material was especially prone to fracturing and fibrillation during trimming. Subsequent sectioning of the seat assembly revealed PTFE material with a translucent appearance in the region of highest interference fit, while the remaining material in the seal retained a normal opaque appearance (Figure 1). One factor thought to be responsible for the formation of the translucent material was excessive shearing accompanied by irreversible property loss. Evidence of irreversible property loss was supported by decreasing Shore durometer hardness of PTFE test coupons with increasing squeeze (percent strain) (Figure 2). Hardness reductions in semicrystalline thermoplastics such as PTFE are generally regarded as indicative of irreversible deformation modes within crystalline lamellae involving chain slip and tilt at lower strains, followed by lamellar shear and crystal destruction at larger strains [4]. [D] Figure 2. Effect of increasing percent squeeze on the Shore A durometer hardness of polytetrafluoroethylene References: Singleton, K. B., Cold Facts about Cold Flow, The Journal of Teflon Reprint No. 39, DuPont and Nemours and Company, Plastics Department, Wilmington, DE. Wichmann, H., TF E Seat Evolution Report. ISC Report 90201, PO T-92270, NASA Johnson Space Center White Sands Test Facility, Las Cruces, NM, February 1999. Waller, J. M., Factors Contributing to the Extrusion of Monomethylhydrazine Pilot Operated Valve Seals, TR-WSTF-960-001, NASA-JSC White Sands Test Facility, June 1, 2000. Balta-Calleja, F., Martinez-Salazar, J., Rueda, D. R., quotHardness,quot Polymers, An Encyclopaedic Sourcebook of Engineering Properties, J. Kroschwitz, Ed., Wiley & Sons, 415, 1987.","Lesson ID":1038}
{"Driving Event":"A new low blow-by pyrovalve was used in place of a high blow-by pyrovalve primarily to avoid the possibility of a pyrotechnic-induced propellant explosion in a newly designed propulsion system. During blow-by testing of the new valves, one valve did not cycle when commanded. Failure analysis indicated that both initiators and the booster had fired, yet the valve did not cycle. Further investigation indicated that the booster charge was expelled from the Primer Chamber Assembly down into the ram bore. This prevented the booster can surface from opening properly (petaling) and some of the booster energy was diverted to expanding the booster can rather than fully transmitting the energy to the ram. As a result, the diminished energy transferred to the ram was inadequate to shear the tube section that opened the valve. The valve manufacturer improved booster retention by increasing an aluminum retention ring diameter to be slightly larger than the ram bore and improved the potting between the booster and housing. This improved valve configuration was then procured by the program and evaluated by typical lot acceptance testing. Subsequent testing and analysis indicated that the potting bond was not consistent, and that the booster retention ring could possibly deform, allowing displacement of the booster into the ram bore. The risk of a flight valve failing was low but still unacceptable to the project because the vehicle did not have redundant pyrovalves. The retention washer material was changed to a high strength stainless steel and the outside diameter was further increased. The potting process was also improved to form a better gas seal. Testing indicated the reliability risk had been successfully mitigated.","Lesson ID":1035}
{"Driving Event":"The Primary Reaction Control System (PRCS) pilot-operated valve (POV) controls the flow of hypergolic liquid propellants, nitrogen tetroxide (oxidizer) and monomethylhydrazine (fuel), to the Space Shuttle Orbiter attitude control thrusters. The POV has experienced numerous in-flight and ground turnaround failures, including leakage and failure to open upon command. Corrosion in the oxidizer valves and seal extrusion in the fuel valves have been linked to most of these failures. The desire to mitigate corrosion and seal extrusion led to an effort to develop a redesigned POV (RPOV) pilot seat assembly. To streamline RPOV seat assembly fabrication, prototype seat assemblies were built using a hot-forming procedure. The hot-forming fixture is shown in Figure 1. [D] Figure 1. Prototype RPOV hot-forming fixture The hot-forming procedure consisted of the following main steps: Fabricating a slightly oversized polytetrafluoroethylene (PTFE) seal preform Installating a loosely assembled preform, retainer, and seat into the hot-forming fixture Heating of the entire assembly to 120-150 \u00b0C (250-300 \u00b0F) under load Removing the heated assembly from the oven, followed by interference fitting (squeezing) of the PTFE seal while cooling Prototype RPOV pilot seat assemblies were fabricated using scrapped POV metal parts and generic PTFE bar stock. Dimensional tolerances were also relaxed on the seal preform. This approach was thought to minimize fabrication complexity, maximize conformance to the seal cavity shape, and maximize dimensional stability of the seal over the expected thruster operating temperature range, which was well below the seal processing temperature. Success during valve-level testing of prototype RPOV seat assemblies gave early confidence in the RPOV design concept and assembly techniques. Based on this success, flight-configuration RPOV seat assemblies were then fabricated. Unfortunately, seal-related problems not revealed by prototyping hampered attempts to fabricate viable flight-configuration RPOV pilot seat assemblies. There were three instances where reduced level of design rigor during prototyping contributed to the difficulties during fabrication of flight-configuration hardware: It is suspected that the two-piece retainer and tiny screws used for securing the retainer to the seat inadvertently increased the mechanical compliance of the seal cavity. This minimized seal squeeze and mechanical deformation that ultimately produced micro-cracking and recession of the seal in flight-configuration hardware. The convenient use of uncontrolled PTFE bar stock for the prototype seals, instead of using a carefully researched PTFE grade based on consultation with materials and processing experts, delayed optimum material selection. A lack of precise strain rate control during prototype hot-forming trials, along with a design change to the prototype hot-forming fixture to accommodate the planned retainer weld, contributed to a lack of process repeatability.","Lesson ID":1036}
{"Driving Event":"Location: DFRC\/B4800 Incident Report: A facilities maintenance shop worker, working alone, was disassembling and removing an 8' high mezzanine structure decked with 4'x8' sections of steel bar grating. The support structure consisted of a bolted-up system of uni-strut columns and beams. While kneeling on a section of partially disassembled and cantilevered grating, the worker removed one bolt too many. The remaining structure collapsed. The panel the worker was kneeling on rotated about the remaining beam and then slid backwards and collapsed onto the floor. The end of the grating severely scraped the worker across his chest and forearms. The worker also suffered multiple bruises. Office workers across the hall from the collapse heard the accident and called for medical help. The medical team arrived on the scene quickly. Because of the nature of the fall and the position of the injured worker, the medical response team slowly and carefully loaded the worker onto a stretcher board. He was then transported to the hospital for examination and treatment of what turned out to be numerous painful but not life-threatening injuries. The injured worker did not return to work for several weeks.","Lesson ID":1034}
{"Driving Event":"DFRC B4822 Incident Report: A workman was on a ladder spray painting alongside a sheet metal panel wall which had previously been insulated with large continuous insulation batts. The insulation was installed on impaling pins about 1\/8\" x 8\" long. The insulation crew had not trimmed or nipped off the excess projecting pins, leaving 2 to 3 inches projecting from the wall. The painter dropped a can or tool and he lunged to catch it. The ladder shifted abruptly. He instinctively put out his hand to steady his situation and impaled his hand on one of the projecting pins. When he pulled his hand off of the pin, he suffered profuse arterial bleeding. The medical team responded quickly, and the painter's wound was treated and bandaged at the site. The area required a blood clean-up. The workman was sent home that afternoon, but returned to work the next morning.","Lesson ID":1031}
{"Driving Event":"Deep Space 1 (DS1) was a cost-capped, schedule-driven, technology validation project, designed to flight validate 12 advanced technologies that represented major breakthroughs over state-of-the-art systems. An aerospace industry partner was originally selected to provide much of the spacecraft hardware and integration, but ultimately required significant JPL expertise and assistance. JPL was originally responsible for project management and several other elements, but assumed significant additional responsibilities. NASA Lewis (now Glenn) Research Center, through the NSTAR program provided the highest priority technology, the ion propulsion system. DS1 exceeded its mission success criteria, both in terms of technology demonstration and mission duration. In addition, it provided the first close-up spectacular views of a cometary nucleus as part of a very successful extended mission. [D] From the very beginning, the project accepted very high risk in developing and flying the mission. The accepted risk was compounded by what turned out to be insufficient schedule and funding, leading to insufficient review and oversight of several crucial processes: A lack of an early and complete review of the project to (1) assess adequacy of plans, schedule, cost, resource margins, and (2) gain a full understanding of the project's risk posture. Cost and schedule reserves that were inadequate given the many advanced technologies to be demonstrated during the mission. Level 1 requirements and mission success criteria that remained unresolved until very late in development. Accepting a formulation phase that was too short for the team to develop a good plan for implementation. A funding profile that lagged the fast-paced schedule, and caused serious inefficiencies during project start-up. This delayed early and full integration of the industrial partner into the project team. Launch vehicle selection that took too long. External influences caused too many different vehicles to be considered. Some technologies were selected for demonstration that proved too ambitious. A cost cap that was imposed early, before the selection of the payload, launch service, and mission plan was finalized. The project manager was not fully empowered. References: quotDeep Space 1 Lessons Learned,quot JPL internal presentation, David H. Lehman, December 1, 2000. quotPlan Timely Implementation of Backups In Case Breakthrough Technologies Fail to Meet Readiness Gatesquot Additional Key Words: Autonomous Navigation, Flight Qualification, Management and Planning, Technology Plan, Technology Readiness Level","Lesson ID":1033}
{"Driving Event":"DFRC B4823 Incident Report: An iron worker, working alone, was rolling up large sheets (4'x10') of galvanized sheet metal that had been laid down on the slab in front of an addition to a flightline building. While rolling one of the sheets into the wind, a gust of wind picked up one end of the sheet metal causing it to curl up rapidly towards the worker. A corner of the sheet slashed backward, cutting deeply into the worker's left forearm. Medical personnel arrived quickly. The wound was treated and bandaged at the site and the worker was transported to the hospital for stitches. The accident occurred on a Friday, and the ironworker recuperated over the weekend. He returned to work on Monday morning. Just prior to the accident, the project inspector advised the ironworker to roll up the metal sheets in the direction of the wind.","Lesson ID":1032}
{"Driving Event":"Shift From Design Philosophy for Micrometeoroid Debris Penetration Scenarios to Flight Operations Strategies for Hazard Detection, Assessment, and Control","Lesson ID":1015}
{"Driving Event":"Collision Avoidance Maneuvers of the ISS Require Close, Real-Time Cooperation Between NASA and US Space Command","Lesson ID":1016}
{"Driving Event":"NASA Budget Situation Impacts on Shuttle Logistics Capabilities","Lesson ID":1012}
{"Driving Event":"Application of Systems Engineering Methodology to ISS Caution and Warning System","Lesson ID":1017}
{"Driving Event":"Possible Lack of Configuration Control and Software Verification and Validation","Lesson ID":1023}
{"Driving Event":"Payload Requirements for Hazardous Materials Containment","Lesson ID":1018}
{"Driving Event":"Lack of Requirement for Wireless Communication Capability for Expedition Crews","Lesson ID":1019}
{"Driving Event":"Potential Inadequacy of NASA Agencywide Software Safety Policy Requirements","Lesson ID":1021}
{"Driving Event":"Wind Tunnel Fan Blade Cracking at Ames Research Center","Lesson ID":1027}
{"Driving Event":"Potential Inadequacy of NASA Agencywide Software Safety Policy Requirements","Lesson ID":1022}
{"Driving Event":"Lower than Anticipated Fracture Toughness of the 2195 Aluminum-Lithium Alloy Used in the SLWT at Cryogenic Temperatures Causing Changes to Test & Verification Procedures","Lesson ID":1010}
{"Driving Event":"Certification of Block II SSME Testing at 109% for Intact Abort Scenarios","Lesson ID":1006}
{"Driving Event":"Environmental Regulations Resulting in Manufacturing Process and Test Certification Changes for RSRM","Lesson ID":1008}
{"Driving Event":"Space Shuttle Safety and Operational Upgrades","Lesson ID":999}
{"Driving Event":"Shortcomings in hardware design details for Alternate High Pressure Fuel Turbo Pump (ATP HPFTP)","Lesson ID":1004}
{"Driving Event":"Block II SSME Test Schedule Slippage and SSME Test Stand Availability","Lesson ID":1005}
{"Driving Event":"Orbiter Avionics Modifications","Lesson ID":1002}
{"Driving Event":"Orbiter Avionics Modifications","Lesson ID":1003}
{"Driving Event":"Improved Auxiliary Power Unit (APU)","Lesson ID":1001}
{"Driving Event":"Environmental Regulations Resulting in Manufacturing Process Changes for RSRM","Lesson ID":1007}
{"Driving Event":"Leaking Reaction Control System (RCS) Thruster Valves","Lesson ID":1000}
{"Driving Event":"Environmental Regulations Resulting in Material Changes for RSRM","Lesson ID":1009}
{"Driving Event":"A valve was damaged by being exposed to excess pressure during testing because it was in the wrong configuration. The valve was in the 'closed' position when warnings and procedures stated to only test in the 'open' position.","Lesson ID":993}
{"Driving Event":"Employees inhaled small fiberglass fibers from not using the vacuum system which was available and lack of adequate safety procedures.","Lesson ID":994}
{"Driving Event":"Three failures occurred on the ground over a three-week period during integration and test of the Space Infrared Telescope Facility (SIRTF) cryostat at a contractor facility: Rupture of a Pressure Release Device (quotBurst Discquot) on Cryostat Fill-Side. During a helium top-off operation performed to place the cryostat in a safe standby configuration, unexpectedly slow helium transfer was noted by test personnel. This was later attributed to a clogged filter on ground support equipment (GSE) that had not been properly maintained. To speed the flow, test personnel intentionally closed the cryostat internal (see V3 in the graphic) and external (V4) fill valves in reverse order, contrary to the formal test procedure. This caused a pressure surge within the plumbing that ruptured the fill-side burst disc. The test crew was not adequately trained and staffed to deal with this test anomaly. Rupture of Burst Disc on Cryostat Vent-Side. A second incident ruptured the burst disc on the vent-side of the cryostat. A fitting on the GSE cryogenic servicing equipment had been removed and reinstalled without proper torqueing or a leak check. The leaky fitting allowed air to enter the flight system over a period of several days. Frozen condensates from the leak blocked the vent side plumbing and caused the failure. The root cause was the lack of a formal procedure for (1) maintaining the GSE, (2) verifying that there were no leaks within the GSE plumbing after connection to the cryostat, or (3) monitoring the GSE for leakage on a continuous basis. Cryostat Helium Tank Overpressurization. The blockage of the vent line described above caused over-pressurization of the helium tank above the maximum design pressure. Due to the blocked flow, the tank pressure increased even as the pressure downstream of the blockage remained stable. The tank temperature sensor readings should have alerted the test crew, but the readings were considered suspect. This lack of response to a safety-critical sensor indication may be attributed to lack of (1) confidence caused by previous sensor calibration and readout problems, (2) red-flag limits in the control software, and (3) careful real time scrutiny of the test data by cryogenic experts outside the core Cryo-Telescope Assembly (CTA) team. Equipment damage was limited to the two ruptured burst discs, but the incident resulted in a significant cost and schedule impact to the SIRTF project, and posed a potentially significant risk to personnel safety. [D] GSE Configuration When Fill-Side Burst Disc Was Ruptured Reference: SIRTF Cryostat Operations Failure Report, contractor internal report, March 27, 2001. Additional Key Words: test facility operations, facility safety, test equipment maintenance, GSE maintenance, QA oversight, test oversight, test plan","Lesson ID":991}
{"Driving Event":"White particulate residue from the ester-plasticized polyurethane purge line was flushed from the tubing wall and contaminated the NOAA N' SBUV\/2 (Solar Backscatter Ultraviolet Radiometer) Flight Model (FM) 8 while the instrument was under purge. A sudden burst of high pressure and excessive flow through the purge line had possibly resulted in rupturing an in-line membrane filter causing the white platelet particles to pass through the inlet filter of the instrument. At the time, no flow meter was placed in the purge line. Although the MIL-HDBK-695, Rubber Products: Recommended Shelf Life, stipulates a shelf life of three (3) to five (5) years for polyester urethane products, this purge tubing had been in service for the past fifteen (15) years up to the time of the incident. Some polyester urethanes have poor resistance to humidity (MIL-HDBK-695). Urethanes also are not resistant to ultraviolet radiation. Both conditions existed during clean room storage of the SBUV\/2 instrument. The material was visibly degraded as it became less flexible and opaque with residue buildup on the inside and outside of the tubing walls.","Lesson ID":990}
{"Driving Event":"During first use after launch, the optical surfaces of the imaging camera onboard the NASA Discovery STARDUST spacecraft were found to be contaminated, thereby degrading the image quality. The cold operational temperatures of the camera CCD detector and optics offered a convenient \"cold sink\" for contamination molecules. This phenomenon occurs when free molecules migrate to the coldest available surface. This contamination may have originated from spacecraft outgassing and\/or trapped contaminates within the camera. Such events have happened in the past on U.S. and international cold-biased instruments. Heat from internal heaters (or the sun for inorganic molecules) is commonly used to remove such contaminates, and has been used successfully on this mission to improve imaging quality. Following the successful removal of contaminants through the heating process, a recontamination of the camera optical surfaces occurred as the temperature gradient between the spacecraft and the camera optical components returned to its nominal value (warm contamination sources and cold optical surfaces). Using internal heaters again removed the contaminants.","Lesson ID":992}
{"Driving Event":"At KSC, during performance of Space Shuttle external tank\/solid rocket booster thrust post ordinance installation in the booster forward skirt, the frustrum separation cable was mistakenly connected. The job was to install ordinance components in flight hardware. There were three NASA Standard Initiators (NSI) to install, and cables to connect to two of the NSIs. The work team, consisting of three team members, did this work correctly. Then one of the team members noticed the third NSI did not have the cable connected and asked a question about the connection. The work team then connected, in error, the third cable. A problem report was written and the mistakenly connected cable was disconnected and safed.","Lesson ID":988}
{"Driving Event":"Most tantalum capacitors are sensitive to the polarity of the applied voltage. Incorrect installation and\/or improper circuit application that subjects the capacitors to reverse bias may lead to performance degradation or catastrophic failure (short circuit) of the capacitor. Dry slug tantalum capacitors can survive being installed backwards for long periods of time (thousands of hours) when derated to 15% or less of rated voltage.","Lesson ID":981}
{"Driving Event":"During Space Station hardware testing at Kennedy Space Center, a technician was in the process of connecting a current probe banana type plug test lead into a breakout box when he observed an arc. The arc caused the circuit protection to trip which safed the system. The exposed plug had contacted a grounding strap which caused the arc.","Lesson ID":985}
{"Driving Event":"The Terra spacecraft relied on several state-of-the-art developments, as a result of the demanding resource requirements of the Terra instrument suite. These spacecraft development activities were performed in parallel with five state-of-the-art remote sensing instrument developments. Due to the nature of this extensive development, it was anticipated that difficulties and schedule challenges would arise on both sides of this interface. The challenge, which faced the Project, was how to mitigate the risk of verification of this interface, particularly when that flight interface might not be verified until very late in the systems integration schedule. The challenge was compounded by the fact that two of the Terra instruments were international instruments.","Lesson ID":980}
{"Driving Event":"Effective, critical traceability of EEE parts may be lost if original shipping containers and documentation are not retained by original equipment manufacturers (OEMs) and their contractors.","Lesson ID":982}
{"Driving Event":"High voltage linemen were on very tight time constraints and were attempting to measure the voltage in a 15kV fuse cabinet. They were going to measure the voltage from phase to ground of approximately 7630 volts. The equipment they were using is engineered to contact high power lines or transformers out in the open for direct readings. The linemen had contacted the phase conductor with one probe of the test meter and were attempting to make contact with a ground point in the fuse cabinet of the transformer when an electric flash occurred, indicating a ground fault. The ground fault went through and out of the back of the meter ground faulting to the cabinet enclosure. No one was injured but the fault caused an immediate interruption of power to the site electric feeder.","Lesson ID":986}
{"Driving Event":"On January 11, 2000, while the Terra spacecraft was attempting its first long orbit raising maneuver, the maneuver was prematurely terminated after 11 seconds of the burn. The burn was halted due to the fact that on-board attitude tolerance limit exceedences were detected. The flight computer correctly aborted the maneuver. There was no time critically for executing the maneuver on that particular day nor at that particular orbit, therefore a rigorous investigation ensued. This maneuver had been preceded by a calibration burn, which was analyzed and deemed to be nominal.","Lesson ID":979}
{"Driving Event":"The successful early mission on-orbit space-to-ground communications between the Terra spacecraft and the EOS Control Center is a reaffirmation of the value of rigorous pre-launch end-to-end testing. The Terra mission has experienced virtually trouble-free space-to-ground communications from launch and ascent, through the present completion of instrument activation. This success is a direct product of the mandate to perform rigorous end-to-end testing prior to launch.","Lesson ID":978}
{"Driving Event":"The Challenger (Space Shuttle Flight #51L) accident triggered a detailed review of all of the joints in the Solid Rocket Motor. Analyses showed a potential weakness and potential flow paths for hot gasses through he case-to-nozzle joint that could cause a catastrophic event similar to that encountered in Challenger.","Lesson ID":950}
{"Driving Event":"The Challenger (Space Shuttle Flight #51L) accident triggered a detailed review of all of the joints in the Solid Rocket Motor. Analyses showed a potential weakness and potential flow paths for hot gasses through he case-to-nozzle joint that could cause a catastrophic event similar to that encountered in Challenger.","Lesson ID":951}
{"Driving Event":"The Challenger (Space Shuttle Flight #51L) accident triggered a detailed review of all of the joints in the Solid Rocket Motor. Analyses showed a potential weakness and potential flow paths for hot gasses through he case-to-nozzle joint that could cause a catastrophic event similar to that encountered in Challenger.","Lesson ID":952}
{"Driving Event":"Prior to starting the engine, there is a period of time referred to as the start preparation phase. At the beginning of this time period, the oxidizer side of the engine is purged with dry nitrogen to eliminate moisture and the fuel side is purged with dry helium to eliminate air as well as moisture. This prevents the formation of ice particles in the LOX system or air frozen by the hydrogen.","Lesson ID":964}
{"Driving Event":"After the main fuel valve starts to open, three oxidizer valves in the SSME are separately subjected to a series of position commands to precisely control oxidizer system priming times for the three combustors. The first oxidizer valve to be commanded is the fuel preburner oxidizer valve (FPOV). After a delay of 0.100 seconds, the FPOV is ramped to 56 percent open at its maximum skew rate. At 0.72 seconds, the FPOV is given a \"notch\" command to close about 10%. Just prior to the third fuel system oscillation, second \"notch\" command is given.","Lesson ID":966}
{"Driving Event":"The Challenger (Space Shuttle Flight #51L) accident triggered a detailed review of all of the joints in the Solid Rocket Motor. Analyses showed a potential weakness and potential flow paths for hot gasses through he case-to-nozzle joint that could cause a catastrophic event similar to that encountered in Challenger.","Lesson ID":949}
{"Driving Event":"The Challenger (Space Shuttle Flight #51L) accident triggered a detailed review of all of the joints in the Solid Rocket Motor. Analyses showed a potential weakness and potential flow paths for hot gasses through the case-to-nozzle joint that could cause a catastrophic event similar to that encountered in Challenger.","Lesson ID":954}
{"Driving Event":"The Challenger (Space Shuttle Flight #51L) accident triggered a detailed review of all of the joints in the Solid Rocket Motor. Analyses showed a potential weakness and potential flow paths for hot gasses through the case-to-nozzle joint that could cause a catastrophic event similar to that encountered in Challenger.","Lesson ID":958}
{"Driving Event":"The Challenger (Space Shuttle Flight #51L) accident triggered a detailed review of all of the joints in the Solid Rocket Motor. Analyses showed a potential weakness and potential flow paths for hot gasses through he case-to-nozzle joint that could cause a catastrophic event similar to that encountered in Challenger.","Lesson ID":959}
{"Driving Event":"The Challenger (Space Shuttle Flight #51L) accident triggered a detailed review of all of the joints in the Solid Rocket Motor. Analyses showed a potential weakness and potential flow paths for hot gasses through he case-to-nozzle joint that could cause a catastrophic event similar to that encountered in Challenger.","Lesson ID":947}
{"Driving Event":"The Challenger (Space Shuttle Flight #51L) accident triggered a detailed review of all of the joints in the Solid Rocket Motor. Analyses showed a potential weakness and potential flow paths for hot gasses through he case-to-nozzle joint that could cause a catastrophic event similar to that encountered in Challenger.","Lesson ID":948}
{"Driving Event":"The Challenger (Space Shuttle Flight #51L) accident triggered a detailed review of all of the joints in the Solid Rocket Motor. Analyses showed a potential weakness and potential flow paths for hot gasses through the case-to-nozzle joint that could cause a catastrophic event similar to that encountered in Challenger.","Lesson ID":957}
{"Driving Event":"The SSME components were originally planned to be tested on a \"bobtail\" engine. To provide integrated testing, which takes into account the component interactions, however it was decided to add a shortened version of the thrust chamber. The shortened version had an area ratio of 35:1 versus the flight configuration requirements of 77.5 to 1. The test engine could throttle to 50% without requiring a vacuum chamber.","Lesson ID":960}
{"Driving Event":"Turbine speed must be high enough at the time of main combustion chamber priming to be able to pump hydrogen through the downstream system against the back pressure rise created by the chamber priming, or an engine burnout will occur due to the oxygen rich combustion.","Lesson ID":967}
{"Driving Event":"The Challenger (Space Shuttle Flight #51L) accident triggered a detailed review of all of the joints in the Solid Rocket Motor. Analyses showed a potential weakness and potential flow paths for hot gasses through the case-to-nozzle joint that could cause a catastrophic event similar to that encountered in Challenger.","Lesson ID":946}
{"Driving Event":"The Challenger (Space Shuttle Flight #51L) accident triggered a detailed review of all of the joints in the Solid Rocket Motor. Analyses showed a potential weakness and potential flow paths for hot gasses through the case-to-nozzle joint that could cause a catastrophic event similar to that encountered in Challenger.","Lesson ID":955}
{"Driving Event":"The Challenger (Space Shuttle Flight #51L) accident triggered a detailed review of all of the joints in the Solid Rocket Motor. Analyses showed a potential weakness and potential flow paths for hot gasses through the case-to-nozzle joint that could cause a catastrophic event similar to that encountered in Challenger.","Lesson ID":956}
{"Driving Event":"The SSME turbobpump test stand had approximately 2,000 valves, two dozen, which were servo-operated. Facility preburner valves weighed as much as 5 tons for the 14,000 psi system. Facility problems were abundant. In one test, for example, a facility rotary flowmeter failed, releasing flowmeter blades into the LOX flow stream, causing a fire. A similar failure also occurred on a fuel facility subsystem.","Lesson ID":961}
{"Driving Event":"In the SSME, a small recirculation flow is maintained by flowing the propellant through a bleed valve located at the main fuel valve to an overboard dump line or pumped back into the LH2 inlet. Recirculation flow of LOX is maintained by flowing LOX through a bleed valve located a the fuel preburner oxidizer valve to an overboard dump system. These recirculation flows have successfully eliminated gas pockets in the LH2 and LOX systems.","Lesson ID":965}
{"Driving Event":"The Challenger (Space Shuttle Flight #51L) accident triggered a detailed review of all of the joints in the Solid Rocket Motor. Analyses showed a potential weakness and potential flow paths for hot gasses through the case-to-nozzle joint that could cause a catastrophic event similar to that encountered in Challenger.","Lesson ID":953}
{"Driving Event":"Fuel or oxidizer starvation will cause hazardous conditions due to off-nominal mixture ratios in liquid propellant rocket engines. A safe and repeatable start sequence was developed by making maximum use of the engine mounted computer to control propellant valve positions. The report stated that \"Without the precise timing and positioning (of valves) allowed by the Main Engine controller (MEC), it is doubtful that a satisfactory start could have been deve","Lesson ID":962}
{"Driving Event":"Computer mathematical models had shown the engine to be sensitive to small changes in propellant conditions, and that timing relative to opening the propellant valves was critical. Expecting difficulties, a cautious step-by-step plan was followed to explore the start sequence in small time increments. It took 35 weeks and a series of 37 test, including 13 turbopump replacements to extend reliable performance form the 2-second startup transient to main power level.","Lesson ID":963}
{"Driving Event":"Project test deficiencies frequently occur in cost\/schedule driven flight instrument developments. Early cost estimates prepared when a mission's science concept is first proposed are frequently overly optimistic due to lack of full understanding of the science scope and instrument complexity. Budget constraints based upon these early cost estimates normally preclude any funding increases. The instrument project may then be forced to cope with unknown, understated, or perhaps unacceptable risk to comply with the funding cap. Under these conditions, the proposed mission assurance plan\/funding is usually inadequate for the actual level of mission risk. Problems typical of complex instrument developments quickly deplete the minimal reserves accepted early in the project. Failure to perform timely risk trade studies of reductions in mission scope versus early depletion of reserves renders contingency plans inadequate. The lack of additional budget, and schedule slips characteristic of complex instrument designs, result in the project having few or no options other than to shrink the overall test program (both functional and environmental). As a result, problems are frequently not discovered until systems integration - or even worse, after launch. Additional Key Words: test planning, mission assurance program, tailoring, integration and test, ATLO, project reserves, risk management","Lesson ID":968}
{"Driving Event":"An individual was using a 10 inch long by 3\/16th inch T-handled Allen wrench to extract screws. While attempting to remove the screws the Allen wrench broke in half resulting in the individual's hand to come down on the broken sharp end of the Allen wrench shaft puncturing his hand.","Lesson ID":942}
{"Driving Event":"A tightly capped bottle containing dilute aqua regia chemical waste was stored in a fume hood. Evolved gases resulted in a pressure build-up causing the bottle to explode. The contents sprayed across the room onto the floor. The bottle explosion occurred overnight when the laboratory was unoccupied; however, a potential acid burn exists if an employee was in the room at the time of the bottle explosion. A review of available literature indicates that aqua regia, which is a combination of hydrochloric acid and nitric acid, will oxidize with time resulting in the evolution of Nitrous Oxide (NO2). This reaction is ongoing and is subsequent to the intended use of the mixture. This pressure build-up is normal for this type of mixture.","Lesson ID":945}
{"Driving Event":"Starting in 1995, WSTF tested approximately 50 pyrovalves in order to provide insights into the Mars Observer and certain other spacecraft anomalies. The pyrotechnic blow-by past the ram was measured and characterized and overall valve speed and other physical properties were characterized. Pyrotechnic\/propellant interaction testing also was accomplished; testing included simulation of the Telstar 402 and LandSat 6 failures, verification that the Mars 98 pyrovalve and actuation scenarios were safe, evaluation of the Interim Control Module actuations, and tests that characterized pyrotechnic induced propellant reaction rates. Some major safety implications are summarized below. Most of the valves with O-ring seals on Telsar 402, Landsat 6, and the Mars Observer produced significant hot pyrotechnic blow-by. (These were manufactured by one company.) Telstar 402: Flight telemetry indicated that the propellant system was breached immediately following initiation of the second parallel pyrovalve. Actuation of the first valve introduced helium-saturated hydrazine into the evacuated downstream manifold. This created a very unfavorable scenario that greatly increased the chances of ignition. The second pyrovalve was liquid locked and some hydrazine foam may have been produced. Both WSTF and Lockheed Martin duplicated the scenario and both encountered explosions that were characteristic of the flight anomaly. LandSat 6: This was very similar to the Telstar 402 anomaly. Significant differences included a small variation in the time between the actuation of the first and second parallel pyrovalve, and the materials from which that the pyrovalves were made. Telstar 402 used titanium valves and the LandSat 6 used stainless steel valves. Both types of valves caused similar explosions in WSTF testing. Interim Control Module: This system used monomethalhydrazine (MMH) and no explosions occurred in WSTF tesing, probably due to the fact that MMH is much less sensitive than hydrazine. Mars 98: These tests were accomplished using separate hydrazine and nitrogen tetroxide systems and used very low blow-by valves (utilizing interference fit rams rather than O-ring seals). No system pressure increases were observed that were above water baseline test data. This indicated that blow-by was below the threshold for ignition of hydrazine, and that this type of valve no reactivity with nitrogen tetroxide (as was observed with some titanium valves from OEA.) Engineers at Langley Research Center developed a test which measures the amount of energy required to actuate a valve by using a weight drop tower and then measures the energy output of the pyrotechnic charge using a volume chamber. Comparing these energies determines if the valve is over or under-powered. It was determined that the Mars Observer and Telstar 402 valves were so over powered that they frequently broke chunks of titanium out of the ram stop at the end of the stroke.","Lesson ID":944}
{"Driving Event":"An engineering technician was standing on a temporary platform located between the guardrails of the 3rd floor and the exterior surface of the test section plenum. The platform did not inlcude guardrails or other fall restraint devices. The technician was threading a pipe assembly into a blind flange. The pipe assembly was necessary to route test-dependent instrumentation wiring out of the plenum. While tightening the pipe assembly, the open-ended adjustable wrench he was using slipped off the pipe. This caused him to lose his balance and fall onto the curved exterior of the plenum at the 3rd floor level. He slid down the plenum surface approximately 25 feet to a metal obscuration platform located 40 inches below the surface of the 2nd level. The technician sustained a fractured left scapula, a severe laceration of his scalp, and a minor concussion. This injury resulted in several days away from work. Medical assistance was provided in a very timely and effective manner by co-workers and medical personnel. This mishap occurred on December 14th, 2000. A mishap investigation board began it's investigation of this mishap on December 15, 2000.","Lesson ID":940}
{"Driving Event":"During the Procurement and Fabrication of the MPLM Support Vehicle, a specification was written for the truck tractor portion of the vehicle. An industry term Gross Combined Weight (GCW) was used and further defined in the specification as the combined weight of the trailer and associated equipment. This is contradictory to the industry term, which is the combined weight of the truck tractor and trailer. During proofload of the equipment it was noted that the proofload weight was not adequate. The vendor picked up on the industry term GCW and assumed a 50,000 lb. GCW. This is a combined tractor weight of 12,000 lb. and trailer weight of 38,000 lb. The intent of the specification was to have a 50,000 lb. trailer and associated equipment weight plus a truck tractor capable of pulling it which is approximately 12,000 lb. This would have resulted in a 24% undersized proofload.","Lesson ID":936}
{"Driving Event":"The MPL flight software did not take into account certain known hardware characteristics. Resulting mission-critical failure modes were not detected during testing of the spacecraft. It was known that the touchdown sensors generated false momentary signals at leg deployment. This transient behavior was not properly accounted for in the software design. It is believed that these momentary signals were recorded as valid touchdown events, resulting in the engines shutting down at an altitude of 40 meters. The resultant free fall to the surface of Mars is viewed as the probable cause of the December 1999 MPL mission loss (References 1 and 2). Neither the software requirements specification nor the software, subsystem or system test plans required verification of transient signal immunity. Therefore it was never verified. Wiring errors in the touchdown sensors prevented registry of the touchdown or detection of the false transient signal during the first system-level leg deployment test. A full leg deployment test was not repeated after the wiring was corrected. However, the footpads were again manually depressed and the sensors successfully registered a touchdown. A rerun of the complete deployment test with the correct wiring would probably have detected the software's inability to disregard the false momentary signal caused by leg rebound. 4\/18\/17 Update. The conclusions of the Young (Reference (1)) and Casani (Reference (2)) reports have not been invalidated over the past 17 years. However, the development of the Mars Phoenix (PHX) lander, which inherited much of the MPL design and spare hardware and was launched in 2007, revealed another 15 failure modes (Reference (5)) during the Entry, Descent, and Landing (EDL) phase which could have led to the MPL mission failure (and one or two of them could also have threatened (the successful) Mars Pathfinder (MPF), Spirit, and Opportunity rover missions). For example, the breakup analysis performed after the 2003 Columbia Shuttle loss reveals the potential for the MPL cruise stage to have re-contacted the rear of the MPL lander during its descent through the Martian atmosphere. References: Mars Program Independent Assessment Team Summary Report (Young Report), 14 March 2000. Report on the Mars Polar Lander and Deep Space 2 Missions, JPL Special Review Board (Casani Report), JPL Internal Document D-18709, 22 March 2000, Section 7.7. JPL Corrective Action Notice No. Z69163, Mars Program Investigation Results: \"Software Design\", 4 May 2000. JPL Lesson Learned, Software Error in the MPL Uplink Loss Timer. Rob Manning, \u201cCan failure be a measure of success?,\u201d JPL LEAP Seminar, March 24, 2017. Additional Key Words: Software Test, System Integration and Test, Test Planning","Lesson ID":938}
{"Driving Event":"A three-man crane operating crew was assisting a three-man crane overhaul crew to refurbish a 140-ton crew and to refurbish a 110-ton government owned mobile crane on September 15, 2000. On this day, the overhaul crew was to install new boom pendants, requiring the cable bridle and its associated cables to be moved from its temporary stowage location behind the cab of the crane to a point on the boom where it could be attached to the boom pendants. To move the bridle with its associated cables forward along the length of the boom, a second 65-ton government owned mobile crane was used to lift the cable bridle assembly and pull it to the new location. The cable bridle (weighing approximately 1100 pounds) was attached to the hook of the 65-ton crane with a web sling (rated for 10,000 pound capacity in the vertical choker configuration) used in a horizontal choker configuration. The crane operating personnel were performing the following duties: One member operated the 65-ton crane used to lift the cable bridle assembly and pull it to its new location. A second member operated the 140-ton crane in order to play out cable while the bridle assembly was being pulled. The third member was on the ground acting as the signalman for the two crane operators. With the three crane operating crew members in position and the overhaul crew members observing the operations, the cable bridle was lifted and slowly pulled along the boom of the 140-ton crane. During this movement the cable bridle underwent several yawing motions due to the cables binding on the sheaves as the cable unspooled from the take-up drums. The sheaves were binding because the cables were being pulled at an angle and the choker hitch configuration did not keep the bridle straight and level with the direction of pull. The web sling failed allowing the bridle to fall. The bridle assembly impacted the butt section of the boom of the 140-ton crane before it landed on the ground. At the same time, the block of the 65-ton crane swung back striking the stowed jib boom attached to the main boom of the 65-ton crane. The jib boom of the 65-ton crane was a total loss because a portion of the main support section was severely damaged beyond repair. The butt section of the boom of the 140-ton crane was slightly bent and the bridle was damaged in several places. The falling cables cracked the overhead glass on the cab of the 140-ton crane.","Lesson ID":937}
{"Driving Event":"The Mars Polar Lander (MPL) flight software design contained mission-critical logic errors that were not detected during testing of the spacecraft due to omissions in the pre-launch test program and pre-launch uplink verification process. The failure reviews (References 1 and 2) attributed MPL mission loss to a leg rebound transient that is summarized in Reference 4. The uplink loss timer is software designed to trigger a switch from a failed uplink hardware string to the backup string if the spacecraft has not received a command from mission operations for a selected time period. Because of the significant physical reconfiguration of the spacecraft telecommunications equipment from the cruise to post-landing configuration, this uplink loss software was planned to self-reconfigure after the landing. Post mission testing demonstrated that an undetected logic error prevented the reconfiguration. With this software misconfigured, the detection of a failed uplink string and the required swapping to the backup string could not occur. Inadequate Test of Mission Phase Transition: During software integration testing, there were several tests that crossed the boundary from Entry, Descent and Landing (EDL) to the landed mission phase. After the successful simulated landing, each test issued commands to configure the quotuplink loss faultquot test case (i.e., loss of primary uplink string). This test condition masked the software flaw by inadvertently completing a successful transition to the landed configuration, which would not have occurred had a true hardware fault happened. The test did not verify the ability of the lander to switch to the redundant string if a failure occurred during the earlier EDL sequence. Failure to Test Full Range of Operational Parameters: Unit and integration testing of the uplink loss timer logic did not cover the full operational range of parameters. This resulted in failure to identify a legal parameter value that could cause catastrophic behavior. References: Mars Program Independent Assessment Team Summary Report (Young Report), 14 March 2000. Report on the Mars Polar Lander and Deep Space 2 Missions, JPL Special Review Board (Casani Report), JPL Internal Document D-18709, 22 March 2000, Section 7.7. JPL Corrective Action Notice No. Z69163, Mars Program Investigation Results: quotSoftware Designquot, 4 May 2000. JPL Lesson Learned quotProbable Scenario for Mars Polar Lander Mission Lossquot Additional Key Words: Fault Tolerance, Redundancy Verification, Software Test, System Integration and Test, Test Planning","Lesson ID":939}
{"Driving Event":"Space Shuttle Main Engine (SSME) test 902-772 was conducted Friday, June 16, 2000, on engine 0523 with High Pressure Fuel TurboPump (HPFTP\/AT) 8109R1, and High Pressure Oxidizer Turbopump (HPOTP\/AT) 8308. The test was prematurely cutoff at 5.2 seconds due a violation of the High Pressure Fuel Turbine (HPFT) temperature limit of 1860 degrees Rankine. The high temperature led to High Pressure Fuel Turbopump turbine damage and the declaration of a type A mishap. The major objective of this test was to characterize the effects of Chamber Coolant Valve (CCV) position on HPFT temperature. Engine 0523 was in the Block Ia configuration (small throat Main Combustion Chamber) with the exception of the Pratt & Whitney High Pressure Fuel Turbopump. It had previously been tested for 119 starts and 59,278 seconds. It was the fleet leader in both starts and seconds. Nominal operation was planned for the first 90 seconds of the test. The first indication of abnormal performance occurred 2.7 seconds into the start transient. High Pressure Fuel Turbine temperature measurements in two of the four locations began increasing beyond predictions. Other two measurements remained normal. All other engine performance parameters indicated normal engine operation at this time. The two high measurements reached the 1860 degree limit at 4.04 seconds. At approximately 4.97 seconds, the High Pressure Fuel TurboPump vibration levels increased sharply and engine performance dropped. The HPFT temperature limit was activated at 5.04 seconds and a failure identification (FID) was issued, accompanied by a major component failure (MCF). The control and data simulator (CADS) commanded shutdown. The turbine temperature measurements continued to increase after shutdown, reaching a high of 2165 degrees Rankine. Post test inspections revealed heat damage to the High Pressure Fuel Turbine. The Fuel Preburner fuel manifold was heavily contaminated with \"LOX\" tape. During the assembly of SSME 0523, tape was introduced into the fuel system during some \"hands on\" process (temporary closure, contamination barrier, unintentional introduction, etc.). The tape contamination went unnoticed and was left in the fuel system during the remainder of assembly and pre-test activities. On June 16, 2000, Stennis Space Center conducted test 902-772. SSME 0523 was to be tested for a scheduled duration of 210 seconds. At engine start the tape contamination was forced downstream in the fuel system, eventually coming to rest as debris in both the Fuel Preburner (FPB) injector and Oxidizer Preburner (OPB) injector. The amount of debris in the FPB was sufficient to block the fuel inlet holes to several FPB injector elements in a localized area. This blockage caused a localized high mixture ratio area in the preburner without affecting overall engine system performance. Data analysis indicates a localized temperature increase occurred in the vicinity of HPFT DS T CH A measurement and the HPFT DS T measurement at joint KG2dt beginning at approximately 2.7 seconds. At approximately 4.9 seconds, the localized temperature increase caused melting of the support struts and first stage vanes in the HPFTP\/AT. The melting of the turbine stator caused local structural failure. The liberated material continued down the hot gas flow stream, impacting the first stage blades, causing the first stage blades to fail due to impact. This caused significant HPF turbopump imbalance. Data analysis indicates synchronous vibrational level increases of approximately 8 Grms on the pump end and 20 Grms on the turbine end. The levels continue to increase with the increase of imbalance of the turbopump; eventually reaching approximately 16 Grms on the pump end and 83 Grms on the turbine end. At 5.04 seconds, the HPFT DS T Launch Commit Criteria (LCC) was activated. At 5.08 seconds, 2 Failure Identifications (FID's) were issued indicating that HPFT DS T CH A2 and HPFT DS T CH A3 had exceeded the 1860 degree Rankine redline. These FID's were accompanied by a Major Component Failure (MCF) indication. The Facility Command and Data Simulator (CADS) was set to respond to an MCF indication before 6.6 seconds with a command to perform engine shutdown. The CADS unit issued a shutdown command and the engine entered shutdown phase at 5.18 seconds. The engine powered down nominally with the exception of the HPFTP. Its spindown was much faster than nominal. It stopped at approximately 4 seconds after shutdown (expected for a pump with severe imbalance).","Lesson ID":934}
{"Driving Event":"During routine starting of the HVOF thermal spray gun, an incident occurred that resulted in the unintended mixing and ignition of liquid fuel (kerosene) and oxygen in the HVOF system. By some mechanism, the kerosene fuel was allowed to mix with gaseous oxygen upstream of the oxygen check valve in the combustion chamber of the gun. Upon starting the HVOF spray gun, this fuel ignited outside of the combustion chamber, in which it normally mixes and is burned. The flame front traveled up stream in the oxygen supply line and into the controller console, burning or melting several plastic tubes and lines in the cabinet, and contaminating the oxygen-regulating portion of the system. No personnel were injured and the equipment sustained approximately $7,800 worth of damage. As the manufacturer (TAFA) repaired the equipment, they offered the most likely cause of the mishap and suggested some corrective actions. If the HVOF gun is not mounted in! a slightly (at least 5 degrees) downhill orientation (barrel is lower than the rear of the gun), it is possible for a small amount of residual fuel to seep into the oxygen supply line. This can lead to \"hard\" starts or, as in this extreme case, damage the equipment. It is suspected that the HVOF gun was mounted level (parallel to the floor), or even slightly uphill, though not enough to be perceived by the operator. While the equipment manufacturer recommends this practice, it was not described or included in the documentation that originally came with the HVOF system. Consequently, the operator had no idea of the potential consequences related to gun orientation. This equipment had been in operation for over 6 years witout incident before this mishap.","Lesson ID":935}
{"Driving Event":"On January 7, 2001, a large washout was discovered in the vicinity of Facility K7-1205F at the Kennedy Space Center Press Site. Water was flowing from the open end of a failed 4\" potable water main. The washout undermined portions of the concrete foundation and driveway apron for a garage canopy at K7-1205F and damaged the sewer and electric services to the facility. The dominant root cause of this mishap was the removal of a concrete thrust block from the end of the 4\" water main during installation of a power conduit by a KSC support contractor. The thrust block was mistaken for waste concrete material. With the removal of the thrust block, used as the primary constraint for the direct buried slip joint piping system, there was insufficient contact area with the soil to prevent the water main from separating at the joints.","Lesson ID":932}
{"Driving Event":"An employee fell through a section of raised flooring that collapsed, suffering knee and back injuries. The ensuing investigation revealed that the floor tile support cross members were not properly positioned on the floor support stanchions. The floor tile support cross member slipped off of the floor support stringer because the pedestals cap in use was the incorrect type. [D]","Lesson ID":930}
{"Driving Event":"JSC employees fell out of their office chairs when they broke. One employee was injured; the other was not. These two events were several months apart. The model that broke is an adjustable, high-back, gray chair made by Dauphin North America, product code # SL1939 1995 model. The investigation found fractures in the mechanism that attaches the backrest to the base. The manufacture confirms that the metal in the mechanism is not strong enough to withstand repeated stress and strain. Both failures occurred when the chair was unlocked in the full recline position. The chairs are under warranty. Dauphin North America is manufacturing new mechanisms to replace the ones on the 1995 models. The 1996 models and succeeding have the stronger mechanism.","Lesson ID":931}
{"Driving Event":"During the pre-modification pressure test, the contractor had a difficult time in reaching the full pressure test value. The clam shell doors were open and the aft seals around the door were inverted and letting air escape. The contractor was preparing to get additional compressors when it was noticed that the skin of the aircraft appeared to be bowed. The test was immediately halted and NASA requested that the pressure gauges be checked for proper calibration. The contractor discovered that the gauges were out of calibration and were reading a lower pressure and it was determined that they had actually reached the full test pressure value and even exceeded this value.","Lesson ID":927}
{"Driving Event":"During the post modification pressure test, the fore and aft cavity walls deflected inward until it reached the full pressure (8.0 psi) deflection value at only 2psi. The test was stopped because of the large deflections present at only 2psi. An investigation was performed to determine the cause of the large deflection at 2psi. It was determined that the contractor had underestimated the cavity wall stiffness by a factor of 4.","Lesson ID":925}
{"Driving Event":"During the period May-July 1998, one or more of the redundant spacecraft control processors (SCPs) failed in each of three commercial communications satellites. This resulted in one of the satellites being removed from service. Three SCP failures were attributed to intermittent or continuous short circuits caused by the growth of conductive filaments, known as quottin whiskers,quot from the tin-plated surface of an electronic assembly or its cover. Although well known in the past, these recent failures have reminded the space community of the potential risks associated with the use of pure tin-plated finishes on electronic components and assemblies. While pure tin protective coatings are favored by the electronics industry because of their material properties and cost, they are susceptible to the spontaneous growth of single crystal structures -- tin whiskers. Growth occurs with pure tin plating, regardless of the presence of an applied electric field, moisture, or an atmosphere. It may begin soon after plating or may take years to initiate. Tin whiskers are capable of causing electrical failures ranging from parametric deviations to catastrophic short circuits. quotBrightquot pure tin plating has been found to be particularly susceptible to whisker growth, and the U.S. military has discouraged its use. [D] Simulation of Whisker Growth (courtesy of GSFC) [D] Reference(s): NASA Goddard Space Flight Center Tin Whiskers Information Page, http:\/\/nepp.NASA.gov\/whisker\/index.html. quotTin Plating, Whisker Growth,quot GIDEP Alert No. AAN-U-00-11, January 4, 2000. Military specification MIL-T-10727, Tin Plating: Electrodeposited or Hot-Dipped, For Ferrous and Nonferrous Metals (cancelled February 7, 1997) - refer to ASTM B545-1997, Standard Specification for Electrodeposited Coatings of Tin.","Lesson ID":924}
{"Driving Event":"A machinist preparing to cut a Space Shuttle Main Engine turbopump part on a Vertical Turret Lathe (VTL) noticed that the cutting fluid did not exhibit a white milky appearance as expected. The machinist also detected an unusual odor and consistency to the fluid. The machining operation was immediately terminated and area management was notified. The management team determined that the fluid was actually cleaning fluid introduced into the VTL over the weekend as part of normal routine maintenance. Although the cleaning fluid had not yet been removed there was no evidence of a Red Tag on the VTL to restrict its usage.","Lesson ID":926}
{"Driving Event":"The aft cavity bulkhead was built entirely outside the aircraft with no requirements to demonstrate the actual fit inside the aircraft. After manufacturing was complete, it was discovered that the aft bulkhead did not fit inside the aircraft. An investigation of this problem revealed that the dimensions on the drawings were incorrect. The aft bulkhead wall had to be removed and modified. This additional work cost the project a delay of about 3 weeks.","Lesson ID":928}
{"Driving Event":"On 10 October 2000, during the STS-92 launch countdown T-3 hour Final Inspection, a 4-inch long and 3\/16-inch diameter quotT-handlequot Quick Release Pin (QRP) and tether were discovered laying between the External Tank (ET) LO2 Feedline and the in-board Feedline Support Bracket. Photo 1 - Quick Release Pin found on inboard side of the ET LO2 Feedline support bracket The inspection team was unable to retrieve the QRP. The launch team was notified and launch was scrubbed at T-20 minutes. Removal of the QRP and tether was completed at 0226 hours on 11 October 2000. The QRP had only caused minor damage to the LO2 Feedline Support Bracket foam insulation. STS-92, the 100th Space Shuttle Mission, was launched successfully at 1917 hours on 11 October 2000. During a follow-up investigative walkdowns of the Vehicle Assembly Building (VAB) and Pad A, a VAB High Bay (HB) 3 quotB Roofquot kickplate attachment for platform F-9 was discovered to be missing a 3\/16-inch diameter QRP. The F-9 platform is located 73.6 feet directly above the found QRP's resting location on the LO2 Feedline Support Bracket. Photo 2 - 2VAB HB-3 Integration Cell Platform configuration in relation to pin location The kickplate was routed to the Malfunction Lab on 16 October 2000 and the Lab confirmed a match between the paint over spray found on the QRP's T-handle and the paint on the kickplate. The Investigative Board concluded that the QRP most likely fell just prior to or during the quotB Roofquot Level F-9 platform retraction, which occurred approximately 3 hours after the pre-rollout inspection of the D-2 Level platform. The parallel task sequencing, of the platform inspections and retractions, was not constrained by current procedures.","Lesson ID":923}
{"Driving Event":"Viscous fluid dampers commonly used to control deployments may exhibit an initial transient of un-damped motion when actuated after prolonged exposure to vacuum. The Mars Polar Lander (MPL) solar panels quotfloppedquot when deployed following thermal vacuum test. It was determined that small bubbles had risen to the top of the deployment dampers and coalesced, resulting in a region of reduced damping during the damper stroke-- a hydraulic deadband. Although the array was not damaged, a study was undertaken to evaluate the risk to in-flight deployment of the Mars Global Surveyor (MGS) high gain antenna (HGA), which uses a similar damper and is deployed following the cruise phase of the mission. [D] Deployment Hinge Assembly for the MGS HGA The study determined that exposure of a damper to vacuum produces bubbles in the silicone fluid within the vane cavity. It was found that a 20-day exposure of this particular damper to vacuum\/low pressure in a gravity field will allow the bubbles to coalesce; this results in a maximum deadband of 55 degrees, insufficient to cause structural damage in this application. To varying degrees, all viscous dampers are believed to be subject to bubble formation. Reference(s): quotMGS High Gain Antenna Deployment Independent Review,quot Jet Propulsion Laboratory IOM No. 3501-WHM-98-001, William H. Mateer II, October 23, 1998. quotViscous Damper, (Sealed Damper Assembly, Non-Temp., Compensated),quot GIDEP Alert No. H6-P-98-01, January 30, 1998. Category: Subsystem and Instrument Development","Lesson ID":922}
{"Driving Event":"The loss of Mars Climate Orbiter (MCO) was attributed to, among other causes, the lack of a controlled and effective process for acquisition of contractor-developed, mission critical software. Under the MCO procurement strategy, JPL placed full responsibility for flight software development in the hands of a contractor\/industrial partner and did not monitor the quality of the contractor's product. (See References 1 & 2.) Reference(s): \"Report on Project Management in NASA by the Mars Climate Orbiter Mishap Investigation Board,\" NASA, March 13, 2000. Corrective Action Notice No. Z66254, MCO-JPL\/SRB Finding #4.2: \"Software Development Process\" JPL Policy: Design, Build, Assemble, and Test Process, Section 2.4: Software Acquisition, July 7, 2000. \u201dDeficiencies in Mission Critical Software Development for Mars Climate Orbiter,\" Lesson Learned Number 0740, April 4, 2000. Additional Key Words: Contract Monitoring, Performance Based Contracting, Software IV&V, Software Quality Assurance (SQA), Software Standards, System Contractor Oversight","Lesson ID":921}
{"Driving Event":"Studies of NASA robotic spacecraft by JPL reliability engineers have shown that mechanism failures are more likely to have a significant impact on mission success than the majority of electronic failures. Spaceflight mechanisms are usually unique designs that lack the years of testing and usage common to electrical devices. They also generally cannot be designed with the same level of block or functional redundancy, or graceful degradation, common with electronic circuit design. Mechanisms, such as deployables, intended for use after a prolonged or severe exposure to space environments provide a special challenge to designers. [D] 60-meter SRTM mast is an example of increasingly large and mechanically complex space mechanisms. Two resources are available to assist in the design and qualification of flight mechanisms: A NASA Space Mechanisms Lessons Learned Study (Reference 1) identifies common mechanical failure modes and suggests preventive measures. The study, which employed an industry survey and a literature search, covers three major categories of mechanisms-- deployable appendages, rotating systems (gears, motors, bearings, reaction wheels, etc.), and oscillating systems (i.e., gimbal bearings). JPL has prepared a Checklist for Reliable Mechanism Usage. This checklist is provided in the Recommendations. Reference 2 also provides a link to the latest version of this checklist. It provides a list of key measures that can be taken to avoid design and test oversights. Some of these items may appear obvious to the experienced mechanical engineer, but may be overlooked under deadline pressure. The Space Mechanisms Lessons Learned Study is used by JPL as a primary design reference, and the Checklist has recently been used to identify high probability\/major impact failure modes subject to risk management. Reference(s): Space Mechanisms Lessons Learned Study, NASA Technical Memorandum 107046, Mechanical Technology Inc., November 1994, at http:\/\/www-rel.jpl.nasa.gov\/reltec\/mechpart\/mti95tr4.pdf Checklist for Reliable Mechanism Usage, James Newell, Jet Propulsion Laboratory, May 2000, at http:\/\/www-rel.jpl.nasa.gov\/reltec\/mechpart\/ mechlist.htm","Lesson ID":913}
{"Driving Event":"The root cause of the Mars Climate Orbiter (MCO) mission failure was identified by the JPL and NASA Review Boards as navigation errors caused by the software output that provided compensation for small forces effects to the JPL navigation team (References 1 and 2). The mission plan called for execution of the fifth trajectory correction maneuver (TCM-5), if needed, two days prior to Mars Orbit Insertion (MOI). TCM-5 had not been included in the baseline mission operations timeline. As a result, it had never been tested for flight sequence compatibility and for mission safety. Furthermore, TCM-5 was not included in operational readiness testing (ORT). Therefore, when the time came to execute TCM-5, the decision represented a major risk item for the MCO project. Because of this high perceived risk just prior to MOI, and the lack of compelling evidence of the need to perform this maneuver, the project declined further consideration of TCM-5. [D] Reference(s): quotReport on the Loss of the Mars Climate Orbiter Mission,quot JPL D-18441, JPL Special Review Board, November 11, 1999 quotPhase I Report,quot (NASA) Mars Climate Orbiter Mishap Investigation Board, November 10, 1999 quotMars Climate Orbiter Mishap Investigation Board - Phase I Reportquot, Lesson Learned Number 0641, December 1, 1999 Corrective Action Notice No. Z66283, MCO-JPL\/SRB Finding #4.13:quotRisk Managementquot Additional Key Words: course correction, trajectory error, navigation uncertainty, configuration control, CM, software testing, compatibility testing, peer review, mission planning, mission design","Lesson ID":916}
{"Driving Event":"During installation of the Thermal Micrometeorite Guard (TMG), the Short Extravehicular Mobility Unit (EMU) #3018 fell from the EMU ground test fixture (EGTF) to the floor. The primary cause of the mishap was that the EGTF was not used in a manner for which it was designed or assessed. The EGTF was designed and certified for 4-pin operations. The design of the TMG required a 3-pin operation during installation (one pin had to be removed.) The existing procedure for installation of the TMG on the SEMU did not address how the SEMU is to be handled or positioned, nor was there a procedure for the use of the EGTF. During this particular mishap, the TMG installation was being conducted with the [front] of the SEMU down. With the front of the SEMU facing up, this type of mishap would probably never occur because of the design of the pin receptacles. Proper procedures for installation of the TMG with the SEMU in an EGTF could have prevented this incident. Even thought this potential for mishap has existed since the EGTF was introduced in 1983, its presence was either recognized and not documented in a hazard analysis or not recognized at all. No formal training plan or objectives exist for personnel who handle flight equipment in the EMU laboratory. While OJT apprenticeship was implemented for these operations, there are neither measurable requirements nor documentation to support successful completion of training.","Lesson ID":918}
{"Driving Event":"JPL has responsibility for the development, integration, and testing of the payload (including the canister and collector arrays) for the Genesis Project, a mission to collect solar wind particles and return them to Earth. While the Genesis canister was being lifted from the transportation dolly at JPL in preparation for system-level thermal vacuum testing on May 3, 2000, the lift fixture detached at one of the three swivel hoist ring tension fittings. [D] Prior to mounting on the test chamber door, one corner of the canister fell ~5 centimeters (~2 inches) back onto the dolly. Nearby personnel cushioned the fall, and there was no damage to the Canister or support equipment, or serious injury to personnel. Post-incident inspection revealed that the threaded fastener had backed out of the fixture and became detached. Additionally, the fasteners at the other tension fittings, and at the upper hoist point, were found only hand-tight. The lift fixture assembly had been proof tested 8 months earlier. The fixture had been reassembled by the vendor following the proof test and dye penetrant inspection of the swivel hoist fittings. The fixture had last been used to lift the Canister two days prior to this incident. The fixture was visually inspected prior to the May 3, 2000 lift incident, but the hoist rings were not checked for tightness. There is no evidence that the hoist ring fasteners had been properly torqued since the proof test. The procedure governing the canister lift operation (Reference 2) did not require adequate checking of all fasteners prior to attaching the fixture to the hoist. Reference(s): Jet Propulsion Laboratory Problem\/Failure Report No. Z69149, May 3, 2000 JPL Assembly and Inspection Data Sheet (AIDS) No. 216421, May 2, 2000 JPL QA Procedure QAP 61.5, quotQA Inspections of MGSE Used on JCIs.quot","Lesson ID":914}
{"Driving Event":"Hydrazine fuel in pressurized tanks is used for satellite stationkeeping. Fuel consumption log indicated sufficient fuel to extend mission beyond date originally planned. During a north-south stationkeeping in July 1998, thruster firing was aborted due to satellite attitude instability caused by uneven thruster firing. This was determined to be caused by two-phase flow of liquid hydrazine and Helium pressurant gas to thrusters in the odd half-system. This only occurs when hydrazine in a tank is nearly depleted. The fuel log indicated that the tanks in both the odd and even half system should have had sufficient fuel for several more stationkeeping maneuvers, contrary to the observed performance.","Lesson ID":915}
{"Driving Event":"The High Energy Spectroscopic Imager (HESSI) spacecraft primary mission objective is to explore the basic physics of particle acceleration and explosive energy release in solar flares. The HESSI spacecraft was scheduled for a July, 2000, launch on a Pegasus vehicle as part of the Small Explorer Program (SMEX). On March 21, 2000, the HESSI spacecraft was being subjected to a series of vibration tests at JPL as a part of its flight certification program. The structural qualification test, a sine-burst test on a shaker table, subjected the spacecraft to a major overtest condition that resulted in significant structural damage to the spacecraft. The incident has been designated as a Class A mishap since the damage exceeded $1 million. A sine-burst test is a quasi-static load simulation technique. The shaker table in this incident was well over 40 years of age. The fatigue life characteristics of such shaker tables are unknown. The root cause of the overtest condition was the mechanical binding (\"stiction\" or static friction) between the slip table and the granite mass. It resulted from physical contact between a portion of the slip table and the granite mass caused by a mechanical failure in the shaker's support structure. The stiction caused the shaker system to present highly non-linear gain characteristics to the control system making it impossible for the controller to calculate an appropriate forcing function. This particular sine-burst was leading to a higher level qualification test. The resulting overtest level was about 10x that planned for this test, but only about 2.5X the final qualification level. Contributing Factors Identified by the Review Board: At some facilities, older test equipment may have time-related failure modes unknown to the users. Misalignment caused the slip table to exhibit non-linear behavior in that it would bind at low levels of force input. The test personnel did not have existing knowledge that data were available to assess the quality of the transfer function calculated from the self-check prior to initiating the sine-burst test. Post-test review of the transfer function used to generate the shaker drive signal for the test and examination of the drive voltage indicated that the test setup was not operating as expected and that an overtest could occur. A significant contributing factor to the mishap was the lack of a facility validation test using the sine-burst on the shaker table before the spacecraft was mounted. It is industry best practice to do a facility checkout with a simulated mass mock-up before mounting a piece of critical hardware. Such a validation test effectively calibrates the entire test setup. A further contributing factor to the mishap was a mechanical anomaly that occurred in the exciter system. The shaker appears to have shifted in its support cradle after being coupled to the slip table in preparation for this test. The shift is thought to have been caused by the breakage of the outer race of a main trunion bearing. This resulted in a misalignment that brought one area of the slip plate into contact with the granite reaction mass creating a much larger frictional drag than normal. An additional contributing factor to the mishap was the low amplitude of the pre-test self-check. If a higher amplitude self-check had been used, the control software would have more closely approximated the system transfer function and increased the probability of detecting that stiction existed. References Jet Propulsion Laboratory Problem Failure Report (PFR) No. Z68924, March 24, 2000. Report on High Energy Solar Spectroscopic Imager (HESSI) Test Mishap, HESSI Test Mishap Investigation Board, May 18, 2000.","Lesson ID":903}
{"Driving Event":"During the launch of the NOAA-K weather satellite there was an anomalous deployment of the Very High Frequency Real Time Antenna (VRA) and an incomplete deployment of the -Y Deployable Sunshade. The VRA is a two-stage deployment. Phase 1 deploys 76 degrees followed by the Phase 2, which deploys through an angle of 166 degrees. The Phase 1 slowly deployed to only approximately 58 degrees instead of its planned 76 degrees. The Phase 2 deployed its full 166 degrees. This left the VRA mispointed by approximately 18 degrees. However, this mispointing does not affect data recovery via the VRA. The telemetry indicated the -Y sunshade had not fully deployed. The incomplete sunshade deployment could not by correlated to other indirect observables, since the -Y deployable sunshade is not required for thermal control in the AM orbit.","Lesson ID":909}
{"Driving Event":"The POES Program made a decision to embellish an instrument by incorporating a new scanner design. This new design was to replace a weak motor with a stronger one that would have the same operational performance. In doing this, the motor and the drive electronics had to be replaced. The Prime Instrument contractor always subcontracts out the build of the motors, and this time the decision was made to allow the motor vendor to build the control electronics as well as the motor. The build of the control electronics was a new venue for the motor vendor and made an equitable offer to the Prime for both the motor and the control electronics. The vendor was never able to produce the control electronics and that activity had to be brought back in-house by the Prime. As a consequence, the modification experienced a significant over-run and substantial delays in the delivery of the units.","Lesson ID":907}
{"Driving Event":"The NOAA-15 (K) satellite was launched on May 13 1998. The satellite was the first in the new series of Polar Operational Environmental Satellites (POES) that had design heritage back to Tiros-N launched in 1978. NOAA-15, however, had three S-band antennas operating in the 1700 MHz frequency range that were new to this mission. Approximately 18 days after launch, data quality degradation was noted during tape recorder playbacks on the S-band #2 link. In October science data from the AMSU-B instrument provided by the UK was observed to have contamination toward one side of the scan field of view. The degradation was consistently evident or not depending upon the satellite orbital location. An Anomaly Review Board was established and investigation revealed that the contamination appeared to rotate around the globe as the sun moved from north to south during the annual season change. Further investigation revealed a thermal correlation to the link degradation and science data contamination as the S-band antennas experienced large thermal gradients throughout the orbit. A detailed thermal stress analysis performed for the antenna confirmed stress levels within internal connecting elements that were sufficient to cause breakage. Once broken, changes in antenna gain, axial ratio, and SWR would significantly degrade link performance and antenna patterns. The failure mode was confirmed in a thermal cycling test of a flight antenna.","Lesson ID":908}
{"Driving Event":"After launch it was observed that the Advanced Very High Resolution Radiometer (AVHRR) instrument was running hotter than normal. The design calls for active louvers to open to radiate heat and bring the instrument baseplate temperature to within design limits. A review of the procedures used in building the spacecraft indicates the louvers were removed after Thermal Vacuum testing and reinstalled as a \"Non-flight \/ Temporary mechanical installation\" for fit check purposes. The connector was not mated at this time. A subsequent decision was made to leave the louvers in place but no notation of the lack of electrical connection was made. There was a procedure run prior to shipment, which is used to verify the mate status of every accessible connector on the spacecraft. This connector was not on the list. The NOAA-K satellite was flown with the thermal louver cable disconnected.","Lesson ID":905}
{"Driving Event":"The Work Breakdown Structure (WBS) in the Request for Proposal (RFP) will become the basis for the Contractor's Project organizational structure and job order numbers. If not mandated via the WBS, the Contractor may choose to organizationally segregate flight software from the spacecraft subsystems it is controlling.","Lesson ID":911}
{"Driving Event":"After the launch of the NOAA-15 spacecraft, an EMI\/EMC interference affecting science data was noted in the Advanced Microwave Sounding Unit (AMSU)-B data. This interference was subsequently attributed to the SAR and S band transmitters and was due to inadequate AMSU-B shielding. The problem was aggravated by a malfunction in the spacecraft antenna. Fortunately, the AMSU-B data was recoverable on the ground through additional data manipulation and processing.","Lesson ID":906}
{"Driving Event":"A hydrazine cylinder containing 11 liters of Hydrazine was shipped to the Kennedy Space Center (KSC). The shipping paperwork indicated the cylinder contained 1 liter of Hydrazine. The cylinder was transported by cargo air. Although transportation regulations allow cargo air transportation for quantities of this commodity up to 2.5 liters, the cylinder is covered by a Department of Transportation (DOT) exemption that specifically requires either motor vehicle or cargo vessel (boat) transportation regardless of quantity. The exemption takes precedence over the general regulation.","Lesson ID":902}
{"Driving Event":"Two workers in Donaldson, La Plant Explosion.. Both were wearing NOMEX OVERALLS. One employee was wearing no under garments; burns over most of the body. The second employee was wearing cotton shorts and tee shirt; there were burns only where the undergarments did not cover the body.","Lesson ID":901}
{"Driving Event":"I was involved in a project in which we were developing a new control and data acquisition system for an instrument to be used to measure radiation absorption in clouds. The instrument was being refitted with electronic hardware that was to be controlled by software I was developing with a peer. Only problem was that the hardware was not ready for 3 months while we were supposed to be developing the software. And the project was on a very tight deadline. What we were able to do was create a software simulator to test and validate many of the features of how our software was supposed to work. Of course, this cannot truly be substituted for the hardware but it can get you 50% or more of the way there (depending on the particular project). This allowed us to complete the project on schedule. Additionally, the simulator drove us to create a truly standalone simulator to be able to demonstrate to others how the instrument and interface will work together.","Lesson ID":895}
{"Driving Event":"Foreign contributor committed to a dollar value & then found that initial cost estimates for the proposed contribution were grossly understated; consequently partner provided only a partial delivery of their contribution, leaving a shortfall for NASA to make up.","Lesson ID":899}
{"Driving Event":"Changes to an approved LV\/SC ICD are submitted via an Interface Revision Notice (IRN) document. The existing formal approval process requires the signatures of NASA-GSFC (SC), NASA-KSC (LV), and the LV contractor on all IRN submittals. Noticeably absent from the formal process is the SC contractor. NASA-GSFC and the SC contractor have an informal agreement whereby the change is reviewed and concurrence is documented via e-mail correspondence. During the GOES-L \"Red Team\" review process the omission of the SC contractor in the formal review\/approval process raised the question of legal\/liability issues.","Lesson ID":897}
{"Driving Event":"Schedules that had been agreed, on closer examination, turned out to mean something different than parties expected; design loads presented to NASA for use in designing a mission payload were wildly conservative & could lead to significant cost increases.","Lesson ID":900}
{"Driving Event":"Construction operations aimed at improving accommodations or improving the capabilities of a mission critical support facility are required periodically. An extensive construction effort was underway at the Spacecraft Operations Control Center (SOCC) in Suitland, Maryland during the period immediately preceding the launch of the GOES-L spacecraft (5\/3\/00). Standard operating procedure for the SOCC is to freeze the hardware\/software configuration of the facility 30 days prior to launch. On-going construction at the facility made it difficult to satisfy this requirement without impacting the facility construction schedule, which can effect multiple programs.","Lesson ID":896}
{"Driving Event":"This Lesson Learned is based on Reliability Practice PT-TE-1406 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Certain failures are not normally exposed by random vibration. Sinusoidal vibration permits greater displacement excitation of the test item in the lower frequencies. Apply sinusoidal vibration to the test item by sweeping over a frequency range beginning at approximately 10 Hz (\u00b1 one octave) up to approximately 100 Hz (\u00b1 one octave). Sweep the frequency range at a logarithmic rate (i.e. delta f\/f is constant). Sinusoidal vibration is performed with the same fixturing and concurrent with random vibration. Sinusoidal vibration is employed to simulate the effects of significant flight environment launch transients. These transients typically produce the dominant loading on primary and secondary structure and many of the larger subsystems and assemblies. Sinusoidal vibration is the only widespread current method of adequately exciting the lower frequency dynamic modes -- particularly those below approximately 40 Hz. Sweeping at a log rate between 1 octave\/minute and 6 octaves\/minute should avoid application of excessive fatigue cycles. The higher rate is near the upper limit which most control systems can accommodate without experiencing some instability. The use of logarithmic sweep rates has the advantage in that a nearly equal time is spent at resonance for a given Q, independent of frequency. Sinusoidal vibration levels can be derived as in the following example: Step 1. Create analytically derived transient waveforms from various flight events: [D] Step 2. Compute the shock spectra for each of the waveforms in Step 1: [D] Step 3. Take data from previous flight measurements: [D] Step 4. Combine results from steps 2, and 3 and envelope: [D] Step 5. Convert to a sine amplitude equivalent vs. frequency by dividing Shock Response Spectrum envelope in Step 4 by Q: [D] Alternatives to the use of swept sine vibration testing are currently under development which address several of the objections to this method. In particular, the problem of excessive resonance build-up in a sinusoidal vibration sweep relative to the flight transient environment may be alleviated by any of the following tests: Narrow band swept random. Discrete frequency sinusoidal pulses applied at regular frequency intervals. Complex waveform pulses representative of a composite of the various launch transient events.","Lesson ID":894}
{"Driving Event":"During preparation for public display of a Lunar Module Test Article, museum personnel claimed to be exposed to a small puff of brown\/orange vapor, presumably oxidizer. The incident occurred August 23, 1998, when the museum technician was removing portions of lines that were not representative of flight configuration. The test article had been field decontaminated and checked for oxidizer contamination prior to shipment to the museum. It may be possible that some isolated portions of the system and offgassing from the flexhose softgoods may have been overlooked as potential sources of oxidizer.","Lesson ID":887}
{"Driving Event":"The New Millennium Program's first Earth-Observing mission (EO-1) is a technology validation mission designed to flight-validate advanced imaging technologies applicable to a Landsat follow-on mission. It includes a pushbroom multispectral imager, a hyperspectral imager, an atmospheric corrector, and several spacecraft technologies applicable to future remote sensing missions. The EO-1 advanced technologies are reflected in Figure 1.","Lesson ID":888}
{"Driving Event":"A ground crew was towing the NASA owned B747SP to the nose docks at Raytheon E-Systems Waco facility. Damage to the aircraft was sustained when the crew was trying to position the aircraft in the nose dock. The aircraft was slightly off center and while it was being moved, it struck one side of the nose dock. The extent of the damage was about 30 square inches located on the left hand side of the aircraft just aft of the flight deck, close to the emergency escape area. Ground handling personnel did not have whistles or any other means to properly communicate with the tug driver. An alignment centering line had been painted on the hangar floor but the scaffolding had since been moved off-center without notifying all ground tow personnel.","Lesson ID":884}
{"Driving Event":"Flight hardware was damaged, and personnel safety potentially compromised, during a system-level ambient functional test of the Mars Polar Lander (MPL) spacecraft intended to simulate the mission profile immediately after landing. The software test sequence that was programmed into the vehicle commanded the gimbaled medium gain antenna (MGA) through its full range of motion. This inadvertently drove the MGA into one of the undeployed solar panels, cracking the composite antenna reflector dish and scratching the substrate of that solar panel. [D] MPL in the quotLandedquot Configuration A previous test left the solar array configured on the lander in the stowed position. This undeployed mechanical configuration obstructs a full-range-of-motion test of the MGA. As the impending collision was observed, the test conductor attempted to command a halt to the motion. However, the commands did not execute because the uplink path was then in the process of being reconfigured from hard-line to radio frequency. Furthermore, the emergency power-off switch only governed the ground support equipment and could not shut down the spacecraft since it was in a battery-powered flight configuration. The primary causes of this test incident were: Configuration Control. Failure to confirm, prior to testing, that the lander was in the quotlandedquot configuration with the solar array deployed to allow full motion of the MGA. Flight Design. Omission of a method for emergency removal of battery power to the vehicle. Reference (2) describes a similar omission. Reference: Jet Propulsion Laboratory Problem\/Failure Report No. Z47115, September 8, 1998. Inadvertent Powering of the Deep Space 2 Mars Microprobe, JPL Lesson Learned No. 0626, June 21, 1999.","Lesson ID":885}
{"Driving Event":"Test personnel from the 3.5-foot Hypersonic Wind Tunnel facility, supported by personnel from the project phase 3 contractor, were conducting blowdown tests as a part of the Integrated Systems Testing (IST). The tests were being done to certify the operational status of the facility following a construction of facilities project for rehabilitation of the facility. The mishap occurred seconds after the start of the 5th run of the day, at approximately 10:00 a.m. Four previous blowdown tests had been completed on that day without incident.","Lesson ID":862}
{"Driving Event":"A personal equipment technician employed by a California Company in support of the operations of the High Altitude Missions Branch, was fatally injured by inhalation of nitrogen while conducting a periodic inspection on a pressure helmet. It is presumed that the technician donned the helmet in the course of his inspection; he then closed and secured the face seal. The helmet was connected to a source of nitrogen, the gas used in the facility for bench-testing and maintenance of this equipment. The technician lost consciousness within 20-35 seconds after beginning to breathe nitrogen; he was found by a coworker at 3:15 p.m., deeply cyanotic and unresponsive. Cardiopulmonary resuscitation efforts were unsuccessful; the technician was pronounced dead at the hospital upon arrival there by ambulance. A post-mortem examination was conducted by the Office of the Coroner-Medical Examiner, County of Santa Clara. The cause of death was stated to be asphyxia due to inhalation of nitrogen gas.","Lesson ID":866}
{"Driving Event":"A fire occurred in a modular building, #T-046, at the NASA Ames Research Center at Moffett Field (Mountain View), California. The building was about three months old, purchased and assembled on site by American Modular Systems, Inc. The building was occupied by code OFX, Range Systems Branch. In the area that the fire occurred, research in microwave landing systems was being conducted. The fire was first reported by a building janitorial worker, who noticed the fire at the rear of the structure at or near one of the four wall-mounted heat pumps. The alarm was received at the Moffett Field Fire Department at 0100 hrs. The first engine company arrived at 0103 hrs. and the fire reported extinguished at 0143 hrs. Most of the fire damage occurred above the suspended ceiling with some heat and water damage below, and some damage throughout the building. Various test equipment and computers located on work benches were damaged. The building was subsequently closed. The fire started at the mouth of one of the heat pump units located at the discharge duct connector. At the discharge flange of the heat pump there are electric resistance heating coils that operate under various conditions in which the unit is unable to produce sufficient heat. Six manufacturing deficiencies were discovered at these duct connectors.","Lesson ID":863}
{"Driving Event":"A casing in Cluster #1 of the Underground Air Storage Facility (UASF) ruptured releasing high pressure air (3000 psig) into the substrate at about 500 ft below the surface. Although, quick action by the crew isolated the UASF from the rest of the distribution system, the entire 5x106 SCF of air, stored in the UASF, was released through the rupture. The released air created a crater around the affected cluster and sprayed mud onto the surrounding area for a radius of approximately 150 feet. Damage was localized to the one cluster. However, personnel that had entered the area to attempt to isolate the individual clusters from the manifold were exposed to streams of water and mud when evacuating the area.","Lesson ID":868}
{"Driving Event":"One of two truck driver employees of Contractor's Cargo Company, was lifted or hurled, from the top of a flatbed trailer parked on the NASA-Ames Vertical Takeoff and Landing (VTOL) Test Pad. This mishap occurred while the employee was positioning a load suspended in slings on the flatbed. The towbar of the load, which was the flatbed front wheel assembly, rotated from a vertical to horizontal position upon being touched or moved by the employee. In the course of being lifted or hurled from the truck by the towbar, the employee sustained serious head injuries and was transported, unconscious, to a hospital. He remained at the hospital for about a month, then was transferred to Southern California. He was still in a coma when he was transferred.","Lesson ID":865}
{"Driving Event":"A mishap occurred with the Propeller Test Rig (PTR) in the 40'x80' Wind Tunnel at an airspeed of about 200 knots. The model was a 25' diameter, three bladed prop rotor, and it was rotating at a speed of about 500 rpm before the mishap. The mishap was caused by failure of a bearing set in the collective pitch control system during a run in which several data points had been taken and new conditions were being set up. The rotor torque went from about 10,000 ft-lb to n\u03032,000 ft-lb (model motors went from acting as motors to generators), and the rotor control system locked up as it was designed to do at n\u03032,000 ft-lb of torque to prevent actuator failures from causing damage to the PTR. At this time it was recognized that there was a problem, and the designated procedure was followed which was to open the breaker to the model motors. Opening the breaker (although it had happened automatically) had been successful during an incident that occurred on March 21, 1991, and it was thought that this was a similar event. As soon as the breaker was opened the rotor began to accelerate. Because the rotor blades had gone to a lower blade angle (unknown at the time) the rotor accelerated to a very high speed. Redlines were rapidly indicated on the Bar Chart Monitor, and as soon as this occurred the Wind Tunnel Emergency Stop was initiated. However, the failure had progressed too far, and the rotor continued to speed up until it self-destructed due to overspeed. The rotor reached a speed of close to 1000 rpm; the safe operating limit was 630 rpm, and the structural limit for the blade tension straps was 930 rpm. At overspeed, one blade tore loose and lodged in the top of the test section. The remaining rotor and mast assembly tore loose from the model drive system due to the imbalance. The mast landed on top of the Rig, and the rotor assembly went down the tunnel coming to rest against the safety fence. Some of the debris went past the first fence, but most was collected against the fence attached to vane set 5 which is the last vane set ahead of the Wind Tunnel drive fans. The only damage to the Wind Tunnel drive was a small gouge in one of the blades.","Lesson ID":869}
{"Driving Event":"The SOFIA B747 aircraft was being towed into the large maintenance nosedock inside the 7500 hangar building at the Raytheon, Waco facility. As the aircraft approached the nose dock it made contact with the upper support structure of the nosedock. Labor and material costs were identified as less than $10,000. There were no personel injury associated with the incident. The damage is located at FS 480, stringer 2A, exterior top left side of fuselage. The exterior skin deformation is approximately 18\" in lenght and 14\" in width, with approximately .250 indentation of skin on either side of the frame. No fracturing of external skin is visible. The cause of this incident was attributed to the following: Insufficient clearance between top of the aircraft and nosedock support structure. Lack of clear communication means between the aircraft\/nosedock clearance observer and the tow task supervisor. Supervisor failure to ensure tow team members were pre-briefed on specific duties and resposnsibilities prior to performance of the task. Supervisor failure to properly plan aircraft tow operations prior to task performance. Supervisor failure to ensure tow team personnel possessed required support equipment (Not all task assigned personnel possessed alert whistles\/horns).","Lesson ID":857}
{"Driving Event":"A loose metal clip inside of a sealed battery box appeared to cause a short that caused excessive heat to build in the NiCd batteries and in turn cause additional shorts between the individual cells. These secondary shorts caused a runaway condition that could not be stopped until the battery voltage was drained.","Lesson ID":858}
{"Driving Event":"A water line coming into a building was being increased in size to accommodate a new building sprinkler system. The excavation was done, but the compaction that should have been done was not. The specification of backfilling was not part of the contract documents.","Lesson ID":859}
{"Driving Event":"The SOFIA B747 upper rudder was dropped after it was removed from the tail of the aircraft and was in the process of being placed on a flat bed trailer. Maintenance personnel attempted to rotate the removed rudder from the vertical to the horizontal position. This task was performed without the use of a holding\/transport fixture as defined within the specific task job card and utilizing only two of the four attach points called out in the written procedures. Prior to removal, the procedures were reviewed and found adequate to perform this task. While the procedures addressed the equipment and the process for removal of the rudder, they did not address the process beyond installation of the vertical rudder on a dolly. Though telephone calls were made in an attempt to locate equipment required by the procedures, there was none available when the decision was made to proceed with the rudder removal. The production supervisor admitted responsibility for the decision to proceed without all of the equipment required by the procedures and he proceeded to transition the rudder from a vertical to a horizontal position. The transition was attempted by unfastening the two harness support brackets on one side of the rudder. As the crew began the transition, the loading was multiplied by approximately 800 lbs. of counterweights on the rudder's leading edge, a condition for which the sling assembly and attach points were not designed to carry. Of the three bolts at the point of failure, one bolt stripped the threads on exit, another pulled the attachement receptacle through and out, and the third bolt pulled the attachment receptacle and surrounding structure loose from the rudder.","Lesson ID":856}
{"Driving Event":"The upper rudder of the 747SP aircraft was removed from the aircraft tail. The rudder was lowered lengthwise in the vertical position to a flat bed. The rudder was rotated to a position above the flat bed. The rudder was next rotated to a hinged up horizontal position. The two right hand fittngs were removed and the rudder was rotated over towards the right side. The lower left hand fitting pulled the screws and some surrounding structure from the rudder. This allowed the rudder to fall on the flat bed and then approximately 30 inches to the concrete floor. One area 8 inches by 5 inches of the rudder frame and skin was pulled loose. One threaded lock was pulled loose and one threaded lock was stripped. Several rivets were popped on one of the counter weight attachments and minor bending on the lower end of the rudder.","Lesson ID":861}
{"Driving Event":"The Mod and Rehab projects are typically requiring that people be moved out of offices while the construction activity is taking place. As a result, there is an extra burden on the Project Manager to coordinate people moves. Along with the moves come the issues of telephone and computer moves, because different organizations handle these moves. In addition, there is also the issue of where are the people going to be temporarily moved to. During the planning phases of moves, it becomes a full-time job to coordinate all the above activities.","Lesson ID":860}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number OPS-14 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Reduction in the failure rate of rotational equipment due to induced failures resulting from improper or inadequate installation, providing more efficient operation as well as reduced operating and maintenance costs. This practice identifies the use of a laser alignment system for installation of machinery with rotating shafts (i.e., pumps, motors) to obtain optimum alignment coupling, resulting in less wear and increased reliability. The laser system is a low power, pulsed semiconductor laser. The detector is a biaxial, analog photoelectric semiconductor position detector with a resolution of 1 micron. The linearization characteristics of each laser detector are unique and are stored in the systems computer, thus only the detector and computer specifically matched to each other may be used together. The laser transmitter is attached to the shaft of the stationary machine and the reflector is attached to the shaft of the machine to be moved. The prism reflects the beam in a plane parallel to that in which it receives the beam. As the prism shifts along the radial axis during rotation, the spacing between the beams is altered, and from this difference the offset of the shafts are determined. In the perpendicular plane, the prism acts as an ordinary mirror. As the prism is rotated about its vertical axis, the angle between the entering and reflected beams changes, permitting angular misalignment to be computed. The computer receives its input data directly from the detector through a connecting cable and calculates the alignment correction values for the feet of the machine to be moved. The computer can also detect the presence of quotsoftfootquot on the shaft alignment. Softfoot results from the mounting base not providing a level and even surface for securing the equipment, resulting in an unstable installation and misalignment leading to premature failure. The system can be used for gauging the amount and effect of softfoot, but cannot determine the cause or corrective action. The objective of alignment is to ensure that the rotating shaft centerlines of different machines are aligned. It is important to understand that alignment refers to the positions of 2 centerlines of rotation. Shaft alignment means quotPositioning two or more machines so that their rotational centerlines are collinear at the coupling point under operating conditions.quot Collinear means 2 lines that are positioned as one line or 2 lines in exactly the same place. As used in alignment it means quotTwo or more lines with no offset or angularity between them.quot The phrase quotcoupling pointquot acknowledges that vibration due to misalignment originates at the point of power transmission, the coupling. It does not mean that the couplings are being aligned. The shafts are being aligned, the coupling center is just the measuring point. quotUnder operating conditionsquot is taking into account that the machines often move after startup due to wear, thermal growth, dynamic loads or support structure shifts. The term quotshaft alignmentquot implies that the bearings and shafts are free from preloads. In properly installed equipment, there are no outside forces or strains on the bearings or shafts. A laser alignment system eliminates the effects of irregular shaft or coupling surfaces, eccentricity, bent shafts, etc. Unlike conventional methods using dials and gages where a spanner bar is used, there is no sag in the laser beam. The effects of vibration on the alignment process is insignificant, as the laser beam travels at the speed of light. The laser system is a 25 to 1 improvement over the dial measurement system, with a 0.00004quot resolution. Simplified Version of How the Optics Work [D] A side view of laser and prism. When the prism is moved up or down, the return beam moves up or down twice the distance the prism moved. Thus measurement offsets between two points can be determined. The offset measured is the offset of the prism relative to the laser. [D] Offset measurement The detector can not only sense up and down motion of the return beam, but side to side as well, However, if we slide the prism side to side, the beam does not move. The beam will move side to side only if we rotate the prism in the horizontal plane. Prism moved side to side; beam does not move. [D] Horizontal rotation moves beam. [D] Note that the angle the return beam moves is twice the angle the prism moves. If the beam is zeroed at the 12:00 position and then read at the 6:00 position, the X reading (or horizontal beam movement) is one leg of a 90 deg. triangle. The distance from laser to prism is the other leg. The angle defined by these two legs is two times the actual angular misalignment between the shafts. The position detector is an analog biaxial photoelectric cell with a repeatable resolution of 1 micron (or approx. 0.00004quot). Because beam movement is twice prism movement, system repeatability is 0.5 micron or (approx.) 0.00002quot. Devices such as position detectors are highly nonlinear and subject to many manufacturing variables. To compensate for nonlinearity, the electronics contain sophisticated linearizing algorithms that linearize the output of a given position detector with 2% of beam displacement. Thus, overall measuring error is less than 2% of displayed value, rounded off to 0.5 mil. Reference: The OPTALIGN Training Book (catalog No. 01-705-01) Ludeca, Inc. 1527 N. W. 89th Court Miami, FL 33172 FAX (305) 591-8935","Lesson ID":882}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number OPS-15 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Incorporating this technique eliminates the need and cost of a separate cooling system to be designed, installed and maintained at each propellant storage area. Maintainability and reliability of the TCU is greatly enhanced since the individual cooling systems have been removed in lieu of connections to the existing Facility Chilled Water (FCW) System. While at the launch pad the Space Shuttle Orbital Maneuvering System (OMS) and Reaction Control System (RCS) propellant tanks are filled with hypergolic propellant; Monomethylhydrazine (MMH) and Nitrogen Tetroxide (N2O4). The OMS\/RCS is used for altitude and attitude changes required by the Shuttle during orbital flight. Loading of the tanks takes place about two weeks prior to launch. A temperature requirement is imposed on the propellant for loading to assure proper operation of the Ground Support Equipment (GSE) and to assure proper weight measurement of the loaded propellant. The temperature requirement is met by raising or lowering the propellant temperature as required by flowing through the Thermal Conditioning Unit (TCU). If the propellant temperature is below that required, the facility chilled water is heated in the TCU heater before flowing through the heat exchanger where the propellant is brought up to the required temperature (see figure 1). [D] If the propellant temperature is above that required, the heater is not operated and the FCW provides the heat sink needed to lower the temperature. Each MMH and N2O4 storage area has a TCU. The FCW is piped to the propellant storage areas through insulated tubing from the launch pad FCW system. Filters are provided in the pad FCW system to prevent contaminants from damaging or clogging downstream components. Using the FCW System to provide the heat exchange medium eliminates the need for a separate conditioning unit at each TCU. The previous TCUs used a Freon conditioning unit for temperature control of the propellant. Eliminating those units eliminates the high operating and maintenance costs and environmental concerns associated with each Freon heat exchanger. Reference: KSC Drawing 79K05081 - Hypergol System Schematic Pad 39A.","Lesson ID":883}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number OPS-13 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Predictive maintenance allows for scheduling of maintenance when it is required and when it will have the least effect on scheduled activities requiring support of the equipment in question. Unexpected equipment breakdowns and scheduled maintenance downtime for periodic disassembly and inspection to determine equipment condition are virtually eliminated. Additional discussion of the benefits of predictive maintenance is provided in the following pages. Predictive maintenance is a technique which checks the \"health\" of an item while it is operating using one or more sophisticated tools. The capabilities for predictive maintenance exist because of the availability of desktop computers, and the increased sophistication of equipment monitoring instruments. Too much or too little maintenance is avoided because the equipment is monitored on a regular basis providing trend data that can be used to project probable machine alarm dates. According to the Electric Power Research Institute (EPRI), the annual maintenance cost of such a program is reduced by 50% or more to between $7 and $9 per horsepower. Predictive maintenance has received a great deal of attention in the past five years or more. U. S. industry spent $200 billion in 1985 alone, to maintain plants and equipment. Studies by the EPRI show that the annual maintenance cost of repairing machinery when it breaks down (corrective maintenance) is $17 to $18 per horsepower. Contrasted to that is preventive maintenance, which uses statistics to determine the probable health of equipment. However, in the real world, machines do not follow averages. The result is usually \"over maintenance\" or \"under maintenance.\" The EPRI Studies show that the annual maintenance cost per horsepower using preventive maintenance is between $11 and $13. As was stated earlier, the EPRI study shows that predictive maintenance reduces manual maintenance costs to between $7 and $9 per horsepower. Benefits from implementing a Predictive Maintenance Program include: Condition of equipment under a predictive maintenance program is known, permitting repairs to be planned and carried out without interrupting scheduled support activities. Reduced maintenance costs are realized through the use of predictive maintenance. Maintenance needs can be anticipated and planned. Maintenance activities are more efficiently planned from a standpoint of manpower, parts, and tools. Catastrophic failures, which impose secondary, expensive damage, are also avoided. Improved equipment performance is achieved through the use of predictive maintenance. Predictive maintenance measures equipment condition so that corrections can be made before performance is compromised. Predictive maintenance provides several potential areas for energy savings. Elimination of high energy vibration sources such as misalignment and imbalance will reduce machine power consumption. Motor phase imbalance, which increases power consumption can be corrected resulting in savings in power and increased motor life. Technical Description Predictive (or condition-based) maintenance is an outgrowth of a preventive maintenance program. Today's state of the art technologies, readily available user friendly desk top computers, and increased sophistication of equipment monitoring instruments, now make it possible to have a reliable and cost effective predictive maintenance program. The first step in developing an effective predictive maintenance program is to determine the cost of the maintenance program such as cost for maintenance personnel, repairs, spares and cost associated with losses incurred due to equipment being down. The next step is to identify the number of man-hours required to monitor the equipment. Simple machinery (motors, pumps, or fans) will require fewer points to accurately detect developing problems than more complex equipment, such as turbines or generators. By counting the pieces of equipment and the number of measurement points, you can estimate the level of manpower required. More critical equipment may require more frequent monitoring, which will increase manpower requirements. The monitoring frequency is a function of the critical nature of the equipment; so the next step is to set up an equipment classification system. For example: Class 1 - essential equipment - includes equipment that must be on-line to continue all or a major part of a process. Loss of this equipment would have a major impact on safety, productivity and availability. Also included in this group would be equipment that has a high repair cost, or a long lead time for ordering repair parts. Class 2 - critical equipment - includes equipment that would limit a major part of a process, and equipment with high initial replacement costs, or chronic maintenance problems. Class 3- serious equipment - includes equipment that is not critical to process, but require monitoring to ensure acceptable process performance. Class 4 - other equipment - includes high speed or high load machinery that is prone to premature failure because of its severe operating mode, but is not considered critical to the process. Once equipment has been properly grouped, the data acquisition schedules and routes can be established; and projected manpower levels determined. If sufficient staff is not available, the potential savings from the program must justify additional personnel. Besides salaries, costs should include the cost of diagnostic and analytical equipment, office space, and any overhead costs that will be charged to the group. Costs should also include training and additional skill development. Training costs can range from a few hundred to a few thousand dollars in the first year; depending on the level of experience and the size of the staff. A typical predictive maintenance system contains four main components: a microprocessor based data collector, a host computer, software and transducers. Each is an important element and it is important that they function well as a total system. Some important characteristics of the integrated system to consider are: User friendly software and hardware. The predictive maintenance program will often be staffed with technicians and engineers that understand the mechanics of machine operation but not necessarily computers. Hardware and software must be designed for simple, straightforward operation. Error correction should be simple, but it should not allow the free form modification of data. Automated data acquisition management and trending. The object of using a microprocessor based data collector and a host computer is to remove the possibility of human error during data input, minimize manpower requirements, and automate as much of the data handling as possible. Flexibility. The system should be capable of collecting, storing and presenting data such as vibration data in a variety of formats (displacement, frequency, velocity, acceleration, cpm) and providing accurate data analysis. The system should accurately accept any commercially available transducer input. Reliability. The hardware and software should have proven field experience. Ask for a users' list and find out strengths or weaknesses from people who have experience with the system. Accuracy. Data must be accurate and repeatable since decisions on equipment condition will be made based on the information that is collected and analyzed. Technical support. Training and technical support is a very important consideration. A properly configured predictive maintenance system should provide valuable information with a minimum level of manpower, and only a limited knowledge of the theory behind the predictive maintenance techniques used. Each system will, however, require some training in the basics of data base development and diagnostics. Report generation. Maximum flexibility in format and content is important and the system should be able to generate reports at several levels of detail. Examples of the types of reports the system should be able to produce are: Exception report. This report consists of listing equipment that have exceeded one or more alarm or alert limits, missing data points, notepad observations, or equipment with a predicted failure before the next scheduled measurement date. Last measurement report. This report is a listing of components, notepad observations, project failure time, and missed measurement points. The report would include information shown on the exception report and a complete review of all equipment. A machine history report recapping total equipment history including all components. If the system does not automatically generate these reports the manpower requirements can increase substantially. If a limiting factor is staff levels or experience; or if the cost-benefit analysis is inconclusive, a pilot program may be the best solution. Equipment vendors will help establish a program and phase out their support as the in-house staff becomes proficient. This option allows the development of financial benefits, provides hands-on training for the in-house staff, and develops a data base. Another option is to contract with an outside company to run the program. With this option, the need for additional in-house staff is eliminated, as is the need for an investment in data acquisition and analysis equipment. One should avoid vendors who quote fixed price per measurement point regardless of the type of equipment. Because of the type of equipment being measured complexity of the measurements will vary and also their cost. A price based on equipment type (motors, pumps vs turbines, generators) should be requested. There are numerous techniques available for implementing a Predictive Maintenance Program. Techniques that may be found in various predictive maintenance programs include: Vibration analysis which is performed on mechanical equipment to evaluate the online condition of its mechanical parts, and effect on related pieces of equipment. Effectiveness of vibration mounts, shafts, bearings, coupling alignment and impeller balance are measured and monitored to determine if equipment is functioning properly and within specifications. Ferrography Analysis, a wear particle analysis being diagnostic and predictive techniques to evaluate the on-line condition of interacting lubricated or fluid powered parts. Lubricants or fluids are analyzed for condition, level and type of contamination. A wide array of problems with equipment, the lubricants\/fluids and maintenance methods can be determined by use of ferrography. Utilization of oil analysis has and will continue to expand the existing life of critical equipment. Thermography is used to analyze equipment that exhibits over-heating and heat links when not operating properly. This includes equipment as varied as circuit breaker panels, electronic circuit boards, cryogenic piping, GN2 heaters and many others. Laser Alignment is used to detect misalignment in mechanical equipment components that can lead to accelerated wear or possible catastrophic failure. It is used to verify proper installation and even fabrication of mechanical equipment before operation. It is also used for online monitoring to ensure proper alignment is maintained during equipment operation. Correct alignment will reduce power consumption. Motor Analysis is used to determine the level of degradation in electrical motor circuits, such as individual phase resistance from power bus disconnect through the motor windings, phase to ground resistance, inductance of motor coils and capacitance of each phase to ground. Detecting and correcting phase imbalance saves in power consumption and prevents motor core reduction. Ultrasonics is that technology used to detect hidden flaws in materials, especially metals. This technology has advanced into a completely digital and portable microprocessor-controlled ultrasonic flaw detector. It is safe and faster than using X-Ray technology to detect flaws. Visual inspection where plant or maintenance engineers, on a regular basis, visually inspect each critical system. A comprehensive predictive maintenance program is composed of several techniques which, when combined, can predict most mechanical and electrical problems found in equipment. References Lockheed Space Operations Company Predictive Engineering Technology Program Implementation Plan, 10\/94. EG&G Florida, KSC Predictive Maintenance Plan, EGG-4061130, 11\/20\/92. P\/PM Technology Publications (issues from 1986 or present). Maintenance Technology Publications (issues from 1993 to present).","Lesson ID":849}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number OPS-18 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Maintainability of the S-Band Uplink Monitoring System is enhanced by providing a means to pinpoint faults should they occur. Reliability is also enhanced by ensuring the communication signals are transmitted as intended. The Goddard Unified S-Band (GUSB) system transmits voice and data signals via free space to two antennas at the launch pad; the Orbiter S-Band Antenna and the Monitor S-Band Antenna on the Fixed Service Structure (FSS). Both antennas receive the same signal. The signal from the Monitor Antenna is retransmitted over an optional link, demodulated at the Orbiter Processing Facility (OPF) and compared to the signal being sent from GUSB (See Figure 1). [D] Figure 1. S-Band Uplink Monitoring System Block Diagram The GUSB voice and data communications are critical, particularly during launch countdown. However, transmissions can be distorted because of a transmission frame error, a discontinuity in Radio Frequency (RF) signal level, or a response to harmonics. Concerns arise about the information reaching the Orbiter: Is it error free? Is it identical to that which was transmitted? The S-Band Uplink Monitor System answers these questions continuously throughout launch countdown. This system detects such problems; furthermore, it provides a frame of reference whereby engineers can troubleshoot and pinpoint the errors to the following areas: The GUSB transmitter The receiver on-board the Orbiter The Orbiter's on-board sensor The monitoring receiver in the OPF This capability enhances the maintainability of the monitoring system, as well as the GUSB transmission system, by providing this pinpointing capability. RF Transmission The GUSB antenna transmits the modulated S-Band signal (2106 or 2041 MHZ, payload dependant) at several levels during the countdown: 10KW, 1KW, 200 W, 16 \u00b5W. The Uplink Monitor S-Band Antenna receives the incoming S-Band Signal at the 295-foot level of the FSS. The antenna was designed to be located as close as possible to the Orbiter S-Band Antenna in order to receive the same signal in terms of strength and noise content. The signal is then split at half power between two channels. The channel selected depends on the GUSB signal power. The channels are identical except for their variable attenuator settings. The high power channel has high attenuation so the optical transmitter does not saturate; the low power channel has low attenuation so the signal has considerable strength when it reaches the optical transmitter input. After the signal passes through the directional coupler, the RF amplifier in each channel boosts the signal with a +52dB gain to acquire optimum signal strength through the optical link. This assures an adequate signal strength at the receiver in the OPF after passing through the final directional coupler. Fiber-Optic Link The signal is now transmitted to the OPF through an optical link. The use of fiber over a long distance minimizes both attenuation and noise interference. In addition, electromagnetic interference is non-existent when transmitting over fiber optics. For these reasons, the fiber-optical link covers a sizable distance of the system's total transmission range (up to 8 KM for Pad B). The optical power at the transmitter is set to allow for losses in the optical link and still be above the sensitivity of the optical receiver in the OPF. The number of patch panels and fiber optic connectors are kept to a minimum to minimize losses during the routing of the signal to the OPF. Two fiber optic couplers are used because the system is required to transmit the signal from either launch pad to OPF-1, 2 or OPF-3. The first coupler is a single-mode 2X2 which allows two inputs such as the low-power channels from Pads A and B to transmit to OPF 1, 2 on output 1 and to OPF-3 on output 2. The second coupler is configured similarly, except that the high power channels feed the inputs. The fiber optical receivers in the OPF communications and Tracking Laboratory receive the modulated optical signal. At this point the signal is demodulated off the light wave and coupled to the S-Band receiver in the OPF where it is compared with that coming off an S-band receiver that is monitoring the GUSB. Information is demodulated from the carrier and recorded by a frame-check computer that indicates the bit-error count. It is at this point that engineers can determine if the S-Band signal received at the Orbiter is accurate and detectable. Reference: KSC Drawing 80K54080.","Lesson ID":878}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number OPS-17 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Water leaks or ruptures can also spill onto sensitive flight hardware or other equipment. This technique will prevent additional repairs if overhead oil or water leaks occur from facility systems. Most importantly, this technique will decrease the electrical hazard potential to maintenance personnel by restricting the entry of water that can cause short circuits. During hoisting operations, oil can drip onto sensitive flight hardware or other equipment. If a drip pan is used, the pan can catch the oil and it can be inspected to monitor the gearbox for oil loss. Significant oil loss can cause damage to the gearbox assembly. To protect against water intrusion, design facilities with drip pans above electronic equipment as shown in Figure 1. Water sources can come from fluid condensation, firex water, or ruptured fluid lines. [D] Use of this technique could have prevented the loss of air conditioning at the KSC Vehicle Assembly Building, Orbiter Processing Facility, and the Launch Control Center when a water line, located above a main power substation, ruptured and shorted the main buses. This mishap interrupted Shuttle processing and cost considerable resources. Hoists contain gearbox assemblies that are filled with oil for lubrication and gear cooling. Gaskets that seal the gearbox housing parts or shaft seals can deteriorate over time and cause oil to leak out. Startup and vibration can cause bolts that connect the gearbox assembly together to become loose and cause oil to leak out. To capture the oil, pans can be constructed from sheet metal. Metal straps are placed on each end of the pan and loop around the front and rear of the gearbox shown in Figure 2. The oil pan should be deep enough to hold all the oil in the gearbox. However, because of space constraints a shallower pan may be used. The pan area should cover the bottom area of the gearbox. [D] For example, Bridge Buckets, located in each of the Orbiter Processing Facilities, are used by personnel to travel along the length of the Orbiter Cargo Bay for inspections. There are gearbox assemblies at various locations such as the hoisting system and the bridge drive assembly. The bucket hoisting system contains a gearbox assembly on each end of the hoist drum. Each gearbox contains a shallow pan with two straps, one on each end, that loop around the front and rear of the gearbox. This prevents any oil that may drip into the Orbiter Cargo Bay. The 250 Ton Bridge Crane, located in the Vehicle Assembly Building, contains an oil drip pan inside the hook load assembly. This prevents oil that could drip onto Solid Rocket Booster Segments or the Orbiter. Reference: SW-E-0002, Space Shuttle Ground Support Equipment General Design Requirements, section 3.4.3.1.ff","Lesson ID":879}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number OPS-07 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. AC variable frequency drive systems for motor speed control offer several advantages over systems that use DC or AC motors coupled with mechanical devices (clutches and pulleys) to achieve motor speed control. These advantages enhance system maintainability resulting in: Improved system maintainability, reliability, and performance. Reduction of preventive and corrective maintenance (manhours and materials) by elimination of mechanical devices. Increased system availability. Self-contained diagnostic test capability. Reduced size and mechanical complexity. Reduced life cycle costs. The use of A\/C variable frequency drive systems provides greater efficiency for motor speed control than mechanical devices with DC or AC motors. AC variable frequency drive systems allow for direct coupling and eliminates the need for mechanical devices such as clutches and pulleys. Elimination of these mechanical devices results in decreased maintenance downtime and repair costs. Adjustable speed AC drives also offer many advantages over DC drives because of simplicity, high-speed capability, and low maintenance requirements of induction motors. These motors are suitable for adverse conditions such as dirty air, explosive atmospheres, and inaccessible locations. Components Typically, an adjustable frequency drive system for an AC induction motor will consist of a converter module, DC link module, and inverter module. The following is a description of an adjustable frequency drive system. The configuration shown and the type of control scheme used classify the drive as a current source inverter type. Figure 1 illustrates three fundamental steps used in converting the AC input into a variable AC output. [D] The converter module can be thought of as a programmable DC voltage source where the three AC input lines are rectified by silicon controlled rectifiers (SCR's) to provide a variable DC output. An SCR can be thought of as a controlled rectifier or switch that lets current flow in the forward direction when gated or opened. Then it cannot shut off again until the flow reverses or ceases. At this point the SCR regains its forward blocking capability until gated again. The control circuitry in the drive turns the SCR's on 60 times per second to obtain the desired current flow. Each time a new SCR is gated, it then forces a previous one to shut off. If it is necessary to turn off all the SCR's, all gate signals are removed and the SCR's then turned off naturally when the AC input voltage is reversed. The DC link module is so called because it is a device that connects the inverter and converter modules. Electronically it is an inductor or choke that filters the output of the converter module and provides a more uniform flow of current to the inverter module. Since the inductor tries to maintain a constant flow of current through it, this allows the voltage source converter to function as a current source to the inverter module. The inverter module takes the filtered DC from the DC link module and converts it back to AC. Here the SCR's are gated, one after the other, steering this DC into and out of each of three input lines to the motor. The faster the SCR's are fired, the faster the motor turns. Since the AC line is not present here, external commutating capacitors are used to ensure that each time a new SCR is fired, an old or previously conducting one is shut off. Drive Operation The following paragraphs briefly discuss some of the characteristics of the drive: Output voltage and current normally delivered to a motor from the AC input line are both sinusoidal. This is not true when operating the motor from a current source inverter (see Figure 1). The voltage waveform is closely sinusoidal with disturbances called commutation spikes. The output current is a high quality quasi-square waveform. The current source inverter makes no attempt to define the shape of the output motor voltage. The output voltage is simply a result of the current and rotation of the motor. The shape of the current waveform is defined and its level is increased or decreased to obtain the required voltage. Stated more simply, the control circuitry contains an inner current regulator loop with an outer voltage regulator loop that ensures that the proper current and voltage are supplied to the motor. Crowbar: Since during normal operating conditions the DC link or choke is carrying a large current, which implies a large amount of stored energy, it is worth discussing what happens should the input or output to the drive be suddenly disconnected. The inductor would normally develop whatever voltage is needed to maintain the constant flow of DC. To mitigate the danger of these damaging voltage levels, protective circuits are incorporated within the drive to provide a path for this DC. The protective schemes are based on the capability of both the inverter and converter modules to provide a path for this current by firing two series SCR's in the converter and inverter modules, thus generating a direct short circuit path through which the current trapped in the inductor may flow. The process of firing these SCR's to provide a current path is called quotcrowbar.quot Output clamp: With an abrupt loss of load, the protective mechanism operates as follows. The inverter output leads to the motor are equipped with a device called an quotoutput clamp.quot If the motor is abruptly disconnected, the output current from the inverter will transfer to this clamp circuit until its level hits 950 volts DC. At this point, the control circuitry will force a quotcrowbarquot and shut off the converter module. This prevents any further increase in output voltage; an orderly shutdown is performed. Commutation: Commutation is a process by which an SCR is forced out of a conducting state by reverse biasing. Two types of commutation normally occur in the power circuit, natural and forced. Regeneration: The SCR converter is a two-quadrant device capable of accepting power from the DC bus and returning it to the line when the DC bus potential is negative. This capability makes the current source inverter one of the few inverter types that are inherently regenerative without excessive circuit complication. Low speed cogging: Each commutation in the inverter module causes the current flow to the motor to be abruptly stopped in one phase and started in another. This action forces the motor to turn one-sixth of a rotation on a 2-pole machine, one-half on a 4-pole machine, etc. This explains why, at very low speeds, the motor appears to move in discrete steps rather than smoothly rotate. At a frequency of 1 Hertz, for example, a two-pole machine would perform one complete rotation in six distinct steps at a rate of six steps per second. This effect is reduced depending on the inertia of the connected load. The visual effect completely disappears at speeds above a few Hertz. Reference: KSC Electrical Advanced Schematic Drawing 79K06382. KSC Electrical Advanced Schematic Drawing 79K40029.","Lesson ID":880}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number OPS-16 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Attaching a source of GN2 to the actuator breather provides an atmosphere in the actuator chamber of pneumatically actuated valves that prevents corrosion thus lengthening the life of the valves. GN2 is provided to the actuator breather of the pneumatically actuated valves. The source may be a dedicated GN2 source or a more efficient means would be to tap off a nearby panel that uses GN2 for an environmental or hazard proofing purge. A line connected from the panel to the actuator breather port would allow access to the GN2 for filling the valve actuator chamber when the valve is deactivated (see Figure 1). [D] When designing the system, caution should be used to prevent or minimize back pressure on the actuator which would reduce actuator performance.","Lesson ID":867}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number OPS-08 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Properly designed fiber optic transmission systems will last for long periods of time without any preventive maintenance and can offer reduced maintenance downtime and repair costs. Well-built optical transmission lines and couplers are relatively immune to electromagnetic interference, adverse temperature, and moisture conditions and can be used for underwater cable. An optic fiber can be 20 times lighter and five times smaller than copper wire and still carry far more energy. Using fiber optic control circuits provides electrical isolation for safety in hazardous environments. Because optical cables carry no current they are safe to use in explosive environments and eliminate the hazards of short circuits in metal wires and cables. Components and Operation The basic elements found in fiber optic systems are a transmitter, fiber optic cable, receiver, and connectors. Figure 1 illustrates the main parts of a fiber optic system. The following is a brief description of these elements and their function: The Transmitter converts an electrical signal to a light signal. The transmitter consists of a driver and a source. The input to the driver is the signal from the equipment being served. The driver circuit changes the input signal into a form required to operate the source. The source, either a light-emitting diode (LED) or laser diode, does the actual conversion. The Fiber Optic Cable is the medium for carrying the light signal. The main parts of a fiber cable are the optical fiber, cladding, buffer jacket, buffer, strength members, and jacket. Figure 2 illustrates the main parts of a single fiber cable. The optical fiber contains two concentric layers called the core and the cladding. The inner core is the light-carrying part. The surrounding cladding provides the difference in refractive index that allows total internal reflection of light through the core. The buffer is the plastic coating applied to the cladding. [D] [D] Cable buffers are one of two types, loose or tight. The loose buffer uses a hard plastic tube having an inside diameter several times that of the fiber. One or more fibers lie within the buffer tube. The tube isolates the fiber from the rest of the cable and the mechanical forces acting on it. The buffer becomes the load bearing member. As the cable expands and shrinks with changes in temperature, it does not affect the fiber as much. A fiber has a lower temperature coefficient than most cable elements, meaning that it expands and contracts less. The tight buffer has a plastic directly applied over the fiber coating. This construction provides better crush and impact resistance; however, it does not protect the fiber as well from stresses of temperature variations. Because the plastic expands and contracts at a different rate than the fiber, contractions caused by variations in temperature can result in loss-producing microbends. Tight buffers are more flexible and allow tighter turn radii. Therefore; tight tube buffers are useful for indoor applications where temperature variations are minimal and the capability to make tight turns inside walls is desired. Strength members add mechanical strength to the fiber cable. The most common strength members are Kevlar Aramid yarn, steel, and fiberglass epoxy rods. During and after installation, the strength members handle the tensile stresses applied to the cable so that the fiber is not damaged. Kevlar is most commonly used when individual fibers are placed within their own jackets. Steel and fiberglass members find use in multi-fiber cables. Steel offers better strength than fiberglass, but may not be the best choice for maintaining an all dielectric cable. Steel also attracts lighting, whereas insulation provides protection from the fiber does not. The jacket-like wire insulation provides protection from the effects of abrasion, oil, ozone, acids, alkali, solvents, etc. The choice of jacket material depends on the degree of resistance required for different influences and costs. The Receiver accepts the light signal and converts it back to an electrical signal. The receiver contains a detector, amplifier, and an output section. The amplifier enhances the attenuated signal from the detector. The output section performs many functions such as: separation of the clock and data, pulse reshaping and timing, level shifting to ensure compatibility (TTL, ECL, etc.) and gain control. Connectors and splices, which link the various components of a fiber optic system, are vital to system performance. A connector is defined as a disconnectable device used to connect a fiber to a source, detector, or another fiber. It is designed to be easily connected and disconnected many times. A splice is a device used to connect one fiber to another permanently. Connection by splices and connectors couples light from one component to another with as little loss of optical power as possible. The key to a fiber optic connection is precise alignment of the mated fiber cores (or spots in single-mode fibers) so that nearly all the light is coupled from one fiber across the junction to the other fiber. Contact between the fibers is not required. However, the demands of precise alignment on small fibers create a challenge to the designer of the connector or splice. Maintainability design features that should be addressed in the design for fiber optic systems should provide for fault localization and isolation, modular replacement, and built-in test and check-out capability. Improvements Fiber optics systems offer many benefits. In sensing systems, sensitive electronics can be isolated from shock, vibration, and harsh environments, resulting in more economical packaging. The number of repeaters required for low attenuation cable is less than with conventional systems and for short hauls of less than 10 km, no repeaters are necessary. In the absence of electrical current, the life of a fiber optic system's components equals the useful life of the control system, the light source, and the electronics. Maintenance and repair costs are reduced dramatically. Installation costs of fiber optic cables are lower than metal cables because the shipping and handling costs are about one-fourth and labor costs one-half that of current metal cables. Reference: RADC-TR-88-124, Impact of Fiber Optics on System Reliability and Maintainability, June 1988. RADC-TR-80-322, Failure Rates for Fiber Optic Assemblies, October 1980. AWP, Technician's Guide for Fiber Optics, 1987.","Lesson ID":881}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number AT-3 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Benefit: Availability prediction and assessment methods can provide quantitative performance measures that may be used in assessing a given design or to compare system alternatives to reduce life cycle costs. This technique increases the probability of mission success by ensuring operational readiness. Analyses based on availability predictions will help assess design options and can lead to definition of maintenance support concepts that will increase future system availability, anticipate logistics and maintenance resource needs, and provide long term savings in operations and maintenance costs based on optimization of logistics support. Implementation Method: Availability can be predicted or estimated using various methods and measures. Availability is a characteristic of repairable or restorable items or systems, and assumes that a failed item can be restored to operation through maintenance, reconfiguration, or reset. It is a function of how often a unit fails (reliability) and how fast the unit can be restored after failure (maintainability). A foundation to support both the establishment of reliability and maintainability (R&M) parameters and trade-offs between these parameters is created by availability prediction before analyses. Availability can be estimated for components, items, or units, but overall spacecraft system or ground system availability estimation is based on the combinations and connectivity of the units within the system that perform the functions, i.e., the series and redundant operations paths. Availability Measures One basic measure of availability, called inherent availability, is useful during the design process to assess design characteristics. The measure involves only the as-designed reliability and maintainability characteristics and can be calculated using the estimated mean-time-between-failure (MTBF) and mean-time-to repair (MTTR) parameters. The predicted or estimated measure of inherent availability is calculated as: [D] The MTTR time in the inherent availability calculation does not include such times as administrative or logistic delay time, which generally are beyond the control of the designer, and does not include preventive maintenance time. However, effective trade-offs using the basic times and parameters are possible. Trade-off techniques and some sample uses are included in Reference 1, Section 5.5. Another measure of availability, achieved availability or Aa, can be expressed as: [D] where OT is the total time spent in an operating state, TCM is the total corrective maintenance time that does not include before-and-after maintenance checks, supply, or administrative waiting periods; and TPM is the total time spent performing preventive maintenance. Aa is more specifically directed toward the hardware characteristics than the operational availability measure, which considers the operating and logistics policies. A third basic measure of availability, operational availability, considers all repair time: corrective and preventive maintenance time, administrative delay time, and logistic support time. This is a more realistic definition of availability in terms providing a measure to assess alternative maintenance and logistics support concepts associated with the operation of a system or function. It is usually defined by the equation: [D] where Uptime is the total time a system is in an operable state, and Downtime is the total time the system is in an inoperable state. The sum of Uptime and Downtime, or Total Time, is usually known, specified as a requisite operating time, or is a given time to perform a critical function. Downtime often is broken down into a variety of subcategories such as detection and diagnosis time, time waiting for repair parts, actual unit repair or replacement time, test and checkout time, etc. Table 1 shows the basic difference between the availability measures defined above. [D] Table 1: Commonly Used Availability Measures System or Function Availability Estimation System\/function availability estimates may be derived in a limited fashion by algebraically combining mean value estimates of the system units, or more rigorously by using computer- aided simulation methods. Mean Value Estimation Mean value estimation of system availability is usually performed by algebraically combining component, LRU, and ORU availabilities calculated using equation (1). When the system is composed of a number of components, LRU's, or ORU's, the failure of any one of which results in the system being down, the system availability is calculated from the product of these units' availability. When the system involves item redundancy, redundant block availability estimates can be calculated using simple Boolean mathematical decomposition procedures similar to reliability block diagram solution methods. See Reference 1, Section 10.4. Computer-Aided Simulation Availability prediction using computer-aided simulation modeling may use either a stochastic simulation or a Markov model approach. Stochastic simulation modeling uses statistical distributions for the system's reliability, maintainability, and other maintenance and delay time parameters. These distributions are used as mathematical models for estimating individual failure and restoration times and can include failure effects and other operational conditions. A computer program generates random draws from these distributions to simulate when the system is up and down, maintains tables of failures, repairs, failure effects, etc., and tracks system or function capability over time. These data may then be used to calculate and output system operational availability estimates using equation (2). Stochastic Simulation Methods Discrete event stochastic simulation programs are recommended to perform operational availability predictions and analyses for large, repairable systems such as the space station or large ground systems and facilities. These methods simulate and monitor the availability status of defined systems or functions that are composed of a collection of Replaceable Units (RUs). The following process is generally used: Generate simulated future failure times for each designated RU based on predicted RU reliability distributions and parameters. Step through simulated operating time, and when failure events are encountered, evaluate the failure impact or function status given the specific failures encountered. Repair or replace the failed RU using a maintenance policy and procedure based on the availability of required maintenance resources, priority or criticality of the failure, or the current system or function status. Once an RU is repaired or replaced, the system or function status is reset appropriately, and a future failure time for the RU is again generated. Generation of simulated failures and maintenance actions for RUs requires as input the estimated RU time-to-failure distribution model parameters and factors that define the frequency of other scheduled or unscheduled maintenance. The maintenance actions can include equipment failures, preventive maintenance tasks, and environmentally or human-induced failures. To evaluate the effect of a simulated failure on the function's operational capability at a particular point in time, minimal cut sets of failure events that define the system or function failure conditions can be used. Minimal cut sets of failure events can be generated from reliability block diagrams or fault tree analysis of the functions, and then used during a simulation run to dynamically determine queuing priorities based upon functional criticality and the current level of remaining redundancy after the simulated failure occurs. Maintenance is simulated by allocating available maintenance resources and spare parts to the awaiting maintenance action (or waiting for resources to become available). Groups of maintenance actions may also be packaged into shifts of work. If the system under consideration is in a space environment, both external (extravehicular activity or EVA) or internal (intravehicular activity or IVA) can be considered. When the stochastic simulation method is used, each run of the simulation model (called an iteration) will yield a single value of the availability measure that depends on the chance component or unit failures and repairs that happened during that iteration. Therefore, many iterations are required to cover as many potential failure situations as possible, and to give the analyst a better understanding of the variation in the resulting availability as a function of the variations in the random failure and repair process. The number of iterations required for accurate availability measure results will depend on the iteration to iteration variation in the output measure. Experience has shown that in system availability simulations with a large iteration-o-iteration variation, 200 to 1000 iterations or more may be required to obtain a statistically accurate estimate of the average system availability. For example, the Reliability and Maintainability Assessment Tool (RMAT) is a stochastic computer-aided simulation method like that described that has been used at Johnson Space Center for assessing the maintainability and availability characteristics of the Space Station. The output of the RMAT includes the percent of total (or specified mission) time each defined space station function spends in a quotdownquot state as well as the percent of time each defined function is one failure away from functional outage (is zero failure tolerant). Using RMAT, analysts at JSC have been able to perform trade studies that quantify the differences between alternative Space Station configurations in terms of their respective operational availability and maintainability measure estimates. The same simulation methods (such as RMAT) that provide for operational availability measures will also provide maintenance resource usage measures such as maintenance manpower needs and spare part requirements. With this capability, JSC has been able to estimate the maintenance manpower needs, including EVA requirements, of various Space Station alternative configurations. Markov Model Approach A Markov process, or state-space analysis is a mathematical tool particularly well suited to computer simulation of the availability of complex systems when the necessary assumptions are valid. This analysis technique also is well adapted to use in conjunction with Fault Tree Analysis or Reliability Block Diagram Analysis (RBDA). Examples of the use of Markov process analysis may be found in Reference 1 or in such standard reliability textbooks as Reference 2. Failure to use availability predictions and analysis during the design process may lead to costly sub-optimization of the as-designed system reliability and maintainability characteristics. Where operations and support costs are a major portion of the life cycle costs, availability prediction and analysis are critical to understanding the impact of insufficiently defined maintenance resources (personnel, spare parts, test equipment, facilities, etc.), and maintenance concepts on overall system operational availability and mission success probabilities. These analyses can therefore greatly reduce the life cycle costs associated with deploying and supporting a space or ground system. References: MIL-HDBK-338; Electronic Reliability Design Handbook, Reliability Analysis Center, Rome, NY, 1989. O'Connor, P.D.T.; Practical Reliability Engineering, John Wiley & Sons Ltd., Chichester, 1991.","Lesson ID":841}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number DFE-4 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Benefit: Digital potentiometers are Dual Inline Package (DIP) devices capable of supporting variable resistance functions currently accomplished by standard electromechanical potentiometers. However, they can be equipped to handle a wide spectrum of specialty tasks not technically possible with standard devices. For example; remote process control, remote calibration, analog to digital conversions, digital to analog conversions, variable gain amplification and variable oscillation. Implementation Method: Digital potentiometers should be installed in electronic systems as a replacement for standard potentiometers. However, designs should be enhanced to utilize the digital potentiometers' extended functionality. Digital potentiometers are suitable in both facility power and battery driven applications. These devices should be appropriately selected to match system operating parameters and affixed to printed circuit cards as necessary. In contrast to standard potentiometers, digital potentiometers are remotely accessible and can be driven to specific resistance values directly via a 17 bit serial shift register. An application diagram is attached which illustrates a generic implementation methodology. [D] The digital potentiometer, although not an infinitely variable device, has either 64 or 256 resistive increments (based on model). In the event that finer control is necessary, digital potentiometers can be cascaded to provide high resolution trim functions. The digital potentiometers' architecture is designed to simulate that of a standard variable resistance device. Three pinpoints provide signal in, signal out and wiper. However, unlike discrete devices, wiper position can be incrementally changed or directly accessed through inputting desired position into the onboard register. Upon power loss, latest wiper position is saved in nonvolatile memory. As an added improvement over discrete devices, noise has been minimized such that signal to noise ratios are greater than or equal to 120db. Installation of digital potentiometers will provide accurate and reliable remote control of electronic hardware. Digital potentiometers will provide cost savings in the following key areas: Reduced equipment downtime (standard Potentiometers are prone to failures\/instability due to contamination). Reduced maintenance and calibration costs on equipment due to superior resistance to drift, remote configuration capability, and remote reporting not available in standard devices. Provides preventive maintenance function and reduces corrective maintenance costs as digital potentiometers do not typically require replacement and can be remotely monitored and configured. Additionally, performance of low level signal processing devices will be greatly enhanced due to superior signal\/noise ratios. References: quotDon't Touch That Dialquot; An Overview of Digital Potentiometers and Applications by Dallas Semiconductor Corporation.","Lesson ID":843}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number OPS-11 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Proper use of filters, prevents contaminated gas from interfacing with component and system operation, provides the following benefits: Decreased component failure caused by contamination. Efficient and effective means of servicing system\/equipment by filter cleaning or replacement. Increased system availability due to reduction in system maintenance. No matter how well a system is designed or how expensive, particulate-contaminated gas interferes with component and system operation. System gas must be conditioned; it must be decontaminated before it is allowed to enter a pneumatic system. The KSC design standard for pneumatic systems defines the following requirements for filters: Filters shall be installed immediately upstream of all interfaces where control of particulate matter is critical and at other appropriate points as required to control particulate migration. Selection of filters shall be made only after analysis of overall system performance requirements. This ensures maximum protection of critical components and minimal performance penalty (pressure drop). Filter housings and elements shall be constructed of 300 series stainless steel to reduce particulate contamination due to corrosion. Seal materials shall conform to manufacturer's recommendations and the requirements specified herein. The element construction should be welded instead of soldered whenever possible to simplify cleaning. Where 300 series stainless steel is specified, type 303 and other austenitic stainless steels should be avoided whenever possible because of susceptibility to stress corrosion cracking. However, overall cost should be the deciding factor. Filter elements shall maintain filtering quality and not be damaged in any way when subjected to worst-case system conditions (i.e., maximum design flow rate and element clogged to its maximum design capability). Providing unconditioned gas in a pneumatic system will have the following effects: Degraded system performance because of contamination. Increased maintenance cost and downtime to recover from problems induced by contamination. Decreased system availability. References KSC-SD-Z-0005A, Standard for Design of Pneumatic Ground Support Equipment. Parker-Hannifin Corp., Bulletin 0225-B1, Fluid Power.","Lesson ID":855}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number DFE-2 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Benefit: Effectively implementing Built-in-Test (BIT) techniques automatically reduces the number of BIT false alarms. Decreasing the number of BIT false alarms increases a system's availability and decreases the maintenance man-hours required. The overall result is a reduction of the system's life cycle cost. Implementation Method: To mitigate false alarms, a system's BIT circuitry must be able to cope with a limited amount of anomalous performance. NASA Handbook 5300.4 (1E) defines a false alarm as an indicated fault where no fault exists. Based on this definition, this technique is concerned only with BIT indications of system malfunction which cause unnecessary maintenance actions. The inability of a system to detect or report the occurrence of a failure, a fails to alarm condition, is not a false alarm and is not addressed. BIT should be designed to distinguish between actual failures and anomalies which must be tolerated due to adverse operating conditions or that are normal anomalies within acceptable limits. To accomplish this, the following principles and techniques must be mandated in the system specifications, requirement documents, and design policies and implemented in the system design. Voting Scheme One technique is called the Voting Scheme. With the voting scheme, all test data are analyzed by three or more different computers. A failure is declared only when a majority of the computers detect the same failure. An example of this type of architecture is the Space Shuttle Orbiter Avionics System. The five General Purpose Computers (GPCs) are all interconnected to the same 28 serial data channels. The GPCs perform all system-level processing and require a majority agreement on all test signals. This technique requires an extensive use of resources but is extremely effective at mitigating false alarms. A less complicated version of this is the use of double or triple redundant monitors. Having two or more sensors in series increases the reliability of the test data reported while only requiring a single computer or processor. Continuous Monitoring Continuous monitoring with BIT filtering can be used in place of the voting scheme. With this technique, BIT results are based on a integration of successive measurements of a signal over a period of time instead of a single check of the signal. The monitoring of the signal does not have to be continuous but only sampled over the time period. The filtering involves comparing the current reading of a signal with past and future readings of the same signal. This filtering allows for the disregarding of sporadic out-of-limit measurements. Only when a signal is out-of-limits for a predefined time limit or a sequence of tests identify the same failure, should the BIT flag be set. To maximize the effectiveness of continuous monitoring, the BIT data must be recorded. Once recorded, the data need to be summarized and evaluated so that trends can be tracked and weaknesses identified. Controls should be implemented to help manage all of this data. The number of signals monitored and the maximum sample rate can be limited. The time span over which data are collected should be set at a reasonable period, and the type of data accumulated should be restricted. Finally, computing techniques can be used that do not require the storage of old data. Once the information is gathered, a failure log should be created. This failure log is the basis for future modifications to the system's BIT. To improve the BIT, every instant of anomalous performance not related to an identified failure mode should be analyzed and the root causes identified. Some form of corrective action must be taken to avoid recurrence. If a design change cannot be made, then the BIT must be modified to accommodate the non-failure causing anomaly. The need for modification requires BIT to be flexible. Test parameters and limits must be easily changed. The operator should be able to control or even change the test sequence. This flexibility allows the necessary changes in the BIT to be made if false alarms start occurring. For example, the Space Station's Command and Data Handling System uses programmable Deadman Timers in the multiplexer\/demultiplexer (MDM's) and standard data processor (SDP's). The response intervals of the timers can be adjusted by the system controller to accommodate changes in system configuration or mode of operation. However, the BIT software must be changed without disturbing the system operation. For this to be possible, the BIT software must be independent of the operating software. Decentralized Architecture Another technique for mitigating false alarms is the use of a distributed or decentralized BIT architecture. With this approach the BIT is implemented so that a NO GO on a given test directly isolates the implied failure to a replaceable unit. Locating most of the BIT internal to a unit greatly reduces the possibility of incorrect isolation of a failure. Although the decentralized BIT concept consists primarily of unit level tests, some system level testing is still required. An excellent technology for combining unit level testing with system level testing is boundary scan. Boundary scan is the application of a partitioning scan ring at the boundary of integrated circuit (IC) designs to provide controllability and observability access via scan operations. In Figure 1, an IC is shown with an application logic section, related input and output, and a boundary scan path consisting of a series of boundary scan cells (BSC), one BSC per IC function pin. The BSCs are interconnected to form a scan path between the host IC's Test Data Input (TDI) pin and Test Data Output (TDO) pin, for serial access. [D] Figure 1. Integrated Circuit with Boundary Scan Paths During normal IC operation, input and output signals pass freely through each BSC, from the Normal Data Input (NDI) to the Normal Data Output (NDO). However, when the boundary test mode is entered, the IC's boundary is partitioned in such a way that test stimulus can be shifted in and applied from each BSC output (NDO). The test response can then be captured at each BSC input (NDI) and shifted out for inspection. Internal testing of the application logic is accomplished by applying test stimulus from the input BSCs and capturing test response at the output BSCs. External testing of wiring interconnects and neighboring ICs on a board assembly is accomplished by applying test stimulus from the output BSCs and capturing test response at the input BSCs. This application of a scan path at the boundary of IC designs provides an embedded testing capability that can overcome test access problems. The unit level tests can also be combined for a subsystem or system level verification (Figure 2). More details on applying these techniques are in IEEE Standards 1149.1 Boundary Scan and 1149.5 System and Maintenance Bus. [D] Figure 2: Typical Test Regimen for Space Systems Finally, high-reliability components should be used in the design. The reliability of the BIT hardware should at least equal or exceed that of the hardware it is testing. The BIT software also needs to be thoroughly tested and verified to ensure that it will not be a source of false alarms. Accordingly, adequate amounts of effort and resources must be allocated during the design phase. The designer should not be unduly limited by memory size, component count, or any other allocated resource. These guidelines are not all inclusive. The false alarm problem is very complex. Each system is unique and must be approached differently. The best approach is simply to eliminate each factor as it is identified. References: Coppola, Anthony, A Design Guide for Built-In-Test (BIT), RADC-TR-78-224, April 1979. Malcolm, John G., Highland, Richard W., Analysis of Built-In-Test False Alarm Conditions, RADC-TR-81-220, August 1981. NASA Handbook 5300.4 (1E), Maintainability Program Requirements for Space Systems, March 10, 1987. Texas Instruments Inc., TESTABILITY, Test and Emulation Primer, 1989.","Lesson ID":837}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number DFE-7 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Benefit: The main goal of fault detection and isolation is to effectively detect faults and accurately isolate them to a failed component in the shortest time possible. This capability leads to reduction in diagnostic time or downtime in general and, therefore, increased system availability. A good inherent diagnostic of a system also enhances the crewmembers' confidence in operating the system, the main driver of mission success. Effective FDIR can keep a difficult to maintain system up and running where normal methods would lead to system downtime. FDIR is especially beneficial to an on-orbit system where maintenance may be impossible. Implementation Method: The growth of electronic technology challenges the use of electronic systems in several respects. One of these is the complexity of testing the systems to determine functional status and to permit efficient fault detection and fault isolation. The term quotdiagnostic capabilitiesquot refers to the abilities of a system to detect a failure and to isolate it to a failed maintainable unit. In the past, diagnostics were considered only as a design afterthought and, as a result, many programs are faced with higher mean time to repair (MTTR) and higher work-hour and false alarm rates. This reduces system availability and operational readiness while increasing life cycle costs. Diagnostics are a significant key to achieving system performance and cost effectiveness goals. In such a critical system as the International Space Station, on which human life is dependent, a system recovery concept is also an important aspect that needs to be considered early in the system's design phase. This technique consists of sections on fault-detection, fault-isolation, and recovery techniques. Since they are all related under the integrated diagnostics concept, techniques of one section may be referenced in other sections. Fault-Detection Techniques A system fault can be detected manually or automatically, depending on operating modes and how quickly the system needs to be restored. For a system that requires human interfaces, system failures can be detected quickly by human visual and\/or auditory senses. If, for example, a light is switched on and there is no illumination, one can visually detect that there is a problem with either the light switch, light bulb, power source, or circuitry. The obvious advantages of manual fault detection are that it incurs no costs associated with complex system designs. Another common methodology, built-in testing (BIT), is employed to detect and isolate faults without using external test equipment. BIT ranges in complexity from a lamp that lights when equipment fails, to a resident computer that generates test signals and evaluates system responses. BIT can be continuously operated, interleaved with other operations, or initiated on command. During power-on self-testing, for example, the system runs a self-diagnostic test after the power is applied and includes hardware sensors and software error correcting codes. Its particular mechanization and utilization in a system are, of course, determined by the designer. BIT often means additional hardware above that required for the primary function. Reliability and cost are affected and tradeoffs leading to a balanced solution must be made. BIT protective circuitry, moreover, should be designed to be fail-safe. This means that failure in the BIT circuitry should not affect system performance. Whenever feasible, the BIT input and output should be sufficiently isolated from the normal channels so that any failure in the BIT will not cause impairment of the function being tested. Also, it should be recognized that BIT can fail, and additional measures should be taken to avoid utilization of possibly erroneous BIT output in recovery measures. In addition to BIT circuitry which actuates visual status indicators, BIT features may also include test points and self-test meters. The goal of BIT design is to decrease MTTR by steering a technician to the faulty component as quickly as possible. BIT designers attempt to attain this goal through various means, including the use of innovative circuitry and rearrangement of circuits to perform dual functions with a single circuit, if possible; e.g., driving a visual indicator and tying into various AND gates with a single driver. The BIT designer also standardizes BIT circuitry as much as possible, thus driving down the cost of implementing BIT. Other important general considerations in designing hardware BIT are: The reliability of the BIT hardware should exceed that of the hardware being tested. If this is not the case, the probability of failure of the BIT may be almost as great as the probability of failure of the unit being tested. The BIT should be kept simple but effective in meeting operational needs. The type of circuitry used for BIT should be, if feasible, of the same type used in the normal system to minimize the number of different types of components used in any particular system. As a part of the BIT design process, the overall system architecture must also be considered for the most effective implementation. Generally, there are two common approaches: centralization and decentralization. Centralization is regarded as a highly integrated approach in which a centralized unit acts as a quotwatch dogquot in detecting and reporting system out-of-tolerance conditions. The centralized unit determines if a failure actually occurred based on the data and information queried from the lower level, and annunciates or reports faults (see figure 1). [D] Figure 1. Centralized Architecture The type of information acquired by the central unit is an example of passive BIT. Passive BIT monitors system performance on line without the use of a test pattern generator; therefore, it may not be able to completely monitor the system. Active BIT, a more comprehensive type of testing, can also be used. In active BIT, a test pattern is written to a unit and compared to an expected pattern. The system operation must be interrupted for this type of test if the module is operating. Not all modules are operated continuously, however, and a computer-controlled BIT system can take advantage of times when a module is not needed to run a test sequence. This is referred to as interleaving BIT, which can be a powerful means for maintaining confidence in a system without disrupting its mission to run tests. On the other hand, decentralized architecture places detection capabilities at the maintainable unit level. Each maintainable unit has the means to detect all the identified failures within the unit. Once a failure occurs, the unit reports to a higher level for record and fault annunciation (see figure 2). Both passive and active BIT can be used in this case. [D] Figure 2. Decentralization With decentralized BIT, each module will have its own circuitry to monitor such out-of-tolerance conditions as voltage, current, or parity word at a particular node or memory location. Failure condition of a module can be notified to a central display unit via a data distribution network such as a 1553 bus network. One advantage of decentralized architecture is that a subsystem or a module can be taken off line for a comprehensive test using active BIT (generated test pattern). In general, the decentralized control must have the following characteristics: Self-test capability. Isolation from other system data. Some type of synchronization with system functions. A voting scheme is another effective technique to detect failure. With this technique, on-line data are processed by three or more redundant computers. A failure is declared when one unit's output is different from the other two or three units. Decentralized architecture is commonly used in this application. The inertial measurement system on the Orbiter exemplifies this type of architecture, in that three redundant inertial measurement units process real-time data and compare the outputs for majority agreement. This method requires additional resources but is highly effective in fault detection. Fault-Isolation Technique Once a failure is detected, the next step is to locate the cause of that failure. The complexity of a system, quick-turn around time demand, repair location, and human skill level are some important factors which must be considered in planning the fault isolation strategy of a system. Faults can be isolated manually by visually inspecting for burned-out components or by using an external test set for system diagnostics. For a more complex system and time-critical mission, the faults can also be isolated automatically. BIT, as mentioned in the fault-detection section, contains an inherent fault-isolation mechanism, since signals generated by a failed module can be identified by the control unit, thereby allowing a test pattern to be injected to that particular unit to confirm its failure. Sometimes BIT can isolate failures down to a certain system level or to a region of a system that has components connected in a series. In this situation, it is rather difficult to determine exactly which component has actually failed. In contrast, voting scheme will accurately pinpoint the failed unit, because the redundant connections of the system dictate the ease of fault isolation. However, in situations where the remaining two units indicate a fault has occurred, a failed unit will not be easily identified because there is no quotmajorityquot reference data for comparison. A more recent approach to isolating a failure in the integrated circuit (IC) industry is called the boundary scan. The IC is divided into regions which are accessible via scan operations. A boundary scan path consists of a series of boundary scan cells (BSC's), one BSC per IC function pin. The BSC's are interconnected with the host IC's test data input pin and test data output pin, for serial access. During normal IC operation, input and output signals pass through each BSC without interference. When the boundary test mode is selected, however, the test stimulus is applied through a series of BSC's, and test results are captured at the end of the scan path. This technique overcomes the test access problems that can cause difficulty in fault isolation. The unit level tests can also be combined for a system-level verification. Recovery Technique In order for a system to recover manually or automatically from a failure, modes of operation which depend on types of failures must be defined and planned ahead. During the design phase, the system's critical functions, levels of redundancy, and functional paths are usually identified so its recovery functions can be realized. In general, there are three categories of recovery: (a) 100 percent functional recovery using redundant system components, (b) functional recovery using an alternative path, and (c) degraded functional recovery. For category (a), the system is designed so that when a component fails, its failure is reported and the component's redundant or backup unit can be turned on manually or automatically. In such systems as satellites, interplanetary probes, and the Space Station, which require autonomous operations, automatic recovery is likely to be provided. Resources are almost always limited in any situation; therefore, instead of having a redundant string or unit, an alternative path, category (b), may be taken to recover the lost function. The alternative path usually does not achieve the full capabilities of the original function because of limiting space and design constraints, including costs. For reasons stated above, many redundant critical functions of the Space Station have been designed using the method of functional recovery. If, for example, the cooling loop of the thermal control system failed and was unable to cool the electronics equipment mounted on the cold plates, cool air from the environmental control and life support system may be redirected in order to keep the equipment from overheating. The equipment may also be required to operate at a minimal level to lessen the heat generated. As a worst case, redundant strings are out or not available; in which case, operating a system at some minimal capacity must be considered to protect crews or vehicles. In these cases, the critical functions of a system must be looked at to decide which of its components or units may be turned off without losing the ability to control the spacecraft until repairs are made. If, for example, some of the solar array panels were damaged, insufficient electrical power would be generated to support all the Space Station functions. In this case, power allotted to less critical functions would have to be curtailed or eliminated and even critical systems may have to be operated at some compromised level. Summary FDIR is becoming an increasingly important factor in designing today's complicated systems and in today's competitive edges for operating an efficient plant or space system with minimal downtime. In any business, downtime or delays may cost millions of dollars a year in addition to operating costs, simply because FDIR was a design afterthought. By implementing FDIR's design features, one can be assured that the final product will be a safe, efficient, and maintainable system. References: Air Force Design Handbook 1-9, quotMaintainability (for Ground Electronic Systems),quot Second Edition, Revision 7, February 25, 1988, United States Air Force Aeronautical Systems Division. Architecture Design Document (ADD) D684-10504, quotFailure Detection, Isolation, and Recovery (FDIR),quot February 22, 1994, International Space Station Alpha Program, National Aeronautics and Space Administration. Anthony Coppola, quotA Design Guide for Built-In Test (BIT),quot April 1979, Rome Air Development Center, Air Force Systems Command.","Lesson ID":839}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number DFE-3 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Benefit: This practice reduces the amount of time spent during maintenance by reducing the number of locations to access for grease lubrication. This practice will also eliminate the need to access difficult to reach locations and make maintenance safer by eliminating the need to access hazardous locations. Implementation Method: Required maintenance time is reduced by use of junction boxes and hardlines to lubricate bearing surfaces on mechanical equipment. This practice is most beneficial on large mechanical systems such as bridge cranes. Overhead bridge cranes require periodic lubrication of pivot bearings, wheel bearings, shafts, and other bearing surfaces. This servicing requires the maintenance technician to access a large number of locations on the equipment. The junction boxes are used to create locations from which many bearing surfaces can be lubricated at the same time. This reduces the number of locations that maintenance personnel must access. The junction boxes are machined metal blocks with internal passageways for the grease or oil. There are two banks of hardline connection points along the bottom of the block. The blocks are available in various sizes allowing 2-12 hardlines to be connected. Each hardline that connects to the junction box is coupled to an internal chamber with a double acting piston. A pin indicator on top of each piston controls the volume (.012 - .072 cu. in.) of lubricant delivered and provides positive indication of discharge to each bank. There is a lever at one end of the block which directs the flow of grease from the grease fitting to one of the two banks of hardlines. With the lever in the vertical position, the maintenance technician applies grease through a grease fitting (Figure A). This directs lubricant to the top of the double acting piston in each chamber driving them downward thereby forcing lubricant under each piston to be discharged into the bank one hardlines. This continues until all of the pin indicators are fully retracted. This indicates that the proper volume of lubricant has been applied to each hardline in bank one and bank two and is ready for discharge. [D] Figure A [D] Figure B Rotary Valve Handle Rotary Valve Measuring Pistons Bank 2 Discharge Lines Indicator Stems Bank 1 Discharge Lines Volume Discharge Adjustment Screws The technician then rotates the lever and again applies grease through the grease fitting (Figure B). This applies lubricant under the piston in each chamber driving them upward. Lubricant is forced into each bank two hardline and the chamber is replenished to service bank one. When all the pin indicators are fully extended, the proper volume of grease has been applied to each hardline in bank two. The lever is then returned to the original position, ready for the next lubrication cycle. The primary benefit of this practice is minimizing maintenance time (20 - 40%) by consolidating a large number of locations requiring maintenance action into only a few. This practice further reduces maintenance time by placing the lubrication junction boxes on easy to access locations such as personnel walkways. Placing the lubrication junction boxes on personnel walkways will also reduce safety hazards during maintenance. Some locations requiring lubrication may not only be difficult to access but may be hazardous, requiring special safety equipment such as safety harnesses and temporary work platforms. Special access requirements can be reduced or eliminated by the implementation of the practice.","Lesson ID":842}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number AT-7 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Benefit: Proper maintenance and testing of electrical circuit breakers will enhance system\/equipment performance, reliability, and overall availability. Cost savings are realized through testing of circuit breakers prior to or during installation by eliminating damage to other equipment\/components caused by defective circuit breakers. Testing will also alert maintenance and logistics to examine existing inventories for other defective circuit breakers. Proper maintenance of circuit breakers will enhance circuit breaker life expectancy as well as the system\/equipment it supports. Downtime for unscheduled maintenance is also minimized through proper maintenance and testing of circuit breakers. Implementation Method: In developing a maintenance practice for circuit breakers one should first identify what type of circuit breakers are used (examples; molded-case, draw-out, high-voltage, etc.). Once the circuit breaker types are identified, one can start to identify the criterion for circuit breaker inspection, test, and maintenance. There are many sources of information available to assist one in defining this criterion (example: Federal & Military Specifications\/Standards, Air Force Manuals\/Regulations, American National Standards Institute (ANSI), National Electrical Manufacturers' Association (NEMA), etc.). The practice should address safety. Safety should be a prime consideration to all concerned in the planning, scheduling, and accomplishment of the work. Supervisors should brief all personnel, prior to the start of each operation, concerning the hazards that may be encountered and the appropriate safety practices to be observed. Supervisors should ensure that only properly trained and qualified personnel participate and that all personnel are equipped with the tools and equipment necessary to do the job safety. Specific safety hazards that may be encountered while working with circuit breakers should be identified. For example; electric shock and secondary injuries caused by contact with energized circuits or devices that are electrostatically charged after removal of test potential. Also physical damage resulting from short circuits, insulation failures, or faulty equipment. Identification of safety equipment that is required when working on circuit breakers should be provided. This equipment may consist of nonmetallic hardhats with chin straps, safety goggles, rubber gloves, sleeves, blankets\/mats as required, area barricades and signs. Safety precautions that personnel should be aware of should be identified. For example; turn off power, look out, and disconnect sources of electrical energy before working on equipment. Use of insulated hand tools designed for specific work. Use of protective equipment such as safety approved rubber-insulated gloves with protectors, insulating blankets\/mats, and non-metallic hardhats. Wear safety eye protection glasses if there is a possibility of arcing or sparking. Ensure that non-current carrying metallic parts of equipment are grounded. Inspect visually or conduct tests to determine the adequacy of grounds. The following is extracted from KSC GP-1002 and illustrates how that practice addressed one of the types of circuit breakers found at KSC. Molded-Case Circuit Breakers Application. Molded-case circuit breakers are used to interrupt fault currents, to provide overload protection, and to switch the electrical circuit. Construction. Molded-case circuit breakers contain two elements: a switch consisting of a set of contacts with suitable mechanical linkage to operate the contacts; and a trip unit which is an overload and fault sensing device. Operation. When the thermal or magnetic trip senses an overload condition in the electrical circuits, a spring-loaded latch is tripped. The released spring mechanism rapidly opens the breaker contacts and de-energizes the faulted circuit. Most molded-case circuit breakers are equipped with a thermal element composed of a bimetallic strip to provide a time delay and establish the tripping characteristics. The instantaneous-trip device is magnetic. High current flow through the breaker picks up the armature of the magnetic trip device. Movement of the armature releases the latch and opens the breaker contacts. Some breakers are available with an adjustable instantaneous trip. The pickup of this trip may be changed in the field from approximately 5 to 10 times the continuous rating of the breaker. Breakers labeled quotnon-automatic' have no trip unit and are used as load interrupting switches only. Maintenance. (1) Preventive Maintenance. Circuit breakers shall be exercised at intervals recommended in Table 1. If the circuit breaker is equipped with a trip indicator, exercise it to verify that it also operates properly. During routine maintenance, check molded-case circuit breakers for improper terminal connection at the time of installation, distorted plug-in tabs or sockets, poorly cleaned or corroded conductors, improper conductors for the lugs in use, and loose terminations. All of the above are fault conditions which may cause heating and deterioration of the circuit breaker and its response characteristics. [D] Table 1. Recommended Maintenance\/Test Intervals for Molded-Case Circuit Breakers Note: The above are minimum recommended maintenance\/test intervals. Additional tests may be made when the operating agency has experience to indicate need for concern. If overheating of connections is evident through discoloration or arcing, the breaker should be removed from service and all conducting surfaces cleaned. The breaker should then pass operations tests and the installation megger test before reinstallation. Those breakers with adjustable instantaneous magnetic trip devices should be set at the highest setting unless otherwise directed. (2) Corrective Maintenance. Perform corrective maintenance on molded-case circuit breakers after fault conditions occur. Follow the procedures given in paragraph 4.(1) and perform the tests required in Table 1 (see paragraph 5). If a molded-case circuit breaker interrupts a fault current whose magnitude is equal to its interrupting rating, the breaker may not be operable. Tests. (1) Insulation Megger Tests. Perform insulation megger tests at the intervals indicated in Table 1 and the following instructions. De-energize and, if necessary, remove the breaker from the panel for test. Do not place the megger on large masses of iron nor near strong magnetic fields. Set the megger scale range selector switch in a position that gives a reading in midscale or above. Observe megger readings after a minimum of one minute or when the pointer has reached an apparent stabilized value; record the readings. After completion of the test, apply temporary grounds to all test materials and disconnect all leads. This procedure tests one phase to ground with all other phases grounded and is equivalent to a phase-to-phase test besides the phase-to-ground test. Each phase must be tested individually. Table 2 provides voltage values for insulation megger tests. If a megger reading of 1 megohm minimum is not obtained for each voltage value replace the circuit breaker. [D] Table 2. Voltage Values for Insulation Megger Tests-Molded-Case Circuit Breakers (2) Operations Tests. Perform operations tests at the intervals suggested in Table 1 and with the following instructions. These tests include overcurrent testing for both time-delay and instantaneous trip. Molded-case circuit breakers use two basic methods, sometimes combined, to achieve overload protection: thermallic strip and electromagnetic. Check the circuit breaker manufacturer's instruction book to determine the type of overload device, the method of adjustment, and the proper breaker connections. Use a low-voltage high-current source such as Multi-Amp Model MSA for small breakers of ratings up to 100A and Multi-AMP Model CB-225 for larger breakers. Consult the Multi-Amp Tester instruction book to set up tester controls. De-energize and remove the breaker from the panel for test. Record all data obtained by these tests. Individually test each pole that is equipped with an overload device. Operate (open and close) the breaker two or three times before applying the overcurrent. Connect the Multi-Amp tester across one pole of the breaker with the breaker closed. If the overload protective device of the breaker under test is the thermal bimetallic strip type, allow sufficient time for the heater element to cool to near ambient temperature before starting a second test. No waiting period between tests is necessary for the electromagnetic type of overload protective device. (3) Time Current Trip Test. If the breaker is electrically operated, connect temporary power to the breaker control circuits. Check for proper voltage and if alternating or direct current. The tests currents provided in Table 3 should be used. If the breaker being tested is not listed in Table 3, the test currents should be approximately 3 times the normal trip rating of the breaker. Perform the time current trip test in accordance with Multi-Amp instructions. Observe and record the time shown on the timer as the operating time of the breaker at that percent of rated overload. Compare this test time with times given in Table 3. If the operating time of the breaker does not agree with the curve or Table 3, replace the breaker. If the breaker is not listed in Table 3, check the manufacturer's time current curves for the appropriate trip time. [D] [D] [D] [D] [D] [D] [D] [D] Table 3. Trip Characteristics for Molded-Case Circuit Breaker (4) Instantaneous Trip Test. Connect the breakers to the Multi-Amp tester and select the proper ammeter range (about 10 times the normal trip current rating of the test breaker). Do not rotate the main control while large currents are flowing. Alternately increase the output current and jog the tester until the breaker trips or until the maximum test current is reached. If the breaker does not trip at the desired current value, replace the breaker. The above is only an example of one type of circuit breaker. The criteria should address all circuit breakers that an organization supports. References: Kennedy Space Center (KSC) General Practice (GP) 1002, quotMaintenance and Test Criteria for Circuit Breakers.quot","Lesson ID":848}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number AT-6 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Benefit: Ferrography provides early detection of abnormal wear of the lubricated critical internal components of mechanical systems. Analyzes the debris in system lubricants. Shows particle size, shape and color as well as quantity. Reveals which system component is wearing, and to what degree, and pinpoints the cause of the wear. Implementation Method: Ferrography is a very useful and comprehensive analysis for trending and reporting. At a minimum, the user can obtain an analytical means of monitoring the wear condition; and, at the same time, accrue the necessary sample points required to establish a wear particle concentration baseline and retain the presence of non-magnetic particles for visual inspection and evaluation. The advantage of Ferrography over other preventive maintenance systems is its capacity to detect a broader range of types and sizes (0.1-500 microns) of wear particles. A micron is one millionth of a meter. Ferrographic analysis encompasses wear (metallic and non-metallic), contaminant (crystals, water, and organic and inorganic compounds), and lubricant (friction polymers) monitoring. Typical wear problems identified by Ferrography; gear teeth wear through excessive load or speed, misalignments, fractures, rolling contact failure, water in the oil or poor lubricant condition, oil additive depletion, outside contaminants such as sand or dust, cam shaft and cylinder wall failure, oil filter failure. There are many others. Industrial application of Ferrography entails the non-interruptive machine condition monitoring of heavily used lubricated mechanical systems. Hence, an operational baseline can easily be established by sampling every 50-500 hours of operation (approximately every one to three months, depending on system criticality), and used for quantitative trending analysis. Any anomalies in the wear particle concentration, especially in the generation rate of large particles (>20 microns), is symptomatic of the onset of failure. For consistent results and accurate trending, lubricant samples are taken from the same places in the system each time. The method of sample extraction assures that the lubricant samples contain a representative selection of wear particles. The samples are then ferrographically analyzed both quantitatively and qualitatively. The Direct Reading Ferrograph (DRIII) classifies metallic wear particles as either large (>20 microns) or small (<20 microns) and calculates the large to small wear concentration. These values are entered into the personal computer based Ferrotrend database, which compiles the data points for wear trending analysis. This process determines the existence of a malfunctioning component in the system. The Dual Ferrograph Analyzer prepares the ferrogram (slide) for analysis through the Ferroscope IV Microscope. The qualitative analysis is documented in the Ferrogram Analysis Report Sheet which documents the severity concentration of specific normal and abnormal wear particles. The ferromagnetic particles are sorted by gravity according to relative size, with larger particles appearing at the leading entry of the ferrogram. Non-magnetic particles (including contaminants and friction polymers) are distributed throughout the ferrogram. This process indicates the presence of contaminants, the condition of the lubricant, and the material composition of the abnormal wear particles being generated, from which the source of the wear may be deduced. Ferrography is just one of the methods used at KSC. Ferrographic, viscosity, total acid number and vibration analysis are cooperative elements of the predictive maintenance program. [D] References: GSE Health Trend Analysis - RT-ENG-2\/ 90-218 P\/PM Technology - March\/April - 1991 Standard Oil Engineered Materials -Technical Bulletin 101 Predictive Maintenance Engineering Lab, USA\/KSC.","Lesson ID":846}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number AT-10 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Benefit: Timely detection and elimination of air\/fluid leaks, electrical shorts, and bearing wear will result in substantial cost savings in equipment operation and maintenance. Examples: Elimination of air\/fluid leaks would produce savings in power consumption, and equipment wear and tear. Detection and elimination of conditions causing arcing in electrical systems would result in increased system availability and repair time associated with downtime and damage that would have resulted from electrical shorts. Implementation Method: Ultrasounds, by definition, are beyond the limits of normal human hearing, an operator using a sophisticated detector translates ultrasound signals to the range of human hearing. Ultrasound detection is the number of times a sound wave cycles from trough to crest. This is expressed in cycles per second and measured in hertz. One kilohertz is 1000 cycles per second. The best human ears can generally hear noises in the range of 20 to about 20,000 Hz (20 kHz). Many ultrasound detectors start at approximately 20 kHz and can work upward to sounds as high as 100 kHz. Operators using the ultrasound instrument can tune to and quothearquot what is going on in operating machinery (figure 1). [D] Figure 1. Use of Ultrasound Gun to Detect Leaks in Pipe Flanges Fluid and gas systems and other working machinery have constant ultrasound patterns. When a leak occurs, fluid passing through an opening produces turbulence with strong ultrasound frequencies. Changes in the quotsound signaturesquot can readily be recognized as wear in components. An ultrasound detector senses subtle shifts in the signature of a component and pinpoints potential sources of failure before they cause costly damage. The longer wavelengths of lower-pitched sounds easily penetrate solid; yet they slip through minute openings. Ultrasound detectors are used for isolating such leaks. Operators use lightweight, battery-powered pistol-shaped instruments which can easily be moved from machine to machine. The instrument circuitry translates the high-pitched ultrasounds to those in the human hearing range. Some instruments feature a frequency-adjust dial to provide tuning capability, enabling operators to hear the ultrasounds through headphones and determine their intensity by the definitions registered on an analog meter. The instrument is used to establish sound patterns, which compared at a later date become useful in locating and diagnosing bearing failure, vacuum and pressure leaks, valve blowby and faulty electrical circuits. References: Plant Engineering, June 18, 1987. Maintenance Technology, January 1994 P\/PM Technology, March\/April 1991. P\/PM Technology, Reprint 1986-1988. Predictive Engineering, LSOC\/KSC.May 3, 1996.","Lesson ID":847}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number AT-2 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Benefit: The Mean Time To Repair (MTTR) predictions can be used to highlight those areas of a system that exhibit poor maintainability in order to justify improvement, modification, or a change of design. They also permit the user to make an early assessment of whether the system predicted downtime and logistic requirements are adequate and consistent with the system operational requirements and allocations. Implementation Method: In general, the MTTR of a system is an estimated average elapsed time required to perform corrective maintenance, which consists of fault isolation and correction. For analysis purposes, fault correction is divided into disassembly, interchange, re-assembly, alignment and checkout tasks. The repair time of a maintainable unit generally consists of both a large number of relatively short-time repair periods and a small number of long-time repair periods. The former would correspond to the more usual case where the failed unit is replaced by a spare at the operational site on detection of a failure. The long downtimes would occur when diagnosis is difficult or removing a defective part is complicated due to, for instance, rusted\/stripped mounted nuts. Having a collection of such field data provides the design engineer an opportunity to assess the Mean Time To Repair (MTTR) of the current system as it matures, or to predict the MTTR of a new system according to its features with the current system. MTTR is a useful parameter that should be used early in planning and designing stages of a system. The parameter is used in assessing the accessibility\/locations of system components; for example, a component that often fails should be located where it can easily be removed and replaced. The estimated MTTR may also dictate changes in system designs in order to meet the turn-around time criteria for critical systems, such as communication and life support systems on the Space Station. In addition, the parameter helps in calculating the life cycle cost of a system, which includes cost of the average time technicians spend on a repair task, or how much Extravehicular Activity (EVA) time is required for astronauts to repair a system. MTTR is defined as the average time necessary to troubleshoot, remove, repair, and replace a failed system component. An interval estimator for MTTR can be developed from the mean of the sample data, within a lower and a upper limit with a confidence bound. For example, from a sample data set, one can find with 90-percent confidence that the range 3.2 to 4.2 will contain the population mean. Unfortunately, the exact MTTR of a system can never be found due to data uncertainties. Log-Normal Distribution The distribution most commonly used to describe the actual frequencies of occurrence of system repair time is the log normal because it reflects short duration repair-time, a large number of observations closely grouped about some modal value, and long repair-time data points. The general shape of log normal distribution is shown in Figure 1. [D] Figure 1: Lognormal Distribution Without getting involved in the derivation of the distribution equations which can be found in any statistical textbook, the following example will illustrate how MTTR of a replaceable unit may be calculated from a finite observed set of data. Example 1: The repair times ti for an orbital replaceable unit (ORU) are observed to be 1.3, 1.5, 1.7, 1.8, 2.2, 2.6, 3.0, 3.1, and 3.9 hours. Using log normal distribution to estimate the MTTR of the unit. Solution: [D] Utilizing statistical methods, the Maximum Likelihood Estimator (MLE), or the best estimated value of the mean is: [D] The Maximum Likelihood Estimator of the variance is: [D] Therefore, the mean of the log normal distribution of this example is: [D] and its variability of time to repair is: [D] How to Implement the MTTR Process Accurately estimating the MTTR of a new system is more than applying the derived formulas on field data of any existing systems. The designer must know the overall maintenance concept and operating conditions of the new system; for example, how and where the system is going to be operated and how its failed units will be swapped out. With this background, the designer can proceed to approximate the maintenance procedure of the new system, then select an existing system that has been exposed to similar operating conditions and that has a mature set of operating data. After the similarity between the two systems is assessed, the designer then can determine certain conversion factors needed to make the existing system data more applicable to the new system. Once this is done, the predictions for the new system are more meaningful and accurate. Elements of MTTR The MTTR prediction of a system begins at the replaceable unit level (RUL) where a defective unit is removed and replaced in order to restore the system to its original condition. Then the system MTTR predictions are accomplished by integrating the MTTR's of maintainable units. The following defines the elements used in the MTTR prediction of a system: Fault Isolation: Time associated with those tasks required to isolate the fault to the item. Disassembly: Time associated with gaining access to the replaceable item or items identified during the fault correction process. Interchange: Time associated with the removal and replacement of a faulty replaceable item or suspected faulty item. Reassembly: Time associated with closing up the equipment after interchange is performed. Alignment: Time associated with aligning the system or replaceable item after a fault has been corrected. Checkout: Time associated with the verification that a fault has been corrected and the system is operational. Constant failure rates: The rate of failures that result from strictly random or chance causes. This type of failure occurs predominantly in the useful life period of a unit. K factor: For on-orbit tasks, a conversion factor may be applied to convert elemental task times performed in 1-g environment to Micro-gravity environment. The conversion factor may be derived from data of past similar programs or from the neutral buoyancy testing. Ground Rules and Assumptions In the prediction, certain ground rules and assumptions apply: Mean Time To Repair (MTTR) does not include the maintenance overhead, which is generally non-related task time such as time to fill out a requisition, time to go get tools, break-time, time waiting for parts, etc. Worksite time is the only variable considered. All equipment experiences a constant failure rate. All tasks are performed sequentially by one crew member unless otherwise noted. Maintenance is performed in accordance with established maintenance procedures and appropriately trained personnel. The prediction depends upon the use of recorded reliability and maintainability data and experience that have been obtained from comparable systems and components under similar conditions of use and operation. System Level Prediction At the system level, MTTR is calculated by summing the product of the replaceable items' MTTR's and their corresponding failure rates; the result is then divided into the sum of all replaceable items' failure rates. Mathematically, it can be expressed as: [D] As an example, assume the three ORUs of a system have the following MTTR'S, Variance (V), and failure rates L: [D] Table 1: ORU \/ MTTR Apply the above formula to calculate the system MTTR: The results of the above example indicate that the most often failed unit will essentially drive the MTTR and variance of a system. [D] Overall, the prediction is a straight forward process and is useful in estimating a system's MTTR. Even with a limited set of data, if the prediction is used early in the design phase, the derived value should help in shaping a preliminary design guideline for the system. In addition, the prediction can also verify logistics and maintainability requirements at some later stage. References: Lamarre, B. G., Mathematical Modeling, Reliability and Maintainability of Electronic Systems, Edited by: J.E. Arsenault and J.A. Roberts, Computer Science Press, p372 - 373. Miller, Irwin, Probability and Statistics for Engineers, Prentice Hall Inc., Englewood Cliffs, p116. MIL-HDBK-338-1A, Electronic Reliability Design Handbook, Department of Defense.","Lesson ID":840}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number DFE-5 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Benefit: Easy and ready identification of piping systems contents. Such identification can aid in: Reduced time in researching a particular system location that is to be modified. Knowing the system that is to be modified, visual identification of that system eliminates a large amount of research time reviewing the pipe location drawings. Safely traversing an area knowing which systems can be dangerous to physical contact. Examples of such systems are high temperature steam lines, low temperature LOX and LH2 lines. Tracing systems in search of leaks or in search of a shutoff valve to stop a leak. Locating a fire box in case of fire (all fire lines are painted red). Each example has beneficial aspects from saving time to saving lives and equipment. Implementation Method: This practice establishes, defines, and assigns a color for recognition to each of six classes of material. Five classes represent universally recognized types of hazards involved in the handling of dangerous gases\/liquids. A sixth is assigned for exclusive use of fire protection for materials and equipment. The practice requires the application of color warnings in a distinctive manner, as a visual aid and supplement to written identification. Further details can be found in KSC-STD-SF-0004B. This practice is not applicable to electrical conduits, ventilation units, or pipelines installed in missiles, spacecraft airborne equipment, or storage vessels. Identification methods for bulk petroleum product system is covered in MIL-STD-161. The identification of pipelines for aircraft, missiles, and space vehicles is covered in MIL-STD-1247, and color coding for containers of liquid propellants is covered in MIL-STD-172. Piping systems are described as any pipe line used to transport gases, liquids or semiliquids, but not those for carrying solids in gas or air. Valves, fittings, operating accessories, pipe coverings and tie-in points at storage facilities are considered piping systems. Piping identification is broken down into 4 types of markings on the outside of the pipe. The primary set of markings identifies the content which is shown by a color band taped around the pipe. All contents are broken down into 8 colors. The colors used conform to requirements identified in Federal Standard No. 595, Colors and are: Yellow, No. 13655 - Flammable Materials known ordinarily as flammables or combustibles. Brown, No. 10080 - Toxic and Poisonous Materials. All materials extremely hazardous to life or health under normal conditions as toxics or poisons. Blue, No. 15102 - Anesthetics and Harmful Materials. All materials productive of anesthetic vapors and all liquid chemicals and compounds hazardous to life and property but not normally productive of dangerous quantities of fumes or vapors. Green, No. 14110 - Oxidizing Materials which readily furnish oxygen for combustion and fire producers which react explosively or with the evolution of heat in contact with many other materials. Gray, No. 16187 - Physically Dangerous Materials. All materials, not dangerous in themselves, which are asphyxiating in confined areas or which are generally handled in a dangerous physical state of pressure or temperature. Red, No. 11105 - Fire Protection Materials. All materials provided in piping systems or in compressed gas cylinders exclusively for use in fire protection. Black, No. 17038 and White, No. 17875. These colors are assigned for general use where specified in KSC-STD-SF-0004B, Safety Standard for Ground Piping Systems Color Coding and Identification except as follows. Water Piping Systems containing water suitable for human consumption and installed for this purpose shall be painted white, No. 17875 throughout or shall be painted to match surroundings when not in conflict with color designations in referenced standard. The second set of markings is shown as the color used in the flow arrow which is taped to the outside of the pipe. The secondary color marking is used to identify a second characteristic associated with the content. If a second characteristic does not exist, the flow arrow is black and white. The flow arrow indicates the direction of flow, if the content can flow in either direction a double headed arrow is shown. The third set of markings is the title. The title identifies the contents by name or recognized abbreviations. The titles may be taped, glued or stenciled onto the sides of the pipe. The fourth set is the pressure rating which is shown by a numerical number taped on the outside of the pipe. The pressure will be given immediately below the title using the same sizes and color. Piping systems may not need a pressure rating shown if it is below 60 psig. [D] Figure 1. Piping Systems, Color Warnings References: KSC-STD-SF-0004B MIL-STD-161 MIL-STD-1247 MIL-STD-172 FED-STD-595","Lesson ID":844}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number AT-8 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Benefit: Vibration analysis allows the maximum interval between repairs to be realized through monitoring the actual mechanical condition of a piece of rotating machinery. Equipment down time is not required for monitoring activities to occur. The monitoring, in turn, directly minimizes the number and cost of unscheduled machine outages created by component failures. Hence, optimum equipment availability may be obtained. Implementation Method: Vibration Analysis is predicated on two basic facts: All common failure modes have distinct vibration frequency components that can be isolated and identified. The amplitude of each distinct vibration component will remain constant unless there is a change in the operating dynamics of the machinery. Monitoring the vibration from machinery can provide a direct correlation between the mechanical condition and recorded vibration data of each machine. Vibration analysis can be used to identify specific degrading machine components or failure modes of machinery before serious damage occurs. Typically, 80% of the machinery problems experienced can often be classified as either imbalance or misalignment. Imbalance and misalignment can lead to premature bearing, coupling, shaft seal, and gear wear. Most of the problems can be rectified by simply improving maintenance standards and procedures and by eliminating careless or sloppy work. Also, imbalance and misalignment do not only occur in established equipment over a period of time, they can be present after initial installation of a new piece of machinery. Vibration analysis can be used to validate that the new equipment has been properly installed. This would prevent the introduction of failure causes which would have a detrimental effect on the life of the equipment and the process which the equipment supports. Recent advancements in microprocessor technology and the development of PC based software have simplified data acquisition, automated data management, and minimized the need to have professional vibration consultants available to interpret the data. Commercially available systems are capable of routinely monitoring, trending, evaluating, and reporting the mechanical condition of all mechanical equipment. Vibration analysis was started in 1988 by the Shuttle Processing Contractor (SPC) in an effort to reduce the high failure rates experienced by the rotating machinery associated with Environmental Control System (ECS) located in the Orbiter Processing Facility (OPF) at the Kennedy Space Center (KSC). The vibration analysis program initially monitored 66 pieces of equipment associated with the ECS and the Orbiter Portable Purge Units used at the OPF and the two launch pads of Launch Complex 39. The information gathered was used to effectively reduce the failure rate and down time of the ECS equipment. Because of the success achieved with the ECS equipment, the SPC expanded the vibration analysis program to include all other Space Shuttle Program ground system equipment for which it had maintenance responsibility at KSC. The equipment considered was machine-train components. Machine-train components consist of a primary driver or drivers (i.e., electric motor, turbine), all intermediate drives (i.e., couplings, belts, gear box), and all driven machine components (i.e., fans, pumps, drums). All the SPC equipment was assessed. A list of equipment that would lend itself to vibration analysis was created. Due to the number of items identified, the SPC categorized the equipment into a priority listing of equipment that would be of benefit to the Space Shuttle Program. Once the equipment to be monitored was identified, a process was established to routinely obtain vibration data from specific locations on the equipment. Preparation for data collection involved determining what type of data equipment was necessary, what type of data to collect, where to take the measurements (i.e., shaft, bearing, housing, mount, coupling, gears, or fan), how many degrees of freedom for each component were to be measured (i.e., x-axis, y-axis, z-axis, radial), and should the measurement devices be of a permanent or temporary type attachment. All of the data is collected via a portable handheld microprocessor-based instrument. This removes the potential for human error, reduces manpower requirements, and automates the acquisition of vibration data. Due to the massive amount of data that is collected, a reliable PC based automated data management system was selected that enables the vibration data to be stored, trended, and recalled for use in developing long-term trends. It is important to note that the bearings in a machine-train are the primary limiting factor for operating life. The first indication of machinery problems often develops in the vibration signature of the machine's bearings. However, the bearings are typically not the cause of the problem. But since they are the weakest link in most machinery, the bearings are usually the first to fail. Vibration checks at points other than the bearings are also taken to check for structural problems. Experience has proven that on new or refurbished equipment, vibration data should be collected once a week for four consecutive weeks. This will enable a trend to be established for future comparison. The frequency of monitoring a piece of equipment after establishing an initial baseline is based on the following considerations: The machine's operating modes (i.e., intermittent or continuous speeds\/loads). The machine's operating environment. The importance of the machine's function. Data derived from comparison of the initial baseline. Availability of spare parts. To regularly acquire enough data for complete diagnosis of a machine's potential failure would be \"overkill\" and unduly burden the data collection process. The periodic collection of vibration data on a prescribed route for trending purposes should be treated as a tool to indicate pending problems. Industry standards are utilized to determine a problem condition unless specific pieces of equipment dictate more stringent or lax alarm limits. Once a possible problem is identified, more data is collected from the equipment in order to aid the vibration analyst in determining the exact cause of the anomaly. In order to resolve the anomaly in an efficient manner, \"if\" and \"what type\" of information is needed. The questions asked are: What is the problem? What is the machine's history? What has the operator observed? When did the problem start? Was it sudden or gradual? Did the machine ever run properly? Have any changes been made recently? Modifications? Realignments? Changes in machine speed? Other NASA centers utilize vibration analysis for their own purposes as shown by Reference 4. References: Lockheed Space Operations Company Predictive Engineering Technology Program Implementation Plan. Mobley, R. Keith: \"An Introduction to Predictive Maintenance,\" Van Nostrand Reinhold, 1990. P\/PM Technology, Volume 5, Issue 3 -May\/ June 1992. \"Absolute Ball Bearing Wear Measurements From SSME Turbopump Dynamic Signals,\" by J. M. Hine. Proceedings of the 59th Shock and Vibration Symposium, Volume III, pp. 45- 55, October 1988.","Lesson ID":845}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number OPS-12 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. This practice reduces the amount of time spent during troubleshooting and maintenance of ground support and facility equipment by: Centralizing test point locations for electrical circuits. Clearly labeling wire\/terminals for ease of locating a particular circuit. Making spare wires available for wire replacement or system modifications. Fault Isolation is simplified by utilizing terminal blocks in the circuitry of ground support and facility equipment. The terminal blocks are used to modularize the equipments circuits at locations that are convenient to personnel access. Examples of convenient locations are control panels and junction boxes. Each wire at the terminal blocks is labeled clearly. The label is the wire number listed on the electrical schematic. Clear, meaningful labels and a centralized location will reduce the time required for maintenance personnel to locate and identify circuits necessary to troubleshoot. The centralized location makes component isolation easier. Only a screwdriver is usually required to disconnect wires during troubleshooting. Consideration must be given to the design of the terminal block. The screw terminals should be recessed into the block or separated by non-conductive dividers so that tools and probes cannot create a short across adjacent terminals during troubleshooting or accidental contact. Consideration must also be given to wiring layout. Signal wiring should be separated from power and control wiring to reduce the chance of electrical interference. Any high voltage wiring should be separated and a cover placed over the terminal block to reduce the danger to personnel. If required, covers should be placed over all terminal blocks if there is a concern regarding debris and foreign objects causing electrical short circuits. Other benefits are realized from this practice. Control panels and junction boxes are located in areas that are safe for personnel access, reducing the need to expose personnel to dangerous conditions. Spare wires between control cabinets and junction boxes are included in the original design. The spare wires can be used to replace existing wires if they are damaged or to add new components during system modifications. A systematic approach to wiring is necessary to implement this practice which reduces wiring errors at startup.","Lesson ID":870}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number AT-1 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Benefit: Neutral buoyancy simulation can provide valuable information for designing-in accessibility, modularity, simplicity, and standardization. It can also provide cost-effective, specific design information on the effectiveness of crew stability aids, crew maneuvering aids, specialized tools, and operational timelines. Maintainability criteria that can be established by utilizing this process include: component accessibility; fasteners accessibility, systems installation; and the configuration and operation of crew stability aids and tools. Implementation Method: The neutral buoyancy facility at MSFC has been used since 1968 to effectively simulate the weightlessness of space, and has assisted in the establishment of maintainability design criteria, particularly in extravehicular activity (EVA). Use of full-scale neutral buoyancy simulations has also allowed for direct human participation in test operations, as well as for access to the large body mock-up hardware developed for EVA simulations. These methods are a very effective way of simulating on-orbit environments for the purpose of verifying and solidifying operations and maintenance procedures. Other neutral buoyancy facilities used for NASA hardware development and test and crew training are the Weightless Environment Test Facility (WETF) at Johnson Space Center, the Neutral Buoyancy Research Facility at the University of Maryland, College Park, Maryland and the neutral buoyancy facility at McDonnell Douglas, Huntington Beach, California. Neutral Buoyancy Characteristics The MSFC neutral buoyancy facility has the following overall characteristics: Six-console control room. Three-person, double-lock hyperbaric chamber. Floating crane for underwater movement of hardware (one 2000-pound hoist, one 500- pound hoist). Removable roof section to accommodate large hardware. T.V. monitors, communications with test subjects, audio\/video taping capability, pressure and depth displays of test subjects, and lightning warning systems. Support of up to four Shuttle space suited crew members. Umbilical-supplied underwater primary life support systems. Operational Remote Manipulator Systems (RMS). Air-lock for emergency test subject evacuation. The neutral buoyancy tank within the facility is a 1.3 million-gallon water tank that measures 40 ft. deep and 75 ft. in diameter. The water temperature is maintained at a range of 88 to 92 degrees Fahrenheit and a pH of 7.50. Cathodic protection systems are used to inhibit corrosion. The tank accommodates up to four pressure-suited test subjects simultaneously. Extravehicular Mobility Units are available for four test subjects. The tank can accommodate test durations of up to 6 hours. HST Simulations Underwater simulations in the neutral buoyancy facility strongly influenced the maintainability design criteria for the Hubble Space Telescope (HST) and its components; particularly with regard to visibility, accessibility, and simplicity. One of the primary considerations in maintainability of space hardware is the accessibility of components and systems by crew members during EVA. To be maintained in space, the components of a hardware item must be seen and reached by a pressure-suited astronaut or be within range of the appropriate tools. Altogether, some 70 Orbital Replacement Units (ORUs) on the HST can be replaced on-orbit. Some of the largest ORUs are batteries, computers, reaction wheel assemblies, science instruments, fine guidance sensors, and wide field planetary cameras. One of the telephone-booth-sized science experiments weighs over 700 pounds. These items are mounted in equipment bays around the perimeter of the spacecraft. The bays open with large doors so components can be readily inspected and handled. Using neutral buoyancy simulations, design features of these components were validated, verified, and refined to ensure that the ORU features of modularity, accessibility, and simplicity were inherent in the design. Other features included a series of crew stability aids; including handrails, portable handles, tether attachments, and foot restraints. Neutral buoyancy simulation studies also determined the placement of foot restraints on both the HST and the RMS arm for maximum accessibility. These design features give the crew mobility and stability during unstowing, transporting, and stowing ORUs. Door latch design criteria were also addressed in neutral buoyancy simulations involving the HST. All internally stowed ORUs except the Radial Science Instrument are concealed by doors that must be opened and closed by a crew member before ORUs are installed or removed. Simulations and Design Influence A design criterion that has become increasingly important in on-orbit maintenance and which has been studied using neutral buoyancy simulation is standardization of the EVA interface to ORUs. The practice of standardization became a key issue in HST development with the decision to mount ORUs with 7\/16-inch double height hex head bolts in three types of fittings: J-hooks, captive fasteners, and keyhole fasteners. Neutral buoyancy simulations have proven that the use of standardized bolt heads, clearances, and torque limits reduces the complexity of ORU maintenance in space. To achieve electrical connector standardization, neutral buoyancy simulation studies have evaluated such criteria as connector geometry (wing-tab presence, length, and diameter) and surface texture (knurls, ridges, and irregular shapes). Response variables studied included ease of alignment, firmness of grip, and level of torque required to lock the connectors. Studies of this type led to the development of a standard for blind-mate, scoop-proof, low-and force, and subminiature connectors. If accepted as a standard, these connectors would be used in the Upper Atmosphere Research Satellite, Explorer Platform, International Space Station, and in robotic manipulators. Human factors studies have been a significant part of neutral buoyancy simulation tests with large space structures. For example, experiments have been conducted to determine the effect of fatigue on productivity during lengthy EVA structural assembly operations. An experienced test subject assembled a 36 element tetrahedral truss structure repeatedly for 4 hours, while the subject's heart rate and general conditions were monitored. These neutral buoyancy simulations demonstrated EVA productivity to be significantly higher in space than in comparable conditions simulated in ground tests. Assembly time for structural assembly tasks was approximately 20 percent less in actual flight. The Experimental Assembly of Structures in EVA (EASE) project, an experiment flown on Space Shuttle mission STS 61-B, revealed that a flexible structure can be assembled in underwater conditions with a learning curve of 78 percent. It was determined that learning rate is independent of the strength, coordination, or size of the test subject; or the fit of the pressure suit. Structural configurations have been used at the MSFC neutral buoyancy simulator to obtain human factors data. In one experiment, six-element tetrahedrons were used to obtain data on learning and on the relative value of a variety of assembly aids. The structural elements in these tetrahedrons were 11-foot-long tubes of PVC plastic, 4 inches in diameter. Sleeve-locking connectors were used to join the beams at the nodes of the structure, or \"joint cluster.\" Much more complex structures were used to collect information on fatigue, and on crew members' ability to deal with complicated configurations and hardware. A single 36-element tetrahedral truss served as a baseline structure for comparing single-person assembly with two-person assembly, for quantifying productivity changes due to the use of various assembly aids, and for evaluating other structural configurations. Results of structural assembly experiments have shown that test subject learning rate is much higher in the weightless conditions of neutral buoyancy than in conditions on dry land. The most time-consuming task during assembly operations is aligning the beams. This large time consumption is due to the kinematics of water drag. Fatigue is not a significant factor in the assembly process if the subjects pace themselves. None the less, the following considerations must be taken when running a simulation to avoid problems: Assign two safety divers per test subject to manage the umbilical and monitor the test subjects performance. When possible, conduct paper computer simulations, and one-g dry run simulations prior to neutral buoyancy simulations. Principal Limitations The principal limitations of neutral buoyancy simulations include: (1) the need to design hardware to accommodate the effects of water corrosion, (2) varying water pressure with depth, and (3) frictional resistance of the water to body and equipment movement. The impact of not taking full advantage of the neutral buoyancy simulation capabilities at MSFC and other locations could mean entering a space mission without full knowledge of the effects of weightlessness on mission tasks, particularly in EVA's. Maximum emphasis should be placed on conducting simulations with the highest fidelity possible to ensure mission success. Failure to do so results in a greater probability of incurring safety hazards, anomalies, increased maintenance resources (man-hours), and hardware damage. References: Akin, David L. and Howard, Russell D.: Neutral Buoyancy Simulation for Space Telerobotics Operations, In SPIE, Cooperative Intelligence Robotics in Space, Vol. II, pp. 414-420, 1991. Akin, David L. and Bowden, Mary L.: \"EVA Capabilities for the Assembly of Large Space Structures,\" IAF-82-393, Massachusetts Institute of Technology, October 1, 1982. Akin, David L.: A Design Methodology for Neutral Buoyancy Simulation of Space Operations, 88-4628-CP, Massachusetts Institute of Technology, September 1988. Barnby, Mary E. and Griffin, Thomas J.: Neutral Buoyancy Methodology for Studying Satellite Servicing EVA Crewmember Interfaces, Proceedings of the Human Factors Society 33rd Annual Meeting, pp. 149-153, 1989. Designing an Observatory for Maintenance in Orbit: The Hubble Space Telescope Experience, NASA\/MSFC, April 1987. EIA Standard for Connector, Electrical, Rectangular, Blind-Mate, Scoop-Proof, Low-Force, Subminiature, AN\/SI\/EIA S-XXX-1991 (draft), American National Standards Institute, Inc., November 18, 1991. Griffin, B.N.: Zero-G Simulation Verifies EVA Servicing of Space Station Modules, AIAA-86-2312, AIAA, Space Station in the Twenty-First Century, Reno, Nevada, September 3-5, 1986. Neutral Buoyancy Simulator Test and Checkout Procedures for NBS Test Operations, NBS-TCP-90, NASA\/MSFC, April 17, 1992. Sanders, Fred G.: Space Telescope Neutral Buoyancy Simulations - The First Two Years, NASA-TM-82485, NASA\/MSFC, June 1982. The Design and Development of the Hubble Space Telescope Neutral Buoyancy Trainer, Final Report for Contract NAS8-35318, Essex Corporation, December 31, 1990. Lessons Learned Document from Neutral Buoyancy Simulation Testing Activities, MDC H34111, McDonnell Douglas Astronautics Company, Huntington Beach, CA, October 1987. Sexton, J.D.: Report for Neutral Buoyancy Simulations of Transfer Orbit Stage Contingency Extravehicular Activities, NASA-TM-103583, NASA\/MSFC, June 1992. Sexton, J.D.: Test Report for Neutral Buoyancy Simulations of Hubble Space Telescope Maintenance and Refurbishment Operations: Simulations of HST Maintenance and Refurbishment Mission and New Block II ORU Access Study, NASA\/MSFC, May 1989.","Lesson ID":833}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PD-ED-1272, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Benefit: There have been many requests by the Space Shuttle Payload customers for a practice which describes all the hazards associated with the use of batteries in and on manned space flight vehicles. This practice is prepared for designers of battery-operated equipment so that designs can accommodate these hazard controls. This practice describes the process that a design engineer should consider in order to verify control of hazards to personnel and the equipment. Hazards to ground personnel who must handle battery-operated equipment are considered, as well as hazards to space crew and vehicles. Implementation Method: The purpose of this practice is primarily to cover battery safety, not performance. Inquiries are frequently received from payload customers as to a listing of batteries quotapprovedquotfor use onboard the Space Shuttle. There is no such list. Any battery which can be made safe to fly in the manned spacecraft environments can be used. There are some kinds of batteries however, that are not practical to make safe for in-cabin use. For example, a battery with large amounts of free electrolyte presents huge problems in a zero quotgquot environment when trying to prevent electrolyte escape. Another example is lithium-sulfur dioxide cells, which have built-in overpressure relief which releases SO2 and other electrolyte components whenever internal cell pressure is high enough. Batteries that contain these chararacteristics are unacceptable in the close environment of the Orbiter cabin. The following is a listing of the types of cells which have already flown in the Orbiter (cabin or payload bay). These include: (1) silver oxide-zinc primary (one shot) and secondary (rechargeable); (2) nickel-cadmium secondary; (3) nickel-hydrogen secondary; (4) nickel-metal hydride, (5) alkaline-manganese primary; (6) LeClanche (carbon-zinc) primary; (7) zinc-air primary; (8) lead-acid secondary pressure relieved cells or cells having immobilized electrolyte; (9) mercuric oxide-zinc primary and (10) lithium primary cells having the following cathodic (positive) active materials consisting of: (a) Thionyl chloride; (b) Thionyl chloride with bromine chloride complexing additive (Li-BCX); (c) Sulfur dioxide; (external to habitable area); (d) Polycarbon monofluoride; (e) Manganese dioxide; (f) Iodine; and (g) Silver chromate. It must be noted that lithium-based cells are subject to extremely close review and are required to have seemingly excessive hazard controls incorporated in their usage. They can yield extremely high energies per unit weight and volume relative to other cell types. They have uniquely hazardous failure modes. For many types of lithium batteries, there is little comprehensive data which characterizes either performance or response to abusive or off-nominal exposure. The chemicals contained in them are usually either highly flammable, corrosive and\/or toxic. In their various failure modes, they are subject to leakage, venting, or violent explosions accompanied by scattered shrapnel and toxic materials. Hence, no effort is spared in providing the utmost assurance that every known or suspected failure mode is prevented by effective hazard controls. Use of other types of cells is strongly encouraged wherever feasible. Weight and volume differences alone are not necessarily sufficient justification for use of lithium based cells. Use of batteries of any chemistry, including those listed above, may require extensive testing, evaluation and use of source controls. Certification prior to flight is always required. Many of the hazard controls associated with the batteries, enhance performance reliability, since the battery is designed to prevent hazards which are the result of failures. For example, the prevention of electrolyte leakage and grounding in a battery case which may cause a battery explosion also prevents aborted battery operation. The content of this practice is not intended to consider every conceivable contingency. There is no attempt herein to provide knowledge on the theory and electrochemistry of batteries, except as necessary to dictate a hazard or its control. General Battery Hazards Sources and Controls Battery hazards can generally be broken into seven categories. These are: (1) short circuits; (2) electrolyte leakage; (3) battery gases; (4) high temperature exposure; (5) circulating currents; (6) structural; and (7) charging. Practice No. 1. Flight batteries should not be subjected to short circuits. Rationale. Shorts can occur in the loads served by the battery through conductive electrolyte leaks between cells within a battery or by careless contact with cell and battery terminals. Internal shorts in cells of batteries which have been prepared for flight by effective procedures are rare. A sustained short can result in extremely high temperature increases. Table I shows effects of shorting relatively benign alkaline-manganese cells and batteries through about 30 milliohms. Peak currents are reached in less than one second. [D] Table 1: Effects of Shorting Through 30 Milliohms High temperatures can result in surfaces which burn crewmen (118 degrees F is the specification limit for touchable surfaces), meltdown of protective plastic structure surrounding the battery, release of noxious or explosive substances (hydrogen for example) or initiation of a fire. In addition to heating, a short circuit through an electrolyte leak can decompose water in the electrolyte to hydrogen and oxygen, then provide the minuscule ignition energy (1-2 micro joules) to explode the hydrogen-oxygen mixture when the short circuit current terminates with a small arc at last contact. This type of failure is considered to have caused a momentary LM descent battery short circuit during the cis-lunar leg of the aborted Apollo 13 mission. Some obvious hazard controls had been omitted to save weight because such an event was considered unlikely. Apollo 14 and later LM batteries incorporated the controls. Special Considerations Batteries must have circuit interrupters which are physically and electrically close to the battery terminals and are rated well below the battery's short circuit current capability. Interrupters may be fuses, circuit breakers, thermal switches or any other effective device. The interrupter should be in the ground leg of batteries with metal cases so that battery grounds inside the battery case (usually grounded to structure) may be sensed and interrupted. All inner surfaces of metal battery cases must be coated with an insulating paint known to be resistant to the battery electrolyte. This procedure aids in preventing battery grounds to the case through electrolyte leakage. Cell terminals must also be protected from contact with other conductive surfaces by potting or by non-conductive barrier (e.g., plastic sheets). The parts of battery terminals extending inside the battery case must be insulated from unintentional contact with other conductors and bridging by electrolyte leaks. The battery terminals which pass through metal battery cases must be insulated from the case by an insulating collar or other effective means. The parts of battery terminals on the outside of the battery case must be positively protected from accidental bridging. This may be accomplished by using female connector, recessing stud-type terminals, installation of effective insulating barriers, etc. Wire lengths inside the battery case must be insulated, restrained from contact with the cell terminals and physically constrained from movement due to vibration or bumping. Practice No. 2. Preventive measures must be implemented to prevent electrolyte leakage. Rationale. Electrolyte leakage can be caused by excessive free electrolyte in vented (pressure relieved) cells. Inadequate design of electrolyte trapping or baffling provisions under covers of vented cells or leakage through cracked cell containers is a major cause for electrolyte leakage. Another cause for electrolyte leakage is faulty seals on sealed cells, and leakage of electrolyte forced through seals by cells overheating or over discharging. Special Considerations Excessive free electrolyte in vented cells should be corrected by performing cell tests in which the quantity of free electrolyte is reduced until the cell capacity begins to be reduced. These tests must be conducted on cells whose age and cycle-life exposure is nearly identical to that proposed for flight cells. This type of test applies mainly to silver oxide-zinc rectangular cells. The cell manufacturer generally specifies a slight excess of electrolyte be used because his cells are generally recharged several times by most customers. With increasing cycles for use, the excess free electrolyte is generally depleted by both water electrolysis and absorption in gradually expanding zinc negative. Cells used in space applications are generally used on their first to fifth cycle and do not require excess free electrolyte. Cell covers can also be designed to have a cylindrical quotstand-pipequot extend downward from the underside of the cell cover toward the cell plates, from the cell vent opening in the cover. When the cell is inverted in a gravity environment, the electrolyte level collecting on the inside of the cell cover is optimized not to rise above the opening of the quotstand-pipequot. This represents the worst case. All other cell positions, including the zero quotgquot are better. Cells having free electrolyte, must be fitted with relief values in their vent ports, not just an opening and\/or absorbent material. Relief valve opening pressures having a range from 3 to 35 psid and are a function of the ability of the cell case to withstand internal pressure without cracking. Some steel-case rectangular NiCd cells are considered quotsealedquot because they use relief valves set to open at 100 to 200 psid. These are not the hermetically sealed, space-type NiCd cells which may also be used. If inputs are feasible at the cell design level, micro porous teflon plugs or sheets may be installed on the vent opening on the underside of the cell cover. Such material, if not covered over the electrolyte, will permit gas to escape but will prevent electrolyte escape due to its small pores and non-wetting property. If it is not possible to use the above controls, absorbent material, such as non-woven polypropylene or cotton wadding, should be used to fill the void spaces in a battery container or is placed directly over the cell vents. This is a less satisfactory control since electrolyte may be trapped against conductive parts by the absorbent material which may also be flammable. Internal surfaces of metal battery cases must be coated with an electrolyte resistant paint as well. The required prelaunch stowage of batteries in any space vehicle, has to be oriented in an quotuprightquot position relative to gravity so that any free electrolyte is forced by earth gravity and the launch acceleration into the cell plates and separators and away from the cells seals or vents. This configuration decreases the chance of an in-flight leakage from occurring. If electrolyte is added at the initial design level of vented cells having free electrolyte, extension of the separator material beyond the cell electrolyte is required. This extension provides additional volume for capillary capture of the electrolyte, which then may require acceleration forces larger than 1g for dislodgment. In-flight maneuvers nearly always provide significantly less g's of force. Practice No. 3. Flight batteries utilizing aqueous-based electrolytes should not be stored in enclosed spaces. Rationale. Hydrogen gas, mixed with air or oxygen is flammable or explosive over a wide range of concentrations (e.g., 3.8 percent to 94 percent in air). Accumulation of hydrogen in enclosed spaces containing oxygen must always be prevented. Aqueous electrolyte cells subjected to charging, will generate oxygen as the charge nears completion, thus providing oxygen where none may have existed before (due to nitrogen purging). Whenever a flammable\/explosive mixture of hydrogen and oxygen exist, an ignition source is presumed to exist although one may not be obviously identifiable. This condition can occur because energy required for ignition is on the order of 1 or 2 micro joules.Special Considerations The traditional means of avoiding hydrogen accumulation is to provide continuous air ventilation at a rate sufficient to continuously dilute evolved hydrogen below the 3.8 percent flammability level. For example, a lead-acid or silver oxide-zinc battery on over-charge is considered to evolve hydrogen at the rate expressed by the following equation: Q = 0.016 NI Where: Q = cu. ft. H2\/hr. at 1 atm. and 77 deg F N = no. of cells in battery I = charging current in amperes Thus, a battery of 20 cells on charge at 3 amps evolves: Q = .016 x 20 x 3 = 0.96 cfh H 2 To dilute the hydrogen to about 2 percent concentration in the ventilating air, the air flow must be: 0.96 \/ .02 = 48 cfh The value Q may be corrected for temperature and pressure by multiplying it by the value: K = { 1.415(T+460) } \/ P Where: P = actual pressure in mm Hg T = actual temperature in degrees F In practice, it is rarely feasible to ventilate hydrogen in normal Orbiter battery applications. Hence one or more of the following controls must be exercised whether or not charging is performed on board the Orbiter. Avoid charging the battery in the habitable spaces of the Orbiter. Do not seal battery cases or provide low pressure relief valves (3 to 15 psid) on the case. Minimize the volume of void spaces inside the battery case by design or by adding electrolyte-resistant, non-flammable filler such as potting material. Prohibit any component inside the battery case which may provide an ignition source, such as arching between relay contacts. Purge the battery completely with dry nitrogen (or any other inert gas) as soon as the battery is installed in the Orbiter. Minimize the exposure of the battery to high temperatures. Practice No. 4. Do not expose flight batteries to high temperatures. Rationale. High temperatures is construed to mean temperatures higher than 120 degrees F. Some batteries can safely and successfully operate at temperatures well above 120 degrees F. Some cells, notably silver oxide-zinc, are subject to thermal runaway. At high temperatures, silver oxide decomposes, yielding oxygen. The release of oxygen oxidizes zinc in the negative plates, resulting in heat evolution and an increase in cell temperatures which increases the silver oxide decomposition rate. This is different from the mechanism of thermal runaway which can occur during constant potential charging of NiCd cells. Special Considerations Perform a thermal analysis on the battery and its surroundings to verify probable battery temperatures under load and non-load conditions. This practice is particularly necessary for high energy, high power batteries that are installed with equipment stowed in the Orbiter payload bays. Do not operate cells at loads above those set as maximum by the battery manufacturers. Provide adequate short circuit protection (See practice no.1, Short Circuits). If the thermal analysis conducted on the battery shows that it will become cold enough to require heat inputs, electrical heaters must have redundant thermostatic over temperature controls. If the thermal analysis shows that any combination of internal and external heating may result in over temperature, the following precautions must be considered: Provision for heat sinking, heat shunts or active cooling. Provisions for barriers from insulation or other convective, radiative or conductive heat sources. Provisions for thermally actuated circuit breakers to interrupt the load current near hazardous temperatures. Thermally optimized on-board location (move battery to cooler location). Practice No. 5. Batteries should be protected from circulating currents. Rationale. Circulating currents are unintended current flow, generally between cells or cell stacks connected in parallel. They can also occur between standby batteries and the prime power they support, or through electrolyte leakage paths between cells. They result in parasitic discharging and\/or unintended charging of cells in the circulating current loop. Circulating currents between parallel-connected cells stacks can result from lowered voltage in one or more stacks due to cell degradation, followed by current flow from adjacent electrically sound stacks due to the resulting difference in stack potentials. Hazards associated with currents circulating through electrolyte leakage paths are described under practice no. 2, Electrolyte Leakage. The hazard due to current flow between parallel stacks of cells or between a standby battery and a prime power source, results from unintended charge and\/or discharge. In adequate electrolyte batteries, charging can result in water electrolysis with consequent hydrogen generation (See practice no. 3, Enclosed Spaces) charging of lithium primary batteries is hazardous and is covered under charge prevention. Unregulated discharging can result in overheating of the hazard which are covered under practice number 4, High Temperatures. Special Considerations Circulating currents between parallel cells or cell stacks must be prevented by a blocking diode in the parallel legs. Small, conservatively current-rated Schottky barrier rectifiers have been used for this purpose to minimize voltage drops. Another alternative is to use larger capacity cells instead of many smaller cells in parallel. In the case of secondary batteries, severe charging current distribution problems can arise with parallel cell strings, requiring special charge current controls. Currents circulating from a prime power source to its back-up battery, must also be prevented with a blocking diode. Depending on the circuit power requirements, redundant controls such as a high resistance or a fuse in series with the battery may be installed. Another option is to put a relay in series with the battery which is held open by the prime power source. Practice No. 6. Flight batteries should not be subjected to mechanical, chemical and thermal stresses which reduce the integrity or functional capability of the cell cases and the battery case. Rationale. Breakage of mounting provisions, permits unconstrained movement of the batteries. Breakage of cell cases, permits uncontrolled release of electrolyte and gases within the battery case. Breakage or other failures of the battery case seals, can also permit the release of the electrolyte and gases to the enclosed battery environment. Fractures of the internal current-carrying members, can also result in arching and explosions. Special Considerations Battery cases are often made of lightweight materials such as aluminum alloy, magnesium alloy, plastics, etc. In such instances, a materials compatibility and stress analysis should be made to ensure maintenance of the cell and the battery case material strength and function after exposure to the electrolyte, potting materials and their solvents or to any material to which the battery may be exposed. Battery cases should not be sealed (in the hermetical sense) but rather should have relief valves or low pressure venting provisions installed. If a design is made which results in a gas-tight seal in spite of this constraint, the case must then meet the requirements of Paragraph 208.4 of NHB 1700.7A, quotSafety Policy and Requirements for Payloads Using the Space Transportation System,quot regarding pressure vessel safety. If the battery case closure contains provisions for low pressure venting and is otherwise sealed, it must meet the requirements of paragraph 208.7 of NHB 1700.7A, regarding sealed containers. Silver oxide-zinc cells swell in the direction normal to the plane of their plates (electrodes). Zinc-air button cells swell axially; e.g., a Duracell 1200HP cell will lengthen axially about 0.015 inches during discharge. Battery development testing must include determinations of such dimensional changes. Battery case structural design must provide the strength to withstand or negate the stresses that are encountered. If it is known that significantly low or high temperatures will be experienced by the battery, whether from external or internal sources, consideration must be given to the effects of the differential thermal expansion and contraction between dissimilar materials; e.g., plastic cell cases and metal battery cases. Plastic cell cases must not be quotpinnedquot to a metal battery case by cement, hard potting or mechanical means. Resilient filler may also be required to absorb dimensional changes due to large temperature changes. Verify the vibration resistance of the battery assembly to the vibration spectrum listed below by conducting battery certification tests or by analysis. [D] Table 2: quotFreq vs Rangequot Vibration should be for fifteen minutes in each of the three axes of the assembly. Verify shock resistance of the battery assembly to shock inputs of the below test by certification test or analysis. Subject the assembly to test in accordance with MIL-STD-810, Method 516.4. Apply a sawtooth shock pulse, 20g peak, 11+ l millisecond rise and 1+ millisecond decay, once in each direction along each of the three orthogonal axes, for a total of 6 shock pulses. This procedure is from the obsolete MIL-STD-810C. Practice No. 7. Prevent overcharging of flight batteries to preclude excessive build up of heat and\/or explosive gas mixtures or expulsion of electrolyte fluids. Rationale. The charging referred to in this practice is that which may be applied on secondary batteries used in the Orbiter while in flight or awaiting launch on the pad. This condition rarely exists at the Cape due to the inaccessibility of the batteries or lack of necessity to charge. If a charge is required, most of the charges are trickle charges to quottop-offquot losses due to self discharge on the pad. Special Considerations Use a battery design which does not require freshening or quottrickle chargesquot. This is equivalent to saying do not use nickel-cadmium cells, since they have poor charged shelf-life. Nearly any other kind of cell has adequate shelf-life for shuttle missions. However, it may be necessary to use nickel-cadmium cells in applications requiring high power and low energy. Note that sealed nickel-cadmium cells on overcharge at or less than the manufactureri\u0301s recommended current and voltage are capable of recombining the generated oxygen within the cell. Therefore they will not vent any gas under these conditions nor experience significant internal pressure rise. Ground service or onboard chargers must be designed with all the performance precision and reliability of other space equipment. The voltage and current controls must follow output requirements determined during development testing or specified by the battery manufacturer to prevent excessive overcharging. Temperature adjustments of voltage and current may have to be included in the charger as well. Lithium-ion batteries require special consideration for charging, since charge control must be implemented on the individual cells. Vented or pressure-relieved batteries requiring-charging while in or on the shuttle on the launch pad should be mounted upright (tops of cells up, relative to the earthi\u0301s gravity) so that any evolved gas is less likely to entrain the electrolyte. Charging instructions must include a safety warning which bans the presence of any ignition source (smoking, welding, hammering, electrical relays or switches opening and closing, etc.) near batteries undergoing charge. If battery cells are truly hermetically sealed, as in the case of certain nickel-cadmium rectangular-cell satellite batteries, gas evolution presents no problem if charge voltage and current controls are adequately implemented. Charging instructions and instrumentation must provide for a ground check between the battery terminals (disconnected from external circuitry) and the battery case after charging. Minimum resistance should be greater than 1 megohm. Where equipment batteries must be charged in flight, this procedure must be addressed in the equipment safety analysis report.","Lesson ID":826}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PD-ED-1273, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Benefit: Quantitative reliability requirements provide specific design goals and criteria for assuring that the system will meet the intended durability and life. Early in the design process, the system developer will be required to consider how the design will provide the requisite reliability characteristics and must provide analyses to verify that the delivered hardware will meet the requirements. Assessment of the early design's ability to meet quantitative reliability requirements will support design trades, component selection, and maintainability design, and help assure that appropriate material strengths are used as well as the appropriate levels and types of redundancy. Implementation Method: The missions and scientific objectives of the subject space system are used to define quantitative reliability goals and objectives. In general, the quantitative reliability goals and objectives are stated as requisite probabilities of achieving specific missions or scientific objectives under stated operating conditions and environments. The probability values specified as being required are established through a process of trading off a desire for very high value against the cost and design constraints of achieving that value. The specified level will also determine an accepted level of risk or likelihood that the mission objective will not be met. Very often, the acceptable level may be negotiated between the science community or user, the contractor, and the various responsible NASA organizations. The use of quantitative performance-based reliability requirements does not supersede or negate the need for specifying fault tolerance or other classical reliability requirements. Fault tolerance requirements and reliability design criteria should also be levied to ensure the proper separation of redundancy, and the avoidance of failure propagation. Quantitative requirements are levied to ensure that the operational performance and missions can be met with an accepted probability level or likelihood. Table 1 shows examples of several different types of quantitative reliability requirements that can be levied on a space hardware program. The importance of using both types of requirements lies in the need to ensure that the system design is as robust as necessary and that it meets the verifiable performance goal. These types of requirements, if utilized correctly, will work hand in hand to provide the contractor direction on developing a more reliable product. The quantitative requirements are levied to ensure that operational needs can be met based on pre-set conditions. [D] Table 1: Examples of Quantitative Reliability Requirements A quantitative reliability requirement by definition means that the reliability is expressed in a measurable quantity. Performance-based reliability requirements are generally stated in terms of the probability of properly performing a mission phase or objective without a failure (or sequence of failures) that will terminate the mission phase. An example is the International Space Station reliability requirement in SSP 41000, quotSystem Specification for the International Space Station (ISS).quot The reliability requirement in SSP 41000 states that the Space Station shall provide an operational capability to provide a microgravity environment for 50 percent of the internal payload locations for at least 180 days per year in continuous periods of no less than 30 days with a reliability of 0.80 or better. This requirement holds the ISS prime contractor responsible for providing a vehicle design that will operate continuously for 30 days without suffering a system failure that would exceed the conditions necessary for microgravity science, and do so at least 4 out of 5 of the periods. The system reliability, given its associated components and redundancy configuration, can be measured against that quantitative requirement. Also, during design reviews, consideration must be given to reliability assessments of the design because of such requirements, thus heightening the awareness of program risks that may otherwise go uncovered. Other requirement statements might relate to the launch phase of a space system or simply to the normal operation phase. However, the specific elements of the requirement statement include the description of the desired performance, usually a direct or indirect reference to the amount of time involved, and the probability value needed. The mission\/objective specified in a reliability requirement may deal with a major portion of the entire mission or may be a very specific portion of the mission. For instance, a reliability requirement may be specified for the ability to maintain attitude or perform a significant mission event. The specification values used for the reliability requirement depends on the criticality of the mission or objective and the consequences of failure. In the Space Station case, loss of the microgravity capability is not inherently catastrophic, and a repair capability is available. Four successful 30-day periods out of five was considered to be reasonably achievable, and was deemed to be acceptable to the scientific user community. In man-rated vehicles, determining an acceptable value for the likelihood of mission success (hence loss of mission) may be more difficult. However, specifications for the reliability may then address the probability of avoiding mission aborts or loss of function. An example might be quotthe item shall perform its functions during the launch phase without losing any of the defined capabilities or functions with a probability of 0.98.quot The Federal Aviation Administration relates the consequence of failure and the probability of its occurrence in its consideration of risk, and is shown in Figure 1. By defining quantitative reliability requirements as those involving failure events throughout a flight leading to emergency procedures or immediate landings (mission aborts), the quantitative values for commercial vehicles would be specified in the 0.999 to 0.99999 range, (or conversely 1 out of a thousand to 1 out of 100 thousand). [D] Figure 1: An Illustration of the Relationship Between Consequence of Failure and the Probability of Its Occurrence (FAA, Updated) In non-man rated vehicles or systems, the emphasis is on specifying a requirement that is sufficient to ensure a high likelihood of mission success, but not so high as to drive cost and weight beyond reasonable bounds. The use of function and item redundancy for increasing the likelihood of mission success will likely be necessary to meet high quantitative reliability specifications, but redundancy can also add significant program costs. Again, trade studies may be necessary to balance requirements for the likelihood of meeting a mission objective against the reliability achieved with current manufacturing technologies and against various design options. For instance, it would be extremely difficult at current technology levels to meet a 0.999 reliability on a lengthy mission of high complexity without the use of functional redundancy. For quick-development, highly cost-restrictive programs with limited objectives, a performance-based reliability requirement of 0.9 or less may be appropriate to keep the acquisition costs within bounds. To verify the fulfillment of a quantitative requirement, reliability analysis such as reliability block diagram analysis (RBDA) is used. The attribute of reliability, by definition, lies in the probabilistic realm while most performance attributes or parameters such as temperature, speed, thrust, voltage, or material strength contain more deterministic characteristics. Within the accuracy of the measuring devices, one can directly measure performance attributes in the deterministic realm to verify compliance with requirements. No such measuring device exists for probabilistic parameters like reliability; it is usually estimated through comparison to similar components or systems through inference, analysis, and the use of statistics. Verification that quantitative requirements have been met also provides answers to questions such as quothow reliable is this system?quot [D] Table 2: Quantitative Reliability Requirement Verification Techniques A reliability requirement specified without a probability value such as quotthe vehicle shall perform xyz mission on-orbit without failure for 5 yearsquot is impossible to verify during qualification or acceptance testing. The likelihood, or probability, that the requirement will be met is assessable, and this activity is inherently equivalent to assessing the reliability. Without quantitative requirements, it is left to the certification assessor to evaluate an estimate of the probability of success and to decide if that is sufficient, which places the risk on the program. A great deal of preliminary analysis may be necessary in the requirement specification process that considers the capability of the technology to various levels of reliability. This preliminary analysis helps avoid setting quantitative requirements too high or too low. Development of quantitative reliability requirements must represent a balance between the operational performance requirements of the system and the ability to restore and maintain the system through maintenance and sparing. Establishment of quantitative requirements as high as possible is necessary to maximize the probability that the system will complete the mission without failure. However, achieving high reliability or probability of mission success increases cost by generally requiring redundant equipment and fail-safe devices as well as high margins of safety in the material properties used. Thus, meeting unrealistic and unnecessary reliability requirements can lead to program weight and volume problems as well as cost inflation Based on the stress-strength concept of failure, perfect reliability could be achieved by building a system whose strength is greater than any conceivable stress put on the system. In reality, weight, volume, and cost constraints usually limit the strength of the design. Although perfect reliability from space systems cannot be expected, consideration of the needs of the operational community as well as the budget of the program will help in determining a requirement level. Also, if reliability goals are not met, it may be necessary to initiate a reliability growth scenario in which failure modes are analyzed and designed out of the system. This may or may not cost the program extra money, as reliability growth testing may not have been part of the original life cycle plan. As mentioned above, the International Space Station Program has levied a quantitative performance requirement on the Prime Contractor. Arrival at that requirement came through rigorous coordination with operational elements of the program, including the Mission Operations Directorate and the Science and Utilization community. The actual benchmark of 0.8 was derived from analysis of the operational needs of the program, the number of failures that could be tolerated, and an early analysis of what the space station design concept could provide. This number was a mutual agreement between the product assurance community and the operations community. As a result of this requirement, the prime is undergoing an effort as part of iti\u0301s reliability group to maintain a running tally of the overall station reliability via reliability block diagram analysis. Every design change, program change, or other input is reflected in the running tally to ensure that the design meets the requirement. Technical Rationale: Many previous NASA program development efforts have relied on specific design requirements such as redundancy to minimize risk and the likelihood of failure. Quantitative reliability requirements augment qualitative reliability analysis such as failure tolerance, but more importantly, gives teeth to a requirement that may otherwise slip from the design. Designers and contractors are held responsible for designing systems and to demonstrate analytically that the system or function will have a sufficient likelihood of failure-free mission operations. References: SSP 41000, quotSystem Specification for the International Space Station (ISS),quot November 1, 1994, Contract NAS15-10000. NASA Risk Management Program Tools and Techniques Handbook, Draft, July 1988, NASA Headquarters, Code QS. NASA Safety Risk Management Program Plan, Sections 1-5, NASA Headquarters, Code QS. Reliability Preferred Practice PD-AP-1313, quotSystem Reliability Assessment Using Block Diagramming Methods.quot","Lesson ID":827}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number AT-4 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Benefit: The ACARA program is an inexpensive tool for conducting maintainability, reliability and availability simulations to assess a system's maintenance requirements over a prescribed time interval. Also, availability parameters such as equivalent availability, state availability (percentage of time at a particular output state capability), and number of state occurrences can be computed. Implementation Method: The ACARA program models systems represented by reliability block diagrams comprising series, parallel, and M-of-N parallel redundancy blocks. A hierarchical description of the system is needed to identify the subsystems and blocks contained in the system. Given a reliability block diagram (RBD) representation of a system, the program simulates the behavior of the system over a specified period of time using Monte Carlo techniques to generate block failure and repair intervals as a function of exponential and\/or Weibull distributions. ACARA interprets the results of a simulation and displays tables and charts for the following: Performance, i.e., availability and reliability of capacity states Frequency of failure and repair. Lifecycle cost, including hardware, transportation, and maintenance. Usage of available resources, including maintenance man-hours. ACARA Inputs A RBD must be prepared for ACARA to simulate a system's availability. The RBD depicts a system, and the arrangement of the blocks depicts a performed function. RBD does not necessarily depict physical connections in the actual system, but rather shows the role of each block in contributing to the system's function. The blocks are sequentially numbered as B1, B2, B3, etc. and subsystems are numbered as S1, S2, etc, which are defined from the inside out. Figure 1 shows an example of a system with its corresponding blocks and subsystems. [D] Figure 1: Diagram of Blocks and Subsystems Beginning with the innermost set of blocks, each parallel or series set of blocks is partitioned into a subsystem which in turn may combined with other blocks or subsystems. The system shown in Figure 1 contains 6 subsystems: Subsystems 1 and 2 are both variable M-of-N parallel arrangement of batteries. These subsystems respectively contain Blocks 6 through 8 and Blocks 9 through 11. Subsystem 3 consists of Subsystems 1 and 2 in parallel. Subsystem 4 is a binary M-of-N parallel arrangement of diodes, Blocks 3 through 5. Subsystem 5 is a parallel arrangement of two turbines, Blocks 1 and 13. Subsystem 6 comprises the entire system and is a series arrangement of Subsystems 3 through 5 and Blocks 2 and 12. Modeling Time-to-Failure The ACARA program uses the Weibull distribution function to model the time-to-failure for the system. The shape and scale factors are adjusted to modify the form of the distribution. Uniform random numbers from 0 to 1 are generated and substituted for the reliability, R. ACARA uses the early failure (i.e., infant mortality), random failure, and wearout failure (life-limiting failure) models. These models are adjusted by user-defined parameters to approximate the failure characteristics of each block. Random failure is modeled by the Weibull distribution function where the shape factor is equal to 1 (equivalent to the exponential distribution) and the scale parameter is equal to the Mean Time Between Failure (MTBF). Wear out failure is also modeled by the Weibull function. The shape factor must be 1 or more. If the block with an initial age (i.e., it is not brand new) is installed, its initial age is subtracted from its first time-to-failure due to wear out. Likewise, if it undergoes a failure-free period, this period is added to its first time-to-failure. ACARA generates time-to-failure events using one or a combination of these models and assigns the minimum resulting time for each block as its next failure event. The early failure model is canceled by assigning to the block type an early failure probability of zero; random failure, by an excessively large MTBF; and wearout failure, by an excessively large mean life. ACARA also simulates redundant pairs of active and standby blocks. A standby block is installed as dormant and its time-to-failure is initially modeled by random failure, in which the MTBF is multiplied by its characteristic Dormant MTBF Factor. Then, the corresponding active time-to-failure is modeled by early, random, and wearout failure until the active block is replaced. Modeling Down Time The downtime for a failed block depends in part upon the availability of spares and resources. These spares may be local spares, i.e., initially located at the site. If a local spare is available when the block fails, the block is immediately replaced and downtime will depend only on the mean-time-to-repair (MTTR). If no local spares are available, ACARA will schedule a replacement according to the schedule production quantities for that block type, the constraints on mass, volume, and delay associated with the manifesting and loading spares to the resupply vehicle. ACARA also checks the constraints on the maintenance agents to determine when the block can be replaced. Once all the above conditions are met to allow the block to be replaced, ACARA then estimates the time required to replace it. The time-to-repair depends upon the MTTR's for that block type. MTTR's may be specified for up to three separate maintenance agents. Examples of maintenance agents are crew, equipment, and robotics. ACARA assumes that the maintenance actions occur simultaneously, so that the block's repair time is determined by the maintenance agent having the maximum MTTR. During the simulation, the time-to-repair may either be set equal to the maximum defined MTTR or to be determined stochastically. Refer to Reference 1 for a complete guide on the use of ACARA and the explanation for entering data and the output of graphs and information. ACARA may be obtained from the Computer Software Management and Information Center (COSMIC) at the University of Georgia, (706) 542-3265. References: Stalnaker, Dale K., ACARA User's Manual, NASA-TM-103751, February 1991. Hines, W.W. and Montgomery, D.C., Probability and Statistics in Engineering and Management Science, 2nd Ed., John Wiley & Sons, 1980","Lesson ID":829}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number AT-5 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Benefit: This technique will reduce unnecessary failures attributed to the traditionally used redline-based system. The average signal power algorithm can be used with engine test firing data to provide significantly earlier failure indication times than the present method of using redline limits. Limit monitoring techniques are not capable of detecting certain modes of failures with sufficient warning to avoid major hardware and facility damage. Implementation Method: For discrete random processes, probabilistic functions are used to describe the behavior of the rocket engine system. The Power Spectral Density (PSD) is computed to describe how the variation of the random process is distributed with frequency. For stationary signals, the PSD is bandlimited to \u00b11\/(2T), where T is the sampling interval in seconds. Average Signal Power Calculations The PSD is defined as the discrete-time Fourier transform of an autocorrelation function. (The derivation of the autocorrelation function is shown in Reference 1.) When the autocorrelation function is evaluated at zero lag, then an expression for the average signal power (ASP) of a random stationary process results: [D] where: P xxf ) = discrete-time Fourier Transform r xx [0] = inverse discrete-time Fourier transform The average signal power for several SSME parameters is determined by calculating the autocorrelation at zero lag for the parameters provided in Table 1. The assumption is made that the signal is stationary over the computation interval. The average signal power calculations are performed over 2-second, 50-percent overlapping window for nominal test firings at both 104- and a 109-percent-rated power levels. A smaller time increment must be used to improve the failure the algorithm. [D] Table 1: Signal Threshold and Safety Factor for SSMEs The average plus three standard deviations of the average signal power are computed for all the nominal firings at both engine power levels. These values are combined to calculate the thresholds (see Reference 1). A safety factor ranging from 1.5 to 3.5 is needed to ensure no false failure indications are computed for the nominal firings. The range of safety factors reflected signal behavior variations that occurred over seven nominal A2 firings. When used in the failure detection mode, failure of the average signal power of a parameter to fall outside its threshold results in a failure indication. Also shown in Table 1 are the thresholds calculated from the SSME nominal test firings based on the average signal power algorithm along with the associated safety factors. Algorithm Implementation A system identification and signal processing software package on a RISC workstation provides the average signal power algorithm. Command and Data Simulator (CADS) data from a predetermined number of SSME test firings are used to establish the failure indication thresholds. Several system conditions must be considered to ensure that the algorithm does not erroneously indicate an engine fault. These conditions include sensor failure, propellant tank venting and pressurization, and propellant transfer. Sensor failure detection techniques must be exercised before, or concurrently, with safety monitoring algorithms in order to eliminate the possibility of a sensor failure being interpreted as an engine problem. Typically, all parameters exhibiting sensor problems are removed prior to the application of the algorithm. Failure indication thresholds are established by applying the average signal power algorithm to a set number of nominal tests. For the SSME four anomalous firings and one nominal firing were tested using the thresholds shown in Table 1. An example of the application of the average signal power algorithm to a SSME anomalous test firing is shown in Figures 1 and 2. Figure 1 illustrates the interval over which the average signal power was computed for a single parameter, HPFP discharge pressure and one test firing. [D] Figure 1: Application of the Average Signal Power Algorithm to the HPFP Discharge Pressure Figure 2 displays the resulting average signal power, as a function of time. As shown, the threshold for the average signal power algorithm has been exceeded. [D] Figure 2: Average Signal Power for that Interval with the Failure Indication Threshold Nomenclature: HPFP high pressure fuel pump HPFT high pressure fuel turbine HPFTP high pressure fuel turbopump HPOP high pressure oxidizer pump HPOT high pressure oxidizer turbine LPFP low pressure fuel pump MCC main combustion chamber PID parameter identification SSME space shuttle main engine References: Meyer, C.M., Zakrajsek, J.F., Rocket Engine Failure Detection Using System Identification Techniques, AIAA Paper 90-1993, July 1990.","Lesson ID":830}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number OPS-03 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Benefit: Adherence to proven robot cell design and operational practices will result in improved consistency, speed, safety, precision, and reliability and increased cost-effectiveness of robotic systems over manual or semi-automated processes. Implementation Method: When the SRB is recovered from the ocean, disassembled for refurbishment, and reused on subsequent Space Shuttle flights, several layers of insulating materials and protective coatings must be removed and then re-applied. Experience has shown that the use of robotic systems for insulation removal and application will improve productivity in most operations by a factor in excess of 10 to 1. Originally, the application of the SRB insulation was a semi-automatic operation. The nine ingredients (see Table 1) were measured by hand, placed in a large blender and mixer, and mixed to a uniform consistency required for spraying. This mixture was pressurized and delivered to the spray gun, which was attached to a pedestal mounted robot in the spray cell. The SRB structures were prepared by hand, i.e., sanded, cleaned, inspected, and areas masked that did not require insulation. The SRB structure was mounted on a portable turntable, which was coordinated with the operation of the robot and spray gun. Then the SRB structure and the turntable were positioned into the spray cell. A technician (with breathing air and protective equipment) was required in the spray cell during actual spraying to take thickness measurements, assist in unplugging the spray gun, and remove the wet insulation, if it did not meet specifications. The cured insulation had to meet a flatwire tensile test of 50 to 100 pounds and a toleranced thickness requirement. Adjustments were made to the delivery system and the insulation reapplied until it met specifications. Preparation of the structure for spraying and insulation required many man-hours. 2215 Adhesive parts A & B* Ground Cork Glass Ecco Spheres Phenolic Micro Balloons Chopped Glass Fibers 1\/4 inch long Milled Glass Fibers 1\/8 inch long Bentone 27 Ethyl Alcohol Methylene Chloride\/per Chloroethylene * The original adhesive that contained shell z Catalyst was a carcinogenic Table 1. Ingredients in the SRB Insulation After automating and robotizing the application of the insulation, the insulation ingredients are automatically measured, blended, mixed, pressurized and delivered to the spray gun, which is mounted on a gantry robot. The gantry robot allows spraying inside the structures without the need to rotate the structure for access. The robot is programmed to automatically attach an end-effector to perform the following operations: sanding, cleaning, inspection, masking, spraying, and thickness measurements. Automating and robotizing the application of insulation eliminated the need for a technician in the spray cell and eliminated many of man-hours of hand work. At the start of the SRB refurbishment program, the insulation was removed manually. This required a technician to manually hold a hydrolaser pressurized to 8,000 to 10,000 psi. This created a backwash of 72 pounds force that the technician had to overcome using two 2-men crews rotated every 15 minutes. Any insulation left after this operation was removed by hand using nonmetallic chisels and mallets. Manual removal of the insulation from the two aft skirts required approximately 400 man-hours. [D] Figure 1. Example Robot Facility: SRB Insulation Removal Procedures for Robotic Removal Robotizing the removal of the insulation reduced the man-hours for two aft skirts to approximately 64 man-hours. The hydrolaser is mounted on a gantry robot which is located in the removal cell. The pressure to the hydrolaser has been increased to 12,000 to 15,000 psi. Technicians have been eliminated from the hazardous environment. The robot is controlled by computer. A turntable (also controlled by computers) is mounted flush with the floor. After removal of the insulation, the robot is programmed to clean the hydrolaser cell. Table 2 lists typical reasons for using automated robot cell to apply and remove SRB insulation. Table 3 is a list of the 13 best practices in the design of robotic systems for removal and application of insulation. The most predominant consideration was the high pressure water spray and debris environment encountered in the hydrolaser insulation removal process. Operational maintenance, as well as design, is important in maintaining a safe and efficient operation. Potable water is used to reduce corrosion in the pumps, valves, and lines. The use of de-ionized water should be considered in areas where the water has a high mineral content. Since the water used in the insulation removal process is recycled, the water must be filtered prior to reuse to prevent erosion and corrosion of pumping and spray equipment. Man out-of-the-loop for hazardous and toxic environments Efficient; robot does not get tired. Will do whatever it is programmed to do and will do it repeatedly. Will handle various end effectors for sanding, cleaning, inspection, spraying, and thickness measurements. Table 2. Typical Reasons for Using Robots For the SRB insulation system removal, the water is filtered to contain particles no greater than 5 microns. On a quarterly basis, or every 100 operating hours, high pressure water pumps are inspected and overhauled if necessary to repair or replace the pump head, pistons, or brass sleeves. Preventive maintenance is performed regularly. Gear Specifications to the environment and the application (i.e., adaption to a solvent or water spray and debris-laden environment). Pay close attention to the ergonomics for operators (i.e., convenience of controls, visibility, amnual override, and teaching procedures). Provide sufficient space in robotic facilities for support equipment, mechanisms, personnel, and operational control stations. Design-in automated shutdown to be activated in the event of excessive flow, pressures, temperatures, or inadvertent ingress of personnel. Consider the use of vision systems for alignment, completion status, inspection, and thickness measurements. Provide overload sensing and tactile feedback for delicate operations. Retain manual capability for emergency and backup operations Establish precise automatic indexing of fixtures with workpiece and robot to minimize setup time. Provide electrical grounding of all system elements Purchase over-rated equipment. Use only 75% or less of the capacity in the initial design to provide growth potential and operational\/maintenance margins. Protect robot elements from solvents in the enviroment to ensure continued robot lubrication. Train and use dedicated personnel for robotic operations Establish preventive maintenance requirements during the design phase based on designed-in ease of maintenance features (i.e., proper panel access, calibration test ports, equipment clearances, etc.). Table 3. Best Practices for Robotic Systems Facility Requirements A robotic facility of the type used for SRB insulation removal and application must allow operator visibility of the process and careful design for personnel safety and access provisions. During the noisy removal process, personnel within a 50 ft. radius are required to wear ear protection. Operators entering the area during or immediately after spray operations are required to wear protective suits with self-contained breathing apparatus to prevent inhalation or contact with toxic fumes. Facility design must be carefully coordinated with robot design and robotic operations planning. A concurrent engineering approach is desirable in the design of robotic systems to ensure use of the correct robot, operating in an optimally designed facility, for the target application. A team of engineers and technicians representing all applicable disciplines should be assigned full time to the project throughout design and operations. Three levels of drawings of the robot\/facility complex representing: (1) components, (2) subsystems, and (3) the integrated system should proceed through 30, 60, and 90 percent design reviews. Three-dimensional solid modeling simulations using computer-aided design techniques will dramatically speed up the design process. (See the MSFC Guideline titled, quotConcurrent Engineering Guideline for Aerospace Systems,quot in NASA TM 4322A, quotNASA Preferred Reliability Practices for Design and Testquot). The facility must contain support equipment, pumping systems, material storage, control stations, and personnel dressing and clean-up. Particular attention should be paid to debris handling. Sloped concrete subfloors provide for easy debris collection and clean-up. Automated cell clean-up techniques should be considered for material removal operations. Special Design Considerations Robotic systems lend themselves to the effective application of automated emergency shutdown, automatic end-effector changeout, overload sensing, tactile feedback, and manual override. These features should be designed into the robotic system at the outset with participation of the robot vendor. Setup time can be minimized by providing pre-engineered or automatic indexing and relative positioning between the work piece, support tooling or equipment, and robot. While mechanical systems should be over-designed for extra margins of safety against wear and malfunctions, care should be taken not to grossly overdesign control system memory, particularly if a bubble memory is used. This could result in slower robot control system operation. References: Rice, Robert: Process Report on the Automated Hydro Removal of TPS, Report # USB-ATG-003, USBI Booster Production Company, Inc., NASA\/MSFC contract # NAS8-36300, January 1986. Loshe, Thomas: Hydrolyzing Operations in High Pressure Wash Facilities, Maintenance Manual # B8598, USBI Document Prepared for Kennedy Space Center, October 4, 1991. Loshe, Thomas: Solid Rocket Booster Thermal Protection Removal System Software Users Guide, Document # 10MNL-0044, United Technologies, USBI, April 2, 1990. Babai, Majid: Robot Simulation and Manufacturing, Aerospace Engineering, SAE, October 1992, pp 11-13. Fertig, Alan R. and Tony S. Humble: Robots Refurbish Space Shuttle Hardware, TABES Conference Proceedings, Huntsville Association of Technical Societies (HATS), Huntsville, AL, 1987. Special Government Publications: MM B8601, Preventive Maintenance Gantry Robot and Controller MM B8604, Preventive Maintenance\/Validation Robot End Effectors MM B8611, SRB Insulation Manufacturing Manual (Forward Assembly) MM B8616, SRB Aft Skirt Assembly-MSA-2 TPS Operations Manual MM B8630, MSA-2 Tunnel Cover Assembly Operations Manual STP 513, Cleaning Sprayable MSA-2 Insulation Spray STP 621, MSA Control Room Operation STP 622, Installation and Removal of Robot End Effector Adapters STP 634, Sprayable MSA-2 Insulation Control Room and Mix Operations TP 741, MSA-2 Spray System Preparation -ARF SESP (Safety Engineering Standard Procedure) 23405, Safety Requirements for Robot Systems","Lesson ID":832}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PD-AP-1313, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Benefit: Reliability block diagram (RBD) analyses enable design and product assurance engineers to (1) quantify the reliability of a system or function, (2) assess the level of failure tolerance achieved, (3) identify intersystem disconnects as well as areas of incomplete design definition, and (4) perform trade-off studies to optimize reliability and cost within a program. Commercially available software tools can be used to automate the RBD assessment process, especially for reliability sensitivity analyses, thus allowing analyses to be performed more effectively and timely. These assessment methods can also pinpoint areas of concern within a system that might not be obvious otherwise and can aid the design activity in improving overall system performance. Implementation Method: Analysis methods described below make use of RBD analyses and commercially available software tools to analyze NASA space system designs. They are equally useful for analyzing mechanical and electrical systems and identifying potential deficiencies in system redundancy and\/or reliability performance based on RBD assessments derived from drawings, schematics, and system specifications and documentation. A detailed understanding of system architecture and functionality is necessary to assess system reliability using these types of quantitative analyses. The output of this analysis is valuable to the design and engineering functions on a program. It is more useful if a concurrent relationship exists between the product assurance team activity performing the analysis and the engineering design team, since design alterations and improvements can be made in near real time. These methods combine research, drawing review, reliability analyses, and the use of software automation. When this approach is taken, it is recommended that a team of individuals be involved to bring the necessary skills to the analysis, to share the workload, and to ensure that all technical areas of the analysis are covered. The RBD Technique: The RBD process involves developing block diagrams of a system or of a systemi\u0301s function (tasks for which hardware\/software systems were designed). JSC analysis personnel have developed both system and system function models. Experience shows that more benefits are realized from the system function models. When a function is represented as a block diagram, the models should include all operational components of the systems that are involved in the function and reflect component redundancy and subsystem-to-subsystem connectivity. The models are developed with a commercially available software tool and, with the proper inputs, are assessed for overall system reliability and design reliability concerns. Software analysis tools are an essential part of the JSC RBD analysis process. For these analyses, JSC personnel use commercially developed software for a personal computer. As with any analysis, it is critical that all involved parties understand (1) what items were used for input and what assumptions were made, (2) what calculations were performed, and (3) what interpretations can be made from the outputs. Inputs. To create an RBD, it is necessary to collect three types of information about the system being studied: functional systems architecture data, component reliability data, and mission times. Architecture defines the redundancy interrelationships between items within a system or function. These relationships are used by the RBD process in determining serial, parallel, and m of n relationships (out of n components, m are required for success). The architecture of the RBD is attained from a study of the schematics and other diagrams of the hardware, as well as the ground rules and survival assumptions that dictate which subset of that hardware is to be used. This information is entered into the block diagram editor of the software and is linked to the failure rate data base (into which data must also be hand entered). The second type of essential information includes failure rates of the equipment of interest to the lowest modeled level of detail (i.e., piece part, etc.). The third type of essential data is the mission time of each modeled component. The last two pieces of data are used to calculate the reliability for each item in the RBD over the mission time specified and is part of the overall function probability of success. Numeric Operations. The core of the RBD analysis is the calculation of the model reliability, usually done with a software tool. The functional relationships, failure data, and mission times are input to the tool and, using user-defined methods, the reliability of the model is calculated. Any number of probability distributions can be used for calculation, with the most common method being the constant failure rate assumption using the exponential distribution. Other distributions can be used, and currently JSC is working to understand early failure phenomena and how an early failure model can be used in the reliability calculations. The software calculates reliability (or unreliability) using the block relationships of the block diagram (interdependencies), the failure rates provided by the user, the mission time, and the user-defined calculation method. Probabilities are output in tabular form by a block, higher level function or nested block for the entire model, allowing the analyst to visualize where the reliability is being affected. There are other outputs as well, and they are described below. Outputs. Using the software tools for evaluating the RBD model, a point estimate or numerical calculation for the unreliability of the system or function being studied for the mission time specified will be provided in the form of the tables described above. The RBD analysis tools will also provide a cutset \"min-cut upper bound\" approximation, which is a list of the failure events ordered in descending probability of occurrence. A failure event is the minimum combination of failures that would result in loss of the modeled function. The most useful features of the cutsets are their ability to conspicuously display the most unreliable characteristics of the design (weak links), areas of incomplete design, and interfaces between two systems within the design which might exhibit low reliability. These concerns are easily identified within a cutset at the top of the listing. The cutset listings are helpful in assessing the failure tolerance of a system and can be used as an indicator of where further study is warranted. Typically, those components, which appear in the top cutsets, are investigated further by changing the failure rates of these components and observing the effects on the overall reliability number. This is known as a sensitivity analysis. If failure rate changes in one component have a significant effect on the overall result, then it is worthwhile to study the possibility of changing this component so that its actual failure rate becomes lower. Other sensitivity analyses are often performed as well, including changes in mission times and actual architectural variations. Utilization of Output: Interpretation and use of the output data are probably the most important parts of the analysis process. The data have been used for verifying quantitative reliability requirements when maintenance of a certain reliability level over a certain mission time is contractually required and this type of prediction is necessary for the verification. The results of RBD analyses can lead to further studies of functional availability, maintenance actions, maintenance times, fault tolerance, spares necessity, etc. The cutsets can be formatted for use by other software tools as input data to a much larger realm of functional simulation. Another type of analysis known as a trade-off study can easily be done with RBD analyses. Trade-off studies are performed by \"trading\" different system architectures for the architecture of the baseline design of the system and noting the results. This method allows the results of adding redundancy or removing hardware from the system to be quickly identified. To facilitate the analysis process, JSC Safety, Reliability, and Quality Assurance (SR&QA) developed several programs that interface with the software tools and enhance their performance. These programs provide the capability to do sensitivity studies through global modification of key parameters in the data base (e.g., mission duration), an area in which the commercial tool was somewhat lacking. Other such capabilities are needed when several runs of the model are being conducted in a batch fashion. A sensitivity study, for example, would require an incremental modification of the failure rate for the given component on every iteration of the model. To do this, one of the programs mentioned above will provide for access to the data base and modification of the component failure rates before every run in the batch file. As a sidenote, the commercial tool JSC uses provides a user interface that is somewhat difficult to use and, until improvements are made, some difficulties will exist in developing and manipulating RBD models and their corresponding data bases. Technical Rationale: The assessment techniques described above, which have been applied on several JSC programs, have provided valuable data on proposed designs. RBD models have been built and studied for the early design of the Space Station attitude control function (ACF), on both the Space Station baseline and all the proposed redesign options. The ACF is one of the most critical Space Station functions, because loss of attitude control in orbit could quickly result in the loss of the Space Station. RBD analysis was used to point out weak links in the baseline subsystem design and to assist in improving the design by pinpointing where reliability could be improved. Models were also built for the redesign options, comparing the reliability of the ACF of each and providing data that helped in the decision to choose the MSFC Option A. RBD models have also been developed for the latest Space Station configurations to assist the program in verifying quantitative reliability requirements set forth in SSP 41000, \"System Specification for the International Space Station (ISS).\" SSP 41000 states that the Space Station shall provide for 50 percent of the internal payload locations to perform at least 180 days of microgravity science per year in continuous time intervals of no less than 30 days at a reliability of 0.8 or better. To verify that the current Space Station design will meet that requirement, JSC personnel have developed an RBD model that includes all Space Station functionality required to provide for a microgravity environment. This model has been instrumental in showing that several design changes were necessary to provide for that reliability. Models have been built in the past and will be built in the near future to be used as inputs to functional simulations of Space Station operations. These simulations will provide input to designers in areas where more fault tolerance is necessary; e.g., critical spares list development, maintenance times and mean number of actions, and expected systems availability on a stage-by-stage basis. This type of analysis has been and will continue to be very useful to program management in defining and managing program risk factors. RBD analyses have also been performed on the Orbiter Project. The Orbiter autoland function was assessed to discern the reliability of the associated hardware\/software configuration over a long-duration Orbiter (LDO) mission. The autoland function was to be a requirement for LDO because of ill effects on the Orbiter crew during extended stays in zerogravity. The analysis showed a high reliability during the 90-minute mission time window in which the autoland equipment was used. Over a 30-day LDO mission, however, reliability decreased substantially, possibly requiring future on-orbit maintenance of Orbiter systems. Other Orbiter Project analyses have proved the reliability assessments to be a valuable design and management decision-making tool. JSC's RBD analysis process has repeatedly identified weak design points that were not identified during qualitative reviews of the Space Station design. Results of computer-aided RBD analyses performed by JSC SR&QA were used by the Station Redesign Team (SRT) to make recommendations to the President about the merit of different redesign options. The SRT requested that JSC SR&QA investigate the reliability of the Lockheed Bus-1 attitude control system using computer-aided RBD analyses. The results of that effort weighed heavily in the early decision to use the Bus-1 on the \"Alpha\" Option in place of the \"Freedom\" baseline propulsion modules (Bus-1 is no longer in the design, since the Russian segment is providing that functionality). Such quantitative approaches as RBD analyses lend a heightened completeness, efficiency, and accuracy to any reliability design analysis. References: RBD Analysis User's Manual (Los Altos California: Science Applications International Corporation, 1992), p. 3-11.","Lesson ID":825}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number OPS-19 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Benefit: A well thought out and properly designed EVA incorporating ease of crew maintainability leads to mission success. Failure to properly address crew maintainability in the EVA design can lead to time-consuming \"work-arounds,\" the inability of the crew to fully complete the desired and\/or required tasks, and may expose the crew to unnecessary safety hazards. Implementation Method: Background Astronaut Jerry Ross has participated in the development of almost all of the EVA hardware and procedures for the Space program since 1981. This includes being the support crewman and EVA Capsule Communicator (CAPCOM) for the first manned maneuvering unit (MMU) flight (STS-41B), the Solar Max repair mission (STS-41C), the WESTAR and PALAPA retrievals (STS-51A), and the attempted \"flyswatter\" activation of the SYNCOM satellite. He has also performed four EVAs on STS-61B and STS-37 to investigate space construction techniques and prototype Space Station EVA equipment and to repair the Gamma Ray Observatory. In addition, he has participated in the testing of advanced space suits since 1984 and in the design of Space Station EVA systems since 1985. Primary Crew Considerations First and foremost, a human being can do almost anything during a space walk that can be done on the Earth's surface. However, working in zero gravity and in a spacesuit necessitates certain design compromises to facilitate the productivity of the spacewalker and to enhance the probable success of the EVA. Two factors that must always be considered when designing EVAs are: (1) that the spacesuit is stiff, restricts visibility and movement, is fatiguing to work in, and all work is done with gloves that significantly reduce tactility and dexterity; and (2) that all things must be tethered (including the crew persons) to preclude them from drifting away and becoming lost. EVA Design Considerations There are several design considerations that must be kept in mind when developing an EVA. Compatibility - EVA equipment and tasks should be designed to be EVA compatible. This will maximize the probability of success, minimize the expense, eliminate EVA hazards, and prevent the need for inefficient, time-consuming operational workarounds due to bad design concepts. Task Design - Tasks should be designed, when possible, so that tools are not required. For example, a doorknob should be used instead of bolts to provide access behind a panel. If tools are required, standard tools and interfaces should be used. This minimizes the number of tools that need to be flown and training required, and enhances the probability of success. Tools should be stowed at work sites when possible to minimize the movement of tools and equipment. Power tools should be used for tasks that are repetitive. This increases productivity and will reduce crew fatigue. For the most part, tasks should be designed so that only one hand is required. This is due to considerations of working in the spacesuit and the frequent requirement to stabilize oneself with the other hand. The maximum force to perform a task should be designed to < 113 N (25 lbs.) and the task should be designed to use large muscle groups whenever possible to reduce crew fatigue. Proven Design Concepts - Proven design concepts should be standardized and used; e.g., double high bolt heads, electrical wing tab connections, and ganged connectors. Designs should also minimize the number of loose parts by using self-retaining fasteners and panel hinges. Good Visual Indicators - Good markings, feedback's, and indicators need to be provided so the EVA crewperson can visually verify that the proper condition has been achieved, such as closed, locked, open, or over-center. Restraints - The right types of restraints, foot restraints, hand-holds, tether points, and translation aids need to be provided in the right locations. Their placement, type, and number must be determined through suited zero-gravity simulations in an underwater facility. Involvement of Safety and Quality Assurance - The Quality Assurance and Safety organizations should be involved in the design process at an early stage. This will help to ensure a good and safe design and help minimize the need for costly redesign. EVA Simulation Water tanks provide an excellent analog simulation capability. They should be used early in the design process with mock-ups of the flight hardware and tasks to be performed. Astronaut participation in these early water tank evaluations is essential to a cost-effective and efficient design process. The mock-up should be upgraded as the design matures and the fidelity of the mock-up to the flight hardware can be critical to the success of an EVA. Functional Testing and Fit Checks Functional tests of EVA hardware and tools in a thermal\/vacuum chamber have proven to be mandatory. Many design changes have resulted from such tests. Fit checks of all flight hardware to all flight (and flight spares) hardware and tools are mandatory. Develop a matrix of all interfaces and perform physical fit checks. Numerous on-orbit problems have been avoided through this process. Space Shuttle EVA Operations For the Space Shuttle, EVA is at least a three person task (two EVA crew members and a third crewman on the aft flight deck to observe and act as an EVA activity manager). This third crewperson or activity manager serves as a time line prompter, procedure reader, picture taker, and keeps track of all of the loose hardware items. Crew coordination is essential when EVA operations are combined with remote manipulator system operations and Orbiter operations. Use conservative EVA timelines so that there will be time to deal with any unanticipated problems or delays. Convenient break points should be developed so that hardware can be left in a safe and stable configuration between EVAs. Backup procedures should be developed to overcome significant problems should they occur on orbit. Such preflight work saved the Solar Max repair mission and the WESTAR and PALAPA satellite retrievals. Develop and maintain good documentation of flight hardware configurations. Closeout (prelaunch) photographs are important to the EVA design and development process. The lack of good closeout photos and other detailed information on the \"as flown\" hardware configuration almost caused the failure of both the Solar Max and WESTAR\/PALAPA EVA missions.","Lesson ID":834}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number PM-1 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Benefit: Implementation of maintainability principles can reduce risk by increasing operational availability and reducing lifecycle costs. Provisions for system maintainability also yields long term benefits that include decreased maintenance times, less wear and tear on project personnel, and extended useful life of ground and in-space assets. Implementation Method: Over the years, NASA has successfully launched manned spacecraft to the moon, sent unmanned probes into the outer reaches of the solar system, and developed reusable space systems for earth orbitable missions. NASA also performs valuable atmospheric research and development of ground systems, all of which contain complex hardware and software that must be maintained during all phases of operations and in multiple environments. However, in this age of shrinking budgets, doing more with less is becoming the overall programmatic theme. NASA space flight programs are being driven towards more automated, compact designs in which fewer support resources will be available than in past programs. This technique will outline the benefits of implementing well-defined and user-friendly principles of maintainability on all NASA programs, regardless of the operational scenario. Emphasis is placed on how and why a maintainability program can enhance the effectiveness of a system and its overall operation. It must be noted, however, that maintainability of unmanned deep space systems provides a different set of challenges. Maintainability is defined in NASA Handbook 5300.4(1E), quotMaintainability Program Requirements for Space Systems,quot as: quotA measure of the ease and rapidity with which a system or equipment can be restored to operational status following a failure,quot and is consistent with NHB 7120.5, quotManagement of Major Systems and Projects.quot It is a characteristic of equipment and installation, personnel availability in the required skill levels, adequacy of maintenance procedures and test equipment, and the physical environment under which maintenance is performed. Applying maintainability principles will enhance the systems readiness\/availability through factors such as visibility, accessibility, testability, simplicity, and interchangeability of the systems being maintained. Using maintainability prediction techniques and other quantitative maintainability analyses can greatly enhance the confidence in operational capabilities of a design. These predictions can also aid in design decisions and trade studies where several design options are being considered. Also, cost savings and fewer schedule impacts in the operational phase of the program will result due to decreased maintenance time, minimization of support equipment, and increased system availability. Another benefit is a decrease in management overhead later on in the life cycle as a result of including maintainability planning as a full partner in early maintenance\/logistics concept planning and development. PROGRAMMATIC BENEFITS Maintainability Program Implementation Project management is responsible for implementing maintainability on a program via development of specific requirements for cost effective system maintenance in the early phases of the life cycle. Trade studies of the impacts of maintainability design on life cycle costs are used to evaluate the balance between cost of designing to minimize maintenance times and the associated increase in system availability resulting from the decrease in maintenance times. Usually, the up-front cost of designing in maintainability is much less than the cost savings realized over the operational portion of the life cycle. Several programs have opted to accept the short-term cost savings by deleting maintainability requirements in the design phase, but the associated increase in maintenance and support costs incurred during operations would have been significant. An example of this is the Space Station Program, which had deleted requirements for on-orbit automated fault detection, isolation and recovery (FDIR), saving the program up-front money. However, the alternative concept was to increase the mission control center manpower during operations for ground based FDIR, but this presented a significant cost increase when averaged over the life cycle. Another positive example is the Hubble Space Telescope Program. Maintainability concepts were included early in the life cycle, where maintenance planning and optimum ORU usage in design saved the program significant costs when on-orbit repairs became necessary. Figure 1 accentuates the cost tradeoffs between introducing maintainability concepts into a program and the time at which they are introduced. These tradeoffs can mean the difference between a successful maintainability program and a costly, less effective one. [D] Figure 1. Effect of Implementing Maintainability Program vs Phase The NASA systems engineering process should require that the system be designed for ease of maintenance within it's specified operating environment(s), and should ensure that the proper personnel (design and operations maintainability experts) and funds are committed to development of the process to achieve maximum program benefit. Program schedule will be affected by lack of system maintainability because necessary ground support will increase, maintenance times will be higher, necessary maintenance actions will increase, EVA will be at a premium, and system availability will be lower. Table 1 highlights key program benefits. Enhanced System Readiness\/Availability Reduced Downtime Supportable Systems Ease of Troubleshooting and Repair System Growth Oppertunities Hardware\/Software Modifications Interchangeability Modular Designs Decreased Storage Considerations Reduced Maintenance Manpower Reduced Operational Costs Compatibility with other Programs Reduced Management Overhead Table 1: Maintainability Programmatic Benefits Maintenance\/Logistics Concept Development Development of the maintenance and logistics concepts for a program early in the life cycle must include the maintainability characteristics of the design. The maintenance concept is a plan for maintenance and support of end-items on a program once it is operational. It provides the basis for design of the operational support system and also defines the logistics support program, which will determine the application of spares and tools necessary for maintenance. The use of other logistic resources, such as tools and test equipment, facilities and spare parts, will be optimized through including maintainability planning as a key operational element. Derivation of these plans early on in the life cycle solidifies many operational aspects of the program, thus allowing for integrated design and support planning development. MAINTAINABILITY DESIGN BENEFITS Visibility Visibility is an element of maintainability design that provides the system maintainer visual access to a system component for maintenance action(s). Even short duration tasks such as NASA space shuttle orbiter component inspection can increase downtime if the component is blocked from view. Designing for visibility greatly reduces maintenance times. Accessibility Accessibility is the ease of which an item can be accessed during maintenance and can greatly impact maintenance times if not inherent in the design, especially on systems where on-orbit maintenance will be required. When accessibility is poor, other failures are often caused by removal\/disconnection and incorrect re-installation of other items that hamper access, causing rework. Accessibility of all replaceable, maintainable items will provide key time and energy savings to the system maintainer. Testability Testability is a measure of the ability to detect system faults and to isolate them at the lowest replaceable component(s). The speed with which faults are diagnosed can greatly influence downtime and maintenance costs. For example, deficiencies in Space Shuttle Orbiter testability design have caused launch delays, which translate to higher program costs. As technology advances continue to increase the capability and complexity of systems, use of automatic diagnostics as a means of FDIR substantially reduces the need for highly trained maintenance personnel and can decrease maintenance costs by reducing the erroneous replacement of non-faulty equipment. FDIR systems include both internal diagnostic systems, referred to as built-in-test (BIT) or built-in-test-equipment (BITE), and external diagnostic systems, referred to as automatic test equipment (ATE), test sets or off-line test equipment used as part of a reduced ground support system, all of which will minimize down-time and cost over the operational life cycle. Simplicity System simplicity relates to the number of subsystems that are within the system, the number of parts in a system, and whether parts are standard or special purpose. System simplification reduces spares investment, the enhances the effectiveness of maintenance troubleshooting, and reduces the overall cost of the system while increasing the reliability. For example, the International Space Station Alpha program has simplified the design and potentially increased the on-orbit maintainability of the space station, thus avoiding many operational problems that might have flown with the Freedom Program. One example is the Command and Data Handling Subsystem, which is the data processing backbone for the space station. Formerly, the system consisted of several different central processing units, multiple level architecture, and several different network standards. The new design comprises only one network standard, one standard CPU, and a greatly reduced number of orbital replaceable units (ORU's). Maintainability design criteria were definite factors in the design changes to this space station subsystem. Reduced training costs can also be a direct result of design simplification. Maintenance requires skilled personnel in quantities and skill levels commensurate with the complexity of the maintenance characteristics of the system. An easily maintainable system can be quickly restored to service by the skills of available maintenance personnel, thus increasing the availability of the system. Interchangeability Interchangeability refers to a component's ability to be replaced with a similar component without a requirement for recalibration. This flexibility in design reduces the number of maintenance procedures and consequently reduces maintenance costs. Interchangeability also allows for system growth with minimum associated costs, due to the use of standard or common end-items. Human Factors Human factors design requirements also should be applied to ensure proper design consideration. The human factors discipline identifies structure and equipment features that impede task performance by inhibiting or prohibiting maintainer body movement, and also identifies requirements necessary to provide an efficient workspace for maintainers. Normally, the system design must be well specified and represented in drawings or sketches before detailed anthropometric evaluation can be effective. However, early evaluation during concept development can assure early application of anthropometric considerations. Use of these evaluation results leads to improved designs largely in the areas of system provisions for equipment access, arrangement, assembly, storage, and maintenance task procedures. The benefits of the evaluation include less time to effect repairs, lower maintenance costs, improved supportability systems, and improved safety. Summary Implementation of maintainability features in a design can bring about operational cost savings for both manned and unmanned systems. The programmatic benefits of designing system hardware and software for ease and reduction of maintenance are numerous, and can save a program, as seen with NASA's Hubble Space Telescope. Maintenance in a hostile, micro-gravity environment is a difficult and undesirable task for humans. Minimal exposure time to this environment can be achieved by implementing maintainability features in the design. The most successful NASA programs have been those which included maintainability features in all facets of the life cycle. Remote system restoration by redundancy management and contingency planning is particularly essential to assuring mission success on projects manned intervention is either undesireable or impractical. References: NASA Handbook 5300.4(1E) quotMaintainability Program Requirements for Space Systems,quot March 10, 1987, NASA Headquarters. NASA Handbook 7120.5, quotManagement of Major Systems and Projects,quot November 1993, NASA Headquarters Air Force Design Handbook 1-9 quotMaintainability (for Ground Electronic Systems),quot Second Edition, Revision 7, February 25, 1988, United States Air Force Aeronautical Systems Division. quotMaintainability Engineering Design and Cost of Maintainability,quot Revision II, January 1975, Rome Air Development Center. Reliability, Maintainability, and Supportability (RMS) Guidebook, Second Edition, 1992, Society of Automotive Engineers G-11 International RMS Committee. MIL-STD-470B quotMaintainability Program for Systems and Equipment,quot May 30, 1989, Department of Defense","Lesson ID":835}
{"Driving Event":"Benefit: This Lesson Learned is based on Maintainability Technique number OPS-01 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Implementation Method: Refurbishment of SRB components is cost effective and conserves resources. This allows for reuse of SRB's, thus saving money for the program versus building new SRB's for each launch. Solid Rocket Booster (SRB) Refurbishment encompasses the activities required to return the reusable SRB component to a flightworthy condition after SRB ignition, liftoff, and flight; separation from the external tank; descent (free fall and parachute); ocean impact; and retrieval. When the decision was made to recover and reuse the SRB hardware, a design team was organized to formulate the maintainability criteria for a reusable booster. The SRB Flow Chart for Maintainability is shown in Figure 1. The maintainability design team produced the Solid Rocket Booster Maintainability Design Criteria Document (reference 1), a document that was used by designers as they conceived each design feature, performed the necessary tradeoffs of the design parameters, and made other design and product engineering decisions. The design team included maintainability as a design goal and incorporated the desired maintainability features into components of the end item throughout the design process. Maintainability factors that were considered during the design of the SRB are shown in Table 1. [D] Figure 1. SRB Flow Chart for Maintainability Accessibility Commonality of Fasteners Electrical Subsystem Installation and Removal Thrust Vector Control (TVC) Subsystem Installation and Removal Markings and Color Coding Unitization of Subsystems Irreversibility of Connectors Tool and Equipment Design Spares Provisioning Table 1. SRB Maintainability Factors Design Process Considerations Table 2 lists typical maintenance actions that were considered during the design process. The SRB was designed to withstand launch, water impact, and towback environments, incorporating the capability of 10 flights for the parachutes; 20 flights for electrical\/electronic components, Thrust Vector Control (TVC) components, and SRM components; and 40 flights for the structures. SRB structures are typically welded and\/or mechanically fastened aluminum except for the external tank attach ring, which is mechanically fastened steel. All aluminum structural assemblies are first painted and then coated with an ablative insulation. The SRM segments are forged D6AC steel. All structural components are cleaned and\/or alodined as appropriate, before being primed and top coated with paint. The mechanically fastened aluminum and steel structural components are designed to be protected from salt water intrusion by applying sealant between adjoining surfaces, installing the fasteners with sealant, torquing the fasteners, and applying a fillet of sealant along the edge of brackets where they join the main structure. The electronic\/electrical components exposed to salt water are sealed, and the external surfaces of these components are painted. The TVC hydraulic system is a closed-loop system that does not permit the intrusion of sea water. The SRM segments' external surfaces are protected with an epoxy paint finish, and the internal surfaces are protected by the propellant insulator that is bonded to the inside surfaces of the SRM segments. Areas not protected with paint or bonded-on insulation are protected with a water-repellent grease. Inspection Troubleshooting Calibration and Adjustment Repair Verification Table 2. Maintenance Actions Specific Improvements Typical areas of the SRB that have been redesigned or modified as a result of trouble areas found during recovery and refurbishment are discussed below: Galvanic corrosion occurred in the aft skirt of the first few SRB's recovered. To prevent this from recurring the design team added a zinc coating to selected metal components, and bolted anodes (Zinc bars) to some components of the TVC system. The aft skirts of the first few SRB's experienced water impact damage. The corrective action included the addition of gusset reinforcements to the structural rings. Foam was sprayed on the interior of the aft skirt to protect the reinforcement rings and the TVC components. Impact force with the water was reduced by increasing the diameter of the main parachutes from 115 feet to 136 feet. The larger parachutes decreased the SRB's water impact velocity from 88 ft\/sec to 75.5 ft\/sec (60 mph to 51.5 mph, respectively). During initial teardown and inspection, water and corrosion were found between the mating surfaces of structural members. To correct this problem, the sealant application specifications were modified to require the sealant to be applied to both surfaces before joining. To eliminate potential water entry into the forward skirt, the following areas were modified or redesigned: The aft seal on the forward skirt was changed from a rectangular to a quotDquot configuration to allow better contact between the forward skirt and the forward dome of the SRM. A fillet of sealant was added between the access door and the surrounding structure after final close-out of the forward skirt. Sealant was added to the mating surfaces and the installation bolts of the separation nut housing for the main parachute attach fittings. The following practices improved maintainability, parachute deployment, and parachute inflation: To avoid abrasive damage that occurred during main parachute deployment, foam and ablative material were added to portions of the frustum and the main parachute support structure. To avoid damage to the parachutes during deployment, the parachutes are now packed in a circular pattern rather than the previous zig-zag pattern. The opening at the top of the main parachute canopy was decreased in diameter to allow quicker inflation of the parachute. After every flight electronic components were being returned to the vendor for refurbishment. After refurbishment, acceptance test procedures (ATP) were performed, including vibration and thermal testing. The vibration level of these tests caused the remaining life of the component to be reduced. To prevent the excessive expenditure of components' lifetime (except for the range safety system components) vibration and thermal testing has been eliminated during normal turnaround. The constant improvement of electronic parts by the manufacturer presents a unique problem to the SRB refurbishment effort because the improved parts are often not interchangeable with their predecessors. A sufficient quantity of spare parts must be procured to meet logistics requirements until the components are redesigned to use the improved parts. Typical Refurbishment Procedures Figure 2 depicts the SRB flight configuration. After approximately 125 seconds into the Shuttle flight, the SRB's are jettisoned from the external tank. During reentry, the nose cap is jettisoned (it is not recovered), deploying the drogue parachute. After the SRB is stabilized in a vertical position, the frustum is jettisoned and descends into the ocean. Its descent is held to a safe velocity by the drogue parachute. In the meantime, the jettisoning of the frustum deploys the three main parachutes, lowering the remaining portion of the SRB into the ocean. Once in the ocean, the parachutes (which are jettisoned at water impact) and the frustum are removed by the recovery team and positioned onto the recovery vessel. A plug is inserted into the SRM nozzle throat and the SRB is dewatered. Removal of the water from the SRB allows the SRB to be positioned from a vertical position to a horizontal position. The SRB is then towed to the disassembly area dock. [D] Figure 2. SRB Flight Configuration At dockside, the SRB is lifted from the water and placed on dollies. The SRB pyrotechnics are disarmed, the TVC fuel system is depressurized, and an assessment team inspects and documents anomalies that may have occurred during flight. Then the SRB is washed with a detergent solution in a semiautomated wash facility. The aft skirt is removed and routed to the TVC disassembly facility. Table 3 lists a typical flow sequence for major structure refurbishment. After the aft skirt is removed, the remainder of the SRB is routed to the disassembly facility. Tow SRB from water impact area to dock Remove SRB from ocean, Rinse with potable water. Place SRB on transporter. Safe SRB Ordnance and Hydrazine Systems. Assessment Team Inspection. Wash SRB with detergent solution and rinse. Remove aft skirt assembly. TVC refurbishement facility. Remove TVC Components. Disassembly area; remove components. Critical dimension check. Thermal protection system removal, robotic hydrolaser. Inspect, Visual and NDE (XRAY and Ultrasonics). Rework, Touch-up paint (repaint every fifth use.) Inspect and identify. Preflight storage. Table 3. Typical Structure Refurbishment Flow As the SRB components are removed, they are identified by attaching a metal tag with their part number and dispositioned per the Predisposition List for SRB Flight Hardware (reference 2). The SRB component is then routed to the refurbishment area where a prepared refurbishment procedure document is attached to the part. The part is reworked to conform to the Refurbishment Engineering Specification. This specification lists the requirements for refurbishing each component to flightworthy condition before it is returned to storage. The SRM segments are disassembled in the disassembly facility at dockside, placed on rail cars, and transported to the SRM contractor located in Utah. At the contractor's plant, the segments are off-loaded and routed to refurbishment areas. All segments that are to be reused must meet the requirements of specification STW7-2744 (reference 3). If segment dimensions fall outside the acceptable requirements of this specification, an individual analysis is required to determine the effect on the structural and sealing capability before reusability is determined. All documented nonconformances are reviewed to determine if the condition of the hardware has changed. The most critical areas to be reviewed are case membrane thickness, vent port and leak port threaded areas and sealing surfaces, and aft segment stiffener stubs. No surface defects (corrosion, pitting, scratches, noncrack-like flaws, etc.) deeper than 0.010 inch are permitted. All segments are hydrotested to 1.125 times the Maximum Expected Operating Pressure and magnetic-particle inspected. Major Structures (Frustrum, Forward Skirt, Aft Skirt, External Tank Attach (ETA) Ring, Solid Rocket Motor (SRM) Segments, etc. Electronic Components: Integrated Electronic Assembly (IEA), Integrated Receiver Decoder (IRD), etc. Electrical Cables. TVD Components Auxiliary Power Unit (APU), Hydraulic Pump, Hydraulic Reservoir, Fuel Service Module (FSM), etc. Parachutes Table 4. Types of Hardware That Have Been Successfully Refurbished References: NASA\/MSFC: Solid Rocket Booster Maintainability Design Criteria Document, SE-019-022-2H, NASA\/Marshall Space Flight Center, AL. USBI: Predisposition List for SRB Flight Hardware, 10PLN-0027, USBI, United Technologies, Huntsville, AL. Thiokol: Space Shuttle SRM Refurbished Case Acceptance Criteria, STW7-2744, Thiokol Corporation, Space Operations, Brigham City, Utah. NASA\/MSFC: Sealing of Faying Surfaces Subject to Sea Water Exposure on the SRB Excluding the SRM, 10A00526, NASA\/Marshall Space Flight Center, AL. NASA\/MSFC: Sealing of Fasteners Subject to Sea Water Exposure on the SRB Excluding the SRM, 10A00527, NASA\/Marshall Space Flight Center, AL. NASA\/MSFC: Protective Finishes for Aluminum and Steel Alloys Subject to Seawater Exposure on the SRB Excluding the SRM, 10A00528, NASA\/Marshall Space Flight Center, AL. NASA\/MSFC: Solid Rocket Booster Flight Hardware Ground Operations Plan, SE-019-040-2H, NASA\/Marshall Space Flight Center, AL. NASA\/MSFC: Solid Rocket Booster Flight Hardware Refurbishment Requirements, SE-019-050-2H, NASA\/Marshall Space Flight Center, AL, Systems Analysis and Integration. Thiokol: Space Shuttle SRM, Requirements and Acceptance for Refurbishment Nozzle Metal Components, STW7-2863, Thiokol Corporation, Space Operations, Brigham City, Utah. Thiokol: Space Shuttle SRM, Process Finalization Requirements for Nozzle Metal Hardware, STW7-3450, Thiokol Corporation, Space Operations, Brigham City, Utah. Thiokol: Space Shuttle SRM, Acceptance Criteria, New and Modified Case, STW7-3489, Thiokol Corporation, Space Operations, Brigham City, Utah. Thiokol: Space Shuttle SRM, Acceptance Criteria for Refurbished Igniter Chambers and Igniter Adapter, STW7-3861, Thiokol Corporation, Space Operations, Brigham City, Utah. Thiokol: Refurbishment and Acceptance Criteria for Redesigned Barrier-Booster Assembly, STW7-3888, Thiokol Corporation, Space Operations, Brigham City, Utah. Thiokol: Manufacturing Plan for Space Shuttle Redesigned Solid Rocket Motor (RSRM) Project, TWR-10341(CD), Prepared for NASA by Thiokol Corporation. Brigham City, Utah. USBI: 10MNL-0028, Solid Rocket Booster Pictorial Representations Handbook, USBI, United Technologies, Huntsville, AL. USBI: Frustum\/Aft Skirt Disassembly Requirements, 10REG-0032, USBI, United Technologies, Huntsville, AL. USBI: Refurbishment Engineering Specifications For Space Shuttle Solid Rocket Booster Assembly Project, 10SPC-0131, USBI, United Technologies, Huntsville, AL.","Lesson ID":836}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1401, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Benefit: EEE Parts Screening provides a lower rework cost during manufacturing and lower incident of component failures during flight. Implementation Method: Screening for each part can be established as follows: Refer to NASA's compilation of screening criteria for use with various EEE part types. An example may be found in Appendix C of the GSFC Preferred Parts List. If Class S parts are purchased, the screening tests shown in Table 1 have already been conducted. When Class S parts are not available, the screens of Table 1 should be used. Failure criteria during screening should specify Percent Defectives Allowable (PDA) and allowable parameter drift. Typical PDA criterion is 5%. A sample listing of failure mechanisms, the associated distribution of failures, and related screening tests are provided in Table 2. [D] Table 1. 100% Parts Screening Matrix [D] Table 2. Failure Mechanisms\/Screening Methods Technical Rationale: The EEE parts manufacturing is controlled by military specification requirements covering a variety of areas such as: starting materials, process controls, electrical or electromechanical performance characteristics, and periodic inspections of some characteristics of finished product. Despite these requirements, defects that cause early-life failures can be randomly built into a product. The screening tests are designed to be destructive to parts with particular defects but nondestructive to good parts. As an example, integrated circuits such as CMOS are highly susceptible to electrical performance failures caused by ionic contamination on the die surface. The contamination can be introduced by any of several uncontrollable avenues during manufacture and cannot be ruled out as an occurrence in any given lot of parts. To avoid early-life failures at higher assembly levels, the lot of parts is subjected to a 100% static burn-in. The burn-in is designed to drive contamination into the die areas where it will interfere with proper circuit operation and cause electrical failures before parts are installed on boards. References: NASA GSFC Preferred Parts List (NPPL) 18\/19. Seidl, Raymond H., Garry, William J., quotPi Factors Revisited,quot Proceedings of the Annual Reliability and Maintainability Symposium, 1990.","Lesson ID":814}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1419 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Adherence to the practice alleviates vibroacoustic-induced failures of structural stress and fatigue, unacceptable workmanship, and performance degradation of sensitive subsystems including instruments and components. Implementation of this practice assures that minimal degradation of quotdesign reliabilityquot has occurred during prior fabrication, integration and test activities. Implementation Method: The GSFC vibroacoustic qualification program for flight hardware requires an acoustics test at the payload level of assembly and random vibration tests on all components. In addition, a random vibration test is required on the payload when practical to better simulate the structure borne inputs. For small payloads, such as those launched by the Scout class launch vehicle, random vibration tests are required and the need for an acoustic test must be assessed. Subsystem level random vibration tests and component level acoustic tests are required when the payload configuration indicates that these exposures are likely to induce significant stress during the mission. In addition, subsystem level acoustic tests may be required. GSFC uses protoflight hardware for verification testing and the basic provisions of this method apply to protoflight hardware but are in general applicable to prototype. Protoflight hardware is flight hardware of a new design and is subjected to a test program that combines elements of prototype and flight acceptance verification; that is, the application of design qualification test levels and flight acceptance test durations. Prototype hardware is hardware of a new design that is not intended for flight and is subjected to a design qualification test program. Vibroacoustic test level limits for protoflight qualification are defined as the maximum expected flight levels (limit levels) plus 3 dB (reference 2). Random vibration levels are determined by responses to the acoustic inputs plus the effects of vibration transmitted through the structure. As a minimum, payload and component vibroacoustic test limits must be sufficient as determined on a case by case basis to demonstrate acceptable workmanship. The acoustic environment at launch is usually the primary source of vibration; however, other transients and sources of vibration must be considered. These sources include possible torsional oscillation imparted by the launch vehicle, vibrations produced by retro\/apogee motors on the payload, and sustained oscillations due to Main Engine CutOff (MECO) and pogo effects. Additional vibration tests (such as sine vibration) are required to qualify payload and payload hardware for these inputs if they are expected to occur during the mission. Payload Vibroacoustic Tests: a. Payload acoustic testing - Protoflight payloads must be subjected to an acoustic test to verify their ability to survive the launch acoustic environment and to provide final workmanship acoustic tests. The test specification is dependent on the payload-launch vehicle configuration and must be determined on a case-by-case basis; however, guideline specifications are given in appendix A of reference 2. Facilities and test control - Acoustic tests must be conducted in a reverberant chamber large enough to maintain a uniform sound field at all points surrounding the test item and to produce reverberant acoustic modes in the lowest third octave band specified. The sound pressure level must be controlled at one-third octave band resolution. The preferred method of control is to average four or more microphones with a real-time device that effectively averages the sound pressure level in each filter band. When real-time averaging is not practical, a survey of the chamber must be performed to determine the single point that is most suitable for control of the acoustic test. Additional information on the test facility, the test control methods, and the test setup are contained in paragraph 2.4.2 of reference 2. b. Payload vibration tests - Random vibration tests must be performed on the protoflight payloads subject to any limitations of the available test facilities to verify the ability of the payloads to survive the launch environments and to provide a final assessment of workmanship. The test is required for small payloads (<1000 lb) and must be assessed for larger payloads on a case-by-case basis. Appendix A of reference 2 provides the maximum expected random vibration levels at the spacecraft interface for various expendable launch vehicles (ELV) and other information and guidance on vibration testing. Additional qualification tests must be performed if expected environments are not enveloped by this test. Sine vibration tests must be added to the verification program if sustained oscillations are expected to occur, or to satisfy other load requirements. Launch random vibration: Protoflight as well as prototype payloads must be subjected to a random vibration test to verify flight worthiness and workmanship. The qualification test limits are the maximum flight levels plus 3 dB. The test is intended for payloads of low (<1000 pounds) to moderate (1000 to 5000 pounds) weight and size such as Scout launched spacecraft, small attached STS payloads, etc. The test covers the full 20 - 20,000 Hz frequency range. For moderate-sized payloads, the test is intended to verify the hardware in the frequency band below 200 Hz where acoustic tests do not excite the payload to the levels it will encounter during launch. The payload in its launch configuration is attached to a vibration fixture by use of a flight-type launch-vehicle adapter and attachment hardware. Vibration is applied sequentially at the base of the adapter in each of three orthogonal axes, one of which is parallel to the thrust axis. The excitation spectrum as measured by a control accelerometer(s) equalized such that the acceleration spectral density is maintained within \u00b1 3 dB of the specified level at all frequencies within the test range and the overall RMS level is within \u00b1 10% of the specified level. If the random vibration test is not performed at the payload level, the feasibility of performing the test at the next lower level of assembly must be assessed. Additional Vibration Tests - If additional vibration tests are required to qualify its performance, the payload is tested in a configuration representative of the time the stress occurs during flight with appropriate flight type hardware used for attachment. Subsystem Vibroacoustic Tests: Subsystem vibroacoustic testing - Subsystems must be exposed to random vibration testing unless analyses show that the test exposures are not needed. Specific test levels are determined on a case-by-case basis. The test levels must be equal to the qualification level (highest predicted flight level +3 dB) predicted at the location where the input is controlled. Subsystem acoustic tests must also be performed if the subsystem is judged to be sensitive to this environment. Additional vibration tests to simulate expected mission environments such as sustained periodic oscillations must be performed if applicable. For very large payloads, the random vibration tests may be impractical because of test facility limitations. In these cases, testing at the subsystem or instrument level must be considered. Component Vibroacoustic Test: Component Vibroacoustic Testing - For qualification as well as screening for design and workmanship defects, components must be subjected to a random vibration test along each of three mutually perpendicular axes. In addition, an acoustic test must be considered when components are particularly sensitive to the acoustic environment. Random vibration testing - Components must be subjected to random vibration along each of three mutually perpendicular axes for one minute each. When possible, the component random vibration spectrum is based on levels measured at the component mounting locations during previous subsystem or payload testing. When such measurements are not available, the levels must be based on statistically estimated responses of similar components on similar structures or on analysis of the payload. In the absence of any knowledge of the expected level, the generalized vibration test specification given in Table 1 must be used. If the hardware contains delicate optics, detectors, sensors, etc., that could be damaged by the levels of the workmanship test in certain frequency bands, the test levels may be reduced in those frequency bands after appropriate management review. [D] Table 1. Generalized Vibration Test Levels Protoflight Components (STS or ELV) (50lb or Less) If possible the hardware, less the sensitive items, should be subjected to the full test levels. As a minimum, all components are subjected to the levels of Table 2, which represent a workmanship screening test. [D] Table 2. Component Minimum Workmanship Random Vibration Levels (50 lb or Less) Refer to Reference 2 for requirements on the mounting of components to test fixtures and other test setup requirements. For very large components, the random vibration tests may have to be supplemented or replaced by an acoustic test if the vibration test levels are insufficient to excite internal hardware. If neither the acoustic nor vibration excitation is sufficient to provide an adequate workmanship test, a screening program should be initiated at lower levels of assembly; down to the board level, if necessary. 2. Acoustic Test - If a component level acoustic test is required, the test set-up and control are in accordance with the requirements for payload testing. 3. Additional Vibration Tests - Additional vibration tests may have to be performed to qualify the hardware for other vibrational inputs expected during the mission; such as a sine sweep to simulate periodic oscillations. Fatigue Life Considerations - The nature of the protoflight test program prevents a demonstration of hardware lifetime because the same hardware is both tested and flown. When hardware reliability considerations demand the demonstration of a specific hardware lifetime, a prototype verification program must be employed, the test durations modified accordingly. Specifically, the duration of the vibroacoustic exposures is extended to account for the life that the flight hardware will experience during the mission . In order to account for the scatter factor associated with the demonstration of fatigue, the duration of prototype exposures are at least four times the intended life of the flight hardware. Acceptance Testing - Vibroacoustic and other vibration testing for the acceptance of previously qualified hardware are conducted at the maximum expected flight levels using the same duration (1 min.) as used for protoflight hardware. The payload is subjected to an acoustic test, and the payload (when practical) and components levels are subjected to random vibration tests in the three axes. As a minimum, the random vibration levels shall represent the workmanship test levels. In addition, subsystems receive vibroacoustic testing as required by project specific requirements. Retest of reflight hardware - The amount of retest that is needed is determined by considering the amount of rework done after flight and by comparing the stresses of the upcoming flight with those of the previous flight. The principle objective is to verify the workmanship and to ensure that structural degradation has not occurred. If no disassembly and rework was done, retests may not be required. The effects of storage and elapsed time since last exposure are considered in determining the need for retest. Subsystems that have been taken apart and reassembled must be subjected ,as a minimum, to an acoustic test (levels are equal to the limit levels) and a random vibration test in at least one axis. More comprehensive exposures must be considered if the rework has been extensive. Performance Monitoring: Before and after each vibroacoustic test, the test item must be examined and functionally tested. During the test, power is applied when appropriate and the performance of the test item is monitored. Technical Rationale: Payloads can be sensitive to the vibroacoustic environment depending upon the degree of coupling between the acoustic excitation and the payload structure. Lightly stiffened, thin-panel type payload structures with large surface areas and low-mass loading are most susceptible to direct acoustic excitation. Truss-type structures are less susceptible to direct acoustic excitation because they have relatively high stiffness and small surface areas; however, the response of truss-type structures to acoustically induced random interface motions may be severe if the truss structure is mechanically coupled to the acoustically sensitive panel-type structures. The acoustic environment at launch is usually the primary source of vibration; however, other transients and sources of vibration can cause hardware problems. These sources include possible torsional oscillations imparted by the launch vehicle, vibrations produced by retro\/apogee motors on the payload, and sustained oscillations due to MECO and pogo effects. References: SPAR-3, Guidelines For Standard Payload Assurance Requirements (SPAR) For Goddard Orbital Projects, March 1990 GEVS-SE, General Environmental Verification Specification For STS And ELV Payloads, Subsystems, And Components, January 1990 D-EH-1, Engineering Handbook For STS Payloads, Part 1: Loads And Structures, September 1982 Space Vehicle Design, Michael D. Griffin and James R. French, 1991 Design of Geosynchronous Spacecraft, Brin N. Agrawal, 1986 quotPowered-On Vibrationquot, Reliability Preferred Practice PT-TE-1405 quotSinusoidal Vibrationquot, Reliability Preferred Practice PT-TE-1406 quotAssembly Acoustic Testsquot, Reliability Preferred Practice PT-TE-1407.","Lesson ID":817}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PD-AP-1318, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Benefit: Reliability of spacecraft structural components is greatly increased, and their cost and weight reduced by the systematic and rigorous application of sound stress analysis principles as an integral part of the design process. Implementation Method: Objectives: Structural stress analysis is performed in order to ensure that a structure will fulfill its intended function in a given loads environment. It is important to anticipate all the possible failure modes and design against them. For a space structure, the most common modes of failure are as follows: Ultimate failure, rupture, and collapse due to stresses exceeding material ultimate strength, Detrimental yielding that undermines structural integrity or performance due to stresses exceeding material yield strength, Instability (buckling) under a combination of loads, deformations, and part geometry such that the structure faces collapse before material strength is reached, Fatigue of material due to crack initiation and propagation under cyclic loads and fracture due to unstable crack propagation, quotExcessivequot elastic static or dynamic deformations causing loss of function, preload or alignment, interference, and undesirable vibrational noise, Other time dependent material failure modes including stress corrosion, creep, stress rupture, and thermal fatigue. A spacecraft (S\/C) structure is usually classified as primary or secondary. The primary structure consists of those elements which react to the overall S\/C bending, axial, shear, and torsional loads. Secondary structure comprises those elements which do not appreciably contribute to overall S\/C stiffness. Non-flight components are referred to as mechanical ground support equipment (MGSE). Structural stress analysis should define and address all the loads acting on the S\/C primary and secondary structures. Table 1 summarizes the most common loads encountered in the space applications. [D] Table 1. Summary of Spacecraft Loads Structural loads are specified at the maximum expected level and referred to as the design or limit loads. Usually, two or more of these loads act simultaneously and their combined effect needs to be considered. Note that the loads environment applied to the structure during the verification testing may be more significant than the loads experienced during flight. Many structural failures have occurred during testing in the past. Therefore, these loads must be considered very carefully in the strength and fatigue calculations. It should be noted that this practice does not address all the possible loads a structure may encounter, such as impact with orbital debris. Analysis Philosophy: The structural analysis should guide the design of the S\/C and sizing of the components and provide a high degree of confidence. The analysis should be an integral part of the design process, thus minimizing design effort and time by eliminating redesign caused by failure during structural verification testing. An important benefit of performing stress analyses is the ability to determine design sensitivities and to conduct trade studies. Thus, effective optimization of the structure can be achieved, enhancing reliability while reducing cost and weight. It is essential for the analysis to be conservative, i.e., the failure load predicted should be less than the actual load the structure can withstand. This is necessary in view of the uncertainties in the analysis assumptions and the variations in the applied loads and material properties within normal bounds. The concept of an overall safety factor (SF) is introduced to account for various uncertainties and the limit loads are increased in proportion to the SF (Ultimate Load = SF x Limit Load). A typical SF value used for the ultimate failure of flight structures is 1.4. In addition, a yield SF typically equal to 1.25 is selected to prevent structural damage or detrimental yielding during structural testing or flight. Additional safety factors may be used for fittings, castings, etc. to account for related uncertainties. The SF requirements may change depending on the responsible NASA center, the sponsoring agency, and the project. In addition to applying a SF, care should be given to conduct a conservative analysis using lower bounds for estimating the structure's load carrying capacity. This will lead to a more reliable design; however, there will be a weight penalty. It should also be noted that the analysis effort decreases with increasing conservatism. Therefore, at the start of the analysis, factors such as weight criticality of the structure, uncertainties in data, and available time for analysis should be considered. Analysis Overview: Stress analysis activities vary depending on the function and maturity of the phase, namely: (a) the Conceptual and Preliminary Design, (b) the Detail Design, and (c) the Verification phases.For the conceptual and the preliminary design activities, the design loads and the safety factors are considered to evaluate the feasibility and adequacy of the load paths and to size the major structural elements. Most of the trade\/optimization studies are conducted in this phase. In the detail design phase, the bulk of the stress analysis activities takes place. Sizing and checking of the load paths is carried out in detail and the design is finalized. In the verification phase, stress analysis is used to analytically show that the structural testing will create the required minimum response (usually 1.25 times the limit loads) and the maximum response will not cause structural damage or detrimental yielding. Analysis Methods: The general method and techniques used in structural stress analysis are outlined in Table 2. A description of each of these activities is given below. [D] Table 2. Stress\/Failure Analysis Outline 1. Determination of the Structural Requirements and Loads: The first step of the analysis is the establishment of the requirements concerning strength, loads, displacements, service (cyclic) life, and verification (reference 1). In addition to strength, the design and sizing is sometimes dictated by maximum displacement requirements. The service life requirements may also dictate design and are to be clearly defined in every structural design and stress analysis activity. A S\/C structure is subjected to a dynamic loads environment due to time varying accelerations, pressures, temperatures, and structurally or acoustically transmitted vibratory disturbances. The time history of loads seen by a specific component will be determined by its relative location as well as its stiffness and thermal paths to the rest of the S\/C. This is determined by means of a dynamic structural analysis of the overall S\/C referred to as quotCoupled Loads Analysis.quot This is usually performed by the quotLoads Groupquot and is out of the scope of this paper. The quotLoads Groupquot provides the stress analyst with given equivalent static loads which envelope the dynamic loads. It is important to make sure that the component does not see higher mechanical forces and this can usually be accomplished by means of checking the resonant frequencies of the structure as discussed under activity 4 below. Coupled loads transient analysis is repeated and refined as the design progresses to provide more realistic and less conservative load levels. Dynamic or time-phased stresses can also be calculated for a structure to determine the actual stress history and peaks. This requires calculation of stresses in conjunction with the coupled loads transient analysis. 2. Material Characterization: Selection of proper materials for a given structure is based on various considerations such as strength to weight (specific strength) and stiffness to weight (specific stiffness) ratios, ductility, resistance to corrosion (reference 2), thermal characteristics, cost, and ease of manufacturability. These and other structurally important material parameters are summarized in Table 3. [D] Table 3. Structural Goals Versus Material Parameters The stress analyst must understand the pros and cons of stock type, material temper, and fabrication processes, since these may significantly affect material characteristics. (reference 3). Certain types of materials, for example, graphite bonded joints, require special consideration and development testing may be necessary for each specific application. For structural model development and stress analysis, the selected material can be classified as follows: Homogeneity - Characterizes the dependence of structural properties on location within the material. Isotropy - A measure of directional dependence of properties. Conventional metals can be classified as homogeneous, isotropic. A composite lamina is homogeneous (macroscopically), transversely isotropic; whereas a laminate is in general nonhomogeneous and anisotropic. Ductility - A ductile material can undergo a significant amount of plastic deformation before ultimate failure as opposed to a brittle material, which fails without any appreciable yield or warning. A ductile material is less sensitive to cracks and flaws since it can yield locally and redistribute the excessive stresses. Reasonable fracture criterion will quantitatively screen out many non-ductile material applications. The classification of materials determines the type and the number of structural properties required in modeling the structure, which is discussed next. 3. Structural Modeling: A mathematical model of the structure is developed in order to predict deformations, internal forces, and stresses. It is based on an idealization of the actual structure using simplifying assumptions on geometry, loads, and boundary conditions. There are basically two different kinds of structural modeling the stress analyst can resort to: Computer model based on a numerical solution of the elasticity equations and boundary conditions that govern structural response. The part is represented using a finite number of degrees of freedom, by approximating the geometry using discretization. The most common numerical method used in structural analysis is the Finite Element (FE) Method. (Reference 4). There are several commercially available FE analysis computer programs. The one most widely used in the industry is NASTRAN. (Reference 5). The structure is represented by a collection of quotelementsquot connected at quotnodal points,quot or nodes, to each other. The governing equilibrium and compatibility equations are satisfied at each of the modal points and solved numerically. Results in the form of modal displacements, element internal forces, and stresses are output. Different kinds of structural analyses (e.g., stress, normal modes, forced dynamic response) that need to be performed should be identified so that the model can be built with necessary and sufficient detail. Analytical or hand calculations based on closed form solutions or empirical data given in various sources for different geometries and loading conditions (References 6 and 7). The concept of a quotfreebody diagramquot is used to isolate and identify the internal forces or reactions acting on the part. For a quotstatically determinatequot case these reactions are calculated based on the equations of static equilibrium. For quotstatically indeterminatequot reactions, additional simplifying assumptions and analyses need to be made regarding structure deformations and load paths. Structure stresses and deformations are determined using the applied loads and the calculated reactions, and based on the solutions or data available in the literature. The analyst can also utilize specialized and proven computer programs such as for the analysis of composites, pressure vessels, and truss structures. It is recommended that both approaches to structural modeling be used. The FE model should contain sufficient detail to represent the overall geometry and the important load paths.However, including quottoo muchquot detail such as fillets, joints, and fasteners may increase the modeling (pre-processing), computing (processing), and results (post-processing) times significantly and sometimes without any appreciable advantage. Including too much detail also compounds the difficulty of the model and the results assessment. Therefore, it is recommended that these structural details be analyzed using the internal forces obtained from the quotcoarsequot FE model and hand calculations. Hand calculations should also be used for the overall structure to approximately verify FE analysis results. 4. Determination of Structural Response: The structural model(s) developed, material properties, and loading conditions are used to calculate the structural response, which consists of displacement, internal force, and stress distributions. An important consideration in the determination of structure's response is whether or not it is linear. For a linear system the response is proportional to applied loads, and the principle of superposition applies, that is, the response due to the application of many loads is equal to the sum of individual responses to each one of the loads. This is not the case for a nonlinear system, e.g., a structure undergoing quotlargequot strain (material nonlinearity). The determination of response for a nonlinear system is much more involved and time consuming than that of a linear system. It also needs to be repeated for different magnitudes of the applied forces and cannot simply be obtained using the principle of superposition as for a linear system. The FE model should be designed to output the internal forces at various critical points of the structure. Corresponding stresses can then be calculated analytically using hand calculations. These calculations can be based on the basic strength of materials equations (References 8 and 9) as well as on solutions given for more complicated geometries in the literature. Some of the most common cases are listed here: bending of beams, torsion of bars, flat plates, shells of revolution and pressure vessels (References 6 and 7), direct bearing and shear stress (lugs and shear pins) (Reference 6), joints and fasteners (Reference 7), and honeycomb sandwich panels (References 10 and 11). For ductile materials under cyclic loading and for brittle materials, stress concentration factors given in the literature (Reference 12) should be used to predict the local stress peaks around geometry\/loading discontinuities. It is necessary to ensure that the equivalent static loads used in the stress analysis conservatively represent the effect of the actual dynamic forces the structure will experience. In the early phases of design (i.e., conceptual and preliminary), this can be verified by determining the resonant frequencies of the structure and making sure they fall within the acceptable ranges determined by the coupled loads analysis. Note that natural frequencies and mode shapes of a structure are defined only for a linear system. They can be determined using the FEM and running an eigenvalue analysis on the structural model, which must possess the correct mass properties. For a nonlinear system, resonance conditions are determined not only by the frequency but also the magnitude of load fluctuations. A forced dynamic response simulation of the structure may be run using the FE model to investigate the resonances of a nonlinear structure. 5. Failure Modes Check: Adequacy of the structure to withstand the calculated forces and stresses is checked by calculating a margin of safety (MS) which is defined as MS = Structure Strength (Force or Stress) - 1 SF x Applied Force or Stress Structure Strength Failure is predicted for MS < 0. Failure stress or force is determined by means of failure theories (References 13 and 14). Some of the most commonly used ones are summarized below: Maximum Normal Stress Theory is used to predict ultimate failure withMS = Ftu \/(SFx smax ) - 1. Here Ftu is the ultimate tensile strength of the material and smax is the maximum normal stress due to the external loading. In general, this theory is more applicable to brittle materials. Maximum Shear Stress (Tresca) Theory is used to conservatively predict ultimate failure for ductile materials. MS = Fsu \/(SF x tmax ) - 1,where Fsu is the ultimate shear strength of the material and tmax is the predicted maximum shear stress. This theory can also be used to predict the onset of yield by replacing Fsu by Fsy, the shear yield strength of the material. Distortion Energy Theory is used for predicting the initiation of yield in a structure and gives more accurate results than the maximum shear stress theory. The margin of safety is given byMS = Fty \/(SF x sVM) - 1, where Fty is the tensile yield strength, and sVM is the so called Von Mises stress. A similar criterion used for the failure prediction of laminated composite materials is the Tsai-Hill Theory (Reference 15). Structural Instability is predicted by first determining the critical buckling load of a structure Pcr. The margin of safety is given byMS = Pcr \/(SF x Pa) - 1,where Pa is the load (compressive, shear) acting on the structure. Pcr for common shapes and loading can be found in the literature, e.g.; buckling strength of columns, flat and curved sheet panels with and without stiffeners, composite shapes, cylinders, crippling References 6 and 10). It is recommended that a conservative approach be taken in the modeling of boundary conditions because they significantly affect the critical buckling load. In certain weight critical cases, a post buckling analysis may be performed to access the remaining load carrying capacity of the structure. It is unconservative to use the quotlowquot stress modulus of elasticity (Young's Modulus) at quothighquot stresses. The value of Pcr depends on the modulus of elasticity which in turn depends on the stress level. Fracture Control Requirements of S\/C parts are outlined in detail in related NASA documents (References 16 and 17). Parts are classified as contained, fail-safe, safe-life or low-release mass and analyzed accordingly. A part is considered contained if it can be shown that even if it broke and became loose, is contained within an enclosure and does not endanger the S\/C (Reference 18). A fail-safe structure is a component with redundant load paths such that failure of one does not lead to the failure of the overall structure. A safe-life part must be inspected for cracks. Also, a crack propagation analysis needs to be performed to ensure adequate service life (Reference 19). A scatter factor typically equal to 4.0 and analogous to SF is used in this analysis. A low release-mass part weighs less than a specified threshold value and is considered non-fracture critical. The effect of simultaneously applied loads on certain structural components is assessed by means of interaction equations. These are empirically based relations used especially for stability (Reference 10) and fastener integrity (Reference 3). Strength of various mechanical components such as springs, bearings, and gears can be assessed based on machine design equations (Reference 14) or load ratings and specifications given by the manufacturer. 6. Optimization and Redesign (if Necessary): Several iterations may be made on the material, configuration, and the dimensions of a component before its design is finalized. Major trade studies and design modifications are considered in the preliminary design phase. Finer details are tuned in the later stages of the design using a similar iterative approach. 7. Documentation: All stress analysis results need to be properly documented with correct references to the models used in analysis, flight and test loads cases, and the safety factors. Proper documentation is essential to a successful stress analysis activity during design, fabrication, and verification testing. Technical Rationale: Systematic application of the stress analysis techniques outlined in the previous section enables the design engineer to establish accurate relationships between structural configuration, size, loading, and strength margins thus leading to more reliable and efficient structural designs. References: quotGeneral Environmental Verification for STS & ELV Payloads, Subsystems, and Components,quot GEVS-SE, NASA Goddard Space Flight Center, Jan. 1990. quotDesign Criteria for Controlling Stress Corrosion Cracking,quot MSFC-SPEC-522B, July 1, 1987. quotMilitary Handbook - Metallic Materials and Elements for Aerospace Vehicle Structures,quot MIL-HDBK-5F, Vol. 1&2, 1 Nov. 1990. quotConcepts and Applications of Finite Element Analysis,quot R. D. Cook, 2nd ed., John Wiley & Sons, 1981. quotUSERS MANUAL - MSC\/NASTRAN VERSION 66,quot The MacNeal-Schwendler Corporation, Vol. 1 & 2, Nov. 1988. quotRoark's Formulas for Stress and Strain,quot W. C. Young, 6 ed., 1989. quotAeronautic Structures Manual,quot NASA Technical Memorandum, NASA TM X-73305, Vol.1-3, Marshall Space Flight Center, Aug. 1975. quotStrength of Materials\/Elementary Theory and Problems,quot S. Timoshenko, 3nd ed., Robert E. Krieger Pub. Co., 1976. quotAircraft Structures,quot D. J. Peery and J. J. Azar, McGraw Hill, 1982. quotAnalysis and Design of Flight Vehicle Structures,quot E. F. Bruhn, S. R. Jacobs and Assoc., Inc., 1973. quotDesign Handbook for Honeycomb Sandwich Structures,quot Hexcel Corporation, 1988. quotStress Concentration Design Factors,quot R. E. Peterson, John Wiley & Sons, 1953. quotFailure of Materials in Mechanical Design - Analysis\/Prediction\/Prevention,quot J. A. Collins, John Wiley & Sons, 1981. quotMechanical Engineering Design,quot J. E. Shigley and L. D. Mitchell, McGraw Hill, 1983. quotMechanics of Composite Materials,quot R. M. Jones, McGraw Hill, 1975. quotFracture Control Requirements for Payloads using the National Space Transportation System,quot NHB 8071.1, NASA, Washington, D. C., 1988. quotGeneral Fracture Control Plan for Payloads using the Space Transportation System,quot NASA Goddard Space Flight Center, 1988. quotContainment Analysis for Fracture Control of STS Payloads,quot Swales and Associates, Inc., 1985. quotFatigue Crack Growth Computer Program - NASA\/FLAGRO,quot Version 2.0, NASA Lyndon B. Johnson Space Flight Center, 1992. Assembly Acoustic Tests, Reliability Preferred Practice PT-TE-1407. Fiber Reinforced Polymer Composite Material Selection, Reliability Preferred Practice GD-DE-2210. Guidelines for Using Flight Loads Analysis as a Spacecraft Design Tool, Reliability Preferred PracticePD-AP-1317. Meteoroids\/Space Debris, Reliability Preferred Practice PD-EC-1102. Pyrotechnic Shock, Reliability Preferred Practice PT-TE-1408. Random Vibration Testing, Reliability Preferred Practice PT-TE-1413. Sinusoidal Vibration, Reliability Preferred Practice PT-TE-1406. Structural Laminate Composites for Space Applications, Reliability Preferred Practice PD-ED-1217.","Lesson ID":819}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1441 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: The reliability benefits of this new valve are that it can be used to transfer gas without risking the loss of the sample or the samplei\u0301s purity. This improved reliability is in comparision to normal refrigeration gas transfer valves which are not leak tight and are not suitable for gas transfer where limited and unique gas samples are available and absolute gas measurements are required. Implementation Method: The purpose of this gas transfer valve was to provide a leak tight method of delivering gases from an Orbiter Aft Fuselage Gas Sampling System (OAFGSS) bottle assembly to a laboratory chromatograph. A commercial gas transfer system was modified to accomplish this task. A tube piercing valve was redesigned to replace the dynamic shaft seal with a compressible hermetically-sealed metal bellows. The redesigned valve and the component parts are illustrated in Figure 1. [D] Figure 1. Valve Assembly and Gas Transfer Set-up The redesigned valve incorporates existing technologies into a compact and most importantly leak-tight device. The metal bellows assembly was obtained from an off-the-shelf valve which was readily available. The body of the valve had to be fabricated; however, the basic idea was obtained from commercial valves. A high vacuum fitting was used as the outlet fitting of the valve due to its excellent ability to provide a leak-tight connection. The redesigned valve also has an adjustable stem travel which allows the stem tip penetration to be set to the desired level without excessive deformation of the tube which could lead to valve leakage. Helium leak checks were made on the valve after its development to determine leak rates and are shown in Table 1. The leak detector was configured to detect helium leaks as low as 1x10-8 standard cubic centimeters per second (sccs) during valve functioning. The values shown in Table 1 indicate that the valve is leak tight. [D] Table 1. Leak Tests on the Gas Sampling Valve Technical Rationale: It was desired by the Space Shuttle Program to determine if and at what levels explosive exhaust gasses were being collected in the Orbiter Aft Fuselage during ascent of the Orbiter. For this purpose, several gas transfer assemblies were developed and flown on the Orbiter. Each of the assemblies were programmed to sample exhaust gasses at several locations and altitudes along the Orbiter ascent trajectory. After a mission, these assemblies were downloaded and taken to a laboratory for gas analysis. Commercial tube piercing gas transfer systems were first used to penetrate the assembliesi\u0301 access tube for chromatography testing. This technique was not suitable in some cases because of valve leakage and not reliable in others because of sample contamination, i.e., smaller samples were sometimes completely lost while other samples became contaminated with atmospheric constituents that rendered the test results meaningless. For this reason, a new gas transfer valve was developed for use that was leak tight and preserved the sample and its integrity during testing.","Lesson ID":816}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1418 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: The practice of using approved nonstandard parts that have been appropriately demonstrated to be acceptable for the applications provides for a wider range of parts selection than are available with standard parts. These parts are at a quality level equal to that of Grades 1 or 2 standard parts. Implementation Method: Any EEE part that does not meet the criteria of a NASA Standard Part by being listed in the NASA Standard Parts List (NSPL) or the Preferred Parts List (PPL) is a nonstandard part that must be reviewed and accepted prior to use. It is the responsibility of the activity selecting the nonstandard part to demonstrate acceptability of the part prior to committing it to a design. Contractors document and approve their selection, application, evaluation, and acceptance criteria for nonstandard parts on a GSFC Form 4-15 (see Figures 1 & 2), Nonstandard Parts Approval Request (NSPAR)(Reference 5). The NSPAR forms are forwarded to the GSFC Project Office for review and GSFC approval. Figure 3 depicts the process flow of the nonstandard parts approval process. [D] Figure 1: Nonstandard Part Approval Request (NSPAR)\/GSFC Form 4-15 [D] Figure 2: Nonstandard Part Approval Request\/ GSFC Form 4-15 (Second Page) [D] Figure 3: Nonstandard Part Approval Process Flow Nonstandard Parts Specifications: Nonstandard parts must be at a quality level equal to that of Grade 1 or 2 standard parts and are procured in accordance with military, NASA, or contractor controlled specifications prepared in accordance with MIL-STD-490. Specifications for nonstandard parts are equal to the requirements of the nearest applicable standard part. Specifications and drawings fully identify the item being procured and include the physical, electrical, and environmental test requirements and quality assurance provisions including parts screening necessary to control manufacturing and acceptance. Specifications also describe marking, handling, packaging, storage of parts and the criteria for testing of parts taken from storage, and address environmental controls for temperature, humidity, particulate contamination, and controls for electrostatic discharge (ESD) for parts which are susceptible to ESD damage. Parts Qualification and Quality Conformance Inspection: Nonstandard parts have qualification bases traceable to test and inspection data at the part level in a manner consistent with the specification requirements of the nearest standard parts. The qualification is based on parts which have been produced by the same manufacturer using the same manufacturing technology as the nonstandard parts for which approval is being sought. Nonstandard parts undergo quality conformance inspection consistent with the specification requirements of the nearest standard parts. Hybrid Microcircuits: Hybrid microcircuits that are not included in the NSPL or the PPL are subject to nonstandard parts control. Their selection and approval is consistent with the requirements of MIL-H-38534B, General Specification for Microcircuits. Additional Parts Requirements Applicable to Nonstandard Parts: The following additional requirements pertain to nonstandard parts as applicable: Derating, Radiation Hardness, Screening Verification Tests, Destructive Physical Analyses, and Parts Identification List (Reference 5). Technical Rationale: The competent selection and acceptance of the proper EEE Parts for spaceflight use is an essential part of design of spacecraft hardware. With the rapidly growing availability of EEE parts that perform major system functions, the selection of parts has become a mainstream activity of electronic design. Further, the assurance that the selected part will perform reliably in the application, whether it be a small component with a limited mission life or an entire spacecraft with a long expected lifetime, continues to be a primary engineering responsibility. References: NASA Standard Electrical, Electronic, and Electromechanical Parts List, MIL-STD-975 (NSPL) GSFC Preferred Parts List (PPL) MIL-STD-490, Specification Practices MIL-H-38534B, General Specification for Hybrid Microcircuits Guidelines for Standard Payload Assurance Requirements (SPAR) for GSFC Orbital Projects","Lesson ID":818}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1234; from NASA Technical Memorandum 4322A, NASA Reliability Practices. Benefit: In addition to improving the timing system's overall reliability by utilizing multiple timing sources, the upgrade from the previous Apollo-era designed system (using LORAN and WWV) provides improvements in the accuracy, monitoring and feedback capabilities. The timing system is used to provide timing commonality between instrumentation systems so data can be referenced with respect to time. Improving the reliability and accuracy of this system improves the time reference capabilities. Implementation Method: The primary time sources of the GPS Timing System are two GPS receivers and an Eastern Test Range UHF timing receiver. Each receiver's output feeds a Time Code Generator whose output feeds an Error Detection and Switching System. The inputs from different receivers are compared for bit error and phase error. Switching to a secondary input is performed if a fault is detected. The output is fed to Distribution Amplifiers for distribution throughout the KSC launch area (see Figure 1). [D] Figure 1. GPS Timing Block Diagram The GPS Timing System is equipped with a computer system that allows the operator to monitor all timing outputs including the signal source, signal level, distribution communication circuit number and end user. The timing signal is also displayed on an oscilloscope. This allows operators to quickly identify any distribution problems. On a daily basis, operators can page through every timing signal distributed from the LCC, checking the code and level of each signal. After checking all signals, the operator places the computer in auto mode, and the computer automatically checks the time difference between a cesium clock and all other timing units (two GPS receivers, the Eastern Test Range UHF timing receiver, two LORAN receivers, the Communication Instrumentation Facility time, ETR time and a portable clock time). The time differences are logged on a printer along with the following information from each GPS receiver: Greenwich Mean Time Satellites being tracked Oscillator control voltage Satellites selected Satellites deselected Antenna status The printout can then be reviewed by the operator and filed as part of the station log for historical purposes. The computer system is also equipped with a program that monitors the Timing Station at night and during other unmanned periods. The program pages through each time unit every 10 minutes, checking the time difference between the units and the Cesium clock. The time difference is logged on disk for use during the next work period when it is imported to a software application that can generate graphs for system analysis. Technical Rationale: Engineers at Kennedy Space Center require timing commonality between instrumentation systems so data can be referenced with respect to time. The development of the GPS allowed for the development of a timing system that is more accurate, more reliable and provides greater monitoring and feedback capabilities than the Apollo-era design it replaces. That system, using LORAN and WWV, resolved time to an accuracy of +\\- 1 microsecond. The GPS system is accurate to within +\\- 200 nanoseconds. Another advantage is that unlike LORAN, GPS satellites are capable of supplying the time and need not be used in conjunction with any other system. References: KSC Drawing - G79K20503, quotKSC Timing System Diagramquot KSC Drawing - 80K54337, quotLCC, Rm 2P22, Timing Systemquot","Lesson ID":820}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1256; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: The major benefit of these design considerations is the greater assurance that loss of power to critical loads and the resulting consequences will not occur. Achieving optimum reliability is of paramount importance in systems that protect life and property. Along with the increase in the reliability of the ATS that is achieved, usually little or no additional design cost is required. Implementation Method: The implementation of these techniques has resulted in the elimination of critical failure modes in Automatic Transfer Switches used in the KSC Shuttle Landing Facility 60 Hertz Power System supporting critical landing aids. Increased system reliability and reduced maintainability costs are inherent features of these practices. Technical Rationale: For critical 60 Hertz Power applications which must use Automatic Transfer Switches (ATS) to provide redundant power sources, it is important to examine the following three design considerations which serve to minimize the probability of ATS failures that could result in loss of power to the load. The first of the three considerations involves the use of ATS's which are designed such that either molded-case circuit-breakers or molded-case switches can be used interchangeably as the switching devices. Only the latter should be used to avoid the possibility of a premature-trip of the circuit-breaker causing total loss of power to the critical load, or depending on the conditions used to cause the ATS to switch, the ATS could transfer prematurely. Whereas a premature transfer is not a critical failure-mode, any unnecessary transfer of an ATS supporting a critical load is undesirable because of the possibility of a system malfunction occurring due to transients or glitches caused by the switch-over. The potential for loss of power to the critical load caused by an open switching device in the ATS brings about the necessity to investigate the second consideration. The second consideration pertains to the technique used to cause the ATS to transfer to its alternate power source. Many ATS's employ a voltage-sensor circuit(s) to detect the loss of preferred input power. When the voltage sensor detects the absence of preferred input power, the transfer is initiated and the ATS switches the load to the alternate power source. In the event that the ATS switching device fails \"open\" as described in the previous paragraph, no transfer would occur because the voltage-sensor at the preferred input would not have detected any loss of input power. The result would again be loss of power to the load. Hence, the only sure way to guard against this failure-mode is to configure the ATS to sense loss of voltage at the \"load\" terminals of the ATS instead of at the \"preferred\" power input terminals. Thus, any internal ATS failure which would otherwise cause loss of power to the load will be neutralized. The intent of providing an ATS in critical power circuits is to eliminate single failures that would cause loss of power to the load. Eliminating the potential for these two types of internal ATS failure-modes significantly reduces the chances of the ATS itself becoming a single-fail point. The third consideration is maintaining the good working order of the ATS, i.e. maintainability and preventative maintenance. Because the ATS is used only for emergency transfer of power, and since maintenance could require taking down the system, regular maintenance may be repeatedly postponed or ignored until a real-time catastrophe reveals that the ATS will not transfer because of a maintenance related failure. Adequate preventative maintenance should not be substituted for convenience. Where possible, scheduled down-time should be used to complete an appropriate maintenance plan. In systems where down-time is not a convenient option, a hardware method of bypassing the ATS to facilitate maintenance should be installed. Designing the system for maintainability allows the required preventative maintenance to be performed without interfering with normal system operation. With the appropriate hardware configuration and preventative maintenance plan in place, optimum reliability can be achieved without any substantial increase in installation or operating cost. Any cost incurred, if any at all, to implement these safeguards is assuredly returned by the avoidance of a single failure of the ATS under worst-case conditions.","Lesson ID":821}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1440 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Specifically, when used in the analysis of Orbiter payloads, the dynamic structural characteristics of a payload created by modal testing can be correlated with finite element models (FEM's) to predict the payloadi\u0301s responses to launch and landing environments as well as any other conditions the spacecraft may encounter. This correlation analysis can also be used to perform coupled loads analyses to ensure that the payload will not have any adverse dynamic effects on the Orbiter. Similar benefits are also derived through modal testing of other space structures. Implementation Method: I. Introduction Modal testing is an experimental means of determining the dynamic characteristics of a structure through mechanical excitation, created either by vibrational or impact methods. This excitation is done to create the mode shapes of the test article which are measured by accelerometers. The data from these accelerometers is then analyzed to develop the dynamic structural characteristics of the test article. The results from the modal testing can then be used to verify the FEM's of the structure being studied. Once the FEM's have been correlated to the modal tests, the results can be used to predict the responses of the structure to any future loads that may be encountered. For Orbiter payload analysis, this correlation can also be used to perform coupled loads analyses to ensure that a payload will not have any adverse dynamic effects on the Orbiter. II. Types of Modal Testing There are three types of Modal testing accomplished at JSC. These are (1) resonant frequency checks, (2) quotminiquot modal survey tests, and (3) full modal survey test. Resonant Frequency Checks. The resonant frequency check is the modal test lab's version of the General Vibration Laboratory's (GVL's) sine sweep test and is the simplest of the tests. As with the sine sweep, the only purpose of this test is to determine the frequencies at which resonances occur. Normally, not enough data is taken to develop either modal shapes or damping values. The benefit of this check over the sine sweep is that all axes can be excited at once, and the modal test lab data acquisition system is capable of taking many more channels of data than the data acquisition system in the GVL. This test requires little laboratory time (less than 1 week) to perform (including test article setup, instrumentation, and data reduction) and can also be used to screen a structure to determine if a full modal survey is needed. Excitation is usually done with a quotsmartquot hammer. quotMiniquot Modal Survey Test. The quotminiquot modal survey test is called this because it is not as extensive as the full modal survey test. The data taken is usually quotexploratoryquot in nature and leads to development of mode indicator functions which determine the frequencies at which mode shapes are generated. Less data is normally taken, curve fitting is not performed, and damping values are not developed as compared to the full modal survey testing. The data generated is useful in verifying existing FEM's, but not enough data is taken to perform FEM correlation. Excitation is generally by a quotsmartquot hammer. This test requires little laboratory time (approximately 1 week) to perform (including test article setup, instrumentation, and data reduction). Full Modal Survey Test. The full modal survey test develops the most data and is the most accurate and detailed of the three types of tests. Frequencies, mode shapes, and damping values are developed. Curve fits are performed on the frequency response functions. Electro-dynamic shakers are generally used; however, quotsmartquot hammers may be used in the preliminary phases of testing. The complete tests may take as long as 7 weeks to perform (including test article setup, instrumentation, data reduction, presentation of results, and final report preparation). The final data can be correlated to FEMs. III.Methods of Excitation Excitation of the test subject can be created either by an electro-dynamic shaker or a quotsmartquot hammer. The electro-dynamic shaker can be controlled to transfer random vibration or sinusoidal vibration to the test subject. The electro-dynamic shaker is preferred over the quotsmartquot hammer in the full modal survey tests because it can be more precisely controlled in regard to input force level and input frequency range. Excitation is transferred from the electro-dynamic shaker to the test article by means of a stinger which is designed to be very stiff axially, but very flexible laterally. A force transducer is included in the stinger to measure the input force, and reference accelerometer is placed on the test article next to the stinger. The quotsmartquot hammer is an instrumented hammer used to provide impact excitation to a test article. A hammer requires less set-up time than a shaker and is good for minimum testing. It can also provide quick preliminary testing of many different locations on the test article in order to identify the location of the best shaker placement. IV.Procedures in Modal Survey Testing In full modal testing surveys at JSC, an excitation is applied to a structure and the input excitation and responses in the form of time histories are measured. These responses are then processed by a data acquisition computer to produce the functions from which modal functions are developed. The block diagram of a full modal survey system as shown in Figure 1 consists of (1) an excitation mechanism, (2) a transduction system to measure the various responses (i.e., accelerometers, force transducers), and analyzer. The input and response output from the test article go through the signal conditioning amplifiers to the analyzer which measures the various signals developed by the transducers which consist of force time histories from the input force transducer(s) and acceleration time histories from the output accelerometer(s). The first stage in analyzing the data, after the raw data has gone through the anti-biasing filters, is the conversion of the time histories from analog to digital signals. The data acquisition computer performs a fast Fourier transform (FFT) on the time histories to convert them from a time to a frequency domain. The data acquisition computer also calculates the discrete Fourier transform (DFT) for a full set of spectral lines. The result of this transform is then used to produce modal survey testing output products such as frequencies, mode shapes, and damping values associated with the test article. [D] Figure 1. Block Diagram of a Full Modal Survey System --- Here V. Modal Survey Non-Linear Testing Occasionally, test articles are found to be non-linear, i.e., their responses change with the level of excitation input. In order to test these structures, drive levels must be selected for excitation which encompass the non-linear response range of the test subject or if this range is too large, to encompass the range of anticipated flight environments of the test subject. Technical Rationale: Modal testing is an experimental technique for determining dynamic characteristics of a structure. Testing is performed by providing an excitation to the structure and measuring the responses which are then used to develop the dynamic characteristics of the structure through testing and comparison to FEM's. Unlike environmental vibration testing which is an end unto itself, modal testing is a means to an end; i.e., modal testing is used to verify the FEMs of a structure which can be used as predictors of the structure's dynamic characteristics over a wide range of environmental conditions. The use of modal testing for verifying FEMs produces much greater confidence in the FEMs as ultimate predictors of structural characteristics. References: Ewins, D. J., Modal Testing: Theory and Practice, John Wiley & Sons, Inc., 1984. Bendat, J. S., Piersol, A.G., Random Data Analysis and Measurement Procedures, 2nd Edition, John Wiley & Sons, Inc., 1986. Halpin, Dennis B., Modal Testing Special Topics, JSC 27161, July 1995. Reliability Preferred Practice PT-TE-1406 Sinusoidal Vibration Reliability Preferred Practice PT-TE-1407 Assembly Acoustic Tests Reliability Preferred Practice PT-TE-1413 Random Vibration Testing Reliability Preferred Practice PT-TE-1419 Vibroacoustic Qualification Testing of Payloads, Subsystems, and Components Reliability Preferred Practice PT-TE-1420 Sine-Burst Load Test","Lesson ID":823}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PD-AP-1317, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Benefit: Flight loads analysis, when used throughout the spacecraft development cycle, will 1) provide a mission specific set of loads, 2) provide a balanced structural design, 3) reduce conservatism inherent in bounding quasi-static design load calculations, 4) provide early problem definition, and 5) reduce surprises at the final verification loads cycle. Implementation Method: The accurate determination of structural loads during all phases of STS (Space Transportation System) and\/or ELV (Expendable Launch Vehicle) flight environments is crucial to spacecraft development. The procedure to calculate these loads involves 1) creation of an accurate spacecraft loads model and its corresponding validation by test, and 2) using this model in conjunction with vehicle\/spacecraft coupled flight forcing functions during the development process. The model is linear and cannot be accurate unless the structure it represents is essentially linear. Finite Element Model Creation: The development of an accurate finite element model (FEM) is crucial to the successful structural design of a spacecraft. It can be used to predict nodal and relative accelerations, member loads and stresses, critical displacements, mechanically transmitted random loads, and thermal distortion loads. In addition, it can be used to perform weight saving studies, deployment studies, static test loads calculations, and control and stability studies. The creation of a FEM should begin early in the design phase of a spacecraft. Even a simple model made from sketches can be useful for preliminary predictions of mass properties, frequency calculations, and primary structure design. As the design matures, more details become available (i.e., mass properties, materials, section properties). At this point, it is essential to understand the analyses for which the model is intended, since this determines the complexity required and the assumptions made in modeling. With the recent advent of very high speed computers (Work-stations, RISC machines, etc.) which are available to today's engineers, the temptation is to create large models which in effect when displayed, look almost like a photograph of the structure. This is often not necessary or efficient, and many times incorrect, especially in the interpretation of results. The engineer should have a clear understanding of the structural load paths, including knowledge about how the actual structure will behave under static and dynamic loading. This is the only way he\/she will be capable to later interpret transient events in the structure. Finite Element Model Checks Model validity must be validated both mathematically and structurally. Throughout the design cycle some of the checks will directly indicate modeling problems, many requiring engineering insight and judgment to assess model validity. The following checks should be performed: Line-by-line check of input data to ensure input accuracy. Static run with fixed boundary conditions and 1G loads applied separately in each primary structural direction, reviewing resultant displacements, forces and stresses for reasonableness, and symmetry (if possible), etc. Fixed base modal run to calculate resultant structural shapes and frequency modes. Results should be consistent with the structural design. Hand calculations should be made to verify simple characteristics such as panel modes. Modal effective weights and participation factors should be tabulated and studied along with animated mode shape displays to gain insight and ensure consistency with design expectations. Modal strain and kinetic energy calculations also yield insight into structural characteristics. The sum of the effective weights for the modes considered should account for almost the total weight in each direction. Free-free modal run to calculate rigid body modes. These modes should be two orders of magnitude less than the first flexible modes, generally less than .001 Hz, to ensure that there is no inadvertent grounding of the structure. Equilibrium checks of the model are calculated by multiplying the free-free stiffness matrix by geometrically derived rigid body modes. Nodes at which the structure is grounded should be displayed in a tabular form. For those models which will be used to predict thermally induced loads and deflections, a thermal equilibrium check is performed in which a bulk temperature change is imposed in a kinematically constrained model which has all thermal expansion coefficients changed to a single value. Negligible element forces should be generated for this case. All rigid elements must be replaced with stiff elastic elements to facilitate proper temperature calculations. Plot element rotations to assure conformity (if applicable). Also generate a boundary plot to verify proper element locations. It is also strongly recommended that extensive verification using a preprocessor with graphic output be used to verify proper load orientation, model construction, etc. Inspection of all FEM software message and warnings which might indicate among other things, improperly shaped elements, ill-conditioning, mechanisms, massless degrees of freedom, and so forth. Mass properties should be compared to current spacecraft weight statements. Comments relative to automatically imposed restraints, in particular, must be verified to be appropriate. Dynamic models reduced by the Guyan reduction technique to facilitate manageable normal modes calculations should be checked with a full-size matrix eigenvalue extraction technique such as Lanczos to assess the validity of the Guyan reduced eigenvalues and mode shapes. An improperly chosen Guyan reduction set may miss modes and result in frequency error. Model Validation: The finite element model is verified via a series of mechanical tests. Instrumentation data acquired during these tests are then compared to the FEM predicted behavior in order to assess the accuracy of the model. Subsequent adjustments are typically made to improve the model correlation to the test data before the model is considered test verified. The static and dynamic response results and the corresponding strength assessment of the structure are solely dependent on the accuracy of the FEM used to calculate these responses. A model uncertainty factor (MUF) is applied to early loads results when coupled loads analysis is used for structural design. The magnitude of this factor may be reduced to 1.0 as confidence in the model is increased through the verification program. Mass Properties Verification: The initial step in the model correlation should be the measurement and correlation of the rigid body mass properties. At the very least, this should include the structural weight. The center of gravity location and rotary inertia values should also be verified to the greatest extent practicable. In specific instances, where the structure has an axis of symmetry or a simple geometry it may be permissible to rely on analytical values at the discretion of the project management. Typically, the mass property adjustments are made by accounting for non-structural mass items such as harnessing, thermal blanketing, or attachment hardware. This adjustment can be included in the model via the use of the non-structural mass parameter on the element property designation or by distributing concentrated mass elements in the region associated with these items. The mass property adjustments will affect both the static and the dynamic characteristics of the structural model making it essential to perform this correlation first. Accurate representation of the mass properties will have the greatest influence on the rigid body component of response which can be the dominant contributor to the total response. Further, for small components or very stiff structures which can be considered rigid bodies, the mass properties correlation is the only verification necessary. Structural Dynamic Verification The modal survey test is the primary test for verifying the ability of the FEM to represent the dynamic behavior of the structure. The goal of this test is to measure the significant natural modes of the structure within a frequency range defined by the frequency content of the loading environment as transmitted by the launch vehicle. If no modes are predicted within this frequency range, a limited modal survey or shaker based sine sweep test should still be performed in order to verify that no modes exist. A pre-test analysis should be conducted in order to predict the natural frequencies and mode shapes and to determine appropriate locations for accelerometers. To assess the choice of a set of potential accelerometer locations, a Guyan reduction, consisting only of the instrumentation locations, should be performed and mode shapes and frequencies calculated. These results should then be compared to the previously calculated modal quantities, for the full model, to assess the adequacy of the test instrumentation set. The principal method of quantifying the similarity of mode shapes is the cross orthogonality matrix. This method of comparison should be used to make the previously discussed assessment of instrumentation and finally used to evaluate the correlation to the measured test data. If the model correlation is perfect, this matrix should be equal to the identity matrix. The correlation is considered adequate when the diagonal and off-diagonal elements of the matrix are within specified values. Once the mass properties are verified, adjustments to the FEM for modal correlation are usually made by the introduction or removal of local flexibilities which may have been based on poor assumptions. These errors can be detected through visual comparison of the test and analysis mode shapes as well as a combination of strain energy or modal effective weight analysis. Spring elements are often included to represent local flexibilities at joints which have originally been assumed rigid. Conversely, rigid elements may be used in instances where electronic boxes or other equipment appear to stiffen an area in which no stiffness contribution was originally assumed. The correct values for these local changes are typically found by iteration and determination of the cross orthogonality matrix. The changes should be demonstrated to be realistic by local detail analysis and not just chosen to match the sparse test values. Automated methods based on sensitivity and optimization techniques are useful to identify areas of likely error. Within this context, all changes should reflect physical reality. Static Verification: Although the purpose of the static test is to demonstrate the strength of the structure, it may also be used as a secondary model verification test. This is usually not possible if the strength test is performed via the sine burst method, but may be appropriate if actual static pulls are used. A pre-test analysis is always performed in order to determine the appropriate test levels and therefore member loads and stress predictions should be available. The actual member loads as experienced in the test are then acquired through strain gage measurements. The locations of this instrumentation should be chosen in order to characterize the primary load paths and are necessary to prove that the qualification levels were attained. Assuming that the measured levels are not in accordance with pre-test predictions, adjustments to the FEM for correlation to the static test data may be applied in a similar manner as discussed pertaining to the modal survey test. It should be recognized that the need for implementation of a significant model change indicated by the static test data could result in an invalidation of the modal test correlation. This situation rarely occurs because the modal test should adequately exercise the structure and the static test correlation should only indicate minor adjustments. Both the modal and static correlation must be based on the model after all changes are made. Coupled Models: The NASA centers have the luxury of having available for themselves and their contractors use, a library of government and commercial launch vehicle FEMs with the appropriate forcing functions to simulate liftoff, staging, on-orbit and in the case of STS, landing events. These models and their forcing functions, when used in conjunction with the spacecraft model, can be used to determine all spacecraft transient responses. This leads to the most accurate prediction of spacecraft loads possible. In addition, time-phased responses can be used to reduce the conservatism resulting from the application of simultaneous bounding quasi-static design loads. The creation of system level models for coupled loads analysis almost always requires the techniques of modal synthesis. This is due to both the size and complexity of the individual instrument, spacecraft, and launch, landing or stage models. Modal synthesis involves 1) reduction of the individual models to manageable and yet dynamically accurate sizes, and 2) coupling of these reduced models to form the overall system level model, ready for forced response calculations. Modal synthesis requires matrix manipulations and transformations, eigenvalue analysis, and extensive bookkeeping to track the structural parameters through the transformations. Typically, a Craig-Bampton modal model of the spacecraft is made which has as its major characteristics, the physical boundary points and cantilever modes defining the vehicle flexibility with respect to that fixed boundary. This form of characterizing the payload not only greatly reduces the model size, but also permits the analyst to check the mass properties, displacements, and accelerations as a rigid body. All parameters of the vehicle are available for later data recovery via the creation of LTMs (Loads Transformation Matrices) in which structural variables are defined with respect to unit boundary and modal acceleration applications. Note that the formulation of the vehicle model may actually require a series of Craig-Bampton reductions for large instruments, antennas, solar arrays, etc. Careful bookkeeping and many checks -- rigid body, 1-G, equilibrium, effective modal weights, mass properties -- are required at each step to ensure accuracy. If rigid body motions are imposed on the physical degrees of freedom of the models there should be zero resulting forces. Adjustments should be made until this requirement is met. The STS or ELV models are delivered in many different formats, but all currently have the attachment portion of the model defined in physical coordinates, which allows for the direct coupling using matrix techniques (i.e., constraint equations , elastic, or rigid elements, direct matrix addition). Any of the current model deliveries, including discrete mass and stiffness matrices, Craig-Bampton models, or residual stiffness models, can be easily handled with these techniques. The coupling procedure should be checked by independent analysis. This is usually done at a NASA center and is initiated by a loads working group consisting of members representing the payload and launch vehicle (including upper stage) contractors. Loads Analysis: The coupled system level model is run through an eigenvalue analysis routine (i.e., Givens, Modified Givens, generalized dynamic reduction, Lanczos) to calculate uncoupled modes and frequencies. These uncoupled modes and frequencies form the basis for the second order differential equations which are integrated to calculate the forced response due to the application of the forcing functions which are delivered with the launch, landing or stage models. In the case of STS, modal damping is incorporated at this point. System level time response accelerations and displacements are transformed back to local vehicle level modal response via the system level mode shapes. A few non-linear degrees of freedom such as for trunnion friction can be incorporated at this level. LTMs and Data Recovery: The methodology used to recover specific data on the vehicle model involves the use of LTMs. LTMs are simply linear transformations which yield physical quantities from modal responses. During the Craig-Bampton model formulation, LTMs are set up at the vehicle coordinate level in which all vehicle parameters including accelerations, displacements, member forces and stresses, and relative displacements are defined with respect to individually applied boundary and modal accelerations. Then, at the system level, the system level mode shapes are used to transform the generalized displacements and accelerations back to the local modal level. The multiplication of these local modal time responses by the LTMs will yield the desired vehicle physical responses. Data recovery is the all important phase of the coupled loads analysis. The engineer must view responses, study min\/max loads, investigate frequency content, etc. until fully convinced that the transient calculations have been accurately carried out. Outputs should include min\/max tables, time response plots, shock spectra plots, finite element plots, animated mode shape plots, timed phased stress calculations, etc. All of these facilitate accuracy studies and final report quality for the end user. Technical Rationale: STS and ELV models are available to NASA centers and their subcontractors. Coupled flight loads analyses using these models with their intended spacecraft complement can be performed in a timely manner and at a reasonable cost. Thus, throughout the development cycle of a spacecraft, from conceptual design to final verification loads analysis, flight loads analyses can be used as a design tool. This process yields a high degree of confidence in spacecraft structural integrity, and the spacecraft models' use in weight reduction studies, control and stability studies, thermal distortion loads calculations, deployment studies, and calculation of random loads, etc. References: 1. Shimizu, M. W., Dattilo, D. O., and Kosick, L. J., \"STS Dynamic Math Models (M6.OZA) for Payloads Analysis\", Rockwell International, STS81l-064F, July 1988 Shimizu, M. W., and Sullivan, A. J., \"Landing Forcing Function 7000 Series Data Base\", Rockwell International, STS86-0020A, February 1988 Haugen, E. A., \"Liftoff Forcing Functions (LR2000 Series) for Payload Loads analysis\", Rockwell International, STS89-0609, April 1988 Frederick, D. H., \"National Space Transportation System Models and Loads Analysis Configuration Management\/Control\", Rockwell International, SD77-SH-0214C, December 1989 \"Proceedings of the Shuttle Payload Dynamic Environments and Loads Prediction Workshop\", JPL D-1347, January 24-26,1984 \"General Environmental Verification Specification for STS and ELV Payloads, Subsystems, and Components,\" GSFC, GEVS-SE, January 1990 Sinusoidal Vibration, Reliability Preferred Practice PT-TE-1406. Assembly Acoustic Tests, Reliability Preferred Practice PT-TE-1407. Random Vibration Testing, Reliability Preferred Practice PT-TE-1413.","Lesson ID":815}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1442 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: This new environmental fixture is much smaller than other larger, bulky environmental fixtures that require long soaking times for even temperature stability over the entire fixture and sample. The smaller fixture has less weight and requires little temperature soaking time for obtaining fixture and specimen temperature stability. This improves the reliability of the test set up as low, long term soaking temperatures can cause armature brittleness and subsequent failure while long term heat soaking of the armature can cause vibrator shaker shutdown. In addition, more data points can be obtained in a shorter period of time with better thermal resolution. Implementation Method: Two small thermal control and conditioning test apparatus' have been developed and utilized in vibration\/thermal testing at JSC for NASA Standard Initiator (NSI) and NASA Standard Detonator (NSD) explosive components. These devices are applicable to all fixturing designs which utilize a flow through manifold for the thermal medium. Although these fixtures were designed specifically for vibrating explosive components under extreme conditions the application could be altered by fabricating fixture(s) to incorporate any type device to be thermally conditioned and\/or vibrated. Photographs of these apparatus' are shown in Figures 1 and 2. Each are fabricated out of aluminum and differ in several ways. Each is fabricated for its appropriate thread type, mounting hole pattern and thermal medium flow manifold. In addition, the NSI fixture has a cover plate where the NSD fixture does not. The reason for this is to minimize the amount of mass the armature has to move during the NSD vibration profile. One main difference between the two fixtures is the transition of the explosive components from one axis to another. [D] Figure 1. Fixture for NSI Thermal\/Vibration Testing [D] Figure 2. Fixture for NSD Thermal\/Vibration Testing In each apparatus, liquid nitrogen is used for cold conditioning the explosive component during vibration testing and is controlled as shown in a block diagram in Figure 3. The system is capable of establishing thermal fixture temperatures as low as -310 degrees F with a temperature gradient across the fixture not exceeding 5 degrees F. A glycol\/water solution is used for hot temperature conditioning. The solution is circulated through the fixture(s) with a Neslab high temperature bath and control circuit with system capabilities of up to 400 degrees F and thermal gradients not exceeding 3 degrees F. Both apparatus' utilize a phenolic insulator plate to minimize thermal soaking to the armature and an armaflex cap to minimize thermal losses. This prevents soak-out and shutdown problems associated with the armature. [D] Figure 3. Block Diagram of Thermal Control of Cooling and Heating Medium Because of the dynamics of the NSI vibration profile a secondary fixture was used to transition from one axis to another. This fixture allows the transition of the thermal fixture from a horizontal plane to a vertical one. This secondary transition fixture is pictured in Figures 4 and 5 with the NSI thermal\/vibration fixture attached in the X and Y vibration planes, respectively. Because of the dynamics of the NSD vibration profile on the other hand, the amount of mass resting on top of the armature is critical, since the profile is demanding close to full power output of the vibration amplifier system. Thus the fixture was designed to have a transition from one axis to another of the explosive components without any extra fixturing. This is done by utilizing both the top and side of the fixture to accomplish the X and Y axes. A 0.018 inch thick shim is used to offset the explosive devices 90 degrees to accomplish the Z axis. [D] Figure 4. Secondary Transition Fixture with NSI Thermal\/Vibration Fixture Attached in X Vibration Plane [D] Figure 5. Secondary Transition Fixture with NSI Thermal\/Vibration Fixture Attached in Y Vibration Plane Technical Rationale: A thermal environmental chamber has been previously used at JSC to thermally condition explosive components that could be mounted to a shaker head and vibrated in three axes (X, Y, & Z). These prior set-ups had utilized a bulky and heavy environmental chamber which required structural supports and bracing to hold it over the shaker head. Liquid nitrogen was used as a cold temperature conditioning media and electric heaters were used for hot temperature conditioning. The environmental chamber had a large air space which created temperature gradients throughout the chamber. Therefore, obtaining a stable thermal condition for the test subject required a great deal of thermal quotsoakingquot time.The time requirement for conditioning the test subject was also increased at cold temperatures because of the need for more thermal accuracy and stability in this test range. This thermal quotsoakingquot acted as a detriment to the shaker armature components which also quotsoaked outquot to the required temperature causing them to become brittle and more susceptible to damage and\/or breakage during the vibration process. Also, when conditioning the test component to a hot condition, the armature ran hotter. If the cooling capacity of the shaker system couldn't keep up with the influx of heat to the armature during the quothotquot test, then the system over-temperature protect circuit shut the vibration test down. All these limitations and inconveniences of the larger environmental chamber led to the development of the smaller, controllable, environmental fixture for vibration\/thermal testing which is the subject of this practice. References: Reliability Preferred Practice PT-TE-1402, Thermal Cycling Reliability Preferred Practice PT-TE-1405, Powered-On Vibration Reliability Preferred Practice PT-TE-1406, Sinusoidal Vibration Reliability Preferred Practice PT-TE-1413, Random Vibration Testing","Lesson ID":822}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1258; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: This practice provides enhanced reliability and availability as well as improved chances for mission success. Failure rates due to space radiation effects will be significantly lower, and thus system down time will be much lower, saving program cost and resources. Implementation Method: Space Radiation Environment, Essential Basics: Radiation in space is generated by particles emitted from a variety of sources both within and beyond our solar system. Radiation effects from these particles can not only cause degradation, but can also cause failure of the electronic and electrical systems in space vehicles or satellites. Even high altitude commercial airliners flying polar routes have shown documented cases of avionics malfunctions due to radiation events. Primary Cosmic rays interact with gaseous and other matter at high altitudes and produce secondary radiation. The combination of both contributes to the Space Radiation environment. The fusion process on the Sun's interior produces electrons and protons in great abundance along with helium and other heavier nuclei, which travel towards earth as the solar wind. This solar wind radiates out from the sun in all directions; but the flux of these particles varies with sunspot activity and solar flares. In addition to the particles originating from the sun are particles from other stars and heavy ion sources such as novas and supernovas in our galaxy and beyond. In interplanetary space these ionizing particles constitute the major radiation threat. These particles are influenced by planetary or earth's magnetic field to form radiation belts, which in earth's case are known as Van Allen Radiation belts, containing trapped electrons in the outer belt and protons in the inner belt. The composition and intensity of the radiation varies significantly with the trajectory of a space vehicle. Experience with many spacecraft since Explorer I shows that higher electron concentrations are observed between 45 degrees and 85 degrees latitude in both the northern and southern hemi-spheres, indicating that the belts descend to a lower altitude in these regions. For low inclination orbits, less than 30 degrees, the electron concentrations are relatively low. Due to the earth's asymmetric magnetic field, a region in the Atlantic near Argentina and Brazil, known as South Atlantic Anomaly (SAA), has relatively high concentrations of electrons. The SAA is known to cause problems such as: single event upsets (SEU) in altimeter electronics gate arrays, and quothardquot SEU's in the Space Shuttle Orbiter's Star Tracker's Analog-to-Digital converter. The March 1991 solar storms significantly increased the charged particle distributions in the Van Allen belts, also creating a third belt. In addition to the trapped charged particles in Van Allen radiation belts (electrons and protons), the spacecraft experience radiation threats from high energy heavy ions in space called Galactic Cosmic rays, and secondary X-Rays or Bremstrahlung generated by particles penetrating the skin of the space-craft while they lose energy. This type of electromagnetic radiation is a significant percentage of the total component producing total dose effects. The usual (Centimeter Gram Second) unit used to specify radiation dose or deposited energy is the quotrad,quot which is defined as 100 ergs\/gm of material. The material is always specified in parentheses, e.g., rad(Si). But the International system of units (SI) defines an essentially Meter Kilogram Second (MKS) units for absorbed dose called the quotgrayquot (GY). One GY is defined as the deposition of 1 joule per kilogram of radiation energy, i.e 1GY = 100 rads. Solar Flares also contribute varying quantities of electrons, protons, and lower energy heavy ions. Solar flares occur randomly at different times, and during times of high solar activity may contribute very high fluxes of particles over periods of hours or days. Heavy ions of various energies cause single event effects (SEE). A convenient way to express the transient charge generated by these heavy ions or charged particles is in charge per unit length, e.g. pC\/micron. However a more frequently used term (but less intuitive) to express the same thing is called, quotLinear Energy Transfer or LETquot, which is expressed in MeV.cm2 \/mg. In bit-storage devices the high energy heavy-ions cause bits to change, and are expressed in terms of bit error rates or SEU Error Probability. The SEU Error Probability is a number generated by computer from three data inputs: (a) the expected distribution of particles vs. LET, (b) the device cross-section for upset or latch up as function of LET, usually obtained from laboratory measurements, and (c) a calculation of expected error rate that combines the first two relationships with a calculation of the effect of the omni-directional particle flux on the charge produced in the device by the incident particles. Computer programs are available that perform this calculation. The net result is a fixed number for the upset or latch up probability. The following rules must be observed for estimating total dose environments: Criteria for Selection of Parts for Enhanced Reliability: For Space vehicles or satellites in low inclination (< 28 degrees) Low Earth Orbit ((LEO), < 500 km or 270 nmi) in both northern and southern hemispheres, typical dose rates due to trapped Van Allen electrons and protons are 100-1000 rad(Si)\/year. For Space vehicles or satellites in higher inclinations (20 < I > 85 degrees) LEO in both northern and southern hemispheres, typical dose rates due to increased number of trapped electrons are 1000-10,000 rad(Si)\/year. There are three categories of components having the following characteristics: Commercial: Process and Design limit the radiation hardness No lot radiation controls Hardness levels: Total Dose: 2 to 10 krad (typical) SEU Threshold LET: 5 Mev\/mg\/cm2 SEU Error Rate: 10-5 errors\/bit-day (typical) Customer performs rad testing, and assumes all risk Customer evaluation and risk Rad Tolerant: Design assures rad hardness up to a certain level No lot radiation controls Hardness levels: Total Dose: 20 to 50 krad (typical) SEU Threshold LET: 20 MeV\/mg\/cm2 SEU Error Rate: 10-7 - 10-8 errors\/bit-day Usually tested for functional fail only, risky Customer evaluation and risk Rad Hard: Designed and processed for particular hardness level Wafer lot radiation tested Hardness levels: Total Dose: > 200 krad to >1 Mrad SEU Threshold LET: 80-150 MeV\/mg\/cm2 SEU Error Rate: 10-10 - to 10-12 errors\/bit-day Latch up: None present in Silicon-on-Insulator\/Silicon on Sapphire (SOI\/SOS) Complimentary Metal Oxide Semiconductor (CMOS)- technologies Exhibit Low SEU sensitivity for SEE's NOTE: Although Class S does not guarantee that the parts are rad-hard, the design process does dictate whether a part is rad-tolerant or not. Using rad-soft components does not significantly reduce cost, but greatly increases risk. There are no components that are ideal for all parameters. IC design requires many tradeoffs in performance (cost included as performance parameter). Commercial components are useful only for commercial applications, where low cost, latest technology (even if it is immature), and high speed takes precedence over extreme temperatures and voltage ranges. Shielding these devices in Space Applications is a futile effort, especially for Single Event Effects such as SEU and Single Event Latch up (SEL). Total Dose Hardness Levels of Various Technologies: It should be noted that Bipolar device operation depends upon minority carrier current levels flowing through the substrate, while Metal Oxide Semiconductor (MOS) technologies operate upon majority carrier current flows at the surface of the substrate. (Junction Field Effect Transistors depend upon majority carrier currents through the substrate). This is what makes their interaction with radiation different . Table 1 shows a comparison of Bipolar to MOS devices and radiation hardness. [D] Table 1: Radiation Hardness Comparison NOTE: Achieving total dose hardness in CMOS-SOS is more difficult than in bulk CMOS, but SOS does appear to offer advantages relative to dose rate, with respect to SEE. Silicon BIPOLAR technology is also heavily utilized in Linear devices, but analog devices require different transistor design characteristics from logic devices whose operation involves simple switching of logic states. Linear devices are affected by radiation in two ways. Low current transistor betas (current-gains) are degraded by surface effects similar to those which degrade MOS devices. Collector current (i.e. base current minus base-emitter leakage current times the beta of the transistor), is thus affected as a result of radiation exposure. When the leakage current (base-to-emitter) increases significantly as a result of radiation, the transistor will not function properly at low current levels, causing problems with input impedance, input offset and open loop gains. Bipolar devices (Integrated Circuits) often contain parasitic MOS devices, which present no problem in logic devices. Bipolar logic circuits typically operate at 5V with logic thresholds below 2V also helps. The parasitics typically have turn-on voltages in excess of 30V. Bipolar linear devices, however, typically operate at higher voltages (with positive- to-negative supply differentials of from 30V to 40V, making them more susceptible to even small radiation induced shifts in the turn-on voltages of parasitics). The problem is partially solved by design layout changes. Other processing characteristics such as the difference between silicon dioxide and silicon nitride (used for surface passivation) can also change the radiation tolerance characteristics of bipolar linear devices. With improvements in current technology, most such devices are rad-hard to one mega-Rad(si) level. One method to compensate for the transistor-to-transistor leakage current effects due to radiation is corrected by using dielectric isolation technique in bipolar devices. Total Ionizing Dose (TID) Effects in CMOS Devices: CMOS-Bulk Devices (IC's) experience quotlatch upquot due to a parasitic four-layer PNPN path, inherent in most unhardened devices. These parasitic four-layer devices act like a Silicon Control Rectifier (SCR), which once latched cannot be turned off without shutting off the power. Radiation hardening for total dose of such devices can be achieved by choice of technology and design changes to minimize the formation of such paths within an Integrated circuit. CMOS-SOS or CMOS-SOI devices do not have such paths and are inherently rad-hard up to one megaRad(Si), but are comparatively more expensive. CMOS-Bulk devices can be made rad-hard by introducing epitaxial layers to reduce the formation of PNPN paths, thus reducing the chances for latch up to one mega-Rad (Si). Single Event Effects (SEE): High energy protons or heavy ions lose their energy mainly through ionization, i.e create electron-hole pairs as they traverse through p-n junctions or the depth of penetration in the semiconductor material. Some of the deposited charge recombines, and some is collected at the junction contacts. The net effect is a very short duration pulse of current that induces transient at internal circuit nodes. The magnitude of the charge, which is generally much larger for ions with high atomic numbers, depends on the energy and ion type, as well as the path length over which the charge is collected. The effect of these random charges on the circuit depends on a number of factors, including the minimum charge required to switch a digital circuit state, called SEU's. Single bit upsets are easy to correct by Error Correction Codes but multiple bit corrections may lead to problems, and can be corrected by redundancy, etc. Also, memory devices are hardened by design to minimize single event upsets. CMOS Static Random Access Memory (SRAM) cells can be hardened by adding capacitors, resistors, transistors or combination of these devices to the circuit, at the cost of circuit parameter degradation especially the speed. If the CMOS-bulk process creates parasitic SCR's or PNPN structures, the excessive charge may cause a Latch up, leading to a SEL, which can sometimes lead to the destruction of the device. It can be minimized by choice of rad-hard process or technologies. CMOS-SOS\/CMOS-SOI, Bipolar and GaAs devices are not prone to latch up or SEL. Latch-up in rad-hard devices is minimized through design and process using (a) numerous, regularly spaced well and substrate contacts in design, (b) thin-epi\/shallow well CMOS processes, and (c) butting of the source-to-substrate and source-to-well contacts. The only certain way to eliminate latch up is to use CMOS-SOS or CMOS-SOI process that eliminates one of the parasitic transistors, thereby removing the possibility of latch up. The problems resulting from SEL's are either immediate or latent damage which may reduce functional performance. Non rad-hard circuits or devices can incur damage from excessively high currents within a few microseconds. Once latch-up occurs, a device would remain in a high current, latched condition until power is turned off. Power cycling will be required each time latch up occurs, which will temporarily shutdown sections of the subsystem that share power supplies. Along with power cycling, circuits and subsystems affected by any component will have to be reinitialized. Another potentially catastrophic SEE phenomenon called quotSnapbackquot exhibits many of the characteristics of latch up and can occur in single MOS transistors structure. It can occur in SOS and SOI technologies that do not contain four-layer parasitic structures. A single high energy particle may trigger snapback if the field across the drain region is sufficiently high. Snapback is due to the prospect of a parasitic bipolar transistor existing between the drain and source region of a MOS transistor which amplifies avalanche current that results from the transversal of the heavy ion Cosmic ray particle. This results in a very high current between the drain and source region of the transistor, with subsequent localized heating. Technical Rationale: To ensure dependable and reliable electronic circuit designs, the radiation environment for Total Ionizing Dose (TID) and Single Event Effects (SEE) encountered at a specific height and orbital orientation during the space-craft mission must be determined. Such data is available from NASA documentation such as SSP 30512, quotSpace Station Ionizing Radiation Design Environmentquot and SSP 30513, quotSpace Station Program Natural Environment Effects Test and Analysis Techniquesquot, applicable to the International Space Station Alpha. Goddard Space Flight Center documentation also provides this information. All electronic devices\/components will experience two radiation-related effects in space. The first, the TID effect is time dependent, and the second, SEE, depends on many factors and is independent of time. The two effects must be addressed separately in design, and as such, this guideline will define basic ground rules for selection of rad-hard devices (radiation tolerant up to a certain specified dose) which can tolerate the effects produced by space radiation, within specified safe limits. If the power is not turned off when latch up occurs in a power Metal Oxide Semiconductor Field Effect Transistor (MOSFET), the avalanche current within the parasitic SCR structure increases indefinitely to cause heating in the gate channel due to I2 R effect and leads to burn-out by a very high energy cosmic ray particle going through the transistor. Another phenomenon associated with the power-MOSFET's is the gate-oxide damage called single-event-Gate-rupture due to the presence of an extremely large electric field, which causes a force on a trapped charge given by [D] where q is the presence of a charge trapped within oxide, v is the potential or voltage across the gate, and d is the thickness of the gate oxide. Both of the mechanisms are fatal to the power transistors. References: David. M Long, quotHardness of MOS & Bipolar Integrated Circuits,quot IEEE Transactions on Nuclear Science, Vol. NS-27, No 6, December 1980 E.G. Stassinopoulos, quotRadiation Environment in Space,quotIEEE NSPEC Short Course, July, 1990 George C. Messenger, and Milton S. Ash, quotThe Effects of Radiation on Electronic Systems,quot Van Nostrand Reinhold Company, New York, NY, 1986","Lesson ID":824}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PD-AP-1308, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Benefit: Circuit analysis for the purpose of evaluating the conducted and radiated EMI from a switching circuit has resulted in the proper design of switching circuit electronics. The devices connected to electronic switching circuits will not be adversely affected by transient currents and associated radiated fields generated by such currents. Implementation Method: Transient circuits are found on many types of analog electronic devices, e.g., thermostats and relays, where the current needs to be switched quotONquot and quotOFFquot at required intervals. Transient currents in these devices can generate a significant amount of conducted EMI. The magnitude of conducted EMI can be expressed in decibels relative to 1.0 microampere m vs frequency after a Fourier Transform from the time domain to the frequency domain. Furthermore, the transient current, when it flows through a wire or conducting line, can make the conductor behave as a radiating antenna. The fields generated by such an antenna (normally expressed in decibels relative to 1 microvolt per meter m vs frequency) can couple to nearby electronic devices, hence degrading their performance. The EMI analysis of switching transients can be divided into three tasks. As noted in the referenced paper, SPICE (Simulator Program with Integrated Circuit Emphasis), one of the most widely used modeling tools for circuit analysis, can be adapted to this type of problem. The switching circuit and all the electronic devices connected to it directly are modeled using the SPICE code. In this process it is important to realize that the switching parameters (e.g. quotON\/OFFquot time, RON & ROFF resistances) must be modeled as accurately as possible. The objective in SPICE modeling is to obtain the quotmagnitude vs timequot profile of the transient current at a location of interest (e.g. across an L, or R, or C component) which would be indicative of the propagation path followed by the transient current that would affect directly other electronic circuits. Once the transient current time-domain profile is known, the Fourier Transform can be calculated. The Fourier Transform is indicative of the magnitude of conducted EMI, at a particular location, as a function of frequency (most conducted emissions are usually in the frequency range of KHz through MHZ). The magnitude of conducted EMI can then be compared with pre-established maximum allowed levels of conducted noise to assess the magnitude of exposure by a susceptible device. If the transient current can be calculated at a location on a conductive line (e.g. wire, cable), it is possible to estimate the amount of radiated EMI emitted by the conducting line as it temporarily behaves as an antenna. From the Fourier Transform previously calculated, the quotmagnitudequot vs quotfrequencyquot component terms are used as driving current sources for the antenna(s) under consideration. A Method of Moments (Ref. 1) code is then used to model the conducting line as a wire antenna and calculate the magnitude of the electric fields as a function of frequency. Figure 1 shows an example of a heater circuit for a battery. The heater circuit consists of two quotON\/OFFquot switching thermostats connected to the heater filament (load) inside the battery. Figure 2 shows a SPICE model of the heater circuits. The transient current due to quotON\/OFFquot switching can be calculated across several of the parameters illustrated in Figure 2. However, since the battery which supplies the thermostats' current also feeds other electronic devices, it is important to evaluate the conducted noise across the battery (V1 in Figure 2). The conducted and radiated emission can be evaluated by following steps 2 and 3 above. [D] Figure 1. Battery Thermostats & Heating Elements [D] Figure 2. SPICE Thermostats Switching Modeling Technical Rationale: It is important to assess the amount of conducted and radiated EMI being emitted from transient circuits to determine if changes are needed to suppress the EMI. References: IEEE International Symposium on EMC, 1988; quotA Simple SPICE Model for Coupled Transmission Linesquot, Clayton R. Paul Analysis of Radiated EMI From ESD Events Caused By Space Charging, Reliability Preferred Practice No. PD-AP-1309","Lesson ID":796}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PD-AP-1301, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Surfaces that are conceivable electrostatic discharge (ESD) sources can be identified early in the program. Design changes such as application of a conductive coating and use of alternate materials can be implemented to eliminate or reduce the ESD risk. Preventive measures such as the installation of RC filters on sensitive circuits also can be implemented to control the adverse ESD effects. Use a validated computer code (NASCAP or other appropriate computer code) to determine the maximum differential charging (V) of each nonconductive surface. When differential charging occurs, an electric field is developed within the dielectric material. The magnitude of the electric field (E) is given by: E = V\/d where d is the thickness of the dielectric material. Usually, when this electric field is greater than 2x105 V\/cm, ESD is likely to occur. To determine the charging level, electrical properties of the nonconductive material must be known. These properties include (but are not limited to) surface resistivity, bulk resistivity, secondary and backscatter electron emission coefficient, and photoelectron yield. For materials with unknown electrical properties, the charging level must be determined by a ground test. In the ground test, the nonconductive surface is exposed to simulated charging environments (mission-dependent) and the resulting charging levels are measured. ESD must not be allowed to occur on surfaces near sensitive radio frequency (RF) receivers and on surfaces near sensitive circuits. For other surfaces, the energy of an ESD should be limited to 3 mJ. The ESD energy can be determined with the following equation: W = 1\/2CV 2 where C is the capacitance of the nonconductive surface with respect to spacecraft ground. The value C depends on the geometry (area and thickness) of the nonconductive surface. The ESD energy as a function of capacitance and charging level is displayed in Figure 1. Usually, the best way to reduce the ESD energy is to limit the value of V. This usually implies the use of a more conductive material. Since the charging current available in the space environment is relatively low, material with resistivity of 109 Ohm-cm is considered adequate for effective charge control. [D] Figure 1: ESD Energy as a Function of Capacitance and Voltage In an environment of energetic electrons, spacecraft surface charging can occur. Due to their high resistivities, dielectric surfaces can be charged to different potentials than the metallic surfaces (which should be at spacecraft ground potential). When the electric field that results from differential charging is sufficiently high, an ESD would occur. ESD is an intense source of electromagnetic interference (EMI). The EMI energies that can be capacitively and inductively coupled to electronic circuits are proportional to both the magnitude and rate of increase (dI\/dt) of the discharge current, respectively. Under most conditions, the discharge current (I) is directly related to the energy (W) of a discharge. By minimizing the ESD energy, the magnitude of discharge current and the magnitude of ESD-induced EMI on circuits can be reduced. The typical energy required to damage a sensitive IC is an order of several \u00b5J. The energy required to upset a circuit is approximately 10 times less. In a typical discharge, only a fraction of the stored electrostatic energy can be coupled to a circuit. The coupling efficiency is dependent on the shielding and geometry of the spacecraft. Restricting the energy of an ESD minimizes the amount of energy available for IC damage and circuit upset, resulting in a more reliable spacecraft. In the Voyager ESD system test program, a 30 mJ discharge did not disturb spacecraft operation. However, differences in spacecraft configurations and circuit protection devices (e.g., RC filters in sensitive circuits) means that the quotsafequot (maximum allowable) energy could be different for different spacecraft configurations. Thus, 3 mJ was chosen as the maximum allowable energy.","Lesson ID":788}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1261; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: This practice validates the compatibility of spacecraft receivers and transmitters. If electromagnetic compatibility problems are identified early in radio design, solutions can be developed, implemented, and verified prior to the integration of the hardware on the spacecraft. Implementation Method: The test configuration should simulate the interconnection of the receivers and transmitters in the system, including simulation of the estimated isolation vs. frequency. The tests are also designed to exercise the full tuning range and the full input signal dynamic range specified for the receiver. Performance criteria which are verified include: Absence of \"self-lock,\" where the receiver does not lock to the output signal from its interconnected transmitter. Absence of \"false-lock,\" where the receiver does not lock to a signal other than its receive frequency applied to the receiver input. Absence of frequency \"pushing,\" where the signal input to the receiver changes the frequency of the receiver's voltage-controlled local oscillators. Absence of dynamic range degradation, both at minimum signal (i.e., receiver threshold) and at maximum signal (i.e., receiver saturation), over the entire receive frequency band. The following RF design components are defined prior to testing: Receiver architecture. Transmitter architecture. Subsystem configuration. System configuration. Receiver\/transmitter isolation vs. frequency estimates. Characterization and verification of spurious responses and spurious emissions is performed as a set of phased activities: Step 1: Characterize the spurious responses at the input port to the subsystem. The result of this effort will be a plot of response levels in dBmWatts vs. frequency. Note: dBmWatt is defined as: 10 log10 (PIN\/1 mW) Step 2: Characterize the spurious emissions at the output port of the subsystem. The result of this effort will be a plot of the emission levels in dB vs. frequency. Step 3: Compare the subsystem spurious response levels with the subsystem spurious emission levels. The emission levels must be substantially lower (a minimum of 9 dB) than the response levels at all frequencies to demonstrate self-compatibility of the RF subsystem. This comparison will produce a plot of the emission vs. response margin in units of dB vs. frequency. Step 4: Translate the emissions of other RF subsystems on the spacecraft as received by the input port of the subsystem being evaluated using the available information on the antenna port-to-port isolation vs. frequency. These translated emissions are then to be compared to the subsystem spurious response characteristics. Again, these translated emission levels must be substantially lower (a minimum of 9 dB) than the subsystem response levels at all frequencies to demonstrate system compatibility. The result of this step will be another plot of the margin in units of dB vs. frequency. Step 5: Translate the susceptibilities of other RF subsystems on the spacecraft to the output port of the subsystem being evaluated using the available information on the antenna port-to-port isolation vs. frequency. These translated susceptibilities are then compared to the subsystem spurious emissions characteristics. These translated response levels must be substantially higher (a minimum of 9dB) than the subsystem emission levels at all frequencies to demonstrate system compatibility. The result of this effort will be yet another plot of the margin in dB vs. frequency. Step 6: The final step is to solve identified problems by filtering the spurious emissions output of each RF subsystem as necessary to restore dB of positive margin below the spurious susceptibility levels. Technical Rationale: Design and development of receivers and transmitters, particularly those located in different subsystems, are often pursued independently. Early identification and resolution of radio compatibility problems requires that the developer: Examine the frequency scheme of each receiver and transmitter on the spacecraft, and identify the known spurious responses and emissions for each. Based on the planned interconnection of each subsystem via the antenna(s), and on the isolation provided between each of the interconnected subsystems, quantify the margin for each subsystem at the input and output ports as a function of frequency. The scheduling of these two activities should be planned to provide time to implement corrective action, such as the addition of RF filters, prior to spacecraft integration. After this time, such solutions become very expensive and pose risks to the spacecraft launch schedule. Related Practices: Spurious Radiated Interference Awareness, Reliability Preferred Practice No. PD-AP-1310 Radiated Susceptibility System Verification, Reliability Preferred Practice No. PD-TE-1416","Lesson ID":793}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PD-AP-1309, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Benefit: The use of a combined SPICE circuit analysis code and a method of moments code for the study of possible conducted and radiated Electromagnetic Interference (EMI) resulting from an Electrostatic Discharge (ESD) event, allow the assessment of EMI noise coupling onto electronic circuit interfaces (Ref. 2). Implementation Method: Background: Surface charging can develop on satellite exterior surfaces as a result of the interactions between the surfaces and the space plasma environment. Considerable research has been done in assessing charging mechanisms that are present when the dielectric surfaces of a spacecraft are exposed to the space plasma environment (at GEO and POLAR orbit primarily). Furthermore, software tools have been developed and utilized for modeling the charging potentials that might be present at several spacecraft locations for a given charging plasma environment. These analysis tools have been useful in the design and configuration of thermal blankets, and other dielectric surfaces on spacecraft. No conclusive theory has yet been developed, but some work has been done in the analysis of the discharge process itself, which occurs when the released charge goes from one surface to another. Nevertheless it is widely accepted that an ESD can occur under vacuum (pressure <105 torr) when either: (a) dielectric surface voltage is greater than 500 V or (b) the electric field between a dielectric surface and a conductor is greater than 105 volts\/cm. Finally, when an electrostatic discharge occurs, the release of stored charge creates a discharge current that can generate conducted emissions and radiated emissions. Conducted emissions occur as a result of the replacement current that originates when charge is blown off the dielectric surface inducing a replacement current to flow from the satellite structure. Radiated emissions are generated by the ESD current pulse. The rapid surface potential change induces noise in circuits through capacitive coupling. The discharge current can also induce an inductively coupled signal into the victim circuit. Furthermore, radiated emissions can cause diverse forms of field-to-circuit coupling. Capacitive, inductive and field-to-circuit coupling scenarios are manifestations of conducted and radiated EMI, and are characterized by electrical noise on a victim electronic component or circuit. This induced electrical noise, which is transient by nature, can interfere with nominal current and voltage levels of electronic components causing transient data or command interruptions or, even worse, permanent component damage. Analysis Steps: I. ESD-EMI Topology: This is the first step in EMI analysis from ESD events. A study is performed of spacecraft assemblies and sub-assemblies to identify: a) the most likely locations for spacecraft charging and ESD to occur, b) the most likely location and types of conductive path(s) which will be followed by the induced current after an ESD event, and c) the most likely susceptible circuits within a spacecraft that can be affected by an ESD event. This preliminary work is needed to characterize the topology under which ESD events occur. Figure 1 illustrates a simple example of an ESD event on a shielded cable from the solar array. [D] Figure 1. ESD Events Due To Spacecraft Charging II. EMI Coupling Phase: This is the second step in EMI analysis from ESD. Because of the complex physics involved in conducted and radiated EMI coupling, an approximation technique consists of the use of L,R,C (inductive, resistive, capacitive) network representations between surface charging and possible ESD paths. This technique provides acceptable results for low frequency, typically less than 50 mHz (l >> l,l being the size of the device affected by ESD and l being the wavelength) EMI analysis. The coupling phase task involves the development of an electronic network representation to model the coupling parameters between a charging surface and a susceptible device or conductive path. The network representation will be useful in the evaluation of several characteristic parameters of ESD events such as current and voltages at desired locations. Figure 2 describes a very simple EMI coupling scenario between a solar array (the charging surface) and a spacecraft shielded cable component. The ESD topology phase previously described is a prerequisite for the development of the coupling phase. [D] Figure 2. Lumped Element Parameters For ESD Event Between Solar Array And Cable III. ESD Event Phase: This phase involves the use of Simulator Program with Integrated Circuit Emphasis (SPICE) or another circuit analysis code to calculate currents and voltages at discharge locations. Figure 3 describes a simplified LRC network representation of the ESD event for the example in Figure 2. [D] Figure 3. Circuit Representation of Solar Array to Spacecraft ESD IV. Induced Current Propagation Phase: This final step involves the usage of method-of-moments in computational electromagnetics to model the conducted path(s) and the lumped-network representations of circuits and devices connected to such paths. The method-of-moments will calculate the noise current distribution at any location on the conducted path(s) or circuits. From an assumed current waveform the conducted noise emissions in the frequency domain can then be obtained. The calculated noise current spectrum is also used for evaluating the radiated EMI noise by using simple radiator models. Figure 5 describes method of moments modeling for evaluating the induced noise current on the shielded cable of Figure 4. [D] Figure 4. Physical Representation of Shielded Cable Inside Spacecraft Structure [D] Figure 5. Method Of Moment Modeling of Shielded Cable Technical Rationale: The emphasis on ESD through the years has been on minimizing the occurrence of such events through: (a) a better understanding of the charging processes that occur on different types of dielectric materials used in a spacecraft, (b) a better understanding of the space plasma environment, and (c) following several EMI rules concerning shielding, grounding and bonding. However, there is a need to analyze the EMI effects of actual electrostatic discharge processes because it is usually not possible to eliminate all sources of ESD. References: 1. IEEE International Symposium On EMC, 1988; quotA Simple SPICE Model For Coupled Transmission Linesquot, Clayton R. Paul Perez, R., quotAnalysis of Electromagnetic Interference Effects in Spacecraft Generated by Electrostatic Discharges using the Method of Momentsquot, 6th Annual Review of Progress in Applied Computational Electromagnetics, Monterey, March 19-22, 1990 Design and Analysis of Electronic Circuits for Worst Case Environments and Part Variations, Reliability Preferred Practice No. PD-ED-1212","Lesson ID":797}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1240; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Early identification, tracking, and control of critical items through the preparation, implementation, and maintenance of CILs will provide valuable inputs to a design, development, and production program. From the CIL activity, critical design features, tests, inspection points, and procedures can be identified and implemented that will minimize the probability of failure of a mission or loss of life. Implementation Method: I. Background The Failure Mode and Effects Analysis (FMEA) is performed to identify failure modes. As part of this process, critical failure modes that could lead to loss of life or loss of mission are also identified. These critical failure modes are then placed into a CIL, which is carefully examined for programmatic control by implementing inspection requirements, test requirements and\/or special design features or changes which would minimize the failure mode occurrence. Failure Mode and Effects Analyses and resulting CILs can be used not only as a check of the design of systems for reliability, but also as main design drivers for the product or service. Reliability management is the activity involved in coordinating the reliability analyses of design, development, manufacturing, testing, and operations to obtain the proper performance of a given product under specified environmental conditions. Reliability management interfaces with the program management function, the design function, the manufacturing function, the test and inspection function, and the quality function. Reliability management is approached through the formulation and preparation of reliability plans, the performance of specific product design analysis, the support of classical reliability analysis activities, and project\/product team participation using concurrent engineering methodologies (see NASA Reliability Design Practice GD-ED-2204). The FMEA\/CIL Process (shown on Figure 1) plays a key role in reliability management. Principal outputs of the FMEA\/CIL process are CILs (shown on the lower right-hand corner of Figure 1). [D] Figure 1. FMEA\/CIL Analysis Process II. Critical Items Lists and Retention Rationale Specific lessons have been learned that will change the value of preparing and maintaining (CILs) early in high-technology, multi-disciplinary aerospace programs and projects. Critical Items Lists are identified through the conduct of a Failure Mode and Effect Analysis (FMEA). The FMEA Process (see Reliability Preferred Practice No. PD-AP-1307) involves a bottom-up analysis of each hardware or software element in a complex system for each possible failure mode. The determination of the i\u0300worst casei\u0302 effect of that failure on the system is then determined. If the item can fail in a mode which could result in the loss of life or vehicle or in loss of the mission, the item is placed on a Critical Items List. The FMEA, and resulting CIL, is most effective when it is performed concurrently with the design process and maintained throughout the life of a program or project. The FMEA results in the identification of single failure points (SFPs) and critical redundant items. A typical SFP is defined as a single item of hardware (usually at the component level) the failure of which could result in the loss of life, vehicle, mission, or damage to a vehicle system. It is the general policy of NASA not to permit the retention of single failure points in design unless special conditions prohibit designing it out, such as technology, operations or cost. Retention of a single failure point requires that a justification or rationale be prepared which describes actions taken, safety margins, failure prevention measures, tests, or inspections that will ensure that the critical item of hardware will not fail in the mode indicated in the FMEA. Typical rationale for retention of hardware or software items on a projecti\u0301s Critical Items List includes information on design, testing, inspection, failure history, and operational use as described below: Design Rationale: Design rationale identifies design features and\/or margins that have been provided in the design of the hardware or software element which minimize or eliminate the probability of occurrence of the failure mode and\/or reduction or elimination of the potential causes of the failure mode. Test Rationale: Test rationale includes a description of specific tests that have been completed to detect potential failure causes during acceptance and certification tests. Inspection Rationale: Inspection rationale addresses specific inspection methods, procedures, tools, and techniques that are used in the hardware or software manufacturing, assembly, and integration process to detect susceptibility to failure modes or to detect and assess the probability of encountering failure modes and their potential causes. Failure History: Failure history and corrective actions are included as a part of single failure point critical items retention rationale to indicate that the reason for previous failures has been removed or reduced as a potential hazard, and to provide trend analysis. Operational Use: Special operational techniques that would either prevent the particular failure mode or mitigate its effect once it has occurred are included as part of the retention rationale. This rationale includes such factors as flight rules, crew procedures, such as emergency stop features or special crew training. It also includes contingency actions such as extravehicular activity and unplanned in-flight maintenance procedures. The flow of these facets of retention rationale are shown on Figure 2. [D] Figure 2. CIL Retention Rationale Process III. Suggestions for Effective CIL Implementation Correlation of FMEA Results with Fault-Tree Analyses and Hazards Analyses: The FMEA\/CIL data can serve as an input to the hazard analysis process. The hazards analysis uses fault trees and is basically a top down approach. It focuses on human errors and considers multiple unrelated failure modes which the FMEA\/CIL ground rules out. The Use of Probabilistic Risk Assessments: Probabilistic risk assessments have proven to be useful procedures in providing product development teams with an insight into factors of safety and to strengthen critical item or single failure point retention rationale. Margins of safety have a strong influence on the acceptability of retaining potential failure modes or critical items if it can be proven that risk of failure is reduced to an acceptably low level. Process, Equipment, and Facility Critical Items Analyses: Failures in manufacturing, assembly, and test processes, equipment, and facilities have only an indirect effect on the freedom of flight hardware and software from mission or life-threatening occurrences. Nevertheless, the conduct of process, equipment, and manufacturing facility FMEAs can provide valuable assistance in identifying critical items whose failure could impact system performance or availability. Statistical process control methods, if used prudently in the manufacture of hardware can assist in the detection of conditions which could lead to impending failures affecting performance or schedule. Computer-Aided Management of Critical Items: Common numbering systems coupled with the use of electronic data processing techniques, can speed up the CIL implementation and management process. Where failure modes or causes are identical or related for various system elements, these failure modes or causes can be referenced rather than repeated, reducing the volume of text in retention rationale. Critical item listings can be more easily referenced to corresponding information derived from fault-tree analyses and hazards analyses if there is a common numbering system. CIL Retention Rationale as a Road-Map: Critical Item List retention rationale that is developed very early in hardware or software programs can be used as a road-map for development plans, tests, and inspections. Development program content, then, can be tailored specifically to prevent loss of mission, vehicle, and human life. This road-map could be used to identify inspection points and to help avoid too many series inspections of the same hardware. Critical Items List should be worked in a way that would not impact important program milestones or create unnecessary work-around in the areas of cost, schedules, or performance. For example, processing methods are needed to quickly disposition discrepancies in critical items. IV. Example Uses of Critical Items Lists The uses of CILs are many. Among the more important uses are: (1) analysis of a product, process or project for reliability and failure avoidance before, during, and after the design process; (2) evaluation of the impact of design, material, or fabrication changes on reliability; (3) assessment of failures experienced during testing; (4) recommendation of design changes that will avoid failure recurrences; and (5) determination of the risk of retaining mission critical or life endangering single failure points or redundant failure modes. Some specific examples of typical applications of the FMEA\/CIL methodology as an aid to design follow: Spacelab Recertification after the Challenger Incident During the Spacelab recertification effort after the Challenger accident, the FMEA revealed a potential single failure point in the jettison circuitry of the Inertial Pointing System (IPS). A condition existed in which a short in the emergency arming switch could cause the firing of all four NASA Standard Initiators (NSIs). The analysis also revealed that the harness separator would not fire under these conditions. The detailed FMEA analysis of the wiring harnesses also revealed several mission critical wiring anomalies that had to be corrected. Additionally, the payload retention latch assembly was found to be in need of a redundant operational mode. As a result, redundant end switches were added. Redesigned Solid Rocket Motor (RSRM) Project During routine review and assessment of the CILs for the RSRM, it was observed that the specifications for the finish of the secondary sealing surfaces for nozzle joints three and four (inlet to throat joints) were inadequate to retain a 1R criticality ranking (which is a criticality 1 failure mode but with a second or redundant system). Defects of up to 50-mil depth were permitted on the secondary sealing surface while defects of only 3-mil depth had to be reworked for blending if they occurred in the primary seals. A CIL analysis indicated that actually a criticality 1 (potential loss of life) criticality ranking existed. Space Shuttle Main Engine (SSME) Independent Risk Assessment Team When contamination was discovered in the bearing cage of SSME No. 1209, a special independent risk assessment team was established to assess the problem and to determine if the engine was safe to fly. The team relied heavily on the FMEA\/CIL analyses that had already been performed by NASA\/MSFC and the SSME contractor personnel in order to understand the potential for failure and possible safety hazards. The team identified rationale for retention of the condition that caused the contamination, and the engine was judged safe to fly. This engine subsequently flew (many missions) successfully with no indication of potential failure. Technical Rationale: Extensive analytical work on existing and emerging programs relative to failure identification, management, and control has resulted in well documented, rigorous procedures for the treatment of critical items. Concurrent engineering approaches to program engineering and management have included attention to more details earlier in the design process and at a much lower level than previously attained. Assurance of success means the elimination or reduction of potential failure modes. Elimination or reduction of potential failure modes can only be achieved through the conscientious application of failure mode and effect analysis, critical item identification early in the concept\/design phase, and prudent engineering management. The advantages of the FMEA\/CIL process are that it: (1) Systematically identifies all credible failure modes and causes; (2) permits a focus on critical single failure points and levels of redundancy; (3) provides risk acceptance rationale for critical failure modes\/causes; (4) provides management control of critical items, associated procedures, specifications, and processes; and (5) provides a single, agreed-to listing of all critical items associated with a given project. References: Requirements for Preparation and Approval of Failure Modes and Effects Analysis (FMEA) and Critical Items List (CIL), NSTS 22206, Revision D, Lyndon B. Johnson Space Center, Houston, TX, December 10, 1993. MSFC Shuttle Elements Lessons Learned for the ASRM Project, George C. Marshall Space Flight Center, September 14, 1993. Space Shuttle Failure Modes and Effects Analysis (FMEA) and Critical Items List (CIL) Groundrules, George C. Marshall Space Flight Center, November 5, 1986. Payload and Experiments FMEA\/CIL Groundrules: Marshall Space Flight Center, Report #CR5320.9, MSFC, Alabama. Reliability Preferred Practice No. PD-AP-1307, Failure Modes, Effects, and Criticality Analysis, Jet Propulsion Laboratory.","Lesson ID":803}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1427 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Highly instrumented engine system tests of varying configurations under varying conditions provides engine system level validation of advanced propulsion technology concepts prior to incorporation of these concepts into development or production units; provides an opportunity for greater understanding and fine-tuning of analytical tools that characterize engine performance; results in the development and improvement of diagnostic methods; and increases the depth of available knowledge about the inner workings, sensitivities, and detailed performance characteristics of liquid rocket engine systems. The overall benefit are the validation of technology, improved system performance, high system reliability, and mission safety. Implementation Method: Experience in the planning and conduct of propulsion technology tests using the Space Shuttle Main Engine (SSME) has resulted in a systematic and methodical procedure for planning, testing, data analysis, and reporting the results of test bed activities. As seen in Table 1, the testing has ranged from evaluation of new engine components and features, to advanced diagnostic and sensor techniques, to the development of systems for anomaly and failure detection. A key to the continued success of this program has been a technology integration process that places emphasis on integration requirements and costs at an early point in the process. Figure 1 is a flow diagram that depicts the technology integration process. Once an engine technology item has proceeded through the concept evaluation process to a point where a decision is made to pursue test bed evaluation, it is presented by the principal investigator to the Test Bed project manager for prescreening review and then a technology item screening review. [D] Table 1. Typical Types of Technology Test Bed Testing [D] Fig. 1. Technology Test Bed Technology Integration Process In the screening review, an engine technology candidate is judged by its technical merit and potential benefit, the risk of testing the item on the Technology Test Bed engine, and the cost of integrating the item into the engine or facility. Key milestones in the process are Technology Item Screening, the Technology Item Final Design Review, the Integration Design Review, and Hot Fire Testing. Technology Item Final Design Review: Once the technology item is accepted as an output of Technology Item Screening, technology item development proceeds with the conduct of analytical studies, component testing, and the incorporation of design revisions, if required. Then a Technology Item Final Design Review is conducted in which four subject areas are presented and discussed: (1) Technology Item Design Description; (2) Technology Item Design Verification; (3) System Issues; and (4) Safety\/Quality Issues. The Technology Item Design Description includes the design configuration and characteristics; the design intent or function; the design requirements; materials and processes, drawings and an integrated design configuration. The Technology Item Design Verification consists of the qualification approach, test and verification plans and results, supporting analysis and assurance that the design and performance meets the intent of the requirements. System Issues include system requirements, system compatibility issues, integration plans and issues, constraints, and Technology Test Bed test operational requirements. Safety\/Quality Issues include quality assurance provisions such as fabrication processes and controls, traceability, vendor qualification, and nondestructive evaluation techniques; technology item life; risk assessment; hazards analysis; failure modes and effects analysis; risk mitigation; materials certification; and supporting analyses. When the technology item final design review is successfully completed, fabrication can proceed and readiness certified upon acceptance. Technology Item Integration Design Review: The integration review is conducted to verify that the technology item can be accommodated safely and effectively into the TTB. It consists of: (1) an Integration Design Description; (2) Integrated Design Verification; (3) System Issues, and (4) Safety\/Quality Issues. The subject areas covered in the Technology Item Integration Design Review are similar to those for the Technology Item Final Design Review except that all factors are viewed from the standpoint of interaction of the technology item with the Test Bed and its related subsystems, facilities, instrumentation, software and data. Hot Fire Testing and Results: A test plan is prepared for each test series, and it is reviewed at a pretest readiness review before each test. Instrumentation is configured in accordance with an Instrumentation Program and Command List (IP&CL). A test results review is held after each test and a test report is prepared. When two or more tests are combined into a test series, a test series report is prepared. Examples of these documents are included in the list of References for this practice. Technical Rationale: In the conduct and analysis of over fifty tests conducted in the Technology Test Bed program by MSFC since September 1988, the SSME TTB program has proven to be an indispensable tool in the validation of propulsion technology advances for large liquid oxygen\/liquid hydrogen rocket engines. The program has also yielded numerous advances in measurement and diagnostic methods that are continuing to be used in the TTB program and are applicable to other similar test and evaluation scenarios. The TTB's highly instrumented engine employs over five times the number of measurements used for an acceptance test of a flight engine. This in-depth instrumentation using flow meters, steady state pressure transducers, high frequency pressure measurements, thermocouples, strain gauges, accelerometers, and sophisticated laser and optics techniques has provided an unprecedented amount of detailed knowledge of the performance subtleties of large O2\/H2 engines under widely varying conditions. The program has yielded results that have permitted the incorporation of state-of-the-art technology advances without compromising engine reliability. References: quotSSME Improved Characterization Using Highly Instrumented Engine Test Data,quot B. Piekarski and J. Leahy, Martin Marietta, AIAA\/SAE\/ASME\/ASEE 28th Joint Propulsion Conference, July 6-8, 1992, Nashville, TN, AIAA # 92-3451. quotSpace Shuttle Main Engine Technology Test Bed overview,quot H.V. McConnaughey, Advanced Earth-to-Orbit Propulsion Technology Conference, 1992, Huntsville, AL. quotTechnology Test Bed Program: Engine 3001 with Instrumented Turbopumps,quot NASA\/MSFC Test Series Report No. TTB-DEV-EP93-001, January 15, 1993, Huntsville, AL. quotTechnology Test Bed Test Report: Engine #3001,quot NASA\/MSFC Report # EP52(92TR-033), August 1992, Huntsville, AL. quotTechnology Test Bed Program: Instrumentation Program and Command List,quot NASA\/MSFC Document 1618, November 1989, Huntsville, AL.","Lesson ID":806}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1426 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Penetrant Testing is a cost effective, nondestructive method for determining cracks, porosity, gouges, laps, seams, and other flaws that are open to the surface of metallics and selected non-metallics. Implementation Method: Liquid penetrant testing is a nondestructive method of detecting surface flaws in solid material and structures. Cracks, porosity, gouges, laps, seams, and other types of flaws can be found using this technique. Penetrant testing is a process in which the liquid penetrant is drawn into small openings by capillary action when it is applied to a surface. After a specified time, excess penetrant is removed from the surface and developer is applied to the surface. The developer absorbs residual penetrant drawn from the flaw leaving a bright-colored penetrant i\u0300bleedingi\u0302 through the developeri\u0301s white background giving a clear visual indication of cracks, porosity, and other flaws. There are numerous types and sensitivities of penetrants. The penetrant systems, consisting of penetrant, developer, and cleaner, must be selected for component compatibility and be suitable for use on the test article. In addition to the specific requirements for actual penetrant test, initial surface preparation and final cleaning often requires detailed procedures. Table 1 shows five sensitivity levels for penetrants. Penetrants have been developed for specific applications for ferrous metals, nonferrous metals, glass, polymers and ceramics. The penetrant must also be compatible with the test article to avoid material degradation and possible explosion. For example, the chemical combination of incompatible penetrant materials, the container material, and liquid oxygen, combined with impact or shock, can cause an explosion. Common properties and characteristics of suitable penetrants are listed in Table 2. [D] Table 1. Sensitivity Levels for Penetrants [D] Table 2. Properties and Characteristics of Penetrants There are six basic steps required to perform a penetrant test. These six basic steps are shown in the flow diagram on Figure 1. [D] Figure 1. Penetrant Test Flow Diagram The most common cleaning methods are application of solvents, vapor degreasing, detergent cleaning, steam cleaning and ultrasonic cleaning. Mechanical cleaning using wire brushes, abrasives, emery cloths, or metal scraping are not recommended. However, if mechanical cleaning must be used, light chemical etching is required to reopen any closed flaws. Penetrant testing should be accomplished before any paint or metallic coating is applied since these coatings will close any flaws. The success of penetrant testing depends upon the visibility of flaw indications. To ensure visibility, the penetrant contains either a colored dye easily seen in white light, or a fluorescent dye visible under black (ultraviolet) light. A list of penetrants typically used is listed in reference 4. The penetrant is applied by either dipping, spraying, brushing, or flowing. After penetrant application, a sufficient time (dwell time) is provided to permit the penetrant to permeate the flaw. The manufacturers of penetrants provide the minimum dwell times charts. A typical dwell time chart is shown in Table 3. The penetrant must not be allowed to dry during the dwell time, and must remain wet until the excess penetrant is removed. If penetrant has dried, then the process must be repeated. [D] Table 3. Typical Dwell Time Chart Removal of the penetrant depends upon the type used. The most common methods used are water washable, post emulsified, and solvent removed. Care must be exercised to ensure that the specimen is not over cleaned, thereby removing the penetrant from the flaw. Generally, a developer is required, although some penetrants are formulated for use without a developer. A whitish powder in the developer is very absorbent and acts as a blotter. This blotting action carries the penetrant from the flaw into the powder, forming a flaw pattern. Inspection of the specimen consists of analysis of the patterns on the developer and determining their cause. Inspection may reveal patterns that are either true indications or false indications of a flaw. The true indications are those caused by penetrant bleeding from the actual flaws. Improper cleaning in the initial cleaning step and incomplete removal of the excess penetrant are common causes of false indications. False indications sometimes look like and may hide true indications. If there is doubt about the source of a pattern on the developer, the test should be repeated and the patterns carefully analyzed as they develop. The ability to identify true indications requires much practice. For example, cracks, cold shunts, seams, and forging laps all show up as a continuous line. The same flaws may show up as an intermittent line indicating that the flaw may be partially closed at the surface. Small dots and round indications generally indicate porosity, small inclusions, or blow holes. If the defect is located below the surface, the sensitivity of this method diminishes rapidly with depth. Penetrant inspectors should be qualified and certified in accordance with MIL-STD-410E or SNT-TC-1A. To provide permanent records, photographs of the specimen should be taken prior to post cleaning. Post cleaning is only required of those specimens that are found free of defects. Defects are described by engineering or as specified in MIL-STD-1907. Post inspection cleaning is necessary since the penetrant and developer residue tend to attract moisture, which can cause corrosion or can interfere with subsequent processing or usage. The cleaning methods for post inspection cleaning are generally the same as those recommended for precleaning. Advantages and disadvantages of the penetrant testing method are shown in Table 4. [D] Table 4. Advantages and Disadvantages of Penetrant Testing Method The hazardous properties that should always be considered when using a dye penetrant are liquid flashpoint and toxicity. The flashpoint of penetrant processes can be as low as 40oF to as high as 200oF. The penetrants should be used per manufacturer's instructions. Most penetrants are not actually toxic and do not present a particular hazard in normal use. However, there are precautions that should be followed. Practically all liquid materials used in penetrant, cleaner, and developer have good wetting and detergent properties. Therefore, they exhibit excellent solvent power for fats and oils. These materials, when allowed to contact the skin for an extended period, will dry out the natural oils from the skin, causing it to become rough, red, and if left untreated to eventually crack open, which could cause a severe secondary infection. This is preventable by wearing neoprene-type gloves and aprons, face shield, and protective clothing. If exposed to this skin drying, replenishing the oils on the exposed skin should prevent any cracking. Another hazard with penetrants is the using of dry developers which could be inhaled and become a health hazard. The use of any of the penetrant processes should be performed in a well-ventilated area. If working in a confined area such as a tank, the inspector should have an individual air supply with a full helmet over the head. The black light used when inspecting fluorescent penetrants can cause severe sunburn and damage to the eyes. The blacklight source should always be checked for missing, cracked, or broken filters and repaired before use. Store penetrants in an approved fire container. Technical Rationale: Marshall Space Flight Center has successfully used the penetrant testing method for years. It is a proven method for locating flaws in surface areas of highly stressed areas of components and structures. In addition, it is an effective method for both metallic and nonmetallic materials. References: Bray, Don E. and Don McBride: quotNondestructive Testing Techniques,quot John Wiley & Sons, Inc., New York, NY, 1992. Metals Handbook, Vol. 17: quotNondestructive Inspection and Quality Control,quot pp. 71-88 ASM International, Metals Park, OH 1989. CT-6-2: quotNondestructive Testing Liquid Penetrant,quot Fourth Edition, Class Room Training Handbook, General Dynamics, Convair Division, 1977. P1-4-2: quotNondestructive Testing, Liquid Penetrant,quot Fourth Edition, Programmed Instruction Handbook, General Dynamics, Convair Division, 1977. MIL-STD-410E: quotNondestructive Testing Personnel Qualification and Certification,quot Military Standard, January 1991. MIL-STD-6866: quotLiquid Penetrant Inspection,quot Military Standard, 1989. MIL-I-25135: quotPenetrant Inspection Materials,quot Military Specification, 1989. MIL-STD-1907: quotPenetrant and Magnetic Particle Inspection, Soundness Requirements for Materials, Parts and Weldments,quot Military Standard, 1990. SNT-TC-1A, quotRecommended Practice, Personnel Qualification and Certification in Nondestructive Testing,quot American Society for Nondestructive Testing, Columbus, OH, 1988.","Lesson ID":807}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1425 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Magnetic particle testing is a cost effective and expedient nondestructive Testing (NDT) method for determining discontinuities in ferromagnetic material. This NDT method can be performed in both the longitudinal and transverse directions. Implementation Method: Magnetic particle testing (MPT) is a nondestructive method for locating cracks, laps, seams, inclusions and other discontinuities on or near the surface of ferromagnetic materials. MPT is based on the principle that the magnetic flux near the surface of a magnetized material is distorted locally by the presence of discontinuities. This distortion of the field pattern, or quotflux leakage,quot as illustrated in Figure 1, is capable of attracting and holding an inspection medium of finely divided magnetic particles. Depending upon the type particles used, they will be visible under the proper lighting condition. [D] Figure 1. Leakage Field at a Crack in a Bar Magnet Direct current (DC) and alternating current are both suitable for magnetizing parts for MPT. The primary difference between the two currents is: the fields generated by DC penetrate the cross section of the part, and the field generated by the AC are confined to the metal at or near the surface of the part. Therefore, AC should not be used for subsurface discontinuities. The most common magnetization processes are circular and longitudinal. Circular magnetization is when electric current is passed through a straight conductor creating a circular magnetic field around the conductor (see Figure 2a). Longitudinal magnetization is when electric current is passed through a coil of one or more turns a magnetic field is established within the coil (see Figure 2b). To form an indication, the magnetic field must approach a discontinuity at an angle great enough to cause the magnetic field to leave the part and return after bridging the discontinuity. Best results occur when the intersection is 45 degrees to 90 degrees to the magnetic field lines. [D] Figure 2. Magnetized bars showing directions of magnetic field: (a) circular and (b) longitudinal Magnetic particles may be applied to surfaces in a dry form or they may be suspended in a water or oil carriers. The particles are usually coated with a fluorescent material for easy visualization using a black light. When using MPT make sure the induced current is strong enough to produce the magnetic field required to show the flaws being tested for. One fast method to insure adequate current is the use of a quotfield indicator.quot The field indicator consist of a metal disk with cross hatch lines with a thin metal cover attached over the cross hatch disk mounted on a yoke handle. This field indicator is placed in the magnetic field and the current increased while adding magnetic particles until the magnetic particles form a well-distinguished cross on the metal cover. There are also formulas in the references that can be used to determine the starting current. The current can be adjusted as necessary to obtain the desired magnetic field. The advantages of using Magnetic Particle Testing are: Complex shapes can be tested. Cracks filled with paint or other foreign material can be detected. Large numbers of similar parts can be rapidly tested\/automated. Small fine cracks can be detected. Subsurface discontinuities can be located. Cracks can be located through thin nonmetallic coatings. Estimate crack depth. Easily learned. Relatively low cost. The disadvantages of magnetic particle testing are: Only ferromagnetic materials can be tested. High electric current required to magnetize. Demagnetization required in some instances. Extreme care to avoid burn spots. Difficult to detect small defects below the surface. Cleaning required after test. Complex shapes may require more than two magnetizations. All personnel performing MPT should be qualified and certified in accordance with MIL-STD-410E. Detecting discontinuities is relatively simple, but adequate interpretation of the indication requires experience and judgement. The safe handling of the magnetic particles are governed by the suppliers Material Safety Data Sheet (MSDS). The suppliers MSDS should certify that the flash point of the oil carriers meet the requirements of DOD-F-87935. The MSDS should also detail personnel hazards such as inhalation, skin contact and eye exposure. Magnetizing equipment should be properly maintained to avoid personnel hazards from electrical shorts. Care should also be taken to avoid electrical arcing and possible ignition of the oil carriers. Any broken ultraviolet filters or bulbs should be replaced immediately. Personnel entering a darkened area to perform fluorescent testing should wait at least one minute for their eyes to adjust to the darkened area. Technical Rationale: MPT is a fast and cost-effective method for determining surface and subsurface defects in ferromagnetic materials. The MPT techniques may be used for in-process inspection and control, final inspection, receiving inspection, and periodic maintenance of machines, structures and handling equipment. References: Bray, Don E. and Don McBride: quotNondestructive Testing Techniques,quot John Wiley & Sons, Inc., 1992. McMaster, Robert C.: quotNondestructive Testing Handbook,quot Volume II, The Ronald Press Company, New York 1963. Metals Handbook, Volume 17: quotNondestructive Inspection and Quality Control,quot pp. 89-128, ASM International, Metals Park, OH, 1989. MIL-STD-1949A: quotMilitary Standard, Magnetic Particle Inspection,quot May 1989. MIL-STD-1907: quotMilitary Standard, Inspection, Liquid Penetrant and Magnetic Particle, Soundness Requirements for Materials, Parts and Weldments,quot March 1990. MIL-I-83387: quotMilitary Specification, Magnetic Rubber Inspection Process,quot July 1987. ASTM E 1444-93: quotStandard Practice for Magnetic Particle Examination,quot American Society for Testing and Materials, 1916 Race St. Philadelphia, PA 18103. MSFC-STD-1249: quotStandard NDE Guidelines and Requirements for Fracture Control Programs,quot Marshall Space Flight Center, AL 35812, September 1985. CT-6-3: quotNondestructive Testing Magnetic Particles,quot Class Room Training Handbook, Second Edition, Convair Division of General Dynamics, San Diego, CA 1977. P1-4-3: quotNondestructive Testing, Magnetic Particle,quot Programmed Instruction Handbook, Fourth Edition, Convair Division of General Dynamics, 1977. MIL-STD-410E: quotMilitary Standard, Nondestructive Testing Personnel Qualification and Certification,quot January 1991.","Lesson ID":808}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1411 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Controlling the operating temperature of parts in a vacuum flight environment will lower the failure rate, improve reliability and extend the life of the parts. Implementation Method: Thermal design is used to control the temperatures of the parts in equipment so that they will not exceed specific maximum safe temperatures and to minimize the parts temperature variations under all environmental conditions in which the equipment will operate. The maximum safe temperatures must be calculated based on a parts stress analysis and must be consistent with the required equipment reliability. It is usually necessary to maximize the heat transferred by only a single mode in order to obtain adequately low thermal resistances within equipment. Even though a complete cooling system may include three modes of heat transfer, each particular heat path will usually emphasize a single mode. Where a single mode dominates, other modes can often be ignored. For example, with conduction as the predominant mode for parts operated in a vacuum, the conductive thermal resistance can be made low by the use of thermal shunts. The heat transferred by radiation and convection is almost negligible. That is, in the electro-thermal analogue, the shunt thermal resistances due to radiation and convection are so large that they are insignificant for design purposes. Figure 1 shows an electrical analog of a thermal system of a typical part. Figure 1: Equivalent Thermal Circuit of a Part [D] For example, consider a linear integrated circuit, Part Number 9716 being used in an A\/D Converter in a vacuum environment. Without a heat shunt, the case to board temperature rise can be about 15oC for the part when dissipating 300 milliWatts. With a metal clad heat shunt, the case to board temperature rise can be reduced to about 5oC for the same conditions. Figure 2 shows the electrical analog of the thermal system with the shunt. Figure 2: Equivalent Thermal Circuit with Heat Sink [D] Additional enhancement can be obtained through the use of printed circuit boards with metal planes for heat conduction and heat straps for other hot spots. This has been found to be an effective method for conducting heat to the spacecraft cold plate. The effect of this design is to reduce the temperature of the board by minimizing the temperature rise from the cold plate to the board. A reduction in board temperature will allow for an increase in thermal shunting capacity for the applicable heat conduction path. Technical Rationale: The failure rates of parts increase with loading or stress level, whether it be thermal, electrical, or mechanical. Stresses below the intensity which causes catastrophic failure result in progressive deterioration of material. The effect of temperature cycling is believed to be extremely significant. Thermal failure of parts is caused by deterioration, due to temperature, of the materials of which the part is made. An old rule of chemistry (the Arrhenius Rate Law) states that the speed of chemical reactions doubles for every 10oC increase in temperature. Parts failure rates are known to increase exponentially with temperature as evidenced in published data. A thermal failure may occur so rapidly as to be considered catastrophic. However, there is always a slow, progressive deterioration of dielectrics, cathode coatings, transistor junctions and many other materials which accelerates with temperature, leading eventually to failure. These effects are cumulative so that failure rate depends to some extent on the entire ground test\/mission thermal history, the temperature-time integral. Thermal failure is, therefore insidious since it is usually impossible to determine the percentage of life remaining in a part. This has a direct bearing on the effects of temperature cycling, which is specified in nearly all specifications for testing parts and equipment, and which may occur during the normal operation of equipment in space, especially if the equipment is power cycled. There are indications that temperature cycling has a very adverse effect on reliability but there exist little quantitative data and no adequate theory by which the effect can be accurately estimated. The true thermal stress is usually at the internal junctions of the part. Since this is internal to the part, it is difficult to measure. The temperature of the accessible outer surface is the most practical index of the thermal condition of the part. Surface or body temperature is a function of the heat dissipation within the part and of its thermal environment, which is a complex function of: (1) coolant type, temperature, pressure and velocity; (2) the configuration, emittances and temperatures of neighboring surfaces; and (3) all conductive heat flow paths surrounding the part. This becomes evident from Figures 1 and 2. References: Electronic Reliability Design Handbook, MIL-HDBK-338-1A, October 1988. Glover, Daniel, Design Considerations for Space Flight Hardware, NASA TM-102300, January 1990. Reliability\/Design Thermal Applications, MIL-HDBK-251, January 1978. Reliability Prediction of Electronic Equipment, MIL-HDBK-217E Notice 1, January 1990. EEE Parts Derating, Reliability Preferred Practice PD-ED-1201 Part Junction Temperature, Reliability Preferred Practice PD-ED-1204 Thermal Test Levels\/Durations, Reliability Preferred Practice PT-TE-1404 Thermal Analysis of Electronic Assemblies to the Piece Part Level, Reliability Preferred Practice PD-AP-1306","Lesson ID":809}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1423 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Unlike most other nondestructive testing methods, radiographic testing provides a permanent visual record of the defects for possible future use. It can also be used to determine crack growth for use in fracture mechanics to determine critical flaw size in a particular component. Implementation Method: Radiography is an effective method of nondestructively detecting internal flaws in materials and structures. The radiation source emits energy that travels in straight lines and penetrates the test piece. As the radiation energy passes through the test piece, an image, is received on the recording medium opposite the x-ray source. This image is used to evaluate the condition of the part being tested. Film is most frequently used as the recording medium for the image, but there are other techniques that may be used such as fluoroscopic screens, and digitized systems coupled with video monitors. The three basic elements are: 1) a radiation source, 2) the test piece being evaluated, and 3) a recording medium are combined to produce a radiograph as shown schematically in Figure 1. An x-ray is radiation produced from a manmade x-ray tube. Table 1 compares the penetration range of high energy x-ray sources with conventional x-rays. Radiographic film is classified according to speed, contrast, and graininess as depicted in ANSI\/ASTM E94. [D] Figure 1. Layout for Flaw Inspection [D] Table 1. Comparison of Penetration Range of Conventional X-Ray Tube vs. High Energy Source Table 2 lists the ASTM film type, relative speed of the film type. Manufacturer-furnished x-ray film exposure charts show the relationships between thickness, kilovolts and exposure time, but only apply to a specific set of conditions. The manufacturer's furnished charts are only accurate to within \u00b110 percent, since no two x-ray machines are identical. [D] Table 2. Film Description and Applications Radiographics constitutes a health hazard that requires special radiation training for personnel concerned with its use. Also, adequate safety devices should be built into the x-ray facility including those listed below: Safety interlock switches Keylock system Radiation monitoring device Warning system Adequate facility shielding At least one qualified operator plus a Radiation Protection Supervisor or designated alternate must be present at all times during any x-ray operation. The personnel requiring access to the x-ray area must be monitored to ensure that no one absorbs excessive amounts of radiation. The normal means for monitoring radiation is by wearing pocket dosimeters and film badges. The dosimeter is read and recorded daily and usually the film badge is developed and read at least quarterly. Both devices are compared and should check within 20 percent of each other. The allowable dose of radiation is 1 1\/4 Roentgen equivalent man (rem) per quarter year. For added safety, each time the x-ray area is entered a survey meter should be used to ensure that the area is safe to enter. Interpretation of radiographs requires highly trained and qualified technicians who must (a) define the quality of the radiographic image, which requires a critical analysis of the radiographic procedure and the image developing procedure; (b) analyze the image to determine the nature and extent of any abnormal condition in the test piece; (c) evaluate the test piece by comparing interpreted information with standards or specifications; and (d) report inspection results accurately and clearly. The major advantages and disadvantages of radiographic testing are listed in Table 3. [D] Table 3. Advantages and Disadvantages of Radiographic Testing Technical Rationale: Radiographic testing has been used successfully at MSFC for years to identify and characterize cracks, voids, inclusions, porosity, lack of weld penetration, lack of fusion in welds, and many other types of defects. Radiographic testing is an accurate and reliable nondestructive testing method for determining defects and flaws internal to materials, structure, and assemblies. It is also used to detect defects and flaws in both metallic and nonmetallic materials. References: MIL-HDBK-728\/5: quotMilitary Handbook: Radiographic Inspection,quot December 1985. MIL-STD-410E: quotNondestructive Testing Personnel Qualification and Certification,quot Military Standard, January 1991. MM 1860.2D: quotRadiation Safety Manual,quot NASA, Marshall Space Flight Center, Marshall Space Flight Center, AL 35812, December 1991. MM 1700.4C: quotSafety and Environmental Health Standards,quot NASA, Marshall Space Flight Center, Marshall Space Flight Center, AL, December 1983. Metals Handbook, Volume 17: quotNondestructive Inspection and Quality Control,quot pp. 295-357, ASM International, Metals Park, OH, 1989. MIL-STD-453C: quotRadiographic Inspection,quot Military Standard, December 1984. Ultrasonic Testing of Aerospace Materials: Reliability Preferred Practice PT-TE-1422 Eddy Current Testing of Aerospace Materials: Reliability Preferred Practice PT-TE-1421","Lesson ID":811}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1415 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Knowledge of the presence or absence of corona discharge will help in controlling the reliability of high voltage components\/systems. Corona testing can reveal potential and unaccounted-for corona discharges that may shorten the service-life of electrical insulating systems, seriously interfere with high voltage system operation and communication links, and result in failure and loss of mission objectives. Implementation Method: Corona current pulses can be detected using electrical measuring instruments. Numerous corona tests performed at LeRC concluded that the corona discharge acceptable limit should be less than 5 picocoulombs. Paschen's curve defines the regions of breakdown as a function of the dielectric media and the product of the pressure times the spacing between the conducting surfaces. The minimum voltage for a common dielectric medium is approximately 300 volts; therefore, testing should be considered for power systems operating at 300 volts and greater. Generally, the corona inception voltage tends to decrease with increasing frequency of the alternating voltage under the influence of which corona takes place. It is reported that the inception voltage decreases somewhat at frequencies above approximately 20 kilohertz and more rapidly at frequencies in the megahertz range (Ref. 9). Several variations of corona test apparatus and circuits are available and can be utilized to generate typical corona environments for the specific power system component type and operating conditions. The basic components of any corona test set consist of a detector, power separation filter and calibration signal coupler. A more general test apparatus that has been used to test corona (partial discharge) is shown in Figure 1. This set up consists of a 40 kilovolt AC and DC partial discharge test set that includes a buffer-isolation amplifier circuit which couples output pulses to a multichannel pulse height analyzer or an oscilloscope. The same partial discharge system of Figure 1 can be connected to a thermal vacuum chamber for testing space power system components to determine corona threshold level. In this test setup, the following modifications are necessary to convert a vacuum pumping test station into a corona threshold test facility: 1) Each O-ring sealed surface is clamped to withstand a maximum test pressure of 1.69X105 newton per square meter (1270 Torr); 2) A 1\/2-inch diameter high-voltage transmission line (of copper tubing) is run from the corona tester to the test sample; 3) The tubing from the corona tester to the vacuum chamber is shielded with a 6-inch galvanized pipe; 4) The 1\/2 inch tubing is supported with polystyrene standoffs; 5) All directional changes are guarded with 1-inch corona balls; and the vacuum feedthrough is guarded with 1\/2 inch radius cover rings. Detailed test setup, procedures and test equipment manuals should be obtained from the test equipment manufacturers. Also, military standards and specifications listed in the References section of this document provide a test apparatus\/circuit guide for the different types of components used in high voltage systems. Reference to these standards and specification should be made whenever possible to ensure that the proper component screening procedures and requirements are observed. [D] Figure 1: Typical Partial Discharge Test Setup In general, all measurements should be carried out in an electrically shielded room with its own isolated and filtered power lines. Care should be taken to see that cabling and vacuum feedthroughs are corona free (Ref. 15). With the help of the information contained in the publications referenced herein, detailed procedures should be developed for the various required tests and evaluation of corona. Technical Rationale: The term quotcoronaquot is used as a generic name for any electrical discharges which take place in an energized electrical insulation as the result of accelerated ionization under the influence of the electric field in the insulation (Ref. 9). The reliability of high voltage power systems is related to an electrical discharge (corona) parameter on a component level. Corona causes insulation deterioration, therefore, failure of components becomes more probable as the component degrades. All power system components should be tested to verify that this parameter can be held to a specified minimum for extended periods to ensure system reliability through corona testing (Ref. 1). Corona is sometimes visible in the form of an arc, but visual inspection for presence of corona is grossly inadequate. The voltage at which visible corona can be observed is at a threshold well above the actual corona inception. Although corona-caused arcing is damaging to power systems, the greater concern is the internal invisible corona within a device. Corona originating within an enclosed item is also damaging and can degrade dielectrics. Corona discharges in insulation systems cause momentary changes of potential and consequently current pulses. These current pulses are superimposed on the test voltage signals and may be detected at the terminals of the device under test. Corona testing should be a part of the design tests to verify that the components meet the less than 5 picocoulombs requirement. Components (any electrical devices, such as transformers, cables, connectors, terminations, etc., which incorporate conductors with suitable insulated regions) that have potential for degradation inherent in their insulation system can be identified. This degradation is due to small voids, fractures, separations, delaminations and other defects that are not detectable by visual inspection, and can be detected in insulating systems by corona testing. The presence of corona, because of these defects, subjects a material to ozone, acid, ultra-violet light and bombardment by electrons and ions. An ionization process takes place as a result of gas in a void located within a dielectric or adjacent to the surface of a dielectric that separates two conductors with electric field. Corona discharge, due to electron or ion bombardment in an ionized region, initiates and can erode almost all dielectrics. This erosion is permanent and cumulative. The cumulative effects of corona will cause failure, without warning at a later date, when the dielectric strength becomes less than the applied stresses. This can occur after installation of high voltage components within a system of assumed high reliability. Corona deteriorates insulation in the vicinity of the discharge, reduces distribution efficiency, and disassociates some gases creating noxious gases and odors. Corona within an electric power system generates spurious high-frequency voltages that produce interference in communication links and malfunctions in sensitive electronic circuits. The current pulses it produces in the circuits of high voltage equipment may have very short rise time, high recurrence frequency and sufficient amplitude for simulating, falsifying, distorting or masking signals which are used in electrical communication, control and measurements. At the development and design of the SERT's Power Conditioner, an arcing problem (due to corona discharge) occurred in the ion thruster and caused power source interruption and overload conditions. Using high voltage components that are screened for corona, and elimination of sharp corners on terminals and connectors, reduced the amount of corona-caused arcing in the high voltage system. An example of an early flight failure caused by corona discharge was a short that developed between two pins of a high voltage connector. The gas trapped inside connector voids gradually decreased in pressure until corona discharge began to decompose the insulating system and caused leakage and a short. The failure disabled the experiment. Definitions of Corona terms discussed in this document are provided in Table 1. Corona (partial discarge) A type of localized discharge resulting from transient gaseous ionization in an insulation system when the voltage stress exceeds a critical value. The ionization is usually localized over a portion of the distance between the electrodes of the system. Corona inception voltage (CIV) The lowest voltage at which continuous corona of specified pulse amplitude occurs as the applied voltage is gradually increased. Current pulse A pulse which occurs at some location in a device as a result of a corona discharge. Ionization Any process by which neutral molecules or atoms dissociate to form positively and negatively charged particles Table 1. Corona Related Terms References: Lalli, Vincent R., Mueller, Lawrence A., and Koutnik, Ernest A.: quotSystem Reliability Analysis Through Corona Testing,quot NASA TM X-3287, Lewis Research Center, Ohio, 1975. Klima, Stanley J., and Riley, Thomas J.: quotUltrasonic Evaluation of High Voltage Circuit Boards,quot NASA TM X-73432, Lewis Research Center, Ohio, 1976. Bagwell, James W., Hoffman, Anthony C., Leser, Robert J., Reader, Karl F., Stover, John B., and Vasicek, Richard W.: quotReview of SERT II Power Conditioning,quot NASA TM X-52858, Lewis Research Center, Ohio, 1970. quotNavy Power Supply Reliability, Design and Manufacturing Guidelines,quot Department of the Navy, NAVMAT P-4855-1A, 1989. quotMilitary Handbook, NASA Parts Application Handbook,quot NASA, MIL-HDBK-978-B (NASA), 1989. quotMilitary Specification, Transformers and Inductors,quot Department of Defense, Washington DC, MIL-T-27E, 1985. quotMilitary Specification, Connectors, Coaxial, Radio Frequency,quot Department of Defense, Washington DC, MIL-C-39012C, 1991. quotMilitary Specification, Cables, Radio Frequency, Flexible and Semirigid,quot Department of Defense, Washington DC, MIL-T-17F, 1984. Heinrich, Oswald X.: quotCorona Measuring Techniques and Their Use in Insulation System Evaluation,quot James G. Biddle Co., Plymouth Meeting, Pennsylvania 19462, Technical Bulletin 66T1, May 1964. Instruction Manual 66J , quotPartial Discharge (Corona) Test Equipment,quot Biddle Instruments, James G. Biddle Co. Plymouth Meeting, Pennsylvania 19462. Galambos, Louis G., P.E.: quotCorona: What it is; Damage it causes; How to Avoid It,quot James G. Biddle Co., Plymouth Meeting, Pennsylvania 19462, Printed from Electronic Products Magazine, April 1965 Issue. The Institute of Electrical and Electronics Engineers, Inc., quotIEEE Guide for Making Corona (Discharge) Measurements on Electronics Transformers,quot IEEE Std. 436-1977, December 15, 1977. Bartnikas, R.:, Institut de Recherche, Hydro-Quebec, Varennes, Quebec, Canada and McMahon, E. J., E. I. duPont de Nemours & Co., Inc., Wilmington, Delaware, U.S.A., quotEngineering Dielectrics, Volume I, Corona Measurement and Interpretation,quot American Society for Testing and Materials (ASTM) STP 669, February 1979. Bever, Renate S., and Westron, John L.: quotPartial Discharge Testing Under Direct Voltage Conditions,quot IEEE Transactions on Aerospace and Electronic Systems, Vol. AES-18 No.1, January 1982. Bever, Renate S.: quotRamp Technique for DC Partial Discharge Testing,quot IEEE Transactions on Electrical Insulation, Vol. EI-20 No.1, February 1985. Kreuger, Frederick Hendrik: quotPartial Discharge Detection in High Voltage Equipment,quot Stoneham, Massachusetts, Butterworth-Heinemann Pub. Co., 1989. quotHigh Voltage Power Supply Design and Manufacturing Practicesquot, Reliability Preferred Practice PD-ED-1202.","Lesson ID":813}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1403, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Benefit: Quick find of electronic components operating at or above recommended temperatures. Also, this technique can validate the derating factors and thermal design via low cost testing versus analysis. Implementation Method: Using an infrared camera and the flight PC board, make thermographic pictures of the prototype PC boards in operation. Verify the thermograph and determine the delta T to the actual use environment with thermocouples. Shut down the equipment and prepare it for a vacuum test. The board to be tested is placed in a mother board with the appropriate +5 V and \u00b112 V power supplies. Power is applied to the board, and after a short period, a video recording of the board is made with an infrared camera. Technical Rationale: The following procedure is used to determine the temperature of each component: Junction temperature: T J = T A + T JA Where: TJ = Junction Temperature TA = Ambient Temperature TJA = Junction to Ambient Temperature Rise TJ = 40o C for this example The case temperature, TC, which is measured on the bench at room ambient is given by Equation(2): T C = T J - Q CAP Where: TC = case temperature QCA = case to ambient thermal resistance P = Power dissipated For reliability purposes, it is necessary to keep junction temperatures for CMOS devices at or below 49 degrees C. The case temperature to be measured on the bench comes out to be TC= 34 degrees C for this application. Infrared pictures are made of the PCB mounted outside the package on extended connectors while the equipment is operating on the bench. The logic IC temperature is determined from the infrared picture. If less than or equal to 34 degrees C, the junctions are at the desired operatingtemperature. If greater than 34 degrees C, the reason for the higher temperature is determined.Corrective action is worked out and approved by the Engineering Review Board. Figure 1 is a drawing of the component layout of the SCSI card, and Figure 2 is a thermographic photograph of the board. Thermographic pictures are usually in color, but in this monochrome reproduction, the cross hairs are at the hottest location (128 degrees F), black represents 108 degrees F, white is 98 degrees F, dark grey is 88 degrees F, and light grey is 78 degrees F. [D] Figure 1. SCSI Card [D] Figure 2. Thermograph The operating temperature with the board back in the case is checked by several thermocouples attached to the hottest observed components. This is done in a simulated use environment, perhaps during the thermal environment tests. The resultant delta-T is added to the measured case temperature as a final check of the junction temperature, TJ, in the end-use environment. For sample logic IC, the delta-T was 5 degrees C so the resultant junction temperature is 45 degrees C in the package. This is below the guideline of 49 degrees C. References: Crall, R. F., quotThermal Imaging Benchtop Analysis for Reliability,quot Evaluation Engineering, December 1989. Masi, C. G., quotWhat Can Thermal Imaging Do for You?, quot Test & Measurement World, May 1988. MIL-HDBK-217E, quotReliability Prediction of Electronic Equipment,quot Rome Air Defense Center, October 27, 1986. Foster, W. M., quotThermal Test Report for the Space Acceleration Measurement System Circuit Boardsquot, NASA LeRC Code 6730 Internal Report, November 1987.","Lesson ID":828}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1262; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Use of inherited flight hardware or software may reduce cost and allow a spacecraft designer to avoid the risk of launching unproven equipment. However, the designer often lacks full information on the many design decisions made during development, including some which may cause incompatibility with current spacecraft requirements. Subsystem inheritance review (SIR) probes inheritance issues to help assure that the proposed inherited item will result in an acceptable and reliable product with minimal mission risk. The inheritance review evaluates the compatibility of the inherited or commercial-off-the-shelf (COTS) item with project requirements. It assesses potential risk associated with item use and the need for modification or additional testing. It is held at the earliest possible time prior to the equivalent level PDR. For complex and critical items or where the preponderance of the hardware or software is inherited, the SIR may replace a PDR or critical design review (CDR) for the inherited item. In other cases, discussion of inherited items can be included in another review-- typically, the preliminary requirements review or the PDR. For smaller projects or tasks, the inheritance review and the PDR may be combined into a single review to obtain the benefit at minimum expense. The higher the level of inherited item criticality, technical complexity, and technical risk, the more likely the inheritance review will be held at the subsystem level, or even the assembly level. Responsibilities: The responsible task manager identifies the need for a formal review and initiates the action by contacting the convening authority, usually the next higher management level. The convening authority, in consultation with the responsible task manager, appoints the review board and a chair, and defines the board charter and schedule. The review board, under the direction of the chair, conducts the review and prepares a written report to the responsible manager stating the findings and recommendations. The board may elect to use the JPL Recommendation for Action (RFA) form to document recommendations. All such recommendations are advisory only. The responsible manager prepares a written response to the convening authority addressing the disposition of the review board findings and recommendations for action. The convening authority reviews and approves these dispositions. Inheritance Review Agenda: The SIR agenda items to be addressed match the subsystem PDR agenda items. The PDR agenda is described in the NASA Preferred Reliability Practice, Preliminary Design Review, Practice No. PD-ED-1215.1. If an existing hardware, software, or design element is being inherited, then the subsystem CDR agenda items also need to be considered. The CDR agenda is described in the NASA Preferred Reliability Practice, Critical Design Review, Practice No. PD-ED-1215.3. In addition to these common review agenda items, the SIR may address the topics listed in Table 1. Selection of topics from this list should be tailored in accordance with product complexity and project needs. [D] SIR Tools: Typical tools which may be effective in support of a productive SIR include: Compliance Matrix. Typically, the specifications of an inherited design or configured item do not precisely match current requirements. A compliance matrix is a very useful SIR tool for matching the requirements of the inherited design against the requirements of the target subsystem. Each requirement line item in the current project is checked off against the corresponding inherited item requirement, permitting visual identification of requirement deltas. The product of this analysis is a proposed plan for achieving inherited item compliance with current requirements. Detailed Technical Review. Agenda items and issues which have a potentially significant impact on the cost, performance, and reliability of the inherited design or equipment merit special emphasis. A detailed technical review (DTR) of a single product may be held to make use of specialized expertise; it permits a more in-depth, detailed, technical review of the compatibility, simplicity, and testability of interfaces than is feasible at the SIR. The DTR is organized as an informal, but structured, mini-review held prior to the formal inheritance review to discuss significant issues such as: A comparison of the functional and design requirements for the inherited items with those for the current project, including single point failure policy (and any exceptions), design margins, operating life, and mission flight profile. Environmental design requirements, including margin requirements and their justification, and the associated qualification (or protoflight) and acceptance test requirements for the target application. Comparison of piece part standards for the current and prior projects. This issue must be addressed early in the inheritance review process in consideration of the long lead time for procurement of piece parts. Design assessment or reliability analyses, such as failure modes, effects, and criticality analyses (FMECAs), worst case analyses, and part stress analyses, including the method of determining and combining variables. Also of importance are the requirements for dispositioning analysis discrepancies, and the history of such activity on the prior project. Problem\/failure history associated with the hardware or software during ground test and flight operations on the prior project, and the applicability of the problems\/failures and their resolution to the requirements of the current project. SIR allows for an assessment of the proposed inherited design and, if applicable, the inherited hardware, software, or firmware by a group of knowledgeable persons not directly involved in the activity under review. A formal review can focus many years of experience on inheritance issues which may affect product reliability. Inheritance review aids the responsible manager in early identification of potential inheritance problems and in developing optimal solutions. References: JPL Standard Practice Instruction (SPI) 4-16-1. Guidelines for Planning and Conducting Formal Reviews, JPL D-10401 (Office of Engineering and Mission Assurance). quotTOPEX Modular Power Subsystem (MPS) Inheritance Review,quot Jet Propulsion Laboratory Memorandum 5131-87-636 (J. Quinn to E. Costogue), December 15, 1987. Preliminary Design Review, Reliability Preferred Practice No. PD-ED-1215.1. Critical Design Review, Reliability Preferred Practice No. PD-ED-1215.3.","Lesson ID":789}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PD-AP-1306, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Benefit: Allows the thermally overstressed parts to be identified and assessed for risk (instead of just the electrically overstressed parts). Allows the design life requirements of the thermal fatigue sensitive elements (solder joints, bondlines, wirebonds, etc.) to be quantified. Implementation Method: On Class A and B programs, piece part thermal analysis (PPTA) is performed on all electronic assembly designs, including all engineering change requests in support of the part stress analysis (PSA). A policy is established mandating that the required design life of all thermal fatigue sensitive elements be quantified via a PPTA and a life cycle analysis. Moreover, it should be the policy of the contracting agency that this analysis be a deliverable and be independently reviewed by the contracting agency. Technical Rationale: Reliability engineering is the discipline of identifying, risk rating, and eliminating the quottall polesquot or quotweak linksquot in a design. Two of the most significant reliability concerns for spaceflight hardware are reductions in the mission life of the electronic designs due to excessive junction temperatures or thermal fatigue. A proper PPTA can be used to verify that the temperature derating requirements specified in the PSA have been satisfied. The PPTA is also one of the key tools for quantifying the required design life of fatigue sensitive elements. Several reliability practices case studies were performed on the Magellan (MGN) synthetic aperture radar (SAR). The results and conclusions of these studies are summarized below: Case Study Background: The MGN SAR consists of 9 prime and 9 redundant units totaling 40 slices. In all, there are more than 15,000 piece parts in this payload. The MGN SAR was chosen for a series of reliability practice case studies because its design was typical of industry for an electronic payload. More specifically, the electrical design, mechanical packaging, and quotblack boxquot thermal design techniques were very typical of those employed by industry. Role of PPTA In Part Stress Analysis: All of the waivers issued as a result of the MGN SAR PSA effort were reviewed to quantify the number of electrical overstresses versus thermal overstresses. Note that the PSAs and PPTAs did identify many overstresses for which design changes were made. There were 38 waivers issued for part stress reasons covering 211 piece parts. It was found that more than 75 percent of the 211 parts required waiving due to thermal overstresses. The remaining overstresses were for either voltage, current, or power. Thus, if the PPTA had not been performed, only 25 percent (or less) of the waived overstresses would have been identified and understood. Analyzing All Piece Parts Versus Significant Power Dissipators: This case study evaluated the feasibility of only analyzing the key or quotsignificantquot power dissipators. The MGN radar contractor used the MIL-STD-1540 philosophy of box level design temperature margins\/levels (not JPL's higher levels). The contractor also used parts derating guidelines very similar to MIL-STD-975G, except that they derated junction temperatures to 105 degrees C instead of the 110 degrees C called out in 975G. One PPTA was performed on each slice. The PPTA's analyzed all piece parts in a slice, even the nondissipating ones. The thermally overstressed piece parts identified in the PPTAs were tabulated according to three different definitions of key or quotsignificantquot power dissipation. They were to analyze only parts with over 100 milliwatts dissipation, over 50 milliwatts dissipation, and no power dissipation. All parts that would have been identified by these three definitions are shown in Table 1. Table 1. Tabulation of thermally overstressed piece parts [D] In fact, the study showed that 10 percent of the thermally overstressed parts dissipated no power. It is quite obvious that the temperature of a piece part is a function of many more variables than just the part's power dissipation. Therefore, all pieceparts should be analyzed when performing a PPTA. Also note that realistic circuit worst-case power dissipation is a key assumption, not just maximum part power capability. Thermal Fatigue Versus Design Life: A study was performed (Reference 1) to define the thermal fatigue design life requirements for various lead attachment arrangements. The PPTA was found to be a key analytical tool in quantifying the design life requirements of the solder joints. References: JPL Publication 89-35, quotMagellan\/Galileo Solder Joint Failure Analysis and Recommendations,quot September 15, 1989. quotPart Electrical Stress Analysis,quot Reliability Preferred Practice No. PD-AP-1303 quotEnvironmental Factors,quot Reliability Preferred Practice No. PD-EC-1101. quotThermal Vacuum versus Thermal Atmospheric Testing of Electronic Assemblies,quot Reliability Preferred Practice No. PT-TE-1409. quotThermographic Mapping,quot Reliability Preferred Practice No. PT-TE-1403.","Lesson ID":794}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PD-AP-1307, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Benefit: The FMECA process identifies mission critical failure modes and thereby precipitates formal acknowledgment of the risk to the project and provides an impetus for design alteration. Implementation Method: Through the use of formal spread sheets, each potential failure within an assembly is recorded together with its resultant assembly, subsystem, and system effect. The severity of the system failure effect is assigned from a pre-defined list ranging from \"negligible effect\" to \"mission catastrophic.\" Design alterations can be made at the circuit level (thereby modifying the assembly level) to eliminate a failure mode or to reduce its severity. The remaining failures are evaluated as potential subsystem failures by accounting for possible redundancy or work-arounds. Again design alterations may be invoked. Those remaining up to the system level are reported as single points of failure (SPFs), and the project makes a conscious decision to either retain them or to initiate corrective action. Technical Rationale: Every technical mission carries with it a degree of risk. A mechanism is needed to identify and quantify the risk to permit decisions to be made which will ultimately reduce the risk to the minimum permissible level within the project cost, schedule, and performance constraints. Because most spacecraft systems are extremely complex, a method of risk identification must be used which has total visibility into the system. The FMECA has been recognized as such an approach and, if implemented rigorously, will provide the necessary visibility. The process requires the assumption of a failure of each part of each unit. The credible failure modes are identified for each part (e.g., capacitors can short or open). If a piece part level FMECA is required by project definition, a line item must be entered for each identified mode of each part, e.g., \"C23 shorts\". If a project employs a high degree of redundancy, the complexity of a part level FMECA is unnecessary because a presumably redundant element will perform the function. Thus a functional level FMECA is adequate, e.g., \"the amplifier chain formed by Q14, Q15, and Q16 and their associated parts has very low gain\". This failure may have many root part failure causes but if all possible failure modes of the block are identified, e.g., \"low gain, oscillation, high gain, high harmonic distortion\", there is no value in recording the individual part causes. The most essential analysis in a design which uses redundancy is that of the cross-strapping networks. For this reason, a parts level FMECA is considered mandatory for all cross-strapped redundant elements, either inside an assembly or at an external interface.","Lesson ID":795}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1434 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Since the operational readiness and future performance of space flight batteries at any point in a mission are strongly dependent upon past power cycles and environments, thoroughly instrumented and analyzed ground testing of space flight batteries identical to flight configurations will ensure predictable performance and high reliability of flight batteries. Implementation Method: Real-time, long term mission, power cycle simulations of space flight batteries in ground facility test beds provide an excellent indication of expected performance in flight. Complete verification of a full real-time mission is not possible with long-term missions due to the test lead time. Instead of accelerating the test, the test engineers should quotleadquot the actual mission by a year or two (as long a lead-time as possible while still being able to use flight designs and configurations). This verification is in addition to qualification steps for the designs. Accelerated testing is not common for low earth orbit (LEO) missions but is used for non-LEO missions. The cells are interconnected in the anticipated flight condition and are housed in a thermally controlled chamber which is purged with an inert gas. Preprogramed, computer controlled power supplies and load banks cycle the batteries through the same dormant, power drain, and charging cycles that they would encounter in the space operation. Shading of solar arrays during eclipse periods is simulated by absence of charging current, and charge cycles are simulated during exposure to the sun. Table 1 lists the principal purposes and features of long-term battery simulations. [D] Table 1. Principal Purposes and Features of Long-Term Battery Simulation All cells are instrumented at various locations for current, voltage, temperature, and pressure. Ambient temperature in the chamber is constantly monitored. Voltage and current values are available in real time through digital readouts. Voltage, current, pressure, and temperature are recorded constantly on strip charts. Data are sampled by computer programs which compute and analyze ongoing performance. Table 2 shows the parameters usually recorded and\/or computed for each battery cell from sampled data. Ground testing of batteries and their associated power systems has proven to be a valuable asset for the resolution of in-flight anomalies. Limits testing can be safely simulated on the ground to verify or explore variations in flight performance. [D] Table 2. Recorded and Computed Data Parameters for Each Cell Safety precautions are important in testing of all battery systems because leakage of electrolytes or effluents can be hazardous. Typical precautions and safeguards for nickel-hydrogen (Ni-H2) batteries are shown in Table 3. [D] Table 3. Typical Precautions\/Safeguards for Ni-H 2Battery Testing An important action that will help to ensure a successful test effort is the preparation of a comprehensive test plan before the test begins. The test plan should describe the overall scope and approach to the test operation, and provide a detailed test sequence including the test set up parameters, data handling requirements, and test procedures. The test setup description should include the cell specifications and method of packaging into the battery configuration, the data acquisition and control procedures, and the thermal control system requirements. Test procedures should include cell characterization testing procedures (assuming that the cells have already passed through acceptance testing prior to receipt at the test site), launch scenario simulation procedures, mission simulation procedures, and mission capacity test and reconditioning procedures if required. Technical Rationale: MSFC has conducted multi-year testing of silver-zinc, nickel-cadmium, and nickel-hydrogen batteries since 1986. Some tests that were started in 1986 are still underway at this writing. Test durations are over eight years and counting. MSFC is conducting 8 to 10 tests simultaneously, with up to 400 channels of instrumentation on some tests. To support the Hubble Space Telescope, diode bypass relays on two batteries were opened to simulate an in-flight anomaly. The HST ground tests indicated that strong performance should continue from the HST flight batteries despite the in-flight anomaly. References: Whitt, Thomas and Lorna Jackson: quotBattery and Cell Testing at Marshall Space Flight Center,quot (a presentation), NASA\/MSFC, EB12, Huntsville, AL, 1988. Brewer, Jeffrey, John Pajak, and Lorna Jackson: quotTest Plan for AXAF-I Ni-H2 Battery Mission Simulation Testing,quot NASA\/MSFC, EB71, Huntsville, AL, March 30, 1994. Brewer, Jeffrey, and Thomas Whitt: quotHST Ni-H2 Flight Spare Battery Test,quot NASA\/MSFC, EB12, Huntsville, AL, Huntsville, AL, October 6, 1989. Whitt, Thomas, and Charles Hall: quotHST Ni-H2 Six Battery Mission Simulation Test,quot NASA\/MSFC, EB12, Huntsville, AL, November 2, 1989. Whitt, Thomas, and Jeffrey Brewer: quotFifth Semi-Annual Report on HST Ni-H2 Six Battery and Flight Spare Battery Test,quot NASA\/MSFC, Huntsville, AL, August 8, 1993.","Lesson ID":802}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1241; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Budgeting of a specific amount of the established allowable contamination to the major elements and operations during fabrication, assembly, testing, transportation launch support, and launch and on orbit operations of space optical systems will preclude jeopardizing the scientific objectives of the mission. Budgeting of contamination to major elements will ensure that the cleanliness of the optics and instruments will remain within designated optical requirements for operations in space. Reliability of the scientific objectives are increased by limiting the contamination allowed to the optical systems during each operation, which ensures that contamination during orbital operations is within specification. Implementation Method: 1. Introduction Contamination budgeting allocations for optical systems should be developed by the chief scientist, systems engineer, and the contamination control engineer using information generated from requirements documents, interface control documents, science working groups, contamination control working groups, contamination control review panels, contamination effects analyses, contamination testing programs, and direct customer involvement. The experience gained from other programs to budget and control contamination is also an input to the determination of a contamination budget. Another factor that should be considered is the cost of controlling contamination versus the scientific payback. The effective control of contamination may require: (1) investments in clean room facilities, (2) training of personnel in clean room operations, (3) monitoring of clean room activities and air quality, (4) acceptance of inefficiencies in working conditions caused by special clothing, restricted space and contamination avoidance provisions, and (5) potential performance tradeoff (i.e., use of cleanable or conductive coatings, modified thermal controls, and use of windows). 2. Budgeting for Contamination The two principal types of contamination sources for optical systems are particulate contamination and molecular contamination. Particulate contamination can consist of airborne particles, insulation shreds, clothing fibers, other human induced substances, and trapped particles in interstitial spaces, such as joints and crevices. When these particles settle on the optical surfaces, they cause degradation by obscuration and light scattering. To avoid jeopardizing the scientific objectives of the HST, the maximum percentage area coverage due to particulate contamination for the primary and secondary mirror was set at 5 percent. [D] Figure 1. HST Particle Contamination Budget Allocation Molecular contamination results from depositing outgassed products on optical surfaces, which may cause performance degradation at most wavelengths by absorbing the wave energy and\/or modify polarization characteristics. Examples of molecular contaminants are lubricants, exposed organics, and volatile condensible materials. The allowed (per scientific objectives of HST) degradation due to molecular contamination dictates that the reflectance at 1216 Angstroms shall not decrease by more than 10 percent between the time of coating and five years in orbit. The operations that have the greatest potential for contamination have been allocated the larger budgets. 3. Reallocation The requirement that limits the primary and secondary mirror area coverage total contamination budget cannot be changed. However, changes may occur in the schedule where the operational budget may have to be re-allocated. For example, in the particulate contamination budget for the HST, the original allocation of 1.35 percent assigned to pre-acoustic fallout and the chimney effect and the 1.35 percent assigned to the acoustic testing were changed to 1.30 percent. The 0.6 percent assigned to the fallout and chimney effect after acoustic testing was changed to 0.5 percent. The total of 0.2 percent obtained from these operations was assigned to the unplanned rework and storage operation. [D] Figure 2. HST Molecular Contamination Budget Allocation Technical Rationale: For an optical system to achieve its desired goal of returning adequate scientific results, contamination of the optical system must be kept to a minimum. Establishing a contamination budget and controlling the contaminates within this budget ensures that the optical system will produce satisfactory scientific results. References: LMSC 4176437D: quotHubble Space Telescope Contamination Control Plan,quot Lockheed Missiles and Space Co., Inc., (LMSC) January 30, 1987. LMSC 4176594A: quotContamination Degradation Budget Allocation,quot ST\/SE-26 Appendix A, Lockheed Missiles and Space Co., Inc., June 4, 1984. LMSC 4176595C: quotHST Environment Definition and Traceability,quot ST\/SE-26 Appendix B, Lockheed Missiles and Space Co., Inc., July 13, 1990. LMSC 4176596A: quotHST Contamination Control Training,quot ST\/SE-26 Appendix C, Lockheed Missiles and Space Co., Inc., November 15, 1984. LMSC 4176597A: quotST Contamination Control Violation Reports,quot ST\/SE-26 Appendix D, Lockheed Missiles and Space Co., Inc., October 30, 1984. LMSC 4176598A: quotST Thermal Vacuum Bake Out,quot ST\/SE-26 Appendix E, Lockheed Missiles and Space Co., Inc., March 31, 1988. LMSC 4176599B: quotHST Cleanliness Status,quot ST\/SE-26 Appendix F, Lockheed Missiles and Space Co., Inc., August 30, 1990. LMSC\/F157834: quotContamination Control Implementation Plan for HST Rework and Storage,quot Lockheed Missiles and Space Co., Inc., November 1, 1986. LMSC\/D975220D: quotHubble Space Telescope, Maintenance and Refurbishment Contamination Control Master Plan,quot Lockheed Missiles and Space Co., Inc., June 30, 1988. NASA SP-5076: quotContamination Control Handbook,quot National Aeronautics and Space Administration, 1969.","Lesson ID":804}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1428 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: The benefit of the ALERTS system is the reduction or elimination of duplicate expenditures of time and money by exchanging information of general concern regarding parts, materials, and safety problems within MSFC, between MSFC and other NASA centers, between NASA and other government organizations, and between government and industry to assist in preventing similar occurrences. The use of the ALERTS system avoids future failures, rules out fraudulent hardware, helps enhance reliability, and ensures mission success. Implementation Method: The Government-Industry Data Exchange Program (GIDEP) is an on-line service that fosters cooperative data interchange between government and industry seeking to reduce or eliminate duplicate expenditures of time and money by making use of existing knowledge. The program provides a means to exchange technical data essential in the research, design, development, production, and operational phases of the cycle of systems and equipment. The primary objectives are to improve reliability, quality, productivity, safety and logistics support. A GIDEP participant may be either a government or industry activity engaged in the design, development, test, production, or support of equipment and systems. Universities and consultant firms who qualify may also participate. GIDEP participants may have access to any of the following four data interchanges 1) Engineering Data Interchange, 2) Failure Experience Data Interchange, 3) Reliability-Maintainability Data Interchange and 4) Metrology Data Interchange. The Failure Experience Data Interchange (FEDI) is the GIDEP data interchange relative to ALERTS, SAFE-ALERTS, and Problem Advisories. The FEDI contains objective failure information generated when significant problems are identified on parts, components, processes, equipment, materials, specifications, or safety hazards. This data includes ALERTS and SAFE-ALERTS, failure analysis, problem information data and manufacturing sources data. The initiator of an ALERT coordinates the ALERT with the manufacturer (vendor) when applicable then forwards the ALERT to the GIDEP Operations Center for electronic distribution to all participants. SAFE-ALERTS describe problems usually related to finished products which could have an impact on the safety of personnel or risk damage to facilities or equipment. FEDI Report definitions follow: ALERT - An ALERT reports a problem with parts, components, materials, specifications, manufacturing processes, or test equipment that can cause a functional failure. SAFE-ALERT - A SAFE-ALERT reports a problem that relates to the safety of personnel or equipment. PROBLEM ADVISORY - A Problem Advisory reports 1) preliminary information on a suspected problem, or 2) a problem with parts, components, materials, manufacturing processes, specifications or test equipment that has an unknown or a low probability of causing a functional failure. Problem advisories that report preliminary information must be followed by updated reports at not less than 30 day intervals until resolved or canceled. MSFC prime contractors are required to participate in GIDEP when their participation is considered advantageous to the program. However, the contractor must obtain MSFC approval for ALERTS which they propose on MSFC hardware. Nonparticipating subcontractors may propose ALERTS for submission to GIDEP via the MSFC System. Approximately 250 to 300 GIDEP ALERTS, SAFE-ALERTS, and Problem Advisories are received and processed each year. Approximately 10 to15 preliminary ALERTS or SAFE-ALERTS are generated within NASA; of those approximately 2 to 4 originate at MSFC. The MSFC ALERT system is comprised of the GIDEP ALERTS, SAFE-ALERTS, and Problem Advisories and internal NASA ALERTS, SAFE-ALERTS, and Problem Advisories. These are processed at MSFC using MSFCi\u0301s tailored system as shown in Figure 1, MSFC ALERT\/SAFE-ALERT System Flow Chart. The left portion of Figure 1 depicts processing ALERTS that originate outside MSFC (includes other NASA centers and GIDEP). The ALERTS are received by the ALERT coordinator, logged in and forwarded to the appropriate MSFC Laboratory for technical evaluation. This evaluator determines whether the alert should be considered a FULL ALERT, Information ALERT, or No Action Required, which is entered onto an evaluation form. These three categories are defined as follows: A FULL ALERT is a serious problem which involves a high probability of causing a failure in quality sensitive equipment. The FULL ALERT should be disseminated immediately for investigation and a required response. An Information ALERT reports a minor problem with low risk of affecting quality sensitive equipment. It will be disseminated for information and will require a response only if it results in an impact. No Action Required is a classification that is applied to conditions which do not represent valid problems or have no impact on quality sensitive equipment. These conditions should not be classified by NASA as an ALERT and it will receive no further dissemination. [D] Figure 1: MSFC ALERT\/SAFE-ALERT System Flow Chart The completed evaluation form is returned to the MSFC ALERT Coordinator and filed if classified as i\u0300No Action Required.i\u0302 If the ALERT is classified as an Information ALERT or FULL ALERT, it is transmitted to MSFC contractors, laboratories, project offices, and the safety office. When a response is received from a MSFC contractor it is routed through applicable MSFC project offices for coordination with MSFC laboratories and transmitted to the MSFC ALERT coordinator for action and closeout. Responses from MSFC laboratories and safety offices are forwarded to the MSFC ALERT coordinator for action and close out. The response to an ALERT indicates whether the item is included in the system and, if so, what corrective action is required. Further use of the problem part, material, equipment, or process does not take place until the corrective action is implemented. The right portion of Figure 1 depicts proposed ALERTS originating within MSFC and MSFC contractors. The proposed ALERT is forwarded to the MSFC ALERT coordinator, logged in and forwarded to the appropriate MSFC laboratory or safety office for technical evaluation and recommendation. The MSFC ALERT coordinator forwards comments to the affected manufacturer (vendor) for their evaluation and comments. The manufacturer returns their comments to the MSFC ALERT coordinator who transmits information ALERT or FULL ALERT to MSFC contractors, laboratories and project office and safety office with copies to NASA Headquarters, other NASA centers and GIDEP. Responses received from MSFC contractors, laboratories, and safety offices are routed and closed out as stated earlier. An ALERT is considered to be a NASA-wide concern if it is a potential source of unreliability, performance degradation, personnel hazard, or if it may result in a significant schedule delay. Technical Rationale: As technical rationale, two specific situations in which ALERTS or SAFE-ALERTS have been vital to mission success are described below: ALERT No. H1-A-88-01 dated 3-15-88 This ALERT started out as a MSFC TWX ALERT 5210A dated 2-17-88 by memorandum from the MSFC ALERT coordinator. The TWX, and later the GIDEP ALERT, stated that a quality assurance product audit was performed on NAS bolts fabricated from A-286 steel and disclosed they were not properly tested to the requirements of the NAS specification by the manufacturer. This ALERT affected shuttle elements, payloads and satellites. Considerable effort was made to identify and determine the extent of prior use of NAS bolts from the same manufacturer. Testing was performed on the fasteners to determine shear and tensile strengths. Stress analysis was performed using the test results. In all cases, positive margins of safety were depicted. To ensure that the fasteners would be acceptable for 40 usages, a fatigue analysis was performed. An inspection plan was implemented for future procurement of these fasteners. SAFE-ALERT No. M7-S-93-01A A Battery case is part of the Alinco Igniter Circuit Tester, Model 101-5CFG. Embedded in the battery case is a resistor that limits the amount of current to 5 milliamps. This current is low enough to prevent activation of the igniter but sufficient to determine if the igniter is functional through a continuity test. In 1989, a tester was returned for battery replacement and calibration. The presence of the current limiting resistor in the battery case was unknown to the repair technician, who discarded the case because new, larger batteries were required. Use of the tester resulted in premature ignition of a test rocket flare. Fortunately, no injuries occurred. A SAFE-ALERT was issued in 1989, but was not incorporated correctly into the GIDEP data base because an improper document number of M7-F-89-01 was assigned. (The F should have been an S, which would have designated the document as a SAFE-ALERT). As a result of this improper designation, all of the users of this circuit tester model were not alerted to this hazardous situation, and, in an incident in Sweden in 1993, the same model tester caused the ignition of a rocket motor which resulted in one death, three injuries, and two damaged buildings. This incident underscores the need to accurately and promptly designate and disseminate ALERTS and SAFE-ALERTS. However, since Canada is the only other country that is a member of GIDEP, it is doubtful that Sweden would have been alerted. With proper designation, membership in GIDEP would have been another essential element in avoiding the problem. References: MMI 5310.2D: ALERTS and SAFE-ALERTS Reporting of NASA Parts, Materials, and Safety Problems, Marshall Management Instruction, Marshall Space Flight Center, AL 35812, February 4, 1986. NMI-5310.2C: Participation in The Government-Industry Data Exchange Program (GIDEP), NASA Management Instruction, National Aeronautics and Space Administration, Washington, D.C., July 9, 1991. NHB 5310.3: Procedures for NASA ALERT Reporting of Parts, Materials, and Safety Problems, NASA, Office of Safety and Mission Quality Publication, April 1993. NMI 5310.1D: NASA Alert Reporting of Parts, Materials, and Safety Problems, NASA Management Instruction. Government-Industry Data Exchange Program (GIDEP), Program Summary, GIDEP Operations Center, Corona, CA 91720, September 1987.","Lesson ID":805}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PD-AP-1304, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Benefit: Any independent review process increases the level of compliance of the subject process. It also broadens the scope and depth of experience available for each individual issue without the need for a large supporting staff at each supplier organization. Also, an in-place independent review structure improves the rate of data flow for a given level of effort. Implementation Method: There are several levels of independent review in a sequential review process. A Problem\/Failure (P\/F) not only affects the subject hardware\/software but other elements of the system as well. At the first level of independent review, the project\/task system engineering organization reviews all identified system related P\/F reports, all unknown cause P\/F reports, all design related P\/F reports, and all critical concern P\/F reports that are identified as \"Red Flag.\" At any level of the independent review process, specialists in the area of the P\/F can be consulted for their expertise. As a subset of the system level review all project\/task systems test or ground operations P\/F reports are routed to the test and operations manager for verification of closure adequacy. All P\/F reports not initially sent to systems, as well as those P\/F reports that have been approved by systems, are sent to the project\/task reliability engineering organization. Reliability engineering reviews each P\/F report for adherence to the P\/F reporting requirements, for completeness and lucidity of the technical contents, for uniformity of rating standards, and for identification of generic P\/F or broad issue-related P\/F. At this point in the P\/F review process, issue-specific specialists can be consulted on issues requiring their field of expertise (safety, environmental factors, etc.) or to explore broader issues raised by an examination of the P\/F that were not apparent at the internal P\/F reporting level. P\/F reports can be recycled back up the review chain if conditions are uncovered in the review process that warrant such an occurrence. The final step in the independent P\/F closure process is the Project Management review and approval cycle. In the optimum review process, the status of closed, nonrisk P\/F reports is provided by periodic P\/F reporting status reports. The critical P\/F reports, classified by the \"Red Flag\" rating, are routed through the appropriate Project Management officials to determine the P\/F impact on schedule and future funding, and to identify an element of residual mission risk. Technical Rationale: Independent P\/F reporting closure is a key to reducing mission risk. On a recent mission, 25 percent of the contractor-submitted Problem\/Failure Reports (P\/FRs) had risk rating changes as a result of independent review by Reliability Engineering. Of the 25 percent changed, 1\/4 were significant or red flag P\/FRs (i.e., 1\/16 or 6 percent were major issues). This process results in fewer schedule delays and attendant funding problems late in the Project\/Task, by providing the earliest isolation and documentation of P\/F that can pose serious mission consequences. Generic P\/F can be detected and consolidated in an efficient manner, with attendant cost savings. The P\/F reporting system is a resource for providing visibility to all levels of management in near real-time. References: \"Risk Rating of Problem\/Failure Reports,\" Reliability Preferred Practice PD-AP-1305.","Lesson ID":790}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PD-AP-1316, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Benefit: Materials and design structures which represent possible internal electrostatic discharge (IESD) sources can be identified early in the program. Risk to hardware may be reduced through design changes which substitute materials having sufficient conductivity to permit charge bleed-off. Sensitive cable runs may be rerouted or shielded to reduce exposure to energetic electrons. Grounding schemes may be changed to ensure that otherwise isolated conductors are grounded and that grounds are designed to maximize the opportunity to bleed-off the charge from dielectric materials. Implementation Method: Utilize the electron environment specified for the mission and a transport code (such as NOVICE) to estimate the electron flux at interior locations where dielectric materials pose an IESD problem. When the electron flux exceeds the guideline values, apply ameliorating strategies: Replace dielectric with a more conductive material, Relocate the dielectric structure to a more suitable location within the spacecraft, and Review the grounding scheme to maximize charge bleed-off. Good design practices can minimize IESD risk by optimizing the spacecraft structure to provide shielding for otherwise exposed cable runs and highly resistive materials. Shielding reduces the ability of incident energetic electrons to cause IESD by shifting the flux spectra to lower energies, resulting in fewer high energy particles. Providing a shield thickness of 400 mg\/cm2 has been found sufficient to reduce most electron environments below the IESD threshold. Technical Rationale: IESD is caused by electron flux present in the earth's magnetosphere which is sufficiently energetic to penetrate the spacecraft skin and imbed in cable insulation, thermal blankets, circuit boards, and other non-conductors. Ungrounded islands of metalization can also develop a charge. When the charge build-up results in an electric field sufficient to break down the dielectric, an arc to an adjacent material at a lower potential will occur. Material damage (burn-out) and an electromagnetic pulse occurs which can couple into the subsystem electronics with the possibility of undesirable anomalous subsystem behavior. Electrons responsible for bulk dielectric charging are more energetic than those responsible for surface charging. The IESD threshold current density is approximately 2x105 electrons\/(cm2-s) for integral electron flux above approximately 100keV. The frequency of IESD increases as the electron flux increases above threshold. Dielectric breakdown begins to occur when the concentration of electrons exceeds approximately 1011 electrons\/cm2. References: Vampola, A.L. (1987), \"Thick Dielectric Charging on High-Altitude Spacecraft\", Journal of Electrostatics, 20, pp 21-30. Fredericks,A.R., Holeman, E.G, Mullem, E.G. (Dec. 1992),\" Characteristics of Spontaneous Electrical Discharging of Various Insulators in Space Radiations\", IEEE Trans. on Nucl. Sci., 39, 6. Purvis, C.K., Garrett, H.B., Whittlesey, A., Stevens, N.J. (Sept. 1984), \"Handbook of Design Guidelines for Assessing and Controlling Spacecraft Charging Effects\", NASA Technical Paper 2361. Mizera, P.F., Fennell, J.F., Hall, D.F., Koons, H.C., and Vampola, A.L., \"Spacecraft Charging Handbook\", SD-TR-85- 26, 1985. Rudie, N.J., \"Electron Caused Electromagnetic Pulse\", DS&E Magazine, pp 58-59, June 1987. Design Practice to Control Interference From Electrostatic Discharge (ESD), Reliability Preferred Practice No. PD-ED-1244 Surface Charging\/ESD Analysis, Reliability Preferred Practice No. PD-AP-1301","Lesson ID":800}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1436 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Advanced computed X-ray tomography can be used to produce both two-dimensional and three-dimensional images of structures, materials, parts, and components. These images are providing information that is useful for inspection, evaluation, and diagnostics of complex hardware. Implementation Method: 1. General Description of the Process: Advanced computed X-ray tomography uses high intensity X-ray sources, sensitive electronic detectors, sophisticated computer control and analysis techniques, and automated manipulation systems capable of translating and rotating test objects, to produce cross-sectional images of precision aerospace components. A system block diagram is shown on Figure 1. This test method can be used to verify tolerances, to determine relative material densities, to locate inclusions or defects, and to measure the extent of erosion and ablation in composite materials. The equipment and procedure is applicable to metals (up to 10 inches thick) composites, or combination metal\/composite structures varying from 2 inches to 50 inches in diameter (depending on the material density) and weighing up to 3700 pounds. [D] Figure 1: Advanced Computed X-ray Tomography Basic System Block Diagram Cross-sectional images, generated by rotating and translating test objects slowly in an X-ray source, produce accurate representations of thin slices of the test object. It takes 20 minutes to produce an image of a thin slice for a typical SRM nozzle. To form a three-dimensional image of the internal structure of the nozzle, 150 to 250 slice images are acquired and stacked. The entire process is controlled remotely by computer. Operational personnel are located external to the test cell. To prevent personnel contact with harmful X-radiation sources or environment, there are safety precautions that include constant dosage monitoring of stray\/exposure radiation. A principal use of advanced computed X-ray tomography at MSFC has been evaluation of solid propellant rocket motor nozzles. The technique has been used for verification of nozzle integrity, thermocouple location determination, and post-fire char depth evaluation. The procedure can locate high or low density inclusions, delaminations, or debonds, and profound material density variations. The images can be observed in near real time as they are generated, and are archived for future detailed analysis and evaluation. 2. Safety Precautions: To ensure maximum safety to personnel, equipment, test objects, and the environment, safety precautions for tomography facilities should be established and enforced. Flammable or explosive materials are not permitted in the facility. The minimum personnel required for operation of X-ray sources should be a radiation protection supervisor and an operator. Both should be trained in the principles of radiation protection and safety. Personnel are not permitted in the exposure bay during the activation of the X-ray sources. A key-lock system is installed to prevent activation by unauthorized persons. An electronically controlled safety interlock switch is located on the exposure bay doors to shut down system operation when the doors are opened. Further, manual emergency shutdown switches are located at operator consoles and inside the exposure bay. Radiation meters are used to monitor the control room and adjacent work areas. These switches and meters should be tested and calibrated on a periodic basis. Thermoluminescent dosimeter badges and pocket dosimeters are used to monitor exposure to radiation of the personnel. Detailed operating schedules, access control, and sign-in logs should be used to prevent or limit unauthorized persons from entering the facility during operation and to record those who visit during non-operation periods. Warning lights are used to warn personnel of impending or ongoing operations. Video surveillance cameras are used to monitor critical areas to prevent access by unauthorized personnel. Technical Rationale: The MSFC has operated its computed X-ray tomography facility since 1988 with significant benefit to product reliability and with no injury to the personnel or facility. X-ray sources used include a two million electron volts (ev) accelerator, and 420, 320, and 150 Kev X-ray tubes. Computer control of high energy X-ray sources with remote video viewing along with the proper precautions and warnings have been proved to provide a safe and effective inspection procedure. References: Hediger Lisa: quotReliability Improvement for the Advanced Computed Tomography Inspection System (ACTIS),quot Marshall Space Flight Center, AL, August 1992. Lawson, Seth et. al.: quotModified NASA Motor Process Procedure,quot M&P-M-NASA-027, Marshall Space Flight Center, July 1993. Hediger, Lisa et. al: quotStandard Operating and Safety Procedures for the Advanced Computed Tomography Inspection System (ACTIS) Facility,quot EH13P-88-01-Revision A, Marshall Space Flight Center, AL, February 1988. Lee, T.J.: quotRadiation Safety Manual,quot MM 1860.2D, Marshall Space Flight Center, AL, December 26, 1991. Reliability Preferred Practice PT-TE-1423, quotRadiographic Testing of x-ray Materials.quot","Lesson ID":801}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PD-AP-1305, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Benefit: Risk rating enables management to focus on the issues with the highest probability of impacting mission success. Project management is provided with visibility to a concise subset (< 5 percent) of a large information base focusing on the key problematic areas in a timely fashion. Implementation Method: A two-factored rating is assigned to each Problem\/Failure (P\/F) report. Figure 1 is a graphical outline of the rating system and indicates the basis of the quotRed Flagquot risk determination. All closed P\/F reports having a potentially significant or major failure effect (Failure Effect Rating of 2 or 3), coupled with uncertain corrective action effectiveness (Failure Cause\/Corrective Action rating of 3 or 4), are defined as quotRed Flagquot P\/F reports. [D] Figure 1. P\/FR Rating Chart quotRed Flagquot Classification: Each Red Flag P\/F report has an attached statement that summarizes the symptom, cause, effect, potential mission impact, and corrective action for the P\/F report, as well as the rationale for accepting the residual risk. The Project\/Task Manager and the Contractor Project Manager (if applicable) review, approve, and sign all Red Flag P\/F report closures to acknowledge understanding and acceptance of the defined residual mission risk. 3. All Red Flag P\/F reports are discussed at subsequent formal reviews and reported in Monthly Project\/Task Management Reports. Each individual Red Flag P\/F report is evaluated for its contribution to the overall mission risk. The total set of Red Flag P\/F reports must be evaluated for any presentation of mission risk. The Red Flag P\/F report contribution to mission risk is a topic for discussion at the preship and the prelaunch reviews. In addition, any unrated P\/F report open for 60 days or longer is reviewed and assigned a two-factored rating to determine if there are potential Red Flag issues. As indicated in Figure 1, the two numerically indicated components of the P\/F report rating system are the Failure Effect Rating and the composite Failure Cause\/Corrective Action Rating. Failure Effect Rating: The first factor, the quotFailure Effect Rating,quot is an assessment of the consequence or impact of the P\/F if it had occurred in flight. It is not an assessment of the adequacy of the corrective action. Redundancy is not considered in making the assessment. The assessment is either 1, 2, or 3 based on the following criteria: Rating 1: Negligible effect on mission performance. No appreciable change in functional capability. Minor degradation of engineering\/science data. Support equipment or test equipment P\/Fs. Support equipment, test equipment, or operator-induced P\/Fs. Workmanship failures found at initial test. Drawing errors found at initial test. Note: For items c, d, e, and f, after correction of the underlying P\/F cause, the hardware\/software must be certified to be in flightworthy condition and the failed test must be successfully completed. Rating 2: Significant degradation to mission performance. Appreciable change in functional capability. Appreciable degradation of engineering\/science data. Significant operational difficulties or constraints. Reduction in lifetime. Significant impact on system safety. Rating 3: Major degradation to mission performance or catastrophic impact on system safety. Failure Cause\/Corrective Action Rating: The second factor, the quotFailure Cause\/Corrective Action Rating,quot is an assessment, with confidence, that the failure cause has been understood correctly, and the confidence that the corrective action is effective and will preclude recurrence of the P\/F. The assessment is either 1, 2, 3, or 4 based on the following criteria: Rating 1: The cause of the P\/F has been determined with confidence by analysis and\/or test. An effective corrective action has been determined, implemented, and verified. Residual risk is considered minimum. Rating 2: The cause of P\/F has not been determined with confidence. However, corrective action is considered effective in precluding the observed P\/F symptom. Residual risk is considered minimum. Rating 3: The cause is considered to be quotknownquot and quotunderstoodquot with confidence. The correction accomplished within constraints (e.g., time, resources, test capability) does not satisfy with confidence all doubts or concerns regarding the corrective action and its effectiveness for precluding recurrence; or, the correction is considered to be a symptomatic treatment without ensuring an effective overall correction of the basic cause. There is residual risk. Rating 4: The cause has not been defined with confidence. The correction of the P\/F is considered to have an uncertain effectiveness for precluding recurrence. There is a residual risk. Technical Rationale: The P\/F report risk rating system is a time-proven technique that permits a Project\/Task to close all P\/F incidents in a timely and efficient manner and yet retain the critical information relating to mission risk in a highly visible and specific format. References: quotProblem\/Failure Report Independent Review\/Approval,quot Reliability Preferred Practice PD-AP-1304","Lesson ID":791}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1260; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: The Radiation Design Margin (RDM) requirement is imposed on assemblies or subsystems to assure reliable operation and to minimize the risk, especially in mission critical applications. The general use of an RDM connotes action to overcome the inevitable uncertainties in environmental calculations and part radiation hardness determinations. Implementation Method: RDM is defined as the ratio of the part or component radiation capability in the given application to the expected radiation environment at the part or component location during the mission. The part\/component radiation capability is defined to be the fluence (or dose), flux (or dose rate) of charged particles, or nuclear radiation which will produce enough change (degradation or radiation induced interference) in the part characteristics to cause the part to operate outside of specification for the particular circuit application. An RDM value of 2, for example, would mean that the hardware is designed to withstand twice the radiation predicted by the radiation model. Based on flight experiences, it is standard practice at JPL for most applications to require an RDM of 2 if only the inadvertent shielding of the surrounding spacecraft or instrument enclosure materials are considered in the radiation\/shielding analysis. However it is required to invoke an RDM of 3 when the local shielding, such as component\/part packaging or spot shielding, is taken into account. The RDM requirement does not apply directly to single event effects (SEE) such as single event upset (SEU), single event latchup (SEL), etc. However, SEE margins are derived by placing limits on minimum SEE sensitivity and by using design-case mission environments that account for the statistical probabilities of solar flares. Radiation Effects (1) Long-Term Ionization Effects Damage to electronics and materials may arise from the long-term effects of ionizing radiation. Ionization occurs when charged particles (or electrons from gamma-ray interactions) transfer small amounts of energy to electrons in the target material. The unit of ionization is the rad (material must be specified), which is defined as 100 erg\/g of material. In semiconductor devices, ionization produces electron-hole pairs within the semiconductor and insulators (such as oxides). Some of this charge will be trapped at the semiconductor\/insulator surface. In MOS structures, the trapped charge will cause a shift in the gate threshold voltage. Mobility (which affects switching speed and drive current) is also degraded. In addition to the gate oxide, ionization also affects the field oxide, which is used for isolation in MOS integrated circuits. This will result in extremely large leakage currents if the threshold shifts are large enough to cause inversion. Field oxide failure is an important failure mode for many commercial CMOS devices. In bipolar devices, trapped charges at oxide layers cause two effects. The traps increase surface recombination, decreasing the gain of bipolar transistors. If the trap density is high enough, an inversion layer can be created in p-doped regions that increases the surface area of the junction. This also affects transistor gain, and may cause substantial increases in leakage current. In optical materials, long-term ionization effects appear primarily as an increase in optical absorption. These usually are manifestations of charge trapping at a pre-existing defect, so the absorption rate is a strong function of the initial material properties. For example, fused quartz generally colors less than alkali glasses from a given ionizing dose. In quartz crystal used for precision oscillators or filters, long-term ionization effects can produce significant resonant frequency shifts. Again, there is a strong dependence upon the type of material used. Natural quartz shows the largest frequency shift for a given ionizing dose; synthetic quartz shows less, and swept synthetic quartz even less. In these cases, selection of the quartz crystal growth method can minimize the potential effect. The devices and materials of concern and the most serious radiation induced effects are: MOS devices (threshold voltage shift, decrease in drive current and switching speed, increase in leakage current). Bipolar transistors (hFE degradation, especially at low collector current; leakage current), and junction field effects transistors (JFETs) (enhanced source-drain leakage current). Analog microcircuits (offset voltage, offset current and bias-current changes, gain degradation). Digital microcircuits (enhanced transistor leakage, or logic failure due to decrease in gain (bipolar devices) or changes in threshold voltage and switching speed (CMOS)). Quartz resonant crystals (frequency shifts). Optical materials (increased absorption). External polymeric surfaces (mechanical degradation). (2) Transient Ionization Effects (Interference) Interference is defined as transient ionization effects that persist only while the electronics are being irradiated, and whose severity is generally proportional to the dose rate. Interference effects depend primarily on the rate of ionization energy deposition, i.e., the dose rate measured in rads (material)\/sec. There are four types of interference in electronic devices and optical materials: Primary photocurrents in low current input stages to the electronics. Electron emission from cathodes of electron multiplier-type detectors. Ionization-induced conductivity in photo-sensitive materials, such as those in detector surfaces. Ionization-induced fluorescence in optical materials such as detector windows and lenses (fluorescence efficiencies vary strongly with the material). (3) Displacement Effects Displacement of atoms in crystal lattices cause permanent changes in material properties. The expected proton and electron fluences usually do not represent as severe an environment for displacement effects as for long-term ionization effects. Therefore, only the most sensitive devices will be affected significantly by displacement effects. Displacement effects can impact the following electronic devices and properties: Bipolar transistors (gain, saturation voltage) PN junction diodes (forward voltage, leakage current). Light emitting diodes (LED) (light emitting efficiency). Semiconductor photodetectors (sensitivity). Linear integrated circuits incorporating lateral p-n-p transistors. RDM Factor Determination (1) Radiation Hardness Determination There are at least five quantities that can contribute to uncertainty in part radiation susceptibility: Statistical variations in parts from a specific manufacturing line, Part type, Manufacturing process, Circuit design, and Circuit application. There are many different part types, many circuit designs and applications and perhaps several different manufacturing processes. Consequently, the uncertainty in the capability of the part to withstand radiation has to be sufficiently large to account for the large variations from part to part. Most of these part variations are difficult to quantify. Testing is the only method for determining the radiation capability to be expected in a given flight lot, but this typically is done with only a small sample of devices. Testing conditions may also affect results. For some linear integrated circuit devices, the total ionizing dose (TID) capability could drop dramatically if tested with a low dose rate instead of a high dose rate. For example, OP42 was formerly rated a radiation-hard device (> 100 Krads), but was recently found very soft (~ 15 Krads or lower) when tested with the low dose rate more typical of a flight environment. As modern electronic parts have higher capacity and smaller volume compared to those used on Voyager and other older spacecraft, they may be more delicate and vulnerable to deposited charges. (See quotRadiation Effects.quot) It will be prudent to carefully examine RDMs of higher magnitude on future spacecraft programs or to refine the part radiation hardness determination technique if an RDM of 2 or lower is demanded. Part radiation hardness testing is considered a cost driver because more accurate testing requires more samples, more realistic radiation sources and conditions simulating spaceflight, and longer test time. (2) Radiation Environment Calculation Definition of the local ambient radiation environment is dependent on the mission design, the environmental radiation models, the radiation transport code, and the spacecraft mass model. The calculated radiation environment might be the total ionizing dose (TID), the 20 MeV equivalent proton fluence for displacement damage, or the flux for detector interference effects. The uncertainty in the radiation model depends on the modeled environment and on the mission design. Uncertainties in the mission design are difficult to quantify. Parameters include the trajectory (heliocentric distance, mission length, altitude, inclination, etc.) and launch date. The uncertainty in the radiation environment depends on the environment in question. For example, prediction of the proton fluences from solar flares is treated probabilistically, and the discrepancy between predictions for the 10 MeV fluence between two different solar flare models is a factor of 2 (at the 95 percent confidence level) (Ref. 1). Similarly, the uncertainties in the Jovian trapped electron environment and the Earthi\u0301s trapped radiation proton model AP8 are estimated to be also a factor of 2. The uncertainties resulting from the use of different radiation transport codes and different spacecraft mass models are generally less than a factor of 2 (Ref. 1). Typically, once the mission design is confirmed, the TID as a function of shielding thickness (dose-depth data) are generated for a simplified geometric mass model such as a spherical shell model. Figure 1 is an example for a flight mission at 1 AU from the sun during the solar max period. It is standard practice to apply the dose-depth curve of 95 percent confidence level for the flight assembly design. This radiation dose curve can be used to obtain conservative quotfirst-lookquot shielded dose values without hardware configuration modeling. These dose plots should only be used to obtain dose value by using the minimum shield thickness applicable to a given hardware location. Since these plots do not represent the flight hardware configurations, they should be used for design assessment only if they are applied in a conservative manner (minimum shield thickness used). If a part does not meet the RDM value of 2 requirement based on this conservative TID level, a three-dimensional mass model simulating the flight assembly is then constructed for the radiation transport code. The resulting TID level will be lower than the TID data from the spherical shell model, and therefore the part is more likely to meet the RDM requirement. However, when the part\/component package has to be included in the 3D mass model or a spot shield has to be added, the RDM is increased from 2 to 3 as explained earlier. The more extensive radiation\/shielding calculations tend to be a cost driver, but it relieves the shielding requirement and saves more mass. [D] Figure 1. Radiation Dose from Solar Flare Protons for 1 Year at 1 AU Technical Rationale: The uncertainties in radiation environment estimates and the part or component radiation capability determinations lead to RDM values between 3.5 to 11.5 (Ref. 1). Historically, the introduction of an RDM value of 2 stems from the Voyager project and was established based solely on available mass. An RDM much greater than 2, perhaps as high as 10, would have been selected to cover all uncertainties were there sufficient mass available (Ref. 1). The RDM of 3 is imposed when the local shielding such as component\/part packaging or spot shielding is taken into account. There is an implied greater risk associated with taking the local shielding into consideration because this is done in cases where soft parts must be used; one is dependent on local shielding and its calculated effectiveness rather than on an inherently hard part. The selection of an RDM may be somewhat arbitrary and will tend to be driven by mass limitations, acceptable risk versus cost, and the overall radiation hardness program. Resource and mass limitations which preclude usage of conservative RDMs are typically imposed on flight projects. Based on the i\u0300besti\u0302 radiation model at the time, the part radiation hardness test data, and the expected mass and other resource limitations, a radiation design factor of 2 (3 if local shielding is considered) is required for spacecraft elements intended to operate during a flight mission. The term used to describe this radiation design factor, radiation design margin or RDM, may be a misnomer. quotDesign marginquot suggests a known factor of safety, which translates as a high degree of certainty of survival in the radiation environment. Instead, the RDM arises from significant uncertainties in all the elements of the radiation susceptibility calculations. It may be more appropriate to refer to a radiation design factor instead of implying the existence of a conservative margin. An RDM value of 2 should not be interpreted as a 100 percent margin as it is sometimes misconstrued. Although an RDM of 2 does not cover the uncertainties, it proved affordable and effective on the Voyager mission. As defined earlier, the RDM is the ratio of the part or component radiation capability, in the given application, to withstand the expected radiation environment at the part or component location for a flight mission. The use of RDM as a spacecraft design tool acknowledges that there are uncertainties in environmental calculations and part radiation hardness determinations. References: JPL IOM 5217-88-39, quotRadiation Design Margins,quot S. B. Gabriel to Distribution, September 22, 1988. JPL IOM 5217-91-208, quotRadiation Design Margin for CRAF\/Cassini Missions,quot G. Murphy and R. Kemski to Distribution, February 14, 1992. JPL IOM 5137-87-233, quotComparison of Predicted and Observed Radiation Levels for Voyager Outer Planet Flybys,quot N. Divine and R. Ridenoure to C.E. Kohlhase, August 5, 1987. quotTotal Dose Hardness Assurance Design Guidelines,quot Defense Nuclear Agency Report No. DNA5909F, February, 1982. Environmental Factors, Reliability Preferred Practice No. PD-ED-1101 Design and Analysis of Electronic Circuits for Worst Case Environments and Part Variations, Reliability Preferred Practice No. PD-ED-1212.","Lesson ID":792}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PD-AP-1310, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Benefit: Spurious radiated interference can be identified and evaluated during the design phase of the project. Solutions can be proposed and implemented in the design phase with far less impact on cost and schedule than when changes are required later. Implementation Method: To perform an intermodulation analysis requires two lists to be prepared. The first list includes the center frequencies and bandwidths of all strong radiators in the vicinity and the frequency of all internal oscillators. The second list includes the frequencies and bandwidths of all receivers and intermediate frequency amplifiers. The number of possible interference frequencies can be a very large number when there are more than a few emitters. Interference results from the sums and differences of all the emitter frequencies and their harmonics taken two at a time. A computer program is utilized to identify potential interference frequencies. Two computer programs are listed under References. The first referenced computer program solves the equation below for up to 200 emitter and receiver frequencies. (F0-BW\/2) < [(n x Ft)\u00b1(m x Ft)] < (F0 + BW\/2) where: F0 = receiver center frequency of each receiver BW = bandwidth of the receiver Ft = list of all emitter frequencies n = harmonic number of each emitter frequency, integers from 1 to h m = harmonic number of 2nd emitter, integers from 0 to h. h = highest harmonic to be selected When potential interference frequencies have been identified, the possibility of their occurrence is evaluated. After positive identification, alternate approaches to eliminating the problem are examined. Alternate approaches include eliminating the non-linearity which causes intermodulation or reducing the amplitude of either of the two emitted signals at the non-linear component. The second referenced computer program is more comprehensive and includes amplitude analysis. Technical Rationale: In an environment of strong field intensities from nearby emitters and complex equipment, surface currents are known to intercept non-linearities in components or conductors. These may be mixer diodes closely coupled to antennas, or contaminated joints between dissimilar metals. These conditions result in rectification of the current which produces odd harmonics of single frequencies and intermodulation products where multiple frequencies occur simultaneously. These spurious signals couple to receiving antennas, producing interference. With multiple frequencies, a large number of harmonics and sums and differences of all possible combinations of the frequencies will occur. Harmonics of local transmitters often cause interference up to their 5th harmonic when they are fairly well filtered, or much higher harmonics when they are not well filtered. The number of intermodulation products to be tested for interference can be large, therefore a computer program is useful in finding the sources of potential interference for each receive frequency and for a number of different bandwidths. References: Paul Rosales, \"Intermod\", Lockheed Advanced Development Co., Palmdale, California, January 1987 - Updated by T. Larter, JPL, May 1991 Jerry Stafford, \"Electromagnetic Compatibility Frequency Analysis, EMCFA\", IBM, Huntsville, Alabama, March 1969 - Updated for the Space Shuttle Program by Arthur Reubens and John Roth, April 1975","Lesson ID":798}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PD-AP-1315, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Benefit: By using a systematic method to assure the switching functionality of designed-in redundancy, the long-term performance of complex systems can be assured. Implementation Method: Redundancy switching analysis (RSA) is a subset of the general FMECA process, but it is performed in greater detail because of its criticality. RSA includes the following steps: Identify and diagram all functional blocks which involve the two redundant elements. Expand the functional blocks to show the interface circuitry at the piece part level. Postulate all credible part failures (viz, shorts, opens, saturated high or low, etc.) and determine the effect on the functional redundant path. Verify design compliance with the following objectives: Hardware failures do not propagate across inter-unit interfaces to produce hardware failures in other units. There is sufficient isolation that the postulated failure does not produce a functional failure capable of disturbing the transfer to, or operation of, the redundant function. Technical Rationale: There have been numerous instances of presumably redundant systems which have failed to successfully transfer to the backup path when the primary path is non-functional. A rigorous, systematic search could have foretold the failure and, through design change, averted the problem. The first objective-- preventing failure propagation-- is of most value in a repairable system. Non-propagation minimizes the number of units requiring repair. In spacecraft, this would correspond to the preflight phases of either subsystem or system testing. The key to this investigation is a complete diagram of the involved interface circuits which penetrates each unit to a circuit depth sufficient to prove that no possible failures in Unit 1 can propagate to become irreversible hardware failures in Unit 2. The second key ingredient is a complete list of part or assembly failure modes for hypothesis. The second objective-- guaranteeing successful transfer (or equivalently independence of the primary and back-up functions)-- is a necessity for either repairable or non-repairable systems and requires the same complete interface diagram and complete list of failure modes. The list includes such items as: Part failure (viz, opens, shorts, stuck-ats), Single event effects (viz, latch-up, transfer), and EMI (viz, latch-up, transfer, overvoltage). These last two items are critical since they can effect both sides of a redundant pair. Figures 1 and 2 are illustrations of the process of a redundancy switching analysis for several typical interface Observation: If the postulated short exists and source A is unpowered, its quotoffquot-state load resistance must be high compared to the quotonquot-state source resistance of source B to assure that adequate VA voltage will be received at LOAD A. If not, the diodes must be made series redundant. [D] Figure 1: Example of Passive Redundancy Switching for Cross-Strapped Dual Sources and Dual Loads Observation: If the postulated short exists, the isolation resistor R1 must be large compared to the output source resistance of amplifier A1 to assure that adequate VB voltage is received at LOAD B. [D] Figure 2: Example of Passive Redundancy Switching for Single Source and Dual Load References: Polovko, A.M. (1968). Fundamentals of Reliability Theory, (Chapter 5-4). New York: Academic Press, Inc. Feduccia, A.J. (1993). Reliability Engineeri\u0301s Toolkit. Griffiss Air Force Base, New York: Rome Laboratory.","Lesson ID":799}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1402, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Benefit: Demonstrates readiness of the hardware to operate in the intended cyclic environment. Precipitates defects from design or manufacturing processes that could result in flight failures. Implementation Method: As part of ATP, run at least eight thermal cycles over the temperature range experienced by the hardware during storage, shipping, launch, flight, and reentry. The maximum and minimum temperatures anticipated should be exceeded by 10 degrees C. The last three thermal cycles should be failure-free. Equipment must stabilize at these limits before cycling to the opposing limit. Equipment generally should be operated within the anticipated thermal range rather than at the thermal limits. Thermal cycling should be conducted in a vacuum if the test item is designed to operate in a vacuum. Technical Rationale: Thermal cycle modeling has shown that the general form of the thermal cycling test math model is given by Equation (1). [D]: Where: TE = Test Effectiveness F = Fraction of total failures that can be recipitated by a thermal cycle Pd = Probability of detection lO = Failure rate at TO N = Number of thermal cycles K = A constant DT = T - TO T = Operating temperature for l TO = Operating temperature for lO Fig. 1 shows that the failures available are the sum of three parts: Failures detected by thermal cycle tests Undetected failures Failures not precipitated [D] Figure 1: General Form of TC Test Model For single temperature range of 50oC, the test effectiveness equation reduces to Equation (2). [D] Figure 2 shows a plot of Equation (2) based on a probability of detection, Pd, of 0.9. The equation is based on values of lO and K that were found by solving two simultaneous equations. [D] Figure 2. Test Effectiveness Plot for lT = 50 oC Printed circuit boards (PCBs) are especially prone to solder joint cracking. The design is required to minimize the mechanical forces, as generated by thermal mismatch of materials or vibration, in the solder joints. References: GDCD BNZ 69-007, Curssell, G. M., Atlas and Centaur Component Acceptance Test Plan, 1984. NASA TMX-53731, Van Orden, R. E., Mounting of Components to Printed Wiring Boards, 1968. Laube, R. B., Space Vehicle Thermal Cycling Test Parameters, Proceeding of the Institute of Environmental Sciences, 1983. Nelson, C. E., System Level Reliability Thermal Cycling, Proceeding of the Institute of Environment Sciences, 1983.","Lesson ID":810}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1424 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Leak testing of a Liquid Hydrogen (LH2) and a Liquid Oxygen (LO2) propellant system prior to flight insures that the flight leakage rate does not exceed allowable leakage established for flight. Leak testing also insures the quality and reliability of a Space Shuttle Element and reduces the probability of system failure. Leak checks also prove that seals and sealing surfaces at joints are defect free and seals are seated correctly. Implementation Method: A leak is the result of cracks, holes, porosity, permeability, surface aspirates or scratches in a pressurized container or joint that allows the escape of liquid or gas. Leak test methods and procedures are designed for detecting, locating leaks, and ensuring the quality, serviceability and safety of components, structures and the entire propellant system. Leak testing can be a time consuming and expensive task but should be implemented when necessary to protect product integrity or personnel safety. One of the most important steps in leak test development is to establish the specification for acceptable and unacceptable leak rates. Choosing the most effective and reliable leak testing method is also important. Leak testing methods and sensors include the following: Acoustical - escaping gas that is audible or can be detected using acoustical instrumentation. Odor - from tracer gas. Leak test solution - bubbles form when applied over escaping gas. Pressure decay - pressure loss over time. Pressurized liquid - normally water, leakage can be seen. Trace gas - color\/radiation\/odor. Gas chromatography. Halogen leak detection - requires use of alcohol torch (blue flame) with a sniffer tube when small amounts of fluorine, chlorine bromine, etc. enter the tube then the blue flame turns to a different color. Helium leak detectors - detects leakage of small amounts of helium. Flow meter - detects the volume of gas escaping over a specified time. Bubble gauge - monitors inter seal leakage between primary\/secondary when primary pressurized. Light refraction. Mass spectrometer. Hydrogen sensors. Oxygen sensors. Electronic detectors. Liquid sensitive electrical aluminum tape. This reliability Practice covers MSFCi\u0301s experience for ensuring that the External Tank, as an element of the Space Shuttle Transportation System, has developed an acceptable leak detection system and leakage verification program for the cryogenic propulsion oxidizer and fuel systems, Liquid Oxygen (LO2) and the Liquid Hydrogen (LH2) tanks. EXTERNAL TANK Extra effort is devoted to the procurement of defect-free raw material. Aluminum plate has been ultrasonic tested at the mill. The skin panels are placed into a weld fixture and welded using the variable polarity plasma arc (VPPA) or TIG welding method. After welding, the welds are x-rayed and penetrant inspected (defects are repaired as required). When the LO2 tank has been assembled, the welds are wrapped with an aluminum tape which has an adhesive that is soluble in water. The LO2 tank is then hydrostatically tested. If a leak is encountered during hydrostatic testing, the water will dissolve the adhesive and provide electrical continuity through the aluminum foil tape. A leak could then be isolated and repaired. After the LH2 tank has been assembled, it is pneumatically proof tested with gaseous nitrogen (GN2). Leakage is checked with bubble solution at a reduced pressure after proof test. After the LO2 tank\/intertank assembly is joined to the LH2 tank, the propulsion delivery systems are installed on the tanks. The propulsion delivery systems consist of the LO2 and LH2 feed lines, recirculation line and pressurization lines. The propulsion delivery system lines are joined with bolted flanges containing Naflex or Raco\/Creavey seals to control leakage. The Raco\u00ae\/CreaveyTM seal consists of a primary and secondary seal set. The primary seal is a Raco\u00ae seal that is a pressure activated seal consisting of a Teflon jacket over an Inconel 718 spring. The secondary seal is a CreaveyTM seal, which is a tubular Teflon cover with a stainless steel spring core that forms an quotOquot ring type seal. For Raco\u00ae\/CreaveyTM seal arrangement, see Figure 1. This two-seal arrangement provides for means for leak checking the primary seal or the total leak rate of the primary and secondary seals. For the Naflex seal arrangement, see Figure 2. The bolted flanges for both types of seals have a leak test port that has been proved to be blockage free. The allowable leakage rate for the Raco\u00ae\/CreaveyTM seals is 0.183 SCIM of helium at 50 \u00b1 5.0 PSIG and ambient temperature. The propulsion line mechanical joints are leak checked in final assembly by pressurizing the leak check port to either 6 or 50 PSIG through a flow meter. The LH2 & LO2 tank and propulsion lines are pressurized to 6 PSIG with GN2 and the leakage rate of i\u0300bi\u0302 nuts and K seals are checked using the leak test solution bubble test (no bubbles in three minutes). [D] Figure 1. Raco \u00ae\/Creavey TM Seal Configuration (not to Scale) [D] Figure 2. Naflex Pressure Assisted Seal (Not to Scale) The LO2 and LH2 tanks remain pressurized to 6 PSIG during storage and could stay pressurized for several years. The tank pressure is monitored and if it decays too rapidly action will be taken to find the leak. During the entire ET program, no repairs have been required for flight hardware. Technical Rationale: The rigorous leak check and nondestructive testing on the External Tank program have contributed to more than fifty successful flights of the Space Shuttle. Leak testing methods performed on the ET including bubble solution, water soluble adhesive on aluminum tape, flow meter testing and pressure decay testing. These techniques have proven to be effective in maintaining 100 percent mission success. References: MMC-ET-SE 25-0: quotSystem Definition Handbook, Space Shuttle External,quot Volume I & II, National Aeronautics and Space Administration, Martin Marietta, August 1987. Bray, Don E. and Don McBride: quotNondestructive Testing Techniques,quot John Wiley & Sons, Inc., 1992. Metals Handbook, Volume 17: quotNondestructive Inspection and Quality Control,quot ASM International, Metals Park, OH, 1989. quotIntroduction to Helium Mass Spectrometer Leak detection,quot Varian Associates, Inc., Palo Alto, CA 94303, 1980. McMaster, Robert C.: quotNondestructive Testing Handbook, Leak Testing,quot Volume 1, American Society for Nondestructive Testing, Inc., 1985. Hammock, W. R. Jr., P.E. Cota, Jr., B.J. Rosenbaum, and M. J. Barrett: quotInvestigative Techniques Used to Locate the Liquid Hydrogen Leakage on the Space Shuttle Main Propulsion System,quot NASA, Johnson Space Center, AIAA SAE\/ASME 27th Joint Propulsion Conference, Sacramento, CA, June 24-26, 1991. Szemenyei, B., R. Delcher, M. Randall, E. Schmidlin, and S. Barkhoudarian: quotGround-Based and In-flight Leak Detection for Rocket Engines,quot X91-10319 Rockwell International\/Rocketdyne Division, Canoga Park, CA. Barile, Ronald G.: quotHazardous Gas Leak Analysis in the Space Shuttle,quot N92-19308, 1991 NASA\/ASEE Summer Faculty Fellowship Program, Kennedy Space Center, University of Central Florida, August 22, 1991. Barile, Ronald and William Helms: H2 Leak Detection Technical Interchange Meeting at KSC, Proceedings, April 29, 1992. S-69-117: quotLeakage Testing Handbook,quot JPL\/GE NTIS N-69-38843, July 1969. Reliability Preferred Practice PD-ED-1208, Static Cryogenic Seals for Launch Vehicles. Reliability Preferred Practice PD-ED-1205, Weld Practices for 2219 Aluminum and Inconel 718.","Lesson ID":812}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1404, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. This test, coupled with rigorous design practices, provides high confidence that the hardware design is not marginal during its intended long life high reliability mission. Establish a minimum hardware test temperature level range of -20\u00b0C \/ +75\u00b0C and specify that a single cycle thermal dwell test be performed for the appropriate durations (24 hours cold and 144 to 288 hours hot). In the early 1960s, JPL adopted a conservative set of thermal design and test temperature levels to demonstrate hardware design adequacy. As a starting point, a reasonable short term flight temperature excursion (+5\u00b0C to +50\u00b0C) was established for thermal control surfaces (shearplates). The +5\u00b0C lower level is a few degrees Celsius above the freezing point of hydrazine, thus integrated thermal control of bus electronics and propulsion systems is possible. The 50\u00b0C upper limit is the approximate level reached by a louvered bus electronics bay after about one hour of full (perpendicular) solar irradiance at one A.U. (astronomical unit) and accommodates near earth maneuvers. The long term desired thermal control range is typically 25\u00b15\u00b0C, but this range may be broader depending on the tradeoffs of long term reliability and thermal control costs. This original approach reduced the overall complexity of the system thermal control design process: the wide range reduced the sensitivity to louver\/radiator size, heater size, power variations, etc. A margin of \u00b125\u00b0C was then applied to the allowable flight range for qualification and protoflight test levels of assemblies mounted to such thermal control surfaces. These levels accommodate thermal compromises in the design where the short term extremes may be approached during steady state operation; they also have been demonstrated to provide an effective screen of assemblies. This resulted in the JPL standard minimum test range of -20\u00b0C to +75\u00b0C (for electronic assemblies in particular). These conservative test level ranges lead to several desirable features. The conservative high temperature limit restricts the permitted temperature rise from the shearplate to the junction of electronic piece parts. Thus junction temperatures during the bulk of a mission are much cooler than assemblies designed and tested at lower shearplate temperatures. The increase in theoretical reliability is on the order of a factor of 10 per 25\u00b0C. (refer to quotPart junction Temperaturequot, Reliability Preferred Practice No. PD-ED-1204) There are at least two failure mechanisms for both design and workmanship that should be screened by an adequate thermal environmental test of any given assembly. The first is based on Arrhenius rate related physics where time at high temperature is the key to demonstrating reliability during testing. Electronic part life is a prime example of an Arrhenius mechanism, but so are other elements of assemblies including interactions between metal traces within printed wiring boards (PWB's), certain component to board joints, and even solder joints to a certain extent. The other identifiable mechanism is thermally induced mechanical stress (including fatigue) as between components and the board and especially solder joints. Arrhenius Rate Physics: Contrast the test level of 75\u00b0C (shearplate) to 50\u00b0C short term worst case transients during flight and 25\u00b0C for the bulk of the mission. Based on Arrhenius reaction rate physics described in the following figures, the 75\u00b0C test provides a demonstrated reliability some 2 to 8 times that of short transients to 50\u00b0C, (typical of thermal cycling tests), and some 4 to 94 times that of long term mission shearplate temperatures (25\u00b0C). These reliability ratios are based on activation energies of 0.3 eV to 1.0 eV which cover most assembly element reaction physics. [D] [D] The Mariner and Viking spacecraft performed a hot dwell test (75\u00b0C) of 288 hours duration. This was reduced to 144 hours for the Voyager and Galileo spacecraft. The statistical database supporting this shorter test is unique to the JPL design rules and processes; therefore, the longer hot dwell duration of 288 hours is recommended for assemblies designed to non-equivalent or less conservative practices. The following figure shows the percentage of the screening test capability for Class S parts that is used by a JPL assembly test at 75\u00b0C for 144 hours. A very conservative assumption here is that all parts in the assembly test have a 35\u00b0C temperature rise and that they are at 110\u00b0C for the entire test. Even given this over-conservative assumption, the JPL test uses only 0.018% of the class S parts minimum screened capability. Clearly less than 2\/10000's of the minimum parts capability being dedicated to the assembly protoflight test is not a concern. The parts are not over-stressed by this test. [D] Thermally Induced Mechanical Stress (Fatigue): JPL has historically done a thermal dwell test rather than a specific thermal cycle test. There are data that indicate thermal cycling uses up hardware life and therefore is degrading to the flight hardware. In practice, the JPL test approach is never really just a one-cycle dwell test. The assembly test program (plus any retest) and the systems test program (frequently two phases) result in a minimum of two cycles and as many as four (or more) are possible although they are not continuous and the transients are controlled to < 30\u00b0C\/hr to prevent thermal shock. The Voyager hardware was tested as follows: [D] In a recent JPL study, a fatigue life relationship of equivalent thermal cycles was determined over different temperature ranges as follows: [D] where: C 1 is the number of thermal cycles over a T 1 range C 2 is the number of thermal cycles over a T 2 range and Y = 2.6 for eutectic solder. As a frame of comparison for workmanship purposes, the JPL protoflight test of 1 cycle over -20\/75\u00b0C range can be correlated to an acceptance test of 6 cycles over a 0\/50\u00b0C range. In this case: C1 = 1, T1 = 95\u00b0C, C2 = TBD, T2 = 50\u00b0C and the equivalent cycles of the JPL test are: C2 = 1(95\u00b0C\/50\u00b0C)2.6 = 5.3 cycles. Therefore, in terms of solder joint fatigue life, the JPL protoflight test equivalency to 5.3 cycles over a 50\u00b0C range says that, for workmanship acceptance purposes, the JPL protoflight test is essentially the same as the example thermal cycle acceptance test, i.e., 5.3 equals approximately 6 cycles. The following figure provides comparison of solder joint fatigue life. The recommended -20\/+75\u00b0C single cycle dwell test uses only 0.14% of the fatigue life of a solder joint qualified to NHB 5300.4 (3A-1). The point of this comparison is that the JPL protoflight test is less strenuous to solder joints than thermal cycle testing performed by most organizations. [D] Ground Test & Thermally Related Problem\/Failure Statistics: These practices were applied to the Mariner spacecraft series, the two Viking 75 spacecraft, the two Voyager 77 spacecraft, and more recently Galileo. These spacecraft all completed (or exceeded) their intended mission successfully (the Galileo mission is still underway at the time of this edition). In fact, the Voyager spacecraft have worked for over 13 years. The total number of assembly problems\/failures during these missions is small, and the number of thermally induced problems even smaller. This is shown in the following table where the number of problem\/failures identified during assembly level thermal testing are compared with suspected flight problems\/failures for the Viking, Voyager, and Galileo programs: [D]","Lesson ID":783}
{"Driving Event":"An excavation was done to facilitate the installation of a larger water line to service a buildings fire sprinkler system. Shortly after the excavation was filled a large sinkhole developed. During the installation of the sprinkler heads, it was noticed the heads installed were not the ones the in the requirements of the contract.","Lesson ID":748}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1408A, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Benefit: Early assembly-level pyroshock testing can often reduce the impacts of design and manufacturing\/assembly deficiencies upon program cost and schedule prior to system-level test. Such testing can provide a test margin over flight pyroshock conditions which cannot be achieved in system testing. Conversely, system-level shock testing can be used to verify system performance under pyroshock exposure, thus providing increased confidence in mission success and verifying the adequacy of the assembly-level tests. Implementation Method: Pyroshock testing of assemblies may be achieved by using one of the following types of sources: An explosive device [Ref. 1,2], Impact of one structural member (e.g., a hammer) upon another (e.g., a beam, plate, shell, or combinations thereof) [Ref. 2-5], or A vibration exciter or shaker programmed to generate short duration transient motion [Ref. 2,3,6,7]. JPL has historically used a shaker, or a beam or plate excited by an explosive device or by hammer-type impact. The test magnitude should include a margin over maximum predicted flight conditions, which at JPL is commonly selected to be equal to 1.5 times the maximum expected flight environment over a frequency range anticipated to encompass the critical resonant frequencies of the test article. This test condition is monitored by accelerometers located at the facility\/test article interface. Usually three shocks are specified for qualification testing, or one shock for protoflight, in each of three orthogonal directions. In most cases, the test article is electrically powered and operational, even when no power is to be applied to the hardware during the flight event. For system-level acceptance testing, the actual pyrotechnic or explosive device(s) are commonly used, with multiple firings (three at JPL) of the devices that generate the dominant shock environment(s) applied to account for firing-to-firing variations. Power-on testing is normally utilized, with the operational mode applicable to the flight pyro event monitored. Pyroshock tests nearly always utilize instrumentation for the purpose of environmental evaluation or test control. Pyroshock measurements are normally made with accelerometers despite some potentially serious deficiencies. Often in the near-field (within 6 in. or 15 cm) and sometimes in the mid-field (within 2 ft or 60 cm) of the source, improperly selected accelerometers may break, hard-bottom, or saturate under pyroshock loading, or incorrectly-set signal conditioners may saturate if accelerometer resonances are sufficiently excited [Ref. 8-10]. Such nonlinear responses will usually make the resulting data invalid over the entire spectrum. Once valid signals are acquired, routine data analysis is performed to provide the desired acceleration time histories and shock response spectrum (SRS) [Ref. 11]. The SRS is utilized with natural frequencies usually selected to correspond to either 1\/3 or 1\/6 octave band center frequencies and a constant quality factor selected as Q=10. Assembly-level test control is usually specified to match the desired SRS, with additional limits placed on total shock duration. With impacting and explosive shock simulation, this SRS matching is usually performed iteratively with a dynamically similar model. With shaker shock simulation, the SRS matching is performed automatically at low levels, checked at intermediate levels, and then applied at full level. Pyrotechnic shock or pyroshock is the transient motion of structural elements, assemblies, subsystems, or systems due to explosive loading induced by the detonation of ordnance devices incorporated into or attached to the structure. Pyroshock is often characterized by its high peak acceleration (300 g- to 300 kg), high frequency content (100 Hz to 1 MHZ) and short duration (10 \u00b5sec to 20 msec), which is largely dependent on the source type and strength, structural type and configuration, and especially the distance from the source to the response point of interest. For aerospace applications, explosive devices are generally used to separate structural subsystems (e.g., payloads from launch vehicles), deploy appendages (e.g., solar panels), or activate on-board operational subsystems (e.g., propellant valves) [Ref. 1,2]. In certain cases, the explosive loading may be accompanied by the release of stored energy due to structural preload. Current spacecraft design often utilizes numerous explosive devices over the course of a mission. JPL has historically utilized most of the available pyrotechnic or explosive devices, which can be divided into two general categories: point sources and line sources. Point sources include explosive bolts, separation nuts, pin pullers and pushers, bolt and cable cutters, and certain combinations of point sources and operational hardware (e.g., pyrovalves). Line sources include flexible linear shaped charges (FLSCs), mild detonating fuses (MDFs), primer cords, and certain commercially-available products intended to capture explosive and structural debris after separation (e.g., Super-ZipTM). Point and line sources have also been combined: V-band (Marmon) clamps use point explosive sources which may then allow the rapid release of stored strain energy from a structural preload acting along a line of contact between the two structures being separated. Because of the high frequency content, many small elements resistant to random vibration are susceptible to pyroshock induced failure. Numerous flight equipment failures have been attributed to pyroshock exposure, some resulting in catastrophic mission loss [Ref. 12-13]. Particular examples of pyroshock induced failures include cracks and fracture in crystals, ceramics, epoxies, glass envelopes, solder joints and wire leads, seal failure, migration of contaminating particles, relay and switch chatter and transfer, and deformation of very small lightweight structural elements. On the other hand, deformation or failure of major structural elements is rare except in those regions close to the source where structural failure is intended. If feasible, assembly-level pyroshock testing should be performed with the test article powered and operational, even when no power is to be applied to the hardware during the flight event, to improve the detection of intermittent failures which might not otherwise be detected until much later in the test program or in flight. Certain hardware can be expected to malfunction during pyroshock exposure but will resume operation within tolerance after the event. Analytical methods and computational procedures have historically been inapplicable to pyroshock prediction. Thus, pyroshock is considered to be an experimental art [Ref. 4,5,7]. References: Kalbfleisch, K.C., \"Review of Pyro-Shock Generating Devices and Source Levels\", IES Pyrotechnic Shock Tutorial Program, 31st ATM, Institute of Environmental Sciences, Apr.-May 1985. Powers, D.R., \"Pyro Shock Test Simulation Methods\", IES Pyrotechnic Shock Tutorial Program, 31st ATM, Institute of Environmental Sciences, April-May 1985. Powers, D.R., \"Summary of Testing Techniques\", Shock and Vibration Bulletin, No. 56, Pt. 3, pp 135-142, August 1986. Davie, N.T., and Bateman, V.I., \"Pyroshock Testing\", Shock and Vibration Handbook (C.M. Harris, Ed.), 4th ed., Ch. 26, Pt II, McGraw-Hill, NY, 1996 Bateman, V.I., and Davie, N.T., \"Recommended Practice for Pyroschock\", Proceedings of the 41st ATM, Institute of Environmental Sciences, pp 208-216, April-May 1995. Luhrs, H.N., \"Equipment Sensitivity to Pyrotechnic Shock\", Proceedings of the 22nd ATM, Institute of Environmental Sciences, pp 3-4, April 1976. Zimmerman, R.M., \"Pyroshock Bibliography\", Proc. 39th ATM, Institute of Environmental Sciences, Vol.2, pp 471-479, May 1993. Himelblau, H., Piersol, A.G., Wise, J.H., and Grundvig, M.R., \"Handbook for Dynamic Data Acquisition and Analysis\", IES-RP-DTE012.1, App. A, Institute of Environmental Sciences, Mt. Prospect, IL, March 1994. Piersol, A.G., \"Recommendations for the Acquisition and Analysis of Pryoshock Data\", Sound and Vibration, Vol. 26, No.4, pp 18-21, April 1992 Piersol, A.G., \"Pyroshock Recommendations in Proposed MIL-HDBK on Guidelines for Dynamic Data Acquisition and Analysis\", Journal of the Institute of Environmental Sciences, Vol. XXXV, No. 5, pp21-26, Sept-Oct. 1992. Ref. 8, Sec. 5. Moening, C.J., \"Pryotechnic Shock Flight Failures\", IES Pryotechnic Shock Tutorial Program, 31st ATM, Institute of Environmental Sciences, April-May 1985. Moening, C.J., \"Views of the World of Pyrotechnic Shock\", Shock and Vibration Bulletin, No. 56, Pt. 3, pp 3-28, August 1986. \"Powered-On Vibration,\" Reliability Preferred Practice No. PT-TE-1405.","Lesson ID":780}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PD-AP-1303, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Part failure rates are proportional to their applied electrical and thermal stresses. By predicting the stress through analysis, and applying conservative stresses, the probability of mission success can be greatly enhanced. Electrical circuits are analyzed to determine the maximum stress on each part when all applied voltages or currents are maximized and when all variations of other parts in the circuit are set to that combination of minimum and maximum values that produce worst-case maximum stress. This requires a new choice of \"other\" part combinations in the circuit each time the stress on a new part is determined. The stresses are aggravated by imposing maximum operating temperature when comparing the part stress to its required derating. The initial analysis usually is made without benefit of a detailed part level thermal analysis; therefore, a conservative temperature assumption is made. Highly stressed parts are identified for possible replacement with more robust parts or for possible circuit changes. The final design is confirmed by analysis, with part temperatures based on a part level thermal analysis, and with voltages and currents derived from either specification limits or the results of worst-case circuit analysis. Numerous life tests have been performed on electrical parts that establish the relationship of part life to applied stresses. There is a very strong dependence. The life expectancy typically can be doubled or tripled by operating at half the manufacturers full rated (100 percent) stresses, which typically are commensurate with a 10,000-hour life expectancy. Complex, multiple year missions must achieve very low part failure rates to achieve mission goals; therefore, operation at derated conditions is mandatory. Although typical reliability predictions are based on nominal stresses, circuit nonlinearities and part and voltage variations can cause large operating point variations. Therefore, it is essential that the conservative approach of using worst-case stresses be implemented as standard practice. Although average temperatures during a mission may be nominal, typical qualification test philosophy results in test temperatures that stress the design to assure margin against possible flight contingencies (typically 75 degrees C). It is essential that negligible aging of the parts be introduced during protoflight testing to assure mission reserve life. For this reason, it is prudent to show that the deratings are met while operating in the worst qualification or protoflight test environment. Historical evidence has shown that significant (>40 degree C) temperature rises can exist between the thermal mounting surface of an assembly and the part body if good thermal design of the assembly is not rigorously pursued. For this reason, the results of a part level detailed thermal analysis must be an input to the part stress analysis. In summary, the stress derating requirements of every part at worst-case circuit conditions and contingency temperatures must be met. This will ensure a design that will function with a high degree of confidence at these extremes. It also will force a conservative thermal design (small temperature rises), which will produce even greater mission life margins under the expected nominal flight conditions. References Part Junction Temperature, Reliability Preferred Practice No. PD-ED-1204.","Lesson ID":782}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1407, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Benefit: Acoustic noise tests subject potentially susceptible hardware to a significant launch environment, revealing design and workmanship inadequacies which might cause problems in flight. Implementation Method: Apply broadband random acoustic noise (~ 25 to 5000 Hz) to the test item in a reverberant chamber. Control the noise level in one-third octave frequency bands with microphones (generally four or more) distributed around the test item at least one foot from test item surfaces. Technical Rationale: Random-incidence, broadband, random acoustic noise is employed to simulate the effects of the launch acoustic environment. The noise generated by launch vehicle engine exhaust during liftoff and by boundary layer turbulence during transonic and high dynamic pressure events is indeed broadband and random in nature. The acoustic environment that a payload is exposed to within a launch vehicle shroud does tend to be reverberant (random-incidence) in nature. In fact, the reverberant acoustic noise test is one of the most realistic environmental tests employed for payloads. Acoustic noise external to a launch vehicle is not random-incident; however, the actual acoustic wave angle of incidence distribution is seldom known. In practice, employing a random-incidence acoustic test envelops the effects of the flight environment. Acoustic noise is usually the most severe dynamic environment for a launch vehicle or payload in the mid to high frequency range (~ 50 to 2000 Hz). The acoustic pressure fluctuations will induce severe vibrations in relatively large lightweight structures, such as solar panels and reflectors, potentially causing failures of the structure or attached electrical components. These structures should be acoustically tested at the assembly level to avoid potential cost and schedule impacts of a failure during system level testing. The full up spacecraft acoustic test provides verification of the integrated system for the vibroacoustic environment, including verification of the adequacy of assembly random vibration requirements. The acoustic test also qualifies spacecraft elements, such as blankets, cable harnesses, plumbing lines, and secondary structure not tested at the assembly level.","Lesson ID":785}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1405, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Aids in the detection of intermittent or incipient failures in electronic circuitry not otherwise found. This reliability practice benefits even those electronics not powered during launch. Apply service power to electronics assemblies. Monitor as many circuits as possible for intermittent behavior or change in voltage\/current level. Record for later analysis the most critical electrical functions. Employ instrumentation such as a storage logic analyzer to monitor relay contacts, especially during pyroshock testing. The NASA and industry practice of powering electronic assemblies during dynamics testing has proven to be effective in uncovering otherwise undetected \"soft\" failures. Studies by the Institute of Environmental Sciences, the U.S. military, Tustin Technological Institute, Hobbes Engineering, and others have all arrived at the same general conclusion: power-on vibration is a valuable tool for exposing latent defects in electronic hardware with the eventual resultant improvement in product quality. Intermittencies in electronic circuitry can often be detected during vibration but may not be observed under ambient functional testing. These intermittencies may not reappear until after launch, where they sometimes degenerate into hard failures. Examples of these intermittencies include: Component shorts due to internal conductive particles, Loose or contaminated connectors, Fractured component-to-board solder joints, Electrical arcing, Data number changes in digital equipment, and Relay transfer or chatter. Powering of electronic equipment during vibration allows for detection of failures or intermittent conditions when they occur. This can be extremely useful in diagnosing the problem and formulating corrective action. In vibration, it is advantageous to know in what environment, level, axis, and time the anomaly occurred. Also, this procedure allows a test to be discontinued at the time the anomaly occurs to avoid the potential for further damage.","Lesson ID":784}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PD-AP-1302, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Benefit: This process of peer review serves to validate both the accuracy and the thoroughness of analyses. If performed in a timely fashion, it can correct design errors with minimal program impact. Technical Rationale: The creation of a well-functioning, highly reliable design requires the rigorous application of numerous design tools. Among these are Part Stress, Worst-Case Circuit Performance, Failure Modes and Effects and Criticality, Fault Trees, and Single Event Effects on Electronics. Each of these is a highly specialized field. The design or analysis engineer who performs these is usually the judge of the attributes to be examined and their exact depth of examination. The analyst also selects the analytical approach. All of these decisions are a function of the analyst's experience, wisdom, and perception of the program constraints and needs. For these reasons, it is very possible that omissions or inadvertent errors are occasionally made. Experience on the above noted programs as well as numerous other projects has shown that approximately 40 percent of all analyses contain significant shortcomings when they are performed for the first time. Approximately half of these are defects or omissions in the analysis alone and are not design defects. The remaining 20 percent actually represent design defects, the severity of which ranges from minor to mission catastrophic. Experience has shown that about 5 percent of all released manufacturing designs contain potential mission jeopardizing defects. The only proven method for detection of these defects is an independent review of the design details by an impartial, objective, competent peer in the appropriate technical field. To be effective this process should be a closed-loop system, which clearly identifies the design defect and enters it into a tracking system that requires resolution by either a design change or a program waiver. The process should also clearly differentiate between analysis omissions or defects and design deficiencies. Analysis deficiencies also should be tracked in a similar closed-loop system to assure timely updates, which may ferret out additional design deficiencies and will serve as an accurate historical record of the design. It is essential that the independent review process be based on purely technical grounds that avoid any connotation of being personal or punitive in nature. The reviewers should maintain an objective, constructive, and professional dialogue with the analysts to aid the resolution process. Experience on numerous projects has shown that this independent review process does work and the resultant quality of both the analyses and the designs is enhanced.","Lesson ID":786}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1259; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: The fluctuating pressures associated with acoustic energy during launch can cause vibration of structural components over a broad frequency band, ranging from about 20 Hz to 10,000 Hz and above. Such high frequency vibration can lead to rapid structural fatigue. The acoustic noise requirement assures that flight hardware-- particularly structures with a high ratio of surface area to mass-- is designed with sufficient margin to withstand the launch environment. Definition of an aggressive acoustic noise specification is intended to mitigate the effects of the launch environment on spacecraft reliability. It would not apply to the Space Station nor to the normal operational environment of a spacecraft. Implementation Method: The failure modes produced by acoustic noise excitation are similar to those associated with other types of vibratory structural fatigue. These include failures due to excessive displacement, in which one deflecting component makes contact with another, as well as fractured structural members and loose fasteners. Broken solder joints and cracked circuit boards and wave guides can also occur. Electronic components whose function depends on the motion of structural parts, such as relays and pressure switches, are particularly susceptible. Large flat panels are most susceptible to damage by acoustic energy as they can undergo large displacements while oscillating at low frequency. For a typical spacecraft, this means that a fixed, high gain antenna must be carefully designed and stiffened to avoid bending failures, debonding of composite members, and related problems. In general, any structure with a high ratio of surface area to mass can be expected to experience potential problems in the acoustic noise environment of spacecraft launch. For small payloads, however, random vibration testing is commonly preferred over acoustic noise testing. A typical acoustic noise requirement is illustrated in Figure 1. [D] Figure 1: Typical Acoustic Noise Requirement Such a figure specifies the level of input sound pressure over the spectrum of frequencies at which the pressure can fluctuate. The pressure is expressed in units of decibels (dB), defined as [D] where P is measured in Pascals (Pa) and P ref is ostensibly the audible limit of the human ear, with a value defined as 2 x 10 -5 Pa. The decibel pressure levels in acoustic noise spectra are not generally provided at each and every frequency. Instead, they are often specified over bands of width D f, which span 1\/3 of a frequency octave. With this method, 3 sound pressure levels will be provided over any interval in which the frequency doubles. Table 1 is an example of such a 1\/3 octave band specification for the curve data of Figure 1. [D] Table 1: 1\/3 Octave Band Specification When pressure levels are defined with these methods, it is convenient to provide a measure of the overall acoustic noise intensity. The overall sound pressure level (OASPL) provides just such a measure and, for 1\/3 octave band specifications, can be calculated as the decibel equivalent of the root sum square (RSS) pressure. Table 2 illustrates such a calculation for the data of Table 1, and shows that the OASPL is 144.9 dB. It should be noted that this figure is greater than any individual sound pressure level in the specification, because it represents an intensity of the spectrum as a whole. [D] Table 2: Calculation of Overall Sound Pressure Level To quantify the acoustic environment during launch, launch vehicles are often instrumented with internal microphones, which measure noise levels within the rocket fairing. This data is telemetered to the ground for processing and ultimately plotted in the form of a sound pressure level versus frequency spectrum. Since the acoustic forcing function is stochastic, depending on many atmospheric and other variables, data from a number of such flights are generally gathered, and an envelope, such as that of Figure 1, is developed to encompass the historical record of microphone data. This process can be extended and applied to data from a number of launch vehicles. If a launch platform has not yet been manifested for a particular payload, acoustic profiles from a number of candidate rockets can be enveloped, producing an aggressive specification which will ensure design adequacy for the spacecraft. Figure 2 reflects such a process, providing an envelope which encompasses the acoustic environments from three launch vehicles. [D] Figure 2: Envelope of Acoustic Flight Data Technical Rationale: The rationale for acoustic noise testing is straightforward, as acoustic energy is the primary source of vibration input to a space launch vehicle. During the initial phases of a rocket launch, high velocity gases are ejected from motor nozzles and reflected from the ground, creating turbulence in the surrounding air and inducing a vibratory response of the rocket structure. During the subsequent ascent phase of a launch, as the vehicle accelerates through the atmosphere to high velocity, aerodynamic turbulence induces pressure fluctuations which again cause structural vibration. These pressure fluctuations increase in severity as the vehicle approaches and passes through the speed of sound, due to the development and instability of local shock waves. The high-level acoustic noise environment continues during supersonic flight, generally until the maximum dynamic pressure or quotmax Qquot condition is reached. Acoustic energy is transmitted to the mission payload in two ways. First, fluctuating pressures within the payload fairing impinge directly on exposed spacecraft surfaces, inducing vibration in high gain antennae, solar panels and other components having a large ratio of area-to-mass. Secondarily, the fluctuating external pressure field causes an oscillatory response of the rocket structure, which is ultimately transmitted through the spacecraft attachment ring in the form of random vibration. From the spacecraft perspective, this random input is generally lowest at the launch vehicle attachment plane, and increases upward along the payload axis. At the integrated spacecraft level, then, acoustic noise is a primary source of vibration excitation. It is a i\u0300real worldi\u0302 environment, should be reflected in spacecraft design requirements, and should be included in virtually any space vehicle test program. These requirements relate specifically to the launch environment and do not apply to the normal operational environment of a spacecraft. References: MIL-STD-1540C, Test Requirements for Launch, Upper-Stage and Space Vehicles, United States Air Force Military Standard, 1994. Steinberg, D. S., Vibration Analysis for Electronic Equipment, New York: John Wiley & Sons, 1986. Himelblau, H., Fuller, C. and Scharton, T., quotAssessment of Space Vehicle Aeroacoustic Vibration Prediction, Design and Testing,quot NASA CR-1596, July, 1970. NASA STD XXXX-94, Standard for Payload Vibroacoustic Test Criteria, National Aeronautics and Space Administration, 1994 (Unreleased). Combination Methods for Deriving Structural Design Loads Considering Vibro-Acoustic, etc., Responses, Reliability Preferred Practice No. PD-ED-1211. Powered-On Vibration, Reliability Preferred Practice No. PT-TE-1405. Sinusoidal Vibration, Reliability Preferred Practice No. PT-TE-1406. Assembly Acoustic Tests, Reliability Preferred Practice No. PT-TE-1407. Environmental Test Sequencing, Reliability Preferred Practice No. PT-TE-1412. Random Vibration Testing, Reliability Preferred Practice No. PT-TE-1413. Vibroacoustic Qualification Testing of Payloads, Subsystems, and Components, Reliability Preferred Practice No. PT-TE-1419","Lesson ID":787}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1409, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Benefit: Assembly-level thermal vacuum testing is the most perceptive test for uncovering design deficiencies and workmanship flaws in spaceflight hardware. The margin beyond flight conditions is demonstrated, as is reliability. However, substituting an atmospheric pressure thermal test for the thermal\/vacuum test can effectively reduce electronic piece part temperatures by 20 deg. C or more, even for low power density designs. The net result of this is that the effective test temperatures may be reduced to the point where there is zero or negative margin over the flight thermal environment. Implementation Method: Establish a policy for spaceflight electronic hardware that requires all assembly-level thermal testing to be performed in a thermal\/vacuum environment. Moreover, deviation from this policy should require a waiver, supported by quantitative analysis that considers the effect on test demonstrated reliability. Technical Rationale: Vacuum effects: A thermal\/vacuum (T\/V) test simulates the flight condition. Two different physical phenomena occur when a thermal\/atmospheric pressure (T\/A) test is performed in lieu of a T\/V test. They are quotpure vacuumquot effects and temperature level\/gradient effects. The quotpure vacuumquot phenomena include corona and multipacting. Corona is of concern in the pressure region from about 0.1 to 0.001 torr. Multipacting can occur starting from the middle of the corona region all the way to near hard vacuum conditions. Pure vacuum problems most often are associated with radio frequency (RF) or high voltage circuits and devices. The addition of an ambient pressure gas alters key temperature levels and gradients. For a unit that is designed to be conductively coupled to the spacecraft structure (shear plate), the prime thermal path from the piece parts to the shear plate is via the boards and the housing. The introduction of a gas into the quotsimulatedquot flight environment results in two significant thermal alterations. First, the dominant thermal paths from key elements of the assembly (piece parts and solder joints, etc.) are altered because the gas creates a parallel path from these elements to the chamber ambient via the total housing skin. Secondly, artificial parallel paths between the key elements to the flight heat sinking surface are added. These additional parallel paths short out any of the high thermal resistance paths that may be present in the design. The net result of this is a reduction in the temperature of the key elements at both test temperature extremes. This test temperature reduction is referred to as the DT effect. A reduction in gradients between circuit elements also occurs, which can lead to circuit performance that is not typical of flight. For example, a timing circuit may show adequate performance due to the reduced gradients, whereas the performance in a flight-like vacuum condition could be unacceptable. JPL Study Results: Analyses and testing have been specifically performed at JPL since 1985 to quantify the effects of performing T\/A testing in lieu of T\/V testing. The results of these efforts are summarized in Table 1. Performing T\/A testing in lieu of T\/V testing reduces the temperature rise from the thermal control surface to key elements (boards, solder joints, parts, etc.) internal to the assembly. Note that this effect reduces the operating temperatures of the key elements over the whole temperature range (i.e., hot testing becomes less severe, while quotcoldquot testing becomes colder). Reductions in the temperature rises can be on the order of 15 deg C to 20 deg C or more. Commonly, T\/A testing reduces temperature rises by a factor of 2 to 4. Table 1: Summary of Analysis and Test Results for the DT Effect Associated with Performing T\/A Testing in Lieu of T\/V Testing [D] Notes: Unit not blanketed during initial T\/V test. Estimates for the effect of this indicated that the load on the heat exchanger was approximately twice that dissipated by the unit. Test performed for the DT effect part case-to-housing. Full DT effect shown is a combination of test and analysis. Such reductions lead to margin demonstrations dramatically lower than desired, and can easily cause negative test margin demonstrations. An electronic assembly is manufactured by a series of chemical and mechanical processes. Design and workmanship failures related to the chemical processes are best described by the Arrhenius reaction rate equation. Mechanical design and workmanship failures are most often a result of thermal fatigue and, to a lesser degree, vibration. Both the chemical and thermal fatigue failure mechanisms are a function of temperature. Tables 2 and 3 quantify the temperature influence on these failure mechanisms. Table 2: Arrhenius Reaction Rate Reduction Factors for Various DT Effects and Activation Energies [D] *Assuming a 75 deg C shear plate plus a 35 deg C rise shear plate-to-part junction. Lower test levels lead to greater reduction ratios. Table 3: Screening Strength Reduction Factor (quotXquot Factors) for Various DT Effects and Shear Plate Temperatures [D] *For compliant solder joints and cold test temperatures above the glass transition temperature for all materials involved. Also presented in Table 1 are various rationales generally in use in industry today for choosing a T\/A test in lieu of a T\/V test. The most common of these rationales are either based on the power density of the unit or type of hardware (i.e. power supply, digital, RF, etc.) undergoing testing. The JPL study results clearly show that these two rationales are not valid. The current rationale in use at JPL today is that if analysis shows that the DT effect is less than 5 deg C on all piece parts, solder joints, etc., and there are no known pure vacuum effects, then performing a T\/A test in lieu of a T\/V test might be allowed depending of the criticality of the unit under test. The safest and simplest course of action is to T\/V test everything. References: 1. Mark Gibbel, quotThermal\/Vacuum Versus Thermal Atmospheric Testing of Space Flight Electronic Assemblies,quot NASA Conference Publication 3096, from the 16th Space Simulation conference, Albuquerque, New Mexico, November 5-8, 1990. quotPart Electrical Stress Analysis,quot Reliability Preferred Practice PD-AP-1303. quotEnvironmental Factors,quot Reliability Preferred Practice PT-EC-1101. quotThermal Analysis of Electronic Assemblies to the Piece Part Level,quot Reliability Preferred Practice PD-AP-1306.","Lesson ID":781}
{"Driving Event":"Building Rehab projects are typically done on the second shift (4:00 p.m.-12:00 a.m.) and construction meetings are held every week to discuss the progress of the job. These meeting times and dates are left up to the participants to determine. The contract requires the meeting, but does not dictate a specific time. The Contractor's job superintendent doesn't start work until 4:00 p.m. and when construction meetings start at 3:00 p.m. some valuable input from the field is missing. The Contractor's Project Manager is always in attendance, however the field representation is also required. If the meetings were moved until 4:00 p.m., many of the Government's representatives would not be in attendance due to their work schedule.","Lesson ID":749}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1412 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Experience has shown that until the thermal-vacuum tests are performed, many failures induced during dynamics tests are not detected because of the short duration of the dynamics tests. In addition, the thermal-vacuum test on flight hardware at both the assembly level and the system level provides a good screen for intermittent as well as incipient hardware failures. Implementation Method: Perform flight hardware testing in the following sequence: Sinusoidal or transient vibration, random vibration, pyroshock, and acoustics, as required. The order among these dynamics tests may be interchanged. Thermal-vacuum testing. To assure that this sequence is followed, specify in the test specifications or test plans, as appropriate, that all dynamic tests will be performed prior to thermal-vacuum tests on both the assembly and system levels. During the normal flight sequence, the launch environment is followed by vacuum and potential temperature extremes. In this flight sequence, the flight hardware is therefore exposed to acoustics and vibration followed by vacuum and temperature variations. Consequently, by performing dynamics tests prior to thermal-vacuum tests, the actual flight sequence is simulated. Also, if the flight sequence produces synergistic effects, the synergism will be simulated. In addition, preserving the sequence of the service environments in the environmental test program is a widely accepted practice. As a result, the effect of reversing the test sequence on spacecraft failure rates has not been quantified. However, evidence exists that many acoustic induced failures have not been detected until the spacecraft is exposed to the thermal-vacuum environment. These failures may not be detected during acoustics tests because of the short one-minute duration or a non-operating power condition. Typically, the identified failures that could be related to or caused by the dynamic acoustic environment were bad solder joints, intermittents, bad bearings, broken wires, poor welds, leaks, foreign materials, etc. An example of a failure that might be induced by dynamic tests but not revealed until thermal vacuum would be a broken wire or solder joint. This defect might be induced by acoustics but not be detected during the acoustic test due to the short duration or to an unpowered or unmonitored state of the affected equipment. During post-acoustic functional testing, the wire or solder joint broken ends may be making adequate contact to show electrical continuity. In the subsequent thermal-vacuum test, the thermal distortions could cause loss of contact, allowing the failure to be detected. Reversing the test sequence could result in the defect not being induced until after thermal vacuum test and not detected until exposure to the flight thermal environment. Even if all defects precipitated by the dynamics tests are revealed during the test, or during post-test functional testing, performing the dynamic tests first will still have the advantage of increasing the probability that defects will be detected earlier, when they will have less impact on the system test program cost and schedule.","Lesson ID":779}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1414 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Proper implementation of this practice will assure that satellites will operate in the space charging environment without failure or awkward ground controller operations. Implementation Method: The following information has been partially derived from NASA Technical Paper 2361, quotDesign Guidelines for Assessing and Controlling Spacecraft Charging Effectsquot. That document is also recommended for further description of the test process. Subject the spacecraft to an environment representative of that expected. The environment applied to the spacecraft should include a safety margin (i.e., be greater than expected) that gives confidence that the flight spacecraft will survive the real environment. Have a design qualification test sequence that is extensive: test all units of hardware; use long test durations; examine many equipment operating modes; apply the environment to all surfaces of the test unit. Have a flight hardware test sequence of more modest scope: delete some units from test if qualification test shows great design margins; use shorter test durations; use only key equipment operating modes; and apply the environment to a limited number of surfaces. Simulation of Parameters The following items should be considered in test design: Spark location. Radiated fields, and\/or structure currents. Area, thickness, and dielectric strength of material. Total charge involved in the event. Breakdown voltage. Current waveform: rise time, width, fall time, and rate of rise (amps\/second). Voltage waveform: rise time, width, fall time, and rate of rise (amps\/second). Table 1 shows typical values as calculated on some spacecraft. They have been compiled from a variety of sources, mostly associated with the Voyager and Galileo spacecraft. New values must be calculated for a different satellite. Table 1. Examples of Estimated Space-Generated ESD Spark Parameters [D] Several representative types of test equipment are described in Table 2. Where possible, typical parameters for that type of test are listed. Table 2. Examples of Several ESD Generators [D] MIL-STD-1541 Sparker The MIL-STD-1541 sparker is commonly used. The schematic and usage instructions are shown in MIL-STD-1541A. Flat Plate Capacitor A flat plate capacitor may be used in several circumstances. Examples of spacecraft areas which may be simulated by a flat plate capacitor are: (a) thermal blanket areas; (b) dielectric areas such as calibration targets; or (c) dielectric areas such as non-conductive paints. The chief value of a flat plate capacitor is to permit a wide-spread discharge to simulate the physical path of current flow. Lumped Element Capacitors Lumped element capacitors can overcome some of the objections raised about flat plate capacitors. They can have large capacitance in similar areas and this supplements a flat plate capacitor if it alone is not adequate. Switches There are a wide variety of switches that can be used to initiate the arc discharge. At low voltages, semiconductor switches can be used. The MIL-STD-1541 sparker uses an SCR to initiate the spark activity on the primary of a step-up transformer. Also at low voltages, mechanical switches may be used (for example, to discharge modest voltage capacitors). The quotbouncequot problem with mechanical switches can be alleviated by the use of Mercury-wetted switches. For high voltage switching in air, a gap made of two pointed electrodes can be used as the discharge switch. For tests which involve a fixed discharge voltage, gas discharge tubes are available with fixed breakdown voltages. The advantages of the gas discharge tube compared to needle points in air is its faster rise time and its very repeatable discharge voltage. Another gas discharge tube is the triggered gas discharge tube. This tube can be triggered electronically, much as an SCR can be turned on by its gate. Methods of ESD Application The ESD energy can be as much as one joule, but usually is in the range of millijoules of energy. The methods of application can range from indirect (radiated) to direct (applying the spark directly to a piece part). In general, the method of application should simulate the expected ESD source as much as possible. The following paragraphs describe several typical methods: Radiated Field Tests The sparking device can be operated in air at some distance from the victim. This can be used to check for RF interference to communications or surveillance receivers as coupled into their antennas. It can also check susceptibility of scientific instruments which may be measuring plasma or natural radio waves. Single Point Discharge Tests Discharging the arc onto the spacecraft surface (or a temporary protective metallic fitting), with the arc current return wire in close proximity, can represent the discharge and local flowing of arc currents. This test is more severe than the radiated test, since it is immediately adjacent to the spacecraft rather than some distance away. Structure Current Tests The objective of structure current testing is to simulate quotblowoffquot of charges from a spacecraft surface. If a surface charges and a resultant ESD occurs, the spark may vaporize and mechanically remove both material and charges without local charge equalization. In such a case the remaining charge on the spacecraft will redistribute itself, causing structural currents. Typically, such a test would be accomplished by using one or more of the following current paths: diametrically opposed locations (through the spacecraft). protuberances (from landing foot to top; antenna to body; thruster jets to opposite side of body). extensions or booms (from end of sensor boom to spacecraft chassis; end of solar array to spacecraft chassis). from launch attachment point to other side of spacecraft. Unit Testing Unit ESD testing serves the same purpose it serves in standard environmental testing; i.e., it serves to identify design deficiencies at a stage when design changes are more easily accomplished. However, it is very difficult to provide a realistic determination of the unit's environment as caused by an ESD on the spacecraft. Spacecraft Testing The system level test will provide the most reliable determination of the expected performance of a space vehicle in the charging environment. Such a test should be conducted on a representative spacecraft prior to exposing the flight spacecraft to assure that there will be no inadvertent over stressing of the flight units. Ideally the spacecraft should be in a 100% flight-like configuration. A detailed test plan must be developed defining test procedures, instrumentation, test levels, and parameters to be investigated. Test techniques will probably involve current flow in the spacecraft structure. Tests may be conducted in ambient environment, but screen rooms with electromagnetic dampers are recommended. MIL-STD-1541 system test requirements and radiated EMI testing are considered to be a minimal sequence of tests. The test levels should be determined from the analysis of discharging behavior in the substorm environment. It is recommended that full level testing, with test margins, be applied to structural, engineering, or qualification models of spacecraft with only reduced levels applied to the flight unit. The test measurements (structural currents, harness transients, upsets, etc.) are the key systems responses which are to be used to validate predicted behavior. Regions of space that contain plasmas (ionized gases, usually consisting of electrons and hydrogen ions) can sometimes be of high energy, as much as 20,000 electron volts or more. The interaction of this plasma with typical spacecraft dielectric surfaces (usually thermal control surfaces, such as Teflon thermal blankets) causes negative charge to be deposited on these surfaces. It has been documented that such charges can generate electric fields in excess of the breakdown strength of the dielectrics. The resultant ESD spark has been known to disrupt digital and analog electronics, and can even be so strong that it damages spacecraft electronic hardware. References: MIL-STD-1541A, quotElectromagnetic Compatibility Requirements for Space Systemsquot NASA Technical Paper 2361, quotDesign Guidelines for Assessing and Controlling Spacecraft Charging Effectsquot","Lesson ID":777}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1410, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Benefit: These test data provide outgassing information on a wide variety of materials and should be used as a guide by engineers in selecting materials with low outgassing properties. Implementation Method: Contamination Control Plans (CCPs), Reference 2, that are prepared and approved for space flight projects, require that materials intended for space applications must be tested and must comply with the outgassing test criteria defined below. These plans generally describe methods for controlling contaminates and verifying that they have been prevented or abated such that the hardware will meet performance requirements. Contamination requirements for space flight hardware specify that materials intended for use in space flight applications shall be tested for their vacuum outgassing properties in accordance with ASTM E-595-77\/84. In general, a material is qualified on a product-by-product basis. However, lot testing may be required of any material for which lot variation is suspected. Only materials that meet the criteria of ASTM E-595-77\/84 [i.e., have a total mass loss (TML) < 1.0% and a collected volatile condensable mass (CVCM) < 0.10%] are approved for use in a space environment unless application considerations dictate otherwise. The outgassing test is conducted in a vacuum of 10-6 Torr at a temperature of 125 deg. Centigrade with a test exposure time of 24 hours. The equipment and test procedures required to conduct the outgassing test are defined by ASTM E-595-77\/84. Materials based on these selection criteria are normally used for space applications; however, some applications may require more or less stringent criteria depending upon such factors as the amount of material involved, expected temperature of exposure, location of the materials on the payload, the criticality of the contamination requirements, etc. A CVCM collector temperature colder than the standard may be required to reflect the intended use. The proposed use of a noncompliant material that does not meet the TML<1.0% and\/or the CVCM<0.1% requirements is documented for GSFC review and approval by a Materials Usage Agreement. Data on tested materials included in reference 1 are presented in three different ways in order to facilitate materials selection. In Section A, the materials are divided by category into 18 probable uses, such as adhesives, greases, paints, potting compounds, and so forth. In Section B, all the material contained in Section A is listed in alphabetical order by manufacturer's identification. In Section C, the only materials listed are those having TML and CVCM equal to or lower than a maximum 1.0% TML and a maximum 0.10% CVCM grouped by use. It should be noted that data has been collected over a period of 20+ years and variations in materials may require retesting in some cases. The selection of polymeric materials with low vacuum outgassing characteristics is an essential part in the selection of materials for use in space flight hardware. Materials must be selected which do not exceed specified levels of outgassing in the vacuum of space. Excessive outgassing can degrade the structural integrity of materials, thereby changing their characteristics and causing excessive contamination of critical surfaces. Outgassing molecules can deposit on cold optical and other critical surfaces, become baked-on when exposed to sunlight, and in some cases change color. These baked-on deposits can not be removed easily. These deposits can significantly degrade ultraviolet scientific instruments and measurements and infrared measurements by obscuring specific wavelengths of interest. Additionally, thermal control surface properties such as solar absorption, infrared emissions, etc., can also be significantly affected. References: NASA, Reference Publication 1124, Revision 2, Outgassing Data For Selecting Spacecraft Materials, November 1990 GSFC, SPAR-3, Standard Payload Assurance Requirements (SPAR) for GSFC Orbital Projects, Paragraph 6.2.5.2 and Section 9, March 1990","Lesson ID":778}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1417 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Inadvertent grounds of isolated circuits and ground loops are detected directly by this test. In some cases, such grounds may pass other tests with no apparent degradation. Failure may not occur until the vehicle is subjected to high level electromagnetic radiation. Since this test requires minimal test equipment and can be performed in a short time, its benefits are achieved at low cost. Implementation Method: Electrical isolation verification is a direct current resistance measurement of all circuits that are required to have electrical isolation from subsystem circuit common or subsystem chassis. The resistance must be at least 1 megohm between each isolated circuit and circuit common or chassis when measured with a suitable multimeter. A multimeter must be selected that will not overstress sensitive components. There are five types of isolation circuits which are tested in slightly different ways. Differences between the five types are shown in Figures 1 through 5 and in Table 1 below: [D] Figure 1: Single Unreferenced End-Circuit General Isolation Test Configuration [D] Figure 2: Multiple Unreferenced End-Circuits, Single Return General Isolation Test Configuration [D] Figure 3: DC Isolation Resistance for Subsystem or Assemblies Isolated from Chassis Ground [D] Figure 4: DC Isolation, Circuit Common to Chassis Ground [D] Figure 5: Isolated Circuit Common Configuration - C O N D I T I O N S - Figure Isolation Test Signal Chassis Common 1. Signal to Common isolated ground ground 2. Signal to Common multiple\/isolation ground ground 3. Signal to Common isolated ground isolated 4. Common to Ground -- ground isolated 5. Common to Chassis -- isolated isolated Table 1: Testing of Five Types of Isolation Circuits When more than one end circuit shares a common return, as in Figure 2, the minimum allowable resistance is divided by the number of end circuits. Each measurement is made with the subsystem or assembly unpowered and disconnected from support equipment. The measurements are made in both polarities of the multimeter because semiconductors have polarity dependent resistance. No attempt is made to record the actual resistance; the only requirement is that it exceed 1 megohm per circuit (0.5 megohm for two circuits, etc.). This is a relatively simple measurement which can be made with minimum impact on other activities during spacecraft assembly. A number of problems, such as inadvertent grounds have been detected by this test which may have passed the normal checkout test operations.","Lesson ID":774}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1413 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Implementation Method: Apply broadband, shaped, random vibration to the test item through its service attachments. The frequency band should span from approximately 20Hz to 2000Hz. Apply vibration in each of three mutually perpendicular axes (preferably the principal axes of the test item). Closed loop, servo control the vibration specification at one or more of the test item-to-fixture interface points. Narrow band test item response limiting or force limiting may be warranted to avoid unrealistically severe resonant responses of the test item. Duration of the random vibration application in each axis should be not less than the flight duration for which the vibroacoustic environment is within 6dB of its maximum or 30 seconds; whichever is greater. The flight acceptance (FA) test level should be equal to or greater than the maximum predicted flight environment, but not less than a level which has been found to provide an adequate workmanship screen for the type of hardware being tested. Qualification and protoflight test levels should have margin above the FA level. Random vibration testing has two principal objectives: To verify the test item design's capability, with some margin, to withstand the launch vibroacoustic environment, and To screen the workmanship integrity of the flight equipment. Random vibration criteria should be developed by the process described in the following four steps: Determine the Power Spectral Density (PSD) of the random vibration directly transmitted into the flight article through its mounts from the launch vehicle ources such as engine firing, turbopumps, etc (see Figure 1). These vibration conditions at the launch vehicle-to-payload interface are typically available from the launch vehicle builder. Perform an analysis to predict the payload\/flight article's vibration response to the launch vibroacoustic environment. Statistical energy analysis (SEA) methods such as the VAPEPS (VibroAcoustic Payload Environment Prediction System) program are effective predictors in the higher frequencies (see Figure 2). The VAPEPS program can also effectively extrapolate from a database using SEA techniques to provide predictions for a similar configuration. If random vibration predictions are needed for the lower frequencies, finite element analysis methods, such as NASTRAN, are commonly used. The vibration is induced into the test article both directly and indirectly (through its mounting). [D] Figure 1: Vibration levels transmitted to flight article through mounts [D] Figure 2: Payload\/flight article response to vibroacoustic environment Establish a minimum level of vibration which is necessary to ferret out workmanship defects--both existing and potential failures (see Figure 3). This is particularly applicable to electronic assemblies for which minimum effective workmanship levels have been established based on extensive test experience. Envelope the curves from 1-3 to produce a composite random vibration specification for the test article as follows: This resultant random vibration specification (Figure 4), which is employed as the flight acceptance test level, covers the two primary sources of this vibration while also providing an effective process for uncovering workmanship defects, particularly for electronics. Qualification and Protoflight test levels are increased typically 3 to 6dB above flight acceptance to verify that the design is not marginal. [D] Figure 3: Minimum vibration levels for workmanship defect detection [D] Figure 4: Composite Conventional rigid fixture vibration tests can severely overtest the hardware at resonances. It is accepted practice to response limit, or notch the input, at resonances of fragile hardware where it can be technically justified with flight or system test data, or analysis. Recently developed techniques to alleviate the overtest at resonances by specifying force limiting criteria potentially provides a much more accurate simulation of the flight vibration environment, but have not yet been implemented NASA-wide. The launch vehicle acoustically excites the spacecraft. This excitation is impractical to simulate for electronic assemblies at the assembly level because of fixture complexity, etc. Therefore, random vibration is substituted to excite the hardware. Random vibration is currently the most widely adopted type of dynamics environmental testing for spaceflight hardware. It is generally perceived by users to be the most realistic environment to reproduce in the vibration test laboratory as well as an effective tool for uncovering workmanship defects-- especially in electronics assemblies.","Lesson ID":775}
{"Driving Event":"On May 28, 1993, a NASA astronaut suffered frostbite on eight fingers during manned thermal-vacuum (MTV) testing in Chamber B, Building 32, at JSC. This test was the second portion of a two-part test designed to evaluate the extravehicular activity (EVA) hand tool functionality and flight crew operations for the Hubble Space Telescope First Servicing Mission. The actual test lasted 6 hours in the thermal-vacuum chamber with the suited astronaut repeatedly operating a large number of hand tools and hardware at temperatures as low as -140\u00b0F. At the conclusion of the test, upon removal of his extravehicular mobility unit (EMU) gloves, the astronaut noted to the test director that his hands appeared frostbitten. During this test, the astronaut had reported that his hands were cold and that he was experiencing pain. This report was not made in a way that indicated any concern or alarm, and it went undetected by the test team. Astronauts routinely note experiencing cold during MTV and some hand pain is also a normally experienced due to the effort required to function in the pressurized suit gloves. The astronaut never again indicated during the run that he was experiencing pain or cold in his hands. As the test continued, the astronaut operated virtually all of the flight tools, most of them repeatedly. Temperature of the tools and other items was consistently measured via thermocouples at between -113\u00b0F and -131\u00b0F. Furthermore, these tools required hand & finger intensive manipulation to operate, and were in some instances operated repeatedly for functional verification. The MTV test team as a whole shared an apparently universal perception that the EMU provides sufficient protection to an astronaut in extreme environmental conditions. Failure modes and effects analysis (FMEA) and hazards analysis were accomplished on the test; however, they concentrated on hardware malfunctions and did not thoroughly assess hazards associated with the unique human factors in this test run, nor adequately consider operational hazards. The EMU-specific hazard analysis also did not adequately address hazards associated with exposure to extreme cold. It was also noted during the investigation that certain of the tools did not operate properly, or had not undergone any type of thermal of vacuum testing prior to the MTV tests. Additionally, the thermal effects of these tools on the astronaut's hands were not a design consideration. Nothing had been done to reduce thermal conductivity of the hand tools, and most had bare metal surfaces. There was also a lack of specific test data on thermal effects within the EMU gloves. Tests had been done on maximum allowable temperatures for short\/light exposure, and on warmer temperatures for longer exposures; but it is difficult to extrapolate from these to actual temperatures, grasp pressures, length (of time) of grasp and cumulative effects. These factors are also affected by a number of variables in EMU sizing and individual astronaut options.","Lesson ID":744}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1243; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Fault protection design maximizes the probability of spacecraft mission success by avoiding possible single failure points through the use of autonomous, short-term compensation for failed hardware. Implementation Method: Except during critical event periods, the primary purpose of an autonomous fault protection system is to place the spacecraft in a safe, commandable state which can be maintained for a reasonable period (typically two weeks) following a fault. During critical periods, the primary purpose of the fault protection system is to ensure the completion of the critical event. A simplified block diagram representing the following three general types of fault protection is illustrated in Figure 1: Subsystems alone. Subsystem to system, and System to ground control. [D] Fault Protection Allocations. All on-board, post lift-off, autonomous fault protection is designated as either quotsubsystem internalquot or quotsystemquot fault protection. Fault protection engineering elements which have been allocated fault protection responsibility must provide the requirements and design for the associated detections, monitors, responses, and diagnostic data in compliance with project functional requirements. Where science instruments include fault protection in their design, designers must still ensure compliance with spacecraft project fault protection requirements if one of the following conditions apply: The fault protection internal to the instrument is dependent on non-standard services from another subsystem (or another instrument), or Internal failures have an impact external to the instrument (viz, a change in power state, momentum, support to other instruments). Spacecraft Safing. Spacecraft quotsafingquot is a general purpose safe-state response which is initiated by both system and subsystem internal fault protection. The purpose of this response is to provide the following: A safe state for the hardware An uplink, and A downlink (with some exceptions for specific failure conditions). To achieve these goals, the normal stored sequence is terminated and non-essential spacecraft loads are powered off. Undervoltage Response. Most spacecraft designs include an undervoltage response, which is designed to protect the spacecraft in the event of a short or a bus overload. The hardware senses when the power drops below an established value for a specified time. If the criteria are met, the power system sheds all non-essential loads from the bus and indicates the undervoltage condition to the Command Subsystem, which will initiate the undervoltage recovery response. Critical spacecraft memories are maintained throughout the undervoltage. Functional Implementation Requirements. Fault protection is typically allocated to the on-board elements of the system in accordance with the following principles: Spacecraft versus ground control. Autonomous fault protection is included on board the spacecraft only if a response by Mission Operations is not feasible nor practical, or if action is required within two weeks of detecting the failure. Otherwise, ground control is responsible for fault recovery. In both cases, ground control is responsible for failure diagnosis and, if necessary, the configuration of the spacecraft to nominal operations after the fault. Protection against sabotage and operator errors. To simplify the development of fault protection, autonomous fault protection is not required to protect against sabotage or operator errors, although such protection is not prohibited. There is limited spacecraft protection against these failures (viz, information system data integrity checks and some software checks). Protection against spacecraft hardware and software design errors. To simplify the development of fault protection, autonomous fault protection is usually not required to protect against spacecraft design errors, although it is not prohibited if practical. The practice of fault protection typically provides some limited spacecraft protection against design errors (e.g., thermal fault responses). The autonomous fault protection function is responsible for all on-board fault detections and corrections except those routinely required to ensure spacecraft data integrity (viz, EDAC, Reed Solomon encoder, checksums, etc.). Data error detections and corrections may be used, however, for fault protection purposes. The spacecraft information system typically has the primary responsibility for ensuring data integrity. Fault Protection Design Requirements. Management and coordination of fault detection, monitoring, and response, for both system and subsystem internal fault protection, is performed in accordance with the following general rules: Enables\/disables for responses. Where applicable, fault responses should have two enable\/disable mechanisms (or the functional equivalent): an enable\/disable by stored sequence, and an enable\/disable by ground control or by fault protection algorithms. Enables\/disables for monitor activation of any response. If a response can be initiated by more than one monitor, those monitors should include an enable\/disable mechanism or the functional equivalent. Enable\/disable state specification. Each enable\/disable is specified by a single parameter unique to each fault protection algorithm. Enable\/disable strategy - general. As a goal, fault protection monitors and responses should be designed to be enabled for the entire mission. This reduces the risk of incorrect fault protection states. Enable\/disable strategy - critical events. For critical events, enable\/disable strategies may be used to minimize or prevent the effects of an erroneous fault indication. Response initiation. Fault responses are initiated if and only if spacecraft performance is unacceptable, or there is a significant risk to the mission or to subsystem safety. Parameter modifications. All fault protection parameters which may reasonably be expected to change as a function of mission mode, type of activity, fault history, or operational experience should be alterable by ground control without requiring flight software modification. Software modifications. To the extent possible, monitor and response algorithms should be stored in programmable RAM. Configuration compatibility. On-board fault protection should be designed to respond to a fault while in any possible spacecraft configuration (e.g., fault protection should be able to accommodate all possible combinations). Independence from instruments. Engineering fault protection should not depend on science instruments or their data. Multiple faults. At a minimum, fault protection should be designed with the assumption that only one fault occurs at a time, and that a subsequent fault will occur no earlier than the response completion time for the first fault. As a goal, fault protection should be capable of recovering from multiple successive or coincident faults provided that the faults and associated fault algorithms are independent. Propagation of failures. Autonomous fault protection assumes that spacecraft hardware design ensures that a single failure in a subsystem (including instruments) cannot propagate to its redundant unit or to another subsystem, or prevent switching to its redundant unit. This can be verified by performing a failure modes, effects, and criticality analysis (FMECA) or fault tree analysis (FTA). Typical Fault Detection Design Requirements. Hardware and software detection sources have two criteria: Direct detection. Detection mechanisms should be as direct as possible (i.e., a direct measurement is preferred over a calculated or derived measurement). Detection coverage. Detection mechanisms should only be required to detect a failure to the level at which that failure can be isolated or corrected. Design Requirements for Fault Monitors. Software monitors used by system and subsystem internal fault protection have the following features: Monitor thresholds. Where possible, thresholds should use reasonableness checks, detection filtering (to exclude certain faults from a previously established fault database), or redundant detections. Threshold modifications. Monitor threshold values should be alterable by ground or sequence command, or by fault protection responses as appropriate. As a goal, monitors are best designed to detect and disregard failed sensors. Redundant detection. For detections where an inadvertent trip would result in a severe response (viz, downlink loss, irreversible hardware swaps, large use of expendables, critical sequence cancellation), and where a sensor anomaly could cause an inadvertent trip, independent physically or functionally redundant detections are employed such that simultaneous detections are necessary for response initiation. Fault response tolerance. Monitors are designed to be tolerant of off-nominal conditions following a reconfiguration resulting from a fault protection response (e.g., thresholds might be relaxed as part of a response). Design Requirements for Fault Responses. System and subsystem internal fault response concerns include: Fault response primary responsibility. Following an anomaly, fault responses should ensure spacecraft commandability and the maintenance of a safe state for at least two weeks. This requirement is superseded only by a requirement to complete a critical event. Fault protection priorities. Fault responses are designed with the following priorities: Protect critical spacecraft functionality, Protect spacecraft performance and consumables, Minimize disruptions to normal sequence operations, and Simplify ground recovery response, including providing for downlink telemetry. Multiple levels of response. Where possible, response design includes multiple levels of response, with the response actions executed in order of increasing severity. Real-time ground responses. Autonomous fault protection is designed so as to not require real-time ground responses for recovery from known faults. False alarm tolerance. Unintended entry into a fault protection response in the absence of a fault must not present a hazard to the spacecraft or mission. For critical event periods, however, this requirement is relaxed and is considered a goal. Use of redundant (and spare) units. Redundant or spare units may be used by autonomous fault protection responses if a satisfactory alternative design is not available. Unpowered redundant units. The transition of a unit from quotoffquot to quotprimequot must not require ground commands in order to support spacecraft fault protection and mission critical functions. Component warm-up times. Fault responses should take into account component warm-up times and similar delay requirements. Data Handling Requirements. The following data handling tasks are performed: Recording engineering data. The combination of sequences and fault responses should ensure the recording of engineering data prior to, during, and after the execution of any fault response. Some exceptions are made for recorder and command subsystems failures. Storage and preservation of diagnostic data. Fault protection is designed to include the storage of diagnostic data (see Telemetry and Diagnostic Data on page 7), and ensure that data are not overwritten as the result of a response action. This requirement only applies if the writing of diagnostic data is not affected by the original fault. Protection of critical science and engineering data. Fault responses must not destroy quotcritical dataquot stored on-board the spacecraft. quotCritical science and engineering dataquot must be defined by project policy. Requirements Interactions with Stored Sequences. The following interactions with on-board sequences may be necessary: Response design for critical events. Fault response is designed to ensure the completion of the critical event as and when required, with spacecraft safety having lower priority, until the critical events are completed. Orbit insertion is an example of a critical event. Response design for non-critical events. Unless required to execute a critical event, fault responses should stop any on-board sequence(s) only if the sequence(s) compromises the integrity of the fault response, or if the fault response compromises the integrity of the sequence. Reactivation of stored sequences. After completion of a response which terminates a non-critical stored sequence, fault responses should not autonomously resume the terminated sequence. Safing Requirements. quotSafingquot is defined as a general purpose fault response which results in the cancellation of non-critical sequences, the possible suspension of critical sequences, and a general reconfiguration of spacecraft components. Safing responses typically include the following general features: Uplink communications. The safing response provides for a spacecraft state and attitude that ensures uplink commandability in the long term. Downlink communications. The safing response provides for a spacecraft state and attitude that ensures continuous engineering telemetry with positive link margin. Environmental constraints. The safing response meets boresight and radiator environmental constraints. Safing priorities. When uplink, downlink, and hardware safing requirements are in conflict, the following priorities apply: Provide a safe state for the hardware, Provide an uplink, and Provide a downlink. Ultimately, uplink must be provided for in the long term. Benign spacecraft configuration. As a goal, safing responses should place the spacecraft in an operationally benign state. This includes but is not limited to the following: (1) powering off of all non-essential equipment including instruments, and (2) stopping of all non-essential spacecraft processes. Telemetry and Diagnostic Data Requirements. The spacecraft design should ensure that following an anomaly, spacecraft telemetry will be sufficient to perform the preliminary failure identification and analysis required for ground control to perform near-term corrective actions. At a minimum, the real-time telemetry stream includes the following: Measurements to unambiguously identify the current engineering subsystem configuration and operating status, Enable\/disable states of fault protection software, and enable\/disable states of fault protection dedicated hardware, Active\/inactive states for fault protection software responses, Identification that a fault response has been activated, Monitor detection logic output (regardless of whether the monitor is enabled or disabled), and As appropriate, cumulative counters of faults detected. Telemetry design should ensure reasonable and timely sampling frequencies for these items. As a goal, the real-time telemetry stream should include monitor high water marks. A quothigh water markquot is defined as a measurement which identifies how close a monitor is to indicating a failure. Following an anomaly involving a fault protection activity, the spacecraft design should ensure that sufficient information is available to reconstruct the audit trail-- the sequence of fault protection events following the anomaly. Diagnostic data is also needed to analyze the anomaly and to identify the sequential effects of the anomaly on spacecraft performance. The data should be available in non-volatile telemetry or stored on-board for later retrieval by the ground system. At a minimum, diagnostic data should include unique identification and time-tagging of monitors and responses which have been active. It is also desirable that diagnostic data include the value of the measurement which initiated a response. Technical Rationale: JPL has incurred numerous instances of presumably redundant systems which failed to successfully transfer to the back-up path when the primary path did not function. A rigorous, systematic search, crosstrap FMECA, or sneak paths analysis could have foretold the failure, and redesign could have averted the problem. Prevention of propagating failures has its greatest value when supplemented by an on-board fault protection system. The practice of failure propagation prevention is of most value in a repairable system. Non-propagation minimizes the number of units requiring repair. In a non-fault protected spacecraft, this capability is limited to the preflight phases of either subsystem or system testing. In a fault protected spacecraft, it can be extended to the flight phase as well. The key to this investigation is a complete diagram of the involved interface circuits which penetrates each unit to a circuit depth sufficient to prove that no possible failures in one unit can propagate to become irreversible hardware failures in a second unit. Another input is a complete list of part or assembly failure modes for hypothesis. Successful transfer (or equivalently independence of the primary and back-up functions) is a necessity for either repairable or non-repairable systems and requires the same complete interface diagram and complete list of failure modes. Such a list must include items such as: Part failure modes (opens, shorts, stiction, etc.), Single event effects (latch-up, transfer, etc.), and EMI (latch-up, transfer, overvoltage). These last two items are critical since they can affect both sides of a redundant pair. References JPL D625-505; Vol. 8, Fault Protection System Design and Operations. 699-CAS-3-330; Fault Protection Requirements, Cassini Project. 699-CAS-3-331; System Fault Protection Algorithms, Cassini Project.","Lesson ID":772}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1416 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Spurious interferences and responses can be identified during system checkout. After the spurious responses are evaluated, solutions can be proposed, and remedial action taken, if necessary, prior to the actual flight. Implementation Method: A system verification susceptibility test is planned as part of the system checkout. The susceptibility of all systems to the specified electromagnetic radiation environment is observed while each subsystem is stepped through a typical sequence of operations. The electromagnetic radiation environment is simulated by operating a number of separate signal generators\/amplifiers connected to a cluster of antennas. As the system test progresses, the antenna cluster is directed sequentially at each subsystem from a distance of one meter or other prescribed distance which will provide adequate coverage. Figure 1 shows the physical arrangement for system test of the Galileo spacecraft; seven antennas are directed toward the Energetic Particle Detector (EPD). The antenna assembly was moved to appropriate locations to illuminate each sensitive area as the test progressed. [D] Figure 1: Galileo System Test with Seven Antennas Directed Toward the EPD When a spurious response is observed, each transmitter is turned off and on sequentially until the cause of the response is isolated to one or a combination of radiators. The probability of the particular signal or combination of emitted signals occurring simultaneously with the particular spacecraft mode must be evaluated before any remedial action is initiated. In a complex system which emits and is exposed to a number of radiated signals, there is a large number of spurious frequencies which may produce unexpected results during ground checkout, launch, and flight. Sources of electromagnetic radiation are listed in Table 1. Table 1: Sources of Radiated Emissions EXTERNAL Test Range Tracking Radars Space Shuttle Transmitters Booster Transmitters AM, FM, & TV Broadcast Transmitters INTERNAL On-board Transmitters Receiver Local Oscillators Data Bus Clock Frequencies These signals or their harmonics may combine to produce intermodulation products at a sensitive frequency which could cause an unwanted response. Susceptible frequencies that may respond to the emissions are receiver main tuning frequencies, image frequencies, and the 1st and 2nd receiver intermediate frequencies. By simulating the radiation environment that the vehicle will be exposed to during system checkout and free flight, potential sources of interference can be identified, evaluated, and corrected, if necessary. Synergistic combinations of sources may be detected with this approach. The probability of a successful flight will be increased by performing this verification test. References: quotINTERMODquot, A computer program to calculate intermodulation products of multiple transmitters that fall within the bandwidths of multiple receivers, Paul Rusales, Lockheed California Co., January 1987.","Lesson ID":776}
{"Driving Event":"On May 16, 1994, an AMDAHL 5995M mainframe computer overheated at approximately 8:20 AM in the Software Production Facility (SPF) in Building 30 at JSC. Physical damage to the computer due to this overheat was estimated at $669,000. This overheat occurred due to an inadvertent miswiring of a circuit breaker after a routine power outage and maintenance of the breaker. The quality inspection failed to check for the proper rewiring of the circuit breaker. The miswiring caused a phase rotation of the power, which in turn caused fans cooling the AMDAHL 2550 to turn backwards. Power isolation and monitoring equipment that could have prevented any impact from the phase rotation was not properly utilized. This led to insufficient cooling of the AMDAHL 2550 which resulted in the overheat and subsequent damage.","Lesson ID":873}
{"Driving Event":"On December 8, 1995, a full-scale model of the NASA JSC Experimental Crew Return Vehicle (XCRV) experienced a failure of its parafoil deployment system during a test drop at the U.S. Army's Yuma Proving Ground (YPG) near Yuma, Arizona. The wingless 24-foot model impacted the ground without the parafoil deployed due to damage sustained when two lines entangled during deployment from a Colorado Air National Guard C-130 Aircraft at 15,000 feet mean sea level. The design of the test-unique model, platform restraint and separation system was neither reviewed by all parties affected by its integration nor well documented. As a result, opportunities to identify design problems were missed, and there was little opportunity to ensure conformance with the intended design in the vehicle configuration process.","Lesson ID":743}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1244; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Minimize the adverse effects of electrostatic discharge (ESD) on spacecraft by implementing the following three design practices: Make all external surfaces of the spacecraft electrically conductive and grounded to the main structure. Provide all internal metallic elements and other conductive elements with an \"ESD conductive\" path to the main structure. Enclose all sensitive circuitry in an electrically conductive enclosure-- a \"Faraday cage\". The first two practices should dissipate most electric charges before a difference in potential can become high enough to cause an ESD. If a discharge occurs, the third practice lowers the coupling to sensitive circuits, reducing the probability or severity of the interference. All external dielectric surfaces such as windows, radomes and solar panels are coated to make them slightly conductive without destroying their transparency to optical\/IR\/RF radiation. Cost and performance trade-offs must be made in order to select suitable materials for each application. The conductive layer should be less than 109 ohms per square and connected to structural ground. All internal metallic elements, greater than 3 cm2 in area or 25 cm in length, including unused wires in cables, connectors, circuit board traces, spot shields, and other conductive elements, have a conductive path to ground with a resistance less than 100 MW. Small metallic objects (< 3 cm2) may be ungrounded if grounding is not practical. Each metallic layer of thermal blankets is grounded to the main structure. All external metallic components are electrically connected to the common ground of the main structure. All electronics are enclosed in a Faraday cage shielded enclosure. External cabling outside of the Faraday cage are shielded by means of overshields with 360 degree backshells at the Faraday cage entry. Sensitive circuits should use independent, balanced wiring with each lead and its return twisted together. Filter all circuits coming into the Faraday cage; low-pass filters and transient suppressors are typical, but digital logic discriminators have also been used. Avoid the possibility of high differential voltages between components by connecting all conductive materials to a common ground. In the case of large structures, such as Space Station, surface charging can be controlled by use of an external ionizing plasma source. Since it is impractical to duplicate the space plasma environment, testing for ESD resorts to resistance measurement on one hand and circuit immunity to artificial discharges on the other hand. The requirements for each of these conditions depend on the spacecraft charging conditions anticipated for the particular orbit that the spacecraft will occupy. All spacecraft designers must consider space charging in the spacecraft design. Space charging arises when materials are immersed in an energetic space plasma. Different materials with different surface resistivities produce voltage gradients which can build up until the voltage breakdown limit is exceeded. When this occurs, a discharge is produced which causes transients in electrical circuitry and degradation or redeposition of material. References Purvis, C., Garrett, H., Whittlesey, A., Stevens, N. (1984), \"Design Guidelines for Assessing and Controlling Spacecraft Charging Effects,\" NASA Technical Paper 2361. (This paper has an extensive bibliography.) Surface Charging\/ESD Analysis, Reliability Preferred Practice No. PD-AP-1301 Thick Dielectric Charging\/Internal Electrostatic Discharge (Draft), Reliability Preferred Guideline No. PD-AP-1316","Lesson ID":773}
{"Driving Event":"On January 4, 1995, at approximately 8:50 a.m., two technicians at WSTF were overcome and collapsed from breathing in an oxygen deficient atmosphere that formed during shutdown operations following a transfer of liquid nitrogen (LN2) from a vendor supply tanker to a WSTF storage tanker. This transfer operation was normally controlled by monitoring a tanker vent line. Flow from this vent line indicated the tank was full, and the operation was suspended. There is also a liquid level indicator and a pressure gage on the WSTF tanker for monitoring purposes. On the morning of the mishap, conditions (high humidity and still air) existed which caused a larger than normal water vapor cloud to form during continuous venting of cold gaseous nitrogen (GN2) during the filling operation. This venting is required to keep the WSTF tanker at a lower pressure than the vendor tanker during the fill operation. The cloud prevented the normal visual monitoring of the vent line, the liquid level indicator, and the pressure gauge. The technicians, instead of positioning themselves to be able to monitor the vent line and gauges, located approximately 30 feet away from the tanker to both remove themselves from the heavy vapor cloud and also to remain out of the rain. During the operation, the technicians would periodically approach the tankers to monitor the liquid level indicator and the pressure gauge. The vent line was never observed due to being obscured by the vapor cloud. After about 50 minutes, the weather got worse and the technicians decided to suspend the operation due to weather and because they thought the tanker was nearly full. Data collected later showed that the tanker was completely full, and that LN2 was being released through the vent line instead of GN2. As the first technician attempted to close the vent and transfer valves, he was overcome and collapsed due to the lack of oxygen. The second technician, who was monitoring the activity, also was overcome and collapsed due to the lack of oxygen. A few moments later, vendor personnel approached and eventually remove both technicians from the area. Later investigation indicated that LN2 flow from the vent line coupled with adverse weather conditions created an oxygen deficient atmosphere in the area.","Lesson ID":871}
{"Driving Event":"On January 4, 1995, at approximately 8:50 a.m., two technicians at WSTF were overcome and collapsed from breathing in an oxygen deficient atmosphere that formed during shutdown operations following a transfer of liquid nitrogen (LN2) from a vendor supply tanker to a WSTF storage tanker. This transfer operation was normally controlled by monitoring a tanker vent line. Flow from this vent line indicated the tank was full, and the operation was suspended. There is also a liquid level indicator and a pressure gage on the WSTF tanker for monitoring purposes. On the morning of the mishap, conditions (high humidity and still air) existed which caused a larger than normal water vapor cloud to form during continuous venting of cold gaseous nitrogen (GN2) during the filling operation. This venting is required to keep the WSTF tanker at a lower pressure than the vendor tanker during the fill operation. The cloud prevented the normal visual monitoring of the vent line, the liquid level indicator, and the pressure gauge. The technicians, instead of positioning themselves to be able to monitor the vent line and gauges, located approximately 30 feet away from the tanker to both remove themselves from the heavy vapor cloud and also to remain out of the rain. During the operation, the technicians would periodically approach the tankers to monitor the liquid level indicator and the pressure gauge. The vent line was never observed due to being obscured by the vapor cloud. After about 50 minutes, the weather got worse and the technicians decided to suspend the operation due to weather and because they thought the tanker was nearly full. Data collected later showed that the tanker was completely full, and that LN2 was being released through the vent line instead of GN2. As the first technician attempted to close the vent and transfer valves, he was overcome and collapsed due to the lack of oxygen. The second technician, who was monitoring the activity, also was overcome and collapsed due to the lack of oxygen. A few moments later, vendor personnel approached and eventually remove both technicians from the area. Later investigation indicated that LN2 flow from the vent line coupled with adverse weather conditions created an oxygen deficient atmosphere in the area.","Lesson ID":872}
{"Driving Event":"On May 16, 1994, an AMDAHL 5995M mainframe computer overheated at approximately 8:20 AM in the Software Production Facility (SPF) in Building 30 at JSC. Physical damage to the computer due to this overheat was estimated at $669,000. This overheat occurred due to an inadvertent miswiring of a circuit breaker after a routine power outage and maintenance of the breaker. The quality inspection failed to check for the proper rewiring of the circuit breaker. The miswiring caused a phase rotation of the power, which in turn caused fans cooling the AMDAHL 2550 to turn backwards. Power isolation and monitoring equipment that could have prevented any impact from the phase rotation was not properly utilized. This led to insufficient cooling of the AMDAHL 2550 which resulted in the overheat and subsequent damage.","Lesson ID":742}
{"Driving Event":"On May 16, 1994, an AMDAHL 5995M mainframe computer overheated at approximately 8:20 AM in the Software Production Facility (SPF) in Building 30 at JSC. Physical damage to the computer due to this overheat was estimated at $669,000. This overheat occurred due to an inadvertent miswiring of a circuit breaker after a routine power outage and maintenance of the breaker. The quality inspection failed to check for the proper rewiring of the circuit breaker. The miswiring caused a phase rotation of the power, which in turn caused fans cooling the AMDAHL 2550 to turn backwards. Power isolation and monitoring equipment that could have prevented any impact from the phase rotation was not properly utilized. This led to insufficient cooling of the AMDAHL 2550 which resulted in the overheat and subsequent damage.","Lesson ID":875}
{"Driving Event":"On May 28, 1993, a NASA astronaut suffered frostbite on eight fingers during manned thermal-vacuum (MTV) testing in Chamber B, Building 32, at JSC. This test was the second portion of a two-part test designed to evaluate the extravehicular activity (EVA) hand tool functionality and flight crew operations for the Hubble Space Telescope First Servicing Mission. The actual test lasted 6 hours in the thermal-vacuum chamber with the suited astronaut repeatedly operating a large number of hand tools and hardware at temperatures as low as 140\u00b0F. At the conclusion of the test, upon removal of his extravehicular mobility unit (EMU) gloves, the astronaut noted to the test director that his hands appeared frostbitten. During this test, the astronaut had reported that his hands were cold and that he was experiencing pain. This report was not made in a way that indicated any concern or alarm, and it went undetected by the test team. Astronauts routinely note experiencing cold during MTV and some hand pain is also a normally experienced due to the effort required to function in the pressurized suit gloves. The astronaut never again indicated during the run that he was experiencing pain or cold in his hands. As the test continued, the astronaut operated virtually all of the flight tools, most of them repeatedly. Temperature of the tools and other items was consistently measured via thermocouples at between -113\u00b0F and -131\u00b0F. Furthermore, these tools required hand & finger intensive manipulation to operate, and were in some instances operated repeatedly for functional verification. The MTV test team as a whole shared an apparently universal perception that the EMU provides sufficient protection to an astronaut in extreme environmental conditions. Failure modes and effects analysis (FMEA) and hazards analysis were accomplished on the test; however, they concentrated on hardware malfunctions and did not thoroughly assess hazards associated with the unique human factors in this test run, nor adequately consider operational hazards. The EMU-specific hazard analysis also did not adequately address hazards associated with exposure to extreme cold. It was also noted during the investigation that certain of the tools did not operate properly, or had not undergone any type of thermal of vacuum testing prior to the MTV tests. Additionally, the thermal effects of these tools on the astronaut's hands were not a design consideration. Nothing had been done to reduce thermal conductivity of the hand tools, and most had bare metal surfaces. There was also a lack of specific test data on thermal effects within the EMU gloves. Tests had been done on maximum allowable temperatures for short\/light exposure, and on warmer temperatures for longer exposures; but it is difficult to extrapolate from these to actual temperatures, grasp pressures, length (of time) of grasp and cumulative effects. These factors are also affected by a number of variables in EMU sizing and individual astronaut options.","Lesson ID":876}
{"Driving Event":"On May 16, 1994, an AMDAHL 5995M mainframe computer overheated at approximately 8:20 AM in the Software Production Facility (SPF) in Building 30 at JSC. Physical damage to the computer due to this overheat was estimated at $669,000. This overheat occurred due to an inadvertent miswiring of a circuit breaker after a routine power outage and maintenance of the breaker. The quality inspection failed to check for the proper rewiring of the circuit breaker. The miswiring caused a phase rotation of the power, which in turn caused fans cooling the AMDAHL 2550 to turn backwards. Power isolation and monitoring equipment that could have prevented any impact from the phase rotation was not properly utilized. This led to insufficient cooling of the AMDAHL 2550 which resulted in the overheat and subsequent damage.","Lesson ID":874}
{"Driving Event":"On May 28, 1993, a NASA astronaut suffered frostbite on eight fingers during manned thermal-vacuum (MTV) testing in Chamber B, Building 32, at JSC. This test was the second portion of a two-part test designed to evaluate the extravehicular activity (EVA) hand tool functionality and flight crew operations for the Hubble Space Telescope First Servicing Mission. The actual test lasted 6 hours in the thermal-vacuum chamber with the suited astronaut repeatedly operating a large number of hand tools and hardware at temperatures as low as 140\u00b0F. At the conclusion of the test, upon removal of his extravehicular mobility unit (EMU) gloves, the astronaut noted to the test director that his hands appeared frostbitten. During this test, the astronaut had reported that his hands were cold and that he was experiencing pain. This report was not made in a way that indicated any concern or alarm, and it went undetected by the test team. Astronauts routinely note experiencing cold during MTV and some hand pain is also a normally experienced due to the effort required to function in the pressurized suit gloves. The astronaut never again indicated during the run that he was experiencing pain or cold in his hands. As the test continued, the astronaut operated virtually all of the flight tools, most of them repeatedly. Temperature of the tools and other items was consistently measured via thermocouples at between -113\u00b0F and -131\u00b0F. Furthermore, these tools required hand & finger intensive manipulation to operate, and were in some instances operated repeatedly for functional verification. The MTV test team as a whole shared an apparently universal perception that the EMU provides sufficient protection to an astronaut in extreme environmental conditions. Failure modes and effects analysis (FMEA) and hazards analysis were accomplished on the test; however, they concentrated on hardware malfunctions and did not thoroughly assess hazards associated with the unique human factors in this test run, nor adequately consider operational hazards. The EMU-specific hazard analysis also did not adequately address hazards associated with exposure to extreme cold. It was also noted during the investigation that certain of the tools did not operate properly, or had not undergone any type of thermal of vacuum testing prior to the MTV tests. Additionally, the thermal effects of these tools on the astronaut's hands were not a design consideration. Nothing had been done to reduce thermal conductivity of the hand tools, and most had bare metal surfaces. There was also a lack of specific test data on thermal effects within the EMU gloves. Tests had been done on maximum allowable temperatures for short\/light exposure, and on warmer temperatures for longer exposures; but it is difficult to extrapolate from these to actual temperatures, grasp pressures, length (of time) of grasp and cumulative effects. These factors are also affected by a number of variables in EMU sizing and individual astronaut options.","Lesson ID":877}
{"Driving Event":"On January 4, 1995, at approximately 8:50 a.m., two technicians at WSTF were overcome and collapsed from breathing in an oxygen deficient atmosphere that formed during shutdown operations following a transfer of liquid nitrogen (LN2) from a vendor supply tanker to a WSTF storage tanker. This transfer operation was normally controlled by monitoring a tanker vent line. Flow from this vent line indicated the tank was full, and the operation was suspended. There is also a liquid level indicator and a pressure gage on the WSTF tanker for monitoring purposes. On the morning of the mishap, conditions (high humidity and still air) existed which caused a larger than normal water vapor cloud to form during continuous venting of cold gaseous nitrogen (GN2) during the filling operation. This venting is required to keep the WSTF tanker at a lower pressure than the vendor tanker during the fill operation. The cloud prevented the normal visual monitoring of the vent line, the liquid level indicator, and the pressure gauge. The technicians, instead of positioning themselves to be able to monitor the vent line and gauges, located approximately 30 feet away from the tanker to both remove themselves from the heavy vapor cloud and also to remain out of the rain. During the operation, the technicians would periodically approach the tankers to monitor the liquid level indicator and the pressure gauge. The vent line was never observed due to being obscured by the vapor cloud. After about 50 minutes, the weather got worse and the technicians decided to suspend the operation due to weather and because they thought the tanker was nearly full. Data collected later showed that the tanker was completely full, and that LN2 was being released through the vent line instead of GN2. As the first technician attempted to close the vent and transfer valves, he was overcome and collapsed due to the lack of oxygen. The second technician, who was monitoring the activity, also was overcome and collapsed due to the lack of oxygen. A few moments later, vendor personnel approached and eventually remove both technicians from the area. Later investigation indicated that LN2 flow from the vent line coupled with adverse weather conditions created an oxygen deficient atmosphere in the area.","Lesson ID":745}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1431 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. On spacecraft hardware where risk vs. cost trades permit higher risk (Class C), Voltage and Temperature Margin Testing (VTMT) is an economical alternative to classical worst case analysis (WCA). The major benefits in using VTMT instead of WCA are: Assurance of a systematic method for investigation of potential risks where the parameters are not adequately modeled by worst case analysis. An example is RF circuits which have distributed circuit parameters. Labor savings for units too complex to simulate and which generally require Monte Carlo or root-sum squares analyses. Real-time operation and review of complex circuits, allowing the weighing of alternative design actions. Cost savings from expedited risk assessment. Comparative studies have demonstrated that testing may be completed in less than one-third the time required for analyses. Implementation Method: The VTMT must be designed to achieve adequate variation of circuit parameters through a judicious choice of voltage, temperature, and frequency margin combinations to achieve an optimal, yet realistic check of the design margin. Sufficient margin must be demonstrated at beginning-of-life (BOL) to permit confident performance extrapolation for those conditions that are not achievable at component infancy. These conditions include radiation effects, initial tolerance variations, aging, and unit-to-unit variations defining end-of-life (EOL) conditions. VTMT applies power downstream of voltage regulating devices to permit an adequate range of voltage variations. Optimum limits for voltage and temperature must extend beyond the extremes of the derated part specifications, but must remain within manufacturer device limitations. The test plan pays careful attention to limits; it describes in detail the execution of the tests, including exercising the functional characteristics of the design and assessing the associated circuit parameters against the established pass\/fail criteria. Potential failure modes must be identified prior to VTMT to ensure that no damage occurs to the unit under test. Typically the operational extremes are extended to demonstrate positive flight margins using temperature as the universal test parameter to simulate other parameters such as environmental and end-of-life changes. Thus the item under test is exposed to risk of damage by stress due to high temperature. Hence, the support equipment used to control the temperature and the test parameters must be extremely accurate, especially at maximum temperatures. Technical Rationale: VTMT has long been an important tool for verification of circuit operational limits that are dependent upon part parameter variations. The following techniques form the VTMT repertoire: (1) temperature variation, (2) applied voltage variation, and (3) clock frequency variations for digital circuits. The use of VTMT to simulate worst case functional performance is justified because the effects of voltage, temperature, and frequency upon device performance parameters is similar to the effects of radiation and end-of-life changes. This concept is very well demonstrated quantitatively at the part level, but less quantitatively at the assembly level. The rationale for use of these three test procedures is discussed below. 1. Temperature Variations: As temperature changes, so does the absolute values of the parameters of the individual parts. Temperature is the first order term in almost every variation of part parameters except for initial tolerance variation. Similarly for cables and transmission lines, distributed parameters exist that also vary with temperature. 2. Applied Voltage Variations: Changing the supply voltage to the circuit under test is equivalent to changing the voltage potentials across groups of parts. Thus the potential across each part within a circuit loop changes accordingly whenever the total applied voltage is changed. Varying the applied voltage can check the ability of an analog circuit to operate within specifications and generally can be added linearly to the temperature induced performance changes. 3. Variation of Clock Frequency for Digital Circuits: Varying the frequency of an input clock or pulse train can simulate changes of digital circuit delay parameters which may occur during flight. The limits of design degradation (and limits of absolute failure) with frequency can be determined. This knowledge can be used to determine if sufficient timing margins exist. Often voltage is reduced during the frequency margin testing to achieve even more margin. Clock frequency changes of \u00b125% are typical in performing the VTMT. In forming combinations of two or more of these test tools, considerable attention is given to simulating the effects of operating life, radiation, and initial tolerance. Preventive measures are ascertained from relevant experience, related reliability analyses, or test and manufacturing data that have been obtained on similar units and interfaces. VTMT duration should be sufficient for the devices to reach thermal equilibrium and exhibit steady-state operating conditions. The test requires approximately 3 hours at each temperature level over a 24-hour duration. Measurements before and after the tests are recorded and compared with a predetermined deviation, e.g., less than 15 percent. The test planner consults the failure prevention plan for the flight project to ensure the safety of the hardware. A test matrix may be used to form a safety prevention checklist of critical conditions, and the matrix may provide a catalogue identifying diagnostics and possible failure chain contributors. The VTMT technique is a closed-loop process; it comprises a checklist that is planned, monitored, and evaluated concurrently by quality assurance, reliability, and engineering personnel. Since the voltage, temperature, and frequency variations applied in VTMT can exceed those expected during flight, the additional circuit design margins successfully demonstrated by the test are assumed to encompass the parameter margins expected from radiation and operating life. Calculations can be performed to estimate the final margin. Note that although initial tolerances of parameters disappear when the to-be-flown hardware is the item under test, the initial tolerance variation must be considered in VTMT application to all other units of the same design. Figure 1 is a flow diagram of the VTMT process. [D] References Reliability Analyses Handbook (1990), Jet Propulsion Laboratory, D5703. Reliability Assurance Guidelines for Low Cost\/Short Duration Missions (1995), Jet Propulsion Laboratory, NASA Technical Memorandum 4629.","Lesson ID":771}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1225; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. By initially selecting a 9 Db margin, the probability of complying with the electromagnetic compatibility (EMC) specification during system test is high. Implementation Method: Radiated and conducted emission specifications established for the customer are based on overall theoretical requirements which will meet the system specifications. The following design practices for subsystems allow for measurement error, combined effects, and manufacturing tolerance. This assures that an adequate margin will be realized when the final system performance is evaluated. In those cases where an outside agency imposes the allowable emissions levels, the included margins must be taken into consideration so that excessive constraints are not applied. When a specific requirement is identified as a major cost driver for design, margin allocations should be reviewed for possible relief. Conducted Emissions: Out-of-specification conducted emission on power, control, and signal lines can usually be controlled by a low-pass filter to reduce or eliminate unnecessary high-order harmonics. On digital circuits, a compromise must be made between the need for square pulses and the suppression of high-order harmonics. Radiated Emissions: Radiated emission can be reduced by cancellation, cross polarization, or by either magnetic or electric field shielding. In some cases, radiated emission can be reduced by using a balanced design so that the external magnetic or electric fields are cancelled or cross-polarized at a particular sensor. Shielding can be added if the additional weight can be tolerated. Otherwise, increasing the separation distance between the emitter and a sensor may be adequate. Low frequency magnetic and electric field emissions must consider the inverse cube relation between amplitude and the separation between source and sensor in order to determine an adequate separation. Technical Rationale: By allowing a 9 Db margin at the design phase, there is sufficient tolerance to provide a high degree of confidence that the equipment will pass the system EMC tests. 9 Db is needed to account for the differences between idealized theory and practice plus the test margin. The test margin covers both manufacturing tolerance and measurement tolerance.","Lesson ID":767}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1435 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Identification of hardware-imposed limitations on RF subsystem performance permits designers to evaluate a selected radio technology or architecture against system requirements. In the test phase of the reliability assurance program, it also helps engineers to understand performance characteristics they encounter during testing. RF modeling and verification provides for designed-in reliability in accordance with NASA's project streamlining policy. Implementation Method: For each major telecommunication function (channel) such as carrier tracking, command demodulation, two-way ranging, differential one-way ranging, and downlink telemetry, generate a model which includes each of the major sources of performance-limiting characteristics. This simulation of major hardware limitations should accurately represent their effect on RF performance. These effects may include band-limiting, non-linearities, non-zero rise and fall times, and SNR degradations. Quantify the potential impact of these limitations on ability to meet mission uplink and downlink requirements. For example, the downlink telemetry function was analyzed for the Cassini radio frequency subsystem (RFS). The analysis was performed in eight steps, including development of: Distortion definitions for trapezoidal telemetry data waveforms. Block diagram for simulating an ideal telemetry control unit (TCU) telemetry subcarrier modulator, as shown in Figure 1. [D] Block diagram for converting ideal random data waveforms into trapezoidal random data waveforms. Block diagram for simulating an ideal linear phase modulator. Block diagram for simulating a non-ideal linear carrier phase modulator. Block diagram of a phase demodulator. Signal to distortion ratio (SDR) estimator block. Complete telemetry channel model. Strong signals were analyzed; no noise of any type was included. The specific products of this Cassini RFS analysis were: Development of a model of the telemetry channel which includes the nonzero rise and fall times of the telemetry waveforms, the non-linearities in the X-band downlink carrier phase modulator, and the non-linearities in the ground receiver demodulation process. Characterization of the distortion introduced in the telemetry signal by the nonzero rise and fall times. Characterization of the distortion of the demodulated actual telemetry waveform at the ground receiver output due to the combined effect of the nonzero transition times and the non-linearities in the carrier phase modulator and phase modulator. The modeled parameters were tabulated to verify compliance with Cassini downlink mission requirements. Technical Rationale: Early in the design phase, when the radio architecture and design concept are selected, it is necessary to understand assembly-level hardware limitations and their effect on radio performance. Given the subsystem complexity, it is often difficult to pinpoint the exact cause of unexpected test results once the subsystem has been integrated. References quotRFS Downlink Telemetry Analysis Report,quot Robert Mueller (Jet Propulsion Laboratory) IOM 3367-93-392 of 8\/24\/93, Cassini Project. Spurious Radiated Interference Awareness, Reliability Preferred Practice No. PD-AP-1310","Lesson ID":769}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1230; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. The use of advanced design management methods in each program phase of major launch vehicle developments will maximize reliability and minimize cost overruns. Significant improvements in user satisfaction, error-free performance, and operational effectiveness can be achieved through the use of these methods. Implementation Method: Introduction: As emphasis in the aerospace industry shifts from maximum performance to low life cycle cost and high reliability, the rate of major technological design advancement is giving way to design management improvements. Common to these evolving improvements are the principles and tools of total quality management as applied to systems design analysis. This practice reviews successful systems engineering methodology as it applies to engineering design analyses for launch vehicles, and identifies total quality management applications that provide reliable, low cost aerospace designs. Since designing to high reliability can be correlated to reductions in the long-term cost of failures and spares, cost emerges as the systems common denominator. Systems management, systems design, and other systems approaches are well-established processes in the aerospace communities for developing all or any part of large, complex systems. The systems design process provides an orderly transformation of mission objectives into a detailed system design through three continuous and correlated phases: concept formulation, definition, and design. Effective use of these design phases has advanced design practice from an earlier single option procedure to the development of multiple options for trading and selecting optimum performance of mission systems. A total system decomposes into tiers of systems, elements, and components throughout the concept formulation, definition, and design phases. Each tier decomposes further into design parameter tasks which expand and interact with systems, elements, or components of the respective tier. Tasks identify design parameter requirements, develop design options to satisfy requirements, perform trades, and formulate criteria by which the best option leading to final design, specifications and plans can be selected. Total quality management procedures consisting of matrix methods, quality techniques, and life cycle cost analyses can be applied within the systems design analysis process throughout all design phases to achieve the simultaneous goals of high reliability and low life-cycle costs. Matrix Methods: A system is a set of parts whose behavior depends on the behavior of other parts. The need to flow scheduled information in a complex system often results in decisions based on limited analyses and understanding of user requirements and the complex relationship among interacting systems. Matrix methods are used to make these relationships more orderly, visible, and understandable. While the work breakdown structure (WBS) is a hierarchical relationship, it is still one-dimensional and, as such, cannot depict the many interactions between a system's subsystems, components, and parts. Matrices, however, can be multidimensional, and can interact with each other in much the same way they do in a relational data base. As an example, Figure 1 shows a multidimensional matrix progression for payload and launch vehicle subsystem analysis. Payload requirements, listed as rows in matrix 1(a), are determined by the characteristics of payload packages A, B, C, or D, which are arranged in columns. Each payload package, transferred to rows in matrix 1(b), can be accommodated by selected vehicle concepts arranged in columns E, F, G, and H. The varying vehicle parameters of each of the vehicle concepts can be displayed in a third matrix 1(c), showing the concept's impact on each launch vehicle system. In a three-dimensional matrix, shown on 1(d), the impact on each system element can be assessed. These matrices, which can progress down further into components and parts, permit interactive assessment of requirements flow-down and buildup as the design evolves for a launch vehicle that can accommodate a family of payloads. This arrangement is uniquely adaptable to computer-aided analysis. [D] Quality Techniques: Typical quality techniques applicable to systems design phases are quality leverage, quality function deployment, concurrent engineering, and Pareto's principle. Quality leverage, as shown on Figure 2, is greater during the earlier phases of a project. The earlier the control of objectives, the more timely and efficient are the solutions and modifications. [D]Concurrent or simultaneous systems engineering is a team effort in which all essential disciplines participate in the analysis and selection of concepts, components, materials, manufacturing processes, and major operations. Concurrent engineering is initiated during the concept phase and may expand and branch into systems and element integration working groups as required during the design phases. Team success depends on the adoption of the best available practices, avoidance of previously unsuccessful practices, and on a creative environment fostered by the team's technical leadership. Pareto's principle observes that 20 percent of parameters cause 80 percent of results. A reasonable approach for setting priorities to improve products or resolve problems is to first address the top 20 percent of the most significant parameters. These parameters are identified through histograms of their relative sensitivities to goals, e.g., ideal performance and lowest cost. The principle may also help specify hierarchic reliabilities. Life Cycle Cost Analyses: While user requirements and their accommodations represent one side of the balance, cost to implement them represents the other weighing pan. Judging from past projects, cost goals have not been achieved too well by the space industry. A major overrun cause is stretching the program to match fiscal appropriations. But aside from programmatics, designers have a unique responsibility to minimize overruns by completing design analyses at each design phase, controlling requirements buildup through all design phases, and reducing sources of engineering bottlenecks. The cheapest design changes are early paper changes. Cost models are the mechanisms for assessing trades and for tracking and controlling requirements buildup. They are initiated in the concept phase and expanded through all phases and levels of solutions. Models provide the basis for identifying cost driving requirements (Pareto's principle) and sensitivities in support of exploring innovative methods and concepts for reducing cost or for assessing vehicle evolution requirements. They provide the source and basis for making initial high leverage cost decisions and for setting development priorities on critical tasks. Cost models serve to formulate budget controls, detect cost overruns, and pace efforts relative to prevailing funds. Good cost estimates throughout the systems design analysis are the balance and enforcers of successful projects. Design Phases: The analytical design tools and principles described in the preceding paragraphs are used throughout the engineering analysis process with increasing intensity as greater detail is generated about the final product. In cost-constrained environments, the analytical tools and principles should be used to derive specifications and requirements in a quotreverse-engineeringquot process which designs the system to a life cycle cost target. The following paragraphs describe the activities in each phase that will result in the best design product. The concept phase is a first-order activity having the greatest quality leverage and, perhaps, is the most critical for the success of the mission. It is first and foremost a marketing phase which analyzes promising demands and competition for access to and for operation in space. It identifies a potential class of user needs, and it scopes missions within doable schedules and costs. Results of this phase are a set of select, top-level design specifications of customer needs and mission concepts to satisfy them. It includes a comprehensive set of mission requirements and constraints; first-order definition of vehicle configuration, systems, and elements; operation scenarios; and a basis for estimating costs. Subsequent phases peel the systems and elements to lower hierarchies, and expand the systems process of requirements, solutions, and selections. The definition phase is a detailed continuation of the concept process in identifying design parameters and requirements of the selected vehicle concept, and in developing solution options and selection criteria leading to a vehicle configuration and to system, element, and component preliminary designs. Results encompass a detailed definition of total vehicle systems and system elements including flight hardware, support equipment, software, and personnel, and the complete operational use definition, configuration description, preliminary design, and systems operational plans. Requirements identified in this phase are documented as vehicle specifications. A total life cycle cost of elements is also required. Concurrent engineering teams develop selection criteria and select and verify solutions. Teams include flight, propulsion, structures, avionics and facilities systems, and should have representation from the mass properties, reliability, manufacturing, verification, operations, safety, and costing disciplines. The design phase is the final systems analysis phase and perhaps the most consequential because its detailed design must fit and function as an integrated whole. It is also in the realm of lowest design quality leverage. This phase must proceed with detailed bottoms-up costing adjustments. The systems analysis must penetrate all final component designs for compliance with all tiers of specifications and requirements, and to amend emanating deficiencies through relevant upstream design phases. It must assess and assure that integration conflicts and issues are identified and resolved through all levels of components and systems. It must further analyze and modify detailed component designs and their integrations for (1) high quality performance, (2) manufacture, (3) verification, and (4) operations at lowest cost. Technical Rationale: Many years of experience in developing launch vehicles, propulsion systems, and payloads, have been combined with emerging design management techniques to formulate a rigorous methodology for developing low cost, high reliability, launch vehicle for space applications. Greater detail in employing this methodology than presented here can be found in the references, and in the recent classic literature on total quality management, project management, and systems engineering. Conscientious application of these latest methods, coupled with the use of emerging computer-based analysis and simulation tools, cannot only improve product reliability and cost effectiveness, but also reduce the cost and time required for the design process itself. References Ryan, Robert, and Verderaine, V.: quotSystem Design Analysis Applied to Launch Vehicle Configuration,quot NASA Technical Paper #3326, Marshall Space Flight Center, Alabama, 1993. Steward, D.V.: quotSystems Analysis and Management,quot Petrocelli Books, Inc., New York, 1981. Blanchard, Benjamin S.: quotSystem Engineering Management,quot John Wiley & Sons, Inc., New York, 1991. Hopkins, J.: quotApproaches to Reduced Launch Operations Costs,quot SAE 901877, Aerospace Technical Conference, October 1990. Rutledge, William S.: quotLaunch Vehicle Cost Trends,quot Aerospace America, June 1994.","Lesson ID":762}
{"Driving Event":"This Lesson Learned is based on Reliability Guideline number GD-ED-2215 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Very early consideration of instrumentation (Note: for purposes of this lesson, the term instrumentation refers only to sensor and signal conditioning subsystems and will not include the data management subsystem) requirements compatible with vehicle or payload system monitoring and control requirements will result in: (1) Choice of sensor technology and sensor hardware\/software that is cost-effectively matched to specific vehicle environment, design, performance, and configuration requirements; (2) Up-front consideration of the effects of instrumentation system and sensor maintainability, calibration, and reliability during the operational phase over the specified lifetime; (3) Optimum sensor location, avoidance of failures due to vibration, shock, thermal and stress effects, efficient cable design and routing; and (4) Lower costs of instrumentation system integration due to well thought-out and preplanned designs that are less subject to change during the development process. Implementation: It has been the general practice in past programs and projects to conceive and design instrumentation systems and related sensors, hardware, and software well after requirements for the system have been established. Instrumentation considerations have frequently waited until well after the design of the parent hardware has been approved, and many times the instrumentation design has not been initiated until the initial test hardware is well into fabrication. In general, this practice has not been seriously detrimental to past programs because of the luxury of ample resources and schedule time to iterate the instrumentation configuration many times prior to flight. Furthermore, the technologies available were not as advanced as those becoming available in the present age of computer-aided analysis, engineering, design, testing, and manufacturing. New concurrent engineering methods and tools that are now available, and the use of integrated product engineering development teams allow instrumentation considerations, designs, and technologies to be introduced at the earlier phases of the project life cycle. Earlier consideration of instrumentation issues will result in greater efficiencies and more effective total instrumentation support of the space system development and flight operations. Background: There are three main purposes of instrumentation systems, (1) to perform measurements, (2) to provide for system control, and (3) to relay information. Measurements are needed to obtain information on system operation and the operational environment. Based upon this information, feedback and adjustments can be made to control loops to maintain system control. Finally, the information generated by the measurements must be processed and relayed from the operational system to data collection and analysis centers. Data processing and relay are outside the scope of this guideline and will not be discussed further. There are three types of measurements: (1) measurements for design, test, and evaluation; (2) measurements for calibration; and (3) measurements for control (Ref. 1). Each of these types of measurements impose unique requirements on the vehicle or payload instrumentation system. Science, design, test, and evaluation measurements seek to answer questions about a physical process or environment about which little or nothing is known. A key consideration in these types of measurements is the effect of the instrumentation system itself on the phenomenon being measured. Control measurements are made to ensure the process or system is working properly. This usually involves making adjustments in control loops so as to maintain an operating point within some acceptable range. Calibration measurements are made to characterize part of the instrumentation system, such as a sensor, in a known environment with specific boundary conditions. I. Key Instrumentation Considerations: There are a number of instrumentation issues that need to be addressed as early as possible in the system life cycle. The earlier these issues are addressed the more reliable the measurements, and thus the overall system, will be. Close communication and interaction among instrumentation engineers, system users, and system designers are essential if these issues are to be adequately addressed. These key issues are briefly discussed in the following paragraphs. A. What is the quotrealquot measurement requirement? Experience has shown that often the user does not state the real measurement requirement but rather an implementation. This must be avoided early-on as it results in limiting potential measurement solutions and affects reliability. A good question to ask to get at the core requirements is, quotIf you could only have one measurement, what would it be?quot In addition to the answer to this question, the type and purpose of each proposed measurement must be understood. B. Operating environment The environment in which a measurement must be made significantly impacts the selection of sensors and ultimately the reliability and accuracy of the resultant information. Examples of important environmental factors include vibro-acoustics, atmosphere, temperature, and pressure. C. Required accuracy and frequency response This is an area where significant tradeoffs and compromises must be worked out between the user and the instrumentation engineer. Since accuracy and frequency response of sensors are directly related to cost, it is incumbent on the instrumentation engineer to make program participants aware of the cost to the project of satisfying stated accuracy and frequency response requirements. Often, it will turn out that less stringent requirements in these areas can satisfy the quotrealquot requirements at significant cost avoidance to the project. D. Constraints There are a number of constraints with which the instrumentation system must comply. Some are limited resource allocations for things like size, power, weight, volume, and cost. Other constraints will arise with regard to possible locations for sensors and signal conditioners, and feasible routing for cables and connectors. All of these constraints must be dealt with in designing reliable instrumentation systems to meet user requirements. E. Maintainability\/Reusability Instrumentation system components such as sensors, signal conditioners, and even cables and connectors are subject to failure. Requirements for access to these components to affect repairs will also impact the instrumentation system design for long-life missions. Related to maintainability are requirements for sensor checkout, calibration, and diagnostics which must also be factored into the instrumentation system design. Similarly, requirements for cleaning and refurbishment associated with reusable flight systems impact on the design. F. Electrical and mechanical interfaces Often early decisions are made on the avionics architecture and on the data management system which will impact the instrumentation system design. Such items as choice of flight computers and data bus standard will be driving requirements in selection of instrumentation system components. Likewise, specific requirements for mounting and other mechanical interfaces will affect instrumentation system design. II. Integrating Instrumentation System Design into the Project Life Cycle Instrumentation engineering is one of the engineering specialties which needs to be integrated into the overall system engineering process required to develop and operate reliable aerospace systems. The tendency has been to wait until the design phase of the life cycle before seriously addressing instrumentation requirements and issues. Often it is even later, even after the design is complete, before instrumentation is considered. When this occurs, it can result in less than optimum instrumentation solutions to engineering and science requirements. One consequence can be less reliable systems due to the inability to gather information on the true condition of the flight system in operation. An example of this problem can be seen in the Space Shuttle Main Engine (SSME) program at MSFC. Only after the High Pressure Fuel and Oxygen Turbopumps were designed did it come to light that the single most important measurement that the engineers wanted was turbine inlet temperature. However, because instrumentation considerations had not been addressed early enough, no provision had been made in the design to accommodate a sensor for this purpose, and it was deemed too costly to redesign the turbopump at that point in the program. A typical NASA flight system passes through several distinct phases in its life cycle as it proceeds from concept exploration to system disposal. NASA Management Instruction (NMI) 7120.4 (Ref. 2) and NASA Handbook (NHB) 7120.5 (Ref. 3) describe these phases and the associated activities and milestones associated with each. Figure 1 (Ref. 4) summarizes these phases and the major activities and outputs of each phase. [D] The appropriate instrumentation engineering activities for each phase are discussed in the following paragraphs. A. Phase A (Analysis Phase) This is a study phase in which mission needs are determined and preliminary concepts are explored. Project objectives, new technology requirements, and potential system concepts are developed and analyzed to determine the project feasibility and cost-effectiveness. Performance tradeoff analyses are conducted to refine the system concepts and to identify risk areas. A key activity in this phase is the definition of preliminary system requirements and the development of a Preliminary Program Plan. Early point designs and even configuration layouts are a product of this phase. Even in this earliest of project phases, instrumentation issues should be addressed. First, the instrumentation engineers should be involved in developing the preliminary system requirements to ensure the key considerations discussed in Section I above are addressed. Obviously, point designs and configuration layouts can have significant impacts on instrumentation concepts and solutions and need to be reviewed carefully. Armed with knowledge and understanding of the system requirements and objectives, the instrumentation engineers can begin to define both the purposes and types of measurements that will be needed and to develop preliminary instrumentation concepts. The instrumentation concepts, preliminary measurement definitions, sensor technology development needs (if any), instrumentation risk assessments, schedule and resource requirements should all be documented in a Preliminary Instrumentation Plan which should be an output of this project phase. Phase A ends upon approval of the Mission Need Statement. Instrumentation Guidelines for the Analysis Phase: Ensure user needs and mission requirements are understood by the instrumentation engineers. Ensure preliminary system requirements include appropriate instrumentation considerations. Prepare a Preliminary Instrumentation Plan that addresses instrumentation concepts, measurement definitions, sensor technology needs, risk areas, and resource requirements. Ensure the Preliminary Instrumentation Plan is reviewed by all program participants in conjunction with a Preliminary Requirements Review or other formal review. B. Definition and Preliminary Design Phase (Phase B) This phase accomplishes the refinement and baselining of system requirements, cost estimates, schedules, and risk assessments prior to final design and development. Alternative system concepts defined in Phase A are refined and a final selection is made. System analyses and simulations are conducted and further tradeoff analyses are made to refine system and support requirements. Preliminary manufacturing and test requirements are also defined and assessed in this phase. Key outputs of this phase include a baselined System Specification and a Preliminary Design Review (PDR) baseline. Instrumentation engineering involvement should increase in this phase with activities focused on influencing the system specifications and preliminary designs to facilitate reliable vehicle instrumentation and measurements. The Instrumentation Plan should be updated and baselined in this phase. Preliminary instrumentation system design and preparation of a preliminary Instrumentation Program & Command List (IP&CL) should be completed. The IP&CL is defined in MSFC-STD-1924 (Ref. 5). Instrumentation Guidelines for the Definition and Preliminary Design Phase: Ensure the System Specification, lower-level specifications, and the preliminary system design include all appropriate instrumentation considerations and requirements and satisfy user needs. Update and baseline the Instrumentation Plan which defines the instrumentation concept and design, measurement definitions, sensor technology needs, risk areas, and resource requirements. Ensure the Preliminary IP&CL accurately reflects the instrumentation system design and component selection. C. Design Phase (Phase C) In Phase C the detailed system design is completed and plans are refined for development, fabrication, verification and validation (V&V), and operations. Detailed subsystem design and performance specifications are baselined in this phase, as well as Interface Control Documents (ICDs). In addition, verification and validation requirements and specifications are finalized. This phase ends with the successful completion of the Critical Design Review (CDR). Instrumentation engineers should be intimately involved in this phase to ensure detailed designs are compatible with user needs and instrumentation requirements of the program. Detailed instrumentation system design and analyses will be completed and final selection made for all system components. Instrumentation Guidelines for the Detailed Design Phase: Ensure the detailed system and subsystem designs include all appropriate instrumentation considerations and requirements and satisfy user needs. Ensure the IP&CL accurately reflects the final instrumentation system design and component selection and is baselined after CDR. D. Development Phase (Phase D)\/Operations Phase (Phase E) In Phase D the flight hardware and software are developed, manufactured\/coded, verified, and qualified for flight operations. During this phase, prototype\/protoflight hardware is developed and tested. This is followed by manufacture, integration, and verification and validation of the flight hardware and software. Finally, the flight system is checked out and launch and initial flight operations commence. Instrumentation engineers will be involved in the V&V effort, as well as vehicle checkout and flight operations. During Flight Operations (Phase E), the instrumentation engineers will be involved in evaluating and resolving on-orbit anomalies. Instrumentation Guidelines for the Development\/Operations Phase: Document and evaluate on-orbit verification results and anomalies. Document lessons learned. Technical Rationale: Without reliable flight instrumentation systems, information needed to accomplish successful missions and document results will not be obtained. Increased emphasis in the early project phases on incorporating instrumentation considerations and requirements will help ensure NASA aerospace systems satisfy mission and science requirements. This guideline and its references provide project managers, chief engineers, and users with a set of instrumentation principles tailored to each phase of the system life cycle. Application of these principles should result in development of more reliable flight instrumentation, in less time, and at lower cost. References Stein, Peter K., quotThe Unified Approach to the Engineering of Measurement Systems for Test & Evaluation,quot 1992. NMI 7120.4, quotManagement of Major System Programs and Projects.quot NHB 7120.5, quotManagement of Major System Programs and Projects - Detailed Policies and Procedures.quot MSFC-HDBK-1912A, quotSystem Engineering Handbook,quot December 6, 1994. MSFC-STD-1924, quotStandard for Instrumentation Program and Command Lists (IP&CL),quot June 21, 1993. Reliability Preferred Practice PD-ED-1251, quotInstrumentation System Design and Installation for Launch Vehicles.quot","Lesson ID":761}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1438 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. The benefits of implementing the practices spelled out herein are protection against inadvertent activation of the launch vehicle command destruct system, reliable activation and operation of the command destruct system in the event of vehicle malfunctions, and protection of the mission hardware and personnel prior to and during the launch. Implementation: Introduction: The Space Shuttle Command Destruct System (CDS) is a triplex configuration providing a redundant subsystem on the SRB. The CDS consists of RF receiving elements, dedicated power sources and pyrotechnics. When activated, the CDS terminates the thrust of the SRB by pyrotechnic charges that sever the Solid Rocket Motor (SRM) cases along 70 percent of their length. The SRB onboard command destruct system allows the Range Safety Officer to intentionally destroy the SRB in the event of flight path deviation, improper flight parameters, or inadvertent separations. The Command Destruct System consists of the components and quantities listed in Table 1. [D] Figure 1 is the SRB CDS Functional Diagram. [D] Ground commands arm the safe and arm (S&A) device approximately five minutes prior to SRB ignition. If destruct action is required, the nominal range safety destruct procedure will consist of energizing the quotarmquot command several times, application of a one second pause, then energizing the quotfirequot command several times or until the destruct action is accomplished. The fire command to the Pyrotechnic Initiator Controller (PIC) discharges its capacitor, igniting the NSD. The detonation from the NSD is propagated through the S&A device transfer charge and the CDF train to the linear shaped charge (LSC). The detonation output of the LSC cuts the case along 70 percent of the length of the Solid Rocket Motor causing destruction of the SRB. Reliability Considerations: The minimum overall system reliability goal for the Command Destruct System is 0.999 at a 95 percent confidence level. Some reliability considerations considered during design, development, qualification, and acceptance testing are listed below: Elimination of single point failures. Redundancy. Fail-safe functions. Personnel properly trained in handling, assembly, installation, and checkout of command destruct systems. Development testing, qualification testing, and, especially, acceptance of every pyrotechnic device lot manufactured are monitored by engineering and quality personnel. Adherence to the provisions of NHB 5300.4 (ID-2), quotSafety, Reliability, Maintainability, and Quality Provisions for the Space Shuttle Program.quot Redundant paths are verified by test. Electronics and cables are checked out after installation down to NSI installed in the NSD. NSD bridge wire resistance is verified after installation. Safe & Arm device function is verified after installation. Other reliability analysis such as Worst Case, Fault Tree, FMECA, Parts Stress, Single Event Effects, Thermal\/Structural Strength, and Sneak Circuit Analysis should also be performed, where applicable. Design methods for reliable Command Destruct Systems are listed below: Separation of redundant equipment except the Range Safety Distributor, Hybrid Coupler, Safe and Arming Device, and dual systems mounted on the same mounting panel. Provide a fail-safe design for ascent critical functions. The Command Destruct System operates in a standby mode for ascent and is exempt from in-flight redundancy verification. The Command Destruct System electronics include sufficient instrumentation to provide self-diagnostic ground indicators except for the PIC which uses built-in test equipment for the ground checkout of the pyrotechnic electronics. Demating of electrical cables is not permitted except for the NSD. Redundant components susceptible to contamination or environmental failure are separated. Inadvertent electrical shorting due to debris is prevented by design. Design engineering and quality engineering review and approve manufacturing procedures and processes. Quality engineering also reviews and approves inspection criteria required to ensure that qualification and flight hardware are free of defects. Development testing, qualification testing, and acceptance testing are principal methods by which pyrotechnic devices are proven to meet design requirements and to meet the reliability levels necessary for manned launch vehicles. All test records and data are reviewed by NASA and prime contractor engineering and quality personnel. The Eastern Space and Missile Center Range Safety Officer's approval is required for Command Destruct System conceptual design, detailed design, qualification\/acceptance test requirements, range prelaunch test requirements, test plans and procedures, installation and checkout procedures, failure corrective action, and launch approval. Technical Rationale: The design, manufacture, testing, and launching of the Command Destruct Systems have been proven over a period of more than 30 years. The Command Destruct Systems for the SRB have flown on the Space Shuttle for over 70 flights without a failure. References AFETRM 127-1: quotEastern Range Regulation,quot Range Safety Space Command, United States Air Force, June 30, 1993. NSTS 007700: quotSpace Shuttle Flight and Ground System Specification,quot Program Definition and Requirements, Volume X, Book 1, NASA, Johnson Space Center, Houston, TX, 77058, June 4, 1993. NSTS 08060: quotSpace Shuttle System Pyrotechnic Specification,quot NASA, Johnson Space Center, Houston, TX, 77508, February 11, 1994. 30A90506D: quotShuttle Range Safety Command Destruct System Specification,quot NASA, Marshall Space Flight Center, Marshall Space Flight Center, AL, 35812, June 5, 1989. 10MNL-0030: quotSolid Rocket Booster\/External Tank Pyrotechnic System Handbook for Space Shuttle,quot Volume I and II, NASA, Marshall Space Flight Center, Marshall Space Flight Center, AL, 35812, July 14, 1989.","Lesson ID":766}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1439 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Experience in systems testing of the Space Shuttle Main Engine has shown that integrated propulsion system testing, (1) provides the necessary test data for \"model basing,\" thus enhancing the reliability of system analysis techniques; (2) integrates vehicle hardware, ground hardware, and procedures for propellant loading, safing, and firing operations; (3) provides a resource for determining stage\/engine design margins, establishing redlines, developing procedures and time lines, and confirming extrapolated criteria used in engine development; (4) identifies potential risks for catastrophic flight failure, vehicle hardware damage, and launch complex damage; and (5) identifies potential risks of a delayed initial launch and subsequent launches. Implementation Method: I. Background: The Space Shuttle Main Propulsion Test Article (MPTA) program was conducted at NASA's Stennis Space Center test site in Mississippi. The program involved NASA and Space Shuttle element contractors. The tests included an orbiter aft fuselage with three Space Shuttle Main Engines, an External Tank, and related ground and flight support equipment. Three non-firing tests and twelve combination development\/verification firings met planned pretest objectives. The main propulsion test article was of a flight configuration with a few practical exceptions. External Tank insulation was of non-flight configuration. The auxiliary power unit was simulated by a ground powered hydraulic system. The Shuttle Avionics Test Set was used for propulsion system control rather than flight computers. A special load bearing structure was provided on the test stand to react against the engine's thrust. Non-flight hardware was used for payload bay purge into the aft compartment, propellant loading, ground umbilical disconnects, and some Ground Support Equipment consoles. II. Propulsion System Testing Twenty hot-firing attempts were required to meet the requirements of the 12 test series. Hot firing aborts were distributed throughout the 20 firing attempts, although the frequency of occurrence decreased after the sixth test series or after 50 percent of the test program was completed. Twenty-six terminal counts were required. Fourteen of these were required during the first six firing attempts. Hydrogen leakage within the aft compartment occurred on 12 tests. Two tests experienced high leaks. The degree of severity of some of the test failures underscores both the risk involved in propulsion system development and the absolute necessity of this type of testing in order to avoid and eliminate these types of failures during a flight mission. For example, fires occurred in nine firings. Eight of the nine fires resulted from engine discrepancies. Four of the fires at the vehicle base were typical of main fuel valve leaks through the engine after shutdown. One aft compartment fire resulted in extensive hardware damage. Two external fires produced significant damage to the vehicle and facility, particularly to the instrumentation. III. Changes and Modifications Brought About by the Main Propulsion Test Article (MPTA) Program The important issues that were addressed in the Space Shuttle Program to enhance the reliability, safety, and performance of the vehicle by MPTA testing were (1) unworkable designs and procedures were made workable by changes and then verified, (2) workable designs and procedures, for which adjustments to achieve acceptance were initially anticipated, were tested and the adjustments were accomplished. Many action items resulted and were resolved in each test series. Table 1 is an example listing of some of the most important action items that resulted from the propellant loading test, an early test where there was not a hot firing. Thirty to forty similar actions from a hot firing test were not unusual. Table 1. Example Action Items From Engine System Testing Review LH2 high point feedline liquid level sensor operation during propellant load test and repair. Review the need for redundancy. Determine the cause of tripped circuit breaker for LH2 recirculation pump #2. Determine requirements for a backup GHe injection system for the LOX antigeyser system operation Review the system requirements and reactivate MEC backup power. Provide necessary engineering to connect the KSC hazardous gas detection system to the LH2 vent system. Perform special cryogenic test of LOX and LH2 auxiliary dump valves using a solenoid actuated system as well as the existing pressure control actuation system and recommend system changes required to improve valve performance Review the need for changing the 1\/8\" sample line on the bottom of the LH2 tank to 1\/4\" or larger line to facilitate tank sampling and verification of purge procedures. Testing identified oversights which could have resulted in serious consequences under differing circumstances later in the development program. For example, design and manufacturing methods were changed to prevent the release of large hydrogen quantities as a result of main fuel valve structural failure. Design changes were made to prevent fuel preburner burn-through and associated engine software changes were made to facilitate automated prevalve closure under all failure conditions. Manual closure was delayed under some failure conditions until the prevalve benefits were seriously compromised. Changes to software corrected this anomaly. Procedures for unloading oxygen from the ET\/Orbiter were corrected to prevent serious pressure surges within the facility hardware. The tests identified the necessity to locate launch facility igniters to burn released raw hydrogen at engine start. The Space Shuttle MPTA testing, as well as testing of previous launch vehicle integrated propulsion systems, resulted in preferred practices that will ensure reliable performance if conscientiously applied. Preferred practices are summarized in Table 2. Table 2. Improved Procedures Integrated testing is conducted to verify the performance of the feed system pressure drops, pressure surges, fluid-hammer responses, and resonances. Mixing of incompatible and hazardous substances in fluid systems are precluded. Contamination is excluded from contamination-sensitive systems. Actual environments, conditions, and designs are simulated. Margins are demonstrated during subsystem or system level tests. Test plans and results are fully documented. Stainless steel tubing and control lines are used for test facilities. Fuel and oxidizer prevalves are used in test facilities, and safe engine shutoff by prevalve closure is demonstrated in a subsystem test prior to propulsion system testing. Thermal and environmental controls of propulsion systems components are provided to prevent freezing, loss of lubrication, and collection of hazardous gases. An emergency source of ground power is provided to terminate the test in the event of a ground power loss. Provisions for pressure relief, flow diversion and control during chill down, and protection against geysering during propellant loading are designed into the test facilities' propellant feed system. Reliable hazardous gas detection and measuring systems and rapid response leak detectors are used for integrated propulsion system firing programs and pre-flight operations. Fire detection, fire protection capability, and internal protective neutralizing purges are used in static test programs, and are evaluated for launch site operations. Heat flux at the vehicle base is measured to determine the relative contributions of convective and radiative heating. Meticulous planning, training, and work control is employed in integrated propulsion system ground tests. Recirculation of rocket engine plume low energy gases into the vehicle base may be a predominant heat source for clustered engine vehicles. Heat flux measurements from ground test programs to determine the relative contributions of convective and radiative heating and analytical methods developed to compensate for flight altitudes assist in establishing design requirements. Meticulous planning, training, and work control is employed in integrated propulsion system ground tests. Specific preplanned and measured personnel training and demonstration of qualifications is a prerequisite for reliable and repeatable success. Steps to assure effective shift change communications and the use of only experienced and qualified personnel is required. A process where both contractor and government safety personnel perform spot checks on all hazardous work control documentation and operations is essential. IV. Other Related Development and Verification Testing In addition to integrated systems ground tests such as those performed on the Space Shuttle MPTA, structural test articles were built and tested, approach and landing tests were performed, an all-up hydraulic simulator Flight control Hydraulic Laboratory was developed and used, a Mated Vehicle Ground Vibration Test program was conducted, a Shuttle Avionics Integrated Laboratory was (and is) used, along with a Hydraulic Simulation Laboratory, for software verification prior to launch, and full scale external tank terminal drain tests were conducted. Extensive development testing was performed at KSC with the flight vehicle prior to the first launch to improve propellant loading procedures and to resolve other launch site\/vehicle interface problems. Due to a thermal protection system failure on the External Tank and the desire to increase onboard propellant mass, several unplanned propellant loading tests were conducted both with the MPTA and with the flight vehicle at KSC. Technical Rationale: Several decades of integrated ground testing of launch vehicle propulsion systems, culminating in the MPTA Testing for the Space Shuttle Program, have proven that this type of testing is essential to perfect the interface between major hardware and software elements and to develop a reliable integrated launch vehicle propulsion system. The test programs themselves have shown that malfunctions, delays, and failures would be unacceptable in a flight situation. The successful performance of the Space Shuttle Main Propulsion System is attributable in great measure to the successful conduct of this series of ground tests and to the corrective actions that were taken to avoid failures. References \"Advanced NSTS Propulsion System Verification Study,\" Space Transportation Systems Division, Huntsville Operations, Rockwell International, July 31, 1989. \"History of MPT Test Program,\" Space Transportation Systems Division, Huntsville Operations, Rockwell International, February 9, 1986. \"Main Propulsion System Testing Tanking Test History,\" Space Transportation Systems Division, Huntsville Operations, Rockwell International, July 1983. Quick-Look Test Reports for: MPT-S1-001, MPT-S1-002, MPT-S2-001, MPT-S3-001, MPT-S4-001, MPT-5A, MPT-5, MPT-6-001, MPT-6-02, MPT-6-03, MPT-SF7-01, MPT-SF7-02, MPT-SF8, MPT-9-01, MPT-9-02, MPT-10-01, MPT-11-001, MPT-11-02, MPT-12; Transportation Systems Division, Huntsville Operations, Rockwell International, 1978 thru 1981.","Lesson ID":763}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1226; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Constraining the electronic component junction temperature through proper design practices will ensure that the assemblies can withstand the mission's environmental conditions. Implementation Method: Sound thermal design practices are followed from the conceptual stage through the final design stage. A system for doing thermal design that takes into account the materials, fabrication methods and processes from the conceptual stage will increase the overall design flexibility as well as the reliability. This practice is primarily coupled to the JPL dual shear plate packaging approach. Packaging design reviews should be conducted with technical personnel participating. The results of these packaging reviews should then be summarized in the formal subsystem Preliminary Design Review and Critical Design Review. Electronic components that require higher thermal conductance than normal assembly methods can support should be mounted with thermally conductive material. High power dissipation axial lead components can be cooled through a thermal window in the printed wiring board providing a heat path directly to the chassis. Conductive heat sinks are also used to maintain the electronic components within their derated temperature range. Selection of the proper high power parts is very important to the success of the mission. Design of the system should avoid using high power analog devices as much as possible. Stud mount or screw mount devices should be used whenever possible. High power TO-type metal can devices should be mounted and bonded top down on the board or chassis using qualified thermal adhesives coupled to an efficient method for removing the excess heat. Placement of parts is as important as the selection. Good thermal design for electronic boards should provide the heat flow toward the mounting edge of the module. The end plates are considered as structural support only and not included as part of the thermal path. The path to the metal chassis or thermal control surface should be as short as possible. Surfaces and finishes should be selected to provide low resistant thermal paths through interfaces. Spacecraft or instruments used in low earth orbit or in the space shuttle payload bay should have a thermal control finish that is designed to withstand erosion from an atomic-oxygen environment. Technical Rationale: A spacecraft chassis and its electronic subassemblies are designed to meet the environmental conditions encountered by the given mission. Thermal analyses of heat dissipation, junction temperature control, and the elimination of hot spots during the design phase should be provided to ensure proper thermal design. Special emphasis is placed on reducing the junction temperatures of all semiconductors to safe levels throughout the mission. Related Practices: Part Junction Temperature, Reliability Preferred Practice No. PD-ED-1204 Thermal Test Levels\/Durations, Reliability Preferred Practice No. PT-TE-1404 Thermographic Mapping of PC Boards, Reliability Preferred Practice No. PT-TE-1403 Thermal Analysis of Electronic Assemblies to the Piece Part Level, Reliability Preferred Practice No. PD-AP-1306","Lesson ID":768}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1227; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Selection of materials, heat treating methods, fabrication methodologies, testing regimes, and loading paths that are not susceptible to stress corrosion cracking will promote fewer failures due to Stress Corrosion Cracking (SCC) and will eliminate downtime due to the change-out of components. Implementation: Numerous materials have been tested for susceptibility to SCC in a 3.5 percent NaCl alternate immersion bath, a 5 percent NaCl salt fog cabinet and a 90-100 percent relative humidity cabinet. These tests resulted in the development of a specification on Design Criteria for Controlling Stress Corrosion (Reference 3). The information contained in the specification is based upon laboratory tests in which specimens were either sprayed with salt water or periodically immersed and withdrawn; by exposure of the specimen to simulated seacoast or mild industrial environments; and by service experience with fabricated hardware. This specification also lists materials that have a high resistance, a moderate resistance, or a low resistance to SCC. MSFC's Material Selection List for Space Hardware (Reference 4) also lists materials that have a high resistance to SCC. [D] [D] [D] To avoid failure, the tensile stress in service must be maintained at a safe level. Since stresses are additive, all sources of stress (see Table 1) must be considered to ensure that the threshold stress (the stress level which will result in a failure if stress corrosion is present) is not exceeded. There is not an absolute threshold stress for stress corrosion as there is with other material properties. Therefore, estimates of the stress corrosion threshold for a specific service application must be determined for each alloy and heat treatment by using a test piece, a stressing procedure, and a corrosive environment that are appropriate for the material's intended application. A simplified stress corrosion test fixture with a round tensile specimen installed is illustrated on Figure 1 in a simulated corrosion environment. A masking material is applied to the test fixture to ensure that the specimen alone is exposed to the corrosive environment. The tensile specimen is stressed to a desired level (typically 25, 50, 75 or 90 percent yield strength). The specimen is then submerged in a 3.5 percent NaCl alternate immersion bath, in a 5 percent NaCl salt spray (fog), or in a 90-95 percent relative humidity test. Test duration is typically three months for low alloy steels and aluminum alloys, and six months for stainless steel. The most common processing methods for production of wrought metal are rolling, forging and extruding. These processing methods produce a granular structure which is parallel to the flow of metal. As shown on Figure 2, grain orientation is parallel to the longitudinal direction of rolling, extrusion or drawing. When thin shapes are rolled or extruded, grains are oriented in a short transverse or long transverse direction as shown on Figure 2. The resistance of metals to SCC is always less when tension is applied in a transverse direction. It is least for the short transverse direction. Stress corrosion is aggravated when tensile stresses due to assembly have been applied in the short transverse direction. Table 2 lists typical materials and environments that may cause stress corrosion. [D] Technical Rationale: SCC is caused by the combined action of sustained tensile stress and corrosion which result in premature failure of materials. Certain materials are more susceptible than others. If a susceptible material is placed in service in a corrosive environment under a tension of sufficient magnitude, and the duration of service is sufficient to permit the initiation and growth of cracks, failure will occur at a stress lower than the material will normally be expected to withstand. References Hall, A. and Hongola, M: Stress Corrosion Test Procedure Applicable to Lot Acceptance Testing and Qualification Testing for Forward Separation Bolt Assembly. Hi-shear Corporation, Ordnance Group, Torrance, CA, June 1, 1988. Fontana, Mars G.: Corrosion Engineering. Third Edition, McGraw-Hill Book Company, New York, 1986. Design Criteria for Controlling Stress Corrosion Cracking. MSFC-SPEC-522B, NASA\/Marshall Space Flight Center, AL, September 30, 1988. Material Selection List for Space Hardware. MSFC-HDBK-527F, NASA\/Marshall Space Flight Center, AL, September 30, 1988. Crain, Bruce D.: Handbook of Corrosion Data. ASM International, Metals Park, OH, August 1989. McEvily, A. J. Jr.: Atlas of Stress Corrosion and Corrosion Fatigue Curves. ASM International, Metals Park, OH, 1990. Scully, J. C.: The Fundamentals of Corrosion. Third Edition, Pergamon Press, Inc., Elmsford, NY, 1990. Torres, P.D.: MSFC Corrosion Test Procedure Currently Followed for Testing Round Tensile Specimens. Memo No. EH24(92-24), NASA\/Marshall Space Flight Center, AL, October 22, 1992. Standard Practice for Evaluating Stress Corrosion Cracking Resistance of Metals and Alloys by Alternate Immersion in 3.5% Sodium Chloride Solution. ASTM G44-88, American Society for Testing and Materials, Philadelphia, PA, June 1988. Standard Practice for Preparation of Stress Corrosion Test Specimens for Weldments. ASTM G58-85, American Society for Testing and Materials, Philadelphia, PA, November 1985, (reapproved 1990). Standard Test Method for Salt Spray Testing. ASTM B117-90, American Society for Testing and Materials, Philadelphia, PA, May 1990.","Lesson ID":764}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1432 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Knowledge of the dielectric breakdown characteristics of RF devices at low pressures or in a near vacuum environment can be used to protect sensitive flight equipment. RF breakdown is a concern because of the low, near-vacuum pressures at which spacecraft are tested and operated. RF breakdown testing is conducted to establish hardware resilience to the application of out-of-spec input signal levels, signal reflections due to mismatches at hardware interfaces, inadvertent evacuation of vacuum chambers during RF input, application of RF signals during the ascent phase of the spacecraft launch vehicle, etc. Implementation Method: Provide the expected signal level, plus an additional 6 dB over the expected operating frequency range, to the input of the device under test while monitoring the output frequency. Reduce the atmospheric pressure from ambient to vacuum at the controlled rate specified in the test plan. After dwelling at vacuum for a period of time sufficient to monitor the performance of the unit under test, increase the atmospheric pressure from vacuum back to ambient at a controlled rate. After the test has been completed, inspect the test article for damage. Hardware damage is manifested by a change in the monitored RF performance during the test, or by visible indicators such as burn marks on output connectors. If neither indication is evident, the equipment is considered to have passed the test. However, if the RF output signal dips or degrades, or external burn marks are seen, the test article is dismantled and inspected for internal burn marks in the vicinity of RF conductors. The typical corrective action is to redesign the equipment to provide wider gaps between RF signal conductors. Technical Rationale: Electrical damage to equipment or devices can occur due to dielectric breakdown. RF energy produces stress on the electrons in the gaseous medium between two electrodes situated within an electrical field. The RF breakdown phenomenon occurs at low pressure when an RF field generates a sufficiently high voltage potential for the gas in the gap between two electrodes to ionize and transition from an insulator to a conductor. This happens when the production of electrons in the intermediary gas exceeds the removal of electrons. The two main mechanisms are: Ionization Breakdown: Ionization by electron collision is the dominant electron production mechanism. Ionization of the gas by electron collision happens at higher ambient pressures when the electron mean free path becomes shorter than the electron separation distance. Multipaction: Multipaction, or secondary electron emission from the electrodes, occurs when the ambient pressure is sufficiently low that the electron mean free path is longer than the electron separation distance. Multipaction is observed at pressures below 10-2 Torr. As a result, damage can occur in the small gaps between conductive or dielectric surfaces which may result in serious degradation of hardware performance. To establish the available margins for safe operation of the hardware prior to spacecraft-level testing or launch, validate the RF power levels below which no damage will occur either in vacuum or at critical pressure. References Woo, R., \"Final Report on RF Voltage Breakdown in Coaxial Transmission Lines,\" NASA Technical Report No. 32-1500, October 1, 1970. Radiated Susceptibility System Verification, Reliability Preferred Practice No. PD-TE-1416.","Lesson ID":770}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1257; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Proper design of solid rocket motor case-to-case field joints reduces joint rotation and potential leakage during ignition and operation. With detailed dynamic loads analyses, thermal analyses, careful insulation design, and suitable quotoquot-ring sealing, the leakage of hot combustion gasses through field joints is eliminated. This prevents potentially catastrophic burning or melting of the solid rocket motor and adjacent metal components. Similar benefits are obtained by using improved design practices for case-to-nozzle joints and factory joints between case segments. Implementation Method: 1. Background The Challenger accident (Space Shuttle Flight #51L) which was caused by the escape of hot gasses from case-to-case field joints in the SRM, triggered an in-depth, detailed review of analytical, design, manufacturing, assembly, and testing methods for solid rocket motor field and factory assembly joints. The case-to-case field joint was the primary target of the investigations and subsequent redesign efforts. However, other joints in the motor such as the case-to-nozzle joint and the factory joint between motor segments were thoroughly investigated and redesigned when the investigation allowed for optimization of the noted configurations. Reliable joint performance was achieved by a detailed review of the design drives and by comprehensive analysis, test, and redesign processes. 2. Case-to-Case Field Joint Improvements Space Shuttle Redesigned Solid Rocket Motors (RSRMs) are made up of four segments in which propellant is cast in monolithic form. The four segments are connected by the field joint shown in cross-section on Figure 1. The case portion of each segment consists of two cylinders connected in the center by a factory joint. A dynamic launch and flight load analysis confirmed that the field joint design, which has been the main focus of attention, needed to be modified after the Challenger accident to incorporate several improvements. The most significant of these improvements was the addition of a quotcapturequot feature, which is essentially an added circumferential band that is incorporated as an integral part of the quottangquot on the male side of the three case-to-case field joints. This capture feature creates an interference fit with the inner clevis surface and restricts the movement of the tang away from the two quotoquot-rings on the internal leg of the field joints during initial motor pressurization. The capture feature also incorporates a third quotoquot-ring which potentially serves as a heat barrier to the combustion process, in event of anomalous insulation performance. In addition to the change in the metal parts, the configuration of the internal insulation interface between adjacent segments was changed to permit an interference fit between adjoining insulation elements. This insulation joint is bonded with a pressure sensitive adhesive around its full circumference, and aided in its contact during motor operation with a circumferential quotJquot shaped pressurizing slot in the tang insulation. With the addition of the capture feature and its quotoquot-ring, a second leak check port, which also serves as a vent during assembly and a means of positioning of the primary quotoquot-ring, was added in the redesigned joint. This ensured that a redundant seal existed in the new design. A quotV-2quot fluorocarbon filler material was placed at the clevis tip between the primary and tang quotoquot-rings to reduce the free volume of the joint and limit the quantity of hot gas that would enter the joint in the event of leakage of the quotJquot seal and capture feature quotoquot-ring. In the new design, the inner clevis leg surface is machined to provide a sealing surface for the capture feature quotoquot-ring. The compression of both the primary and secondary quotoquot-rings was increased by increasing the quotoquot-ring diameter by 0.010 inch from the pre-Challenger configuration, and the quotoquot-ring grooves were widened by 0.005 inch to prevent four wall contact by the quotoquot-ring. All sealing surfaces were smoothed to an average roughness of 63 micro inches (63 millionths of an inch). A chamfered clevis leg was provided to aid in the assembly process. Each field joint in the Redesigned Solid Rocket Motor is connected by pins (a cross sectional drawing of one of these pins appears on Figure 1). A key reliability enhancement feature is an increased-length pin with a circumferential pin retainer band. Each pin includes a hole which assists in assembly, and an opening with a dovetail cross-section to assist in pin extraction for refurbishment after flight. The increased pin length causes the dovetail to lie outboard at the outer clevis leg outside diameter. A stress analysis confirmed that this would reduce unit area shear stress on the pin because the dovetail is outside of the high shear area. This modification eliminated the potential for pin deformation. Custom shims were inserted between the inside surface of the outer clevis leg and the outside surface of the tang to maintain a constant gap between the two surfaces and to limit the growth of the metal-to-metal gap at the primary and secondary quotoquot-rings during pressurization. [D] 3. Case-to-Nozzle Joint Improvements Concurrent with the improvements in the case-to-case field joints, case-to-nozzle joints were also improved to obtain higher reliability and to achieve a more robust design. Changes to the insulation configuration, joint adhesive material, quotoquot-ring and quotoquot-ring groove configurations, and the nozzle attachment fasteners provide positive assurance of sealing. As in the instance of the insulation surrounding the case-to-case field joints, a pressurizing slot in the case insulation, coupled with a layer of sealant between the case and nozzle insulation, provides protection against combustion gasses reaching the nozzle or case metal parts. A circumferential slot is located in the case insulation near the interface between the case and nozzle insulation. A circumferential flow baffle is installed in this slot to prevent erosion of the insulation, and a stress-relieving radius former is included at the base of this slot to prevent cracking. To provide an additional margin for reliability, polysulfide adhesive material is used to bond the carbon phenolic nozzle insulation material to the asbestos\/silica-filled, nitrile butadiene rubber insulation in the rocket motor case. A wiper quotoquot-ring in the glass phenolic layer of the nozzle insulation and wiper vent slot in the rubber case insulation were incorporated to prevent entrapment of air in the case-to-nozzle joint during assembly, and to prevent the polysulfide adhesive from contaminating the primary quotoquot-ring. The wiper quotoquot-ring also provided the second of two barriers (the first is the polysulfide material in the insulation joint) to inhibit gas flow to the primary seal. Stress analysis studies and strength testing proved that radial bolts, as well as longitudinal bolts, were required to ensure an impenetrable seal between the nozzle and case metal parts under all environmental and motor performance conditions. Radial bolts ensure that sufficient compression of the primary quotoquot-ring is maintained to provide effective sealing. Increasing the diameter of the quotoquot-ring and redimensioning the quotoquot-ring groove to provide optimum quotoquot-ring squeeze while preventing quotoquot-ring entrapment were required reliability enhancement measures in the RSRM case-to-nozzle joint. 4. Factory Case-to-Case Joints Custom shims, widened quotoquot-ring grooves, slightly larger quotoquot-rings, increased pin length, and revised pin retainer bands were improvements made in the factory case-to-case joints. Because of the continuous insulation and propellant strata over the factory joints, special joint provisions were not required in the insulation. Clevis legs were chamfered and undercut at the leg tips for consistent final configurations after assembly. Technical Rationale: Based on detailed analyses of key design and manufacturing\/assembly drivers, the SRM case-to-case field joints have exhibited satisfactory performance in close to 100 solid rocket motors since the Challenger accident without evidence of hot propellant gas leakage through the insulation to the joint sealing system. The critical parameters associated with the case-to-case field joint, case-to-case factory joint, case-to-nozzle joint, and ignition system mounting joints continue to be closely monitored on a flight-to-flight basis to prevent the occurrence of undesirable hot gas transmission through any of the multiple seals provided. References 360L001 Acceptance Review: Morton Thiokol, Inc. Aerospace Group, Brigham City, Utah, March 14-15, 1988. Design Data Book (DDB) for Space Shuttle Redesigned Solid Rocket Motor (RSRM), Thiokol Corporation, Space Operations, November 1990. quotSpace Shuttle Solid Rocket Motor Program, Lessons Learned,quot AIAA Paper #91-2291-CP, A. A. McCool, George C. Marshall Space Flight Center, Alabama, 1991.","Lesson ID":759}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1422 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Careful attention to detail in ultrasonic testing can result in the identification of very small cracks, debonds, voids or inclusions in aerospace hardware that could be detrimental to mission performance. New ultrasonic technologies are enhancing the accuracy, speed, and cost-effectiveness of this method of nondestructive testing. Implementation: As schematically illustrated on Figures 1, 2, and 3 there are three principal methods of ultrasonic testing of aerospace materials: (1) the pulse-echo method; (2) the through-transmission method; and (3) the pitch-catch method. These three ultrasonic methods use pulses of energy during testing operations. These methods and their principal use in support of MSFC projects and technology programs are described below: 1. The pulse-echo method (Figure 1). In the pulse-echo method, a piezoelectric transducer with its longitudinal axis located perpendicular to and mounted on or near the surface of the test material is used to transmit and receive ultrasonic energy. The ultrasonic waves are reflected by the opposite face of the material or by discontinuities, layers, voids, or inclusions in the material, and received by the same transducer where the reflected energy is converted into an electrical signal. The electrical signal is computer processed for display on a video monitor or TV screen. The display can show the relative thickness of the material, depth into the material where flaws are located, and (with proper scanning hardware and software), where the flaws are located in the X-Y plane. In aerospace applications, the pulse-echo method is used primarily for the detection of flaws in metals, but has been used for first and second bondline interrogation in solid rocket motors (each transmitted\/received wave in Figure 1 represents a pulse of energy). [D] 2. The through-transmission method (Figure 2). In the through-transmission method, an ultrasonic transmitter is used on one side of the material while a detector is placed on the opposite side. Scanning of the material using this method will result in the location of defects, flaws, and inclusions in the X-Y plane. This method is used for nondestructive testing of multi-layered and multicomponent materials as encountered in solid rocket motor case\/insulation\/liner\/propellants, in composite materials, and on highly attenuative materials. (Each transmitted\/received wave in Figure 2 represents a pulse of energy.) [D] 3. The pitch-catch method (Figure 3). The pitch-catch method, in which the ultrasonic energy is transmitted at any angle to the surface of the material and received as reflected energy returning at the reflected angle, is used primarily for cylindrical tubes and other nonlinear parallel sided surfaces. The pitch-catch method can determine depths of the flaw in the material as well as detect the location in the X-Y plane through scanning. (Each transmitted\/received wave in Figure 3 represents a pulse of energy.) [D] All three methods are most effective on parallel sided surfaces, but techniques are being developed to inspect variable thickness materials or parts if and when the variation in thickness relative to the X-Y plane is known precisely. Precautions to be observed in ultrasonic testing include: (1) acoustical impedance matching of the sensors with the subject test material through the use of the correct coupling media; (2) use of air-coupling for moisture-sensitive materials; (3) resolution requirements needed to discriminate between adjacent anomalies; and (4) the use of electronic methods wherever possible to make corrections in distance inaccuracies encountered due to ultrasonic beam spreading; (5) characteristics of the transducer(s); and (6) the dependence of resolution on index, scan speed, repetition frequency, computer speed, etc., when using automated scanning. Water has been the best coupling media because of its ready availability, low viscosity, and its relatively safe use with most spacecraft construction materials. When immersion in water is not practical or desirable due to potential moisture absorption, material contamination, or part sizes and configurations, various forms of squirters bubblers have been devised to introduce a layer of water between the sensor and the material to serve as an acoustic coupler. In the pitch-catch method, a water-based gel has proven to be the most practical coupling agent. For solid propellant rocket motors, an elastomeric material similar to solid rocket propellant is used for acoustic coupling of sensors to the material during testing. Ultrasonic transmitters and receivers encased in a water jet nozzle have been used to provide continuous coupling during testing of large areas by continuously injecting a plane of water between the sensor and the material being tested. The most thoroughly researched application of ultrasonic testing at MSFC has been the detection of bond line failures between the case and insulation, the insulation and liner, and the liner and propellant. Ultrasonic waves can be focused at an oblique angle to establish the integrity of adhesive bonding. These oblique ultrasonic excitations cause standing waves in any unbonded areas which can then be detected by conventional ultrasonic methods. In this manner, weak or kissing bonds can be detected. NASA has had considerable success in detecting imperfections and debonds between the case or insulation and the liner, but work is continuing to develop reliable methods of detecting debonds at the second bondline between the liner and the propellant. In materials that have high attenuation impedance such as solid rocket propellants, relatively low ultrasonic frequencies (50kHz in an available ultrasonic range of 3kHz to 50MHz) are more effective than the high ultrasonic frequencies used for metals. Rapid strides are being made in information processing and display techniques which filter out extraneous acoustic signals and provide improved visual images of ultrasonic testing results. The pulse-echo method regularly reveals defects down to .047 inch in diameter. Through-transmission methods have been able to detect anomalies of .050 inch in diameter, which are far smaller than those which could detrimentally affect a solid rocket motor's performance. Ultrasonic capability to detect flaws depends on the wavelength (derived from the frequency and wave velocity). A general rule of thumb for the detection limit is: the smallest detectable flaw size is half the wavelength. The use of higher frequencies improves the sensitivity to small flaws, however there is an increase in the wave attenuation and the noise due to scattering from the material microstructure. Also, in any ultrasonic test there is a dead zone caused by the finite pulse length. This dead zone leads to the inability to detect flaws near the surfaces of the test materials. Ultrasonic testing personnel should be qualified and certified in accordance with MIL-STD-410E or SNT-TC-1A. Technical Rationale: Selection criteria for NDE techniques, specifically ultrasonic techniques, has been a subject of research by MSFC's Materials and Processes Laboratory for a number of years. These techniques have been verified by Thiokol Corporation, Martin Marietta, Aerojet, SAIC, The Naval Surface Warfare Center, and others. References Bray, Don E. and Don McBride: Nondestructive Testing Techniques, Chapter 11, Ultrasonic Testing of Aerospace Materials, John Wiley and Sons, New York, NY, 1992. Kutz, Myer: Mechanical Engineers' Handbook, Section 27.3; Ultrasonic Methods of Nondestructive Testing, John Wiley and Sons, New York, NY, 1986. Seydel, James, A. and Julian R. Frederick.: A Computer-Processed Pulse-Echo NDT System, Materials Evaluation, November 1973. Whaley, H.L. et. al.: Applications of Frequency Analysis in Ultrasonic Testing, Materials Analysis, January 1975. Smith, A.C. and H. Yang: Ultrasonic Study of Adhesive Bond Quality at a Steel-to-Rubber Interface by Using Quadrature Phase Detection Techniques, Materials Evaluation, December 1989. Green, R. E.: Ultrasonic Testing, Nondestructive Testing Handbook, Volume 7, American Society for Nondestructive Testing, Columbus, OH, 1991. Metals Handbook, Volume 17: Nondestructive Inspection and Quality Control, pp. 231-277, ASM International, Metals Park, OH, 1989. MIL-STD-410E: Nondestructive Testing Personnel Qualification and Certification, Military Standard, January 1991. SNT-TC-1A: Recommended Practice, Personnel Qualification and Certification in Nondestructive Testing, American Society for Nondestructive Testing, Columbus, OH, 1988.","Lesson ID":765}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1421 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Eddy Current Testing (ECT) is a fast, reliable, and cost effective nondestructive testing (NDT) method for inspecting round, flat, and irregularly shaped conductive materials. Specific processes have been developed to determine the usability and integrity of threaded fasteners. In addition, ECT has the capability of being automated. With proper equipment and skilled test technicians readout is instantaneous. Implementation: Alternating Current (AC) flowing through a coil produces an alternating magnetic field about the coil. When the coil is positioned near to, or placed on, material that is capable of conducting electrical current, the magnetic field passes into the material and circular (eddy) currents are induced in the material near the coil. The flow of eddy currents in the material causes the excitation of a fluctuating magnetic field of its own. This magnetic field is always in opposition to the coil's magnetic field as illustrated in Figure 1. When the coil is placed on conductive material, the strength of the coil's magnetic field is reduced. This change in the magnetic field causes a change in the impedance of the coil, which causes a change in the current flowing through the coil. These changes are detected by an instrument placed in the circuit. [D] The flow of eddy current within the material is disrupted by the presence of discontinuities, such as, cracks, porosity, or inclusions. Discontinuities cause a decrease in the flow of current in the material by increasing the length of the path along which the current must flow as shown in Figure 2. This results in a reduction of current flow which causes a change in the impedance of the test probe coil. [D] There are three major factors that affect ECT. These are material conductivity, geometry, and permeability of the material being tested. In addition, there are contributors that affect the three major factors. These are shown in Table 1. Table 1. Factors Affecting Eddy Current Testing Conductivity Geometry Permeability Alloy Hardness Temperatur Residual stress Coatings Thickness Discontinuities Coil-to-Material Seperation (liftoff) Ferromagnetic* * Material capable of being magnetized The ECT signal is strongly related to the geometrical shape of the coil, i.e., the size, shape, and positioning of the coil; the relationship between the coil windings and suspected discontinuities; the effect of changes in liftoff or fill factors; the depth of penetration; and the edge effect. Identifying the various factors causing impedance changes depends upon the knowledge and skill of the ECT technician. Thus, selecting the appropriate eddy current probe is an important part of eddy current testing. Various types of test instruments available for ECT are: 1) conductivity testers, 2) crack detectors, 3) resistance and reactance measuring testers, 4) coating thickness testers, and 5) oscilloscopes and output devices such as strip chart recorders, printers, etc. when used as part of a test setup. A standard test specimen with known flaw sizes must be fabricated for use in adjusting the sensitivity setting of the test instrument for accurate interpretation of the test results. The standard test sample should be sound and of the same alloy, temper, and geometry as the part to be tested. Flaws may be produced in the standard test specimen by drilling, electrical discharge machining, milling, or any other means that will not distort the standard. Any flaw size outside the predetermined acceptable flaw size for the object being tested shall be a noted defect for corrective action or rejection. Table 2 lists advantages and disadvantages to be considered when selecting ECT. The most important elements required to maximize successful eddy current operations are dedicated personnel, training, proper equipment, and adequate standards. Also, at reasonable time intervals during ECT, routine checks should be made with the standard test specimen to insure equipment is operating properly. Table 2. Advantages and Limitations of Eddy Current Testing (ECT) Advantages Limitations 1. High speed testing (can be automated) 2. Accurate measuring of conductivity 3. Discontinuities at or near surface can be reliably detected 4. High-sensitivity to small discontinuities 5. Accurate coating thickness measurements 6. Direct Go\/No Go answers can be quickly obtained 7. No physical contact required 8. Low cost 9. Portable 1. Limited penetration into test article 2. Several variables simultaneously affect output indication 3. Discontinuities are qualitative not quantitative indications 4. Material must be conductive 5. Requires skill when many variables are involved 6. False indications can result from edge effects and parts geometry ECT is useful in the areas of material heat treat determination, coating thickness measurements, and flaw detection. A list of typical applications is shown in Table 3. Table 3. Typical Applications of Eddy Current Testing Material Property Determinations Thickness Measurements Flaw Detection Heat treatment evaluations Hardness Fire damage Impurities Chemical compositions Corrosion damage Conductivity of ionized gas Thin sheet metal Foil Paints Anodic coatings Lacquers Thin insulation Rocket motor linings Sheet metal Foil Wire Bars Tubes Bolt holes Fasteners Welds Ball bearings Technical Rationale: For the past ten years, eddy current testing has been a necessary tool at MSFC for the inspection of bolts, (heads, grip length, and threads), nuts, and holes for defects. Standards are fabricated as required and special adapters have been fabricated which allows the probe (coil) to be positioned at the correct angle and distance from surface. ECT is a fast, accurate, and highly reliable method for determining defects in surface and near surface areas of aerospace materials. References MIL-HDBK-728\/2: quotMilitary Handbook Eddy Current Testing,quot December 1985. MIL-HDBK-727\/1: quotMilitary Handbook Nondestructive Testing,quot December 1985. Bray, Don E., and Don McBride: quotNondestructive Testing Techniques,quot John Wiley & Sons, Inc., 1992. CT-6-5: quotNondestructive Testing Eddy Current,quot Classroom Training Handbook, Second Edition, Convair Division of General Dynamics, 1979. PT-4-5: quotNondestructive Testing, Eddy Current Testing,quot Programmed Instruction Handbook, Convair Division of General Dynamics, San Diego, CA, 1967. Bray, Don E., and Roderick Stanley: quotNondestructive Evaluation,quot McGraw-Hill, Inc., 1989. Kutz, Myer: quotMechanical Engineers Handbook,quot John Wiley & Sons, Inc., 1986. ASTM E426-92: quotStandard Practice for Electromagnetic (Eddy Current) Examination of Seamless and Welded Tubular Products, Austenitic Stainless Steel and Similar Alloys.quot Birnbaum, George, and George Free: quotEddy Current Characterization of Materials and Structures,quot ASTM Special Technical Publication 722, American Society for Testing and Materials, 1916 Race Street, Philadelphia, PA, 19103, September 1979. McMaster, R.C., P. McIntire, and M. L. Mester: quotNondestructive Testing Handbook,quot Second Edition, American Society for Nondestructive Testing, Inc., 1986. Metals Handbook, Volume 1: quotNondestructive Inspection and Quality Controlquot ASM International Metals, Park, OH, 1989.","Lesson ID":760}
{"Driving Event":"Upon arrival at Mars in September 1999, the Mars Climate Orbiter (MCO) began a scheduled 16-minute Mars orbit insertion (MOI) maneuver to achieve orbit. Approximately 49 seconds before the anticipated occultation by Mars, communication was lost and never reestablished. The root cause of the mission loss was an error in the \"Sm_forces\" program output files. The JPL MCO review board determined that the files containing the magnitudes of the small impulses applied to the spacecraft had been delivered by the Spacecraft Operations Team to the Spacecraft Navigation Team in English units (pounds-force seconds) instead of the specified metric units (Newton-seconds). See Lesson No. 0641, first paragraph under Lesson Learned The discrepancy in these files led to an underestimate (by a factor of at least 4) of the influence of the twice-a-day momentum wheel desaturation burns on the spacecraft trajectory. The cumulative effect of these small impulses led to a 169 km navigation disparity, which was catastrophic to the mission. The erroneous engineering units provided by these files to the navigation software were not discovered in the walkthroughs of requirements, design, code, and testing. Contrary to preferred practice: The \"Sm_forces\" software was misclassified as non-mission critical, which reduced the rigor of the review program. The Software Management and Development Plan (SMDP) was not followed in the walkthroughs of the \"Sm_forces\" software, and the overall training in the software walkthrough process was not adequate. Specifically, required persons were not always in attendance, the Software Interface Specification (SIS) was not used, minutes were not taken, and action items were not published. An (end-user) navigation representative was not specifically requested to be present at any of the major development phase reviews, software walkthroughs, or the software acceptance test. The \"Sm_forces\" software interface with navigation software was not tested. There was no flowdown of requirements from the higher-level MCO SIS to the software requirements document. The \"Sm_forces\" requirements specification did not state the required engineering units for parameters. References: Report on the Loss of the Mars Climate Orbiter Mission, JPL D-18441, JPL Special Review Board, November 11, 1999. Phase I Report, (NASA) Mars Climate Orbiter Mishap Investigation Board, November 10, 1999. \"Mars Climate Orbiter Mishap Investigation Board - Phase I Report\", Lesson Learned Number 0641, December 1, 1999. Corrective Action Notice No. Z66254, MCO-JPL\/SRB Finding 4.2: \"Software Development Process,\" November 23, 1999.","Lesson ID":740}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PD-ED-1266, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Benefit: Improved ruggedness, reduced size, and greater opportunity for redundancy are the potential benefits of using binary and hybrid optical systems for space applications. Hybrid optical systems can be designed that are less sensitive to color (or chromatic variations) and to temperature variations. When combined with conventional optics, binary optical systems can correct for spherical aberrations. Implementation Method: Binary Optics: Binary (diffractive) optics uses computer-aided design (CAD) tools and very-large-scale-integration (VLSI) electronic circuit manufacturing technology to create novel optical devices and to provide design freedom and new materials choices for optical elements. When combined with conventional (refractive) optical lens systems, binary optical systems cannot only provide athermalization and achromatization, but offer the opportunity for miniaturization, significant weight savings, and resulting opportunity for redundancy in aerospace telescope systems, sensors, vision systems, and microelectronic optical systems. While conventional optics lenses are polished to a desired profile, binary optics uses high resolution lithography (the design and replication process used in electronic circuit fabrication) to transfer a binary surface relief pattern to the optical element. This pattern is then etched into a surface using ion-beam etchers. A single etching step produces a two-level surface, thus the term i\u0300binary optics.i\u0302 The etching process can be repeated with different etch depths to produce multi-level optical elements. A binary coded set of lithographic masks can double the number of phase levels with each etching step. For example, four etching steps result in a 16-level optical element with a theoretical diffraction efficiency of better than 99 percent. The etch profile approximates a continuous phase surface. Hybrid Optics: Hybrid diffractive\/refractive lenses are being considered for NASAi\u0301s Geostationary Earth Observatory (GEO) to reduce weight and increase reliability of its sensors, telescopes and imaging systems. Hybrid lenses can be built that weigh less than half of conventional lenses, offering the possibility of providing redundant systems. Since the color separation properties of binary optic lenses are opposite in sign to those of a traditional lens, achromatic, lenses can be constructed using combined diffractive\/refractive elements. Certain optical materials, particularly plastics and infrared materials, have optical and mechanical properties that may cause decreased performance over a wide temperature range. For space applications, the unique properties of diffractive lenses offer significant advantages in this regard when used in combination with traditional refractive or reflective systems. Temperature compensation may also be achieved in an optical system mounted in a housing that is subject to expansion or contraction in various thermal environments. It is possible to design an element that contains both refractive and diffractive surfaces such that the change in focal length with increasing or decreasing temperature is equal to the change in position of the image detector in relation to the lens. Optical technicians have developed an opto-thermal expansion coefficient that is used to design athermalized lenses that combine refractive and diffractive surfaces. Opto-Electronics: Since binary optics are fabricated using the same equipment and techniques used to make semiconductor chips, the next step is to fabricate binary optics into the chips themselves, which results in opto-electronic assemblies with built-in processing functions. Micro-optic lens arrays can be integrated with semiconductor detector arrays to produce compact, lightweight, rugged, integrated imaging\/detector systems. If the system is spaceborne, radiation resistance can be improved, since each smaller active detector element now presents less cross sectional area for gamma ray interactions. Technical Rationale: Binary and hybrid optics have created a revolution in the way lenses, and ultimately, opto-electronic systems are designed and manufactured. Hybrid optics combines the best features of diffractive and refractive optics technology. Many highly reliable types of hybrid lenses, filters, multiplexers, and diffractive coatings have recently become feasible. By applying a mixed optics approach to system design and fabrication, the number of series elements in a complex system can often be halved, improving reliability. The lower weight of the systems, in addition, offer the opportunity of increased redundancy through the use of multiple backup systems. Further evidence of the usefulness of these technologies should become evident as they are put into practice. References: Behrmann, Greg: \"Influence of Temperature on Diffractive Lens Performance,\" Applied Optics, May 1993. Behrmann, Greg: \"A Hybrid Approach Opens the Door to Diffractive Optics,\" Photonics Spectra, May 1993. Morris, G. Michael: \"Diffractive and Binary Optics,\" University of Rochester, Rochester, NY, January 1994. Morris, G. Michael: \"Diffractive Optics Technology and the NASA Geostationary Earth Observatory (GEO),\" Rochester Photonics Corporation, Fairport, NY, July 31, 1992. Veldkamp, W.B.: \"Binary Optics: A New Approach to Optical Design and Fabrication,\" Optics News, December 1988.","Lesson ID":751}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1263; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Controlling contamination of space optical systems limits the amount of particulate and molecular contamination which could cause performance degradation. Contamination causes diminished optical throughput, creates off-axis radiation scattering due to particle clouds, and increases mirror scattering. Controlling molecular contaminates minimizes performance degradation caused by the deposition of molecular contaminants on mirrors, optical sensors and critical surfaces; improves cost-effectiveness of mission results; and improves reliability. Implementation Method: Contamination control of space optical systems consists of the planning, organization, and implementation of all activities needed to determine, achieve, and maintain the required cleanliness level of the optical system. Each optical system has its own unique contamination control requirements. To effectively control contamination, concurrent engineering procedures should be employed during design, manufacturing, precleaning, assembly, testing\/checkout, transportation, storage, launch and on-orbit operations. The desired level of cleanliness, established during the design phase, determines the techniques required to accomplish the desired results. These steps should be documented in a contamination control plan which can be developed by utilizing the following steps: Determine degree of cleanliness required. Prepare design with optimum materials, configuration, and tolerances to help accomplish the desired cleanliness level. Select and train personnel in contamination control techniques. Select and use the proper materials, equipment, and processes to accomplish the desired end result. Implement contamination budgeting and monitoring throughout each program phase. Plan the product flow to minimize the chance of recontamination after cleaning. Select qualified personnel and equipment to monitor the cleaning processes. The major sources of particulate contamination are: Airborne particulates settling on hardware surfaces during manufacturing, assembling, and testing operations. Paint overspray, insulation shreds, clothing fibers, and other human-induced substances. Trapped particles on internal surfaces of subassemblies and in other hardware crevices. These are released and redispersed from acoustic vibration, transportation, and launch. Reaction control system (RCS) or main propulsion system plume exhaust and flash evaporator water release that may create residual cloud environments. The major sources of molecular contamination are: Manufacturing residues (machine and cutting oils) which result from fabrication of hardware. Material outgassing. Space vehicle surface outgassing during ascent, deployment, and retrieval operations. Ground and air transportation environments. Volatile condensable materials in the environment to which contamination-sensitive, critical surfaces may be exposed during assembly operations. Return flux of outgassed molecules due to collisions with residual atmospheric molecules. Propulsion system plume impingements causing deposition of nonvolatile substances (MMH-Nitrate) on optical surfaces. Oxidation through exposure to atomic oxygen present in low-earth orbit. A contamination control engineer should be assigned the responsibility for coordinating contamination control requirements. This person should not only interface with the systems engineers, but with the engineers and technicians responsible for design, materials, manufacturing, testing, checkout, facilities, and quality assurance. The contamination control engineer's responsibilities should include: 1) contamination control coordination, planning, and budgeting; 2) coordination of materials selection and testing; 3) participation in design reviews; 4) preparation of detailed contamination control requirements; 5) review and sign-off of engineering drawings, specifications, and procedures; and 6) monitoring with witness samples to meet budgeting allocations throughout each program phase. The contamination engineer and the quality assurance engineer should establish contamination control procedures for the assembly and test facilities. Monitoring of the facilities should be performed by quality assurance personnel. To avoid contamination of the optical critical surfaces, contamination control should be a foremost consideration in the design. Contamination sources can be minimized in the design by careful selection and testing of materials, coatings, and processes. Purging the optical system with clean, dry nitrogen during time the system is not in a clean environment (i.e., storage, transportation, idle times during test, etc.) is an effective method of controlling contamination. The selection and testing of organic materials should be accomplished per MSFC-SPEC-1443 (ref. 6). Clean room assembly areas should be maintained to class 10,000 and clean benches to class 100 per MSFC-STD-246. After fabrication, all parts should be cleaned, outgassed per established procedures, doubled-bagged using approved material and sealing methods, and placed in bonded storage. Electronic assemblies should be assembled in a separate class 10,000 or better clean environment and double bagged. Mechanical assemblies should be assembled in a separate class 10,000 or better clean environment. Electronic assemblies, mechanic assemblies, and structural subassemblies should remain double-bagged until brought into final assembly clean area. Structural assemblies and optical instrument assemblies should be assembled in a closely-monitored and controlled class 10,000 clean room. All required personnel required for assembly must be trained for work in a clean room environment. After assembly, optical instruments should be double-bagged for purging with dry nitrogen to help maintain cleanliness. The final assembly should be tested in at least a class 100,000 clean area. Optics should be protected when they are exposed during the test and monitored with witness samples which should be checked after the test. After testing, the optical instrument is double-bagged and prepared for purging with dry nitrogen during storage or shipping to the launch site. Measurement, Tracking, and Control The following training in precision cleaning should be provided to personnel required to enter a clean room: clean room maintenance, hardware handling, and clean room operational procedures and principles. The optical system and clean room should be monitored and measurements recorded using automatic particle counters, total hydrocarbon analyzers, temperature\/relative humidity measurements, and pressure fallout sampling of particulate and molecular contaminants. These measurements should be tracked against the contamination budgeting plan. Fallout sampling is usually checked with optical witness samples that are strategically placed throughout the clean room and optical system. During the monitoring for contamination of the clean room and optical system, any contamination control discrepancy should be resolved with the contamination control engineer to determine the impact on the optical system. This impact will be weighed against the contamination budget and should be dispositioned by the materials review board. Technical Rationale: Contamination control is vital in aerospace optical systems to maintain high reliability and clarity of images. Ground and space contamination prevention, detection, and control are essential for the high-resolution space optical systems now in development or planned. In-depth studies have shown that contamination avoidance is feasible and enhances mission success. References SPIE 967: \"Stray Light and Contamination in Optical Systems.\" The International Society for Optical Engineering, Proceedings 17-19, August 1988. SPIE 1329: \"Optical System Contamination Effects, Measurement, Control II.\" The International Society for Optical Engineering Proceedings, July 10-12, 1990. SPIE 1754: \"Optical System Contamination Effects, Measurement, Control III.\" The International Society for Optical Engineering, Proceedings, July 23-24, 1992. SPIE 777: \"Optical System Contamination Effects, Measurement, Control.\" The International Society of Optical Engineering Proceedings, May 19-22, 1987. NASA SP-5076: \"Contamination Control Handbook.\" Technology Utilization Division, Office of Technology Utilization, NASA, 1969. MSFC-SPEC-1443: \"Outgassing Test for Non-Metallic Materials Associated with Sensitive Optical Surfaces in a Space Environment.\" Materials and Processes Laboratory, Marshall Space Flight Center, December 3, 1987. MSFC-SPEC-2223: \"Outgassing Test for Materials Associated with Sensitive Surfaces Used in an Ambient Environment.\" Materials and Processes Laboratory, Marshall Space Flight Center, May 17, 1993. MSFC-STD-246: \"Standard Design and Operational Criteria for Controlled Environmental Areas.\" Rev. B, Marshall Space Flight Center, NASA, March 1992. SP-R-0022A: \"General Specification Vacuum Stability Requirements of Polymeric Material for Spacecraft Application.\" Johnson Space Center, NASA, September 9, 1974. PA 01: \"Space Telescope Project, Wide Field Planetary Camera Cleanliness and Control Plan.\" Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, May 16, 1978. CON 218: \"Passive Contamination Control Monitoring Plan for the Hubble Space Telescope During Transportation through Launch.\" Lockheed Missiles and Space Company, Inc. Engineering Memorandum, July 14, 1985. MSFC-RQMT-691.8A: \"Space Telescope On-Orbit Maintenance Mission Contamination Control Requirements.\" Space Telescope Systems Integration Branch, Marshall Space Flight Center, July 1984. K-DPM-11.96.1: \"Contamination Control Implementation Plan for Hubble Space Telescope Maintenance and Refurbishment (HST M&R).\" Kennedy Space Center, September 1987. FED-STD-209: \"Clean Room and Work Station Requirements Controlled Environments.\" MIL-STD-1246: \"Product Cleanliness Levels and Contamination Control Program.\" LMSC\/D975220D: \"Hubble Space Telescope Maintenance and Refurbishment Contamination Control Master Plan.\" Lockheed Missiles and Space Company, Inc. June 30, 1988. LMSC4176437D: \"Hubble Space Telescope Contamination Control Program Plan.\" Lockheed Missiles and Space Company, Inc., January 30, 1987. LMSC\/F157834: \"Contamination Control Implementation Plan for HST Rework and Storage.\" Lockheed Missiles and Space Company, Inc., November 1, 1986. 52100.200.90.0039: \"Advanced X-Ray Astrophysics Facility, VETA-1 Contamination Control Plan.\" TRW Space and Technology Group, Redondo Beach, CA, June 1, 1990. Reliability Preferred Practice PD-ED-1241, \"Contamination Budgeting of Space Optical Systems.\" Reliability Preferred Practice PD-ED-1233, \"Contamination Control Program.\"","Lesson ID":754}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1231; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Experience learned from the Atlas\/Centaur and Space Shuttle flights serve to emphasize the importance of the implementation of the proper protection\/design enhancements to avoid and survive natural or triggered lightning for all launches. Implementation Method: Due to the lightning strike incident on Apollo 12, the AC-67 failure, and the numerous lightning strikes to the shuttle launch complex at 39-B, significant changes were made to improve electromagnetic compatibility (EMC) of launch vehicles and ground support equipment. The EMC approach is essentially the same for all of these vehicles with special considerations given to specific payload and launch requirements. The Atlas\/Centaur and the Shuttle protection design are described in Reference 2. The major areas that a designer needs to address for lightning and transient hardening are: proper grounding of vehicle and ground support equipment, bonding requirements, and circuit protection. This is accomplished primarily through wire shielding and secondarily through transient limiters. Following the detailed requirements will limit the damage inflicted by lightning or high current transients. Ground Support Equipment The Launch System Fixed Service Structure (FSS) stands considerably taller than the airborne vehicle, creating a 45 degree quotcone of protectionquot relative to the vehicle (as illustrated in Figure 1). The probability of a lightning strike is a function of the design of the cone and the location of the object within the cone. The tower itself acts as a low impedance down conductor. [D] Figure 1. Shuttle Vehicle Complex Lightning Protection The ground support equipment (umbilical tower, service tower, etc.) must contain the appropriate conductive paths for lightning currents. These structures should follow the code in the quotU.S. Lightning Protection Code (NFPA-78)quot. The reason these requirements are placed on the structure is to avoid large potential differences between the lightning conductor and ground support equipment within the tower. All equipment susceptible to high current must be sufficiently grounded and bonded. Critical circuits are normally protected with transient limiters. All cable harnesses should have an overshield, which is grounded on both ends. Also, to protect against induced electromagnetic transients circuit wire twisting should be implemented. All wires and components connecting ground support equipment with payloads should be appropriately grounded. Circuits or components which interface with the vehicle should be hardened against lightning transients and electromagnetic interference. The following lists the recommended practices for circuit protection: a) Lightning suppression devices and appropriate mechanisms should be placed at areas of critical circuit interfaces and in current loop areas where potential differences can be substantial during direct and induced lightning strikes. Such areas would be the inertial navigation unit (INU) uplink and data acquisition system (DAS) downlink circuit interfaces and telemetry connections. b) Individual equipment should be grounded to facility structure when ground support equipment is installed. c) Items subjected to transient charging must meet MIL-B-5087 (Class S) bonding requirements. Components should be connected to the tower facility grid. d) Heavy gauge grounding cables should be instituted to ground external items to major structural members. e) Auxiliary grounding straps should be employed, as needed, to relieve differences in potential for items being mated and demated. Airborne Vehicle Equipment Airborne vehicle equipment consist of the launch vehicle and the payload (satellites, experiments, etc.). Since lightning will predominately strike the nose or fairing of a rocket, the equipment contained there should be shielded to withstand the current and induced effects. To protect the vehicle and components, several lines of defense are used starting with the vehiclei\u0301s structure, bonding requirements, and cable shielding. In order to protect the internal equipment, a large conductive surface must extend the length of the vehicle. This is easily resolved by constructing an all metal surface vehicle with adequate bonding between the stages. With composite skin vehicles, a cable raceway is needed to extend the entire length of the vehicle, and conductive paint should be used on the skin. All memory sensitive devices should be EMI hardened and placed far from the raceway. The purpose of overall airborne system bonding is to maintain an equipotential system (see Figure 2). To ensure this all tank sections should be welded and bonded to achieve a low impedance reference plane. All metallic parts of linear length greater then 12 inches should have a discharge path to structure. In launch vehicles all critical areas must follow MIL-B-5087B (Class R) or NSTS 07636 bonding to satisfy NASA bonding requirements. The bonding of all electrical components (connections, metallic plumbing, etc.) is mandatory to achieve an equipotential environment. This is important in areas where large current loops might be formed (see Figure 2) or on the vehicle where critical electrical components are found. All areas should follow the MIL-B-5087B (Class S & R) or NSTS 07636 requirements for electrical bonding. The designer should also note that adequate cross-sectional area and skin area must be taken into account when applying the bonding requirements. All connection surfaces must be free from insulation material and foreign material such as, paint, oxide, and corrosion. It is also important to reduce sharp bends in conductors. Sharp bends cause high conductor separation forces and are areas of high impedances to the leading edge of the current pulse; more importantly, they are potential arcing points. [D] Figure 2. Example of Ground Plane Bonding on the Atlas\/Centaur Shielding guidelines were established after the critical failure of AC-67. In order to reduce magnetic induced voltages in cable wires, it is possible to design cables such that the induced voltages can be self-cancelling. This is completed through twisted-pair wiring enclosed by a copper braid shield. The following shielding list can be applied to all launch vehicles. a.) Power and Low Frequency. Twist the power or signal wire\/wires with its return line. This should be referenced to the vehicle structure on both ends. Any power lines leading to inductive loads that are not locally diode suppressed should be shielded with the shield grounded on both ends. Do not shield power leads between power supply and a subsystem, or between units of a subsystem. b.) Radio Frequency Circuit Shielding. RF circuits or circuits susceptible to RF should have the outerbraid of the coaxial cable grounded at both ends and all points along the length of the shield as necessary. c.) Digital Data Lines. Use a shielded twisted pair with the shield being grounded at both ends. d.) Ordnance Circuit Shielding. Twisted shielded wire should be used from electroexplosive devices to the ordnance power switching device. The shields should be grounded at both ends. e.) Memory Device Shielding . Due to the difficulty in predicting the shield attenuation on at metallic structural corners, an adequate safety margin should be used for protection against excessive interior flux. f.) Rules for Circuit Shielding. Circuits with impedances greater than 100 ohms or are sensitive to high frequency must have the twisted pairs shielded. All circuit shields should be grounded to structure at both ends of the circuit via the connector backshell. g.) Harness Shielding. All cable or harness shields must be terminated at both ends of a conductive EMI backshell. The 360 degree peripheral shield termination technique should be applied. In order to reduce the amount of induced effects caused by lightning, it is important that the electrical wiring follow the requirements for shielding. This will limit the possibility of quotnoisequot throughout the system or quotcircuit upsetquot. The designer should also consider the possibility of using fiber-optic cables, thus eliminating the susceptibility to the electromagnetic effects of lightning. This can be applied in the areas for control, data, and transmission lines. Structural Design Provisions. In addition to hardening the electrical system, structural designs should avoid susceptibility to triboelectric or frictional charging. Fairings should be of an all metal stringer construction. This encases the inertial navigation unit and all electrical components in a Faraday cage enclosure (Ref.4 &5). Technical Rationale: All ground station equipment and airborne vehicle equipment should be hardened against lightning transients and electromagnetic interference. When lightning strikes an object, current flows and voltages are produced across impedances. The voltage becomes large if the impedance is high, and thus produces substantial arcing. This occurred on AC-67 during flight resulting in a improper yaw command and destruction of vehicle and payload. Arcing and circuit upset can even occur if lightning does not strike directly, but discharges nearby producing a high magnetic flux which will induce a current in the electrical components. This was observed while AC-43 was on the launch pad resulting in several components experiencing circuit upset. As a result of these modifications and improvements, the flight history of Atlas II has not been affected by lightning transients or electromagnetic interference (EMI). Compliance with transient and bonding requirements, harness shield termination improvements incorporated throughout the system will provide the necessary immunity to any lightning-induced effects at the unit\/subsystem level. References: Atlas\/Centaur AC-67, quotProblem Report Closeout,quot No. AK44901 CT, General Dynamics Space Systems Division, 1987. AFSC DH 1-4, quotElectromagnetic Compatibility,quot4th ed., March 1984. Gabrielson, Bruce C., The Aerospace Engineeri\u0301s Handbook of Lightning Protection, Interference Control Technologies, Inc., Gainesville, VA, 1988. Hasbrouck, R.T. , Lightning-Understanding It and Protecting Systems from Its Effects, Lawrence Livermore National Laboratory, 1989, UCRL-53925. Hart, William C. & Malone, Edgar W., Lightning and Lightning Protection, Don White Consultants, Inc., Gainesville, VA, 1979. KSC-STD-E-0013, quotFacility Lightning Protection Design Standardquot. MIL-B-5087B, quotBonding, Electrical, and Lightning Protection, for Aerospace Systems,quot October, 1964. NSTS 07636, quotSpace Shuttle: Lightning Protection, Test and Analysis Requirements,quotNovember 1991. NSTS 16007, Revision F, quotLaunch Commit Criteria and Background,quot NASA, 1992. quotReport of Atlas\/Centaur-67\/FLTSATCOM F-6 Investigation Board Vol. I-Final Report,quot NASA, July 15, 1987. NFPA-78, quotU.S. Lightning Protection Codequot. Fisher, F.A. & Plummer, J.A., Lightning Protection of Aircraft, Lightning Technologies, Inc. SL-E-0002, quotNSTS EMI Characteristics, Requirements For Equipmentquot. Electrical Shielding of Power, Signal and Control Cables - Reliability Preferred Practice No. PD-ED-1213 Electrical Grounding Practices for Aerospace Hardware - Reliability Preferred Practice No. PD-ED-1214","Lesson ID":739}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PD-ED-1267, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Benefit: The benefits of using special design and test procedures for aerospace check valves are long life, consistent operation, and trouble-free performance during prelaunch, launch, and orbital operations. Implementation Method: Introduction: Aerospace check valves allow fluid flow of propellants and gasses in one direction and, if the system pressure reverses, close quickly to prevent flow in the opposite direction. Aerospace check valves are normally self-contained, spring loaded devices, requiring no external actuation signals or sources of power. The valving elements are activated by the pressure forces of the flow media. Ball type check valves are suitable for smaller applications, while poppet type valves are more appropriate for large flows, such as in the Space Shuttle Main Engine (SSME) application shown on Figure 1. Internal check valve leakage due to contamination is the main reliability detractor for both types of valve, although other failure modes such as external leakage, failure of the poppet or ball to open, and poppet or ball chatter are other potential failure modes. Highly reliable check valves have been designed, built, installed, and operated for extended periods in launch vehicle and propulsion applications with no detrimental in-flight failures. [D] Figure 1. SSME Purge Check Valve Design Practices: Successful design practices have evolved that have resulted in failure-free aerospace check valve configurations. Large flow paths are provided through poppet-type check valves to reduce flow velocities and erosion of seats. Figure 1 is a cutaway view of the SSME purge check valve, a typical check valved used in aerospace applications. Teflon sleeves are provided for smooth operation and quick opening and closing of the poppets to permit rapid response to pressure differentials. Valve housings are configured to avoid areas that can trap contaminants. quotSwept-byquot designs are employed where the fluid flow tends to pass contaminants through the valve. Material compatibility with the working fluid is an important design consideration. The material evaluation includes dynamic as well as static implications, and considers temperature, pressure, and phase variations of the fluid. To minimize valve-induced contamination, material selection includes consideration of wear particle size on useful life. (Particle sizes vary as the Youngi\u0301s Modulus divided by the square of the compressive yield stress.) Where threaded connectors are used, rolled threads are used in preference to machined threads to minimize burrs and to achieve higher strength. Pipe threads are avoided, and the check valve should have female threads to avoid thread damage. Dead-end passages and capillary passages are avoided. All materials and tolerances must be examined to account for material properties after exposure to fluids and contaminants. Testing should include exposure to fluids and contaminants in the failure mode operation. Materials compatibility testing is particularly important for check valves used to isolate bipropellant tanks of hypergolic systems where the valves can be exposed to both oxidizers and fuel vapors and their byproducts. Teflon in particular swells after exposure to nitrogen tetroxide vapor or liquid and adequate clearance must be provided in the valve after swelling to prevent binding of moving parts. Aerospace check valves work best in a contamination-free system, but where contamination is likely to be present, internal leakage due to contamination is minimized if the spring force is matched with material softness to ensure compression and closure. Self-aligning poppets or balls are desirable in most instances. System contaminants are identified to determine particle size and material properties. Metal-to-metal sliding parts are avoided as they not only are prone to produce contamination, but can also entrap externally induced contamination. Valving elements are designed with quick-opening areas to preclude chattering, flow instability, and high fluid velocities around the valve seat. Guidance of the poppet onto the valve seat to allow for a maximum alignment and eccentricity tolerance is achieved by providing a large diameter guide bearing surface length to poppet diameter ratio. (Minimum ratio should be 2:1). A finish of 16 or 32 microns root-mean-square is recommended. Positive stops are provided at the end of travel to minimize transient stresses due to poppet travel. Leakage rates are minimized by lapping poppet and seal surfaces to produce very smooth finishes. Reduced life due to vibration sensitivity is minimized by decreasing available clearances in bearings and guides, avoiding large overhung moments, and restricting lateral motion of poppets. Stress corrosion is controlled by avoiding stress corrosion susceptible materials and by designing the parts to operate at low stress levels. External leakage is minimized or eliminated by using welded valve body construction, requiring the use of vacuum-melt bar stock material, and by impregnating valve body castings with sealants. Process and Control Practices: Aerospace check valve parts are ultrasonically cleaned, assembled in specified clean areas, and controlled by a single contamination control specification during manufacturing, assembly, and testing. Test fluid media is governed by this same contamination control specification. Fabrication barriers (bags) are used to protect clean parts. Vendor controls are used to warrant that contamination particle size and count will not exceed specified limits. In some instances, a continuous purge of dry Helium is needed on the downstream side of check valves for cryogenic applications to prevent freezing of water vapor or atmospheric Nitrogen on the downstream sealing surface. Testing Practices: Contamination susceptibility tests are conducted during development to determine the levels of contaminant that the check-valve can tolerate. Verification of valve operation is achieved through 50 to 100 run-in cycles. Rapidly cycling valves designed for liquid applications for functional verification is not done in a dry condition because the lack of fluid damping can increase seat stress and reduce check-valve lifetime. Life cycle endurance tests and long term materials compatibility testing are conducted under operational environmental conditions. In launch vehicle applications, it has proven desirable to perform eight-cycle leak checks on each check-valve prior to launch. Integration and Application Practices: Aerospace check valves are often used in redundant configurations to increase reliability. Valves are installed into functional groups within systems using permanent connections, (such as welded or brazed connections) to avoid contamination and to prevent leakage. This type of installation allows a group of valves to be replaced in the event of a malfunction. Technical Rationale : The six purge check valves on the Space Shuttle Main Engine (SSME) have performed successfully in more than 67 missions to date without a failure. Five check valves used on the engine's pneumatic control system have performed equally as well in all missions. These check valves, and others used in the SRB and ET, were designed, built, tested, and operated in accordance with the practices described herein. References: SSME Orientation: Space Transportation System Training Data, Report # ME110(A)RIR, Rockwell International Corporation, December 1991. Long Life Assurance Study for Manned Spacecraft Long Life Hardware, Report #MCR-72- 169, Martin Marietta Corporation, September 1972.","Lesson ID":752}
{"Driving Event":"This Lesson Learned is based on Reliability Practice Number PD-AP-1314, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Identification of sneak circuits in the design phase of a project prior to manufacture can improve reliability; eliminate costly redesign and schedule delays; and eliminate problems in test, launch, on-orbit, and protracted space operations. Sneak circuit analysis can also be beneficial in identifying drawing errors and design concerns. Implementation Method: Some of the devices and equipment benefiting from hardware sneak circuit analysis are solid state electronic devices, relay logic systems and digital systems. The relay equipment includes associated items such as: resistors, capacitors, single load devices, diodes, switches, integrated circuits, and other semiconductors. Another type, analog equipment, includes amplifiers, inverters, converters, and feedback systems. Sneak circuit analysis is an effective tool for locating potential problems in software, and for identifying potential drawing errors and design concerns. Sneak circuit analysis is a labor intensive technique which requires specialized training and is often limited to those areas of a design where safety compliance is an issue. When considering sneak circuit analysis as an applicable tool to be applied to a program, the following considerations are recommended: Reasons for conducting a sneak circuit analysis: Improve reliability which results from the identification and resolution of system problems. Conduct an independent analysis of the design. Locate unresolved system problems that could not be found by other analyses or tests. Identify high criticality items (crew and mission-critical). Respond to a high change rate in baseline design. Applicable systems: Systems which perform active functions. Electrical power distribution and controls. Computer programs which control and sequence system functions. Sneak circuit analysis can be implemented on a limited subsystem, a complete functional system or a complete vehicle or program. Analysis is based on documentation in the form of quotas builtquot schematics, drawings, wire lists and quotas codedquot source computer programs. The preferred start time to begin sneak circuits analysis is during the engineering development phase prior to Critical Design Review (CDR), but sneak circuit analysis can be performed during any phase of the program. The analysis cannot be completed until the overall program\/project drawings are baselined. Performing sneak circuit analysis during the last phases of the program tends to drive program costs up because of the potential redesign effort. The effects of making a change later in a program are illustrated in Figure 1. [D] The data used for sneak circuit analysis must represent the system circuitry as built, contingent upon quality control checks, tests, and inspections. The technique for sneak circuit analysis requires the analyst to accumulate detailed circuit diagrams and wire lists, arrange circuit elements into topological network trees, and to examine these network trees for suspected sneak circuits. After the topological trees have been produced, the next step is to identify the basic topological patterns that appear in each tree. The five basic topological patterns are: (1) the single line (no-node), (2) the ground dome, (3) the power dome, (4) the combination dome, and (5) the quotHquot pattern. These topological patterns are illustrated in Figure 2. The quotPWRquot represents electrical power, quotSquot=switching element, quotLquot=electrical load, and quotGquot=ground. The quotHquot pattern usually has the highest incidence of problems due primarily to the higher number of power sources, returns, loads, and switches. The problems normally occur in the quotHquot crossbar, which includes L3, S3, and S4. This can result in power reversals, ground reversals and current reversals. As the analyst examines each node in the network tree, the analyst must identify which pattern or patterns that node is part of and apply the basic clues that have been found to typlify sneak circuits involving that particular pattern. [D] Associated with each pattern is a list of clues to help the analyst identify sneak circuit conditions. The clues are questions that the analyst must ask about the circuit in question. The clue list becomes longer and more complicated with each successive topograph. The clue list for the quotHquot patterns includes more than 60 clues. Almost half of the critical sneak circuits can be attributed to the quotHquot pattern so this pattern should be analyzed very carefully. (Depending upon contract provisions, the developed clues may be proprietary to the performing contractor.) Sneak conditions are classified into four basic types: Sneak paths - which cause current to flow along an unexpected route. Sneak timing - which may cause or prevent the activation or inhibition of function at an unexpected time. Sneak indications - which may cause an ambiguous or false display of system operating conditions. Sneak labels - which may cause operator error through inappropriate control activation. When a suspect sneak condition is identified, the analyst should verify that the circuit is valid. The circuit should be checked against the latest drawings, revisions, as-built documentation and equipment; and operational information should be reviewed concerning the system in question. Upon verification of the sneak condition, a sneak circuit report should be written which includes the drawings, an explanation of the condition, system level impact, and a recommendation for correcting the sneak circuit. Software sneak analysis should be used to discover program logic which causes one of the four sneak condition types. During the sneak circuit analysis, unnecessary or undesired conditions may be discovered. These conditions could be newly identified failure points, unsuppressed inductive loads, unnecessary components, unnecessary software codes and inadequate redundancy provisions. These conditions should be documented in design concern reports. Any documentation discrepancies should be reported in document error reports. A final sneak analysis report should be written that details the scope, procedures, results and conclusions of the analysis. The final report should also include all sneak conditions, design concern reports, documentation error reports and report tracking status sheets. Technical Rationale: Sneak analysis is a reliability-enhancement method used to identify designed-in conditions that could introduce undesired events and inhibit desired system functions which could adversely affect crew safety or mission success. The sneak circuit analysis technique differs from other system analysis techniques in that it is based on identification of designed-in inadvertent modes of operation and is not based on failed equipment or software. References Buratti, Davey L. and Sylvia G. Godey: quotSneak Analysis Application Guidelinesquot, RADC-TR-82-179, Boeing Aerospace Company for Rome Air Development Center, Griffis AFB, NY 13 441, June, 1982. Hill, E.J. and C. J. Bose: quotSneak Circuit Analysis of Military Systemsquot, Boeing Aerospace Company, Seattle, WA, 2nd AIAA International Systems Safety Conference, San Diego, CA, July 21-25, 1975, Proceedings, A77-16726- 31, Newport Beach, CA, System Safety Society, 1976, pgs. 351-372. Miller, Jeff: quotIntegration of Sneak Analysis with Designquot, RADC-TR-109, Vol. 1 of 2, Sohar Incorporated for Rome Air Development Center, Griffis AFB, NY 13441, June, 1990. Walker, Frank Ellis: quotSneak Circuit Analysis Automationquot, Boeing Aerospace, Seattle, IEEE, 1989 Proceedings Annual Reliability and Maintainability Symposium. Wilson, Joe L. and Robert C. Clardy: quotSneak Circuit Analysis Application to Control System Designquot, The Boeing Company, Houston, TX, AGARD-AG-224, In AGARD Integrity of Electronic Flight Control Systems for Aircraft Reliability, April, 1977. Vogas, James L.: quotSneak Analysis of Application Specific Integrated Circuitsquot, Boeing Aerospace Operation, Inc., Houston, TX, AIAA-92-0976, 1992 Aerospace Design Conference, Irvine, CA, February 1992. MIL-STD-785B: quotReliability Program for Systems and Equipment Development and Productionquot, Military Standard, September 15, 1980. NSTS 22254B: quotMethodology for Conduct of Space Shuttle Program Hazard Analysisquot, NASA, Johnson Space Center, Houston, TX 77058, December 30, 1993.","Lesson ID":756}
{"Driving Event":"This Lesson Learned is based on Reliability Practice Number PD-AP-1311, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. The use of computer-based computational fluid dynamics methods will accelerate the design process, reduce preliminary development testing, and help create reliable, high-performance designs of space launch vehicles and their components. In addition to design verification and optimization, CFD can be used to simulate anomalies that occur in actual space vehicle tests or flights to more fully understand the anomalies and how to correct them. The result is a more reliable and trouble-free space vehicle and propulsion system. Implementation Method: Accurate definition of flow-induced pressure and temperature loads can be achieved long before actual hardware testing through the use of high-speed, computer-based computational fluid dynamics analytical techniques. Designs can be constructed in electronic three-dimensional computer-aided design format, and the flows of fluids and gases can be accurately simulated using CFD techniques. Computer-based simulations of this type can be accomplished so rapidly that designs can be changed in real time even before hardware is fabricated. CFD techniques are being successfully used as diagnostic tools to provide insight into problems with existing rocket engine components and to develop optimum designs of liquid rocket engine pump components such as impellers, diffuser vanes, and shrouds; turbine components such as turbine blades, turbine staging, volutes, and turbine wheels; launch vehicle base thermal protection configurations; transpiration and conductive cooling methods for rocket nozzles; flow paths within solid rocket motors at various stages of combustion; and launch and reentry pressure and thermal loads on vehicle configurations. The Team Approach to CFD Code and Data Base Development MSFC has found that a very effective way of developing and selecting CFD codes (the computer-based equations that control a CFD analysis) and CFD Data Bases (the empirically derived factors that fit the CFD codes to various specific applications) is to form multi-organizational teams in specialized areas related to propulsion and to other space flight applications. These teams, which are part of a CFD Consortium for Applications in Propulsion Technology (CAPT) are comprised of individuals from within MSFC, other NASA centers, prime and subcontractors, and the academic community, communicate frequently and meet periodically to exchange and disseminate information about the rapidly growing field of computational fluid dynamics as related to rocket propulsion and other related space flight applications. The teams take into account the best available theory on CFD, the most advanced computer computational and graphic capabilities, and the latest test techniques and results of component, subsystem, subscale and full scale rocket engine tests. This information is used to continuously develop and improve the computer-based representation of the temperatures, pressures, and flow patterns (velocities, accelerations, and directions) in space vehicles and their propulsion systems. Implementation of CFD Into the Design of Rocket Engine Pumps The implementation of CFD into the design process for rocket engine pumps has been aided by the activities of a Pump Stage Technology Team (PSTT) which is a part of the NASA\/MSFC CFD Consortium for Applications in Propulsion Technology. The team's goals have included the assessment of the accuracy and efficiency of several CFD methodologies and application of the appropriate methodologies to understand and improve the flow inside fuel and oxidizer pumps for liquid propellant rocket engines. As an example of the type of CFD work that has been done under the cognizance of this team, subtle changes in the axial impeller length, blade count, and blade configurations of pump impellers resulted in efficiencies of up to 98 percent. This resulted in head coefficients (which are measures of pump power) increasing from 0.53 to 0.66 in experimental impeller designs. CFD Analysis of Base Flowfields in Clustered Nozzle Configurations As a launch vehicle proceeds up through the atmosphere into space from its near sea-level launch position, the rocket exhaust plumes expand to a point where a plume reverse flow is encountered. Where multiple nozzles are used, the closed impingement of the exhaust plumes can cause a reverse jet. The reverse jet impinges on interior base surface areas, components, and base shields causing heating, contamination, and\/or possible combustion in the launch vehicle base areas. Computational fluid dynamics has proven to be a useful tool in predicting the recirculating exhaust base flow patterns encountered in various launch vehicle configurations, and these patterns can be used as an input to the design and development of reliable vehicle configurations and thermal or pressure protection schemes. Figure 1 is a typical output from a CFD analysis which shows velocity vectors indicating the flow patterns that are generated at high altitude (approximately 92,000 feet above sea level) when a launch vehicle has four exhaust nozzles. With the knowledge of the pressure, temperature, and flow profiles in the base region provided by a CFD analysis, components and insulation systems can be designed to withstand environments in the base region or insulated to protect them against the potentially hostile environment that occurs due to exhaust recirculation at high altitude. [D] Turbine Improvements Using CFD Computational fluid dynamics techniques are being used in the advancement of turbine aerodynamic design techniques as well as the development of a understanding and characterization of the unsteady aerodynamic environments in existing rocket engine turbines. The CAPT Turbine Technology Team is addressing several areas of CFD application to existing and future liquid rocket engines. The techniques reduce developmental risk, decrease the amount of intermediate testing, improve performance and durability, and reduce cost. In one turbine improvement effort, gas turning angle in the turbine blades was increased from the traditional design limit of approximately 140 degrees to 160 degrees. The CFD analysis showed that this change, coupled with other minor improvements, would increase turbine efficiency by almost 10 percent and reduce the required number of turbine blades by approximately one half. Maximum blade mach number was decreased dramatically from the 1.32 of the original design to 0.87 for the new design. The new configuration employed a single stage turbine rather than an originally planned two stage configuration. CFD has also proven to be a useful tool in the evaluation of secondary losses and turbine blade tip loss control mechanisms such as endwall fences, blade fences, tip grooves, tip cavities, and mini-shrouds. This technique is also useful in the simulation and design of inlet and outlet turbine volutes. Cold flow testing of reduced scale and full scale turbines has verified many of the CFD simulations. Flow Fields, Flow Separation, Film Coolants, and Heat Transfer in Rocket Engine Combustors Computational fluid dynamics analyses have been successfully applied in areas related to the prediction and simulation of combustion flow behavior and heat transfer to the internal walls of rocket engine injectors, combustion chambers, and nozzles. These analyses have been used to optimize nozzle entrance geometries, evaluate new step nozzle exit configurations that adapt to altitude changes, determine pressure and temperature profiles in rocket engine chambers and nozzles, and to study the effects of coolant flows in liquid rocket engine chambers on internal wall temperatures. These analytical procedures have helped to evaluate anomalies discovered in actual engine firings and to design reliable combustion chamber, nozzle, and coolant arrangements that result in high thrust coefficients under various atmospheric and space conditions. The CAPT Combustion Devices Technology Team has been instrumental in many of these investigations. Computational fluid dynamics simulations have also been useful in determining pressure, heating, and insulation requirements for launch vehicles during liftoff, ascent, and reentry into the atmosphere. Technical Rationale: NASA\/MSFC has sponsored the CFD Consortium for Applications in Propulsion Technology since the early 1980s. Symposia have been held for the past twelve years in which participants from MSFC, other centers, prime contractors, laboratories, other agencies, and the academic community have exchanged information in the development and application of CFD analytical techniques related to rocket engine propulsion systems. MSFC has also been involved in the other aerodynamic and fluid dynamics applications of CFD. Computational fluid dynamics is a discipline that has come of age in the concurrent engineering process that results in the design, development, and flight of highly reliable and cost effective launch vehicle systems. References quotProceedings of Workshop for Computational Fluid Dynamic (CFD) Applications in Rocket Propulsion,quot April 19-21, 1994, Marshall Space Flight Center, NASA. quotOverview of the NASA\/MSFC CFD Consortium for Applications in Propulsion Technology,quot McConnaughey, P.K. and L.A. Schutzenhofer, AIAA, 92-3219, AIAA\/SAE\/ASME\/ASEE 28th Joint Propulsion Conference, July 6-8, 1992, Nashville, TN. quotComputational Fluid Dynamics Analysis for the Reduction of Impeller Discharge Flow Distortion,quot R. Garcia, et al, 32nd AIAA Aerospace Sciences Meeting, January 10-13, 1994, Reno, NV. quotNumerical Analysis of Base Flowfield at High Altitude for a Four-Engine Clustered Nozzle Configuration,quot T.S. Wang, 29th AIAA Joint Propulsion Conference, June 28-30, 1993, Monterey, CA. quotAnalytical Investigation of the Unsteady Aerodynamic Environments in Space Shuttle Main Engine (SSME) Turbines,quot Lisa W. Griffin, et al, May 24-27, 1993, ASME, New York, NY. quotAdvancement of Turbine Aerodynamic Design Techniques,quot Lisa W. Griffin, et al, May 24-27, 1993, ASME, New York, NY. quotAdvanced Technology Low Cost Engine (ATLCE) 50K Testbed Combustion Chamber Film Coolant Parametrics,quot Joe Ruf, November 5, 1993, MSFC, AL. quotUnified Navier-Stokes Flowfield and Performance Analysis of Liquid Rocket Engines,quot T.S. Wang, et al, Journal of Propulsion and Power, September 1993, AIAA, New York, NY. quotNumerical Analysis of the Hot-Gas-Side and Coolant-Side Heat Transfer for Liquid Rocket Engine Combustors,quot T.S. Wang, et al, 28th AIAA Joint Propulsion Conference, July 6-8, 1992, Nashville, TN. quotNumerical Study of the Transient Nozzle Flow Separation of Liquid Rocket Engines,quot T.S. Wang, CFD Journal, October 1992, MSFC, AL. Reliability Preferred Practice PT-TE-1427, quotRocket Engine Technology Test Bed Practice.quot","Lesson ID":758}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PD-ED-1268, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Use of precision design; manufacturing; and advanced material selection, fabrication, and treatment techniques will ensure reliable operation of large, high performance liquid hydrogen turbopumps. Many of these practices will also lengthen the operational life of the turbopump, increasing the number of uses before teardown, inspection, refurbishment, and re-assembly for subsequent flights. In addition to higher reliability, lower costs and continued assurance of high performance are resulting benefits. Implementation Method: I. Background: The 85,000 horsepower liquid hydrogen turbopump being flown on each flight of the Space Shuttle represents almost three decades of design, development, and fine-tuning of its performance and reliability. It is a three-stage centrifugal pump driven by a two-stage hot gas turbine. The pump rotates at 37,000 revolutions per minute (RPM) which is over 600 revolutions each second. The high horsepower, high RPM, high flow rates, and high pressures in this turbopump created a unique set of design and engineering challenges to the prime contractor and to NASA (Marshall Space Flight Center). Problems have been encountered over the years that manifested themselves in bearing wear, turbine blade cracking, turbine blade erosion, and rotodynamic issues. In overcoming these problems, specific design features, materials, and fabrication methods have been developed and perfected for the hydrogen turbopump that permit the Space Shuttle Main Engine (SSME) to maintain its unprecedented high performance while exhibiting manned space flight levels of reliability. The practices that have been developed and included in this document are essential to the continued high reliability of the SSME and can also be applied in next-generation turbopumps for reusable and expendable launch vehicles. II. Bearings and Blades The two major components of the fuel turbopump that have required focused engineering and manufacturing attention are the turbopump bearings and the turbine blades. Both the bearings and the blades have performed well in initial firings and flights of the engine, but have resulted in unsatisfactory condition reports when subjected to detailed inspection on disassembly after flight. The bearings have exhibited wear before their expected rated lifetime has been reached, and tiny hairline cracks have been observed in the turbine blades. Fractures in bearing cages were discovered during disassembly inspection of the turbopump in early engines. Investigations indicated that the failures were most likely due to high cycle fatigue; and stress analyses showed a marginal factor of safety on high cycle fatigue for \"infinite\" life. Post disassembly inspection of some engines also revealed rub marks, evidence of wear, and indentations on bearing races and balls. Although the slightly damaged bearings were still suitable for development testing, a bearing wear potential prior to end of rated life still exists. Reliable, long-life fuel turbopump bearings are made possible by sophisticated cooling arrangements and by careful material selection. The fuel pump bearings are cooled by internal flows of liquid hydrogen. The coolant source for pump-end bearings, including an axial load-carrying thrust bearing, is the output of the first impeller of a three-impeller fuel pump. Liquid hydrogen flows from the back face of the impeller through orifices in the impeller hub, through the bearings, and back into the pump inlet. The bearing inner races are clamped to the pump shaft with the bearings free to slide axially within the bearing cartridge. Liquid hydrogen performs the function of a highly effective coolant because all heat is removed from the bearings, resulting in very little, if any, bearing wear. Bearing specifications are very tight, minimizing bearing defects. An alternate bearing material, silicon nitride has successfully demonstrated long life in oxygen turbopumps and the same benefits are expected in hydrogen turbopumps. The provision of ample cross-sectional area and the addition of Fluorinated Ethylene Propylene (FEP) coating to the bearing cages eliminated a bearing cage cracking problem. The turbine blades experience enormous centrifugal force loads as well as high thermal loads at 600 revolutions per second. High cycle fatigue and hydrogen embrittlement effects, have caused small hairline cracks in the turbine blades of the high pressure fuel turbopump. These cracks are an order of magnitude shallower than the critical depth of 0.100 inch, but have persisted throughout the program. Although the hairline cracks are not detrimental to performance, periodic disassembly inspection is needed to continue to monitor this condition. Attention is given to blade porosity after machining (less than or equal to 5 mil pores). Shot peening of blades on the blade-to-wheel interface improves toughness and resistance to cracking. Gold plating of blade shanks resists hydrogen embrittlement. An important design feature in the turbine blade-to-wheel connection is a \"loose\" fit that gives the blades freedom to adapt to dynamic turbine environments. III. Turbopump Seals One of the keys to high reliability liquid hydrogen turbopumps is the use of a variety of compression and flow restricting seals. The compression seals, which include gaskets and piston rings, contain the liquid hydrogen and hot gas inside the pressure vessel or chamber. Flow restricting or flow redirecting seals restrict liquid hydrogen and hot gas flow in one direction and\/or redirect flow in another. The principal types of seals are pump interstage (or \"damping\") seals, fluorocarbon seals, liftoff seals, labyrinth seals, platform seals, and turbine blade tip seals. The interstage seals permit a small amount of liquid hydrogen to flow between impeller stages. A knurled surface on the seals at the impeller interface slows down axial and circumferential flow of liquid hydrogen and traps enough fluid to provide cooling and vibration damping. Stepped fluorocarbon seals that contact ridges around the impeller face on all three pump stages control the amount of propellant flow around the impeller front shrouds. The liftoff seal assembly, which acts as a check valve ---permitting flow in only one direction---prevents hydrogen leakage into the turbine end of the turbopump prior to engine start and after engine cutoff. During engine start, a pressure unbalance develops across the seal to offset the spring load and retract the seal, allowing liquid hydrogen to enter and cool the turbine end. A turbine hub labyrinth seal directs part of the coolant flow from the liftoff seal to the bearings, disc, and coolant liner to cool the turbine end bearings and discs. Forward and aft platform seals restrict flow and enhance cooling balance while maintaining efficiency of the first and second stage turbine wheels. Turbine blade tip seals help direct hot gas flow through the turbine blades, improving turbine efficiency. One of the most critical seals in the high pressure fuel turbopump is the lift-off seal. Avoidance of contamination is important because it must act as a static seal when closed. It must avoid trapping contamination, and work properly repeatedly in the dynamic engine environment. Repeated and consistent response to pressure differentials is required. The seal must resist rubbing and wear while retaining its capability to pass fluids reliably when open and to seal off fluids completely when closed. The seal is a complex component in itself, incorporating 55 springs, guide bushings, carbon nose, adaptor, retainer plate, and additional secondary seals. IV. Materials and Fabrication Methods Because of the hydrogen environment, the wide temperature ranges, the high structural and thermal stresses, and the close tolerances encountered in the turbopump; a thorough knowledge of material properties is necessary, and precision fabrication methods must be used. A variety of manufacturing techniques are used such as TIG (tungsten inert gas) welding, EDM (electrodischarge machining), conventional machining, investment casting, CNC (computer numerically controlled) machining, broaching, grinding, polishing, and burnishing. Directional solidification is used when casting the turbine blades to produce grains parallel to the major operational stresses. Copper and gold coating and plating techniques are used to protect certain critical components such as turbine housing struts and the blade attachment \"firtree\" slots in the turbine discs from hydrogen embrittlement. Replacement of sheet metal components with castings eliminates and\/or reduces potential hardware failures due to welding defects. Replacement of some titanium rotating components with Inconel 718, the addition of a baked-on dry film lubricant, the use of stellite bore inserts, and the use of knurled pump inserts to smooth out and enhance the damping characteristics of coolants resulted in beneficial improvements in turbopump reliability and lifetime. V. Advanced Design and Inspection Methods Advanced computer simulations are now available to characterize the flows, stresses, and thermal environments in rocket engine fuel turbopumps. Computer analyses, well anchored and authenticated by thoroughly instrumented tests, will do much to provide the most reliable and effective turbopump design. Verification of design environments is essential. Advanced computed tomography inspection of critical fuel turbopump components such as the first and second stage turbine blades has been proven to be an effective way to screen the hardware for potential blade failure modes. Sophisticated analytical techniques and precise balancing methods were used in solving a \"subsynchronous whirl\" problem that caused spurious turbopump vibrations. Technical Rationale: Specific design features, materials, and fabrication methods must be used in high performance liquid hydrogen turbopumps to ensure satisfaction of performance requirements while exhibiting manned space flight levels of reliability. References Engineering Change Proposal #11-17R1: Space Shuttle Main Engine, Rocketdyne Division of Rockwell, International, Canoga Park, CA, 1988. Space Transportation System Training Data: Report No. ME-110(a) R1R, Rocketdyne Division of Rockwell, International, Canoga Park, CA, December 1991. \"Space Shuttle Main Engine Instrumented High Pressure Fuel Turbopump Technology Test Bed Testing Results Summary,\" AIAA Report No. 93-1908, June 28-30, 1993. \"Fabrication of the Space Shuttle Main Engine High Pressure Fuel Turbopump,\" Marshall Space Flight Center, Huntsville, AL, April 1994. \"Solution of the Subsynchronous Whirl Problem in the High Pressure Hydrogen Turbomachinery in the Space Shuttle Main Engine,\" Paper # 78-1002, AIAA\/SAE 14th Joint Propulsion Conference, July 25-27, 1978. Reliability Preferred Practice PT-TE-1439, \"Systems Test Considerations for High Performance Liquid Rocket Engines.\" Reliability Preferred Practice PD-ED-1269, \"High Performance Liquid Oxygen Turbopumps.\"","Lesson ID":750}
{"Driving Event":"This Lesson Learned is based on Reliability Practice Number PD-AP-1312, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. The use of the team approach to fault-tree analysis permits a rapid, intensive, and thorough investigation of space hardware and software anomalies. This approach is specifically applicable when the solution of engineering problems is urgent and when they must be resolved expeditiously to prevent further delays in program schedules. The systematic, focused, highly participative methodology permits quick and accurate identification, recording, and solution of problems. The resulting benefits of the use of this methodology are reduction of analysis time, and precision in identifying and correcting deficiencies. The ultimate result is improved overall system reliability and safety. Implementation Method: Determination that a Team Approach to Fault-Tree Analysis is Required: In situations where program hardware or software anomalies are uncovered which could potentially reduce the possibility of mission success or cause harm to personnel, and where the pressure of schedules requires a rapid and accurate solution of problems, the team approach to fault-tree analysis should be strongly considered. Fault-trees are necessary when the system in question is complex and has many potential contributors to the problem so that the solution defies simple intuition, engineering judgement, or easy elimination of the events that contributed to the problem. The team approach to fault-tree analysis brings all disciplines to bear simultaneously in an interactive but controlled environment. A fault-tree is defined as, quota graphic depiction or model of the rationally conceivable sequences of events within a complex system that could lead ultimately to the observed failure or potential failure.quot It is a systematic approach to fault prevention achieved by postulating potential high level faults, and identifying the primary and secondary causes, down to the lowest piece-part, that could induce the high level fault. A typical arrangement of a fault-tree showing the potential types of quotgatesquot containing Boolean logic is shown on Figure 1. In situations of high urgency and cost or schedule sensitivity, it is often desirable to apply a team approach to development and use of the fault-tree methodology. [D] Fault-Tree Team Methodology: The keys to a successful team approach to a fault-tree analysis are: (1) selection of the right people to participate in the analysis; (2) interactive meetings of these people in a creative but focused environment; (3) thorough documentation of objectives, fault-tree structure, and action items; (4) parallel (but not redundant) participation by all team members; and (5) careful attention to general ground rules for effective team dynamics. All of the preceding must be backed up by a data base containing the hardware\/software configuration, operational time lines, potential failure causes, and exonerating or indicting data. Logic flow networks are built based on the system's design, then laboratory test results, hardware\/software test results, and modeling based on deterministic and\/or probabilistic statistical analyses. These logic flow networks also feed into the information data base that is used by the fault-tree team. An integral part of successful fault-tree methodology is the selection of an orderly structure on which to base the fault-tree and the team participation. The Work Breakdown Structure (WBS) is an ideal starting point for the team as well as for the design. Each event or activity in the WBS is subdivided into its main contributing events or activities, then the tree is subdivided again until the smallest activity that cannot be further subdivided is reached. These final events or activities are the quotleavesquot on the fault-tree. Team Composition: Given the nature of the failure or anomaly being investigated, people should be assembled who have both an intimate disciplinary knowledge and a knowledge of the overall system. Elements heads and subteam leaders should be established for major investigative elements of the work breakdown structure. Important administrative functions to support the team are: (1) the maintenance of a current address, phone, and fax listing of all persons involved; (2) recording daily team meeting minutes; (3) preparation of agenda for the next day, (prepared at the end of the current day); (4) recording of all action items including the name of the person responsible, suspense dates, and the specific action required; and (5) the maintenance of a master schedule of major planned events, based in part on the suspense dates. Team Dynamics and Work Strategy: The entire team should meet together in one location in a meeting to expose all known data related to the anomaly or failure, then the team should meet at least once per day thereafter. Action items should be assigned and as much work as possible should be done in parallel without undue redundancy. Series activities of the team should be avoided. Team interaction is important because the fault-tree is built in a dynamic, contributory fashion. During the fault-tree team activities, the team leader and scribe should keep files of action items, agendas, technical data related to development of the fault-tree, correspondence, administrative reports, the master fault-tree diagram, and the team's schedule. Top management and other related organizations should be kept informed as to the progress of the team. Hand written notes to the key players from the team leader quoten route,quot at key milestones and critical junctures, and on successful completion of the investigation are particularly helpful. Rambling discourses should be avoided. Meetings and discussions must be diplomatically kept on track. The leader should be as democratic as possible in team meetings. No one should be affronted, but in case of an impasse, the team leader must make the decision. Refreshments should be provided occasionally, especially on Saturday or Sunday and after hours. This will boost morale and provide an atmosphere conducive to free discussion. Other General Techniques and Methods: The purpose of the team approach is to provide multidisciplinary perspectives that will uncover details and to resolve cause\/effect relationships which may not be apparent in more narrowly focused detailed engineering analytical and design methods. Therefore, each element of the fault-tree must be doggedly and systematically analyzed, persistently subdivided into it's smallest elements, and pursued to the lowest level. The history of these types of investigations has indicated that a methodical, vigorous assessment is needed to develop and to utilize a fault-tree of sufficient depth. This vigorous assessment will eliminate illogical assumption, identify or eliminate synergistic effects, help to avoid partial fixes and reduce intuitive or random approaches that cannot be substantiated. The team should resist the temptation to preconceive a conclusion or take on a quotpet theoryquot to the exclusion of a systematic, orderly, and vigorous treatment of all elements in the decision tree. The team should avoid any tendency to slow down the analysis process or to assume that a conclusion has been reached when a likely cause candidate has been identified, because this potential candidate could mask the true cause or divert the team's attention from a more fruitful path. Probability and statistics are important disciplines to use in the fault-tree analysis process. The team should have an appreciation of the fact that if it is necessary to stack too many possible events together to eventually postulate the occurrence of the failure, then it is improbable that it occurred in that manner. The references list several computer-aided fault-tree analysis software packages that will aid in performing the statistical analysis and informing the decision tree graphics required to document a fault-tree analysis. Technical Rationale: The team approach to fault-tree analysis described in this practice was used very successfully in a number of in-depth investigations of problems that occurred in propulsion elements of the Space Shuttle, and related facilities and equipment. The procedure was first used in full measure in the investigation of a fire in the casting pit of the Space Shuttle Solid Rocket Motor (SRM) in 1984. It was also used in identifying causes of problems in the SRM propellant mix facility. Several problems and potential problems with the Space Shuttle Main Engine (SSME) were successfully investigated using the team approach to fault-tree analysis. These investigations involved the bearings for the alternate turbopump, and a synchronous vibration problem. Hydrogen leaks in the Space Shuttle Columbia were investigated and successfully resolved in an in-depth and intensive three-month team approach to fault-tree analysis. References Dhillon, Balbir S: quotFault-Tree Analyses,quot (Chapter 20 of quotMechanical Engineers Handbookquot) John Wiley & Sons, New York, NY, 1986. Koren, James: quotComputer-Aided Fault-Tree Analysis (CAFTA) User's Manual,quot Science Applications International Corporation, Los Altos, CA, 1993. Van Fleet, Kevin: quotRisk Spectrum Fault-Tree Software,quot User's Manual, Innovative Software Designs, Inc., Baltimore, MD, 1993. Wild, Tony, Ph.D.: quotTree Master Software,quot User's Manual, Management Sciences Incorporated, Albuquerque, NM, 1994. Schwinghamer, Robert: quotLeak Team's Final Eureka Anthemquot Hydrogen Leak Investigation Team Final Report (Presentation), NASA, Marshall Space Flight Center, A-L, November 8, 1990. Reliability Preferred Practice PD-ED-1208 - quotStatic Cryogenic Seals for Launch Vehicle Applicationsquot","Lesson ID":757}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PD-ED-1269, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. The use of special design features, materials, and coatings in high pressure liquid oxygen turbopumps will prevent inadvertent overheating and combustion in the liquid oxygen environment. Special sealing, draining, and purging methods prevent contact between the oxygen in the pump section and the hydrogen rich gasses that drive the turbine. These precision design and manufacturing procedures prevent latent or catastrophic failure of the LOX turbopump. Silicon nitride bearings, coupled with other bearing enhancements, prevent bearing wear in advanced LOX turbopumps. Implementation Method: I. Background The high pressure oxidizer turbopump (HPOTP) of the Space Shuttle Main Engine raises the pressure of liquid oxygen flowing to the main engine combustion chamber injector and preburner injectors sufficiently to ensure positive injection of oxygen into the chambers at all thrust levels. Its centrifugal pump contains both a double-entry main impeller and a single entry preburner oxygen boost impeller. The pump bearings are cooled by internal flows of oxygen from points of higher pressure to points of lower pressure. A hollow retaining bolt and hollow turbopump shaft provides a liquid oxygen coolant flow path to two of the pump bearings. The other two bearings are cooled by liquid oxygen that flows down the back face of the preburner pump impeller, through the hub seal, through the bearings, and into the main pump inducer. The pump bearings consist of two matched pairs of angular-contact ball bearings whose inner races are clamped and whose outer races are preloaded. Excessive axial loads are counteracted by two balance cavities which lie between the front faces of the impeller and adjacent stator rings. The HPOTP turbine is a two-stage, cantilevered turbine powered with hot, hydrogen-rich gas generated in the oxidizer preburner. The second stage turbine wheel is an integral part of the turbopump shaft and the first stage wheel is bolted to the second stage wheel. II. Special Considerations for High Pressure Oxidizer Pumps Because of the oxygen environment, any condition that results in heat generation must be avoided to prevent inadvertent combustion. Contamination, rubbing, and cracking of components are closely monitored and controlled. More stringent tolerances are required in LOX turbopumps than hydrogen turbopumps, and silver plating is used rather than gold plating because silver does not as readily decompose in an oxygen environment. The cantilevered turbine, coupled with the heavier fluid being pumped, creates a greater load on the oxygen pump bearings. Operation of the bearings in an oxygen environment with these high loads increases their susceptibility to wear. Routine tear-down and inspection of bearings is required to ensure continued reliable operation. The use of silicon nitride bearings has shown promise in long-term component tests for longer lifetime and greater wear resistance. The addition of a preburner liquid oxygen pump to the main liquid oxygen pump makes the pump design more complex. Multiple interference fits require precision assembly procedures. III. Sealing, Draining, and Purging Between Liquid Oxygen and Hydrogen-Rich Turbine Gasses To prevent contact between the liquid oxygen being pumped and the hot, hydrogen-rich gasses that drive the turbine a sophisticated three-cavity labyrinth seal is used. The first cavity next to the turbine drains the fuel rich gasses overboard. The second cavity is purged with helium to eliminate any other fluids or gasses that may leak in from the first and third cavities, and the third cavity drains off liquid oxygen that leaks in from the oxygen pump side. Cavity pressures are carefully monitored and represent redline values for engine control. It was found early in the SSME liquid oxygen turbopump development effort that three-step shaft mounted labyrinth seals with stationary plastic wear rings were superior to bellows loaded hydrodynamic liftoff seals for isolation of pumped liquid oxygen and turbine hydrogen. IV. Reduction of Vibration and Addition of Damping Provisions Vibration of liquid oxygen turbopumps, can be reduced significantly by careful analysis of the dimensions, weights, and clocking of turbopump components on the turbopump shaft. Precision optical methods have been developed for computer-based balancing of turbopumps through precise assembly of components at the proper rotational position on the shaft. Two-piece dampers were installed on the first stage turbine blades to reduce dynamic stress and to eliminate transverse blade shank cracks. Resonant frequencies are reduced by the proper design of seals. Internal clearances for bearings was increased by elongating cage pockets in the turbine and preburner pump bearings. V. Design, Fabrication, and Assembly Practices An effective means of controlling or eliminating cracking in the high pressure oxidizer turbopump components has been to provide higher radius fillets. Assembly process improvements have aided in the effective disassembly, inspection, and reassembly of the turbopump when required. For example, Hot Isostatic Pressure (HIP) Process was performed on turbine nozzle castings to eliminate near-surface porosity. A visual inspection system was developed for the inspection of turbine blades. Bearing defect specifications were tightened, as were the specifications for protective platings and installation procedures. VI. Alternate Liquid Oxygen High Pressure Turbopump To extend the operational lifetime of liquid oxygen turbopumps for the Space Shuttle Main Engine, an alternate turbopump development program was undertaken by MSFC in conjunction with the cognizant contractors. In the new turbopump development effort, it was necessary to eliminate bearing wear and distress of the pump-end ball bearings, which was the primary failure mode in early development tests. Potential failure mechanisms that were investigated were: (1) misalignment, (2) inadequate prelubrication, (3) bearing cage instability, (4) inadequate inner bearing race clearance, (5) high fixed and dynamic loads on the bearings, (6) inadequate cooling (7) inadequate lubrication, (8) high ball\/race heat generation, and (9) inappropriate bearing material configuration. In a detailed fault-tree-based investigation, all but items (6), (7), and (8) were eliminated as not being a likely cause or at the most being a secondary factor in excessive bearing wear. Inadequate cooling can be caused by an inadequate source pressure and resulting inadequate coolant flow rate or by a higher than required coolant temperature. Lubrication of bearings of cryogenic rocket engine turbopumps have traditionally depended upon the transfer of a polytetrafluorethylene (PTFE) film from the bearing cage by rubbing to the bearing balls and races. This film must be of adequate thickness to achieve adequate lubrication. Excessive heat generation is a function of the friction factor of the materials, the contact loads, and bearing geometry. The corrective actions taken to eliminate bearing wear were to improve the coolant supply at the inner bearing race ball contact, to use an outer race guided cage, and to use silicon nitride ball bearings. Larger ball-to-cage pocket clearances were provided, prelubrication was used on the inner race only, and a colder coolant was directed to the inner race. These changes were completely successful in correcting the advanced liquid oxygen turbopump pump-end bearing wear problem. No wear of these bearings has been observed since these incorporations. Technical Rationale: The Space Shuttle Main Engine Turbopump has operated successfully in over 200 flight uses, and has steadily improved in resistance to potential failure through three major design phases. Nine improvements were made from Phase II to reflight after Challenger, and ten improvements have been made since the Challenger accident. Engineers at MSFC and the prime contractor continue to closely monitor performance during flight and the condition of the turbopump after flight to determine if additional improvements are necessary to continue to maintain the SSME's record of high reliability. References Engineering Change Proposal #11-17R1: Space Shuttle Main Engine, Rocketdyne Division of Rockwell, International, Canoga Park, CA, 1988. Space Transportation System Training Data: Report No. ME-110(a) R1R, Rocketdyne Division of Rockwell, International, Canoga Park, CA, December 1991. Reliability Preferred Practice PT-TE-1439, 'Systems Test Considerations for High Performance Liquid Rocket Engines.' Reliability Preferred Practice PD-ED-1268, 'High Performance Liquid Hydrogen Turbopumps.'","Lesson ID":890}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1264; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: The use of computer-based models for integrated x-ray optical performance modeling will provide an independent check of optical systems design and will ensure high quality optical systems by providing in-process verification of the fabrication process. These models can save time and money in optical systems design and development, and should result in highly reliable x-ray imaging. Implementation Method: Software has been developed and is being refined to model the images produced by the grazing incidence optics of the Advanced X-ray Astrophysics Facility (AXAF-I) based on a number of optical system and mirror parameters. Commercial optical design and analysis programs are not tailored for grazing incidence mirror systems with their highly annular entrance apertures and cylindrically shaped mirrors. Analytical modeling is required to verify the design and to check fabrication in real time based on in-process mirror inspection metrology. A computer model has been developed that includes the effects of x-ray source position, x-ray source size, mirror figure errors, mirror surface roughness, mirror reflectivity, mirror alignment, and detector shape. Links are provided in the program to mirror surface metrology data and the mirror distortion predictions of standard structural analyses programs. Mirror figure errors are incorporated into a ray trace model by interpolating metrology data and structural model results onto a finely spaced grid. Individual surface parameters such as curvature and slope errors can also be applied to influence model results. The ray trace results can be convolved with the x-ray scattering predicted from the roughness of the mirror surfaces, and with the detector aperture shape and x-ray source size. An integrated, interactive program has been developed which will produce various two and three-dimensional image plots as well as parameters such as x-ray collecting area, root mean square image size, and image encircled energy distribution. This model is being developed as part of the AXAF-I project, but it is applicable to other grazing incidence x-ray optical systems. Figure 1 is an illustration of the Wolter I combined paraboloid\/hyperboloid mirror system used for x-ray telescopes. [D] Figure 1. Combined Paraboloid\/Hyperboloid Mirror Systems Used in X-ray Telescopes Where: r = radius z = coordinate along the optical axis (z = 0 at midpoint between the mirrors, z > 0 at system focus) r o = radius at z = 0 S = subnormal k = conic constant = 1 - e 2 2 = eccentricity |R| = |vertex radius of curvature| = [D] The mirrors are bodies of revolution around the longitudinal or z- axis. A flow diagram of the integrated optical performance computer model is shown on Figure 2. The model will produce a three-dimensional picture of the image intensity distribution as well as an X\/Y plane contour map of this intensity distribution at preselected intensity intervals. These outputs can be compared with the ideal output configurations by running test cases from a collection of stored parameters and by comparison with the results of ground tests and the analyses of independent investigators. Contamination and gravity (weight) effects are not included in the model's parameters and must be considered separately. Gravity structural and thermal effects for the ground test can be analyzed by exercising the structural\/thermal distortion program inputs. [D] Figure 2. Flow Diagram of Integrated Optical Performance Technical Rationale: Due to the expense of ground x-ray tests of precision grazing incidence x-ray mirrors for aerospace applications and the extensive time required for fabrication, it is imperative to have performance predictions ahead of time and to evaluate actual configurations in near real time as they reach completion during the manufacturing process. Optical performance modeling is necessary to ensure accurate and reliable performance before the mirror is put into service. References: Final Report: quotSoftware to Model AXAF Image Quality,quot Center for Applied Optics, University of Alabama in Huntsville, Huntsville, AL, June 1993. Zissa, D. E.: quotAXAF-I Performance Analysis Software Development,quot (a presentation), Marshall Space Flight Center, AL, February 1, 1994. quotSoftware for AXAF-I Performance Analysis,quot (a presentation), Center for Applied Optics, University of Alabama in Huntsville, February 1, 1994. D. E. Zissa: quotComparison of Ring-Focus Image Profile with Predictions for the AXAF VETA-I Teat,quot Proc. SPIE, Vol. 1742, pp. 91-103, 1992. P. Glenn, P. Reid, A. Slomba, and L. Van Speybroeck: quotPerformance Prediction of the AXAF Technology Mirror Assembly using Measured Mirror Surface Errors,quot Proc. SPIE, Vol. 830, pp. 278-282, 1987. M. Freeman: quotInterim Report, Transfit, Finite Element Analysis Data Fitting Software,quot Smithsonian Astrophysical Observatory Memorandum SAO-AXAF-DR-93-052, September 1993.","Lesson ID":753}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1265; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Highly reliable diffractive, refractive, reflective, and hybrid aerospace optical systems can be produced by a meticulously controlled and protected diamond turning process. The result can be rugged, temperature-compensating achromatic precision optical elements suitable for a wide variety of applications. Implementation: Diamond turning is a well-established fabrication process for shaping high quality optical surfaces on metals, polymers, and crystals. Diamond turning has the capability of precision machining with a single point cutting tool to an accuracy of a fraction of a wavelength of light which makes it suitable for fabricating lenses. The surface finish quality of diamond turning is satisfactory for optical components in the mid to long wavelength regions of the infrared spectrum. Diamond machining can be beneficial for metal mirrors because of the ability to machine a reflective surface directly onto a structural substrate which may contain mounting bosses, alignment flanges, and rib reinforcements. The precision to which components can be machined is partially dependant upon the extent to which the dynamic motion of the machine tool can be controlled with the work piece. The detrimental dynamics of the diamond turning machine can be minimized by stiffening the machine, or mounting it on a vibration isolating mount. Vibration can be reduced by mounting the machine on a block of granite, or in-ground concrete blocks surrounded with vibration isolation material. Other necessary features and components of a diamond turning lathe include stiffness, balanced air bearing spindles, straight square ways and closed loop controllers using laser interferometric feedback. Changes in humidity and partial pressure of atmospheric gases affect accuracy and should be avoided. Thermal considerations are also important. Lack of temperature control is the greatest cause of error in this machining process. Therefore, the environment housing the diamond turning lathe should be maintained to \u00b1 0.01\u00b0F. To minimize errors caused by temperature changes, the work piece, machine and its components should be at thermal equilibrium before material removal begins. In diamond turning the surface finish is determined by the radius of the cutting tool, cutting feed rate, depth of cut, rake angle, tool wear, coolant supply consistency, stiffness of the machine and the material being machined. Materials compatible with diamond turning include: copper, gold, silver, aluminum, platinum, electrolyzed nickel, beryllium, copper, germanium, silicon, plastic, and lithium niobate. Metals that contain carbon are not considered machinable because of the chemical reaction that occurs between the carbon and diamond tool due to the high temperatures of machining. Diamond turning is insensitive to cutting speed. For example, when facing a circular disk a cutting speed of 4572 meters\/minute at the outer edge decreases to zero at the center of the disk, while maintaining a specular finish. Progressively finer cuts are usually taken to reduce damage from previous cuts. Finish depths of 127 to 510 nanometers are not uncommon. The feed rate can be as large as the tool size and shape will permit, but is normally below 0.25 millimeters per revolution. Rigid machine tools are an essential part of diamond turning. Vibration or sudden impact shortens the life of the diamond tool. Sufficient spindle power is required for high cutting speeds, which reduces the pressure on the cutting edge. The use of cutting fluids reduces wear and aids in chip removal. The most common cutting fluids are kerosene and lightweight machine oil. For protection against inadvertent damage during handling or setup, the cutting edge of the diamond tools should be covered with plastic or rubber caps when not in use. Design features that distinguish diamond turning lathes from standard machine tools are: Machine base stiffness and stability, Spindle accuracy and repeatability, Slide accuracy and repeatability, Servo performance, Vibration control, Temperature control, Positioning accuracy, and Tool support and setup. External vibrations, even the sound waves of speech, can affect the surface finish of a diamond turned workpiece. Three point pneumatic damping systems isolate vibrations and shocks from the machine and provide automatic leveling to accommodate changes in the slide position and the workpiece weight. Some machines are built on a solid granite base, other machines use a solid cast metal base. New designs should be run through a computer simulation and finite element analysis to determine the machine stiffness and natural frequencies. Hydrostatic supported spindles are required for accuracy and repeatability from revolution to revolution. Air bearings are used to lower heat generation and to avoid vibration from the hydraulic supply pump. Both systems can provide rotational accuracies below 10 micro-inches. All motors and drive mechanisms must be dynamically balanced and isolated to eliminate vibration between the tool and the workpiece. The machine slides should give smooth repeatable motion between tool and spindle for control to one micro-inch or less. Technical Rationale: Precision diamond turning and other advanced production techniques are gradually replacing conventional lens grinding and polishing procedures because these methods can produce accurate optics more rapidly than traditional methods and because they can produce optical elements such as diffractive and hybrid systems that are not producible by previous methods. The newer optical elements have improved weight-efficiency, reliability, ruggedness and superior precision if machined in a carefully controlled environment. References Benjamin, R. J.: Diamond Machining Applications and Capabilities,\" SPIE Vol. 433, pp. 24-31, August 1983. Donaldson, R. R. and S. R. Patterson: Design and Construction of a Large Vertical Axis Diamond Turning Machine,\" SPIE Vol. 433, pp. 62-67, August 1983. Dow, Thomas A.: Third Annual Report on Precision Engineering SR0154,\" Precision Engineering Laboratory, North Carolina State University, Raleigh, NC, 1986. Dow, Thomas A.: \"Precision Engineering Center Annual Report, 1986\", Precision Engineering Laboratory, North Carolina State University, Raleigh, NC, 1986. Drescher, Joseph Dean: Tool Force Measurement in Diamond Turning,\" Department of Mechanical and Aerospace Engineering, A Thesis Submitted to the Graduate Faculty of North Carolina State University, Raleigh, NC, 1989. Johnson, E. E. and M. E. Curcio: Production Diamond Machining of Optics,\" SPIE, Vol. 433, pp. 37-45, August 1983. Krauskopf, B.: Diamond Turning: Reflecting Demands for Precisians,\" Manufacturing Engineering, Vol. 92, No. 5, pp. 90-100, May 1985. Krauskoph, B.: At the Cutting Edge: Ultra Precision Machining,\" Manufacturing Engineering, Vol. 91, No. 4, pp. 66-68, April 1984. Rohorer, R. L.: Update on Precision Machining at Los Alamos,\" SPIE Vol. 433, pp. 107-111, August 1983. Saito, T. T.: Diamond Turning of Optics: The Past, The Present, and the Exciting Future,\" Optical Engineering, Vol. 17, No. 6, pp. 570-573, November-December 1978. Sanger, G. M.: Optical Fabrication Technology, The Present and Future,\" SPIE Vol. 33, pp. 2-18, August 1983.","Lesson ID":755}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1251; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: The benefits of implementing these reliability practices for instrumentation system and related sensors are: (1) consistent performance and measurement results, (2) minimum need for continuous or periodic calibration, (3) avoidance of and resistance to contamination, and (4) reduced necessity for repair or replacement in repeated usage. Implementation Method: Introduction: Close attention to design details, precision craftsmanship, and an integrated approach to design, manufacturing, testing, installation, and operations are paramount to sustained accuracy and reliability of performance in launch vehicle and propulsion system instrumentation and related sensors for aerospace applications. Instrumentation systems and their related sensors have reached a high degree of maturity, and preferred practices have evolved in recent years which will ensure high reliability if meticulously followed throughout the life cycle of the instrumentation system. Design Practices: During the preliminary design, critical design review, and initial development phases, the integrated design and concurrent engineering processes have proven to be essential in producing instrumentation that will continue to perform reliably in repeated and long term usage. Instrumentation systems should be planned and designed in close connection with and parallel with the design and analysis of the principal systems and subsystems they are intended to monitor, measure, and control. Sensor vendors and suppliers must be an integral part of the design team for effective coordination and communication. Error budget analyses and metrology considerations are considered up front in the design process. Designing the instrumentation system and its components for contamination-free manufacturability and ease of inspectability is vital. Calibration considerations and compensation methods are developed early in the design process to permit analysis of sensor shift and drift, and to provide a means of predicting and adjusting for both anticipated and unanticipated variances from nominal sensor performance. Sensors, connectors, and wiring are designed to avoid the potential of contamination creation or entrapment, damage during removal and refurbishment, misidentification, leakage, solder wire fatigue failure, electrical shorts, insulation breakdown, or vibration-induced deterioration. Testing and Verification Practices: Careful analysis of all instrumentation system design requirements and development of comprehensive test and verification plans help ensure that all instrumentation requirements are thoroughly verified in testing. For manned missions, continued testing and retesting of sensors and other components on a sampling basis from each production lot is required to ensure that delivered parts are continuously meeting standards. Experience has shown that careful attention must be given to any rework processes, and that reworking of lead wire channels should be avoided. Source control drawings are established to ensure that manufactured items conform exactly to those of the qualified parts. Leak checks are performed on all sensor welds. Manufacturing and Assembly Practices: Closely controlled manufacturing and routing procedures have proven to be essential in the manufacturing and assembly of sensors as well as the installation and testing of instrumentation systems. Inspection points are added during pre-assembly or partial assembly steps if inspection would be difficult at later steps in the process. Inspection steps are added prior to any cavity closeout, and prior to the use of coatings, sealants, or potting compounds that could mask contaminants. Potting compounds for connector terminals, printed wiring boards, or connector boards are formulated, installed, and inspected to eliminate voids and potential resulting failure in a dynamic vibration environment. Inspection for contamination is conducted following secondary machining operations and prior to the assembly of machined parts. Magnification is specified for all inspection operations during manufacturing and assembly. Handling containers, tooling, and support equipment that will come into close contact with the flight hardware is meticulously cleaned and closely controlled during manufacturing and assembly. Alternate rework procedures are evaluated and acceptance or rejection criteria for these rework procedures are developed. Heat sinks are provided in tooling for electron-beam weld joints. High temperature solder is used to improve strength under elevated temperature environments. Changes to Instrumentation Systems and Sensors: Changes to instrumentation systems and sensors are subjected to certification through analysis, by similarity, through laboratory verification, and by hot fire testing on the selected launch vehicle, propulsion system, or component. A stress analysis accompanies any change in configuration to ensure that the resultant component or system is at least as strong, if not stronger, than the original. Resulting improvements in material properties, reduction in weight, and improvement in reliability are verified through analysis. A dynamic evaluation of modified configurations is conducted to identify changes in resonant frequency and load capability. Verification of changes by similarity is based on hot fire experience of sensors or other instrumentation system components with identical features. Laboratory testing to verify changes includes verification of diaphragm burst pressures (pressure sensors, for example), case structure burst pressures, and leak tests. Hot fire verification includes the testing of one sensor in each vibration zone (as in the SSME) and multiple long duration tests in each planned sensor location. General Practices for Instrumentation Sensors (Transducers) in Long Lifetime, Refurbishable or Reusable Vehicles: Selected pressure and temperature transducers are capable of lifetimes in excess of 10 years. Flow meters have less life capability, but meters without moving parts and operating in an environment of low contamination and corrosion are capable of long life. Humidity, oxygen, and carbon dioxide sensors are life limited, requiring periodic maintenance actions such as cleaning and replacement of cartridges. A prime problem with transducers is the lack of long-term stability (freedom from drift). One solution to this problem lies in making the total transducer dimensionally stable over long periods of time. Accordingly, it is important to minimize the use of nonmetallic materials and to employ and control processes that yield parts in a stress free condition. Long term stability (and process control) must then be demonstrated through testing of the assembled transducer under appropriate environmental conditions such as temperature cycling. A second solution is to provide sensitive and pre-calibrated ground-based software that will detect unpredictable sensor drift and adjust the software to compensate for this drift where possible. However, this process can yield an increased uncertainty of the measurement because the instrument, has in effect, been recalibrated through a process that could have less accuracy than the original calibration standard. If the reference drifts, this uncertainty grows with time. There is more to be gained from correction of unpredictable drift if a cross check can be performed with a statistically significant number of instruments. Cross checks are of great value for determining when an instrument has drifted outside the allowable tolerance band. When this occurs, the instrument can be replaced or calibrated as required by corrective maintenance. A well-constructed test program provides the best assurance that a transducer will perform satisfactorily in a long-life application. Unfortunately, the lead time available from selection of a transducer to commitment of the transducer to service may be only a fraction of the time required for a comprehensive test program. Therefore, transducers should be chosen where such data has already been acquired. Long-life transducer applications fall into two broad classifications: open-loop and closed-loop. Open-loop applications only provide information regarding the performance of a system. Closed-loop applications involve a control function to regulate a system based upon transducer output. Transducer failures in open-loop applications result in uncertainty about the condition of the system, while similar failures in closed-loop applications of transducers are more critical from the standpoint of failure effects. They require greater attention to the factors influencing reliability and life. In general, redundancy techniques do not provide solutions to transducer problems. Active redundancy cannot provide a solution if a known life limiting mechanism exists in the transducer. Multiple potentiometer wipers, for example, exposed to the same wear, may fail within the same time span. Standby redundancy is generally not feasible. In standby redundancy a non-active transducer is protected from the failure producing condition until the first transducer has failed. Applications involving standby redundancy are severely restricted by size, weight, and the complexity of devices required to switch from the active to the standby transducer. Technical Rationale: Each Space Shuttle Solid Rocket Booster (SRB) has 65 measurements during flight to monitor parameters such as chamber pressure, actuator positions, temperature, and vibration. In addition to these measurements, there are 142 i\u0300eventi\u0302 measurements that are telemetered back to earth for each SRB. Therefore, for each Space Shuttle flight, the SRB contributes over 400 channels of telemetered data. Each Space Shuttle Main Engine (SSME) contributes 66 more channels of telemetered data, making a total of 466 channels of telemetered data for the reusable propulsion system components of the Space Shuttle. In the Critical Design Review of the SSME pressure sensor, which is only one of the many sensors used in a Space Shuttle flight, fourteen design changes and a number of process changes were identified to reduce contamination and to improve the reliability of this sensor alone. These design and process changes implemented many of the practices described in this document, and a much higher reliability of the resulting modified sensor is expected. The changes involved sensor body, wiring, potting materials, manufacturing methods, a slightly revised configuration, increased strength, and improved inspectability. References: Solid Rocket Booster Instrumentation Program and Components List, Report No. 16A00103, Marshall Space Flight Center, AL, March 15, 1983. SSME Flight Measurement Location Document, Revision D, Rockwell International, Rocketdyne Division, Canoga Park, CA, May 1991. Critical Design Review of Eaton SSME Pressure Transducer, Rockwell Aerospace, January 31, 1995. Space Station Furnace Facility Metrology Plan, NASA\/MSFC Astrionics Laboratory, November 1994. \"Long Life Assurance Study for Manned Spacecraft Long Life Hardware,\" Report # MCR-72-169, Martin Marietta Corporation, September 1972.","Lesson ID":734}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1253; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Long-term spacecraft and propulsion system compatibility in near earth orbital environment has been demonstrated by several experimental test flights. This thruster system is currently being incorporated into the new series of Martin Marietta satellites as well as a new series of military reconnaissance satellites. The benefits are a decrease in propulsion system weight, a potential reduction in mission cost, and an increase in orbital lifetime and satellite reliability. Implementation Method: Electrothermal (arcjet) engines and thrusters have been around for the past thirty years. It has only been in the last ten years that these devices have gained popularity due to the decrease in weight of the power conditioning systems and improved performance of the thrusters. Lewis Research Center and Olin Aerospace Corporation are jointly working on several varieties of low power arcjet thrusters for use as North-South stationkeeping thrusters for satellites. The mechanics of electrothermal propulsion is shown in the schematic of Figure 1. Propellant is pumped into a chamber where it is passed through an arc and electrically heated. This hot gas is then thermodynamically expanded through a nozzle and accelerated to supersonic speeds. Exhaust velocities of 1000 to 5000 m\/sec have been produced with thrust ranges of 0.01 N to 0.5 N.1 [D] [D] Several areas of development at Lewis Research Center in cooperation with outside vendors, have focused on the advancement of electrothermal propulsion and integration of this into commercial and military satellites as a reliable maneuvering propulsion system. These areas include investigations into new propellants, low power capabilities, and advanced power processing. Propellant considerations Current propellant considerations for north-south stationkeeping have been ammonia, hydrogen, and hydrazine. The ideal propellant for arcjet engines is one which can be stored easily, has a low atomic mass, and favorable thermodynamic conditions during heating and expansion. The chart below shows the advantages and disadvantages for the various arcjet thruster propellants. Table 1. Electrothermal Propellant Considerations2 Electrothermal Propellants Advantages Disadvantages Hydrogen (H2) High specific heat and thermal conductivity. Difficulty in storage. Suffers from frozen flow losses in the nozzle expansion. Ammonia (NH3) Liquid phase does not require refrigeration. Heavy molecule which dissociates into low-molecular-mass constituents which introduces frozen flow loses. Hydrazine (N2H4) Can be dual used for a combination propulsion system on satellites. Can be easily stored. Chemical erosion problems are intensified at higher specific impulses. Heat transfer problems at the nozzle and chamber. Power Processing Development The current research and testing of arcjet thrusters is the low power (1-2kW) range. NASA LeRC and Olin Aerospace are investigating the use of a low power arcjet thrusters on the new generation of satellites. Early work on low power arcjet thrusters used a ballasted DC power supply hich transitioned the arc to steady-state operating conditions4. This caused significant electrode erosion and nonuniform arcs. These problems were overcome through changing the geometry of the electrode, providing vortex flow stabilization, and development of a pulse-width modulated power processor with limiting current circuit for startups.5 These improvements have lead to a 1000h\/500 cycle lifetest which demonstrated long-term, reliable, non-damaging arcjet operation. Also demonstrated was an 891 hr qualification lifetest of a 1.8 kW hydrazine arcjet with 918 restarts and a specific impulse of 520s.6 The 1.8 kW hydrazine has been developed and approved for use on Lockheed Martin Series 7000 geosynchronous telecommunications satellites to provide a highly efficient means of north\/south stationkeeping. AT&T's Telstar 401 spacecraft was the first application of Lockheed Martin's Series 7000. Technical Rationale Due to the gravitational perturbations caused by a combination of forces from the sun\/moon\/earth system, most geosynchronous satellites require north\/south (N\/S) stationkeeping. For a satellite to maintain a positional accuracy of between 0.05 and 0.1 degrees, a delta velocity of approximately 49 m\/s\/year must be added in the north or south direction, perpendicular to the orbital plane.7 The propellant requirements for N\/S stationkeeping can represent up to 80% of the mass of total propellant and up to 20% of the on-board quotwetquot mass of the satellite. Therefore to improve the efficiency of stationkeeping class thrusters various designs and improvements have been developed. The latest and most efficient thruster design developed thus far is the hydrazine arcjet system. Table 2 compares the use of hydrazine in various thruster configurations. The high specific impulse and the decrease in propellant weight add to the arcjet's competitive edge over other propulsion thruster systems. Table 2. N\/S stationkeeping propellant mass comparison for a 12 Year, 1700 kg dry mass satellite.7 Thruster Systems Typical Thrust Level (N) Specific Impulse (lbf-s\/lbm) N\/S Stationkeeping Propellant (kg) Hydrazine (N2H4) 0.4-20 220 532 Bipropellant (MMH\/N2H4) 20-40 302 373 Resistojet (N2H4) 0.2-0.4 302 373 Arcjet (N2H4) 0.15-0.3 520 207* *Does not include dry mass penalty of approximately 20 kg. The hydrazine arcjet not only outperforms existing propulsion options, it also has several key advantages over other electric propulsion options. The performance and economic edge is derived from three major areas. The first is that arcjets have a relatively higher thrust than other electric propulsion devices which reduces duty cycles and battery demands. Second, the arcjet's use of hydrazine propellant allows commonality and simplicity in the feed system. Third, the arcjet system is relatively compact in size and has a very high thermal efficiency which provides relatively simple structural and thermal spacecraft integration. While trade studies for different satellite masses and lifetimes will show a greater or lesser advantage for the arcjet, the conclusion reached is the same: arcjet thrusters will have a major impact on reducing propellant mass and increasing the economic return on investment for many commercial satellite systems. References Sutton, George P. , Rocket Propulsion Elements: Introduction to the Engineering of Rockets, John Wiley & Sons, 1992 Jahn, Robert, Physics of Electric Propulsion., McGraw-Hill Series in Missile and Space Technology, McGraw-Hill Book Company, 1968 Smith, W.W., Smith, R.D.,Yano, S.E., quotLow Power Hydrazine Arcjet Flight Qualificationquot, IEPC-91-148, October 1991. Smith, R.D., Roberts, C.R., Davies, K. and Vaz, J., quotDevelopment and Demonstration of a 1.8 kW Hydrazine Arcjet Thrusterquot, AIAA-90-2547, July 1990. Curran, Francis M., Sovey, James S.,and Myers, Roger M.,quotElectric Propulsion: An Evolutionary Technologyquot, Acta Astronautica Vol. 29, No. 9 pp. 651-665, 1993. Sovey, James S., Curran, Francis M., Haag, Thomas W., Patterson, Micheal J., Pencil, Eric J., Rawlin, Vincent K., quotDevelopment of Arcjet and Ion Propulsion For Spacecraft Stationkeepingquot, NASA TM-106102. Sovey, James S., Pidgeon, David J., quotAdvance Propulsion For LEO and GEO Platformsquot, AIAA 90-2551, July 1990.","Lesson ID":736}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1249; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. This ESD Control Practice significantly enhances mission reliability by protecting susceptible flight and critical flight support electronic parts and related hardware from damage and\/or degradation caused by ESD and Induction Polarization Charge (IPC) during the prelaunch phases of the mission. Implementation Method: NHB 5300.4 (3L) \"Requirements for Electrostatic Discharge Control \" (Reference 1) specifies the NASA requirements for ESD avoidance and control. It describes basic considerations and requirements for ESD control programs including responsibilities of NASA Installations for invoking ESD control programs. GSFC Document No. P-303-840 \"Electrostatic Control Program\" (Reference 2) describes the ESD control program that has been established by GSFC for its spaceflight projects. The GSFC program incorporates the ESD requirements of Reference 1. The Reference 1 and 2 documents as well as this practice do not include ESD control requirements and programs for electrically initiated explosive devices. Special requirements for the control of these devices exist at the various NASA centers. This ESD Control Practice describes the procedures and controls whereby ESD sensitive components and devices are received, distributed, assembled, disassembled, handled, tested, repaired, and stored at GSFC. This practice applies to spacecraft, launch vehicles, mission peculiar equipment, mission-essential support equipment and elements thereof; when invoked contractually in procurements. The Practice includes many elements with many details. This description of the Practice can only cover the highlights with limited details. Refer to Reference 2 for complete details and a list of references to ESD control documents. The following are the primary features and requirements of this Practice. Quality Assurance Responsibilities for the ESD Program: ESD trained and certified personnel are assigned to support each project and are responsible for the following items: 1). Follow established procedures to verify that all ESD requirements are complied with in applicable work areas. 2). Certify the adequacy of ESD-controlled areas and grounded work stations prior to their use. 3). Ensure the use of protective personnel clothing and proper personnel grounding at all locations where ESD sensitive components and devices are handled. 4). Ensure that all personnel with access to ESD controlled areas and who handle ESD sensitive components and devices have been trained and certified in accordance with Reference 2. 5). Perform audits to assure the integrity of ESD-controlled areas. 6). Verify that all documentation including drawings and work instructions contain ESD marking precautions and handling procedures as appropriate. 7). Verify proper ESD markings or labels on ESD dissipating or shielding boxes\/carriers\/bags containing ESD sensitive components and devices, printed circuit boards or flight ready hardware with ESD sensitive components and devices. 8). Ensure that purchase documentation includes ESD requirements as appropriate. 9). Ensure that all handling of ESD sensitive components and devices are performed in ESD controlled areas. 10). Prepare and maintain internal records of each certification and audit to ensure compliance with the ESD Control Program. 11). Provide internal reports to the project and to the AMO with results and recommendations from audits. 12). Ensure that corrective actions are initiated for all NASA deficiencies noted during audits and certifications. Responsibility for ESD Work Sites and Spaces and for Workstations: The organizations responsible for the facilities where work\/test sites or spaces are assigned are responsible for the implementation of the ESD Programs in their facilities. The cognizant System\/Subsystem Electrical Engineer is responsible for the initial setup of ESD approved work stations. ESD Training of Personnel: All personnel with access to ESD-controlled areas and those who handle ESD sensitive components and devices receive training from an approved NASA training Facility. Additionally, those with any management or quality assurance responsibilities for ESD sensitive components and devices also receive training. This includes project management personnel, engineering, test, and integration personnel, acquisition and quality assurance personnel, field engineers for installation and maintenance where appropriate, and production, material handling, and stockroom personnel as appropriate. Janitorial and facility maintenance personnel receive on-site training and\/or facility\/project procedures as needed. Each individual attends one of several specific courses appropriate for his\/her job assignment. All certified personnel must have their certification card with them whenever they are performing tasks which require ESD control. Certification must be renewed every two years. ESD Control Requirements: A long list of ESD control requirements too long to include herein is imposed when ESD sensitive components and devices are handled. The following is an outline of these requirements. Refer to Reference 2 for complete details. Control of ESD-controlled areas including personnel access and relative humidity. Control of ESD work surfaces and floors. Receiving and shipment of ESD devices. Equipment and materials used in the protection and handling of ESD devices. Protective packaging materials. ESD Audits: ESD-certified AMO personnel conduct audits of the facilities and the personal and work station equipment handling ESD devices in accordance with Reference No 2. These audits are scheduled in accordance with the schedule shown in Table 1. TABLE 1. ESD CERTIFICATION AND PERIODIC INSPECTION SUBJECT INITIAL CERTIFICATION CONTINUOUS EACH WORK SHIFT MONTHLY SEMI-ANNUALLY ANNUALLY Work Surface Resistivity (Including ESD Dissipative Mats) X X Work Surface Grounding X X Work Surface Solvent Resistance X X Work Surface Static Charge Dissipation X X Wrist Strap Release Force X X Wrist and\/or Heel Strap Continuity X X Tool and Equipment Grounding X X Stool and Chair Grounding X X Facility Earth Ground X X ESD Controlled Area Metal Frame EntryDoors X X Humidity (RH) X X Certification of Electrostatic Field Survey Meter X X Monitoring Static Levels X X Nuclear Air Ionizer Effectiveness X X Corona Discharge Air Ionizer Effectiveness X X Check both Ionizers for: Ion Balance EMI Radiation X X X X Soldering Iron Tip Grounding X X Cart, Wagon and Tram Grounding (When Used) X X Temperature Chambers X X Personnel Garmets (Testing Physical Condition with an Eslectrostatic Field Survey Meter) X X Part of the audit is monitoring the testing of the equipment and recording the test measurements and the electrostatic voltage readings of the ESD-controlled work stations and areas. Records are kept of all ESD audit data, corrective actions, written reports on corrective actions, and follow up ESD audits conducted after corrective actions have been completed. Formal reports are prepared from these records and include comments\/observations on any ESD-control deficiencies and suggestions for preventing recurrence. Technical Rationale: The generation of triboelectric and electrostatic charges are a common cause of damage and\/or degradation to unprotected ESDS devices. A carefully devised and implemented ESD control program can provide protection from this damage and\/or degradation. References NHB 5300.4 (3L), Requirements for Electrostatic Discharge Control (Excluding Electrically Initiated Explosive Devices) GSFC Document No. P-303-840, Electrostatic Discharge (ESD)Control Program","Lesson ID":732}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1250; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. This practice significantly enhances the probability of mission success by ensuring that problems\/failures occurring during ground test are properly identified, documented, assessed, tracked and corrected in a controlled and approved manner. Another benefit of the PFR procedure is to provide data on problem\/failure trends. Trend data may then be analyzed so that errors are not repeated on future hardware and software. Implementation Method: A formal procedure (Reference 1) establishes the GSFC system for the identification and documentation of Problem\/Failure Reports (PFRs), the data collection and monitoring of PFRs, the risk assessment and rating of problems\/failures, and the Project and Center management approvals of corrective actions. For hardware, the procedure begins with the first application of power (or first test usage for mechanical items) at the lowest level of assembly of qualification or flight configuration hardware. For software, the procedure begins with the first test use of the software item with a hardware item of the mission system at the component level or higher. Identification and Documentation of PFRs: Anyone with knowledge of a problem or failure may initiate a PFR. PFRs are generated for any departure from a design, performance, testing, or handling requirement that affects the function of flight equipment, ground support equipment that interfaces with flight equipment or that could compromise mission objectives. All GSFC generated PFRs begin as problem records identified on applicable Certification Logs (Ref. 3), Problem Records (Ref. 4) and work orders. After a PFR occurrence, the Certification Log and Work Order, as applicable, are used to document, define and control any repairs, fixes, or modifications that may be performed on the hardware or software. PFRs are generated and entered electronically into a PFR database, normally accessible on designated personal computers in hardware assembly and test areas. The PFR database program's on-screen instructions indicate certain required data that is to be provided, and automatically assigns a PFR number for traceability. PFRs can be prepared manually on GSFC PFR Form 4-2 (Figures 1 & 2) when the PFR database is not available or the system is inoperative. The PFR data on this form is entered into the database at the earliest opportunity following the problem\/failure, but must be filed within 24 hours. All PFRs, including both hardcopy and electronic formats, are forwarded to the Project Office for routing to designated personnel. Contractor-generated PFRs are provided to the Project Office in accordance with applicable contract requirements. PFRs generated in-house or at launch sites are provided directly to the Project Flight Assurance Manager (FAM) and the Systems Assurance Manager (SAM) or their designees, as appropriate. The Project FAM\/SAM or their designees enter all the hardcopy PFRs that they receive into the GSFC PFR database. Data Collection and Monitoring of PFRs: The FAM\/SAM provide copies of all PFRs to the members of a Failure Review Board (FRB) that is established and authorized by each project to investigate, analyze, and determine the cause of each problem\/failure and the appropriate disposition of each PFR. The FRB consists of the following project personnel as a minimum: The project FAM\/SAM or designees (serves as chairman) The Project Manager or designee The cognizant engineer(s) responsible for the failed item(s). Continuation of operations or immediate initiation of troubleshooting operations after the occurrence of a problem or failure is at the discretion of the cognizant engineer and other members of the FRB as appropriate and is based on the following factors: The number and severity of problem\/failure occurrences during the operation in question; The degree of confidence in ability to quickly diagnose the source or cause of the problem or failure; The potential risk to hardware or software posed by continuing the operations after the problem or failure; The consequences of terminating an operation in which a failure has occurred (e.g., thermal vacuum testing). Risk Assessment and Rating of Problems\/Failures: The residual risk of each PFR must be considered by the FRB before it can be considered for closure. A two-factored risk rating system is used. The first rating factor identifies the impact that the problem\/failure would have on the flight hardware and\/or software performance capabilities if it occurred during the mission. Redundancy is ignored in establishing this rating. The failure effect ratings are illustrated in Table 1. Table 1. PFR Failure Effect Ratings RATING FAILURE EFFECT 3 Catastrophic or major degradation to mission, system or instrument performance, reliability or safety 2 Moderate or significant degradation to mission, system or instrument performance, reliability or safety, defined as: a) Appreciable change in functional capability b) Appreciable degradation of engineering or science telemetry c) Causing significant operational difficulties or constraints d) Causing reduction in mission lifetime 1 Negligible or no impact on mission, system, or instrument performance, reliability or safety. The second rating factor identifies the confidence in understanding both the cause(s) of the problem\/failure and the effectiveness of the resulting corrective action. The failure corrective action ratings are shown in Table 2. Table 2. PFR Failure Corrective Action Ratings RATING FAILURE CORRECTIVE ACTION 1 The root cause of the problem\/failure has been determined with confidence by analysis and\/or test. Corrective action has been determined, implemented and verified with certainty. There exists no credible possibility of problem\/failure recurrence. 2 The root cause of the problem\/failure has not been determined with confidence. However, some corrective action has been determined, implemented and verified with certainty. There exists some possibility that the problem\/failure may recur. 3 The root cause is considered to be known and understood with confidence. Corrective action has not been determined, implemented or verified with certainty. There exists some possibility that the problem\/failure may recur. 4 The root cause has not been defined with certainty. Corrective action has not been determined, implemented nor verified with certainty. There exists some possibility that the problem\/failure may recur. Any PFR with a failure effect rating of quot2quot or quot3quot, coupled with a failure corrective action rating of quot3quot or quot4quot is identified as a Red Flag PFR indicating significant residual risk associated with the problem\/failure in question. GSFC Project Manager signatures are required on all red flag PFRs. No delegation of signature authority is permitted. All red flag PFRs are highlighted at GSFC Project Flight Assurance Reviews. Project and Center Management Approval of Corrective Actions: A PFR is considered for closure when the FRB determines that appropriate and sufficient investigation of the cause of the problem\/failure has been completed and that commensurate corrective action has been completed and properly documented. The following signatures are required to formally close a PFR: The Contractor Program\/Project Manager and Contractor QC for PFRs initiated by off-site GSFC contractors The GSFC FRB chairman The GSFC Project Manager or his delegated FRB representative. Red Flag PFRs, defined above require the signature of the Project Manager. Technical Rationale: This practice ensures that all problem\/failure occurrences including minor glitches are fully reported and dealt with as appropriate in a formal procedure with Project and GSFC management oversight and approval. References GSFC Flight Assurance Procedure, No. FAP P-303-849, quotProblem\/Failure Reportingquot Guidelines for Standard Payload Assurance Requirements (SPAR) for GSFC Orbital Projects The GSFC Certification Log, FAP P-303-820 Problem Record Items, GSFC, FAP P-303-845 NASA NHB 5300.4 (1A-1) ReliabilityProgram Requirements for Aeronautical and Space Systems Contractors (January 1987) Reliability Preferred Practice PD-AP-1304, Problem\/Failure Report Independent Review\/Approval Reliability Preferred Practice PD-AP-1305, Risk Rating of Problem\/Failure Reports Reliability Preferred Practice PD-ED-1232, Spacecraft Orbital AnomalyReport (SOAR) System Reliability Preferred Practice PD-ED-1255, Problem Reporting and Corrective Action System [D] Figure 1. GSFC PFR Form 4-2: Problem\/Failure Report (Click on Image for .pdf file) [D] Figure 2. GSFC PFR Form 4-2 (cont.): Instruction Sheet for Problem\/Failure Report (Click on image for .pdf file)","Lesson ID":733}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1252; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Reliable materials can be selected for aerospace applications by choosing those materials that have demonstrated reliability in carefully controlled laboratory testing and in operational space flights. Use of the Materials and Processes Technical Information System (MAPTIS) data base by system designers will ensure that materials that have demonstrated reliable performance in flight and test experience are the first to be considered in new or revised designs. Engineers will then have the confidence in their selections, knowing that the data on which their decisions have been made have been thoroughly validated. Implementation Method: Introduction: The Materials and Processes Technical Information System (MAPTIS) resides on a DEC Alpha 7620 Computer located at the George C. Marshall Space Flight Center in Huntsville, Alabama. It can be accessed through the Internet after assignment of an account number by completing a user request form which can be obtained from MSFC. The MAPTIS data base contains properties and test histories on both metals and nonmetals. Searches of the database can be accomplished by material code, material specification, manufacturer, or by a string or phrase search. Materials are rated based on criteria in NASA Handbook 8060.1C [reference 1] , Marshall Space Flight Center Specification 250 [reference 2] , Marshall Space Flight Center Specification 522 [reference 3] , and SP-R022A [reference 4] . For metals, information is included in the database on corrosion, stress corrosion cracking, and compatibility with: (1) gaseous oxygen, (2) liquid oxygen, (3) nitrogen tetroxide, (4) hydrazine, (5) low pressure hydrogen (<450 psi) and (6) high pressure hydrogen (>450 psi). In addition MAPTIS contains: a material code index, an alloy designation, the heat treatment, material specifications, and the generic identification and form. The database elements for nonmetals includes information on flammability, toxicity, thermal vacuum stability, and compatibility with: (1) liquid oxygen, (2) gaseous oxygen, (3) nitrogen tetroxide, (4) hydrazine, (5) liquid hydrogen, and (6) hydraulic fluid. Nonmetallic data is included for adhesives, elastomers, plastics, tapes, tubing, potting compounds, coatings and lubricants. Material Selection: The materials selection portion of MAPTIS is a design selection tool that can also be used for material surveys and design reviews. It is based on comprehensive storage of test data and handbook information on metals, nonmetals, and standard parts. It includes a thermal vacuum stability data base which is a compilation of vacuum outgassing data from tests conducted at MSFC and various other organizations including the White Sands Test Facility, the Goddard Space Flight Center, the European Space Agency, the Jet Propulsion Laboratory, and others. Data elements included are total mass loss, residual mass loss, volatile condensible material, pressure, temperature, duration, and test facility description. An atomic oxygen data base includes the effects of atomic oxygen on various materials, guidelines for selection of materials based on this parameter, and protective techniques. A special database included in MAPTIS is an analytical tool to evaluate toxic outgassing data. The analysis provides a method for determining if the material or the assembled article meets the requirements of NHB 8060.1C acceptance criteria including the comparison of projected contaminant concentrations with maximum allowable concentrations. The material selection function is a vital part of achieving high reliability for long duration space missions or missions on which the materials encounter severe environments. Material Properties: The material properties portion of MAPTIS contains comprehensive online materials information including physical and mechanical properties. Materials are listed specifically by designation, trade name, and manufacturer. The metallic materials portion includes such information as mechanical properties, design allowables, variations with environment and temperature, graphical and tabular tensile and compressive yield and ultimate strengths, elongation, fatigue, stress-strain, and elastic modulus. Physical properties such as density and thermal expansion are also included, as are chemical, thermal, and electrical properties. Many of these same properties are also included for nonmetals with additional information on peel, tear, and impact resistance; lap shear, creep, and resilience. Physical and chemical properties such as viscosity, hardness, color, formulation, flashpoint, chemical and environmental resistance, and pH are included in the data base. For nonmetals, processing parameters such as extrusion or molding temperatures, pressures, and times; cure conditions, mix ratios, rise, and demold times are also included. The types of materials contained in the nonmetals portion of the database are: plastics, nozzle materials, coatings, tapes, adhesives, and lubricants. Verification and Control: The MAPTIS is also used to obtain information on where the materials listed have been used, to determine the history of hardware and material selection rationale, and to correlate U.S. material designations with those of foreign material designations. The \"where used\" data aids in the identification, tracking, and control of all material usage as a function of part number, environment, contractor, and\/or project. This information is available for the SRM\/SRB, External Tank, Space Shuttle Main Engine, and Spacelab programs. The data includes configuration information, application information, materials usage information, and support information. Configuration information includes the associate contractor, the detailed drawing numbers and part numbers, and the next assembly drawing and part numbers for the device, part, or structure that used or uses the material. Application information includes test data, fluid systems compatibility, environmental conditions to which the item(s) have been subjected, evaluation and analysis rationale, and process specifications. Materials usage and support information includes: (1) all materials by designation, code, and specification; (2) an overall material evaluation rating; (3) a record of the weight, surface area, and thickness of nonmetals; (4) a record of material usage agreements; and (5) material specifications. These success stories of materials which performed in an acceptable manner in real programs, as well as in laboratory tests, are indispensable inputs to the aerospace designer. Structural Materials Failure Analysis Database: It is not only the success stories that are important inputs to the designer, but also an in-depth knowledge of the failures that have occurred and why they occurred is another vital link to high reliability. The NASA-wide failure analysis data base for structural materials is also a part of MAPTIS. It provides fast and easy access to selected NASA and contractor reports on failure investigations for structural materials and processes that have been conducted over a period of 35 years. The database fulfills the stated requirements of personnel surveyed at NASA centers, the Department of Defense, and contractors who need to be able to retrieve data quickly, cross reference large quantities of technical information, and share results in a standard format between organizations. The database presents failure analysis information in a simple format. It is used by engineers and managers to get a head start on investigations, minimize duplications of effort, use resources effectively, and ensure that problems have been resolved or can be avoided. There are approximately 900 records in the database at this writing, and the information is continuing to be updated and amended as new information becomes available. The database has nine identifying data fields plus an abstract averaging about 100 words to describe the nature of the failure, its cause, and corrective actions. Failures are categorized into 15 categories as follows: Critical Defect Growth Corrosion Fatigue Corrosion Creep High Cycle Fatigue Hydrogen Embrittlement Hydrogen Environment Embrittlement Low Cycle Fatigue Liquid Metal Embrittlement Overload Oxidation Stress Assisted Grain Boundary Oxidation Crack Stress Corrosion Cracking Stress Rupture Other Knowledge of the types of structural failures that have been encountered, the details of the failure analysis, and the corrective actions taken are essential elements in the material selection for systems which must perform reliably. Project Support Data Base: MAPTIS contains a project support data base designed for both external and internal support to the major ongoing NASA and MSFC projects. The project support data base includes an electronic bulletin board, lead engineer data records, a standards data base, specifications status, and correspondence status. The electronic bulletin board provides a method for rapid dissemination and exchange of materials and processes news, developments, and problems NASA-wide. Lead Engineers are listed for each project. A standards data base lists all NASA specifications and standards. The specifications tracking data file provides evaluation or approval status, disposition, description and effectivity for material and process specifications, operations, and procedures reviewed and evaluated by MSFCi\u0301s Materials and Processes Laboratory. Technical Rationale: Historically, materials and their properties have been inextricably tied to the ability to withstand severe environments and to provide hardware that will operate successfully in multiple missions. An intimate knowledge of the materials, their composition, their reaction under various operating conditions, and their success and failure history will provide the designer with the ability to select the right material for any given task. MAPTIS contains an accumulated body of data and evidence that has been documented over many years and perfected into an electronic access system that is still being updated and growing. Use of this system has become an essential element in the continuing pursuit of the ultimate in reliable space flight systems. References: NHB 8060.1C;\" Flammability, Odor, and Offgassing Requirements and Test Procedures for Materials in Environments that Support Combustion.\" MSFC-SPEC-250A; \"Protective Finishes for Space Vehicles, Structures, and Associated Flight Experiments.\" MSFC-SPEC-522B; \"Design Criteria for Controlling Stress Corrosion Cracking.\" SP-R022A; \"Vacuum Stability Requirements of Polymeric Materials for Spacecraft Applications.\"","Lesson ID":735}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1254; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: The increasing importance of ceramics as structural materials places high demand on assuring component integrity while simultaneously optimizing performance and cost. Components using ceramics can be designed for high reliability in service if the contributing factors that cause material failure are accounted for. This design methodology must combine the statistical nature of strength controlling flaws with fracture mechanics to allow for multiaxial stress states and concurrent flaw populations. The Ceramics Analysis and Reliability Evaluation of Structures (CARES) uses results from MSC\/NASTRAN or ANSYS finite-element analysis programs to evaluate how inherent surface and\/or volume type flaws affect component reliability. Implementation Method: Introduction The unique properties that advanced ceramics have to offer for future commercial industries, propulsion and space related programs are phenomenal, such as high temperature strength, environmental resistance, and low density materials. NASA is dedicating a major effort to propulsion systems that reduce pollution, noise, and fuel consumption while improving reliability and service life. Consequently, research has been focused on improving ceramic material processing and properties as well as on establishing a sound design methodology. Because of the variable severity of inherent flaws, the nature of ceramic failure is probabilistic and optimization of design requires the ability to accurately determine a load component's reliability. Methods of quantifying this reliability and the corresponding failure probability have been investigated and refined at NASAi\u0301s Lewis Research Center. The result of this effort is a public domain computer program with the acronym CARES. The design methodology used by CARES combines three major elements: (1) linear elastic fracture mechanics (LEFM) theory which relates the strength of ceramics to the size, shape, and orientation of critical flaws, (2) extreme value statistics to obtain the characteristic flaw size distribution function, which is a material property, and (3) material microstructure. Inherent in this design procedure is that component integrity is a function of the entire field solution of the stresses and is not based only on the most highly stressed point. In addition, the size of the stressed material surface area and volume affect the component strength. Program Capability and Description CARES is an integrated computer program written in FORTRAN 77 WAT V compiler which uses Weibull and Batdorf fracture statistics to predict the fast fracture reliability of isotropic ceramic components. CARES has three primary functions: (1) to analyze statistically the data obtained from the fracture of simple uniaxial tensile or flexural specimens, (2) to estimate the Weibull and batdorf material parameters using these data, (3) to perform a fast fracture reliability evaluation of a ceramic component experiencing thermomechanical loading. Component reliability is predicted by using elastostatic finite element analysis output from the MSC\\NASTRAN or ANSYS computer programs. The CARES code includes a number of fracture theories to predict material response due to multiaxial stresses. These methods are summarized in Table 1. Weakest Link Fracture Model Size Effect Stress State Effects Compensational Simplicity Theoretical Basis Weibull (1939) Yes Unaxial Simple Phenomenological Normal stress Yes Multiaxial Complex Phenomenological Principle of independent action (1967) Yes Multiaxial Complex Maximum principal stress theory Batdorf: Shear-insensitive (1974) Shear-sensitive (1978) Yes Multiaxial Complex Linear elastic fracture mechanics Table 1. Statistical Fast-Fracture Models Available with CARES The Batdorf method is recommended because it couples LEFM with the Weibull weakest link theory (WLT). The Weibull normal stress averaging method and the principle of independent action (PIA) theories are included for comparison purposes and because of their previous popularity. All the fracture models available of strength distribution. Figure 1 shows the fracture criteria and crack geometries available to the user for both surface and volume distributed flaws. The PIA and Weibull normal stress averaging fracture theories do not require a crack geometry. Batdorf's fracture theory can be used with several different mixed-mode fracture criteria and crack geometries. For coplanar crack extension, CARES uses the total strain energy release rate theory. Out-of-plane crack extension criteria are approximated by a simple semiempirical equation. This equation involves a parameter which can be used to approximate various mixed-mode theories or experimental result. For comparison, Griffith's maximum tensile stress analysis for volume flaws is also included. The highlighted boxes in Figure 1 show the recommended fracture criteria and flaw shapes. [D] Figure 1. Available Failure Criteria and Crack Shapes. (Recommended failure criteria and crack shapes are highlighted) Two version of the code, designed as CARES1 and CARES2, are available. The CARES1 version assumes that stress and temperature gradients within each element are negligible, and, therefore, only element centroidal principle stress is used in the reliability calculations. The CARES2 version takes into account element stress gradients by dividing each brick element into 27 subelements and each quadrilateral shell element into 9 subelements. Subelement centroidal principle stress is then computed and used in the subsequent reliability calculations. CARES2 enables the finite-element model to consist of fewer elements for the same level of convergence to the true solution as CARES1. Input Requirements To control the execution of the CARES program, an input file must be prepared. On the tape or disks provided with the program is a file called TEMPLET INP that can be used to construct an input file for a particular problem. Input to CARES is keyword driven. Data are input by the user under each keyword. An explanation of the input required or a list of input choices is provided next to the keyword. The CARES program requires three categories of input: (1) Master Control Input, (2) Material Control Input, which includes temperature-dependent material data, and, optionally, (3) MSC\\NASTRAN or ANSYS output data files from finite-element analysis. The Master Control Input is a set of control indices that directs the overall program execution. The Material Control Input consists of control indices and either the data required to estimate the statistical material parameters or direct input of the statistical parameter values themselves for various temperatures. This input category includes the choices of fracture criteria and flaw shapes shown Figure 1. The Master Control Input and the Material Control Input are contained in the TEMPLET INP file. The third input category, MSC\/NASTRAN or ANSYS output data files, includes finite-element analysis data files containing the element stresses, volumes\/areas, and temperatures. [D] Figure 2. Block Diagram for Analysis and Reliability Evaluation of Ceramic Components Output Information The first part of the CARES output is an echo of the choices selected (or default values) from the Master Control Input. If a finite-element model reliability analysis is not performed, then CARES proceeds to echo the Material Control Input. If postprocessing of a finite-element model is done, then, for each element, the centroidal or subelement principle stresses with appropriate element area or volume and temperature are listed. The printing of element stress tables in CARES is optional. In addition, two element cross-reference tables are printed. The first table lists the shell element number and gives the corresponding solid element to which it is attached. The second table lists the solid element identification number and lists up to six associated shell element (a brick element could have all of its six faces as external surface). CARES echoes the user inputs for each section of the Material Control Input. If statistical material parameters are directly input, then output pertaining to calculated values of the normalized Batdorf crack density coefficient kb will follow. If statistical material parameters are determined from experimental fracture data, then the output will identify the method of solution, the number of specimens in each batch, and the temperature of each test. In addition, the output echoes the sorted input values of all specimen fracture stresses with proper failure mode identification. Results from the statistical analysis of the fracture data are then printed. The fracture strength and corresponding significance level are listed for detected outliers followed by the estimated statistical material parameters from least-squares or maximum likelihood analyses. The biased and the unbiased values of the Weibull shape parameter, the specimen Weibull characteristic strength, the upper and lower bound values at 90-percent confidence level for both parameters, the specimen Weibull mean value, and corresponding standard deviation are printed for each specified temperature. For censored statistics these values are generated first for volume flaw analysis and subsequently for the surface flaw analysis. The K-S goodness-of-fit test is done for each specimen fracture stress and the corresponding K-S statistics D+, D-, and significance level are listed. Similarly, the K-S statistic for the overall sample set is printed along with the significance level. This overall statistic is the absolute maximum of individual data D+ and D- factors. For the A-D goodness-of-fit test, the A-D statistic A2 is determined for overall population and its associated significance level is printed. The next table of the output contains data to construct K-S 90-percent confidence bands about the Weibull distribution. The table includes fracture stress data, the corresponding Weibull probability of failure values, the 90-percent upper and lower confidence band values about the Weibull line, and the median rank value for each data point. The last table from the statistical analysis section of CARES summarizes the material parameters used in component reliability calculations. These parameters, which are listed as a function of temperature, include the biased Weibull modules, the normalized Batdorf crack density coefficient, and the Weibull scale parameter or the unit volume or unit area characteristic strength, whichever is appropriate. The values printed correspond to the experimental temperatures input and five additional interpolated sets of values between each input temperature. The interpolated parameters are output for checking purposes. Information on the selected fracture criterion and the crack shape is printed as required. If a component reliability analysis with finite-element data is being performed, then tables will be generated to summarize the reliability evaluation of each finite element. One table is provided for volume flaw analysis (solid elements) and one table is given for surface flaw analysis (shell elements) as requested by the user. The tables list the element identification (ID) numbers and the corresponding element material ID, survival probability, failure probability, risk-of-rupture intensity (risk-of-rupture divided by element volume or area), and temperature-interpolated statistical material parameters. Following each table is a list of the 15 most critical risk-of-rupture intensity values and corresponding element numbers. Also included is the probability of failure and survival for the component surface or volume, whichever is appropriate. Finally, the overall component probability of failure and the component probability of survival are printed. Theory and Example For additional information on theory and example of different applications such as statistical material parameter estimation, rotating annular disk and Si3N4 mixed flow rotor, please refer to NASA TM 102369 and other referenced articles on the reference section of the practice. Technical Rationale: The CARES computer program was developed by NASA LeRC's Structural Integrity branch. The branch combines the three disciplines of analytical modeling, mechanical testing, and nondestructive testing to understand and predict the behavior of advanced high-temperature materials, particularly brittle ceramic and inter-metallic matrix composites. CARES is an enabling technology primary created to foster the introduction of ceramic materials in demanding engine environments to achieve breakthrough gains in energy efficiency and emissions reduction. The specific purpose of the project is to transfer and upgrade technology for understanding and predicting the behavior of brittle ceramic materials. To accomplish this, CARES incorporates the capability to design for any component shape and services environment. The resulting software is a comprehensive general-purpose design tool for government, industry, and academia that predicts the probability of a ceramic component failing as a function of its time in service. For the past three years over 100 companies worldwide have obtained the CARES software. As the only general-purpose public domain integrated design program for predicting the reliability of brittle materials in the United States, CARES has tremendous impact on helping U. S. industrial competitiveness. The CARES probabilistic design methodology is necessary for accurate failure prediction and efficient structural utilization of brittle materials subjected to arbitrary stress states. This technology applies to materials such as glass, graphite, and advanced ceramics including silicon nitride and silicon carbide. Many commercial products, such as turbocharger rotors, rocker arm and cam followers, poppet valves, radiant heater tubes, heat exchanges, and prototype ceramic turbines, are widely designed by using the CARES series of software. In addition, these programs are used to design large infrared transmission windows, glass panels for skyscrapers, ceramic packaging for microprocessors, cathode ray tubes, and even ceramic tooth crowns and knee caps. Although similar codes now exist, CARES has two unique features. The code is public domain software and thus readily available. Furthermore, it can be integrated with popular finite element analysis computer programs such as ANSYS, NASTRAN, and ABACUS. Software Release Request Form (.pdf) References: Nemeth, N. N. and Manderscheid, J. M. and Gyekenyesi, J. P., Design of Ceramic Components With the NASA\/CARES Computer Program, NASA Technical Memorandum 102369, 1990. Nemeth, N. N. and Powers, L. M. and Janosik, L. A. and Gyekenyesi, J. P., Designing Ceramic Components for Durability, American Ceramic Society Bulletin, Volume 72, No. 12, December 1993. Research & Technology - 1993, NASA LeRC TM 106376, 1993. Nemeth, N. N. and Power, L. M. and Janosik, L. A. and Gyekenyesi, J. P., Durability Evaluation of Ceramic components using CARES\/LIFE, NASA Technical Memorandum 106475, 1994. Ratajczak, A. F., NASA Software of the Year Award, NASA Tech Briefs, Volume 18, No. 12, December 1994.","Lesson ID":737}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1255; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: The information provided by Proplem Reporting and Corrective Action System (PRACAS) allows areas in possible need of improvement to be highlighted to engineering for development of a corrective action, if deemed necessary. With this system in place in the early phases of a program, means are provided for early elimination of the causes of failures. This contributes to reliability growth and customer satisfaction. The system also allows trending data to be collected for systems that are in place. Trend analysis may show areas in need of design or operational changes. Implementation Method: A closed-loop system that collects, analyzes and records failures that occur is developed. Documented procedures for the analysis of failures to determine their root cause and then the establishment of effective corrective action are also developed. This aids in the prevention of future reoccurrences by elimination of problem areas in the equipment. Technical Rationale: Figure 1 illustrates the closed loop PRACAS with the necessary steps required to get full use out of such a system. This continuous loop provides the program with the opportunity to fine tune hardware reliability and performance through repeated iterations of reporting and corrective action. [D] Figure 1. Closed-loop Problem Reporting and Corrective Action System Essentially the system must provide information on: What was the failure? How did the failure occur? Why did the failure occur? How can such failures be prevented from occurring in the future? The documentation procedures should include instructions for initiating problem reports, analyzing the failure and method of providing corrective action to the design and operation of the equipment. The most important step in the process is documentation of the problem. The quality of the document will determine the effectiveness of the PRACAS for creating an acceptable solution. Minimum documentation for the problem should include: The location of the failure The date and time of the failure The applicable part numbers, serial numbers, model numbers The operation being performed The failure symptom The name and number of the reporting individual(s) The environment under which the failure occurred The impact of the failure on hardware and personnel safety For each test-related failure, a quotStress statementquot on whether or not the failure induced any stress in the hardware. A means should also be available for tabulating the failure information for determining trends and the mean-time-between-failure of the equipment. Besides being useful to design and reliability engineering, this information may also be useful to maintenance personnel for determining maintenance periodicity of the equipment already in use. Failures that require quotstress statementsquot shall include test failures, operator induced failures, test equipment failures, environmental equipment failures, or any other problem\/failures which did result in overstress, or which could have resulted in overstress, to any portion of flight hardware. Use at KSC The KSC PRACA System provides the means to monitor and track the health of the Space Shuttle Ground Support Equipment and identify problem areas that require further investigation. See figure 2 for the report that is used to identify and track problems at KSC. The majority of problems that are reported deal with component failures. However, any other condition that results in the system or equipment not meeting the requirements that were specified is also reported (corrosion, out-of-calibration, etc.). [D] Figure 2. KSC Problem Tracking Form Click on image for larger form in PDF format The PRACA system incorporates the following features: Tracking - The system encompasses the reporting, documentation, analysis and initiation of corrective actions relative to nonconformances detected during ground processing operations that are associated with flight systems, ground support equipment and facilities. Recurrence Control - The system provides a recurrence control function which is directed toward ensuring that specific problems or failures do not reoccur. History - The system maintains historical data that supports ongoing problem resolution, trend analysis and recurrence control activities. This historical problem data is needed to support reliability, maintainability, and availability analysis. NASA Centers - The system provides on-line visibility of the nonconformance data to other NASA Centers. Johnson Space Center and Marshal Space Flight Center can view the data on-line. Extracts of data are also provided to JSC for input to the PCAS (Program Compliance Assurance and Status) System. Batch Report - The system provides for the generation of batch reports on demand, weekly and\/or monthly. Security - The system provides access control that ensures that only authorized personnel may write to the database and then only to areas in which authority has been established. Query capability of the system is available to valid users at any time. Automated Management Document Control System (AMDCS) - The system provides for the automatic transfer of nonconformance report data to AMDCS when final acceptance data is entered. Ad Hoc Reports - The system provides for the generation of ad hoc reports using a user-friendly language. It also provides for the user to save ad hoc report specification for later use. These reports are needed for specific trend and failure reports. Document Accountability Control System (DACS)- The PRACAS utilizes the DACS for document tracking by attaching a bar-code symbol to each PRACA report. As the report is routed through the closure process the bar-code symbol is scanned at each stop. The location of the report can then be determined by query of DACS. Disposition\/Causes\/Corrective Action - The system identifies all actions associated with troubleshooting, remedial action, cause identification, recurrence control and unexplained problem resolution. Trouble shooting and remedial action steps are documented. Critical Items - The system identifies the criticality of the failure mode of the problems encountered. A Critical Items List (developed from a Failure Modes and Effects Analysis) is maintained in the database and the criticality code is entered based on the part number. Failure Analysis - The system identifies if failure analysis is required and provides the data for the analysis. Orbiter Thermal Protective System - The system provides for the documentation and disposition of the Orbiter Thermal Protective System nonconformances. This includes a diagram showing the location on each tile of the nonconformance. Corrective Action Assistance Request - The system supports addition, modification and retrieval of the Corrective Action Assistance Requests. Formatted Problem Report - The systems provides for the formatted problem report to be printed on local printers. Status - The system provides real-time status visibility of open and closed nonconformances and constraining nonconformances. It identifies whether the nonconformance is a constraint to further test or precludes the performance of any sequence in the work document. Search and Retrieval - The system provides for interactive search and retrieval which can be displayed on a terminal or, if large volume of data, sent to a printer. Number Generation - The system provides for automatic number generation for the nonconformance documents. The automatic number generator can be turned off as is the case when the nonconformance reports that are initiated when the system is not available are entered in the system. Real-Time - The system supports testing operations and closeouts with real-time status information. Other Useful Information - The system contains other useful information such as part numbers, serial numbers, end item control numbers, next higher assemblies, FSCM (Federal Supply Code for Manufacturers), STS (Space Transportation System) #\/effectivity, when failure is detected and operational document, including document type and number of the operation being performed, name of the technician, government quality assurance and contractor quality assurance who accepted the completion of the work. Other information such as, the need for critical skills, the need for retest and the system restore date are provided. References: Reliability Engineering for Electronic Design, Norman F. Fuqua, Marcel Dekker, Inc. 1987, pp. 322-325. Lockheed Space Operations Company, Standard Practice Instruction, Problem Reporting and Corrective Action (PRACA) System - QA-001(3)K. Problem Failure Reporting Procedures, Reliability Preferred Practice PD-ED-1250. Problem\/Failure Report Independent Review\/Approval, Reliability Preferred Practice PD-AP-1304. Risk Rating of Problem\/Failure Reports, Reliability Preferred Practice PD-AP-1305.","Lesson ID":738}
{"Driving Event":"This Lesson Learned is based on Reliability Practice Number PT-TE-1420 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. The sine-burst test is a simple method to apply a quasi-static load using a vibration shaker and shock testing software. Depending on the complexity of the test item, it often can be used in lieu of , and is more economical than, acceleration (centrifuge) or static tests. For components and subsystems, the fixture used for vibration testing often can also be used for sine-burst strength testing. For this reason, strength qualification and random vibration qualification can often be performed during the same test session which saves time and money. Implementation Method: The process involves subjecting each orthogonal axis of the test item to five-to ten cycles of a sine wave whose peak is equivalent to the qualification load level. The qualification load root-sum-squaring (RSSing) the limit loads that cause the most significant stress to the critical elements in the test item and multiplying this value by a qualification margin of 1.25 (Reference 1) . If the item can be placed in a combined axis fixture that orientates the test item in a manner that allows application of the correct combined qualification load vector, only one test has to be conducted. This option often prevents any overtesting of elements in the test item. Since the test is intended to impart a quasi-static load to the test item, the test frequency must be below the fundamental resonant frequency of the test item. As a general guideline, the test frequency should be less than one-third the test item resonant frequency to avoid dynamic amplification during the test. This is a strongly recommended guideline. In some cases, it is allowable to use a sinal-burst closer to the test items fundamental frequency if it solves a test procedure problem. Such a case would be where the qualification load input can not be theoretically applied due to constraints of the equipment such as exceeding shaker stroke. Using a sine-burst whose frequency is closer to the first primary resonant frequency, thus taking advantage of the first modes dynamic amplification factor, will result in achieving the correct loading. If test item\/fixture weight rather than stroke is the limiting constraint, it is possible to achieve the desired level by overdriving the shaker current. The short duration of the test will allow this overdrive of shaker current. After the test level and fixturing method is determined, a sine-burst open loop program must be built to drive the vibration table. The practice at GSFC has been to synthesize the waveform using a short program, written in Time Series Language, a general purpose application program from GenRad. The resulting waveform is then transferred to the shaker control program, quotTransient Waveform Controlquot, which runs on a GenRad 2514 Vibration Control System. The actual test is conducted in a stepwise manner applying a number of lower level sine-bursts that are fractions of the full load. For example 1\/8,1\/4, and then 1\/2 of full level. This assures the test conductor that the test item\/fixture\/shaker table is reacting in a linear manner. If it is not the waveform can be modified by outputting only a percentage of the programmed level, i.e., 90%. After these preliminary runs with corrections are made then the full load is applied to the item under test. The figure shown below is a typical sine-burst waveform. The waveform is sinusoidal with a ramp up to maximum level, several cycles at maximum level, and then ramp down to zero. The number of cycles at maximum level is usually 5 to 10 cycles. The sine-burst test is performed with the same fixturing used for sine and random vibration. [D] Technical Rationale: The sine-burst test was developed at GSFC to satisfy requirements for strength qualifying structures to quasi-static load specifications. The primary objective of the sine-burst test is to apply the specified acceleration to the test item in a uniform manner. A secondary objective is to minimize potential fatigue damage to the test item. At GSFC the test item can be a flight unit undergoing Protoflight qualification . Protoflight hardware is flight hardware that is flown after qualification testing. Since the applied loads in this test are significant, it is important that the total number of cycles of peak strain be minimized. The test frequency must be sufficiently below any resonant frequencies of the test item. This requirement will preclude sine-burst testing of large structures, which usually have lower resonant frequencies. The sine-burst test has been shown to be a cost effective alternative to either static loads or to centrifuge testing. References General Environmental Verification Specification for STS and ELV Payloads, Subsystems, and Components, GEVS-SE, January 1990, GSFC","Lesson ID":730}
{"Driving Event":"This Lesson Learned is based on Reliability Practice Number PT-TE-1429 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. These practices prevent the long term degradation and early failure of electrical parts and components due to electrical and mechanical overstressing. Damage due to overstressing may not result in immediate failure and may not be detected by component or assembly level testing but can result in early failures. Implementation: Formal Electrical Integration Procedures are prepared, reviewed, and approved to document and control the step by step procedures used in mating, testing, integrating, etc. of flight hardware at all levels of assembly. A number of practices are incorporated into these procedures to prevent electrical and mechanical overstressing of electrical parts and components. These practices are described in the following: Safe-To-Mate Cable Harness Test: This test is performed on flight cables and harnesses prior to their connection to flight hardware. A breakout box is inserted at one end of the cable. Power and signal flow, continuity, isolation, etc. are tested through the entire cable. This test checks for wiring errors that could apply over-voltages, reverse polarities, improper signals, etc. that could cause electrical stress to parts and components. Safe-To-Mate Cable And Simulator Test: This test is performed on cables and harnesses connected to simulators prior to their connection to flight hardware, A breakout box is inserted at the flight unit end of the cable or harness. Power and signal flow, continuity, isolation, etc. is tested through the entire cable or harness. This test checks for wiring errors in both the simulator and the cable that could apply over-voltages, reverse polarities, improper signals, etc. that could cause electrical stress to parts and components. Disconnect Meters Before Changing Range Scales: Meter probe connections to flight hardware and to GSE when connected to flight hardware are disconnected and grounded during meter range switching in order to drain off electrostatic charges and voltage transients that may develop during the range switching. Ground Cable and Harness Connectors Before Mating: Cable and harness connector shells are grounded before mating with flight hardware in order to drain-off electrostatic charges. Verify Ground Connections: The resistance of ground connections between flight hardware boxes and packages and between flight boxes and packages and structure ground are verified by measurement and must be no greater than 2.5 milliohms. Verify Power-off Before Mating Or Demating Connectors: Power-off is verified for ground support and test equipment and for flight hardware before signal and power connectors are mated or demated with flight hardware. This is to prevent transients and partial and intermittent connections that could occur during the connection process. Ground Scaffolding and Workstands: Scaffolding and workstands located near flight hardware are grounded to a central ground point to prevent electrostatic buildup and discharges to the flight hardware. Painting of scaffolding and workstands is not permitted in order to prevent electrostatic charge buildup on the painted surfaces that can be transferred to the flight hardware. Paint also prevents proper ground connections to the scaffolding and workstands. Unroll Tapes Slowly: Tapes used on or around flight hardware are unrolled slowly in front of an ionized air source if available in order to prevent electrostatic charge buildup and discharges to the flight hardware. Connector Savers: Connector savers are used on those flight connectors where frequent mates and demates are required during the integration and test program. The connector savers minimize the wear and stress on the connector pins due to frequent mate and demate procedures. Connector Demate Tools: Connector demate tools are used to demate flight connectors in order to minimize stress on flight connector pins. Log of Flight Connector Mates And Demates: A log of all flight connector mates and demates is maintained and monitored in order to access the impact on the connectors of the mates and demates and to facilitate cleaning of connector pins every 10 mate and demate operations. Secure Flight Cables To Connectors: Flight Cables are secured to the back of connectors with strain relief clamps or by potting in order to minimize strain at the connector pins and wire crimp areas. Check Cable Assemblies For Sharp Edges: Cable assemblies are carefully checked for sharp edges that could cut into or nick wire insulation and flight components and boxes during installation and handling and could cause a failure at a later date. Typically, these sharp edges are caused by the aluminum foil wrapped around cables for EMI shielding purposes. Abrasiveness Of Cable Harnesses On Flight Structure: Cable harnesses are designed and installed on flight structures so as to prevent abrasions on the structure and on flight boxes and parts. Abrasions can be caused by moving parts, handling during integration and test activities, insufficient bending radiuses, etc. Harness Flexing Across Hinged Joints: Harnesses across hinged joints are designed for the number of planned operations of the joint and also for an appropriate number of additional operations of the joint that could be required during the integration and test activities. Protection Of Flight Cables And Harnesses: Flight cables and harnesses are appropriately stored and protected from stress and damage until they are installed. This is to ensure that damage to cables and harnesses will not lead to early failures. Quality And Protection of GSE Cables: GSE and test cables are fabricated to good quality standards and are protected from damage to prevent failures that could result in stress to and early failures of flight hardware. This includes appropriate separation of power, signal , and ground wires to minimize cross coupling of signals and transients that could stress electrical parts and result in early failures. Technical Rationale: Electrical components in flight hardware can be very susceptible to damage due to overvoltages including transients and electrostatic buildups and discharges, application of voltages in the reverse polarity, application of improper signals etc. Flight connectors can be degraded and damaged by excessive and improper mates and demates. The damages can be so severe that the performance is affected and the faulty part can be identified and replaced during the integration and test program. However, in many cases the damage is not immediately apparent and can begin a process of gradual degradation to failure during the mission life of the hardware in space. The above practices have been adopted to prevent the damaging influences that can cause the degradation of components and the loss of reliable operation during the flight mission.","Lesson ID":729}
{"Driving Event":"This Lesson Learned is based on Reliability Practice Number PT-TE-1433 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. This practice significantly enhances flight reliability by ensuring that mechanical fasteners do not fail during the mission due to inadequate integrity requirements or Quality Control inspection procedures. Implementation Method: The mechanical fastener inspection system, defined in detail in Ref. 1, assigns responsibility to specific Quality Assurance individuals assigned to each project team. These individuals are responsible for ensuring that the various steps, provisions, requirements, and procedures defined by the inspection system are appropriately complied with including review of fastener procurement documentation, monitoring of inspections and tests, reporting, and problem resolution. Specification, Ref. 2, defines the fastener integrity requirements for all fasteners used in flight hardware and for critical nuts and bolts used on ground support equipment, including all flight hardware\/GSE interfaces. This specification includes specific requirements for material selection, audit of manufacturers and approval of their products, material test reports, and traceability. Quality Assurance Provisions include screening inspections and testing, visual inspections, tensile testing, nondestructive evaluation, dimensional inspection, and hardness and proof testing. The fastener inspection system ensures that the requirements of this specification are appropriately applied in the procurement of fasteners by each project by requiring that the Flight Assurance Manager or his\/her designee review and approve all fastener procurements in accordance with Ref. 2. Fasteners, along with their vendor test and inspection reports, are delivered to the Assurance Management Representative, (AMR) assigned to the specific project. The project Cognizant Engineer, (CE) originates a work request for incoming inspection by a contractor operated inspection facility, (Lanham Inspection Facility) and also generates a Certification Log in accordance with Ref. 3. He also forms a Certification Log package by attaching appropriate vendor test and inspection reports and data to the Certification Log. The AMR reviews the Certification Log package and the work request and forwards this documentation and the fasteners to the Lanham Inspection Facility for inspection in accordance with a Fastener Inspection Test Plan, Ref. 4. All fasteners are identified as acceptable\/rejectable in accordance with the Certification Log. Fasteners that exhibit nonconformance are tagged and impounded until they are dispositioned by the CE in accordance with the Problem Record, Ref. 5. On occasion, the Material Review Board will disposition discrepant fasteners and initiate corrective action to resolve nonconformance issues that can not be dispositioned by the CE in accordance with Ref. 5. Upon completion of the fastener inspection\/test by the Lanham Inspection Facility, the Lanham inspector completes the Certification Log which includes all inspection reports and pertinent data associated with the inspection. The Certification Log and the fasteners are returned to the AMR for review. The AMR returns the conforming fasteners to the CE. Figure 1 is a flow diagram of the Fastener Inspection System. [D] Technical Rationale: The integrity of fasteners is a significant element in the reliable operation of flight hardware. The high reliability required of fasteners is dependent upon appropriate procurement documentation and acceptance inspection and testing procedures. References Fastener Inspection- GSFC Doc. No. P-303-625 GSFC Fastener Integrity Requirements- S-313-100 The GSFC Certification Log- FAP P-303-820 Fastener Inspection\/Test Plan- GSFC Doc. No. FAP P-303-626 Problem Record Items - GSFC Doc. No. FAP-303-845 NASA","Lesson ID":728}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1248; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. This practice enhances reliability of the SDS and the probability of mission success by simplifying the design and operation of the SDS system and providing capability to work-around spacecraft and instrument problems. Implementation: The first SDS system described in this practice was successfully flown on the SAMPEX mission that was launched in 1992. This SDS system is being used on a number of later missions such as the X-Ray Timing Explorer (XTE), the Earth Observing System (EOS), and the Tropical Rainfall Measuring Mission (TRMM). The SDS is a dual-redundant command and data handling system which functions as a command decoding and distribution system, a telemetry\/data handling system, and a data storage system. It provides on-board computational capability for processing attitude sensor data and generating commands for the attitude control actuators in a closed loop fashion. It also provides stored command processing and monitoring of the health and safety functions for the spacecraft and instrument subsystems. The system design allows for modularity and flexibility in adapting the system for many different spacecraft. The use of standard interfaces and space qualified versions of widely used processors and related software, translates into higher reliability and major cost and schedule reductions not possible with the use of spacecraft unique interfaces, processors and software. The higher reliability results from widespread experience with the standard hardware and software in both space and nonspace related applications. The following are design practices incorporated into the SDS to improve reliability. 1) Use of MIL-STD-1773 Protocol For Data Bus Interfaces: The use of the MIL-STD-1773 fiber optic data bus and associated standard processors and operating systems significantly simplifies the design of command and data handling systems and the test and integration of spacecraft systems. This approach also significantly reduces the number of failure prone wires and electrical connections previously needed in the discrete wiring method. The fiber optics also reduces the probability of upsets and other radiation problems due to the radiation environment. A SDS for a typical spacecraft, such as the X-Ray Timing Explorer (XTE),will provide three data buses, namely Attitude Control, Spacecraft, and Instruments. Figure 1 is a block diagram of the XTE SDS system architecture. [D] 2) Redundancy and Cross-strapping: The reliability of the SDS system is significantly enhanced by the total redundancy of the system with each unit provided an identical backup unit to the other. The SDS units are cross-strapped to their respective data buses which provide the interconnections between them. All bus connected subsystems, components, and instruments are cross-strapped to their respective data buses. The cross-strapping of the SDS with the up and down links is shown in Figure 2. This figure does not show the cross-strapping of the transponders with their antennas. The SDS receives both primary and redundant power lines. [D] 3) Error Detection and Correction (EDAC): An EDAC capability designed into the SDS system improves reliability by preserving the integrity of data and protecting against induced errors. The backplane for the SDS is based on a modified PC-AT 386 backplane design which has been optimized by the GSFC for use in a space environment. A significant modification is the addition of an 8-bit wide check bit bus to the PC-AT design to support the EDAC function. 4) Uplink Board: The reliability of spacecraft operations and control are enhanced by ensuring that the uplink board is the sole avenue by which commands and data are received by the spacecraft from ground support systems during orbital operations. The design for this board is modeled after the SAMPEX uplink board design, but incorporates a number of design modifications unique to the SDS design. The primary command link circuitry and operation is fundamentally unchanged, but a capability to accept hardware decoded uplink commands (bypassing the SDS system software) and cross-strapping between dual transponders has been added. A power converter has been added to the board design in order to permit the board's power supply to always remain on and independent from the rest of the SDS system power. The input to this power converter is unswitched power from the essential SDS power bus. The uplink board interfaces to the SDS and the rest of the spacecraft primarily through communication on the SDS MIL-STD-1773 data bus, on which it is designated as a remote terminal. There are 64 discrete hardware decoded command lines from the uplink card to various spacecraft subsystems. 5) Bulk Memory Boards: The reliability of the Bulk Memory Boards is increased by memory isolation circuitry which isolates a failed segment of the memory board and keeps it from affecting the entire data system. The SDS bulk memory board is modeled after the SAMPEX memory board design, but incorporates the memory isolation as well as a number of other SDS design modifications. 6) Low Voltage Power Converter Boards (LVPC): The design of the 2 redundant LVPCs in the SDS system are similar to the SAMPEX Recorder\/Packetizer\/Processor (RPP) power converter board except for two significant SDS changes to enhance reliability by providing capability for improved control of discrete RESET commands. One change was the addition of a redundant power line. The other change was the addition of a hardware-decoded discrete RESET input command which allows commanding of an 80386 reset independent of the SDS MIL-STD-1773 data bus and system software. 7) Reliability Related Command Execution Capabilities: Every SDS autonomous function is capable of being enabled or disabled by command. The SDS by command can perform preplanned diagnostic and operations checkout of itself. No single command can place the SDS into a configuration from which it cannot recover. The SDS can supply telemetry data such as configuration and health and safety status, indications of anomalous conditions, and performance monitoring data to enable ground controllers to assess the operational state of the SDS and its software. The SDS will execute only ground commands to exit from quotsafequot modes. 8) Failure Tolerance: The reliability of the SDS is significantly enhanced by its capability to tolerate single failures including the failure of spacecraft harnesses servicing the SDS. The SDS design does not permit a single failure to cause another failure or the loss of a redundant critical function path. Technical Rationale: The redundancy and cross-strapping features of the SDS and its data bus provide a wide range of fault isolation and work-around capabilities that can significantly increase the reliability and the useful life of spacecraft missions. In addition, a number of other design features minimize the impact of component failures and prevent the execution of false or inappropriate commands. References MIL-STD-1773: Fiber Optic Mechanization of an Aircraft Internal Time Division Command\/Response Multiplex Data Bus Individual Project C&DH Specification and Interface Control Documents","Lesson ID":731}
{"Driving Event":"This Lesson Learned is based on Reliability Practice Number PT-TE-1437 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefits: This testing significantly enhances flight reliability by ensuring that all portions of the flight operational system work together as expected. This includes the proper flow of data to the end users. Implementation Method: The GSFC Mission Operations and Data Systems Directorate (MO&DSD) develops, maintains, and operates a worldwide Ground Data System (GDS) to support a wide range of flight missions. Various organizational units within the MO&DSD such as branches, sections, and mission readiness test teams collaborate with the Flight Project and the Flight Assurance Directorate in planning and performing a wide range of mission readiness testing. The purpose of this readiness testing is to verify the performance and to demonstrate the readiness of the integrated GDS to support specific flight missions. This practice is implemented by the MO&DSD in the following three basic phases. Phase A: Acceptance and Interface Testing of Individual Elements of GDS Acceptance and Interface testing is performed on each element of the GDS for each flight mission. This testing is particularly applicable to those hardware and software elements in the GDS that have been updated, modified, or added to meet specific requirements of a mission. The acceptance and interface testing is followed by a formal Project Integration and Test Program. The Project Integration and Test Program verifies that the GDS can meet all of the project mission support requirements and documents the system's operational readiness. After all requirements have been verified, all discrepancies have been resolved, and all corrective actions have been completed, the verification process through Integration and Test is complete. The GDS is now ready to participate in Phase B, Compatibility Testing. Phase B: Compatibility Testing Compatibility testing is conducted on all portions of the operational system including the payload, the operational software, and the ground systems. The ground systems include the Space and Ground Networks, the Mission Operations Control Center (MOCC), and the data processing facilities. When the mission scenario calls for electrical operation of the payload aboard the STS or in conjunction with it, compatibility of the operational system is demonstrated with the use of the appropriate elements of the STS, such as the Orbiter Payload Data Handling System and the Mission Control Center. After completion of compatibility testing, the GDS is ready to participate in Phase C, Mission Readiness and Mission Simulations Testing. Phase C: Mission Readiness And Mission Simulation Testing Mission Readiness Testing is conducted to verify that system design specifications are being routinely met, to ascertain the level of operational proficiency being maintained throughout the networks, and to evaluate the network's abilities to meet or exceed design specifications in response to project requirements. An evaluation phase follows in which all Discrepancy Reports (DRs) are reviewed by a DR Review Board. Mission Simulation Testing includes data flow tests performed on the total system in a realistic mission timeline. When practical, external stimulus of the spacecraft instruments and attitude control sensors are used. Mission Readiness and Mission Simulation Testing is carried out in accordance with formal test plans prepared and approved by the MO&DSD with concurrence by the flight projects. These test plans define test coordination, system requirements, test procedures, problem resolution procedures, and reporting requirements. In order to ensure an integrated testing effort, testing and planning is coordinated through a Mission Readiness Test Team comprised of project and MO&DSD development, test, and operations representatives. Test Facilities and Systems Used for Compatibility and Simulations Testing This section on test facilities and systems used for compatibility and simulation testing provides a description of the major elements of the GDS and how they are used in these test programs. The Simulations Operations Center (SOC) located at the GSFC provides support and test tools that can emulate the spacecraft, the MOCC, the Network Control Center, and the Ground and Space Networks. System evaluations and validation test and simulation programs are also conducted to characterize new or modified Space and Ground Network capabilities, to verify that system design specifications are being met routinely, to ascertain the level of operational proficiency being maintained throughout the networks, and to evaluate network abilities to meet or exceed design specifications in response to user requirements. The SOC provides various resources used to simulate and test ground data system elements. These resources include the Project Platform Training Simulator, the SOC Mission Control Simulator, the RF Simulations Operations Center, the Portable Simulations System, and various utility programs such as a Super Programmable Data Formatter and the data blocker\/deblocker. The SOC has a standard NASA Communications (NASCOM) interface which permits it to communicate with all ground data system elements during Simulation and End-to-End Testing. The Platform Training Simulator provides support for training Flight Operations Teams (FOT) in normal and contingency operations of the spacecraft. The FOT can refine and practice operations and contingency procedures without using valuable spacecraft time. The Training Simulator is also used to support the Integration and Test data flows and the Network Simulation tests. The SOC Mission Control Simulator emulates the Johnson Space Center's payload support functions for simulations with the MOCC. The RF SOC is a simulations facility used for Space Network (SN) simulations and data flows. It has the capability to communicate with the Tracking and Data Relay Satellite E through a small satellite earth terminal located at the GSFC. The Data Evaluation Lab (DEL) provides recording systems, engineering support, and special data services. It can generate, quality check, and provide distribution for pre-mission simulation tapes and analog tapes. Additionally, the DEL can playback generated tapes in the form of data flow to the Mission Operations Center (MOC) and other elements in support of engineering, pre-mission, and operational readiness tests. The SUPER Programmable Data Formatter (PDF) is a portable, stand-alone system used in the SOC or at remote sites for ground system data flow tests, interface verification tests, and end-to-end rehearsals. The SUPER PDF can generate simulated real-time and playback telemetry. It is packaged in a portable unit for supporting tests from the Ground network (GN), spacecraft integration areas, or launch sites. Mobile Compatibility Test Vans (CTV), normally stationed at the GSFC, travel to the spacecraft factory or to the launch site. They are used for verifying the spacecraft's RF compatibility with the network by performing initial checkout of the spacecraft RF interface with the tracking and data networks. The CTVs also provide the MOCC with a direct link to the spacecraft at the manufacturer's plant. The CTV can send spacecraft telemetry data via the GN and NASCOM to all support elements and can receive commands from the MOC via the SN and the NASCOM. They can also be used as a data source for performing network verification tests. Monitoring and Witnessing of Ground Data System Testing The GSFC Office of Flight Assurance assigns an Assurance Management Representative (AMR), a Systems Assurance Manager (SAM), and others as needed to perform assurance functions on flight projects. These functions include identifying tests to be monitored or witnessed, determining the level of coverage based on the test objectives and criticality, and arranging for the coverage by assurance representatives or their contractors. The assurance functions also include observing and reporting on the success of the test in meeting its objectives. The results are documented and identify any events or anomalies for use by engineering and management. The AMR test report contains the objectives of the test, anomaly reports, corrective actions expected, and the AMR's appraisal of whether test objectives were met. Technical Rationale: The detailed performance of the Ground Data System in meeting the specific technical requirements of spaceflight missions is thoroughly evaluated and validated in order to ensure mission readiness and compatibility with mission requirements. This readiness includes the training of control center operational personnel by simulating and practicing both nominal and contingency flight operations. References GSFC Document Entitled \"Directorate Test Support\", Subject - Code 500 Directorate Test Support GSFC Document Entitled \"Flight Assurance Procedure\" No. P-303-1025, Subject-Monitoring and Witnessing Ground Data System Testing\" GSFC, SPAR-3, Standard Payload Assurance Requirements (SPAR) for GSFC Orbital Project, Paragraph 3.7 March 1990","Lesson ID":726}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1228; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: The use of Independent Verification and Validation (IV&V) processes ensures that computer software is developed in accordance with original specifications, that the software performs the functions satisfactorily in the operational mission environment for which it was designed, and that it does not perform unintended functions. Identification and correction of errors early in the development cycle are less costly than identification and correction of errors in later phases, and the quality and reliability of software are significantly improved. Implementation: Independent verification and validation is defined as a series of technical and management activities performed by someone other than the developer of a system to improve the quality and reliability of that system and to assure that the delivered product satisfies the user's operational needs. Verification is an iterative process aimed at determining whether the product of each step in the development cycle (a) fulfills all of the requirements levied on it by the previous step and (b) is internally complete, consistent, and correct enough to support the next phase. Validation is the process of executing the software to exercise the hardware, and comparing the results to the required performance. Embedded software is software that is designed to execute in a computational device to control or perform a specific process in support of an end item. End item examples include payloads, vehicles, experiments, flight avionics, ground support equipment, and other mission support activities such as mission, payload, and science operations. It could also be incorporated into laboratory experiments or simulations such as training, verification, or breadboard simulators. Embedded software is not used for general purpose computing applications. Some of the technical and management activities included in IV&V for embedded software are: requirements analysis and tracing; peer reviews; status monitoring and reporting; walk-throughs; dynamic analysis; simulations; risk analysis; code inspection; software library maintenance; audits; and IV&V testing using software analysis tools. These activities come into play during the various phases of the software development life cycle, and are usually documented in a family of reports as shown on Figure 1. [D] Figure 1: Synchronizing IV&V with the Software Development Life Cycle Although the IV&V is generally concurrent with the software developer's life cycle phases, the completion of the IV&V corresponding phases lags the completion of the software development phase slightly as shown on Figure 1. Typical key IV&V functions that are performed in each phase are summarized as follows: 1. Concept Analysis Phase: Documentation that is produced in the software development conceptual phase is independently evaluated. These documents include the statement of work, advanced planning reports, project initiation descriptions, and feasibility study reports. The allocation of functions to hardware and software elements, and the criticality of each software element are assessed. 2. Requirements Analysis Phase: Software requirements are verified through independent derivation of requirements, comparison to standard reference systems, functional simulations, and timing and sizing analysis. A software requirements traceability analysis and a software interface analysis are performed. A system test plan is developed, and acceptance test requirements are established. IV&V software is designed, and requirements analysis phase reports are prepared. 3. Design Analysis Phase: A number of techniques are used to verify the satisfaction of software requirements. These techniques include correlation of traceability between design elements, functional simulations, independent derivation of equations and algorithms, comparison with standard references and models, analysis of interfaces, and identification and development of a software test program. Design analysis techniques to be used for any particular function are dependent on the nature of the function (such as filtering, display output, and device interfacing). For example, logic analysis techniques are appropriate for executive control functions while mathematical methods are better suited for numerical functions. The proposed design of each software function is verified by using the selected method to determine the extent to which it satisfies the corresponding software requirements. Control logic is similarly verified to ensure proper interaction between software functions. 4. Implementation Analysis Phase: During this IV&V phase, two parallel activities are performed: (1) coding analysis and (2) testing. Coding analysis includes version comparison, textual and syntactical analysis, standards auditing, equation reconstruction, data structure analysis, flow charting, logic reconstruction, manual code inspection, traceability analysis, interface analysis, and database analysis. Software tools are employed to automate many of these program analysis techniques. They are used to help identify actual or potential errors in the developed code, and to reformat and consolidate information to facilitate manual analysis, software tools present a reliable, cost-effective means to supplement manual program analysis techniques. To maximize the visibility of software development quality, coding analysis is performed in parallel with code development. Coding analysis is achieved by analyzing the incremental code deliveries and modifications introduced in the updated program versions. Testing analysis includes the application of independent tests performed to determine compliance with software and system requirements. Component testing and interface testing are planned for both nominal and extreme conditions within the required performance limits. 5. Independent Verification and Validation Phase: Simulation, testing, inspection and computer-aided software verification and validation are performed during this phase. Problem reports are prepared which identify anomalies in formal documentation, source code analysis, software database analysis, and the software developer's test results. Component test results and interface test results are documented. 6. System Integration Analysis Phase: The credibility of the system in its operational environment is established in this phase. In this phase, the final results of the software development effort are evaluated after the software has been fully tested in IV&V, and all problems and discrepancies have been corrected. During this IV&V phase, integration, system, and acceptance tests are performed in a serial fashion to validate the software. 7. Operational and Maintenance Analysis Phase: The validated system is placed under configuration control during installation, checkout, operation, and maintenance. IV&V functions during the operation and maintenance analysis phase include monitoring problems reported and ensuring that they are resolved according to established configuration management procedures. Outputs of this phase are IV&V problem reports, installation and checkout reports, configuration management reports, and flight software problem reports. Technical Rationale: IV&V has proven to be a necessary function for software projects of all sizes, but is particularly important in large, critical software packages. Although the level of IV&V performed will be proportional to project size, its performance in embedded flight software projects is widely considered to be mandatory. References: 1. Lewis, Robert O.: Independent Verification and Validation. John Wiley & Sons, Publishers, New York, NY, 1992. MSFC Software Management and Development Requirements Manual. MM8075, George C. Marshall Space Flight Center, Huntsville, AL, January 21, 1991. IEEE Guide for the Use of IEEE Standard Dictionary of Measures to Produce Reliable Software. IEEE Standard No. 982.2-1988, Institute of Electrical and Electronics Engineers, New York, NY, June 12, 1989. IEEE Standard Dictionary of Measures to Produce Reliable Software. IEEE Standard No. 982.1-1988, Institute of Electrical and Electronic Engineers, New York, NY, April 30, 1989. Beizer, Boris: Software Testing Techniques, Second Edition. Van Nostrand Reinhold, New York, NY, 1990. Perry, William E.: How to Test Software Packages. John Wiley & Sons, Publishers, New York, NY, 1986. Hollocker, Charles P.: Software Reviews and Audits Handbook. John Wiley & Sons, Publishers, New York, NY, 1990. Wallace, Dolores R. and Fujii, Roger F.: Software Verification and Validation: Its Role in Computer Assurance and Its Relationship with Software Project Management Standards. NIST Special Publication No. 500-165, National Institute of Standards and Technology, Gaithersburg, MD, September 1989. Tauswarthe, Robert C.: A General Software Reliability Process Simulation Technique. JPL Publication No. 91-7, Jet Propulsion Laboratory, Pasadena, CA, April 1, 1991. Cost-Effectiveness of Software Independent Verification and Validation. NASA RTOP No. 323-51-72, Jet Propulsion Laboratory, Pasadena, CA, October 15, 1985.","Lesson ID":723}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique Number PM-3 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Effective development of a maintenance concept can enhance the effectiveness of maintenance support planning and aid both logistics planning and design of a maintainable system. The maintenance concept can also provide assessments of cost savings for maintenance activities and resources allowable at each maintenance level. The maintenance concept provides the basis for overall maintainability design requirements for the program, and contains detailed planning of maintenance policy for the operational system. It establishes the scope of maintenance responsibility for each level (echelon) of maintenance and the personnel resources (maintenance manning and skill levels) required to maintain a space system. Early development and application of the maintenance concept in structuring the maintainability plan can eliminate or reduce occurrence of problems that may interrupt system operation. The maintenance concept for a new system must be systematically formulated during the early conceptual design phase of a program to minimize maintenance problems during the operational phase. This proactive approach is being used on Space Station-based experiment development programs at LeRC to incorporate current Space Station Program support principles, prescribed Space Acceleration Measurement System (SAMS) and Combustion Module One (CM-1) operational and repair policy, and identified sparing requirements. Elements This maintenance concept will aid in logistics planning and will guide design by providing the basis for establishment of maintenance support requirements in terms of tasks to be performed, frequency of maintenance, preventive and corrective maintenance downtime, personnel numbers and skill levels, test and support equipment, tools, repair items, and information. Inputs to the maintenance concept should include: a mission profile, system reliability and availability requirements, overall size and weight constraints, and crew considerations. The concept should support the following design elements as they apply to a manned orbital space program where on-orbit and ground maintenance is planned. Repair Policy The repair policy should consider the support to be provided at the maintenance echelons (levels) summarized in Table 1. Table 1. Echelons of Maintenance Organizational Maintenance Depot Maintenance Where Performed On-orbit NASA Center or Contractor System Maintainer Flight Crew Center Engineers and Technicians Basis Repair and retain equipment Repair and return equipment to stock inventory Type of work accomplished Inspect equipment Repair at module, ORU, and component level Remove and replace modules and ORU's Repair and maintain ground support equipment Adjust equipment Calibrate equipment Organizational Maintenance Organizational maintenance is maintenance performed by the using organization (e.g., flight crew) on its own equipment. This maintenance consists of functions and repairs within the capabilities of authorized personnel, skills, tools, and test equipment. Organizational level personnel are generally occupied with the operation and use of the equipment, and have minimum time available for detailed maintenance or diagnostic checkout; consequently, the maintenance at this level is restricted to periodic checks of equipment performance. Cleaning of equipment, front panel adjustments, and the removal and replacement of certain plug-in modules and Orbital Replaceable Units (ORUs), referred to as black boxes, are removed and forwarded to the Depot Level. Depot Maintenance Depot maintenance is maintenance performed at NASA Centers or contractor facilities for completely overhauling and rebuilding the equipment as well as to perform highly complex maintenance actions. The support includes tasks to repair faulty equipment to the part level, if deemed necessary. This level of maintenance provides the necessary standards for equipment calibration purposes, and also serves as the major supply for spares. System Availability Operational Availability (Ao ) is defined as the probability that at an arbitrary point in time, the system is operable, i.e., is quotup.quot It is a function of the frequency of maintenance, active maintenance time, waiting time, logistics time, administrative time, and the ready time of the system, and is expressed as: [D] (1) Where: UPTIME = the total time a system is in an operable state, and TOTAL TIME = the combination of uptime and downtime, in which downtime is the time in which a system spends in an inoperable state. Repair vs. Replacement Policy Normally, on-orbit repair should not be performed on any plug-in modules or ORUs. If any on-orbit repair actions are planned, they should be clearly identified in the concept. At the organizational level, failed items should be either discarded or sent to the NASA Center or contractor for exchange and repair in accordance with repair\/discard policies identified in the system requirements. Corrective maintenance, limited to replacement of faulty ORUs and plug-in modules, should be specified to be performed during the mission period. Prime equipment should be designed to have ready access for maintenance. Quick-opening fasteners should also be specified. Level of Replacement The design for proper level of ORU definition should consider compatible failure rates for hardware parts within the same ORU. Relative ranking of ORU's through reliability and maintainability considerations and mission criticality analysis can also contribute toward the proper level of replacement definitions. The required level of replacement should be specified at the plug-in module and ORU levels. Maintenance and support of a system should involve two-tier maintenance echelons. The first level provides for repair of the end- item on-orbit by replacing select faulty or defective plug-in modules and ORUs identified through use of specified diagnostic procedures. Faulty ORUs should then be evacuated to the second level of the maintenance echelon (depot level), which will be at a NASA Center for repair if deemed necessary. The particular NASA center\/ facility should act as the depot for repair of faulty items. Skill Level Requirements Hardware should be designed to aid on-orbit and ground maintenance, inspection, and repair. Special skills should not be required to maintain a system. The following design features should be incorporated: Plug-in module and ORU design to minimize installation\/removal time and requirements for hand tools, special tools, and maintenance skills. Plug-in modules and ORUs should be designed for corrective maintenance by removal and replacement. Plug-in module and ORU designs requiring preventive maintenance should be optimized with respect to the access, maintenance hours, and maintenance complexity. Software and its associated hardware should be designed so that software revisions\/corrections can be easily installed on-orbit with minimum skill level requirements. Flight crew training for payload flight operation should identify hands-on crewmember training, at the NASA center where the system is built, to familiarize crewmembers with the removal\/replacement of hardware. Spares Philosophy Two basic types of spares should be required to support a maintainable system: development spares and operational spares. Development spares are those that must be identified and acquired to support planned system test activities, integration, assembly, check-out and production. Operational spares are those spares that must be acquired to support on-going operations on-orbit. The quantity of development spares required for each system, and the total quantities to sustain the required availability during the planned test activities, integration, assembly, and check-out test should be determined according to the following: Custom-made components\/parts Long-lead time items The quantity of spares required for each system and the total quantities to sustain the required operational availability on-orbit should be determined according to the following: Items that are critical to system operation Items that have high failure rate Items that have limited life In the initial spares provisioning period and to the maximum extent practical, spares should be purchased directly from the actual manufacturer; i.e., lowest-tier subcontractor, to eliminate the layers of support costs at each tier. The initial provisioning period should cover early test and evaluation, plus a short period of operation, to gain sufficient operational experience with the system. This will provide a basis for fully competitive acquisition of spares. Spares with limited shelf life should be identified and should be acquired periodically to ensure that adequate quantities of spares are available when needed. Spares with expired shelf lives should be removed and replaced. Procurement of spares should be initiated in sufficient advance of need to account for procurement lead time (administrative and production lead time). The location of the spares inventory (on- orbit and on-ground) should be a function of the on-orbit stowage allocation capabilities and requirements. A volume\/weight analysis should be conducted to determine the quantity and types of spare items necessary to sustain satisfactory operational availability. The volume\/weight analysis shall assure available or planned payload volume and weight limits, and planned or available on-board stowage area. Breakout should be addressed during initial provisioning and throughout the replenishment process in accordance with NMI 5900.1, Reference 1. Breakout is the spares procurement directly from the original equipment manufacturer, prime contractor, or other source, whichever proves most cost-effective. A spare item requirement list should be maintained by procurement and technical personnel. Diagnostic\/Testing Principles and Concepts The system should meet the following failure detection requirements as a minimum: The system should have the capability to detect, isolate and support the display of failures to the plug-in module level. Crew observations may be used as a method of failure detection of the following: visual displays, keyboards\/buttons, general lighting, speakers. System design should provide the capability for monitoring, checkout, fault detection, and isolation to the on-orbit repairable level without requiring removal of items. Manual override and\/or inhibit capability for all automatic control functions should be provided for crew safety and to simplify checkout and troubleshooting. All failures of the system should be automatically detected and enunciated either to the flight crew or the ground crew. Accesses and covers should be devoid of sharp corners\/edges and be equipped with grasp areas for safe maintenance activities. Systems\/subsystems\/items should be designed to be functionally, mechanically, electrically, and electronically as independent as practical to facilitate maintenance. The concept should also describe operating\/testing techniques to identify problems and consider the complexity of the various types of items in the space system and associated maintenance personnel skills (for all software, firmware, or hardware). The techniques will identify maintenance problems. In all cases of fault simulation, the safety of personnel and potential damage to system\/equipment should be evaluated in the concept. The concept should request that a safety fault tree analysis be the basis for determining simulation. Also, a Failure Modes, Effects, and Criticality Analysis should be used to evaluate and determine fault simulation. Some of the fundamental maintenance actions to be evaluated, monitored, and recorded are as follows: Preparation and visual inspection time Functional check-out time Diagnostic time: fault locate and fault isolate Repair time: gain access, remove and replace, adjust, align, calibrate, and close access Clean, lubricate, service time Functional check-out of the repair action Responsibilities for Contractor Maintenance The prime contractor's maintainability program should provide controls for assuring adequate maintenance of purchased hardware. Such assurance is achieved through the following: Selection of subcontractors from the standpoint of demonstrated capability to produce a maintainable product. Development of adequate design specifications and test requirements for the subcontractor-produced product. Development of proper maintainability requirements to impose on each subcontractor. Close technical liaison with the subcontractor (both in design and maintainability areas) to minimize communication problems and to facilitate early identification and correction of interface or interrelation design problems. Continuous review and assessment to assure that each subcontractor is implementing his maintainability program effectively. Responsibilities for Payload Maintenance Director of field installations responsible for launch preparation, maintenance, or repair activities should be responsible for maintenance planning and for providing the resources necessary to support the efficient identification of maintenance related problems in accordance with system requirements. These responsibilities include: Implementing a system that will identify, track, and status problems related to routine maintenance activities attributable to the design characteristics of flight hardware and software. Providing information for use in a data collection system to improve the accuracy of quantitative maintainability and availability estimates. This information can be used to identify failure trends influencing reliability growth characteristics during design and to communicate quotlessons learnedquot from ground maintenance experience. Recommending to the Program Manager, responsible for design and development of flight hardware\/software, areas for design improvement to increase the efficiency in ground processing or maintenance operations. The rationale for supporting these recommendations should include factors such as reduction in ground turnaround time and operational support costs. Allocation of Crew Time for Maintenance Actions Crew time for maintenance should be identified in accordance with system complexity, reliability, and criticality of the items to the system and mission requirements. Analytical methods exist which can be used to prioritize and allocate crew time for maintenance actions. References NASA Management Instruction, Spare Parts Acquisition Policy, NMI 5900.1A, NASA Responsible Office: HM\/Procurement Systems Division, Washington, DC, November 6, 1992. NASA Management Instruction, Maintainability and Maintenance Planning Policy, NMI 5350.1A, NASA Responsible Office: Q\/Office of Safety and Mission Quality, Washington, DC, September 26, 1991. NASA Handbook, Maintainability Program Requirements for Space Systems, NHB 5300.4(1E), Reliability, Maintainability, and Quality Assurance Publication, Washington, DC, March 10, 1987. Space Acceleration Measurement System (SAMS) Experiment, SAMS-SS Product Assurance Plan, SAMS-SS-005 (Preliminary), NASA Lewis Research Center, Ohio. Space Acceleration Measurement System (SAMS) Experiment, Express Payload Integration Agreement, SAMS-SS PIA, NASA Lewis Research Center, Ohio. Space Station Program, Space Station Program Definition and Requirements, Sections 3 and 4, SSP 30000, NASA Lewis Research Center, Ohio. Combustion Module One (CM-1) Experiment, Product Assurance Plan, NASA Lewis Research Center, Ohio. Blanchard, Benjamin S., Jr. and Lowery, E. Edward of General Dynamics, Electronics Division, Maintainability Principles and Practices, McGraw-Hill Inc., N.Y., 1969.","Lesson ID":724}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1239; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. This practice enhances the probability of mission success by controlling temperatures of flight hardware as well as spacecraft charging and RF emissions over the life of the mission. Implementation: Spacecraft and scientific instruments usually contain hardware, including sensitive detectors, which require that temperatures be maintained within specified ranges. A good thermal design is therefore essential to a successful mission. Thermal control coatings is one of several systems, such as thermal blankets and electric heaters, that are used to control temperatures. In space, the operating temperature of a spacecraft is determined by the heat input from the sun, the reflected solar energy from the earth, the background temperature of space, the internal heat generated by the spacecraft and by the emittance and absorptance of spacecraft coatings. Predicting the operating temperature of the spacecraft therefore requires a knowledge of the thermal properties (absorptance and emittance) of the coatings used. In addition to these basic requirements, it is usually necessary to be cognizant of other spacecraft requirements such as spacecraft charging and particulate and molecular contamination requirements in order to choose the proper thermal control coating. It is also important to know how those properties are going to degrade throughout the life of the spacecraft due to exposure to UV, high energy protons and electrons, low energy solar wind protons, and contamination from other parts of the spacecraft. The practice for the selection and application of thermal control coatings includes the following key elements in the selection and application of thermal coatings: 1) The absorptivity and emissivity of particular thermal control coatings are determined and verified by testing. When possible, test measurements are made with the test sample subject to actual flight conditions such as vacuum, temperature, etc. Electromagnetic theory can give useful insights into the absorption and emission of electromagnetic energy from thermal control coatings and how the absorption and emissivity vary as a function of angle, temperature, and wavelength. Maxwells equations can be used to show a theoretical description of the interaction of electromagnetic radiation with spacecraft coatings if one knows the optical constants of conductivity, permittivity, and permeability of the coating. However, in a number of cases, it has been shown that predicted reflectivity and emittance do not agree with test measurements. This can be due to lack of precise data and also due to the fact that electromagnetic theory does not always account for factors that can cause irregularities in the actual performance. Therefore, the absorptivity and emissivity of particular thermal control coatings are determined and verified by testing. 2) Effects of surface roughness and coating thickness are primary considerations in applications of coatings. The surface roughness and the thickness of thermal coatings can have a significant effect upon the emittance and absorptance of the coating. The absorption and emittance will begin to change when the surface is no longer optically smooth; that is when surface defects are much smaller than the wavelength of radiation being absorbed or emitted. When the wavelength becomes comparable to the size of the imperfections, multiple reflections and diffraction effects can occur resulting in changes in the absorption and emittance. Also, if the coating is too thin, the coating becomes partially transparent in the infrared or visible part of the spectrum. This makes the effective emittance or absorption of the coating the sum of the emittance of the coating plus some portion of the emittance of the substrate. It is important to test samples analogous in roughness and thickness (same coating processes and substrate) as used in the space application. Thickness is also a consideration for optimum adhesion and stability during thermal cycling. 3) Flight data is researched and laboratory testing is performed to determine a thermal coating's susceptibility to space radiation and the amount of degradation that can be expected during the lifetime of a mission. Degradation of thermal control coatings in space can manifest itself as changes in emittance, solar absorptance, loss of adhesion, changes in specularity, or changes in electrical conductivity. These changes can be caused by absorption of electromagnetic photons, contamination of the coating by outgassing from other parts of the spacecraft, and by thermal effects on the coatings. The degree to which thermal coatings degrade also depend upon the energy and total contamination that the coatings receive during the mission. It is therefore, necessary to assess the mission radiation environment. This includes the energy fluency at each energy level of protons, the total UV exposure and atomic oxygen exposure level over the life of the mission. From this data, a test program is devised to determine the susceptibility of the coating to each form of radiation as well as to assess the synergistic effects of multiple radiation sources. 4) A detailed analysis of the contamination of the spacecraft is performed in order to determine the amount and type of contaminates expected to develop on surfaces of the spacecraft. Chemical contaminants on surfaces including oxide layers deposited either by absorption or through a chemical reaction with the surface can cause significant changes to the absorptance, emittance and conductivity. These surface contaminants can change the chemical composition of the outer layer and the electrical conductivity thereby increasing the emittance of most metals. Particulate surface contaminates can also affect the thermal properties of coatings. This effect though is usually much less than that caused by chemical contaminants. Particulates tend to scatter incident radiation but since the total area coverage is small they generally do not greatly affect the absorption or emittance unless the contamination becomes excessive. In addition, very thin layers of particulate contamination can have an effect on the emittance of a coating and must be taken into account. 5) Electrical properties are primary considerations used in the selection of thermal control coatings. Electrostatic discharges (ESD) can occur in space between various parts of a spacecraft due to differential charging of the spacecraft caused by energetic charged particles. This ESD is a source of electromagnetic interference (EMI) which can be coupled to electronic circuits and devices. Sensitive ICs can be damaged by several micro-joules (uJ) of ESD and circuits can be upset with only several nano-joules (nJ). This charging phenomena has been blamed for arcing that has caused blown fuses and loss of data transmission on several spacecraft. ESD can also cause electronic parts failure, operational anomalies, degradation of thermal control surfaces, and can also render low energy particle detectors useless. It is recommended that the energy stored by each electrical nonconductive surface be less than milli-joule (3mJ) and that ESD should not be allowed to occur near receivers or antennas operating at frequencies less than 8 GHz or near sensitive circuits. This implies that the spacecraft must be immune to 3 mJ ESD. Differential spacecraft charging is primarily the result of low energy electron flux. High energy electrons penetrate the thin thermal coatings and therefore do not contribute to the differential charging process. The relatively few high energy protons encountered do not penetrate the coatings and therefore contribute to the charging although to a much less extent than the low energy electron flux. This is because the mass of electrons is much less than the mass of protons and they must travel much faster than protons in order to reach the same kinetic energy and hence thermodynamic equilibrium. This means that the total number of electrons passing a given point in a fixed amount of time is greater than for protons, therefore the spacecraft receives a much greater electron flux than proton flux. Finding a coating which satisfies both thermal and electrical conductivity requirements is sometimes difficult to achieve, particularly if a low absorptance high emittance coating is needed. The conductivity of coatings can depend upon a number of factors. First, the length of time the coating has been exposed to vacuum can cause outgassing of volitales and water vapor which can alter the conductivity. Second, the energy of the electron flux can have a bearing on the extent to which a coating will charge since the conductivity is a function of particle energy. And thirdly, the temperature of the coating can also play a significant role in the charging process. Therefore the measurement and the verification of the conductivity of space flight coatings is performed under as close to actual conditions as is possible in a laboratory. In those cases where a coating is applied over a nonconductive substrate, charge control is achieved through the conductivity of the coating. Provisions are made for grounding the edges of the coating. In some cases the substrate is coated with a conductive medium before the thermal coating is applied in order to alleviate a high charge with respect to ground. Refer to the following Figures 1 and 2 for methods for grounding conductive coatings to spacecraft ground. [D] [D] 6) Specific, detailed, and written GSFC approved methods and procedures have been prepared for the selection, handling, and application of each thermal coating used on GSFC instruments and spacecraft. These procedures have been prepared for both paint and tape coatings. The procedures include general considerations on the use and applications of the coatings, formulation where applicable, and complete procurement and acceptance inspection and testing requirements. Acceptance testing includes outgassing tests, electrical charging and erosion characteristic measurements as applicable, adhesion, and optical measurements and degradation. Materials and equipment lists for handling and applying the coatings are provided including safety and toxic considerations and equipment such as air filtration and ventilation hoods etc. Formulation and blending procedures are detailed where applicable as well as surface preparation and cleaning procedures including post coating operations and cleaning and touch up. The application of the coating whether by brush, spraying, or by applications of strips of tape are defined. The procedures require monitoring samples for inspection and testing and in some cases require that monitoring samples be maintained for inspection and testing throughout the life of the coating in space. Storage requirements and shelf life limitations of coating materials must be observed. Curing times can be a factor to be considered in the selection of coatings due to interference with other testing or hardware activities. Complete documentation is maintained of the coating material from delivery to launch of the spacecraft. A procurement log of delivery date, manufacturer's batch and lot numbers, expiration of shelf life date, etc. and incoming inspection and testing data including monitor samples are maintained. A processing work order document is filed in the coating facility to provide a description of the specific coating requirements including required tests and test samples. A complete log of the coating process including any problems and test failures is maintained. Technical Rationale: The reliable operation of a spacecraft and its complement of scientific instruments and equipment require thermal control coatings to maintain temperatures within specified ranges. In addition, these coatings must also control spacecraft charging and ESD. This practice ensures good thermal coating design and application procedures to reliably meet a wide variety of thermal design and ESD requirements. References Handbook of Heat Transfer, (Rohsenow & Hartnett), GSFC Library Reference No. QC320.R528 C.1 Engineering Radiation Heat Transfer, (J. A. Wiebelt), GSFC Library Reference No. QC320.W64 C.1 Radiation Pyrometry and Its Underlaying Principles of Radiant Heat Transfer, GSFC Library Reference No.QC.338.H31 C.7 Thermal Radiation Heat Transfer Vol.1 NASA SP-164 Environmental Testing of Thermal Control Coatings Design Material IITRI Proposal 72-422C Solid State Physics, Ashcroft and Mermin Long Term Performance of Thermal Control Coatings at Geosynchronous Altitudes Hall and Fote Spacecraft Dielectric Materials Properties and Spacecraft Charging A. R. Fredrickson and D. B. Cotts TL 1492 SG2 1986 J. A. Wall and F. L. Bouqet NASA Reference Publication 1121 Entitled quotSolar Absorptance and Thermal Emittance of Some Common Spacecraft Thermal Control Coatingsquot Prepared by John Henniger Individual Procedures For The Formulation, Application And Maintenance Of Thermal Control Coatings Prepared by GSFC Thermal Control Branch","Lesson ID":727}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1236; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. One of the most important considerations in designing reliable flight hardware is selection and use of the highest quality possible components. Proper selection, application, and testing of Electrical, Electronic, and Electromechanical (EEE) components will generally contribute to mission success and provide long term program cost savings. An effective EEE parts program has helped many projects in achieving optimum safety, reliability, maintainability, on-time delivery, and performance of program hardware. The resulting reduction in parts and part-related failures saves program resources through decreased failure investigation and maintenance costs. Implementation Method: The selection of EEE parts should be driven by performance demands, environmental and circuit application, reliability, and maintenance allocations defined by the equipment specification. EEE parts should be selected based on the suitability for their applications and proven qualifications to the requirements of their specifications. Selection of standard EEE parts when required or where feasible, will help minimize the number of styles and generic types and will provide parts with proven technologies and inherent reliability features. Program Requirements Documents (PRDs) for the various NASA hardware usually includes EEE parts selection criteria, including definitions of standard and nonstandard parts. There is an order of precedence for selection of EEE parts that range from MIL-STD- 975 grade 1 parts down to commercial off-the-shelf parts\/hardware. When standard parts are required by the PRDs, but the design requirements cannot accommodate any of the parts listed in MIL-STD-975, there is a provision for submittal of a nonstandard part approval request (NSPAR). A NSPAR request is made and approved prior to procurement and use of the part in the design. 1. Standard Parts General. The parts listed in MIL-STD-975 have been selected to meet the needs of a project while providing parts that are available, economical, and recognized within the parts industry as quality parts. The specifications for these parts are based largely on the Department of Defense (DoD) parts standardization program and methods. All users of MIL-STD-975 have a responsibility to inform the NASA Parts Project Office (NPPO) of the requirement for new or improved parts . NASA Headquarters has designated GSFC as the lead Center. Requirements. Standard parts are listed in MIL-STD-975; procured in accordance with the specifications listed; processed in accordance with any special requirements shown; procured from the designated sources of supply; bear the specified part designations, and are properly classified. Parts exhibiting equivalent performance requirements and having the same generic part designation as the standard part, but not procured to the MIL-STD-975 specifications or from the qualified manufacturing sources, are not standard parts. These parts are treated as nonstandard parts. Assurance requirements for standard parts are included in the procurement specification for these parts. These requirements typically include qualification testing, in-process tests, inspections, quality conformance testing, screening, and any special processing requirements. Standard part grade levels. MIL-STD-975 provides two levels of parts to accommodate part reliability, cost, availability, and delivery. Grade 1 parts are those which demonstrate a low failure rate. Grade 2 parts are available at a lower cost than grade 1 parts, but often exhibit higher failure rates. The requirements for grade 1 and grade 2 parts are contained in the controlling source control documents which describe the differences in part design, processing, qualification, quality conformance inspection, and screening to ensure appropriate reliability and performance. Screening. The screening requirements for standard parts are included in the procurement specification for the part. Radiation effects. The radiation requirements for standard parts are specified in the source control document for the part. For those parts that require radiation hardness, two important requirements need to be specified: total dose and single event effect (SEE) magnitudes. Derating. Derating is the reduction of electrical, thermal, and mechanical stresses applied to a part in order to decrease the degradation rate and prolong the expected life of the part. Derating increases the margin of safety between the operating stress level and the actual failure level for the part, providing added protection from system transients. All parts must be derated in their application in accordance with the PRD's derating requirements (usually MIL-STD-975, Appendix A). 2. Nonstandard Parts General. Any part that is not listed in MIL-STD-975 is a nonstandard part. Nonstandard parts are submitted for review and final approval by the project office. Requirements. All nonstandard parts must perform satisfactorily in the mission envelope. Risks using nonstandard parts are identified. The following steps are often taken when selecting a nonstandard part (i.e. data required to complete Form 4-15): Establish that the part is required for form, fit, and function. Prepare a source control drawing for the part if none are available. Identify screening and quality conformance requirements for the part. Develop a rationale for why the part is needed. Explain why this part has been accepted. Identify problems with the part (i.e., GIDEP ALERT or NASA TWX). (This should be completed for all parts.) Select and certify qualified manufacturers for the part. Identify radiation hardness requirements, if applicable. Processing nonstandard parts. Nonstandard parts are divided into the following categories based upon their nearest equivalent part availability: Nonstandard military parts. Standard Military Drawing (SMD) parts that are listed in MIL-I-38535 Qualified Manufacturers List are non-standard parts unless they are listed in MIL-STD-975. Acceptance of this category of part should be considered if: (a) proper grade level of part is being used; (b) there is any reason a standard part cannot be used; (c) there are any reported problems with the part; (d) there are any additional tests, screening, or quality assurance provisions required by MIL-STD-975 for the nearest equivalent standard part; or (e) the part meets the expected radiation environment. Commercial parts. A commercial part is any part for which the part requirements, processing, and tests are stipulated solely by the parts manufacturer and are exclusively under the manufacturer's control. Establishing qualification for these parts takes time, costs money and depends on the application, mission environment, and tailored test program. Items (a) through (e) from paragraph on nonstandard military parts should be reviewed even more carefully for these parts. New improved or developed parts. Accepting new-technology parts is somewhat difficult. It is important that their form, fit and function be necessary. They must also be qualified for the mission environment. A comprehensive qualification test program should be conducted and the test results must be examined carefully to ensure the new part meets the mission needs and that it will perform in the expected radiation environment. Custom and limited-application parts. Nonstandard parts that are intended for a custom use or for a limited application often do not have qualification data. Here again, careful study is important to ensure these parts are really necessary and if they have special form, fit or function that cannot be obtained from heritage parts. They must meet the mission environmental and radiation requirements. The response to these items should be addressed prior to procurement and installment of the nonstandard part in the flight system. Acceptance of nonstandard parts. If nonstandard parts are used in spaceflight systems, they should be qualified to meet the mission requirements. Nonstandard parts should be qualified to identify predominant failure modes and mechanisms. They should be screened against the known failure modes and mechanisms, to verify conformance of the electrical characteristics against the controlling procurement specification, and to assure the absence of workmanship defects. The evidence supporting their acceptance must be verified, documented, and approved by the project office. Final acceptance for procurement is the responsibility of the Project Office. Technical Rationale: One of the aspects affecting mission success of flight systems is the selection of standard EEE parts which have designed in reliability at the part level. This implies utilizing proven technology parts, procured from qualified manufacturers, and selected from an established program based on project approved parts lists which are, based on the requirements levied for the program. A parts program assures that the selected parts, derating and testing activities are sufficient to achieve mission success for the application environment and expected life of the program. The projects are responsible for providing acceptable parts for their mission classification and for the circuit design, production, and testing to verify flight readiness. The selection of mission classified parts for spaceflight systems is an essential part of the design of flight hardware. With the rapidly growing technologies in the microelectronics area, the selection of parts has become a challenge to designers. The selected part has to perform reliably in the application. References NHB 5300.4(1F) \"Electrical, Electronics, Electromechanical (EEE) Parts Management and Control Require-ments for NASA Space Flight Programs,\" July 1989. MIL-STD-975 \"NASA Standard Electrical, Electronic, and Electromechanical (EEE) Parts List,\" January 1994. MIL-STD-978B NASA Parts Application Handbook, Vol. 1 - 5, March 1988. Reliability Preferred Practice PD-EC-1101, Environmental Factors Reliability Preferred Practice PD-ED-1201, EEE Parts Derating Reliability Preferred Practice PD-ED-1203, Class S Parts in High Reliability Applications Reliability Preferred Practice PD-ED-1212, Design and Analysis of Electronic Circuits for Worst Case Environments and Part Variations Reliability Preferred Practice PD-AP-1303, Part Electrical Stress Analysis Reliability Preferred Practice PD-AP-1306, Thermal Analysis of Electronic Assemblies to the Piece Part Level Reliability Preferred Practice PT-TE-1401, EEE Parts Screening Reliability Preferred Practice PT-TE-1411, Heat Sinks for Parts Operated in Vacuum Reliability Preferred Practice GD-ED-2202, Design Considerations for Selection of Thick-Film Microelectronic Circuits Reliability Preferred Practice GD-ED-2203, Design Checklists for Microcircuits","Lesson ID":725}
{"Driving Event":"This Lesson Learned is based on Reliability Guideline Number GT-TE-2406 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Star image measurements provide the primary means of appraising end-to-end health of an optical imaging system. These tests represent good engineering practice, and are reliable indicators of system performance. Star image tests are thus the final arbiter of quality control. A system passing the star tests discussed here ensures that the optical instrument is performing in a reliable way. Measurements of irradiance distributions provide important quantitative information concerning the fidelity of the star image to theoretical expectations. Such measurements either validate performance, or provide important clues as to the nature of a problem. For example, the problem might be a decentered component or an inappropriate conic constant. Implementation Method: 1. Description of Star Image Test Apparatus The basic equipment needed to perform laboratory star image visual measurements is indicated in Figure 1. The optical system on the left half of the drawing is a Star Simulator. This is a Collimator with a back-illuminated pinhole located in the focal plane. The Collimator can be either reflective or refractive, and its pupil should be larger than the imaging system being tested. The pinhole represents the star, and its diameter should be smaller than the Collimator Airy Disc, (i.e., unresolved). Depending on the application, the pinhole back-illumination can be either from a coherent or incoherent source. An example of the former is a laser; the latter, a point arc lamp. Between the source and the pinhole there is usually some coupling optics to maximize the power through the pinhole, and to fill the aperture of the Collimator with light. [D] Figure 1: Basic Layout of a Star Image Test Setup Caution: The pinhole acts like a quotpinhole camera.quot If a coiled filament lamp is used, an image of the coil will be formed on the collimator pupil and the output irradiance will be quite nonuniform. A support structure is needed to hold the optical system under test. This mounting fixture should provide modest azimuth and elevation tilt control to allow alignment of the quottest systemquot to the Collimator optical axis. The test support fixture should also allow the quottest systemquot to be accurately rotated through its operational field of view. For refractive quottest systems,quot the rotation axis should ideally pass through the system's rear nodal point. A mechanical support fixture that accomplishes this is called a T-Bar Nodal Slide. (Reference 1.) However, for catadioptric and reflective systems, rotation through the rear nodal point is impractical because this point is usually far removed from the physical embodiment of the quottest system.quot In this Guideline, the rotation axis will be at, or near, the entrance aperture of the quottest system.quot For irradiance measurements the quottest systemquot star image can be probed directly by some methods. Other methods need a magnified star image. In the latter case, this can be accomplished using a high quality microscope objective which should be well-corrected for both axial color and spherical aberration. Its numerical aperture must be sufficient to collect all the light emerging from the star image. In the Reliability Preferred Practices Guideline No. GT-TE-2405, i\u0300Star Image Measurements, Part I: Visual Measurementsi\u0302, we relied on making dimensional measurements by eye on key features of the star image both laterally and axially. In this Guideline, irradiance is the key measurement parameter. The dimensional features discussed in Part I are not lost but contained within this broader measurement context. 2. Ideal Star Image Please refer to Reliability Preferred Practices Guideline No. GT-TE-2405 (Lesson Learned 0718). 3.1 Axial Intensity Method A new technique (Reference 2) has been developed in recent years that makes use of axial intensity scans on star images to extract quantitative information about aberration content. Laboratory embodiments can have a number of forms. One embodiment is illustrated in Figure 2 which makes use of a commercially available quotscanning micrometer eyepiece.quot The star image is magnified with a microscope objective. The magnified image is centered on the entrance face of a fiber optic. The exit face of the fiber is coupled to a detector such as a photomultiplier tube (PMT). The output signal of the detector is connected to the y-axis of an xy-recorder. The x-axis is driven by a signal from a linear transducer attached to the Z-axis motion of the microscope. The experiment generates an intensity plot as a function of axial microscope position. [D] Figure 2: Experimental Configuration for Measuring Spherical Aberration via Axial Intensity Scans We will use spherical aberration as an example to illustrate the utility of the axial scan profile. It is well known that the axial intensity of a lens free of spherical aberration has a symmetric axial intensity profile about paraxial (Reference 3) focus as is shown in Figure 3. However, it is not well known that the axial intensity pattern remains symmetric in the presence of spherical aberration.(Reference 3). The pattern is not the same shape as that for the zero aberration case, and the center of symmetry is no longer in the paraxial focal plane. However, the axial separation, d, between the plane of symmetry and the paraxial focal plane is directly relatable to the exit pupil spherical aberration coefficient W040 (in micrometers) present through the equation: [D](3) [D] Figure 3: Axial Intensity of Diffraction Limited System Figure 4 (a) shows an experimental axial intensity plot for a system with significant spherical aberration. The F-number of the system is F\/10.3. The operating wavelength is 0.6328 micrometers. The separation between the plane of symmetry and the paraxial focal plane is 3.07 mm. (Note, paraxial focus is established by a separate axial intensity scan with a small aperture in the entrance pupil). Using Eq.4, we find that the amount of spherical aberration is 5.7 waves! Figure 4 (b) shows a theoretical plot with the same amount of spherical aberration. The two plots are virtually identical. A recent paper (Reference 4) also shows how axial intensity scans of star images with mixed Seidel aberrations can be used to identify and quantify those aberrations. [D] Figure 4: Axial Intensity where W 040 = 5.7 Waves (a) Experimental; (b) Theoretical. Courtesy Dr. Qian Gong 3.2 Lateral Irradiance Methods 3.2.1 CCD Arrays The magnified star image formed by the microscope can be focused on the detector chip of a CCD camera. A video frame-grabber tied into a PC can be used to acquire a frame of data for analysis. Hardcopy can be acquired via a video printer. Software packages are commercially available that will allow analysis of the data frame. Among the useful features are: a) power profiles across the star image; b) power centroid location; c) calculation of encircled energy; d) 2-D contour and 3-D power maps. The profiles can be compared to theoretical predictions like the one shown later in Figure 8(b). Not only is the size of the Airy Disc obtained, but also the relative power between the central peak and the rings. (Note: Small aberrations rob power from the core and shunt most of it into the first bright ring). In addition, an encircled energy calculation should show 84% of the energy within the core (for a circular unobscured entrance pupil). Potential problems with some CCD arrays are: dynamic range, linearity, and pixel uniformity. For example, the ratio of the peak power in the Airy Disc to the peak power in the first bright ring is about 68. Some CCDs do not have enough dynamic range. To see the first few rings means the central core is saturated. An unsaturated core means that the second bright ring, and sometimes the first, are buried in noise. Nonlinearity and pixel nonuniformity imply that profile shapes would be wrong. 3.2.2 Fiber Optic Probe The fiber probe scanner used in Sec.3.1 to obtain axial profiles can also be used to obtain lateral profiles. The fiber optic probe assembly is mounted on a motion controlled boom. This boom can be translated horizontally either manually or under computer control. In this way the probe can be scanned through the magnified star image. A transducer provides a voltage signal proportional to the linear position of the boom. The entire scanning micrometer eyepiece can be rotated and the axis of rotation is the optical axis of the microscope. This allows the observer, who views both the star image and the probe location through an eyepiece attached to the device, to select the orientation of the scan relative to the star image. The boom signal can be used to drive the x-axis of an xy-recorder while the signal from the PMT\/radiometer can drive the y-axis. PMTs have significantly more dynamic range than CCDs, and excellent linearity. This will allow more accurate profiles through the star image. (A commercially available eyepiece of this type can be obtained from EG&G\/Gamma Scientific. The unit is shown in Figure 5.) [D] Figure 5: Commercial Scanning Probe Eyepiece Figure 6 shows a combination of axial and radial scans for 5 waves of spherical aberration (Reference 5). The radial scans are made at various image planes of interest as defined by either geometric (e.g., minimum blur) or diffractive (e.g., Strehl) criteria. [D] Figure 6: Axial and Radial Irradiance Plots Using Scanning Fiber Optic Probe Eyepiece 4. Modulation Transfer Function Measurements 4.1 Connection Between MTF and Star Image In imaging theory, an object is considered to be made up of an array of sinusoidal patterns differing in spatial frequency, amplitude, and lateral positioning. It is akin to a Fourier series decomposition of a periodic waveform of arbitrary shape, e.g., a square wave. If an imaging system is presented with a pure linear sinusoidal amplitude object having unit modulation, then the image of this pattern (assume unit magnification for now) will also be sinusoidal of the same spatial frequency but with reduced modulation, and a possible decentering or shifting of the pattern as illustrated in Figure 7. [D] Figure 7: Physical Basis for MTF In Fourier transform theory (Reference 6 and 7), it can be shown that a point object contains all sinusoidal spatial frequencies at unit modulation at all spatial orientations and that the star image, the point spread function (PSF), is related to the MTF by a Fourier Transform, FT{ }: [D](4) If we scan the point spread function with a slit (as illustrated in Figure 8) we generate a line spread function (LSF). [D] Figure 8: Scanning the PSF with a Slit Sampling Aperature Mathematically this means we have integrated out the y dependency: [D](5) It can be shown that the Fourier transform of the line spread function yields an MTF profile through the origin: [D](6) 4.2 Scanning Slit One method of obtaining the star image line spread function is now described. The standard microscope eyepiece is replaced with a scanning micrometer eyepiece similar to that described in Sec. 3.1 and 3.2.2. However, in the plane of the magnified star image, the scanning probe is a slit. Note that the slit's width should be significantly smaller than the PSF diameter, and its length should be significantly longer. Light passing through the slit is coupled into an optical fiber and then into a fiber optic cable. The fiber optic cable is brought out through the side of the scanning micrometer eyepiece and coupled to the PMT\/radiometer. The latter drives the y-axis of an xy-recorder while the x-axis position is controlled by the lateral position of the slit. For a rotationally symmetric PSF, slit scans along any diameter will generate identical MTFs, i.e., the MTF is also rotationally symmetric. On the other hand, MTFs for asymmetric PSFs will be direction dependent. PSF slit scans will have to be made along several different directions to build up a valid picture of the MTF. 4.3 Knife Edge Scan Instead of scanning the star image with a slit sampling aperture, suppose we scan across it with an opaque straight edge (knife edge). We collect the power (not blocked by the knife edge) and measure it with a radiometer. The signal output of the radiometer can be used to drive the y-axis of an xy-recorder. A linear transducer connected to the knife edge translation drives the x-axis. The resulting plot is called a knife edge distribution (KED). The steepness of the slope is a direct indication of image compactness. The LSF is the derivative of the KED in the scan direction. [D](7) This is illustrated in Figure 9. This also implies that the knife edge distribution and modulation transfer function are related via the line spread function as per Sec. 4.1. [D] Figure 9: The Line Spread Function is the Derivative of the Knife Edge Distribution 5. Measuring Wavefronts at the Star Image 5.1 Scanning Knife Edge The scanning knife edge technique is a clever enhancement of the classical Foucault knife edge test (References 8 and 9). The optical set-up is illustrated in Figure 10. A pair of orthogonally oriented knife edges is scanned across the image point (so that slope data can be acquired along two orthogonal directions). A lens behind the knife edge pair is used to image the pupil onto a CCD. [D] Figure 10: Wavefront Sensing via Double Knife Edge Scan The intensity is monitored at each pixel of the CCD. When a knife edge interacts with a quotrayquot from the conjugate pupil position, the intensity in the pixel changes. Data is accepted from that location when the intensity reaches 50% of its original value. This is also tied into the position of the knife edge at that moment (to yield the transverse ray aberration measurement). After both knife edges have passed through the image point, the data ensemble is passed to a computer program for analysis. Local slope data is fitted with a global Zernike polynomial (References 1 and 10) which can be related (via a large matrix inversion) to a Zernike description of the pupil optical path difference (OPD). 5.2 Point Diffraction Interferometer The point diffraction interferometer (PDI) (Reference 1) is a simple self-referencing interferometer. (It is a commercially available instrument built by Ealing Corp.) A physical description of the PDI is shown in Figure 11(a). It is a monolithic device consisting of two concentric circles (thin-film coated onto a thin transparent substrate). The fat annular region is semitransparent and acts like a neutral density filter. The small inner circle (pinhole) is a diffraction aperture and plays a spatial filtering role. PDI operation is illustrated in Figure 11(b). The aberrated wavefront is focused onto the PDI disc. Most of the beam passes through unhindered except for a reduction in intensity. The tiny part of the beam interacting with the pinhole is diffracted into a clean spherical wavefront, i.e., it has become the reference wavefront. Immediately on the far side of the PDI, interference takes place between the aberrated main beam and the reference beam. The operational F-number range of the commercial PDI is between F\/2-F\/11. However, at the extremum fringe contrast is down considerably. [D] Figure 11: (a) Construction of PDI; (b) Operational Principle Technical Rationale: All optical imaging systems used on spaceborne or space-related instruments should undergo an end-to-end systems check to validate performance. Star image testing is the primary means of conducting this validation process. It provides data pertinent to the pass\/fail criteria associated with the optical imaging system. References: 1. J. Geary, Introduction to Optical Testing, Tutorial Text TT-15, SPIE Press,(1993). J. Geary and P. Peterson, quotSpherical Aberration: a Possible New Measurement Approach,quot Opt.Eng. 25, 2, (1986). V. Mahajan, Aberration Theory Made Simple, Tutorial Text TT-6, SPIE Press, (1991). Q. Gong and S. Hsu, quotAberration measurement using axial intensity,quot Opt.Eng. 33, 4, pp 1176-1186, (1994). P. Peterson and J. Geary, quotIntermediate spherical aberration,quot Opt.Eng. 25, 11, pp 1232-1240, (1986). J. Gaskill, Linear Systems, Fourier Transforms and Optics, John Wiley, (1978). J.Goodman, Introduction to Fourier Optics McGraw-Hill (1968). J. Geary, M. Yoo, P. Davila, A. Wirth, A. Jankevics, M. Ruda, R. Zielinski, and L. Petrilli, quotComparison of Wavefront Sensors,quot SPIE Proc. Vol. 1776, pp 58-72, (1992). D. Vanderberg, W. Humbei, and A. Wertheimer,quotQuantitative Evaluation of Optical Surfaces by Means of an Improved Foucault Test Approach,quot Opt.Eng. 32, 8, pp 1951-1954, (1993). J. Wyant and K. Creath, Applied Optics and Optical Engineering, Vol. 11, Chap. 1, ed. R. Shannon and J. Wyant, Academic Press (1992). Reliability Preferred Practices, Guideline No. GT-TE-2405, Star Image Metrology Part I: Visual Measurements Reliability Preferred Practices, Guideline No. GT-TE-2404, Optical Testing Guideline: Fizeau Interferometry.","Lesson ID":720}
{"Driving Event":"This Lesson Learned is based on Reliability Practice Number PT-TE-1430 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Ni\/H2 battery technology is gaining wide acceptance as an energy storage system for use in space applications because of its reliability, weight and long cycle expectancy at deep depths-of-discharge (DOD). When a charged Ni\/H2 battery is short-circuited, its short circuit current data can be used to calculate the internal resistance of the cells for the purpose of determining the overall characteristics of the energy storage system. Also, by examining the cell impedance only, a Ni\/H2 battery simulation utilizing low cost lead-acid cells can be developed. Implementation Method: Ni\/H2 batteries will be used as the secondary source of electric power systems for many space applications, such as a space station. Most long term spaceflight will be orbiting in Low-Earth-Orbit (LEO) once every 90 minutes, which equals to approximately 6000 cycles per year and during each cycle there will be an eclipse period of approximately 30 minutes. During the eclipse period, electric power must be maintained to support many on going activities, such as life support, communication and experiments. A typical Ni\/H2 battery will contain 76 Ni\/H2 cells connected in series to produce a nominal battery voltage of 112 volts DC. Each cell has a capacity of 81 Amp-hours and will operate at nominal 35 % DOD. Based on the short-circuit testing conducted here at LeRC, Ni\/H2 battery is inductive in nature (no large current spike) and this was later confirmed by analysis of its internal cell structure. A 76 cell battery was not available, therefore, characteristics of a single cell and two cells in series were used to extrapolate the overall characteristics of the entire 76-cell Ni\/H2 battery. Figure 1 shows the external configuration of a typical Nickel\/Hydrogen cell. [D] Figure 1: Typical Nickel\/Hydrogen Aerospace Cell The test setup for the single cell short circuit test is shown in Figure 2. For safety reasons, the instrumentation and test personnel were separated from the short circuit test stand by means of a separate room. The test equipment located in the control room consisted of: a battery charge\/discharge controller to monitor and control state of charge, the relay control panel to control relay activation, and a four channel Digital Oscilloscope to record current and voltage transients. In the energy storage room the Ni\/H2 cell was mounted on a cold plate and contained in a sealed chamber which was purged with Gaseous Nitrogen (GN2) in case of hydrogen out-gassing. The cell was connected to a 400 Amp relay by a pair of 1\/0 welding cables, keeping cable length and inductance to a minimum. Current measurements were obtained using a Pearson current transformer (to capture quick alternating current (AC) transients) and a Hall effect current sensor. Initial tests showed that the Hall effect current probe had ample bandwidth to capture the current transient, and the Pearson current transformer was removed. [D] Figure 2: Ni\/H 2 Cell Short Circuit Test Block Diagram The test setup for the two-cell short circuit test differs only in the configuration of the cells. Instead of a single cell, two cells are connected in series and both are placed inside the test chamber. TEST DESCRIPTION: The cell(s) are setup as shown in Fig. 2, and the cell(s) are either charged to 100% state-of-charge (SOC) or discharged to a 65% SOC. The digital oscilloscope is set to trigger on the current rise and the relay is closed by the operator. The relay activation switch automatically de-energizes the relay after only 175 milliseconds of short circuit current. The test cells never lost any capacity and were not subjected to any thermal stress. The following are brief descriptions of the seven test measurements: Short Circuit Current Response of Ni\/H2 Cell (100% SOC) with the Pearson Current Transformer. The result shows a peak current of 746 A. During the short, it shows a cell voltage drop from 1.477 to 0.692 Vdc and a relay voltage drop of 0.339 Vdc. Short Circuit Current Response of Ni\/H2 Cell (100% SOC) with the Hall Effect Current Sensor. The result shows a peak current of 775 A. During the short, it shows a cell voltage drop from 1.479 to 0.691 Vdc and a relay voltage drop of 0.329 Vdc. Short Circuit of Ni\/H2 Cell (re-conditioned 100% SOC). The cell was fully discharged then fully charged again. This re-conditioning method has shown to improve the ampere capacity of the cell(s). However, little change in short circuit current (Isc) was measured. Same test as NO.3, but the time base was reduced to examine the start-up transient and switch bounce effect It has shown a good transient after the initial bounce. Short Circuit of Ni\/H2 Cell (re-conditioned 65% SOC). After the cell had been discharged to 35% DOD, results were lower cell voltage (1.295 Vdc) and consequently lower Isc of 659 A. Short Circuit of two series Ni\/H2 Cells (100% SOC). The Hall effect current of 987 A peak falling to 950 A within 171 ms. During the short, total cell voltage dropped from 2.967 to 0.795 Vdc. Short Circuit of two series Ni\/H2 Cells (65% SOC). The Hall effect current of 856 A peak falling to 832 A within 171 ms. During the short, total cell voltage dropped from 2.595 to 0.685 Vdc. Test Result Comparison Analyzed test results between single and duel cell test measurements. The short circuit current of a cell is not increasing at the same rate as the voltage from a single cell (test no. 2) to a double cell (test no. 6). The dual cell test had the NiH2 cells connected in series. The cell voltages would add up to be about double the voltage of a single cell (2.967 V vs. 1.479 V). However, in a series connection, the short circuit current is not expected to double. The short circuit current is simply a function of the cell voltage and the resistance in the short (Isc=Voc\/R). The resistance, R, is comprised of the internal cell resistance (Rb) and the external circuit resistance, Rext (cable and relay contacts). In an ideal test Rext= 0 the short circuit current should not change since both the voltage and the resistance is doubled when the cells are connected in series. However, since the external circuitry adds resistance, the short circuit current will increase as the external resistance becomes a smaller part of the total resistance. For example: analysis of the single cell data shows that the external circuit had 0.87 mOhms of resistance and that the internal cell resistance was about 1.06 mOhms. Therefore, the short circuit current should have about 1.479 V\/1.93 mOhms = 766 A. The test results were 775 A. Analysis of the two cell data goes along the same line. Assuming that both the voltage and the internal resistance were doubled, adding in the external resistance gives the expected short circuit current of: Isc=2.967 V\/(1.06 mOhms * 2 +0.87 mOhms)= 2.967 V\/2.99 mOhms = 992 A. The Actual test result was 987 A. In the same manner the voltage across the cell(s) during the short circuit is a function of the external resistance and the short circuit current (Vsc=Rext*Isc). Since Isc does not double and Rext remains constant, then Vsc is not expected to double. It will, however, increase as Isc increases. Note: Figure 3 shows a data plot of test NO. 7. Please refer to reference 1 for additional data plots of the other tests. [D] Figure 3: Plot No 7, Short Circuit Response of Two Series NI\/h 2 Cells at 65% SOC Data Analysis The internal impedance of the Ni\/H2 cell was calculated from the data presented above. Using the single cell and multiple cell tests, an internal resistance\/inductance was calculated. The data is used to extrapolate the short circuit current of the entire 76-cell battery. The equivalent Ni\/H2 single and dual cell(s) circuits are shown in Figure 4 and 5 respectively. All of the resistive components' values are derived by using direct-current (DC) circuit analysis. The internal cell inductance is calculated by simplifying the circuit in Figure 4 and 5 to a voltage source switched into a series resistor-inductor (RL) circuit. [D] Figure 4: Single Cell Equivalent Circuit Model [D] Figure 5: Dual Cell Equivalent Circuit Model Single Cell DC Analysis Measured values: Open circuit voltage (Voc), short circuit voltage (Vsc), battery voltage (Vbat), short circuit current (Isc), switch\/relay voltage (Vsw). Cable values: Cable resistance #1 (Rc1), cable resistance #2 (Rc2). Calculated component values: Battery resistance (Rb), switch\/relay contact resistance (Rsw). >From handbook or manufacturer specifications, look up cable resistance of 1\/0 copper stranded welding cable with .09 mOhm\/ft. Rc1= 2 ft. = 0.18 mOhms, Rc2 = 3 ft. = 0.27 mOhms, therefore total cable resistance (Rct) equals 0.45 mOhms. Relay resistance quotONquot calculation: Rsw= Vsw\/Isc An average value of Rsw was obtained: Average Rsw = 0.42 mOhm Battery resistance calculations: Voc represents the battery cell's ideal voltage source. Method #1: Isc = Voc \/ (Rb + Rc1 + Rc2 + Rsw ), therefore, Rb = (Voc \/ Isc ) - Rc1 - Rc2 - Rsw Method #2: Isc = (Voc - Vsc ) \/ Rb , therefore, Rb = (Voc - Vsc ) \/ Isc Note: Please refer to reference 1 for the detailed analysis of all the components values and calculation. Technical Rationale: ASA Lewis Research Center has conducted and will continue to support future research on Ni\/H2 cell battery technology for commercial and aerospace applications. From the current test equipment setup, and with the data obtained through the testing methods of a single cell and two cells in series, the internal cell characteristic impedance has been determined to be of approximately 1.0 mOhm and an internal inductance of approximately 0.55 microhenrys. Based on these test results, the short circuit current depends on the voltage and the resistance in the short. Knowing that the Ni\/H2 cell internal resistance was about 1.06 mOhms, the ultimate short circuit current could easily be calculated. Therefore a short worst-case short circuit current of 1753 Amps was predicted for a long term spaceflight, 76 Ni\/H2 cell battery design. References: Button, Rob; Pease, Gary; Birchenough, Art; Petrik, John; quotNi\/H2 Cell Short Circuit Testquot, Electrical Systems Division, NASA LeRC, Preliminary Test Report # 14, April 20, 1992. Button, Robert M., quotNi\/H2 Short Circuit Test of an Abnormal Cellquot, Electrical Systems Division, NASA LeRC, PIR #243, May 22, 1990. Research & Technology - 1992, NASA LeRC TM 105924, 1992. Dunlop, J. D.; NASA Handbook for Nickel-Hydrogen Batteries, Preliminary draft, Goddard Space Flight Center, May 1992. Gates Energy Products, Sealed Rechargeable Batteries Application Manual, 1989 quotBattery Selection Practice For Aerospace Power Systemsquot, Reliability Preferred Practice PD-ED-1221 quotDesign and Analysis of Electronic Circuits for Worst Case Environments and Part Variationsquot, Reliability Preferred Practice PD-ED-1212","Lesson ID":719}
{"Driving Event":"This Lessons Learned is based on Reliability Practice Number PD-ED-1242; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefits: This practice can be used to determine an optimum truss configuration (e.g. minimum number of members) for a given loading condition and specified reliability. Probabilistic Structural Analysis Methods (PSAM) provides a formal and systematic way to evaluate structural performance reliability or risk at minimal time and low cost. Implementation Method: The purpose of this application is to probabilistically evaluate a three-dimensional, three-bay, space cantilever truss by using the computer code NESSUS (Numerical Evaluation of Stochastic Structures under Stress). Using PSAM will enable design engineers to identify and quantify the sensitivities associated with uncertainties in primitive variables (structural, material and load parameters) describing the truss. The primitive variables for a given space truss such as stiffness parameters, strength parameters, spatial truss geometry, and applied loads or moments will vary continuously due to changes in the space environment. Each of these primitive variables distribution is characterized in terms of one of several available probability distributions, such as the Weibull, exponential, normal, log-normal, etc. The cumulative distribution functions for the response functions considered and sensitivities associated with the primitive variables for given response are investigated. These distributions have significant impact on the separation\/range of the response variables such as nodal displacements, eigen-values, member forces, vibration frequencies, etc. These sensitivities help in determining the dominating primitive variables for a particular response. Program Capability and Description The NESSUS code consists of three major modules: (1) NESSUS\/PRE (pre-processor) module is used to obtain the characteristic of a partially correlated Gaussian field in terms of a set of uncorrelated random vectors. (2) NESSUS\/FEM (Finite Element Methods) module is a finite element analysis code that can generate perturbed solutions about a deterministic state. It contains an efficient perturbation technique such that the perturbation of each variable is done rapidly. Each perturbation corresponds to a prescribed deviation from the deterministic model. (3) NESSUS\/FPI (Fast Probability Integration) module contains several advanced reliability methods including Monte-Carlo simulation. Since NESSUS\/PFEM combined the NESSUS\/FEM and NESSUS\/FPI modules into a single computer program, the entire probabilistic finite element analysis including perturbations of the primitive variables can be performed in a single execution step. The fast probability integration (FPI) techniques are one or several orders of magnitude more efficient than the Monte-Carlo simulation methods. FPI module extracts the database of perturbed solutions from NESSUS\/FEM to calculate the probability distribution functions of the response variables. In general, the primitive variables are specified with their mean values (m), standard deviation (s), and the type of distribution. Note: Each module can be operated independently. Probabilistic Finite Element Analysis In general, the finite element equation for motion is written as: [M] {u\u0308} + [C] {m} + [K] {u} = F(t) Equation (1) Where: [M] denotes mass matrix. [C] denotes damping matrix. [K] denotes the stiffness matrix {u\u0308} denotes acceleration vector. {m} denotes velocity vector. {u} denotes displacement vector. Note: These matrices are calculated probabilistically in the NESSUS code. The forcing function vector, {F(t)}, is time dependent at each node. In this practice, the static case is considered by setting the mass and damping matrices to zero and considering the forcing function being independent of time in equation (1) such that [K] {u} = {F} Equation (2) Furthermore, by just setting the damping matrix to zero, eigenvalue analysis can be accomplished by using [[K] - w2 [M]] {u} = 0 Equation (3) where w denote eigenvalues and {u} are the corresponding eigenvectors. Finite Element Model A three-dimensional, three-bay cantilever truss is computationally simulated using a linear isoparametric beam element based on the Timoshenko beam formulation. The element is idealized as a two-noded line segment in three-dimensional space. The cantilever truss is assumed to be made from 44 hollow circular tube members (see Fig. 1). The tubes are made up of wrought Aluminum alloy with modulus of elasticity (E) equal to 10 Mpsi. The outer and inner radii (ro and ri) of the tube are 0.5 and 0.4375 in., respectively. All 6 degrees-of -freedom are restrained at the fixed end (left side) nodes. The truss is analyzed twice, once using beam elements and then using pseudo-truss elements. The beam element is converted into a pseudo-truss element by suppressing the effective shear areas in the principal planes (Axx and Ayy), the two principal moments of inertias for the tube cross-section, (Ixx and Iyy), and torsional constant, J. In the case of truss elements, 3 rotational degrees of freedom at each node and 3 translational degrees of freedom at support nodes are restrained. Each bay of the truss is 5 ft wide, 8 ft long, and 6 ft high ( see Fig. 1 ). The overall length of the truss is 24 ft. Six vertical and two longitudinal loads are applied. Twisting moments are applied at the truss-end top nodes for truss elements. The directions of the forces and moments are shown in Figure 1 and the mean values are given in Table I. Probabilistic Model The following primitive variables are considered in perturbation analysis: ( 1 ) Nodal Coordinates ( X, Y, Z ) ( 2 ) Modulus of elasticity ( E ) ( 3 ) Outer radius of the tube (ro) ( 4 ) Inner radius of the tube (ri) ( 5 ) Vertical loads ( V ) ( 6 ) Longitudinal loads ( H ) ( 7 ) Truss-end moments ( M ) ( 8 ) Truss-end coupling forces ( P ) It is possible that the above primitive design variables will vary continuously and simultaneously due to extreme changes in the environment when trusses are used in upper Earth orbit for space station type structures. The normal distribution is used to represent the uncertainties in E, ro, ri, and X, Y, Z coordinates. [D] The applied loads, moments and coupling forces are selected to represent anticipated loading conditions for a typical space truss. These are represented by log-normal distributions. Initially, NESSUS\/FEM module is used to take into consideration the mean value of these primitive variables. In the subsequent probabilistic analysis each primitive variable is perturbed equidistant from the mean value. However, each variable is perturbed independently and by a different amount. Usually, the perturbed value of the design variable is taken as a certain fraction of the standard deviation at either side of the mean value. Finally, the NESSUS\/FPI module extracts response variable values (one deterministic and two times the number of primitive variables) to calculate a probability distribution function of the response variable considered. The mean, distribution type and percentage variation for different primitive variable are given in Table I. [D] Data Analysis The three-dimensional, three-bay cantilever truss is probabilistically analyzed and the cumulative probability distributions for the truss end displacements, member forces and vibration frequencies are plotted. The sensitivities of the primitive variables on the scatter in the truss structural responses (truss free end displacements, member axial forces and vibration frequencies) are quantified in Table II. Please refer to the reference articles of this practice for other information\/figures such as the probabilistic displacement of the truss free end nodes (top and bottom) in X, Y, and Z directions using the truss element. The cumulative distribution functions of frequencies of modes 1 and 2 using truss elements are plotted (see sample Figure 2, others please refer to the reference articles). Please refer to the reference articles for other valuable information such as data plots for the truss modelled with beam elements. It is important to note from Table II that the cross-sectional area (primitive variables ro and ri) has a significant impact on the probabilistic distribution of the vibration frequencies. For additional result formats please refer to reference 1. [D] [D] Technical Rationale: Traditional deterministic methods applied to the analysis of space truss design only consider applied loads for given operating condition. To account for uncertainties in assumptions of loading and material strength, load factors and safety factors are applied to assure the final design will satisfy design specifications. This traditional approach to stress analysis does not formally address the natural uncertainties of primitive variables (fundamental parameters describing the structural problem) such as the uncertainties of loading and material strength. Numerous uncertainties associated with truss structures in space environments require a quantitative and systematic method to ascertain that the structural response will be within the acceptable limits during the life of the structure. Probabilistic structural analysis provides a formal way to properly account for all these uncertainties. Currently available software tools do not easily allow determination of any local instability in any of the internal members of the truss during probabilistic analysis. Therefore, NASA Lewis Research Center developed PSAM, which provides a formal and systematic way to reliably evaluate structural performance and durability. PSAM takes into account the uncertainty of primitive variables and will yield a stable and optimum configuration for given load conditions. This probabilistic approach also takes into account the uncertainties of primitive variables in the space environment. References Pai, S.S., quotProbabilistic Structural Analysis of a Truss Typical for Space Stationquot, NASA Technical Memorandum 103277, 1990. Pai, S.S. and Chamis, C.C., quotProbabilistic Progressive Buckling of Trussesquot, NASA Technical Memorandum 105162, 1991. Research & Technology - 1992, NASA LeRC TM 105924, 1992. Pai, S.S. and Chamis, C.C., quotProbabilistic Structural Analysis of Adaptive\/Smart\/Intelligent Space Structuresquot, NASA Technical Memorandum 105408, 1991. Pai, S.S. and Chamis, C.C., quotProbabilistic Assessment of Space Trusses Subjected to Combined Mechanical and Thermal Loadsquot, NASA Technical Memorandum 105429, 1992. NOTE: Please refer to the attached Software Release Request form for information on how to obtain the NESSUS software. SOFTWARE RELEASE REQUEST","Lesson ID":721}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number PM-4 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. In the past, preventive maintenance was performed without any guidance or regard for safety or cost concerns, as long as systems performed their functions. The primary reason for the development of RCM was to implement a preventive maintenance strategy that could adequately address system availability and safety at the lowest possible cost. The RCM process answers and directs preventive maintenance decisions as to the what, where, and when types of questions. Introduction In the past, product development and manufacturing engineering dominated the technical disciplines in the U.S. industrial community with operations and maintenance (O&M) taking a lower priority to corporate success strategies. This priority has dramatically shifted to the point that O&M is now on a par with the development and manufacturing disciplines. Concerns about maintenance and logistics costs caused this shift in priority. A valid question is how to get maximum use of resources committed to the preventive maintenance program. This technique discusses preventive maintenance and defines RCM as part of an effective preventive maintenance program. Some cost-benefit considerations realized through the use of RCM are also illustrated. Introduction to Preventive Maintenance The majority of systems have long been operating in the corrective maintenance mode. Corrective maintenance is the performance of and almost total commitment of resources to unplanned or unexpected maintenance tasks. Preventive maintenance, however, is the pre-planning of inspection and\/or servicing tasks. Corrective approaches restore the functional capabilities of failed or malfunctioning equipment or systems. However, corrective maintenance is more costly than preventive maintenance because of the unplanned interruptions of operations, idle time waiting for spare parts, and haphazard troubleshooting for failure causes. Preventive Maintenance Program In general, when creating a new or upgrading an existing preventive maintenance program, two items of essential information are required: (1) identification of what preventive maintenance tasks are to be performed and (2) when each task should be performed (see Figure 1). [D] Whatever method is used to determine what or if a task is to be performed results in a time-directed, condition-directed, or failure-finding task selection or a run-to-failure decision (as defined above). The next step is to incorporate the preventive maintenance program into the existing operations infrastructure and to ensure that it is implemented in everyday operations. Moreover, a series of questions must be answered before any program can be implemented. Typically, such questions might include the following: Are new procedures or modifications to existing procedures required? Are all the standard materials (tools, filters, etc.) available? Is any special tooling or instrumentation required? Are an appropriate number of people available to conduct the program? Are any capital investments required? Will the new\/upgraded program affect the quantity of on-hand spares required? How long will it take to incorporate the new\/upgraded program into the maintenance management information system (MMIS)? Is the existing MMIS capable of accepting the entire new\/upgraded program (e.g., tracking time sequenced data in condition-directed tasks)? If full shutdown must be periodically planned, do the tasks and task intervals lend themselves to such a schedule? Do new tasks require a cycle that is a common denominator with other existing task intervals? Preventive Maintenance Program Elements Figure 1 is a simplified illustration of a preventive maintenance program development. Many supporting management and technical disciplines are involved in the development of the ideal preventive maintenance program and task packaging, and they are important in supporting the RCM concept that is discussed later in this technique. The important supporting technologies used in the development process are described below. A product malfunction or failure can present a significant learning opportunity in that much technical knowledge can be gained from comprehensive failure reporting, root cause analysis, and corrective action feedback programs. Without such programs, it is virtually impossible to establish proper corrective action or to intelligently decide if any preventive maintenance action is possible. A good failure reporting system is vital to the quotretain or increase mean-time between failuresquot portion of an availability improvement program. To prudently employ condition-directed tasks requires an entire diagnostic technology that is still evolving with new techniques and applications. The technology is dedicated to following, understanding, and contributing to the area generally referred to as quotpredictive maintenance technology.quot Some of the tools that comprise predictive maintenance technology are as follows: Vibration, pulse, and spike energy measurement. Acoustic leak detection. Thermal imaging. Fiber optic inspection. Trace element sensing. Debris analysis. Lubricant analysis. Stress\/strain\/torque measurement. Nonintrusive flow measurement. Microprocessors with expert system software. Preventive Maintenance Task Packaging This task consists of three major elements: Task Specification. The task specification provides complete technical definition and direction of specific requirements to the implementing maintenance organization. This document, which is the key transition from the ideal to the real world, either (1) details the data measurement and evaluation requirements for a condition-directed task along with the limiting acceptance criteria or (2) specifies critical requirements that must be met in a time-directed overhaul task. Procedure. The procedure is a basic document that guides the execution of a preventive maintenance task. The document may be a one page instruction for a simple task or complex details on precisely how the preventive maintenance task is to be achieved. Logistics. The logistics entail a variety of administrative and production support activities. Typical logistic considerations include tooling, spare parts, vendor support, training, documents and drawings, make\/buy decisions, test equipment, scheduling, etc. Clearly, these considerations closely interplay with both the task specification and procedure and constitute a major portion of maintenance planning. In summary, a preventive maintenance program can be created or upgraded by implementing the ideas given above. With the support of key technologies, it will produce the quotwhat taskquot and quotwhen donequot information. Reliability Centered Maintenance (RCM) As conveyed above, the objective of most of the current preventive maintenance practices is to preserve equipment operation. Until recently, this has resulted in little, if any, consideration as to why certain preventive maintenance actions and are taken and what priority should be assigned to the expenditure of preventive maintenance resources. Almost without fail, maintenance planning starts with the equipment and seeks to specify as quickly as possible those components necessary to keep it running. RCM is not just another approach to this repetitive process. The basic RCM concept is really quite simple and might be characterized as organized engineering common sense. The features that define and characterize RCM and set it apart from any other preventive maintenance planning processes in use today are described below. Preserves System Function. Unlike the ingrained notion that preventive maintenance is performed to preserve equipment operation, the primary objective of RCM is to preserve system function. Although equipment preservation leads ultimately to system preservation, it is not the initial step in the RCM process. In RCM, the expected output is known, and preserving that output or function is the primary task. This feature enables systematic decisions in later stages of the process as to just what equipment relates to that function and does not assume a priori that quotevery item of equipment is equally important,quot a tendency that seems to pervade the current preventive maintenance approach. Identifies Failure Modes That Can Produce Unwanted Functional Failures. After preserving system function, avoiding loss of function or functional failure is the next item of RCM consideration. Functional failures take many forms and may occur in various stages, all of which must be considered. The loss of fluid boundary integrity is a functional failure that illustrates this point. A system loss of fluid can be caused by (1) a minor leak that may be qualitatively defined as a drip; (2) a leak defined as a design basis leak (any loss beyond a certain gallon per minute value will produce a negative effect on system function); or (3) a total loss of boundary integrity, which can be defined as a catastrophic loss of fluid and loss of function. In this example, a single function could lead to three distinct functional failures. The key to the failure identification feature is to identify the specific failure modes in specific components that can potentially produce those unwanted functional failures. Enables Prioritization of Failure Modes. In preserving system function, RCM provides a systematic approach to deciding what priority must be assigned to budget and resource allocations. Since functional failures and their related failure modes are as diverse as the functions and components they affect, the prioritization of failure modes is essential. Allows Preventive Maintenance Tasks To Be Judged As To Applicability and Effectiveness. The features described above help in developing a very specific roadmap to the where and why, of the maintenance task and the priority that should be assigned to it. Each potential task must then be judged as to (1) its applicability (i.e., will it prevent or mitigate a failure, detect the onset of a failure, or discover a hidden failure) and (2) its effectiveness (i.e., does it justify the spending of resources to do it). Generally, if more than one candidate task is judged to be applicable and effective, the least expensive task will be selected. If a task fails either the applicability or effectiveness test, a run-to failure decision must be made. Cost-Benefit Considerations. The primary force behind the invention of RCM was the need to develop a preventive maintenance strategy that could adequately address system availability and safety without creating a totally impractical cost requirement. Figure 2 illustrates the success of keeping commercial aircraft maintenance cost per flight hour constant from the late 1960's to the early 1980's. [D] Table 1 presents another way to view the impact of RCM on the commercial aircraft world. [D] Two significant points can be observed from these data: (1) the dramatic shift in the reduction of costly component overhauls during the pre-1964 and post-1960\/1987 periods; and (2) the constancy of the condition-directed task structure. The reduction in expensive component overhauls, brought about by run-to-failure decisions, was made possible by a design philosophy that included double and triple structural design redundancy in the flight-critical functions. RCM was used to take advantage of these structural design features when preventive maintenance was critical and the run-to-failure decision was appropriate. The constancy of the condition-directed task structure is attributed to the fact that the commercial aircraft industry was one of the early users of performance and diagnostic monitoring as a preventive maintenance tool. It has continued to successfully apply this practice throughout the generation of the newer jet aircraft. The results indicated in figure 2 and table 1 have led to a growing interest in other such areas as nuclear power generation and electric utility plants. The obvious reasons for this growing interest are (1) control and reduction of O&M costs and (2) increase in plant availability. All of this indicates that the cost-reduction benefits of RCM that dramatically impacted commercial aviation offer similar potential dramatic payoffs in other areas in which complex plants and systems are routinely operated. Conclusion RCM is a logical approach to preventive maintenance which does not rely on any heuristic processes. RCM helps in making direct and deliberate preventive maintenance decisions that were not previously possible. It can also be used as the methodology for defining preventive maintenance for a such new systems as the Space Station. Virtually every organization that has conducted an RCM program has recognized the value of the system analysis process as a training ground for system engineers. In addition, the failure scenarios developed in RCM analyses may be used beneficially as simulator inputs to plant transient or upset conditions in order to anticipate such occurrences in the future. References Annual Reliability and Maintainability Symposium, 1991 Proceedings. Matteson, Thomas D., quotThe Origin of Reliability-Centered Maintenance,quot Proceedings of the Sixth International Maintenance Conference, Institute of Industrial Engineers, October 1989. quotReliability-Centered Maintenance for Aircraft Engines and Equipment,quot MIL-STD-1843, February 8, 1985. quotRCM Cost-Benefits Evaluation,quot Electric Power Research Institute, Interim EPRI Report, January 1992.","Lesson ID":891}
{"Driving Event":"This Lesson Learned is based on Reliability Guideline Number GT-TE-2404 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: The Fizeau interferometer is used to measure the quality of optical components and systems. It provides a guide for the manufacturing of components, an aid for alignment, and a validation of system performance. Implementation Method: Description of Fizeau Interferometer The basic layout of a Fizeau interferometer is shown in Figure 1 (Reference 1.). A laser source is spatially filtered via a microscope objective and a pinhole. This pinhole is located at the focal point of a collimating lens. Between the pinhole and lens is a beam-splitter. The collimated beam encounters a slightly wedged glass plate. This is the heart of the interferometer. The surface adjacent to the collimating lens is of good optical quality. However, the next surface is of exceptional optical quality, l\/20 peak to valley (PV) or better. This is the reference surface and part of the collimated beam is reflected by this surface. Part of the collimated beam continues on to interrogate the optic being tested. The return beam contains information on aberration introduced by the test optic. The two wavefronts recombine inside the interferometer. The beam-splitter diverts the combined beams toward a recording medium, either film or a TV (CCD or vidicon). An intermediate lens together with the collimating lens forms an image of the test surface onto the recording plane. An observer will see a sharp image of the test surface with an interference (or fringe) pattern running through it. [D] Application of Fizeau Interferometer 1. Testing a Flat Suppose the test object is a plane glass surface whose quality (flatness) we wish to inspect. We must first align the test surface to the interferometer. Most commercial Fizeau interferometers have an quotalign mode.quot This requires the user to center a bright dot (the reflected return) on a crosshair on some viewing screen. Suppose the test surface has a depression in it as illustrated in Figure 2. The flat wavefront from the interferometer is incident on the test surface and reflected back into the interferometer. Note that the reflected portion shown in Figure 2 has picked up twice the surface error inherent in the test surface. This aberrated wavefront returns through the reference plate to combine with the reflected reference. [D] Wherever two coherent wavefronts overlap they interfere with each other. The equation describing interference (Reference 2) is as follows: [D] To obtain good high contrast fringes requires that the reflection off the reference and off the test piece must be equivalent in intensity. Maximum fringe contrast occurs when I1 = I2 . For example, a bare glass test surface reflects 4%. To maximize fringe contrast the reference surface must also reflect 4%. If a 4% reference surface is used to test a mirror (with 90% plus reflectivity), then a very thin beam-splitter (e.g., a pellicle) can be used to reduce the intensity from the test optic. Alternatively, a reference surface having a much higher reflectivity can be used to improve fringe contrast. In the latter case, one will notice that the dark fringes become much thinner, like sharp pencil lines. A sample interferogram of a supposed quotflatquot mirror is shown in Figure 3. If the mirror were flat, equally spaced straight line fringes should be observed (depending on the relative tilt between the reference surface and the test surface). Obviously, the mirror is not very flat at all. Each fringe is a height contour as in a topographical map. (The metric or unit of measure in most Fizeau interferometers is the wavelength of the source. For example, the helium near laser wavelength is 0.6328 microns.) The height difference between each contour or fringe is 1 wave. If knowledge of the surface error or its departure from flatness is desired, we must interpret these fringes as representing half-wave contours! [D] In addition we must know whether the pattern seen in Figure 3 is a hill or a valley on the mirror surface. This can be determined by placing your finger on the front of the reference surface metal support ring (Figure 1) and pressing lightly toward the interferometer housing. If the fringe patterns collapse or contract, the pattern represents a hill or bump. If they expand, the pattern represents a valley. 2. Testing a Lens The setup for testing a lens is illustrated in Figure 4. The lens is carefully aligned to the Fizeau beam. The beam is focused by the lens to an image point. To return the beam back to the interferometer another auxiliary reference surface is needed. In this example a small concave spherical mirror is used. This sphere should be mounted so that X,Y, and Z translation degrees of freedom are available. The center of curvature of the sphere is then made coincident with the focal point of the lens. (Be careful\u2013make sure that the focussed beam is not on the surface of the small retro sphere). The beam is reflected by the reference sphere and returned through the system. [D] The interferogram that is initially seen is likely to be an off-center bull's eye pattern. This means that the reference sphere's center of curvature is not axially coincident with the lens focal point. Use the tip and tilt adjustments on the Fizeau reference surface to center the bull's eye as shown in Figure 5(a), then use the axial translation on the concave sphere to move the interferogram into a best null condition (i.e., minimizing the number of fringes seen over the interferogram), Figure 5(b). Now use the adjustments on the reference flat to introduce tilt fringes as shown in Figure 5(c). It should be noted that the test system has significant spherical aberration. [D] An alternate setup for testing a lens is shown in Figure 6. Here the Fizeau reference surface is a sphere. It is a specially designed positive power lens where rays emerging from the last surface of the lens are normal to that surface. The test lens is aligned to the test beam and oriented so its rear focal point is coincident with the transmission spheres focal point. The beam emerges from the lens as collimated light. A flat auxiliary referencesurface is needed to retro-reflect the test beam back to the interferometer. [D] We note that transmission spheres come in a variety of F-numbers. Since your test lens has a certain F-number, pick a transmission sphere whose F-number provides a beam that either fills or overfills the test lens. Never pick a transmission sphere that underfills because then you are not testing the lens over its full aperture. Aberration content will appear lower than it actually is. Configurations for testing a wide variety of other systems are illustrated in Figure 7. [D] 3. Retrace Error The purpose of the reference sphere in Figure 4 is to return the incoming ray back upon itself so that it follows the same path on the second pass as it did on the first pass. This occurs exactly only when the incoming beam happens to be perfect, i.e. exhibits a spherical wavefront. As aberration accumulates on the first pass through the test system, the match to the reference sphere becomes less perfect. Path deviations appear on the return ray, which is now no longer coincident with the first pass ray. The optical path difference picked up by the second pass ray is not the same as the first pass ray. This is retrace error (also called ray-mapping error) (References 1, 3 and 4). As a consequence, it is no longer true that we can simply divide the results by two to obtain the single pass wavefront aberration from double pass fringe data. There are some visual clues to indicate if retrace error is significant. First, with the room darkened, check to see that the beam diameter of the light returning through the test optic on the second-pass is the same as that for the first pass after setting the null-fringe. Second, examine the irradiance distribution of this second-pass beam at the test optic. If the second-pass beam overfills or underfills the test optic aperture, and\/or the intensity distribution is nonuniform, then retrace error is significant in the test setup. To minimize the effect of retrace error, a different retro optic is usually needed. If retrace error were significant in the case illustrated in Figure 4, then a longer radius of curvature retro sphere is needed and it should be convex instead of concave. This is shown in Figure 8. The longer radius convex surface reduces the angular disparity between the incident and reflected rays. It also reduces the lateral offset between the first and second pass rays at surfaces in the test optic. [D] 4. Collecting and Handling Data It is not the purpose of this guideline to describe methods used to analyze interferograms. That deserves a guideline of its own. However, we will describe the various data collection schemes and how they interface with the analysis software. There are basically three options available to the user: 1) digitizing tablet, 2) automatic fringe following; 3) uniform grid phase measuring. The simplest and least expensive means of selecting and inputting data to an analysis code is via a digitizing tablet. A hard copy of the interferogram is placed on the tablet. The user interfaces with the tablet (and the fringe analysis code) with a digitizing pen or mouse. The code first asks the user to define the pupil. Next, data points for each fringe are entered in proper sequence from low to high contour. Once this data file is entered into the computer, the fringe code can proceed with its analysis and determine aberration content. To avoid the toil of hand digitizing, software packages are commercially available that incorporate a fringe following routine. The interferogram is imaged onto a CCD. A frame-grabber captures the fringe pattern and formats it for the computer. This intensity digitized image is then operated on by the fringe following software. It automatically generates data centered along a fringe. However, the user still must define the fringe order. An alternative approach to fringe following is a phase measuring interferometer (PMI). This is a highly automated data acquisition system. The reference plate of the Fizeau is mounted in a fixture which is piezoelectrically driven, i.e. minute cyclic axial shifts are introduced. (This is equivalent to introducing a piston into the fringe pattern.) The pupil image (with fringes across it) is recorded on a CCD. The CCD is a uniform array of sensors. Each pixel monitors the variation in local irradiance as the reference plate is moved by the actuators. Data is acquired at every pixel for four or five discrete positions of the reference plate during its sweep. This enormous amount of data is fed into a computer where the analysis software calculates the local phase at each pixel. Fringe ordering is done automatically. Plus, the huge amount of data collected on a uniform grid offers a dramatic improvement in accuracy and repeatability. Also note that this method allows the user to analyze the quotnullquot interference pattern, something the first two techniques cannot do. For a particular test setup it is usually a good idea to take four separate interferograms with fringes tilt-biased top, bottom, right, and left respectively. Fringe codes usually have an option whereby several interferograms can be averaged. An interferogram from each fringe bias is entered into the code, and the ensemble average obtained. This average is a better estimate of aberration content than any single interferogram. When testing imaging systems it is a good practice to repeat the test setup at least three times. This is because misalignments in the setup can introduce unwanted aberrations (usually coma). For each setup obtain the four fringe biased data sets mentioned above and calculate the subaverage. Then average these subaverages. 5. Environmental Constraints Vibration, whether induced through the floor into the air-isolated optical table supporting the interferometer or coupled via acoustics, is a major weakness of interferometers. This mechanical noise makes the fringe pattern unstable; it dances around at high frequency. It is hard to do meaningful interferometry under such shaky circumstances. Hence it is very important when establishing a metrology lab to locate it in a quiet area. For example, you would not want to place it between a machine shop and an optical fabrication shop. At times it may even be necessary to come in at night, when everyone else is gone and all other machines are turned off, just to get stable fringes. Another source of trouble is air currents or turbulence from air vents, or thermals (from electronic equipment for example). The fringes don't dance as with mechanical vibration but actually change shape. They meander! When an interferogram is obtained under these circumstances you are not sure how much is the test piece and how much due to changes in the refractive index in the intervening air. Shrouding the work area can be a considerable help. For example, commercial foam board from office supply houses is a useful shrouding material. Also, with a PMI, frame averaging can sometimes reduce the problem considerably. 6. Mounting Sometimes an aberration attributed to a test optic is actually induced by the manner in which the optic is held in a mount. People are sometimes afraid that an optic might fall out, so they clamp it in (or down) good and tight. As a result, the interferogram may show significant aberration (usually astigmatism) even though the optic itself is of excellent quality. So be careful, you want to constrain the test optic with a minimum of force\u2013snug enough so that it doesn't rattle around\u2013but loose enough to avoid stress-induced deformation. Large optics (meter class) have an additional mounting difficulty. They are usually quite heavy and can deform under their own weight (Reference 5). The fringe pattern will show significant astigmatism. Astronomical primary mirrors are particularly susceptible to this. Elaborate fixturing is sometimes required to alleviate the problem. Technical Rationale: All optics to be used on spaceborne or space-related instruments should be tested to validate their performance as required by specification. The Fizeau interferometer is the primary tool in this optical validation process. It provides the standard against which other optics are compared. Therefore proper use of a Fizeau interferometer ensures that the resulting data can be employed as a pass\/fail criteria on the component or system. References J. Geary, Introduction to Optical Testing, Vol. TT 15, SPIE Optical Engineering Press (1993). P. Hariharan, Basics of Interferometry, Academic Press (1992). D. Malacara, Optical Shop Testing, 2nd edition, John Wiley (1991). L. Selberg, quotInterferometer accuracy and precision,quot in SPIE Proceedings, Vol. 749, pp. 8-18 (1987) and in Vol. 1400, pp. 813-820. P. Yoder, Opto-Mechanical System Design,quot Marcel Dekker, Inc., 2nd edition (1993). J. Geary and L. Parker, quotNew test for cylindrical optics,quot Opt. Eng. 26, 8, pp. 813-820.","Lesson ID":717}
{"Driving Event":"This Lesson Learned is based on Reliability Guideline Number GT-TE-2403 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Adherence to this Guideline gives confidence that mechanisms will operate successfully during flight. The design phase analytical methods and results are verified. Testing determines margins to show by how much the design requirements are exceeded and pinpoints potential problem areas. Experience gained from failures and anomalies during testing help prevent recurrence in future programs. Implementation Method: In order to realize the benefits of a deployable appendages test program, the following steps should be taken: Use the design requirements for the hardware to be tested to generate a list of tests that will verify that each requirement will be met. This list should include how many times each test must be conducted, and the pass\/fail criteria for each test. From this list, determine which tests can be combined to save time and costs. Select the critical design parameters for which test values and margins are to be measured. Decide what facilities and equipment will be needed for the tests. Design, analyze, fabricate, and check out any new items needed. Determine what personnel will be required for each test. Put together an overall schedule of tests, paying particular attention to the logistics of personnel, facilities, and material needed for each test. Use the results of the previous steps to write a comprehensive test plan. Follow the plan to set up and conduct the tests, then perform data reduction and analysis. Write up the results of the tests in one or more test reports. Correct deficiencies revealed in testing and re-test to verify the modified configuration. Technical Considerations: To realize all the benefits, the test program should include: Thorough testing to qualify the design and correlate the design analysis. Acceptance criteria must be established prior to the start of testing. Testing at greater extremes (temperatures, vacuum, loads) than expected during flight to determine margins. Testing of flight-like hardware to prove designs. Testing of actual flight hardware to prove workmanship and determine values of specific design parameters. Comprehensive part and component testing, to lessen the risk of failure at subsystem and system program phases, when such failures are very costly. Parts and components include: Bearings Springs Dampers Motors, gear trains Switches, position indicators Testing of subsystems (such as drive assemblies, hinge assemblies, gimbals, etc.) should include the following general tests: Mass properties Component interfaces System interface Subsystem performance verification (including margins) Subsystem strength verification Subsystem life, including lubricant\/lubricant systems Thermal vacuum EMI\/EMC Magnetic Vibration\/acoustics Specific subsystem tests should include (where applicable): Restraint\/release assembly tests Hinge assembly tests Drive assembly tests (solar array-antenna) Gimbal assembly tests System tests of complete deployable appendages should include: System tests should match flight configuration as closely as possible. Where practical, full deployment testing in simulated zero-G environment, including release, deployment, and lock-in. Deployment in thermal-vacuum is preferable, but generally impractical. Vibro\/acoustic testing of the system in launch configuration should precede full deployment testing. Parameters to measure (where applicable) should include: Deployment time, release to lock-in Motor current Stiffness stowed and deployed Alignment Envelope of motion during deployment Electrical integrity of cables across hinges and gimbals Release shock Velocity at end of travel Torque margins System life, if applicable In-depth investigation of all anomalies. Test facilities include: Design and Analysis - deployment testing of large appendages usually requires special, tailor-made facilities to simulate actual flight conditions as closely as possible, and to perform special engineering tests. Such hardware includes: G-negation devices Inertial load simulators Thermal control devices capable of producing temperature levels and gradients Fixtures for environmental tests Fixtures for conducting stiffness measurements, modal tests, etc. Facility Design Parameters Simulation of mechanical and electrical launch configuration interfaces Space available for full deployment Type , number, size, and location of g-negation supports Weight, size, cost, manufacturability of fixtures Transportability of fixtures, if required Analysis Parameters Load carrying capacity of fixtures Effect of fixtures on measured data Pre-test predictions and establishment of pass\/fail criteria Pre-test Environmental test fixtures must be calibrated and safety tested in actual facility prior to use Technical Rationale: Testing of deployable appendages for spacecraft differs somewhat from the testing of other space hardware. It involves special considerations for dealing with large, cumbersome devices that usually require some degree of manual handing after each operation. Since ground testing is done in a 1-g environment, a complex facility is usually required for simulating the zero-g space condition (g-negation device). This guideline covers the complete test program for spacecraft deployable appendages, including the general tests that also pertain to other space hardware, and the tests specifically pertinent to deployable appendages. References: GSFC Engineering Directorate paper, \"Spacecraft Deployable Appendages,\" May 1992. Reliability Preferred Practice No. PD-EC-1101, Environmental Factors","Lesson ID":716}
{"Driving Event":"This Lesson Learned is based on Reliability Guideline Number GT-TE-2405 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Star image measurements provide the primary means of appraising the end-to-end health of an optical imaging system. These tests represent good engineering practice, and are reliable indicators of system performance. Star image tests are thus the final arbiter of quality control. A system passing the star tests discussed here ensures that the optical instrument is performing in a reliable manner. Visual inspection of the star image pattern is a simple and efficient means of determining whether a problem exists. If something is wrong, important clues as to its nature (e.g., decentered component, inappropriate conic constant) can be provided. Implementation Method: 1. Description of Star Image Test Apparatus The basic equipment needed to perform laboratory star image visual measurements is indicated in Figure 1. The optical system on the left half of the drawing is a Star Simulator. This is a Collimator with a back-illuminated pinhole located in the focal plane. The Collimator can be either reflective or refractive, and its pupil should be larger than the imaging system being tested. The pinhole represents the star, and its diameter should be smaller than the Collimator Airy Disc, (i.e., unresolved). Depending on the application, the pinhole back-illumination can be either from a coherent or incoherent source. An example of the former is a laser; the latter, a point arc lamp. Between the source and the pinhole there is usually some coupling optics to maximize the power through the pinhole, and to fill the aperture of the Collimator with light. (Caution: The pinhole acts like a quotpinhole camera.quot If a coiled filament lamp is used, an image of the coil will be formed on the collimator pupil and the output irradiance will be quite nonuniform). [D] Figure 1. Basic layout of a star image test setup A support structure is needed to hold the optical system under test. This mounting fixture should provide modest azimuth and elevation tilt control to allow alignment of the quottest systemquot to the Collimator optical axis. The test support fixture should also allow the quottest systemquot to be accurately rotated through its operational field of view. For refractive quottest systemsquot, the rotation axis should ideally pass through the system's rear nodal point. A mechanical support fixture that accomplishes this is called a T-Bar Nodal Slide (Reference 1). However, for catadioptric and reflective systems rotation through the rear nodal point is impractical because this point is usually far removed from the physical embodiment of the quottest system.quot In this Guideline, the rotation axis will be at, or near the entrance aperture of the quottest system.quot For visual measurements the quottest systemquot star image needs to be magnified. This can be accomplished using a high quality microscope. The microscope objective should be well-corrected for both axial color and spherical aberration. Its numerical aperture must be sufficient to collect all the light from the quottest system.quot The eyepiece must also be of good quality, and contain at least a cross-hair reticle to provide reference lines. The reticle plane will be coincident with the image formed by the objective. The microscope should have micrometer controlled XYZ-translation capability. 2. Ideal Star Image The structure of the star image is controlled by diffraction and aberrations in the imaging system. If aberrations are negligible, the system is said to be diffraction-limited. For a given focal length, the size and shape of the stop (i.e., the limiting aperture) determines the size and shape of the star image. This is considered the best one can do. The diffraction-limit is a benchmark or standard by which all other imagery is judged. Since most systems have circular unobscured stops, the resultant star image has a special name. It is called an Airy pattern and is shown in Figure 2. The central core is called the Airy Disc (and is measured across a diameter to the center of the first dark ring). Figure 3 (a & b) shows theoretical lateral and axial profiles about paraxial focus. (Although they look similar they actually represent two different mathematical functions). The separation between the zero intensity points on both plots is directly related to the system F-number (f\/#). Note: F-number is the effective focal length divided by the entrance pupil diameter. (1) Lateral Scale = 2.44 l(f\/#) (2) Axial Scale = 16 l (f\/#)2 [D] Figure 2. Airy Pattern For an unaberrated diffraction-limited optical imaging system, the monochromatic star image is symmetric for an equal \u00b1 focus shift. Reflective imaging systems (e.g., Cassegrain telescope) typically contain central obscurations which modify the profile shapes shown in Figure 3. The extent of the modification depends on the obscuration ratio. As the obscuration ratio increases, the diameter of the central core contracts and more relative power enters the first bright ring. [D] Figure 3. Profiles of diffraction-limited star image Most optical systems are not diffraction-limited across their entire field. They suffer from defects called aberration (Reference 2). Given a single color (monochromatic), there are five primary (Seidel) aberrations. Two of these, field curvature and distortion, do not affect star image structure but rather its axial and lateral location with respect to the paraxial image plane. The remaining three aberrations, spherical aberration, coma, and astigmatism, do change the size and shape of the star image. It is the latter three that are of interest in this Guideline. (Note: There are higher order aberrations that can affect star image structure. But their influence is usually minor). For chromatic aberration, the effective focal length of a system and its magnification varies as a function of color or wavelength. This is because the refractive index of glass components in the imaging system are color dependent. This is called dispersion. In refractive systems the primary aberrations are also color dependent. It is common practice to measure the aberration over a restricted spectral bandwidth. The width and center wavelength of the band will depend on the application of the optical system. 3. Direct Visual Measurements on Star Image 3.1. Unaberrated System Align the microscope with the quottest systemquot and view the star image. Center the cross-hair on the pattern. Adjust the focus of the microscope until the Airy pattern is found. (This can be accomplished by: minimizing the number of observed rings; making the first dark ring as dark as possible; minimizing the power in the first bright ring). This establishes the location of paraxial focus. Offset the microscope laterally until the center of the cross-hair is in the middle of the first dark ring. Note the position on the lateral micrometer. Traverse to the opposite side and place the cross-hair center in the middle of the first dark ring. Note this position on the micrometer. Subtract these two micrometer readings to obtain the diameter of the Airy Disc. As a confirmation of F-number, substitute the measured Airy Disc value into Eq.1 and solve for f\/#. Center the cross-hair on the Airy Disc. Adjust the focus and locate the first zero axial intensity positions on either side of paraxial focus. Note the Z-micrometer readings for both positions. Subtract these two Z values. Substitute this difference into Eq.2 and solve for f\/#. 3.2. Axial Color In refractive imaging systems we rely on the curvatures, thicknesses, and refractive indices of the glasses used to form a point image at a certain plane. Unfortunately, the index of refraction of glass is wavelength dependent, a phenomenon known as dispersion. This is illustrated in Figure 4. A white light collimated input beam is imaged at various points along the optical axis according to color. [D] Figure 4. Dispersion in simple lens results in color dependent axial image points [D] Figure 5. Axial Color of Complex Lens To measure axial color (Reference 1), align the quottest systemquot to the Collimator. A white light source is needed but the source housing should have a provision for supporting narrow band color filters between the source and the pinhole. Five to ten spectrally separated filters should be enough to sufficiently sample the visible region. (Note: If there is significant spherical aberration, stop the lens down to about 3\/4 of the aperture). Using the microscope, we measure the axial location of the Airy pattern for each filter. A sample plot is shown in Figure 5 for a 6quot f\/1.5 airborne surveillance objective. 3.3. Primary Aberrations The success with which one can visually measure an aberration type in the star image depends on the relative purity of the aberration. On-axis there should only be spherical aberration. Off-axis will be a mixture of spherical, coma, and astigmatism. If spherical is well-corrected, coma will tend to dominate small field angles. As field angle increases, a point is reached where astigmatism and coma are the same magnitude. Thereafter, astigmatism increases at a faster rate than coma, and dominates the larger field angles. 3.3.1. Spherical Aberration Spherical aberration (References 2 and 3) arises when different annular zones of a lens focus at different points along the optical axis as illustrated in Figure 6. The location of the minimum blur circle is where the marginal ray intersects the caustic. (In Figure 6 note the point where the marginal ray crosses the next innermost ray. This point starts the caustic which is the envelope of crossover points of adjacent rays.) [D] Figure 6. Ray fan showing the caustic and minimum blur circle (courtesy Dr. John Loomis) We examine the aberrated star image with the microscope and adjust the focus back and forth until we find the minimum blur circle. Using the lateral translation capability on the microscope, we measure the diameter, Dmb, of this blur circle (in a manner similar to the Airy Disc measurement). Dmb is related to the wavefront aberration coefficient W040 (References 1 and 2) by: (3) D mb= 4(f\/#) W 040 The above method will generally work for spherical aberration magnitudes above 2 waves. i.e., W040= 2l. Below this a different technique can be used for unobscured systems. (Reference 4). Stop the quottest systemquot down by centering a small circular aperture in the entrance aperture. Observe the enlarged diffraction pattern. Move the microscope axially back and forth to identify the best Airy pattern as discussed in Sec.3.1. This establishes the paraxial plane. Note the reading on the micrometer. Remove the small circular aperture. Readjust the microscope axially once again to identify the best Airy-like pattern. Note the new micrometer reading. Take the difference, d, between the two micrometer readings. This difference can be related to the aberration coefficient by: (4) d = 8 (f\/#) 2 W 040 By averaging over 10 readings an accuracy of a quarter wave should be attainable. 3.3.2. Astigmatism Astigmatism (Reference 2 and 3) arises in a system because sagittal and tangential rays from an off-axis point source do not come to a common focus as is illustrated in Figure 7. The images formed by the two fans both lie on the chief (or principal) ray but are longitudinally separated. Further, the images formed at these two locations appear as lines orthogonal to each other. These are called the tangential and the sagittal line images. [D] Figure 7. Illustration of astigmatism showing sagittal and tangential ray fans (Modern Optical Engineering) Astigmatism can be measured (Reference 1) by determining the separation between the two line foci (along the chief ray) as a function of field position. (Note: If the quottest systemquot has a significant amount of spherical aberration it would be helpful to stop the system down to about 3\/4 of its aperture). Referring back to Figure 1, we rotate the quottest systemquot about the rotation axis to some field angle. Because this rotation does not take place at the rear nodal point, the microscope will have to be translated laterally to reacquire the image. Center the microscope cross-hairs the on the star pattern at medial focus (or circle of least confusion). Adjust the focus of the microscope and locate each line focus. Note the Z-micrometer readings. These can be plotted up as a function of field angle, and the separations between the line focii will be readily apparent as illustrated in Figure 8. If higher order astigmatism is negligible, the longitudinal separation at maximum field angle can be related to the 4th order aberration coefficient by: (5) d = 8 (f\/#)2W222 [D] Figure 8. Astigmatism plot for Aerojet lens (Ref. 1). Significant higher order astigmatism is present. 3.3.3. Coma Coma (Reference 2 and 3) is zonal dependent like spherical aberration. Coma formation is illustrated in Figure 9. (Reference 1). Each circular zone in the lens pupil forms a ring in the image plane. The rings are of different sizes, and are shifted relative to each other as shown in Figure 9 (b). The pattern resembles an ice cream cone. The chief ray intersects this image plane at the tip of the cone. The line bisecting the coma pattern in the image plane passes through the optical axis. The lines tangent to the ensemble of rings on either side form a 60o angle. The ring from the marginal ray zone is the largest and its center is farthest from the chief ray intersection point. The paraxial-like zone about the chief ray forms the smallest ring and its center is closest to the chief ray. The length from the chief ray to the farthest point on the marginal ring is called tangential coma. The radius of this ring is termed sagittal coma. It can be shown that: (6)Tangential coma = 3 Sagittal coma [D] Figure 9a. Formation of coma from an off-axis object point [D] Figure 9b. Coma pattern Coma is usually measured in the paraxial plane. This means that in addition to moving the microscope laterally to reacquire the image after rotation, some predetermined axial adjustment must also be made to place our point of observation in the paraxial plane. (If a T-Bar nodal Slide is being used, such adjustments are accomplished automatically). Tangential coma is then measured. Tangential coma (TC) can be related to the aberration coefficient at the maximum field position by: (7) TC = 6(f\/#)W 131 Unfortunately, unless coma is pure or heavily dominant, it will be difficult to measure. Unlike axial color and astigmatism, stopping the lens down does not help us because coma, like spherical, is zonal dependent. Hence, in the presence of competing aberrations, the anchor points for the lateral coma measurement become difficult to define. Note: Further information on star image testing can be found in Reference 6. 4. Indirect Visual Measurements ... Knife Edge Test In this procedure a knife edge (e.g. a razor blade) explores the region around the star image while the observer views the quottest systemquot pupil directly by eye or on an observation screen. The setup is illustrated in Figure 10. The microscope has been removed from the XYZ-translator, and a knife edge put in its place. [D] Figure 10. Knife edge test on star image Figure 11 illustrates the basic operating principle of the knife edge test for an unaberrated quottest system.quot In the exit pupil, we have a spherical wavefront. Ray normals to the wavefront converge to a point focus. We place an observation screen well outside of the focal region. On the screen we see a circular patch of uniform light (essentially a scaled version of the light distribution in the pupil). Next, we set up a razor blade on an Y-Z translator in the neighborhood of the focal point. Assume we are inside focus (between the pupil and the image point). As we translate the knife edge laterally and start blocking light, we see a straight edge shadow move across the box of light on the observation screen in a direction opposite the knife edge motion. [D] Figure 11. Knife edge scan inside focus We then move the knife edge axially the same distance outside of focus (between the image point and the screen), and then cut across. Again we see a straight edge shadow creep across the light box, but now in the same direction as the scan. At paraxial focus the observer is not aware of a shadow transition...just a general dimming and then darkness. This effect occurs very quickly as the knife edge is translated. If we rotate the knife edge about the optical axis so that it cuts the beam along a different vector, the shadow pattern behavior rotates through the same angle as the knife edge. This holds true not only for unaberrated systems but for all rotationally symmetric aberrations as well. It is not true, however, for asymmetric aberrations. When aberrations are present, the shadow and its boundaries can take on rather complicated behavior. Further, pattern behavior depends on the axial location of the knife edge relative to paraxial focus. (Reference 7). Knife edge testing has been used in optical shops for generations. Though not easily quantifiable, it is quite sensitive and provides an important source of information to the trained eye of an optician. The knife edge patterns guide the optician to locate and correct sources of figure error. In recent years a modified knife edge test coupled with sophisticated software has successfully quantified this venerable technique. (References 8 and 9). Note: Further information on knife edge testing can be found in Reference 10. Technical Rationale: All optical imaging systems used on spaceborne or space-related instruments should undergo an end-to-end systems check to validate performance. Star image testing is the primary means of conducting this validation process. It provides data pertinent to the pass\/fail criteria associated with the optical imaging system. References: J. Geary, Introduction to Optical Testing, Tutorial Text TT-15, SPIE Press (1993). J. Wyant and K. Creath, Applied Optics and Optical Engineering, Vol. 11, Chap. 1, ed. R. Shannon and J. Wyant, Academic Press (1992). J. Hecht and E. Zajac, Optics Addison-Wesley (1975). J. Geary and P. Peterson.quotSpherical Aberration: a Possible New Measurement Approach,quot Opt. Eng. 25, 2 (1986). M. Born and E. Wolf, Principles of Optics, Pergamon, 6th Ed. (1980). W. Welford, in Optical Shop Testing, 2nd Ed. Chap. 11, ed. D. Malacara, John Wiley (1991). M. Cagnet, M. Francon, and J. C. Thrierr, Atlas of Optical Phenomenon, Springer-Verlag (1963). D. Vandenberg, W. Humbei, and A. Wertheimer, quotQuantitative Evaluation of Optical Surfaces by Means of an Improved Foucault Test Approach,quot Opt. Eng. 32, 8, pp 1951-1954 (1993). J. Geary, M. Yoo, P. Davila, A. Wirth, A. Jankevics, M. Ruda, B. Zielinski, and L. Petrilli, quotComparison of Wavefront Sensor Techniques,quot SPIE Proc. Vol. 1776 (1992). J. Ojeda-Castaneda, in Optical Shop Testing, 2nd Ed. Chap. 8, ed. D. Malacara, John Wiley (1991). Reliability Preferred Practices Guideline No. GT-TE-2404 - Guideline for Use of Fizeau Interferometer in Optical Testing. Reliability Preferred Practices Guideline No GT-TE-2406 - Star Image Metrology: Part II Irradiance Measurements.","Lesson ID":718}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1219; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Using prudent and carefully planned methods for specifying tolerances and for designing, manufacturing and mating major elements of aerospace hardware, will result in a cost-effective program with minimal rejects and waivers, and will avoid costly schedule delays due to potential mismatching or misfitting of major components and assemblies. Implementation Method: Introduction: Elements of large aerospace hardware, such as those encountered in the Space Shuttle program, are often (1) manufactured in diverse locations; (2) manufactured and assembled by different centers, prime contractors, and subcontractors; and (3) manufactured and assembled in varying climates and environments. Several additional factors must be considered in establishing design tolerances and in providing jigs and fixtures to assure that the major elements can be mated successfully prior to launch. Specifically, the size and weight of these major components and assemblies (such as the ET and SRB) are so great that special consideration must be given to hardware deflection and deformation due to vehicle mass; wind loads; and environmental factors, such as temperature, humidity, and atmospheric contamination. A variety of methods of calculating and allowing for tolerance buildup and for ensuring matching components at the assembly site have been developed to meet the specific needs of these large hardware elements of the Space Shuttle program. No one method suits all needs. In some instances (in the ET project, for example), the overall tolerance between major critical dimensions is the sum of all of the quotworst-casequot tolerances of the subassemblies. In the SRB project, for example, the root sum square of the tolerances of segments is used to arrive at the tolerance on major critical dimensions. In addition, adjustable supports are used at critical attach points to permit minor variations in matching and assembling these two major Space Shuttle hardware elements. This practice provides selected methods that have proven successful in ensuring that major elements of aerospace hardware will be successfully and accurately assembled both in the factory and in the field; and it provides methods and definitions of dimension and tolerance buildup practices that have proven successful in designing, building, and flying large aerospace vehicles. Master Tooling\/Jigs And Fixtures: Master tooling should be used when machining a number of interchangeable parts to ensure that each part will fit and function properly. Another method of assuring interchangeability of parts during manufacturing is through the use of jigs or fixtures. This method is used primarily when an operation such as welding, drilling, or reaming is performed by hand on interchangeable parts. Example: Thiokol, Inc. is under contract to NASA MSFC to fabricate the motor segments of the SRB. These segments must fit together precisely when they are assembled at KSC; therefore, each segment must be indexed when it is manufactured by drilling the indexing holes in the tang and clevis joints of the Solid Rocket Motor (SRM) segment using a master tool. All of the master tools are made from transfer gauges, and the transfer gauges are made from a master gauge, resulting in the same indexing regardless of where the segments are manufactured (see Figure 1). [D] [D]Master Gauge: The master gauge is a stable, heavy cast iron fixture into which the master interface hole pattern has been precision bored. The bored holes are lined with pressed-in, hardened bushings (see Figure 2). The exact location of each hole is determined by independent inspection and is entered on the master gauge drawing as a basic no-tolerance dimension. This drawing, and the master gauge it depicts, describe and establish the mastered hole pattern. The master gauge is used as a template when bushings are potted into the transfer gauge. Transfer Gauge: Transfer gauges are stable, rigid fixtures into which hardened bushings are potted with an epoxy compound. During potting, the bushings for the transfer gauge are held in the correct position by potting pins located in the master gauge. (As shown in Figure 2), transfer gauge is fitted over the master gauge before potting, and the transfer gauge bushings are located precisely before potting using the potting pins. After the potting material has cured, check pins are inserted first through the master tool and then through the new bushing location. Master Tool\/Drill Jig: [D] Master tools are fixtures into which hardened bushings are potted with an epoxy compound. The transfer gauge is used as a template when bushing are potted in the master tool (see Figure 3). The bushings are held in position by the transfer gauge and potting pins. After the potting material has cured, check pins are inserted through the transfer gauge into the master tool to verify the location of the potted bushings. Master tools are used as drill jigs to assure that the assembly holes and pins and the indexing holes and pins in the tangs and clevis joints of the SRM segments are precisely the same (see Figure 4). Master tools are made from the same material as the SRB segment casings. Therefore, the coefficient of expansion is the same for both. It is critical that the master tools and the SRB segments be subjected to the same environment until they stabilize with the area temperature before attempting to mate them or initiate drilling. Inspection pins are used to verify hole locations in the SRM segment relative to the master tool. Mobile Launch Platform (MLP) Preparation for SRB Stack: [D] The support post #2 under the MLP is adjusted to a certain height in reference to a benchmark in the Vehicle Assembly Building (VAB). There is a corresponding support post #2 and benchmark at the launch pad. Once support post #2 has been adjusted to the correct height, a triangular reference plane is established using two other points under the MLP. This reference plane is then transferred to the top of the MLP. The eight support posts (four per SRB) are then adjusted by the following means: Shims are added between each support post and the haunch which is permanently attached to the MLP to raise the support post to a reasonable height. Shims may be added under each spherical bearing for height adjustment up to a maximum of 0.5quot (see Figure 5). Eccentric bushings and the eccentric spherical bearings are rotated to bring them into alignment with a bias to give the SRBs a very slight inward pitch (towards ET). The bearings are then locked so they cannot move when the SRB aft skirt is installed. SRB Stacking: [D] The SRBs are stacked on the spherical bearings on the MLP in five separate sections, one section at a time. The aft skirt, kick ring, and aft motor segment are preassembled in another area and stacked on the MLP as the aft booster assembly. The aft center segment is then stacked on top of the aft booster assembly. The forward center segment is stacked on top of the aft center segment. The forward motor segment is stacked on top of the forward center segment. The forward skirt, separation ring, frustum and nose cap are also preassembled and stacked on top of the forward motor segment as one unit. All of these sections make up one SRB. The fit of one section with the next is ensured because their mating parts (tangs and clevis joints) were all drilled using a master tool. There is no alignment adjustment between the sections and the deviation from vertical in the quotyquot plane is +0.8299quot per stack. Tolerance Buildup Practices: External Tank: In the External Tank project, manufacturing drawings have tighter tolerances than the interface control documents (ICD) to eliminate the need for waivers if tolerances are exceeded slightly. The ICD tolerance for the overall length of the external tank (ET) is +0.74quot, while the manufacture drawing tolerance is +0.62quot. The ET assembly drawing overall length tolerance represents the worst-case stack-up of the major ET assemblies, and the lower level assembly drawings use the same philosophy. For instance, the aft dome roundness is +0.50quot, the barrel attach points are +0.02quot, the machined and fabricated (formed) parts are +0.03quot, and thin sections are +0.10quot. ET design engineers strive for tolerances of fabrication tools up to 10 times better than the flight hardware tolerances. For example, if the target tolerance on a part is +0.1quot, engineers strive to make the tool tolerance +0.01quot. If the worst-case tolerance on a part is +0.1quot, they strive to make the tool worst case tolerance +0.05quot, or no greater than one-half of the part tolerances. ET design engineers use the ANSI Standard for Dimensioning and Tolerancing for block tolerances; i.e., x.x=+0.10quot, x.xx=+0.03quot, x.xxx=+0.010quot, and x.xxxx=+0.000xquot. In some instances, match drilling is used during ET fabrication to ensure a perfect fit rather than using machine-to-drawing holes which would require a very tight tolerance on the machining process. Methods of Calculating Tolerance Buildup: In aerospace hardware, two methods are normally used to calculate tolerance buildup. They are the root sum square (RSS) method and the root mean square (RMS) method. Each seems to serve best for particular applications. The RSS method is generally used for calculating the tolerance buildup of large pieces of hardware like the SRBs when they are assembled at KSC. This method of tolerance buildup assumes a random ordering of the various combinations of the interface theoretical tolerances and resulting misalignments. The following formula is used for RSS calculations: [D] Where: A, B, C, and D are the tolerances of mating segments of an assembly. The RMS method is generally used in calculating the tolerances of piece parts for small assemblies such as pumps and valves. The RMS method is also used in connection with surface roughness. The roughness value is assumed to be approximately equal to the square root of the mean value of the squares of the heights and depths of the surface roughness irregularities measured from the nominal surface in micro-inches. This value is considered to be representative of the surface condition because it is assumed to give appropriate emphasis to the peaks and valleys comprising the surface. The following formula is used for RMS calculations: [D] Where: A, B, C, and D are the tolerances of mating segments of an assembly, and N is the number of tolerances. Environmental and Physical Factors: When designing a part and establishing tolerances, it is important to consider both the environment where the part is initially manufactured and assembled, and the environment where the part may have to be replaced or reassembled. Factors to be considered include assumptions as to whether the part has to be disassembled and reassembled at a later time and\/or different location from the initial assembly. Tolerances of the part will be determined by expected variations in temperature, material, coefficient of expansion, humidity, wind load, or cleanliness. Example: Several precision components such as the LO2 and LH2 pumps and valves in the Space Shuttle Main Engine may be assembled initially in a clean environment of 68 degrees and low humidity. If it is anticipated that one of these parts may have to be replaced on the launch pad at KSC, the fit of its parts could be affected if the temperature was 98 degrees and the humidity 95 percent, if the wind was blowing at 45 mph, or if sand and dirt were present in the local atmosphere. Potential Cost\/Schedule Impact Avoidance: Cost and schedule are two of the most important factors to consider when establishing tolerances. Designers should never specify a tighter tolerance on any part or component than is absolutely necessary for that part to fit and function properly. Tighter tolerances require more precise machining, and result in potential scrappage of parts or components at inspection. Excessively tight tolerances also require more time for machine setup and machining as well as extra time for inspection. The loss of material, the extra time for machining and inspection, and the potential overtime required to meet a schedule can result in higher overall costs. Example: The critical mating surfaces for interface mounting flanges designed for a pump or valve are required to be flat within .002quot. If the designer were to unnecessarily require the same tight tolerance on the size and location of the mounting holes, flanges could be unnecessarily rejected if the holes did not meet the specifications. This could increase the cost of the flanges because of the wasted material and machining time. Technical Rationale: The rationale for tolerancing is to assure that the majority of small and large parts will fit and function as they were designed to when they finally come together as an overall assembly. It is also essential that these parts can be disassembled and reassembled if necessary under less than ideal conditions with the minimum amount of effort in the least amount of time. The selected tolerance buildup and hardware integration approaches described in this practice have evolved over the past four decades of developing launch vehicles and their related propulsion systems and structures. Minor deviations have been made from standard ANSI practices in instances where the prior U. S. standards were not applicable to large aerospace hardware components, subassemblies, and assemblies. Specific design requirements, specifications, and procedures are described in detail in the references and in documents identified in the references. References: ANSI Standard for Dimensioning and Tolerancing Y14.5M 1982, published 1983, The American Society of Mechanical Engineers, United Engineering Center, 345 East 47th Street, New York, NY 10017. External Tank Tolerance Control Drawing Number 82600209001, W.E. Warren, May 24, 1974, Martin Marietta Corporation, P. O. Box 179, Denver CO 80201. Modern Geometric Dimensioning and Tolerancing, Second Edition, 1982, Lowell Foster, National Tooling and Machining Association, 9300 Livingston Road, Fort Washington, MD 20744, Catalog Number 5021. Space Shuttle Stacking Tolerance and Mating Assessment for (MLP\/ASRB\/ET) 20ENR-0001, S. Fisher, July 30, 1991, United Technologies USBI, P. O. Box 1900, Huntsville, AL 35807. Space Shuttle Vehicle MLP\/SRB\/ET Stacking Tolerancing and Mating Assessment, 30A90507, Bill Cole, March 4, 1977, National Aeronautics and Space Administration, George C. Marshall Space Flight Center, Huntsville, AL.","Lesson ID":713}
{"Driving Event":"This Lessons Learned is based on Reliability Practice Number PD-EC-1104; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: The quottell talequot device will provide an indication of the peak D.C. magnetic field intensity to which the transported (or stored) system has been exposed. High residual fields are sometimes caused by nearby lightning strikes, power system faults or exposure to strong permanent magnets. Compliance with the peak magnetic field exposure, as defined in the Magnetic Control Plan document, assures that the flight hardware is in its lowest magnetic state, thereby minimizing any adverse effects on the integrity of science data. Implementation Method: JPL uses a version of the quottell talequot sensor devised by the Ames Research Center to verify compliance with the magnetic control imposed on the Apollo program and by the science requirements for the Pioneer spacecraft. This 3 cm cubic sensor is comprised of 3 orthogonal Dumet wires (20 AWG, approximately 5 cm long) embedded in a plastic block (provided with a ground strap to avoid electrostatic discharge). The block is demagnetized in a near zero field environment and the net magnetic moment is measured in the earth's field (0.05 mT) [Typical value at mid-latitudes (0.5 Gauss), Gauss = 10-4 Tesla, mT = milliTesla] and at several intermediate points up to a maximum exposure of 2.5 mT (25 Gauss). After a demagnetization, the device is ready for use. For practical considerations, the device characteristics are expressed in terms of the observed effect of field exposure, i.e. magnetic field in nanoTeslas (nT) produced at a distance of 0.3 meter (12 inches) from the tell tale. Figure 1 shows a sample calibration. [D] Given the measured field exposure characteristics for peak exposure of the device, subsequent measurements are indicative of the maximum field exposure since the last demagnetization. Sample results are indicated in Table 1, where the maximum field exposure was less than 0.3 mT (3 Gauss). Table 1: Magnetic Exposure Recorder, Sample Results Serial Number Measured Magnetic Field @ 0.3m (12quot)* X-Axis Y-Axis Z-Axis SN 003 <1 1 1 SN 002 1 1.5 1 SN 001 <1 <1 <1 SN 009 2 1 <1 * (nT, peak to peak) Typically, 4 to 6 sensors are mounted around the perimeter of the system being monitored. At significant points in the processing of the flight hardware, the sensors are removed for measurement, demagnetized, and returned to their initial locations. In the event that excessive field exposure is detected, cognizant hardware personnel can determine if the flight hardware being monitored requires demagnetization. Knowledge of the locations of the sensors, their relative field exposure, and the hardware processing performed since the last measurement can aid in the identification of the source of the magnetization and in determining if the spacecraft needs localized demagnetization. An example of the use of this device is the transport container for the Galileo spacecraft. Four sensors were located on the inside of the truck container wall around the spacecraft. Two sensors were mounted ahead of the spacecraft on the right and left side wall and two more were mounted behind the spacecraft. Thus, the sensors would be more exposed than the spacecraft to any external magnetic field that might pass by the transport truck. At the end of the cross country trip, none of the twelve magnetizable rods showed any evidence of exposure to an excessive magnetic field. Technical Rationale: Because it is impractical to completely eliminate the use of ferromagnetic materials on spacecraft and flight hardware, it is important to control the maximum magnetic field exposure for hardware used on those missions for which a magnetic control plan has been implemented. In most cases, a magnetic control plan is required for missions which have a science magnetometer or a plasma wave experiment as part of the payload. Verification of compliance with the specified maximum field exposure is difficult because not all sources of strong magnetic fields are obvious, and there is no sensual perception of magnetic fields in the range of interest for spacecraft concerns, 0.1 to 2.5 mT (1 to 25 Gauss). In addition, the time interval over which monitoring may be required can be very long-- particularly if the flight hardware has to be shipped over long distances or placed in storage. Hence, a passive sensing device is needed. Dumet, a ferromagnetic alloy, has mechanical properties which make it suitable for applications such as component leads requiring a hermetic seal to glass. An ancillary characteristic of this material is a high magnetic permeability. This property, coupled with the fact that the material is available in the form of small diameter wire, makes it suitable for use in the fabrication of the quottell talequot sensors. Alternate materials include Kovar and ferrites. References: quotAssessment and Control of Spacecraft Magnetic Fieldsquot, NASA SP-8037, September 1970. Magnetic Design Control for Science Instruments, Reliability Preferred Practice No. PD-ED-1207 Demagnetization of Ferromagnetic Parts, Reliability Preferred Practice No. PD-ED-1220 Magnetic Field Restraints for Spacecraft Systems and Subsystems, Reliability Preferred Practice No. PD-ED-1222","Lesson ID":706}
{"Driving Event":"This Lesson Learned is based on Reliability Practice Number PD-ED-1246 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefits: Fault tolerant design provides a means to achieve a balanced project risk where the cost of failure protection is commensurate with the program resources and the mission criticality of the equipment. By providing compensation for potential hardware failures, a fault tolerant design approach may achieve reliability objectives without recourse to non-optimized redundancy or overdesign. Implementation Method: The practice of fault tolerant design (FTD) presumes that the potential causes of failures are identifiable. This identification is performed by means of the existing practices of hardware and software failure modes, effects, and criticality analysis (FMECA). Similarly, fault tree analysis (FTA) identifies safety issues and potential faults in mechanical and electromechanical devices. Design engineers utilize the preliminary results of FMECAs and FTAs to establish fault tolerant equipment design priorities. FTD is an iterative process; its current validity relies on the current iteration of the FMECA and FTA and their corresponding criticalities and probabilities of occurrence. The iteration cycle ceases when either the cost of the next design iteration is programmatically unacceptable or when the risk has been reduced below a stated goal. It is assumed that all of the normal reliability design tools such as part stress derating, worst case performance analysis, qualification testing, life demonstration, quality control, etc., have already been used to preclude any design or material deficiencies. The FTD process also assumes that, in spite of the above practices, an in-flight failure may occur in a given set of manufactured hardware. This process flow is illustrated in Figure 1. The diagram illustrates that FTD is a top-level system design philosophy covering other NASA preferred reliability practices, including analytical design disciplines, FMECA and FTA studies, fault protection plans, and test results. The FTD process at JPL includes four phases beginning with analytical design. [D] Technical Rationale: To increase the reliability of a spacecraft system, two complementary but fundamentally different approaches are taken: Fault prevention (fault intolerance), and Fault tolerance. Fault prevention deals with the objective of increasing reliability by elimination of all faults, which is not feasible in reality. Therefore, the goal of fault prevention is to reduce the probability of system failure to an acceptably low value. The fault tolerance approach expects failures to occur. However, their effects will be automatically counteracted by incorporating either redundancy or other types of compensation. A fault tolerant design approach differs from a pure design redundancy approach in that provisions are made for planned degraded modes of operation where acceptable. For example, the high gain antenna of a spacecraft is usually non-redundant because of its size. An FTD would favor the use of a backup medium gain antenna operating at reduced data rates as a degraded but acceptable operating mode. Similarly, a partially failed power source within a solar panel array or a failure of one of three radioisotope thermoelectric generators (RTGs) could be accommodated: an appropriate failure detection circuit and a software fault protection algorithm would be provided to shed low priority electrical loads or instruments, while maintaining most mission capabilities. Also, FTD may be preferable to mere hardware redundancy in that higher probability multiple failures can be identified and accommodated. For example, the common design practice for inertial sensors (gyros) is the use of three packages of orthogonally located dual axis sensors (i.e., the X-Y, Y-Z, and Z-X axes). This scheme is tolerant of the loss of any one gyro but can be extended to accommodate the loss of any two gyros by the use of a pair of two-axis positionally adjustable gyros insertable by command or by detection algorithms. It can be placed in the X-Y or X-Z directions, thereby providing at least one signal on each axis even if two pairs of fixed mounted gyros are lost. In this case, dual failures are accommodated with only a short interruption of service and some additional mechanical complexity, but with no significant loss in system performance. The essential ingredients to achieving a fault tolerant design are the performance of a thorough FMECA and FTA, the detailed communication of these identified failure modes and effects to the fault protection design engineers, and strong participation by the project engineer and program management in assessing design cost\/benefit trade-off iterations. An FTD will be limited by either weight, volume, schedule, or cost constraints. Presentation of fault tolerant design options to program management requires a skilled engineering team with intimate knowledge of system operation and close communication with system designers. An FTD can provide dramatic improvements in system reliability and lead to a substantial reduction in flight failures as a consequence of fewer disabling system failures. References: Fault Protection System Design and Operations, JPL Document D625-505, Vol. 8, Galileo Project, October 1989. Fault Protection Requirements, JPL Document 699-CAS-3-330, Cassini Project, March 1994. System Fault Protection Algorithms, JPL Document 699-CAS-3-331, Cassini Project, January 1995. Fault Protection, Reliability Preferred Practice No. PD-ED-1243 Active Redundancy, Reliability Preferred Practice No. PD-ED-1216 Failure Modes, Effects, and Criticality Analysis (FMECA), Reliability Preferred Practice No. PD-AP-1307","Lesson ID":707}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1203; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefits: Low parts failure rates in typical circuit applications result in significant system reliability enhancement. For space systems involving serviceability, the mean-time-between-failure (MTBF)is greatly extended, which significantly reduces maintenance requirements and crew time demands. Implementation Method: Redundancy is an appropriate usage of resources-- especially in critical applications to protect against random failures -- but is not a justification for using less than Class S or quotequivalentquot parts. Establish a policy that Class S parts will be used without exception or that limited exceptions are only permitted with extensive testing and inspections for upgrading of Class B to an acceptable level (approximately Class S or Grade 1). Technical Rationale: Basic reliability is a function of parts failure rates. In any analytical calculations of reliability, the usage conditions of parts (derating, temperature, stress, etc.) are expressed as a failure rate that integrates these conditions from empirical or analytical considerations. High reliability parts (Class S or Grade 1) are screened and tested to yield the lowest failure rate parts producible in large quantities. (Refer to Table 1 for the relationship of Class S to Class B). The failure rates of Class S parts are generally about one fourth the rates for Class B. When parts failure rates are coupled into circuit applications, the effects can be significantly magnified, depending on the circuit configuration. ISSUE CLASS S CLASS B IMPACT Wafer lot acceptance Required ---------- Uniformity and pedigree traceability Certification of production facilities To specific assembly lines To technologies and general facilities only Burn-in and screening value relates to consistency of original product Precap internal inspection 100% Sampled Significant driver on level of reliability - criteria much more stringent in MIL-M-38510H PIND for loose particle detection Required ---------- Loose metallics in zero g field can cause failures Serialization Required ---------- Traceability lost Interim electrical test between test phases Required ---------- Potential of passing over problems and their causes Burn-in 240 hours 160 hours Later problem discovery Reverse bias burn in Required ---------- Impurity migration not detected Interim electrical test after reverse bias burn Required ---------- Effects of reverse bias burn-in may be masked by subsequent actions Radiographic inspection Required ---------- Observation of latent defects Nondestructive 100% bond pull test 100% Sampled Parts with mechanical deficiences get into equipment When spaceflight equipment is not serviceable in a system requiring high reliability and long life, the lowest possible failure rate parts should be selected. This is especially true when considering the economics associated with the launch costs. For example, when changing from Class S to Class B parts, the parts cost decreases by a factor of 4x to 10x but the reliability of the system decreases significantly (by 20 to 50 times in the typical 5-year mission example provided). When total system, mission operations, and launch costs are considered, the delta between the parts costs for Class S and Class B is a minute percentage of total cost. This is especially true for Space Shuttle payloads. On systems that are serviceable, the MTBF of an assembly is extended in proportion to the basic failure expectation. This significantly longer MTBF reduces on-orbit service requirements with less time demands on the crew, less risk associated with extravehicular activity (EVA), fewer spares required, and fewer launches to transport spares. Redundancy has a much lower reliability payoff than does parts class-- until it is needed. Maverick parts, workmanship flaws, and other uncertainties justify redundancy for critical circuits in high reliability, long life applications to protect against random failures. For long life, the use of high reliability hardware, Class S (or Grade 1) parts, and redundancy in critical applications, provide an optimum and cost-effective approach.","Lesson ID":709}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1222; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Limits magnetic field interference at flight sensor positions and minimizes magnetic dipole moments that can increase magnetic torquing effects that place additional loads on attitude control systems. Implementation Method: A magnetic test procedure has been established which includes separate determinations of the permanent, induced, and stray field magnetization of parts and sub-assemblies. These three conditions represent the prominent sources of spacecraft magnetic field restraint problems. Applied field vectors are utilized to determine the induced magnetic field properties which the spacecraft will experience in orbit. The stray field measurements are designed to differentiate between the power-on vs power-off conditions of operation as well as the shifts in the stray-field levels during operation of the equipment. In the case of the permanent magnetization measurements, the following conditions or states are normally measured: A. Initial Perm - \"as received\" magnetic state of the item which indicates: one possible level of perm which may exist for a newly manufactured item of the same design. a relative magnitude of the field used to determine the effectiveness of the deperm treatment. the stability of perm by initiating a record of its magnetic history. B. Post Exposure - Magnetic state of the item after exposure to a 15 or 25 gauss D.C. magnetic field which represents the most probable maximum field to which the item is expected to be exposed during the environmental testing. C. Post Deperm - Magnetic state of the item after being demagnetized in a 50 gauss field (normally 60 Hz AC field). Appendix C of Reference 1 provides further data related to methods of demagnetization and compares the results obtained. A substantial amount of test data has been accumulated which relates to the magnitudes of magnetic field for various components normally used in spacecraft systems by indicating the magnetic field disturbance in gamma (10-5 oersted) at a distance of 12 inches from the center of the item. These magnitudes have been measured directly or extrapolated, (by inverse cube) from supplementary distance data. In many cases two or more identical items were measured to insure more representative data; however, in those cases only the maximum value has been listed. In the case of particular components which are required to be non-magnetic, i.e., resistors and connectors, the data is presented for the distance of 2 inches. This data is intended to represent the various magnetic field levels to be expected from the items rather than representing an acceptable or nonacceptance parts list. Magnetic test data has been accumulated from tests of various types of batteries used in flight programs such as IMP, UA-2, OAO, OGO, MMS, and DE. These data show that cells with the nonmagnetic silver cadmium electrodes should be used for spacecraft containing magnetic field experiments. Nickel Cadmium cells should be particularly avoided since these cells have a substantial permanent magnetic field characteristic due to the presence of the nickel material. In the case of other spacecraft where the nonmagnetic requirements are not quite as stringent, it might be more desirable to use the nickel cadmium cells because of their preferred electrical characteristics. While the use of silver cadmium cells will minimize the permanent magnetic field disturbance, their use will not reduce the stray field disturbance which depends on the current flow in the individual cells as well as the combined terminal connection arrangement. Reduction and cancellation of the stray field can be best achieved in those cases where an even number of cells have been combined to form the complete battery pack. Cancellation of the stray field, would be accomplished by combining the cells back-to-back in pairs so that the stray field of one cell effectively opposes that of the other. When an odd number of cells is combined, the stray field of the one unmatched cell can be canceled by adding a supplementary loop of wire which generates a stray field in opposition to that of the single uncompensated cell. Similar magnetic test data has been accumulated for a variety of flight capacitors, connectors, various materials and products such as metals and alloys, electric motors, relays, wiring, etc. These tests were performed a number of years ago and the test samples may not represent some of the materials and components used in more recent years. The magnetic test technique and the approach used in selecting materials with suitable magnetic characteristics can provide a guide to the testing and selection of newer materials and components. References 1, 2 and 3 provide more details on the testing and include many tables of test data. Technical Rationale: The problem associated with magnetic field restraints for components and spacecraft vary according to the spacecraft program requirements. Those spacecraft which include magnetic field experiments must control and limit the magnetic field disturbance of the integrated spacecraft so that no undue magnetic field interference will occur at the flight sensor positions. In the case of spacecraft which employ magnetic or gravity gradient attitude control systems, the magnetic restraint problems are normally not as stringent; however, all spacecraft designers should avoid the use of components and sub-assemblies with significant magnetic moments since these will increase magnetic torquing effects and place additional loads on the attitude control system. This practice is primarily intended for use by spacecraft programs subject to magnetic field restraints, i.e., spacecraft containing magnetic field experiments or magnetic attitude control systems. Accordingly it can be used as a guide in the magnetic testing, assessment, and selection of parts and materials to be used by such programs. References: \"Magnetic Field Restraints For Spacecraft Systems And Subsystems,\" Dated February 1967, GSFC Document No. X-325-67-70 Supplement 1 (1971) to \"Magnetic Field Restraints For Pacemaker Systems and Subsystems,\" Dated December 1971, GSFC Document No. X-325-71-488 \"Spacecraft Magnetic Test Facility (Attitude Control Test Facility),\" Dated April 1984, GSFC Document No. X-754-83-9 Reliability Preferred Practice No. PD-ED-1207, \"Magnetic Design Control For Science Instruments\" Unit Conversions: 1 gauss = .1 millitesla (mT) 1 oersted = 79.57747 ampere\/meter (A\/m) 1 inch = 2.54 centimeter (cm)","Lesson ID":711}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1224; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefits: By using standard military and industry-accepted tubing design criteria, the overall design of a system consisting of tubing will achieve maximum reliability, producibility, and safety at a minimum cost. Implementation Method: CONFIGURATION DESIGN Configuration design considerations of tubing systems should be coordinated among the engineering disciplines (structures, electrical, mechanical, etc.) that will be affected by the proposed paths of the tubing systems. Mockups and\/or interface control drawings (ICD's) should be used in an interactive, iterative manner to verify outside tube diameter, bend radii, and end connector locations and interfaces. Drawings used during the configuration design phase should be to a level of detail which will accurately show all applicable equipment, structures, and general clearances (such as tubing support spacing) in order to accurately assess the acuteness of space limitations and effective tube lengths. Design layouts of tubing systems should allow for on-orbit access for maintenance, inspections, and removability if necessary. Electrical lines and their acceptable proximity to tubing paths should be fully assessed in accordance with operational parameters of the systems and the effects of failure of each system upon the other. Design elements such as material selection, tube fittings and routing, and maintenance properties must receive special consideration in systems using corrosive fluids. Tube routing should follow straight paths, avoiding bends and fittings whenever possible, thus avoiding flow head losses associated with such configurations. In routing straight tubes between fixed points, thorough consideration should be given to tube length tolerances needed because of thermal and pressure differential induced stresses, structural\/mechanical movement, vibrational movement, and end fitting thermal expansion induced stress differentials. Supports should be designed and implemented in such a way as not to overrestrict or underrestrict motion of tubing via proper material selection, structural design, and interval placement onto the tubing. Additionally, manufacturing, maintenance, inspection, and fabrication limitations should be considered during layout configuration. MATERIAL SELECTION Material selection for tubing should be compatible with the intended use of the tubing, its surrounding environment, and fluid commodity it is intended to carry. Special consideration should be given to offgassing properties in a space flight environment; corrosion\/stress corrosion susceptibility (such as defined in Reference 1) for both the tubing, associated support structures, blind fasteners; and the effects of using dissimilar materials as exemplified in References 2 and 3. Additionally, a minimum of different types of tubing materials and sizes should be used to lower production costs and increase the reliability and safety of the system. All tubing used in a flight environment should be of a seamless configuration. BENDS In many design applications, tube bending will be necessary to compensate for relatively large induced thermal contraction or expansion stresses, to act as equal distant pressure manifolds, or to route around adjacent hardware in the surrounding configuration. Therefore, when tube bending is necessary, the linear distance from the end of the tube to the bend or from a fitting to a bend should be as great as possible. Bends in close linear proximity to one another along a common tube are not desirable because of the increase of stress concentrations in the area of the end of a tube and the bend, increased fabrication time to make the piece, and a possibility of high scrap rates during fabrication. When the bending of tubing is necessary, the bend radius is an important consideration. Factors governing the bend radius limitations of the tubing are: tubing material properties, tube wall thickness (WT), outside tube diameter (OD), and internal pressure differentials. The WT\/OD ratio will place limitations on the degree of bending allowable because of inside bend radius buckling and outside bend radius stretching. Material properties, microscopic grain structure, and annealing processes will additionally limit the degree of bending. Common and current industry and military standards that are sufficient for orbital conditions should be consulted to determine the minimum and maximum bend radii allowable for tubing as a function of these considerations. Additionally, the selected standards should delineate the amount of ovalization (\"out of roundness\") allowable as a function of internal pressure and tubing material. The amount of tubing ovalization will usually be defined in terms of tube flatness and given as a percent of original outside diameter. As a rule of thumb, most standards will not allow a minimum bend radius of less than three times the outside diameter of the tubing because of excessive tubing ovalization as exemplified in Reference 4. COIL MOTION Coil motion tubing should be installed into a system such that the tubing is in a relaxed, unstressed position. The coil design should be such that motion of the tubing is concentric about the centerline of the tubing coils. Additionally, the motion should not adversely affect tube fittings, overly stress the tubing, or cause damage to surrounding equipment. Specific individual material property characteristics should be considered when designing coil motion systems. Proper coil pitch distances should be decided upon after consultation with current military standards. UNDESIRABLE PLASTIC DEFORMATION During the cold forming of a tube bend radius, care should be taken to minimize the degree of material buckling occurring in the inside portion of the bend radius. Buckling in this area reduces the strength of the tubing and could cause transition turbulence in flows with relatively high Reynolds numbers. Additionally, caution should be taken to minimize the degree of tubing ovalization. Ovalization creates a situation of hoop stress concentrations in tubing walls that could give way to lengthwise splitting of the tubing wall. Precautions such as the use of appropriate bending shoes should be used to minimize ovalization. SPRINGBACK During the cold forming process of tube bending, most materials will exhibit a springback characteristic when bent into the plastic deformation region of the material. Structurally, the degree of springback varies as a function of the WT\/OD ratio, the degree of the bend, and the bend angle and radius. The finished bend radius should be coupled with the appropriate bending shoes, internal tube mandrills, and applicable standards delineating finished bend radius as a function of tube WT\/OD ratio, and tubing material. PROOF PRESSURE As a minimum, each tube and tubing assembly should be exposed to a proof pressure testing procedure consistent with the pressures, pressure cycles, and temperature gradients that the part will experience. Standards for proof testing should be consistent with current appropriate standards. The part must be able to withstand the test without any evidence of premature failure. Using appropriate liquid or gaseous testing mediums, the test should verify that the tubing material and applicable fitting(s) are sound and leak free based upon the requirements of the applicable design drawing and project. The designer should take measures to ensure that the drawing or specification delineating the fabrication details of the part contains requirements for proof and leak testing of all parts, usually at minimum and maximum fluid operating temperatures. For example, the Space Shuttle Program assigns general minimum factors of safety for proof pressure and ultimate pressure testing at 4.0 times the maximum operating pressure (MOP) for tubing less than 1.5 inches in outside diameter, and at 1.5 times MOP for tubing greater than 1.5 inches in diameter (References 5 and 6). TUBE FITTINGS Standard and NASA approved tubing fittings should be used whenever possible to avoid excessive use of nonstandard part types and the manufacture of nonstandard tube endings. Unless otherwise necessary, tube fittings should be of the same material as the tube and adjoining fittings. Use of dissimilar materials should be strongly weighed with respect to material incompatibilities, differential thermal properties, and possible dielectric incompatibilities. Offgassing properties should also be evaluated for all materials used in tube fittings when used in space flight situations. Tube ends and tube fitting interfaces should be free of burrs both inside and outside the tubing. Tubing ends should be finished square, within tolerance limits well defined by the designer and consistent with current engineering standards as applicable. Additionally, surfaces should be cleaned within tolerances for foreign particulate presence defined by the engineering organization for the intended use of the part. All welded surfaces should be fabricated in a fashion that applies military standards with considerations for flight and space environments. For the purposes of this document, extensive discussion of mechanical and welded fittings is left to related standards, practices, and other documentation. Technical Rationale: Use of this practice as a standard will result in a higher degree of design and configuration coherency than previously realized. Engineering judgments can be baselined according to military and industrial standard practices such as References 7 and 8. This practice is not all-inclusive; special care and sound engineering judgments must be made when tubing is being used for high-velocity liquid and gaseous substances and in applications where comparatively large cross-sectional-average Reynolds numbers are present. The latter is especially true, since flows that possess Reynolds numbers near 2300 may be transitioning from laminar to turbulent flow conditions, creating a condition of quasi-steady flow. Additionally, special considerations should be exercised and explored for orbital and space environments. Specific standards are revised as lessons are learned and technologies change. The most current standards should be cited when designing fluid systems, and sound engineering judgment should be exercised when deciding which standard will be consistently applied to a given project. References: KSC-SPEC-Z-0007C, \"Specification for Tubing, Steel, Corrosion Resistant, Types 304 and 316, Seamless, Annealed.\" MSFC-SPEC-250, \"Protective Finishes for Space Vehicle Structures.\" KSC-STD-C-0001B, \"Standard for Protective Coating of Carbon Structures.\" MS33611, \"Tube Bend Radii.\" NSTS 07700, \"Program Definition and Requirements.\" NSTS 08318, \"NSTS Hydraulic System Exceptions to MIL-H-5440.\" MIL-F-45764C, \"Fabrication and Installation of Fluid Lines and Fittings for Missiles and related Ground Equipment.\" MIL-H-5440G, \"Design and Installation Requirements for Hydraulic Systems, Aircraft, Types I and II.\" Schlichting, H., \"Boundary-Layer Theory (Grenzschicht-Theorie),\" 1979, McGraw-Hill Book Company, New York, New York. Boyerk, H., Gall, T., \"Metals Handbook,\" 1985, American Society for Metals, Metals Park, Ohio. \"Installation Considerations for Fluid Tubing Systems\", Reliability Preferred Practice GD-ED-2208","Lesson ID":712}
{"Driving Event":"This Lesson Learned is based on Reliability Guideline number GT-TE-2401 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Implementing the Guideline provides the following technical controls in the Electromagnetic Compatibility characteristics of hardware: a. The payload and its elements do not generate electromagnetic interference that could adversely affect its own subsystems and components or the safety and operation of the launch vehicle (STS or ELV), or the launch site. b. The payload and its subsystems are not susceptible to emissions that could adversely affect their safety and performance. This applies whether the emissions are self-generated or derived from other sources, or whether they are intentional or unintentional. Implementation Method: Electromagnetic compatibility requirements have been established to ensure that a payload or its elements do not generate electromagnetic interference that can adversely affect its own subsystems and components, or other payloads, or the safety and operation of the launch vehicle (STS or ELV) and launch site. Additionally, the payload (spacecraft) and its subsystems and components should not be susceptible to emissions that could adversely affect their safety and performance. This applies whether the emissions are self-generated or emanate from other sources, or whether they are intentional or unintentional. The Guideline consists of verification requirements in each of the following categories: conducted emissions, conducted susceptibility, radiated emissions, and radiated susceptibility. Most of these requirements are taken from the widely used MIL-STD-461, 462, and 463 EMC specifications and have been tailored by the GSFC for space flight application and incorporated into the GSFC's General Environmental Verification Specifications For STS & ELV Payloads, Subsystems, and Components (GEVS-SE). The Guideline also incorporates the applicable EMC requirements defined in the Shuttle Orbital\/Cargo Standard Interfaces Document (JSC 07700 Volume XIV Attachment 1 (ICD 2-19001). These EMC test requirements when performed as a set are intended to provide an adequate measure of hardware quality and workmanship. The tests are performed to fixed levels which are intended to envelope those that may be expected during a typical mission and allow for some degradation of the hardware during the mission. The levels are tailored by the user to meet mission specific requirements, such as the enveloping of launch vehicle and launch site environments, or the inclusion of very sensitive detectors or instruments in the payload. The following table is a matrix of EMC tests that apply to a wide range of hardware intended for launch either by the STS or an expendable launch vehicle (ELV). Tests are prescribed at the component, subsystem, and payload levels of assembly. Not all tests apply to all levels of assembly or to all types of payloads. A project or hardware designer must select the requirements that fit the characteristics of the mission and the hardware, e.g., a transmitter would require a different group of EMC tests than a receiver. Symbols in the hardware levels of assembly columns assist in the selection of an appropriate EMC test program. Table 1. EMC Requirements per Level of Assembly Type Test STS ELV Component Subsystem\/ Instrument Payload* Spacecraft CE DC power leads X X Sb,Rb,R Sb,Rb,R Sb CE AC power leads X Sb,Rb Sb,Rb Sb CE Spikes on orbiter DC power lines X Sb Sb Sb CE Spikes on orbiter AC power lines X Sb Sb Sb CE Antenna terminals X X R - - RE Magnetic fields (STS payloads) X - - Sb RE AC magnetic field X X Rb,R Rb,R Rb,R RE E-fields X X Rb,R Rb,R Sd,Rb,R RE Payload transmitters X X - - Sd,** RE Spurious (transmitter antenna) X X - Rb,R - CS Power line X X Rb,R Rb,R Rb CS Intermodulation products X X Rb,R - - CS Signal rejection X X Rb,R - - CS Cross modulation X X Rb,R - - CS Power line transients X X Rb,R Rb,R Rb RS E-field (general compatibility) X X Rb,R Rb,R Rb,R RS Compatibility with orbiter transmitters X - - Rb RS Orbiter unintentional E-field X - - Rb RS Magnetic-field susceptibility X X Rb,R Rb,R Rb,R RS Magnetic properties X X R R R CE - Conducted Emission CS - Conducted Susceptibility R - Test to insure reliable operation of payload, and to help ensure compatibility with the launch vehicle and launch site Rb - Test to ensure reliable operation of orbiter attached payloads RE - Radiated emission RS - Radiated Susceptibility Sb - Items interfacing with orbiter power in payload bay or in the cabin: required by ICD 2-19001 Sd - Items operating on or near orbiter: required by ICD 2-19001 * - Payload, Mission, or highest level of assembly ** - Must meet any unique requirement of launch vehicle and launch site for transmitters that are on during launch Once the program is selected, all flight hardware is tested. The EMC test program is meant to uncover workmanship defects and unit-to-unit variations in electromagnetic characteristics, as well as design flaws. The qualification and flight acceptance EMC programs are the same. Performance of both will provide a margin of hardware reliability. A wide range of EMC test requirements are provided to cover a variety of free flyer and shuttle-attached operating modes. For example, some free flyers will be operated with the orbiter during prerelease and checkout procedures and must be tested to ensure EMC with the orbiter. In other cases, the most stringent EMC requirements can occur after the free flyer moves away from the orbiter when it or its sensitive instruments can become susceptible to the operation of its own subsystems. Because some free flyers will not be operated or checked out before release from the orbiter, they do not have to meet the orbiter EMC requirement and the tests need only ensure self-compatibility and survival to exposure to the high-level emissions from the orbiter's transmitters. Requirements are also provided for attached payloads that may be subjected throughout the mission to EMI from the orbiter and from other payloads. It is recommended that testing be performed at the component, subsystem, and payload levels of assembly. Testing at lower levels of assembly has many advantages: it uncovers problems early in the program when they are less costly to correct and less disruptive to the program schedule; it characterizes box-to-box EMI performance, providing a baseline that can be used to alert the project to potential problems at higher levels of assembly: and it aids in troubleshooting. The tests and their limits are considered minimum requirements, however they may be revised as appropriate for a particular payload or mission. Technical Rationale: The Guideline presents EMC verification requirements for GSFC payloads, subsystems, and components and includes a baseline for demonstrating by test satisfactory performance of hardware in the expected mission environments. The Guideline includes the applicable requirements for Shuttle carried hardware. References: General Environmental Verification Specification for STS & ELV Payloads, Subsystems, And Components (GEVS-SE) Shuttle Orbiter\/Cargo Standard Interfaces Document (JSC 07700 Volume XIV Attachment 1 (ICD 2-19001). Power Line Filters - Reliability Preferred Practice No. PD-ED-1206 Electrical Shielding Of Power, Signal, and Control Cables - Reliability Preferred Practice No. PD-ED-1213","Lesson ID":710}
{"Driving Event":"This Lesson Learned is based on Reliability Guideline Number GT-TE-2402 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: For high frequency, large aperture antennas, near field antenna facilities provide more timely, cost effective, and efficient pattern measurements resulting in the following benefits: protection for environmentally (and gravitationally) sensitive antennas from elements such as wind, rain, smog, wildlife, etc.; characterization of complete far field pattern over region corresponding to sampled near field; measurements are not affected by weather or uncontrolled reflections; diagnostic capability for feed misalignment, phased array element amplitude and phase excitation, holographic determination of reflector surface accuracy; and depending on range geometry, accurate characterization of far sidelobes and backlobe patterns; accurate far-field pattern construction of both co- and cross-polarization patterns from the same set of near field data. Implementation Method: The implementation of near field antenna measurements for the determination of far field antenna patterns involves the following. A near-field probe is placed in close proximity to an antenna under test. The probe or test antenna or both are moved in such a manner that a set of complex field measurements can be made at known locations, with respect to the test antenna. The surface containing the measurements should, in general, completely enclose the antenna. However, for most directional (larger aperture) antennas, an abbreviated plane, which intercepts all but a small percentage of the radiated energy, can be used, resulting in negligible loss in accuracy. A spherical, cylindrical, planar, or other convenient surface can be used. At each measurement point, on the measurement surface, the complex field and position are measured. The set of measurements are transformed, via near-field to far field transformation algorithms, to obtain the far field patterns for the test antenna. The near field antenna test facility at LeRC is in an in-door, environmentally controlled test area. The facility contains a moveable antenna mount that is used to orient and position the antenna and a structure used to move the near-field probe within a 22 ft x 22 ft vertical plane. The facility is designed to test antennas with horizontal orientation of the antenna boresite. A block diagram of the LeRC Near Facility is shown in Figure 1, below. [D] A laser distance measuring system, shown in Figure 1, is used to measure x and y position of the probe in the scan plane. The complex electric field is measured at each measurement point in the scan plane using a Hewlett Packard 8510 automated network analyzer; and Hewlett Packard 8340 frequency synthesizers are used to provide RF and local oscillator signal sources. Fiber optic links are used to distribute local oscillator signal to RHG mixers. The data acquisition and system control are performed by an on-site computer. Data processing is performed in an offsite computer facility. The LeRC near field test facility was designed for frequencies of operation from 0.8 GHz to 60 GHz. The scanner can test antennas having a D\/l to 1100 for antenna apertures up to 18 ft. D is a characteristic dimension of the test antenna (i.e. diameter for a circular aperture antenna), andl is the wavelength for the antenna operating frequency. For detailed description of design, operation and performance see references 1, 2, and 3. Other near field antenna test facilities within NASA (see Appendix) are located at JPL, and JSC. In selecting a near field range for antenna testing, just as in selecting a far field range, attention must be given to the determination of measurement uncertainty. This can be of importance for applications requiring low measurement uncertainties or high precision. As in far field ranges, near field ranges are affected by electronic equipment sources of error such as drift, noise, dynamic range, nonlinearity, signal leakage, and reflections. However, the error manifestations may differ between the near field and far field ranges. In addition, the near field range is affected by error sources from probe interactions with the near fields, probe position, antenna alignment, and errors caused by flexing cables. Mathematical errors are generally very small in comparison to experimental errors. For more information on the effects of errors in near field antenna testing see references 6 and 7. Technical Rationale: The measurement of far field antenna patterns can be accomplished by using a far field range or a near field measurement facility. For measurements made in the far field, the distance between the test antenna and the measurement transmitting source (or receiver) must be greater than 2D2\/l, where D is a characteristic dimension of the test antenna and l is the wavelength. (For antennas having significant aperture phase deviations and requiring low measurement uncertainties, the spacing required can exceed 8D2\/l.) From this relation it can be seen that large distances are required for far field testing of large aperture, high frequency antennas. For example the test distance required for far field pattern measurement of a 12 GHz parabolic reflector antenna with a 12 ft diameter would be 3500 ft. Because of the large distances the far field tests are conducted outdoors where the testing is constrained by weather and the transmission path is influenced by the weather. In addition, the path between the test antenna and the source must be controlled to preclude variations due to reflections from traffic entering the path. The determination of far field antenna patterns, obtained by using near field measurements, has been demonstrated and proven, references 4 and 5. The validity and accuracies have been shown to be comparable to measurements made using far field ranges, under conditions controlled to preclude environment errors. The determination of far field antenna patterns, from near field measurements, can be done indoors in a protected, controlled environment, where the testing is not constrained by the effects of weather on the test antenna or results. The anechoic environment can provide protection for costly flight hardware from weather, smog, wildlife, and other environmental hazards. The region of testing can be designed and controlled to minimize the effects of reflections. And, for spacecraft antennas designed in a microgravity environment, the effects of gravitational deformations can be reduced or eliminated when tests are conducted with vertical boresite orientations. These advantages are gained at the expense of increased measurement times and complexity. Many measurements must be made to define the near field pattern, see reference 7. The set of near field measurements must be made up of complex field quantities (e.g., a+jb) and an accurate determination of probe position. Data acquisition time is a function of desired accuracy, aperture area, and frequency. In addition, computation time is required to transform the near field data to the far field patterns. Appendix: This appendix provides a listing of near field antenna test facilities within NASA, and lists their salient characteristics. The table below lists the location of the facility, the type of scanning surface used, the size of the scanning plane, the maximum frequency of operation, and antenna boresite orientation. The table also describes the mode of operation supported for the test antenna, i.e. transmitting and\/or receiving, and notes if the test antenna must be moved during testing. Location Type Size, m Frequency, GHz Boresite Orientation Mode Probe motion Note JPL Cylindrical 5.2 18 horizontal trans 1d rotate antenna JPL Plane polar 6.1 32 vertical trans 1d rotate antenna JSC Plane rectangular 12.2x12.2 40 vertical trans 2d fixed LeRC Plane rectangular 6.7x6.7 60 horizontal trans rec 2d fixed The following is a brief description of each center's near-field capability. Jet Propulsion Laboratory Cylindrical Near-Field Facility The cylindrical near-field scanning facility at JPL contains an anechoic chamber that is 20x20x40. The chamber contains two automated positioners, one for the test antenna and the other for the sampling probe. Cylindrical near-field scanning is performed by rotating the test antenna in an azimuth direction while the probe step along the z-direction after the test antenna completes a full 360 degree rotation. The Jet Propulsion Laboratory has conducted recently an extensive research in the area of cylindrical near-field that led to the development of efficient and fast algorithms for far field construction, probe pattern compensation, probe characterization, and an error analysis. Plane-polar Near-Field Facility The plane-polar near-field range facility is located in an anechoic chamber with a dimension of 20'x20'x40'. The facility utilizes two automated positioners, one for the test antenna (generally has a large planer aperture) and the other for the sampling probe. The test antenna aperture is horizontally situated close to the ground with the aperture placed in the x-y plane facing up and rotated azimuthally around the z-axis. The probe is situated close to the ceiling facing down with a single linear translational motion in the x or y direction above and across the center of the test antenna. The probe is generally separated several wavelengths away from the test antenna. The near-field amplitude and phase data are taken with the probe initiated at a particular incremental location while the test antenna is rotated 360 degrees incrementally, which is repeated at the next incremental probe location, etc. The probe has a total rms deflection of 0.025 cm over the total run of the carriage (7m long). This provides sufficient accuracy for measurement up to Ku-band and can be improved for Ka-band measurement. Johnson Space Center Plane Rectangular Near-Field Facility The anechoic chamber at the Johnson Space Center is capable of testing antennas up to 30 ft in diameter. The frequency range of the facility is from 1.0 Ghz to 60.0 Ghz. The near-field facility includes a two-axis horizontal scanning system. The scanner is configured with a RF probe which can function as a transmitter or receiver. The probe travels in the Y-direction for each step increment moved by the translation beam in the X-direction. The movement of the scanner will describe a raster scan geometry. During testing, the position of the test antenna will be fixed such that its boresight will be perpendicular to the horizontal scan plane of approximately 40'x38'. The planarity of the scanner as described by the probe tip motion will be flat within +\/- 0.005 inch. This accuracy is especially critical at the maximum operating frequency of 60.0 GHz. References: Sharp, G. R., et al: quotCharacteristics and Capabilities of the NASA LeRC High Precision 6.7-by 6.7-m Planer Near-Field Scanner,quot NASA TM 83785, October 1984. Kunath, Richard R. and Zakrajsek, Robert J.: quotNear-Field Testing of the 30-GHz TRW Proof-of-Concept Multibeam Antenna,quot NASA TM 87357, September 1986. Kunath, Richard R., and Garrett, Michael J.: quotNear-Field Antenna Testing Using the Hewlett Packard 8510 Automated Network Analyzer,quot NASA TM 103699, October 1990. Joy, Edward B. and Paris, Demetrius T.: quotSpatial Sampling and Filtering in Near-Field Measurements,quot IEEE Trans. Antennas and Propagation, Vol. AP-20, May 1972, pp. 253-261. Newell, A. C., and Crawford, M. L.: quotPlanar Near-Field Measurements on High Performance Array Antennas,quot NBS, NBSIR 74-380, July 1974. Evans, Gary E.: quotAntenna Measurement Techniques,quot Artech House Inc., 1990. Acosta, Roberto J., and Lee, Richard Q.: quotCase Study of Sample Spacing in Planar Near-Field Measurement of High Gain Antennas,quot NASA TM 86872, September 1984. Yaghjian, A. D.: quotNear-Field Antenna Measurement on Cylindrical Surface: A Source Scattering Matrix Formulation,quot NBS Tech. note 698, July 1977.","Lesson ID":715}
{"Driving Event":"This Lessons Learned is based on Reliability Practice Number PD-EC-1107; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Micrometeoroid protection minimizes the risk of impacts that can damage spacecraft systems and jeopardize flightworthiness. Sources of meteoroids include planetary ejecta and particles of asteroidal and cometary origin. Impacts on spacecraft can cause partial penetration, perforation, spalling, local deformation, or secondary fractures, any of which can result in failure of a critical system. Typical failure modes include: Catastrophic rupture. Leakage. Deflagration. Vaporific flash. Reduced structural strength. Erosion. Implementation Method: Micrometeoroid protection is designed to attain an acceptable failure probability for critical spacecraft subsystems. It involves the application of spacecraft and mission design measures which are also used to control other aspects of the spacecraft environment \u2014 radiation protection, thermal protection, thermal insulation, and space radiators \u2014 requiring an integrated approach to environmental design. Damage Assessment The first step in determining the appropriate level of spacecraft protection is evaluation of the environment as defined by the meteoroid fluence, defined as the number of impacts per square meter (m2) of the spacecraft over the mission duration. The meteoroid environment is calculated based on models of near-Earth and interplanetary space (Ref. 4, 5), with particular attention to the asteroid belt between Mars and Jupiter. The current models describe meteoroid mass and orbital distributions based on data from impact detectors aboard the Pioneer 10 and 11, Helios 1, Galileo, and Ulysses spacecraft and measurements of the interplanetary flux (particles\/m2\/second) near Earth. Meteoroid fluence models are continously updated based on flight experience. However, because the major portion of the meteoroid flux has a random distribution, a statistical model is used to determine the probability of a spacecraft encountering a meteoroid of a given critical mass. The meteoroid fluences \/m2 are then evaluated for different mission phases \u2014 for example, transit, aerobraking, mapping, and relay. The fluences as a function of particle mass may then be calculated from the spacecraft trajectory and velocity as determined by the mission profile. Following evaluation of the meteoroid environment for each mission phase, three additional factors \u2014 areas of interest, field of view, and spacecraft attitude \u2014 are then factored into the fluences for all mission phases. For the areas of interest, spacecraft drawings are reviewed to obtain the surface areas in m2 for each critical spacecraft system. The field of view, or geometric factor corresponding to all visible surfaces of an object, is calculated using a ray tracing computer code. The geometric factor specifies the fraction of the fluence that will be detected by a detector placed on one of the surfaces. The spacecraft attitude during the mission is important because the surface perpendicular to the velocity vector will receive the highest fluence, while the trailing edge surface will receive the lowest fluence. To derive the probability of failure of each spacecraft system, the fluence (as a function of velocity) is multiplied by the appropriate area (m2), geometric factor, and attitude factor to give the expected number of impacts on the area of interest. Penetration equations are then used to estimate the critical mass as a function of velocity necessary to cause penetration of a surface. For example, a review of Mars Global Surveyor (MGS) propellant and helium tanks indicated that the probability of propellant tank No. 1 being struck by a meteoroid (though not necessarily damaged) during the mission is 30 percent, and 25 percent for propellant tank No. 2. Based on the damage assessment, a decision is made on suitable protective measures to minimize damage to critical spacecraft subsystems. (For a linear component, calculation of the surface area may not be feasible. Damage assessment for the cables along the MGS high gain antenna boom, for example, was based on a determination that only one side of the cables is vulnerable: the other side is protected by the boom.) Protective Measures System Design Measures. Micrometeoroid protection is considered in the design of the spacecraft structure and the location of critical assemblies relative to the spacecraft structure. Critical assemblies may be positioned so that their field of view is shielded by less critical assemblies or by structures which may be penetrated or deformed without resultant mission-critical damage. With this approach, the most crucial or easily damaged circuit board, for example, should be placed deepest in the electronics bay; the board's long axis could also be positioned parallel to the velocity vector to minimize the fluence. More realistically, however, meteoroid protection requirements must be balanced against the need for radiation and thermal protection in an integrated environmental design. Operational Measures. Due to the directional properties of particle impact velocities, spacecraft attitude has an effect on the micrometeoroid fluences that each side of the spacecraft receives. Certain mission phases, such as planetary mapping, place the spacecraft in a high flux location in interplanetary or orbital space. Hence, a measure of protection may be attained from a mission profile which adjusts spacecraft attitude to minimize damage to critical systems during hazardous mission phases. For the Mars Global Surveyor (MGS) project, fluences were calculated for the different sides of the spacecraft (+X, -X, +Y, -Y, +Z, and -Z). For the Cruise phase of the mission, the +X side of the spacecraft will face the Earth, and the varying attitude will cause the -Y and -X sides to receive similar fluences. During the Mapping and Relay phases, with MGS orbiting Mars while moving with Mars in its orbit around the sun, the +Z side of MGS will face the planet while the +Y side will face in the direction of Mars orbital velocity. The net effect is a rotation of MGS about its Y axis. Calculations indicate that the flux at the leading edge of the spacecraft (+Y) will be approximately 20 times larger than the trailing edge. [D] The MGS propellant and helium tanks are located on the +Y side of the spacecraft, as indicated in Figure 1. Combining the formulas for penetration with the meteoroid fluences, and multiplying by the field of view (geometric factor), the attitude factor, and the area of each side of the spacecraft, gives the number of impacts per unit area that can produce failures. Applying a Poisson distribution gives the probability of failures over each mission phase. Figure 2 indicates the probability of success for the MGS tanks. [D] Protective Shielding. The primary technique for meteoroid protection is placement of multi-layer insulation (MLI) blankets on critical areas of the spacecraft, such as propellant and helium tanks. MLI blankets are composed of layers of a Kapton polyamide or mylar; gold foil on one side and silver on the other provides very effective thermal insulation and thermal radiation transfer. In its use as a projectile shield, the blanket function is to break up the projectile before it strikes an exterior wall, disperse the fragments, and reduce the velocity of the fragments below that of the original projectile. Spacecraft damage is caused by the debris from the projectile and the shield. MLI effectiveness in preventing damage to critical spacecraft subsystems depends on the: Blanket material, location, and number of layers. Meteoroid mass, impact velocity, density, and angle of impact. Impacted structure material, thickness, temperature, stress level, and the number and spacing of the plates composing the structure and the subsystem package. However, an MLI layer density approximating that of tissue paper is sufficient to stop most strikes due to the very small mass of the typical micrometeoroid. Specification of MLI blankets for meteoroid protection is not generally practiced because the blanket characteristics are established for the objective of maximizing thermal control, with penetration shielding as a secondary benefit. A single exception is the use of MLI specifically to shield certain components of the rocket nozzles on the Cassini spacecraft. However, the spacecraft MLI design \u2014 the MLI integration with the spacecraft structure \u2014 is planned to provide the optimal level of meteoroid protection. The primary MLI design variable for providing micrometeoroid protection is the blanket-structure separation distance. Modeling and ground test have demonstrated that the likelihood of micrometeoroid damage decreases with increasing separation between the blanket and external spacecraft structural surfaces. This is mostly due to the dispersion of the projectile and shield fragments with increasing distance. Where a tight cluster would result in penetration by debris approaching the mass of the original projectile, dispersion may produce scattered separate craters, bulges, or holes. Penetration equations derived from modeling, and from tests using particle accelerators and light-gas guns, are used to calculate the critical meteoroid mass (mc) necessary to cause the failure (i.e., penetration) of a given surface. Separate equations are used for single surfaces (e.g., the spacecraft wall and attached shield) and double surfaces (e.g., spacing between the spacecraft wall and blanket). Equation 1 calculates the critical penetration mass (mc) of the meteoroid in grams for a single surface geometry. [D] Eq 1. (Single Surfaces) Where: m c = critical penetration mass of the meteoroid (grams) t = wall thickness (inches) K t = material constant (0.54 for aluminum alloys) r m = meteoroid mass density (2.5 g\/cm 3) V = impact velocity (km\/s) Equation 2 is used to calculate the critical mass (mc) for a double-wall structure where a blanket shields the exterior of a spacecraft structure (such as a propellant tank) or component (such as a cable along a spacecraft boom). [D] Eq 2. (Double Surfaces) Where: S = spacing between blanket and tank wall (cm) t b = thickness of tank wall (cm) s y = yield stress for the tank wall (47,000 lb\/in 2) r m = meteoroid mass density (2.5 g\/cm 3) r t = blanket mass density (0.3 g\/cm 3) V = impact velocity (km\/s) Equation 2 demonstrates that the critical penetration mass will increase and the probability of failure will decrease with increased spacing between the blanket and the shielded surface. For example, when applied to a review of Mars Global Surveyor (MGS) propellant tanks, Equation 2 showed that a 2-inch spacing between the surface of each tank and the MLI blanket will decrease the probability of failure during the mission to about 6 percent on both tanks, given the expected meteoroid fluences. This represents a decrease from the 30 percent probability of failure for propellant tank No. 1 and 25 percent for propellant tank No. 2, given no separation, which was previously mentioned. Figure 3 depicts the effect of blanket separation on the probability of success for the MGS tanks. [D] The applicability of these equations is limited by data availability. The practice has been to extrapolate the equations over the micrometeoroid mass and velocity anticipated during a spacecraft mission. They provide the best available estimate of penetration in the 0 to 10 km\/s velocity range; lacking experimental test data for higher impact velocities, they have also been used for velocities exceeding 10 km\/s. However, there may be insufficient validating data on impact velocities exceeding 7 km\/s. Although JPL is presently working on extending the penetration equations to higher velocities, JPL has no reason to believe that micrometeoroid protection practices for long missions have been other than successful. Technical Rationale: The ability of meteoroids to penetrate the external skin of a spacecraft has been amply demonstrated by meteoroid detection satellites and other near-earth spacecraft. The ability of micrometeoroids in interplanetary space to damage spacecraft is inferred. Environmental models of meteoroids in near-earth and interplanetary space, and particularly in the asteroid belt between Mars and Jupiter, are continuously updated. However, because the major portion of the meteoroid flux has a random distribution, a statistical model is used to determine the probability of a spacecraft encountering a meteoroid of a given critical mass. The damage capability of a meteoroid depends on its mass, velocity, density, and angle of impact. The physical response of an impacted structure depends on the material, thickness, temperature, stress level, and the number and spacing of the plates (including shielding) composing the structure. Based on models of the micrometeoroid fluence and calculations of the number of impacts that can lead to failure, the degree of damage can be estimated and appropriate design or operational measures can be implemented. References: Aguero, R.C., quotMeteoroid Impacts on MGS,quot (Mars Global Surveyor Project), Jet Propulsion Laboratory IOM 5050-95-316 to T.D. Newell, November 6, 1995. Frost, V.C., Meteoroid Damage Assessment, Space Vehicle Design Criteria (Structures) Document SP-8042, National Aeronautics and Space Administration, May 1970. quotSpacecraft Environmental Estimates,quot (Mars Global Surveyor Project), Jet Propulsion Laboratory Document MGS 542-203, October 14, 1994. Divine, N., quotFive Populations of Interplanetary Meteoroids,quot Journal of Geophysics Research, 98, pp. 17,029- 17,048, 1993. Divine, N. and Gruen, R., quotModeling the Meteoroid Distributions in Interplanetary Space and Near-Earth,quot Proceedings of the First European Conference on Space Debris, Darmstadt, Germany, April, 1993. quotMeteoroids\/Space Debris,quot Reliability Preferred Practice No. PD-EC-1102.","Lesson ID":705}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-EC-1106; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefits: Potential EMI sources are identified in time so that appropriate measures can be incorporated into the electromagnetic compatibility (EMC) program. If the high predicted levels turn out to be a problem, the early identification allows time to develop a solution. Implementation Method: Perform a comprehensive survey of the mission environments and payload characteristics, then determine the possible sources of plasma generated noise. If the source of plasma noise is from the natural occurring space plasma or arises from the motion of a spacecraft through the earth's geomagnetic field, the radiated susceptibility (RS03) test levels specified in MIL-STD-461C will be adequate. The magnitude of plasma waves in the natural space environment is usually limited by the thermal energy of the ambient plasma. Due to the low plasma densities of the earth and other planets, the energy content of the naturally occurring space plasma is relatively low. It can easily be shown that the MIL-STD-461C radiated susceptibility RS03 limits are adequate to demonstrate a spacecraft's immunity to EMI generated by natural plasma noise. The RS03 specifications are: Frequency Range E-Field (Volts\/meter) 14 kHz to 30 MHz 10 30 MHz to 10 GHz 5 Above 10 GHz 20 For large conducting structures moving across the geomagnetic field, additional plasma noise is generated as a result of wave emission due to the motion induced VxB electric field. In low earth orbit, the noise level generated by a typical space station structure is estimated to be 10-3 V\/m per ampere current (ref. 1) and that of a tethered satellite system is 10-1 V\/m (ref. 2). Since the typical current flow for the space station and the tethered satellite is less than 1 Amp, the electric field generated by motion of a space structure will also be enveloped by the MIL-STD-461C RS03 limits. Plasma can also cause structure current (conducted emission) to flow in the spacecraft. In the absence of any externally induced events, the net current to the spacecraft structure is always zero. When the spacecraft goes in and out of eclipse, a transient current would be induced on the spacecraft structure. Since the time scale of this type of transition is relatively long, on the order of seconds, and the current involved is the plasma current that can be collected by a spacecraft (which is on the order of 0.1A), this transient current will not be a EMI source of any concern. Technical Rationale: Electron beam experiments can generate high levels of conducted and radiated EMI. When an electron beam is injected into the plasma from a spacecraft, a return current must be present in order for the current loop to be completed. The rise time of this return current is determined by the transit time of thermal electrons through the sheath surrounding the spacecraft. This time scale is >0.1 ms (ref. 3 and 4). The upper bound value of the peak return current is given by the peak injected electron beam current. Therefore, the dI\/dt of the structure current will be in the range of 108 A\/s (assuming a peak current of 10 Amp). For programs that have tests to demonstrate immunity against lightning or ESD inducted structure current, the dI\/dt of those test specifications are usually >104 A\/ms and thus they envelope the dI\/dt induced by electron beam. For a program that has no test specifications for structure current, it should be added to the EMC program if an electron beam experiment is on-board. This is particularly important when the beam current exceeds 10 Amp. The injected electron beam also generates large amplitude waves in the ambient plasma (ref. 5). A comprehensive analysis is needed to determine the maximum amplitude of the beam generated plasma noise. This analysis involves an estimate of the conversion efficiency of the beam energy into electromagnetic wave energy. Usually this conversion efficiency has an upper bound value of 1% (ref. 6). Once the amplitude of the EMI produced by beam generated waves has been determined, the adequacy of the MIL-STD-461C RS03 specifications can be evaluated. Similar approaches can be applied to determine the EMI resulting from the interaction of an ion engine plume and the ambient plasma. References: Hastings, D. and Wang J. (1989), \"Induced Emission of Radiation from a Large Space-Station-Like Structure in Ionosphere,\" AIAA Journal, 27, N4. Wang, J. and Hastings, D. (1991), \"A Dynamic Analysis of the Radiation Excitation from the Activation of a Current Collecting System in Space\", Journal of Geophysical Research, 93, A3. Singh, N. and Hwang, K. (1988), \"Electric Potential Structures and Propagation of Electron Beams Injected From a Spacecraft Into a Plasma\", Journal of Geophysical Research, 93, A9. Neubert, T., et al. (1986), \"Waves Generated During Electron Beam Emissions from the Space Shuttle\", Journal of Geophysical Research, 91, A10. Wincler, J., et al. (1989), \"Echo 7: An Electron Beam Experiment in the Magnetosphere,\" Eos, Transactions, American Geophysical Union, 70, 657. Winglee, R. and Kellog, P. (1990), \"Electron Beam Injection During Active Experiments, 1, Electromagnetic Wave Emissions\", Journal of Geophysical Research, 95, A5.","Lesson ID":708}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1221; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Selection of the optimum battery for space flight applications results in a safe, effective, efficient, and economical power storage capability. The optimum battery also enhances launch operations, minimizes impacts to resources, supports contingency operations, and meets demand loads. Implementation Method: Primary batteries, those which are not recharged are and useful for short duration, are used principally for providing electrical power for launch vehicles. These batteries must have high energy density, high current capabilities, and good reliability. MSFC has had experience with Lithium\/Monoflouride (Li\/CF), Lithium\/Thionyl Chloride (Li\/SOCl2), and Silver\/Zinc (Ag\/Zn) primary batteries. Secondary batteries, those which are discharged and then recharged numerous times, are principally used for spacecraft, satellite, and other long-term space-oriented applications. In space applications, reliability, costs, producibility, responsiveness, risks, safety, and maintainability are more important than high current content. MSFC has had experience with Silver\/Zinc (Ag\/Zn), Nickel\/Hydrogen (Ni\/H2), Nickel\/Cadmium (Ni\/Cd), Nickel\/Metal Hydride (Ni\/MH), and Bi Polar-Lead Acid (Bi-Pb\/Acid). [D] Battery types are selected for specific applications based on a number of factors including specific energy and energy density (see Figures 1 and 2), lifetime, number of cycles, discharge rate, charge retention, shelf life, ruggedness, operating temperature, and other factors. Figure 3 presents these factors for various battery types. Figure 3 should be used by the designer as an initial tool for selecting the required battery type. The design of batteries for space flight should be accompanied by battery level electrical, mechanical and thermal analysis. [D] A typical battery selection flow chart is shown on Figure 4. After the program is identified and electrical power requirements are established, a trade study should be performed to determine the actual battery (primary or secondary) that will fulfill the requirements at a reasonable cost. Cell selection includes charge voltage, discharge capacity, and discharge voltage after cycling. Establishing the battery size is determined by the number of cells required to provide the required electrical power, i.e., a 24-volt battery using a 1.5 volt cell will require 16 cells. Mechanical packaging of the cells into a battery requires such parameters as cell type, number of cells, weight, length, height, temperature requirements, mounting method, vibration environment, electrical feed through, and venting requirements to ensure proper functioning of the battery. Perhaps the most important part of selecting a battery is the selection of a reliable cell\/battery manufacturer. Preferably one that has consistently produced high quality and reliable batteries. Manufacturing engineers should critique the design for producibility and testability early in the design process and make corrective suggestions when problems are discovered. [D] Accelerated life testing of batteries is extremely difficult due to the nature of the chemical reaction between the electrolyte and the positive and negative electrodes. Therefore, preferred type and configuration of the battery should be selected early in the program to allow for lifetime testing. Performance testing of the selected battery can be accomplished in parallel with life testing. Performance testing should be accomplished in an environment to which the battery is expected to be exposed during operation. The battery should demonstrate during testing that it will deliver the required electrical power and will charge and discharge as designed. Technical Rationale: MSFC's aerospace flight battery experience comes from a combination of its own in-house laboratory experience on numerous programs; from coordination with battery manufacturers, prime contractors, and subcontractors for a number of launch vehicles, space vehicles, and experiments; and from many years of participation in NASA\/industry aerospace battery workshops. Two such workshops, hosted by the Marshall Space Flight Center in Huntsville, Alabama, were attended by approximately 200 persons each, representing both Government and industry. Credit must be given to the interdisciplinary efforts of Goddard Space Flight Center, NASA Headquarters, Jet Propulsion Laboratory, Johnson Space Center, Kennedy Space Center, Ames Research Center, Langley Research Center, Lewis Research Center, and their suppliers and contractors, as well as to many academic and nonprofit organizations who have contributed to the battery research leading to this body of knowledge. References: Bykat, Alex, quotDesign of an Expert System for Diagnosis of a Space Borne Battery Based Electric Power System,quot University of Tennessee at Chattanooga, IECEC, Vol. I Aerospace Power Systems Conference, August 1990. Dunlop, J. D., quotNASA Handbook for Nickel-Hydrogen Batteries,quot Preliminary Draft, Goddard Space Flight Center, June 1991. Glover, D.G., quotAerospace Energy Systems Laboratory: Requirements and Design Approach,quot Ames Research Center, Dryden Flight Research Facility, Edwards AFB, CA, NASA Technical Memorandum 100423, 1988. Guthals, D.L. and Olbert, Phil, quotCRRES Battery Workshop,quot Ball Space Systems Division, letters dated March 11 and 16, 1992. Halper, G., Subbarao, S., and Rowlette, J.J., quotThe NASA Aerospace Battery Safety Handbook,quot JPL Publication 86-14, July 15, 1986. Jones, Dr. G.M., quotATM Electrical Power System Post Mission Design and Performance Review,quot George C. Marshall Space Flight Center Report No. 40M22430, February 6, 1975. Kennedy, L. M., quot1990 NASA Aerospace Battery Workshop,quot 1991, NASA Conference Publication 3119, Marshall Space Flight Center, December 4-6, 1990. Linden, David, Handbook of Batteries and Fuel Cells, McGraw Hill Inc., 1984. Manned Space Vehicle Battery Safety Handbook, NASA, Johnson Space Center, JSC 20793, September 1985. MIL-B-81502B(AS), quotBattery, Silver-Zinc-Alkali, General Specification for,quot February 26, 1980. MIL-B-82117D, quotBattery, Storage, Silver-Zinc, Rechargeable, General Specification for,quot July 25, 1983. NASA SP-172, quotBatteries for Space Power Systems,quot NASA 1968.","Lesson ID":714}
{"Driving Event":"This Lesson Learned is based on Reliability Guideline Number GD-AP-2304 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Consideration of fracture mechanics reliability during the design process can assist in the prevention of failures of structural and mechanical components subject to fluctuating loads in service. Explicit consideration of the reliability of structural and mechanical components provides the means to evaluate alternate designs and to ensure that specified risk levels are met. Probabilistic fracture mechanics analyses may also be applied to life extension of existing structures, and for problem assessment of in-service fatigue failures. Potential applications of this method to the Space Shuttle or Space Station include: landing gear, control surfaces, main engine components, auxiliary power unit components, external tank and solid rocket booster welds, pressure vessels, propulsion modules, and logistics modules. The method is also applicable to reusable, Shuttle launched payloads or spacecraft such as Spacelab, Spacehab, EURECA, SPAS and Spartan. Stochastic fracture mechanics analysis provides the basis for analysis consistency between reliability analysis of mechanical systems, such as reliability block diagram analysis, and traditional deterministic fracture mechanics safe life estimation. Implementation Method: The method outlined below is a stochastic elastic fracture mechanics approach (for metallic or ceramic materials) which neglects any crack retardation or acceleration effects. Composites and other materials with insufficient crack growth data or intractable flaw growth characteristics are not considered. The detailed development of this approach is essentially the same as that given in references 1 through 6. The purpose of the simplified approach described herein is to illustrate some of the advantages and typical results of a stochastic fracture mechanics analysis. Discussion of technical implementation details, such as the use of crack growth laws other than the Paris equation (for example, the modified Forman equation [reference 15]), follows in the technical rationale section. For illustration, a Paris crack growth law is assumed, which may be written in the form of a differential equation. For random applied stress processes, a solution can be written in the form of a limit state function, M, as: [D] (1) in which: [D] Failure is defined to occur when the critical crack length, a c, is exceeded, so that at failure M <0. The probability of failure is then the probability that the limit state function is equal to or less than zero: [D] (2) The first term of Equation 1, the integral, essentially defines the fatigue resistance of the structure against a crack growing from an initial size, ao, to critical size ac. This integral must be evaluated numerically in all but the simplest of cases. Particular forms of the geometry function, Y(a), are available for simple configurations in the literature or from general purpose fracture mechanics software packages. For unique structural details, other approaches are available to determine Y(a), such as detailed finite element modeling of the cracked structure. The second term of Equation 1 defines the accumulated quotdamagequot caused by the applied stress process. A random stress process is characterized by its power spectral density and may be described as being narrowband (slowly varying random) or as wideband. In either case closed form approximations for the second term of Equation 1 are available. If the stress process is deterministic or if time histories of the stress process are available time domain methods, such as rainflow cycle identification [reference 10], approximations are available for determining the factors in the second term of Equation 1. It should be noted that all of the terms in Equation 1 may be treated as random or uncertain. This enables the modeling of all the sources of uncertainty pertinent to the problem, such as crack size and location, scatter in crack growth data, etc. Subsequent sensitivity analyses can be used to determine which variables contribute the most to the fatigue life uncertainty and require treatment as random, and which variables may be considered as fixed (deterministic). Sensitivity analysis can also indicate the parameters for which further data collection could reduce the overall uncertainty in the fatigue life. Modern reliability methods, the so-called First-Order Reliability Method (FORM) or Second-Order Reliability Method (SORM), are available in commercial computer programs to solve Equation 2. Monte Carlo or more sophisticated simulation techniques are also available [references 1, 7, 8, and 9]. In particular, PROBAN [1] has been available commercially from Det Norske Veritas (Oslo, Norway) since 1986 and has been used extensively in the offshore oil industry. PROBAN is available for UNIX and VAX\/VMS based workstations. STRUREL is a PC\/Windows based application available from RCP, GmBH, of Munich, Germany. RELACS is a similar package available from REA, Inc., of Golden, Colorado. A NASA-funded application called NESSUS, which runs on UNIX workstations and mainframes, is available from the Lewis Research Center. The commercial codes are recommended because of better user-interfaces and better user support. Monte Carlo approaches generally require direct programming for the solution for the specific problem under study. For a structure or mechanism in service, the results of inspections may be incorporated into the analysis and the estimated failure probabilities updated to show the change in reliability based on the additional information on existing crack size. For each inspection, two outcomes are possible: either no crack is detected, or a crack is detected and its size or length is measured. Figure 1 is an example analysis result (from reference 1) showing reliability as a function of time for which inspections were assumed at 10 and 20 years, with no crack detected at 10 years, but a 4.0 mm crack detected at 20 years. Note that with the new information gained from inspection at t=10 years, the reliability is shown to increase as no crack was found. After inspection at t=20 years, reliability is also shown to increase even though a small crack was detected, but only for a short time. The increase at t=20 years can be attributed to the discovery that the crack length was less than the critical crack length for the structure, but it should also be noted that the reliability decreases much faster with the uncertainty tied to the presence of a flaw. Inspection of structures and the new information that is gained can essentially reset the reliability, and even though a crack may be discovered, this new information can lead to increased inspections, which can lengthen the life of the item. However, a crack detection generally decreases the reliability, as in this case after about t=22 years. [D] Technical Rationale: A stochastic fracture mechanics approach to fatigue gives an estimate of the reliability of structural and mechanical components as a function of time in service and allows the reliability estimate to be updated if the results of in-service inspections and\/or in-service load data are available [references 1 and 2]. The procedure may also be used to optimally schedule inspections, and to compare the adequacy of different inspection types or quality levels [references 1 and 2]. Type and quality of repair techniques may also be compared and selected to maintain a desired reliability level. Updating of these analyses as actual inspections or repairs occur is also possible [references 2 and 3]. The application of in-service reliability estimates is dependent on the availability of some form of flight load data and accessibility to the structure or mechanism for inspection. Without such data no updating of the initial design reliability analysis is possible. The primary intent of this guideline is to make available to the NASA reliability engineering discipline the engineering mechanics-based methods for estimating the reliability of structural and mechanical components. Use of such methods would allow for consistency of models and data between the reliability and structural\/mechanical engineering disciplines within NASA. A stochastic fracture mechanics approach provides a quotphysics-of-failurequot basis for estimating the reliability of components subject to fatigue and fracture. This enables fault tree or reliability block diagram analyses, or probabilistic risk assessments, for structural and mechanical components in spacecraft systems to be performed using the same data and engineering mechanics models as the NASA accepted, deterministic fracture analysis procedures [reference 14]. For example, the mean time to failure for a pressure vessel girth weld (as may be needed for a propulsion system reliability block diagram analysis) estimated using probabilistic fracture mechanics would be rationally consistent with the safe-life analysis performed to meet current NASA fracture control and safe-life analysis requirements. The approach outlined herein is a simplified formulation that neglects load interaction effects, such as retardation, by using the Paris crack growth law. If a Paris equation is properly fit to the basic crack growth data, the resulting deterministic safe life estimate will be more conservative (shorter) than the estimated life resulting from a fracture analysis which incorporates retardation. The current NASA accepted practice in fracture mechanics analysis uses the computer program NASA\/FLAGRO, which includes interaction effects. Load interaction effects may be included in a stochastic fracture mechanics analysis by using crack growth laws such as the modified Forman equation found in NASA\/FLAGRO. For example, a FORM\/SORM formulation which included the modified Forman equation has been used to study aircraft durability and damage tolerance [reference 14]. A direct Monte Carlo solution implementing the modified Forman equation may also be found in references 7, 8, and 9. Issues related to the implementation, applicability, and accuracy of FORM\/SORM and Monte Carlo methods are beyond the scope of this guideline. In general, if a fracture mechanics reliability analysis is to be performed and it has been determined from a preliminary deterministic fracture analysis thatthe Paris formulation is inadequate, the modified Forman equation (as in NASA\/FLAGRO) should be used following either the approach described in reference 14 or in references 7, 8, and 9. Two critical parameters in any fracture analysis, deterministic or stochastic, are the size, location and distribution of initial flaws or cracks, and the ability of nondestructive evaluation (NDE) techniques to detect a flaw or crack smaller than a certain size. NASA has established standard NDE flaw sizes for Space Transportation System (STS) payloads [reference 14]. Two recent NASA research projects, one directed at establishing NDE probability of detection (POD) data, and one directed at gathering initial flaw distribution data, also may provide additional data for modeling initial flaws and NDE quality. Deterministic fracture analysis practice uses relatively large safety or quotscatterquot factors to account for the many inherent sources of uncertainty or error, such as analytic model inadequacies, inaccuracy of stress intensity predictions, and the scatter of experimental crack growth data. Stochastic analysis methods extend the accepted deterministic methods by allowing (or forcing) the analyst to explicitly account for these uncertainties by treating them as random variables (or process or fields), requiring the analyst to consider the likely range and distribution of the parameters. Both the deterministic and the stochastic analysis will suffer from the same shortcomings of model inadequacy, etc. The stochastic model has the advantage of addressing the uncertainties specifically using probability and statistical theory, while the deterministic approach addresses uncertainty in a general manner through the use of the safety or scatter factor. Use of a stochastic approach and a reliability based design criteria can be beneficial in avoiding over- or under-conservatism that may result from the use of a deterministic safety factor approach. References: PROBAN-2: Example Manual, Report No. 89-2025, A.S Veritas Research, Hovik, Norway, August, 1989 Madsen, H.O., Skjong, R.K., and Kirkkemo, F., quotProbabilistic Fatigue Analysis of Offshore Structures - Reliability Updating Through Inspection Resultsquot, A.S Veritas Research, Hovik, Norway Madsen, H.O., Skjong, R.K., Tallin, A.G., and Kirkemo, F., quotProbabilistic Fatigue Crack Growth Analysis of Offshore Structures, with Reliability Updating Through Inspectionquot, Society of Naval Architects and Marine Engineers, Proceedings, Marine Structural Reliability Symposium, Arlington, VA, October 5-6, 1987 Wirsching, P.H., Torng, T.Y., and Martin, W.S., quotAdvanced Fatigue Reliability Analysisquot, International Journal of Fatigue, Vol. 13, No. 5, 1991, pp. 389-394 Wu, Y.-T., Burnside, O.H., and Dominguez, J., quotEfficient Probabilistic Fracture Mechanics Analysisquot, Numerical Methods in Fracture Mechanics: Proceedings of the Fourth International Conference, Luxmoore, A.R., Owen, D.R.J., Rajapakse, Y.P.S., and Kanninen, M.F., Eds., Pineridge Press, Swansea, U.K., 1987 Veers, P.S., Winterstein, S.R., Nelson, D.V., and Cornell, C.A., quotVariable-Amplitude Load Models for Fatigue Damage and Crack Growthquot, Development of Fatigue Loading Spectra, STP 1006, American Society for Testing and Materials, 1989 Sutharshana, S., et al., quotA Probabilistic Fracture Mechanics Approach for Structural Reliability Assessment of Space Flight Systemsquot, Advances in Fatigue Lifetime Predictive Techniques, STP 1122, American Society for Testing and Materials, 1991 Sutharshana, S., et al., quotComputational Methods for Probabilistic Flaw Propagation Analysesquot, Proceedings of the ASCE Structures Congress '91, April, 1991 Moore, N. R., et al., quotAn Improved Approach for Flight Readiness Certification - Probabilistic Models for Flaw Propagation and Turbine Blade Failurequot, JPL Publication 92-32, December, 1992. Matsuishi, M., and Endo, T., quotFatigue of Metals Subjected to Varying Stressquot, Presented to the Japan Society of Mechanical Engineers, Fukuoka, Japan, March, 1968. Fracture Control Requirements for Payloads Using the National Space Transportation System, NHB 8071.1A Fracture Control Requirements for Space Station, SSP 30558 Sigurdsson, G., et al., quotProbabilistic Methods for Durability and Damage Tolerance Analysisquot, presented at the 1992 USAF Aircraft Structural Integrity Program Conference (ASIP), San Antonio, Texas, December 1-3, 1992. quotFatigue Crack Growth Computer Program NASA\/FLAGRO Version 2.0quot, JSC-22267A (Draft), January, 1993. Reliability Preferred Practices Guideline GD-AP-2303: Spectral Fatigue Reliability","Lesson ID":700}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1208; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Leak-free joints can be achieved in cryogenic lines, joints, valves, and pumps for launch vehicles through the use of proven, state-of-the-art static cryogenic seals. These seals adapt to wide ranges of temperature and continue to seal when subjected to high pressures, in-flight static stresses, and in-flight dynamic loads. Implementation Method: 1. Introduction: Low or zero fluid or gas leakage in flight and ground-based cryogenic systems can be achieved through meticulous joint design and testing, selection of the proper seal configuration and materials, thorough cleaning and inspection of seal and flange surfaces, carefully controlled installation, and carefully controlled fastener tightening procedures. The most widely used and successful cryogenic seal for NASA space flight applications has been the deflection actuated, pressure assisted coated metal seal. High nickel content steel alloys coated with a thin layer of Teflon\u00ae or plated with gold, silver, indium, palladium, lead, copper, nickel, or aluminum have provided good sealing properties at elevated as well as cryogenic temperatures. This practice covers experience with pressure assisted and spring energized cryogenic seals in the SSME and ET. Experience was derived from earlier programs (Saturn I and Saturn V) to develop these effective seals. Although the subject of this practice is cryogenic seals, the pressure assisted and spring energized seals described are also effective over the broad temperature ranges from liquid hydrogen (-423 deg.F) to hot gas (1000\/1200 deg.F). 2. Nonspacer Type, Deflection Activated, Pressure Assisted Seals [D] The nonspacer type seal shown in Figure 1, fits into a groove in the flange. It can be used with a separate spacer to eliminate the need for a seal groove, but a retaining groove is preferred. As shown in Figure 1, these seals have two sealing surfaces that mate with adjoining flanges. Diameters range from 0.55quot to 16.75quot as used in the SSME. Cross sections of the seal ring vary from 0.200quot x 0.164quot to 0.150quot x 0.120quot in radial width and installed length, respectively, and the seals can be made in other diameters and other cross-sectional configurations. They are found throughout the SSME in both cryogenic and hot gas applications. The seals are machined from high nickel alloy steel and coated with either silver or silver with rhodium overcoat. The silver coated seals have a temperature range of -423 deg.F to +1000 deg.F, while the silver with rhodium can be used over a -423 deg.F to +1200 deg.F range. The seals are used in both fuel and oxidizer systems. In installing both the nonspacer type and the spacer type seals, the seals are compressed during joint assembly, which provides a load at the sealing circumference to effect sealing at low pressures. As the pressure increases, it acts on the internal surfaces of the seal, increasing the force on the seal tips to augment sealing capability as pressure increases. The seal coating presses into the flange surfaces, filling microscopic asperities and irregularities in the flange sealing surfaces. The combination of the installation deflection and the pressure on the internal surfaces permits the sealing faces to compensate for joint separation under system pressure and for shrinkage during exposure to cryogenic temperatures. 3. Spacer Type, Deflection Activated, Pressure Assisted Seals [D] This type of seal was originally used on the Saturn program and was later adapted for use on the Space Shuttle. The seal incorporates a flange, drilled to match the mating parts, which provides a positive stop to control seal compression and secondary pressure barriers on each side of the seal to facilitate leak checking. While some seals were originally silver plated, present use is confined to Teflon\u00ae coated high nickel alloy steel seals. The seals are used on the ET and on the piping connecting the Tank to the Orbiter. Most have rated temperatures of -423 deg.F to +350 deg.F except for one which has a -423 deg.F to +800 deg.F rating. A typical seal installation as it is used on the ET is shown on Figure 2. Notice that the seal has both a dual-sided primary seal located at the interior periphery of the seal and a dual-sided secondary pressure barrier just inside the bolt circle. A Teflon\u00ae coated seal is used in the LH2 and GH2 systems while a silver plated seal is used in the LO2 and GO2 systems. 4. The Raco\u00ae\/CreaveyTM Seal Configuration [D] Figure 3 shows the combination Raco\u00ae\/CreaveyTM seal as used for 17-inch diameter feed lines on the ET. The primary Raco\u00ae seal consists of a metal hoop-spring inside an energized Teflon\u00ae jacket. The secondary CreaveyTM seal is a metallic coil spring housed within an energized tubular Teflon\u00ae casing. 5. Recommended Practices a. Design Practices In general design practice, the development of a good leak-free joint design requires an integral look at the design of all the parts: seal(s), flanges, and fasteners. It also requires some foreknowledge of the degree of access required for leak checking, inspection, and potential disassembly and reassembly during downstream operations and particularly on the launch pad. Leak-free joint design is based on the seal maintaining contact between a surface on one flange and the mating surface on the other flange under all operating conditions. The fasteners take the dynamic loads and are installed in a preloaded condition to maintain seal contact with the flange surfaces. The seal in the joint must prevent leakage in excess of the allowable limit. The advantages of deflection actuated, pressure assisted seals are that they maintain a nearly constant fastener loading under pressurized and nonpressurized conditions and that they result in minimum flange deflection at the sealing surface. Sealing surfaces on flanges can be recessed to protect them from damage, and seal grooves can be configured for easy seal installation, centering of the seal, and for error-free assembly. The seal and joint can be designed with detents to prevent misaligned or reverse installation. The design of joint assembly and seal installation tooling, equipment, fixtures, and procedures should proceed concurrent with joint design. The designer must remember that a separable joint is used to permit later disassembly, inspection, and reinsertion of seals or refurbishment\/replacement of systems or components either in the manufacturing shop, on the test stand, or on the launch pad. The joint design and the assembly tooling or fixtures should provide: (1) protection to the seal and mating surface; (2) concentric and accurate seal positioning; and (3) even pressures around the periphery of the seal and joint during the fastener tightening process. Circumferential indexing that will ensure relocation of impressed seal surface deformities over corresponding flange deformities is desirable if the seal is to be reused. A good design practice is not to depend entirely on flange bolt locations to position seal components radially. A notch or groove should be provided to retain the seal. Gaskets, seals, parts, and subassemblies should be designed to preclude improper alignment or rotation. Using seals very close to the same size in the same area should be avoided. The design should be adaptable to using the same size seal (or a very different size) in all locations which are in close proximity. This practice will reduce the potential of installing the incorrect size seal. The following design suggestions pertain to seals for cryogenic and gaseous hydrogen and oxygen: Where feasible, secondary seals with a vent for direct measurement of leakage should be provided. The materials in cryogenic\/gaseous hydrogen seals should be resistant to hydrogen embrittlement. Walls should be provided in the seal groove to carry the seal hoop load when pressurized. Designs of liquid oxygen seals should include LO2 compatible materials. Designs of liquid hydrogen seals should include LH2 compatible materials. Potential flange ovality resulting from flange stresses or temperature cycling must be taken into account in establishing the width of flange sealing surfaces. The seal material(s) must be compatible with any anticipated purge or cleaning material that may contact the seal during its intended use. Purge or cleaning material restrictions should be noted on engineering drawings and in procedural documentation. A seal alignment provision should be incorporated in the design process. Design optimization in metal seals for cryogenics can be accomplished with currently available general purpose finite element analysis programs such as ANSYS (produced by Swanson Analysis Systems, Inc., see reference #13) or by specially programmed finite element models (reference #14). Modeling of seals can take into account surface texture, gas transmission flow methods, seal load distribution, material properties, and dynamic environmental conditions (temperature, pressure, vibration, shock, etc.). New seal designs should be evaluated using these analysis and modeling techniques and qualified before use. (see below). b. Qualification Practices Prior to incorporation into the production design, the entire joint system, which includes the flanges, seal(s), and fasteners, should be qualified for use in the specific environments expected to be encountered in operations. [As part of the qualification procedures for SSME seals, seals of 0.8quot, 1.1quot, and 3.8quot diameter were chilled to -250 deg.F and pressure cycled from ambient pressure to 8,970 psig for 240 cycles while demonstrating their ability to continue to meet leakage requirements. Seals were also subjected to structural verification at pressures up to twice operating pressures after completion of 240 pressure cycles, while still meeting leakage requirements.] If different temperatures, pressures, or gases are used for qualification and\/or leak checking, leak and nonleak conditions must be carefully calibrated and correlated with leak and nonleak conditions in the actual environments expected. These calibrations must be meticulously adhered to in interpreting leak test results. c. Manufacturing Practices Cleanliness and inspection at intermediate manufacturing steps are extremely important in the manufacture of deflection actuated pressure assisted seals as well as for other types of seals used in liquid oxygen and liquid hydrogen environments. Nonspacer type seals are usually silver plated with an initial gold undercoat. The gold undercoat prevents oxidation of the substrate at temperatures above 600 deg.F, when used in hot gas environments, and this prevents blistering of the silver plating. Silver is used for its low compressive yield strength and ductility required for effecting a seal, and for its corrosion resistance. Rhodium overplate is used to prevent bonding of the silver plate to the mating flange surfaces at high temperatures. A chromate coating is used to prevent discoloration of the seal or flange due to tarnishing of the seal's silver plating. Care must be taken to thoroughly clean and inspect each seal between the plating and coating operations. Adherence of the Teflon\u00ae primer coat and subsequent final coat to spacer type seals also requires stringent cleaning and inspection between each operation to prevent inclusions, voids, contamination, and surface defects. d. Inspection Practices Seal and flange mating surfaces should be visually inspected after manufacture and immediately before installation with a 10X magnification device. Very tiny scratches across the face of the seal's coated or plated sealing surface can cause leaks. [In one instance, a scratch .001quot wide and .0005quot deep extending across the radial length of the sealing surface was of sufficient size to cause a Class I leak.] The inspector should look carefully not only for nicks and scratches in seals, but also for metal or foreign particles on the seal or on the mating flange surfaces. NASA problem reports have indicated that, in at least one incidence, metal flange faces were allowed to contact each other and to rub together prior to seal installation, causing fine metal particles to be created which interfered with the seal's ability to seat properly against the flange sealing surface. Optical microscopy up to a power of 50X has been used to detect very small flaws and irregularities in flange and seal surfaces when leakage tests failed. Seal flatness or waviness can be confirmed or detected by the glass test in which the seal is placed against a plate glass sheet and observed from the underside. This method can be used to detect potential nonparallelism or small deviations in seal contact or coating thickness. Precision flat bars can be used with a light source to verify that flange faces are flat. e. Protection Practices Many of the leaks detected from joints of cryogenic and gaseous lines were possibly caused by scratching or nicking of the flange sealing surfaces or the seal, after initial manufacturing and inspection, but before assembly. Post manufacturing, in-transit, and preassembly protection of both the seals and the joint sealing surfaces have proven to be essential in ensuring leak-free or acceptable leakage rate joints. LO2-compatible protection caps or plugs should be used to protect sealing surfaces between manufacturing inspection and final assembly. Liquid oxygen compatibility is required of materials protecting oxidizer system joints because small particles of the protection material can rub off against the seal or flange surface and could lead to a fire or explosion. Cleanliness is more easily maintained with proper protection while the joint is in a disassembled condition. f. Preparation Practices As with in-transit or in-storage protection, thorough cleaning of the seals and flanges, accompanied by preinstallation inspection, is required to ensure leak tight joints. If the flanges are to be in storage for an extended period, they require a protective grease or jelly. If so, this material must be removed and the flange cleaned and reinspected prior to assembly, as this substance may have picked up fine particles during storage. If a protective substance has not been used, thorough visual inspection must take place to ensure that there are no evidences of corrosion. If corrosion exists, it must be removed and the flanges or seals reinspected both dimensionally and visually. g. Installation and Assembly Practices Several of the unacceptable leaks of joints carrying cryogenic fluids reported in NASA's Problem Reporting and Corrective Action (PRACA) system resulted from scratches to the seal or flange faces during the assembly process after preassembly inspection. These scratches may have been caused by the flanges rubbing together or the seal rubbing against corners or edges of the flanges. Several methods have been proposed or implemented to reduce the potential of seal or joint sealing surface damage during assembly. One method is to place Teflon\u00ae shims on both sides of the seal while it is being inserted into place between the flanges, and then to remove the shims once the seal is in place. Procedures have been developed which would not allow the flanges to touch the seal until the bolt torque pulls the flanges together. Special seal retaining or insertion tools and other assembly equipment can be designed to minimize the potential of damage during assembly. Operators must be thoroughly trained and certified in these procedures. To provide uniform compression of the seal and a final uniform load around the seal's circumference, fasteners should be tightened in stages in a prescribed alternating fashion, starting with fasteners located 180 degrees apart. h. Leak Checking Methods The most common method of seal and joint inspection after assembly is the leak test. Several leak detection procedures are used to check the integrity of LH2, GH2, LO2 and GO2 joints and seals: (1) bubble method; (2) gas analysis method; (3) pressure decay method; and (4) flow meter method. The most prominent method of leak testing is the bubble method. In the bubble test, a leak test solution is applied to the periphery of the joint while the interior is being pressurized with liquid helium gas or nitrogen in a manner that has been calibrated against the operational fluid's temperature, pressure, and flow rate to provide acceptable or nonacceptable leak rates. The bubble test method is confined to gaseous systems or cold gas simulations of cryogenic joint pressures and temperatures. Four classes of leakage have been defined. In general, they are: Class I: Steady formation of very small, long persisting bubbles. Class II: Mixture of random size bubbles of moderate persistence. Class III: Large, fast-forming bubbles. Blowing: Bubble formation does not take place because of large gas flow. Another common method of leak detection is the gas analysis method using a mass spectrometer. Although this method will determine that a leak exists, it is difficult to measure or to calculate the leak rate from mass spectrometer test results. Advanced methods of leak detection using palladium sensors, colorimetric methods, and nonintrusive sensors are being studied, but none has yet been as successful in both detecting the leak and indicating its magnitude as the leak test solution method. The solution test method is simple, easy to use, and readily observable with the naked eye. Two precautions are important, however: (1) complete coverage of the joint with the leak test solution; and (2) close observation of the complete periphery of the joint. The technician should observe the leak test solution immediately after application so that a blowing leak is not missed. The general practice is to releak test whenever a joint is disturbed. In the case of the SSME, all joints are leak tested both before and after final hot firing acceptance. A total engine leak test is conducted at final acceptance to determine the total leakage from all 154 joints (80 oxidizer system joints, 44 fuel system joints, and 30 hot gas joints), which must be less than six standard cubic inches per minute. In general, ambient temperature leak checks are not as accurate as testing in the chilled condition. Therefore, at least in initial development and checkout, the system must be cooled to its operating temperature, and realistic pressures and flow rates must be provided to identify potential leak conditions. The alternative is to use a different cryogenic or gas with prior accurate calibration of leakage results with the operational fluids, as mentioned earlier. i. Storage Practices Joints, flanges, or seals in storage must be protected against corrosion and against inadvertent damage of the seal or sealing surfaces. The protection device or substance must be compatible with the fluid for which the joint was designed and with which it will be operated. In-storage protection devices or substances must be completely removed and the parts must be recleaned and inspected prior to assembly. j. Refurbishment and Reuse Practices Seals can be refurbished by replating and reinspecting them to the original manufacturing standards. Seals that are reused without refurbishment should be indexed to provide reassembly in the same position as originally installed. Seals with damaged coating can be stripped and recoated or replated as long as the parent metal seal is dimensionally correct. Technical Rationale: These practices were derived from a review of Unsatisfactory Condition Reports (UCRs) of the PRACA system at Marshall Space Flight Center; from sources listed in the references including professional journal articles, presentations, books on cryogenics, and Government reports; and from over 30 years of experience in designing propulsion systems and stages incorporating cryogenic sealing requirements. References: Allen, P. and H. Becker, quotSealing for Long-Term Space Applicationquot, 3rd Annual AIAA\/GNOS Aerospace Technology Symposium, November 7-8, 1985. American Institute of Aeronautics & Astronautics. Brincka, D. R., quotHigh Pressure Static Seals for Aerospace Applicationsquot, 36th International Astronautical Congress: Stockholm, Sweden, October 7-12, 1985. IAF. Burr, M. E., quotDevelopment of Large Diameter High Pressure, Cryogenic Radial Static Sealsquot, Lubrication Engineering, (December, 1977), 638-643. quotCritical Items List (CIL) MC-ET-RA04b-Hquot, Volume II Propulsion\/Mechanical, Huntsville: NASA, MSFC, May 1, 1991. Daniels, C. M., quotAerospace Cryogenic Static Sealsquot, Lubrication Engineering, (April 1973), 157-167. Daniels, C. M., quotDevelopment of Flightweight Static Face Seals for 75.84 MPa (11,000 psi) Pressure and Cryogenic Temperaturesquot, Lubrication Engineering, (October 1978), 552-562. quotDucts\/Lines, Joints and Orificesquot, Volume XI. Failure Mode and Effect Analysis (RSS-8553-11) Critical Items List (RSS-8740-11): January, 1991. Rockwell International, Rocketdyne Division. quotFailure Modes and Effects Analysis (FMEA) MMC-ET-RA04a-Kquot, Volume II Propulsion\/Mechanical, Huntsville: NASA, MSFC, May 1, 1991. Hunter, Rick C. and Ready J. Johnson, quotGas Transmission Through a Plastically Deformed Metallic Interfacequot, Energy Sources Technology Conference and Exhibition: Houston, January 22-25, 1989. American Society of Mechanical Engineers. Russell, Dr. John M., quotOn the Selection of Materials for Cryogenic Seals and the Testing of Their Performancequot, 1989 NASA\/ASEE Summer Faculty Fellowship Program, August 18, 1989. John F. Kennedy Space Center and University of Central Florida. Schwinghamer, quotLeak Team's Final `Eureka' Anthem,quot Hydrogen Leak Investigation Team Final Report, (Presentation) Huntsville: NASA, MSFC, November 8, 1990. CreaveyTM is a registered trademark of the Creavey Seal Company. Raco\u00ae is a registered trademark of the Furon Company. Teflon\u00ae is a registered trademark of E.I. DuPont de Nemours & Co. Inc. Definitions cryogenics. Temperature region of liquified gases below 123 deg.K (-150 deg.C). ET. External tank. GH2. Gaseous hydrogen. GO2. Gaseous oxygen. high nickel alloy steel. A heat-treatable, nickel-base (53 percent) steel alloy with good properties at both cryogenic and elevated 922 deg.K (1200 deg.F) temperatures. leak. Defined in text. LH2. Liquid hydrogen. LO2. Liquid oxygen. scim. Standard (atmospheric) cubic inches per minute; volumetric flow rate. scratch, nick, or gouge. A damaged area in which material has been removed, or moved, with a resultant decrease in wall thickness. SSME. Space Shuttle Main Engine. static seal. A device used to prevent leakage of a fluid through a mechanical joint in which there is no relative motion of the mating surfaces other than that induced by changes in the operating environment.","Lesson ID":701}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1109; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Nickel-Hydrogen (Ni-H2) batteries will significantly deteriorate, principally due to capacity fading, if the proper storage and handling procedures are not followed in a number of stages in the cell\/battery lifetime. A set of proven guidelines is followed by flight projects in the preparation and utilization of project unique handling and storage procedures in order to minimize these deterioration effects and ensure the reliable performance of Ni-H2 batteries. Implementation Method: A sealed Ni-H2 secondary cell is a hybrid, combining battery and fuel-cell technologies. The nickel positive electrode comes from the nickel-cadmium cell and the negative platinum electrode from the hydrogen-oxygen fuel cell. The cell is contained in a pressure vessel designed to operate up to 1,200 p.s.i. of hydrogen gas when the cell is fully charged. Pressure measurements can be used to determine the \"state of charge\" of batteries in flight. Salient features of the Ni-H2 battery are a long cycle life that exceeds any other maintenance-free secondary battery system, high specific energy (gravimetic energy density), high power density (pulse or peak power capability), and a tolerance to overcharge and reversal. It is these features that make the Ni-H2 battery system the prime candidate for the energy storage subsystem in many aerospace applications, such as geosychronous-earth-orbit (GEO), commercial communications satellites, and low-earth-orbit (LEO) satellites. The GEO and the LEO applications have two different requirements for batteries. The LEO applications require charge\/discharge cycles of 18,000 to 30,000 cycles with depth of discharges (DOD) up to 40% and up to a 5 year lifetime in orbit. The GEO applications require lifetimes in orbit of 5 to 10 years and about 100 cycles per year with maximum DODs of 60% for a total of 500 to 1,000 cycles. To meet these mission requirements, a number of different design approaches are used by a variety of Ni-H2 battery manufacturers. Generally, two or more batteries are used per spacecraft to meet the power requirements. The major advantage of using multiple batteries is reliability. If one battery fails, the other battery or batteries can maintain all or at least the most significant functions of the spacecraft. The storage and handling of Ni-H2 cells and batteries can significantly alter performance during both prelaunch and mission lifetimes. The development of a low-voltage plateau in the discharge mode or capacity fading (loss of capacity to 1.0 volts) is the major concern. Under most circumstances, capacity can be recovered. However, if a cell or battery is overheated, it can be permanently damaged. The following storage and handling procedures cover the three stages in the cell\/battery lifetime: Stage 1 - Storage of cells after manufacture and before assembly into batteries: Storage periods can range from a few weeks to several years depending upon the launch schedule. The following three methods are used to store and maintain capacity of cells for periods of time from several weeks up to three years. Store fully charged cells open-circuited at temperatures below 0\u00b0C. These cells must be recharged, (topped off), every 7 to 14 days. Store fully charged cells at temperatures below 0\u00b0C with a trickle charge rate of C\/100. Store discharged cells open-circuited at 0\u00b0C for up to three years. Stage 2 - Storage of batteries after assembly: Once the flight batteries are assembled, they are generally stored until they are shipped to the launch site for integration into the spacecraft. For flight batteries, the storage period can range from a few months to three years. The longer periods represent program delays that affect launch schedules. The same methods for the storage of batteries can be used as defined above for cells. Regardless of the method of storage used, the capacity of batteries is measured both before and after storage to determine if any capacity fading has occurred during storage. Stage 3 - Storage of cells\/batteries during shipment: Cells\/batteries are fully discharged and short circuited during shipment. Each cell\/battery is wrapped separately with its own packaging material to exclude humidity and control temperatures to 5\u00b0C (+\/- 5\u00b0C). Five to 10 cells can be packed within the same container and shipped air express to minimize shipping time. The shipping container should be equipped with temperature recorders to provide assurance that flight cells\/batteries have not been exposed to temperatures exceeding 25\u00b0C. The capacity of cells\/batteries is measured both before and after shipment to determine if any capacity fading has occurred during shipping. Stage 4 - Storage of batteries at the launch site: Batteries should be in the fully discharged state during handling operations at the launch site. Batteries can then be maintained during short term storage in the charged state at room temperatures but must be recharged every 7 to 14 days. Also, flight batteries can be maintained on trickle charge prior to launch. The final reconditioning of flight batteries should be performed 14 days prior to spacecraft launch. Upon completion of the reconditioning, flight batteries should be kept on low rate trickle charge until launch or reconditioned every 30 days if the launch is delayed. The batteries should be kept in cold storage if the launch is delayed beyond 90 days. The following additional general guidelines and procedures are used in the handling and operation of Ni-H2 batteries. A battery should be \"reconditioned\" if it has been on open circuit, subjected to intermittent use, i.e., open circuit, trickle charge, occasional discharge, etc., for a cumulative period of 30 days. Reconditioning is effected by performing the following sequence at 20\u00b0C. Discharge at C\/2 constant current rate until the first cell reaches 1.0 v\/c. Drain each cell with a 1 ohm resistor until each cell's voltage is less than .03 V\/C. Recharge battery at C\/20 constant current rate for 40 hours (+\/- 4 hours). Repeat steps a and b. Charge battery at C\/10 constant current rate for 16 hours ( +\/- 4 hours). Repeat steps a, b, and e. Batteries are not charged or discharged in parallel. Isolation is provided in spacecraft power systems to ensure that a failure of one battery does not affect another battery. Batteries are charged and all functions and cells are checked out thoroughly prior to installation in a flight spacecraft. Batteries are installed into a spacecraft in a discharged state. \"Tap\"s are never installed on any portion of a string of cells in series that can cause unbalanced loading of portions of a battery. Shorting resistors are normally placed across individual cells to prevent cell reversal which could damage individual cells when flight Ni-H2 batteries are stored short circuited. Power system designs include circuitry to prevent overcharging of batteries and the generation of excessive heat which can damage batteries. The temperatures of Ni-H2 batteries are monitored during operation and storage. Operating temperatures are not permitted beyond 18\u00b0C and non-operating exposures are not permitted beyond 25\u00b0C. Exposure to temperatures beyond 30\u00b0C results in permanent loss of capacity. Heaters are used as required to insure that the temperature of Ni-H2 batteries do not go below -25\u00b0C at any time in order to prevent freezing of the electrolyte. Flight batteries should not be subjected to extended spacecraft integration and test activities. The open circuit and intermittent use of Ni-H2 batteries during extended spacecraft integration and testing activities are known to significantly accelerate the degradation of batteries. Results from controlled tests have shown permanent and irreversible changes. The design of flight batteries should include the following provisions for ground console interfacing with the batteries while integrated into the spacecraft. Signal lines for monitoring total battery voltage, charge and discharge currents, battery temperatures, and individual cell voltages. Capabilities to charge and discharge the battery from the ground test console. Capability to place a resister and a shorting plug across each individual cell. A log book shall be maintained on each flight battery including the complete test histories of each cell, of the assembled battery, and of all integration and test and launch site activities. Each log book shall identify the project and battery and individual cell serial numbers. Chronological (date and time) entries for all test sequences, summary of observations, identifications of related computer stored records, malfunctions, names of responsible test personnel, and references to test procedures controlling all tests shall be recorded. Since Ni-H2 batteries are perishable, their ability to satisfactorily complete their mission life is directly related to their storage, their ground use, and handling. Historical performance information is required to ensure their flight worthiness at launch time. Technical Rationale: Ni-H2 batteries can deteriorate due to improper storage and handling. This practice which avoids this deterioration is based on a long period of battery development, testing, and flight experience. References: NASA Handbook for Nickel-Hydrogen Batteries: NASA Reference Publication 1314, September 1993","Lesson ID":704}
{"Driving Event":"This Lesson Learned is based on Reliability Guideline number GD-AP-2305 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: The use of detailed structural analyses throughout the design\/development process of a mirror, either stand-alone or as part of a concurrent engineering structural-thermal-optical performance (STOP) analysis, will result in a minimum weight mirror design which is able to meet all of its performance criteria and enhance the reliability of the overall optical system. Implementation Method: A detailed structural analysis of an optical mirror and its mounting performed throughout the design\/development cycle is crucial to developing a design which will meet all mirror requirements. The first step in being able to predict reliable mirror performance characteristics is in the development of an accurate detailed finite element model (FEM). This involves not only developing a model using good modeling techniques, but also ensuring mathematical validity of the model. Next, the required analyses must be identified. Besides having to meet optical requirements under effects such as deformations due to thermal profiles and 1-G release, the design will have to exhibit adequate strength capability due to loads from launch and possibly thermal induced growth. Also, desired design features such as coating thicknesses can be derived from early analyses. Because of the extremely small deformations involved in mirror distortion analyses, the validity of the use of finite element models has been suspect. As long as the disturbance sources (typically temperatures) are large enough to develop forces large enough to be out of the numerical noise of the computer, the resulting results should be linear and valid from a numerical standpoint. Finite Element Modeling Techniques [D] Because extremely small deformations can significantly degrade mirror performance (on the order of micro-inches), the use of good modeling techniques is essential. A typical lightweight mirror design is based on a rib-stiffened facesheet. This structure may be either closed on the back with a back facesheet or left open. In either case, plate elements are typically used for the facesheet and ribs, and the back close-out if appropriate. An example of an open back lightweight mirror is shown in Figure 1. A minimum of three nodes of resolution through the thickness of the structure is often desired. This level of detail will allow a 2nd order variation in temperature through the thickness of the mirror to be applied in subsequent analyses. The minimum facesheet nodal resolution may be dictated by the rib mesh necessary to maintain good aspect ratios in the rib elements. Beyond this level of detail, it is many times of interest to include at least one grid on the facesheet interior to a given cell (i.e., not a part of any rib structure). This will allow the facesheet deformations typical of quilting to be portrayed. Plated facesheets are commonly represented as composites using composite property behavior. In addition, the supporting rib structure may also be represented as a composite material if it is also plated. By doing this, deformations due to the coefficient of thermal expansion (CTE) difference between the base material and the plating when undergoing bulk temperature changes will be able to be portrayed (many times a very significant factor). Because of the relatively large uncertainty in the disturbance sources and the material property characteristics relative to the deformation magnitudes being calculated, many times it is more desirable to do the analyses on a parametric basis where sensitivities of the deformations to various parameters may be more significant than the absolute answers themselves. By identifying the most sensitive parameters, mirror design trades can be made on a relative basis for a given environmental condition. Also, an already selected mirror design may either be modified, or the fabrication process closely monitored to minimize the effect of these parameters instead of having to rely on the absolute correctness of the optical degradation. For example if the interface flatness of a mirror is found to be an unusually critical design factor, this finding alone may be enough to cause the design details to be modified or to trade off different mirror designs in an attempt to minimize this effect. Finite Element Model Validation Again, because of the typically small deformations of interest in mirror distortion analyses, the importance of performing a complete mathematical validity check of the FEM cannot be overemphasized. To ensure proper mathematical FEM behavior, following are some of the model checks which should be performed: Line-by-line check of input data decks to ensure input accuracy. Static run with fixed boundary conditions and 1-G loads applied separately in each axis, reviewing resultant displacements, forces, and stresses for reasonableness, symmetry, etc. Free-free modal run to calculate rigid body modes. These modes should be two orders of magnitude less than the first flexible mode, generally less than .001 Hz to ensure that there is no inadvertent grounding of the structure. Equilibrium checks of the model which are calculated by multiplying the free-free stiffness matrix by the geometrically derived rigid body modes. Nodes at which the structure is grounded should be displayed in a tabular form. A thermal equilibrium check in which a bulk temperature change is imposed on a kinematically constrained model which has all thermal expansion coefficients set equal to a common value. Negligible element forces should be generated with the model exhibiting free expansion with relative deformation values between points equal to CTE x L x DT where CTE is the coefficient of thermal expansion of the mirror material, L is the distance between the points, and DT is the temperature difference from reference being imposed. RMS and peak-to-valley mirror surface deformations calculated should be equal to theoretical values. The difference being the quotnoisequot level inherent in all subsequent analyses (analysis predictions can only be made to levels approaching this level). A bulk temperature check with all CTE values set to their correct values. The resulting structure should deform in a predictable way (i.e., concave or convex) depending on material mismatches and platings present. Inspection of all FEM software messages and warnings which might indicate among other things, improperly shaped elements, ill-conditioning, mechanisms, etc. Comments relative to automatically imposed constraints in particular must be verified to be appropriate. Mass properties should be compared to approximate hand calculations during the early stages of design and to the actual value if the mirror has been fabricated. Correlation with actual mirror fundamental mode shapes and frequencies if data exists. A duplicate analysis run should be made with the input disturbance (typically temperatures) doubled. Results should also double indicating that the actual solution is not operating in the numerical noise of the computer. Data Reduction and Reporting Optical distortions are typically reported as a wavefront error in units of waves where one wave is equal to the shortest wavelength of interest. The performance of an optical system is frequently given in terms of cumulative RMS wavefront error at the focal plane. Errors in the wavefront are twice the mirror surface deformations. Typically these values are specified in both RMS and peak-to-valley relationships. Initial structural analyses may only report the mechanical distortions of the mirror surface in these terms for a quick assessment of optical performance. Later analyses, however, should not only report these mechanical deformations, but should be evaluated in terms of the Zernike coefficients. These coefficients are typically calculated as part of an optical analysis and provide a mathematical means of describing the mirror surface. When analyzing an existing mirror design for distortion, it may be desired to include the effect of the actual mirror surface figure errors as polished. Because these surface figure errors are small and will not alter the mechanical behavior of the mirror FEM if included in the undeformed geometry data, their effect should be added to the deformations resulting from a structural distortion analysis. Initial Design Activity During the initial phase of a lightweight mirror design, the first design parameters that must be specified are the rib thicknesses, rib spacing, and facesheet thickness. The minimum facesheet thickness required for a given rib spacing (described by the diameter of an inscribed circle in a single cell pocket) is determined by deciding on an acceptable level of optical distortion at ambient conditions due to quilting \u2014 the phenomenon whereby the facesheet material is pushed away from the polishing tool as opposed to being polished away. As a result, once the tool passes a given cell, the center of the facesheet in that cell will tend to spring back close to its original position. Because of the higher stiffness of the facesheet along the ribs, this motion does not occur and relatively larger amount of facesheet material is removed along the ribs. As a result, when finished, the facesheet is higher at the center of each cell pocket as opposed to along the rib paths and the mirror surface appears to be quotquiltedquot when tested optically. Once an acceptable level of quilting is determined (many times as low as 1\/80th of a wave), the facesheet thickness is fixed for a given rib spacing and assumed mechanical polishing pressure. It should be noted that for certain optical figuring techniques, e.g. ion beam figuring, there is no mechanical pressure applied to the mirror surface and therefor no resulting quilting. During this initial design phase, mirror optical performance is typically tracked primarily mechanically in terms of RMS and peak-to-valley deformations of the mirror surface. Because thermal conditions are not typically known to a detailed level, optical degradation is calculated for general thermal conditions such as uniform bulk temperature changes, linear gradients in each axis, and a radial gradient from the center of the mirror to its edges. These initial studies are not only necessary for preliminary optical performance assessment, but give an early insight into sensitivities to certain thermal conditions which can possibly impact the thermal design. Also, simultaneously during this phase, various means of supporting the mirror are investigated. At this time preferred support points and methods are selected based not only on thermal growth requirements, but on stress requirements due to launch loads. Detailed Design Activity The anticipated thermal environment has been defined prior to detailed design and can be incorporated into the structural model for on-orbit thermal distortion optical degradation calculations. Depending on the thermal model employed and where temperature data is calculated, different methods of mapping these temperatures onto the structural model are employed. [D] [D] A common method is to rely on a thermal model developed similar to the structural model, ie. thermal nodes corresponding to individual rib elements and the facesheet. Temperatures at thermal nodes then will have a physical point on the structural model at which this temperature can be specified. By doing this for all thermal node points, which is typically a much smaller set of points than the structural grids, a thermal analysis is performed on the structural model to determine temperatures at all remaining structural grid points. A potential problem exists with this technique, however, due to the fact that unspecified structural temperatures are interpolated from surrounding temperatures in an iterative fashion until thermal equilibrium is achieved (relaxation technique). Figures 2 and 3 illustrate this potential problem by showing vastly different thermal equilibrium temperature distributions resulting from attempting to specify a 1. to 10. degree linear gradient in a plate two different ways. Figure 2 shows the resulting equilibrium temperature distribution when the temperatures are specified only at the four corners. Figure 3 shows the temperature distribution when the same gradient is applied by specifying a fixed temperature along both edges of constant temperature. The structural distortions which would result from the imposition of these two thermal environments would be vastly different. Therefore it is advised that the structural analyst work closely with the thermal analyst to determine if additional temperature constraints need to be imposed upon the set of discrete temperatures specified at distinct thermal nodes obtained from the thermal analysis. Another technique used to map thermal analysis temperature results onto a structural model is based on developing a thermal model consisting of homogeneous bricks for the rib structure with the thermal behavior of these bricks modified to account for discreet rib behavior. Temperatures at individual structural grids can then be calculated by a using a simple three dimensional interpolation of the surrounding thermal nodes. A third technique which eliminates all thermal mapping errors is for the thermal structural analysts to use the same model. A potential problem with this method, however, is the long computation time necessary for full orbital temperature calculations. Mechanical surface deformations at this time are then input to an optical analysis for an assessment of the optical quality of the surface. These deformations can be directly input into certain optical analysis software packages (CODE-V for example) or by calculating Zernike polynomials for the deformed surface which can then be used for further optical analysis. Technical Rationale: The use of finite element analyses to predict structural deformations due to loads (both mechanical and thermal) is a widely understood and used practice that is readily available. With a relatively minor effort, the major sources of distortion in a mirror can be identified and minimized. References: Valenta, Tina M. and Vukobratovich Daniel, quotA Comparison of the Merits of Open-Back, Symmetric Sandwich, and Contoured Back Mirrors as Light-Weighted Optics,quot SPIE - the International Society for Optical Engineering, Vol. 1167, 1989. Yoder, Paul R., quotOpto-Mechanical Systems Design,quot Marcel Dekker, Inc., New York, 1986. Mehta, Pravin K., quotFlexural Rigidity Characteristics of Lightweighted Mirrors,quot SPIE - the International Society for Optical Engineering, Vol. 748, 1987. Cho, Myung K., Richard, Ralph M., and Hileman, Edward A., quotA Comparison of Performance of Lightweight Mirrors,quot SPIE - the International Society for Optical Engineering, Vol. 1340, 1990. Pepi, John W., quotAnalytical Predictions for Lightweight Optics in a Gravitational and Thermal Environment,quot SPIE - the International Society for Optical Engineering, Vol 748, 1987.","Lesson ID":699}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1204; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Reliability is greatly increased because the failure rate is directly related to the long-term flight temperature. Implementation Method: Establish in-specification design (and test) temperatures >75\u00b0C and limit part junction temperatures (JT) to <110\u00b0C which constrains permissible part junction temperature rise (DJT) to <35\u00b0C. (This practice has been verified on programs in place before the release of MIL-STD-975H. If the MIL-STD-975H junction temperature of 100\u00b0C is used, junction temperature rise should be changed to assure that long-term flight junctions stay below 60\u00b0C.) Technical Rationale: Basic reliability is directly related to temperature and time, i.e., l = f(T,t). The following relationship is obtained either theoretically from the Arrhenius relationship (l= Aexp[-Ea\/k (1\/T - 1\/T0)]) or empirically from the data in MIL-HDBK-217E. [D] Given: Specific part Specific derating factor Specific chemical activation energy The curve shape is representative of all electronic parts (and most mechanical processes) in the range of temperature typified by space exposure. Simply stated, the higher the long-term flight temperatures, the lower the reliability: [D] Assume that a design and test temperature of 75\u00b0C is chosen. In the graph from MIL-STD-883B observe that a 25\u00b0C D T corresponds to a failure rate increase of more than an order of magnitude-- i.e., >1000% difference. MIL-HDBK-217E has different values, but the factor is up to approximately 3X on some parts (depends on derating criteria and parts qualification). The following example illustrates the effect of this relationship on design and test temperatures. Assume the following conditions as an example: Case A: T = 75\u00b0C in-specification design temperature for baseplate Case B: T = 50\u00b0C in-specification design temperature for baseplate Case A and Case B: T = 25\u00b0C long-duration flight temperature for baseplate J T = 110\u00b0C limit for any exposure or analysis Then: Design\/Test Parameters Case A Case B Design Baseplate 75\u00b0C 50\u00b0C JT limit 110\u00b0C 110\u00b0C Permitted DJT rise 35\u00b0C 60\u00b0C Flight Conditions [D] from Arrhenius [D] NOTE: In the example given, short-term ground test exposure on the order of 1-2 weeks will use an insignificant amount of life in hardware designed for long-life and high reliability. For example, a 1-week thermal vacuum test at 75\u00b0C provides a short-term high temperature screen in the actual circuit usage configuration to provide confidence for a long-term exposure under flight conditions (JT<60\u00b0C), and uses only 0.018% of the parts capability. This demonstration is an important element in establishing pre-launch confidence in design adequacy. [D] (Click image for a larger view) References: Gibbel, M. and Clawson, J.F., quotElectronic Assembly Thermal Testing Dwell\/Duration\/Cycling,quot Proceeding of the 12th Aerospace Testing Seminar, March 13-15, 1990. Gibbel, M. And Cornford, S.L., quotSurface Mount Technology Qualification Methodology (Testing and Verification),quot Proceeding of the NASA Surface Mount Technology Workshop, NASA Lyndon B. Johnson Space Center, Houston, Texas, July 28-29, 1992. Thermal Design Practices for Electronic Assemblies, Reliability Preferred Practice No. PD-ED-1226","Lesson ID":703}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1209; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Heat pipes use the latent heat of vaporization of a working fluid to transfer heat efficiently at a nearly constant temperature. This characteristic can be used to control the temperature of spacecraft components and systems. The Goddard Space Flight Center (GSFC) has chosen ammonia-charged aluminum heat pipes for most near-room temperature (200\u00b0K to 350\u00b0K) applications. The axial groove aluminum pipe is the design of choice, because it is easy to design and relatively easy to fabricate. The aluminum container and axial grooves are extruded in one process. At the operating temperature of unmanned spacecraft, ammonia has the most favorable thermodynamic properties that make it an excellent heat pipe working fluid. Anhydrous ammonia is compatible with the aluminum heat pipe body and wick if proper care is taken in the manufacturing process. Implementation Method: All heat pipes have three physical elements in common. These include an outer container, a small amount of working fluid, and a capillary wick structure. In addition to these basic components, heat pipes may also include gas reservoirs (variable conductance\/diode heat pipes) and liquid or gas traps (diodes). Functionally, the heat pipe consists of three sections: evaporator, condenser section, and adiabatic regions. The evaporator section is mounted to the heat-producing components, while the condenser is thermally coupled to a heat sink or radiator. The adiabatic section allows heat to be transferred from the evaporator to the condenser with very small heat losses and temperature drops. Figure 1 depicts the basic heat pipe. [D] Heat pipes can operate in the fixed conductance, variable conductance, or diode mode. The fixed conductance heat pipe can transfer heat in either direction and operates over broad temperature ranges, but has no inherent temperature control capability. Constant conduction heat pipes allow isothermalization of shelves, radiators and structures; spread heat from high heat dissipating components; and conduct heat away from heat producing devices embedded within instruments and satellites. In the variable conductance heat pipe (VCHP), a small quantity of non-condensable gas (NCG) is loaded into the heat pipe. The VCHP can be used to control the temperature of equipment within very narrow limits; control is possible to less than 1\u00b0K by using careful design techniques. This is accomplished by controlling the location of the NCG\/vapor interface within the condenser end of the heat pipe, thereby varying the active length of the condenser and causing a modulation in the condenser heat rejection capability. Temperature control of the attached device is achieved by an active feedback system consisting of a temperature sensor at the heat source and a controller for a heater at the NCG reservoir. The heater causes the gas in the reservoir to expand, thus moving the gas\/vapor interface. Diode heat pipes permit heat to flow in one direction and inhibit heat flow in the opposite direction. Specific benefits of heat pipes are: 1) heat pipes have enormously more heat transfer capability than other methods on a weight and size basis, 2) heat pipes permit configuration flexibility in contact areas with heat sources and heat sinks, 3) heat can be transported over considerable distances with insignificant temperature drop, 4) capillary pumping in the wick is generated by the heat transfer process and requires no other power or moving parts to pump the condensate, and 5) heat pipes operate satisfactorily in a zero gravity environment. The choice of working fluid is dictated by several considerations, including operating temperature, latent heat of vaporization, liquid viscosity, toxicity, chemical compatibility with container material, wicking system design, and performance requirements. Figures 2 and 3 and Table 1 depict some of the above characteristics for several fluids. The highest performance from a heat pipe is obtained by utilizing a working fluid that has a high surface tension (s), a high latent heat (l), and a low liquid viscosity (n1). These fluid properties are contained in the parameter N1 the Liquid Transport Factor. Figure 4 is a plot of N1 for five typical heat pipe working fluids. These data are used as selection criteria for heat pipe working fluids. Once an application is defined, the heat pipe designer reviews the requirements and selects the best working fluid. Below the freezing point of water and above about 200\u00b0K, ammonia is an excellent working fluid. Regardless of the fluid chosen, minimum purity must be at least 99.999 percent. A careful analysis of the purity of the ammonia should be obtained from an independent laboratory prior to use. [D] [D] [D] Table 1: Comparison of Latent Heat to Specific Heat for Typical Heat Pipe Fluids FLUID PROPERTIES FLUID BOILING POINT &$176;K LATENT HEAT kJ\/kg hfg SPECIFIC HEAT kJ\/kg-\u00b0K cp RATIO K hfg\/cp Helium 4 23 4.60 5 Hydrogen 20 446 9.79 46 Neon 27 87 1.84 47 Oxygen 90 213 1.90 112 Nitrogen 77 198 2.04 97 Argon 87 162 1.14 142 Propane 231 425 2.20 193 Ethane 184 488 2.51 194 Methane 111 509 3.45 147 Toluene 384 363 1.72 211 Acetone 329 518 2.15 241 Heptane 372 318 2.24 142 Ammonia 240 1180 4.80 246 Mercury 630 295 0.14 2107 Water 373 2260 4.18 541 Benzene 353 390 1.73 225 Cesium 943 49 0.24 204 Potassium 1032 1920 0.81 2370 Sodium 1152 3600 1.38 2608 Lithium 1615 19330 4.27 4526 Silver 2450 2350 0.28 8393 [D] The outer container usually consists of a metal tube to provide mechanical support and pressure containment. The chosen design and processing of the container are extremely important in selecting the metal, because they can affect the useful life of the heat pipe. In addition, a compatibility must exist between the pipe material and the working fluid. For heat pipes, working fluid\/container compatibility issues encompass any chemical reactions or diffusion processes occurring between the fluid and wall\/wick materials that can lead to gas formation and\/or corrosion. Table 2 lists the compatibilities of several metals and working fluids. Along with the metal\/fluid compatibility, other considerations in the metal selection are ease of working the material, extrusion capability of the material, and its weldability. Proper container cleaning and heat pipe processing procedures are of extreme importance, since residual contamination within the heat pipe may also lead to gas generation. Steps must also be taken to ensure the purity of the fluid charge; trace amounts of water in ammonia can lead to a reaction with the aluminum container and the formation of hydrogen gas. Chi [reference 1] and B & K Engineering [reference 2] list standard cleaning and filling methods for a variety of working fluid\/wall material combinations. Special consideration must be given to the processing of heat pipes to be used at temperatures below 250\u00b0K. As the temperature drops, the vapor pressure of the fluid falls off. This allows any non-condensable gas created by contamination to expand, thus creating an even larger problem. The heat pipe wick structure provides a porous medium for the formation of liquid menisci (which cause the capillary pumping action) and a vehicle for returning the working fluid from the condenser to the evaporator. To accomplish these wick functions effectively, the designer must provide pores, cavities, or channels of the right size, shape, quantity and location. An optimization technique is used in wick design to find the desired combination of ultimate heat transfer capacity, pumping capability, and temperature drop. The designer must also consider ease of wick fabrication, compatibility with the working fluid, wetting angle and permeability of the selected wick material. Figure 5 depicts a cross-sectional view of an axial groove wick; this design probably is the most commonly used for space application. [D] In addition, X-ray certification of all welds at the end caps and fill tube is required to ensure good weld penetration and the absence of voids. The heat pipe container must be pressure tested to at least twice its maximum expected operating pressures (MEOP) prior to filling [reference 3]. Other qualification procedures include performance tests at adverse tilt angles to demonstrate proper wick function, and gas pocket tests performed with the heat pipe in the reflux mode. Heat pipes should be handled with care, especially those that contain ammonia or other high vapor pressure fluids. They should be treated as any other pressure vessel, and appropriate safety precautions must be exercised. Exposure to ammonia vapor can cause severe irritation to eyes and other mucous membranes. Exposure to ammonia liquid can cause severe burns to the skin. Whenever possible, heat pipes should be stored in a cold, dry environment. This will inhibit any internal chemical reactions which produce non-condensable gas. Technical Rationale: Spacecraft applications to date have been for heat pipes operating between 200\u00b0K and 350\u00b0K. Consequently, a working fluid whose freezing and boiling points encompass this temperature range and has a high latent heat, a low viscosity, and high heat transport capability must be selected. GSFC has selected ammonia as an appropriate working fluid whose fluid properties meet these criteria. However, for safety reasons, the toxicity of ammonia precludes its use in manned environments such as the shuttle cabin [reference 4]. GSFC has selected aluminum alloys, such as 6061 and 6063, for the container material of the heat pipe because of their long-term compatibility with ammonia (see Table 2); heritage; ability to have an extruded axial groove wick structure; ease of fabrication, shaping, and configuring; good thermal compatibility with aluminum radiators and heat sinks; and weldability characteristics. References: Chi, S. W., quotHeat Pipe Theory and Practice,quot Hemisphere Publishing Corp., New York, 1976 Brennan, P. J., and Kroliczek, E. J., quotHeat Pipe Design Handbook,quot B & K Engineering, Inc., Towson, Maryland, 1979 MIL-STD-1522A (USAF), quotMilitary Standard General Requirements for Safe Design and Operation of Pressurized Missile and Space Systems,quot May, 1984 NSTS-1700.7B, quotSafety Policy and Requirements for Payloads Using the Space Transportation Systemquot, January, 1989","Lesson ID":698}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1207; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Provides for a magnetically clean spacecraft, which increases the quality and accuracy of interplanetary and planetary magnetic field data gathered during the mission. Implementation Method: Because the dipolar portion of a spacecraft's magnetic field at its magnetometer experiment sensor location dominates the nondipolar part, each spacecraft subsystem is assigned a maximum allowable dipole magnetic field specification based on the magnetometer sensor sensitivity and the distance between the bulk of the subsystems and the sensor location. A typical maximum dipolar field allocation is 10 nanoTeslas (gammas) at a distance of 1 meter from the geometric center of a spacecraft's subsystem, assuming the magnetometer sensor is mounted at the end of an 8-meter boom. To ensure that each subsystem will meet its respective dipole field specification, several design practices are observed during the early stages of the subsystem design. These practices include: Magnetic Shielding of Magnetic Components A magnetic source can be enclosed in a high permeability material shield, which in effect confines the source's magnetic flux to within the walls of the shield enclosure. The shield should be completely enveloping, with the minimum number of holes and cutouts. The shield must be annealed after all machining and forming operations are completed. A general rule of thumb is to design the shield to operate within the linear range of the permeability curve between points A and B. [D] Compensation of Magnetic Components A magnetic component can be neutralized by placing on or near its surface an equal but opposite field vector using compensation magnets or current loops. [D] Redesign of Circuit Board Current Paths to Reduce Loop Area Coverage Because a magnetic field B is proportional to loop area geometry A, number of loop turns N, and current flow I through a circuit, a reduction in A produces a reduction in the magnetic field B, while still leaving I and N intact. [D] Replacement of Ferromagnetic Parts with Nonmagnetic Parts Another method for reducing magnetic fields is by simply replacing ferrous materials with nonmagnetic materials, preferably with relative permeability mr of approximately 1 so that the magnetic susceptibility cm is kept at approximately 0. [D] where m = momr, mr = 1 + cm, and mo is the permeability of vacuum. All spacecraft subsystems are individually subjected to a testing program aimed at fully characterizing each of the subsystems' magnetic traits, as well as determining compliance with dipole field specifications. This testing program includes several exposures to magnetizing fields of 25 Gauss and 3 Gauss to uncover easily permeable materials contained within the subsystem, and several exposures to demagnetizing fields of 50 Gauss and 40 Gauss to eliminate or reduce a subsystem's residual magnetic field. Based on the above test program, a data base is established containing subsystem information such as the X, Y, and Z spacecraft coordinates, maximum and minimum measured static magnetic fields, measured dynamic fields, and the calculated dipole moment components. From this data base, the total spacecraft static and dynamic dipole fields at the magnetometer sensor location are calculated using computer code, and are continually updated as new information becomes available. Results then are compared with the spacecraft's static and dynamic magnetic field science requirements. Technical Rationale: A spacecraft's total allowable magnetic field at the magnetometer sensor location r usually is determined by the sensor's sensitivity level or by an agreed upon science requirement. The total field can be approximated by N number of dipoles, with N representing all of the spacecraft subsystems. To guarantee that the spacecraft's total magnetic field at r is within the desired allowable range, the individual moments due to N number of dipole sources must be kept to within predetermined dipole moment specifications. These individual specifications are derived by distributing the total allowable spacecraft moment amongst N number of spacecraft sources using a model that consists of a number of randomly oriented dipoles of strength Mj. The magnitude of the spacecraft's dipole magnetic moment is approximated by the Pythagorean sum of these individual subsystem dipole moments, with the radial part tending to be greater than either of the transverse components for the dipole portion. The individual magnetic dipole field allocation, therefore, is determined from this model by the following equations: [D] where B R,B Q, and B F are the field components of the spacecraft's magnetometer experiment sensor sensitivity or the science requirement levels at location r. Thus, M j can be determined for all spacecraft N sources assuming that M j is the same for all j and the magnetic moments determining the far field are linear functions of the vectors M j. Because the dipolar portion of the spacecraft magnetic field dominates the nondipolar part and the spacecraft is dominated by the few largest sources, the general field allocation B s for a subsystem at a normalized distance of R meters is thus derived from M j as follows: [D] By ensuring that the dipole moment specifications of all spacecraft subsystems, as represented by N number of dipolar sources, are within their respective allocated dipole moment specifications, the overall spacecraft magnetic field at the magnetometer sensor location can be kept to within its science requirement or to below the magnetometer's sensitivity level. Final verification is done by measuring the magnetic fields of all spacecraft subsystems and, subsequently, calculating the magnitude and orientation of their respective dipole moment components Mxj, Myj, and Mzj at spacecraft coordinates Xj,Yj, and Zj. The total spacecraft magnetic field at the magnetometer sensor location r then can be modeled using computer code to verify compliance with the specified science requirement or magnetometer experiment sensitivity.","Lesson ID":702}
{"Driving Event":"This Lesson Learned is based on Reliability Practice Number PD-ED-1232 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: The Spacecraft Orbital Anomaly Report (SOAR) System provides a single uniform, effective, and efficient computer data base for in-orbit reliability studies to identify performance trends for use in design reviews, flight readiness reviews, and in the evaluation of test, reliability, and quality assurance policies. Implementation Method: Anomaly Reporting - Immediately after the occurrence of an anomaly, the orbiting spacecraft's control center initiates the procedure shown on the SOAR Flow Diagram, Figure 1, by notifying the cognizant Project Operations Director (POD) or other cognizant NASA\/government representative. The originator then enters all known information onto a SOAR reporting form (GSFC Form 4-29), Figure 2 and sends it to the POD. The POD assigns a person to be responsible for determining the cause of the anomaly, corrective actions to be taken, etc. The responsible person conducts an anomaly investigation and analysis with the help, as required, of control center personnel, the system or instrument representative, the system integration contractor, the subsystem fabricator, and the Flight Assurance Manager (FAM) or the SOAR System Manager. The cause of the anomaly is determined, if possible, and corrective action is proposed, agreed to and approved by project and Center management, as appropriate. This information is entered onto the SOAR form by the responsible person. The FAM or SOAR System Manager assures that the agreed-to corrective action indicated on the SOAR form takes place. When all the SOAR corrective actions have been completed, the FAM or SOAR System Manager is responsible for entering the information onto the SOAR reporting form and closing out the SOAR. The completed SOAR form is distributed to the appropriate project, Flight Assurance, and other interested personnel by the SOAR System Manager. The SOAR System Manager enters information from the SOAR report into the SOAR computer data base and distributes a printout. [D] [D] Yearly Summary Reports - These reports present a summary of the in-orbit reliability and performance of active spacecraft built under the management of the Goddard Space Flight Center and collectively form a continuous, published record of this performance. These reports provide a variety of statistical summaries including the total number of anomalies, the number of spacecraft over which the anomalies were distributed and a comparison with the anomalies of the previous year. A brief discussion is included of the condition and performance of each active spacecraft. The yearly SOAR reports contain a complete list of all anomalies that occurred during the year, each with the subsystem identified that caused each anomaly, the criticality, effect, and a description of the anomaly, and any corrective action that was taken. In addition, graphics show the distribution of anomalies among spacecraft and subsystems and comparisons of levels of criticality, effects, failure categories, and types of anomalies. Anomalies are classified and described in these summaries, lists, graphics, etc. as shown below. These classification categories are defined on the SOAR Form along with instructions for their use. Subsystems - The spacecraft is divided into the following nine subsystems: Attitude Control & Stabilization Power Propulsion Structure Telemetry & Data Handling Thermal Timing, Control & Command Instrument (Payload) Other Mission Effect (Criticality) - The following schedule describes the impact of the anomaly on the mission: Negligible Non-negligible but Small (minor) 1\/3 - 2\/3 Mission Loss (Substantial) 2\/3 to Nearly Total Loss (Major) Essentially Total Loss (Catastrophic) 0 - 5% loss 5 - 33% 33 - 66% 66 - 95% 95 - 100% Anomaly Effect - Spacecraft Failed Subsystem\/Instrument Failed Component Failed Assembly Failed Part Failed Subsystem\/Instrument Degraded Indeterminate Loss of Redundancy None Failure Category - Design Problem Workmanship Problem Part Problem Environmental Problem Other (w\/explanation) Unknown Type of Anomaly - Systematic (would occur if identical equipment were operated under identical circumstances) Random Wearout (a special case of systematic) Indeterminate Intermittent An appendix of the yearly SOAR report also presents a table of spacecraft lifetime data. Table 1. is a sample sheet of spacecraft lifetime data from a yearly SOAR report. [D] Technical Rationale: The SOAR System provides a positive feedback system for reporting, documenting, collecting, analyzing, and closing orbital anomaly information. The timely recognition and analysis of anomalies can lead to corrective measures that can restore performance and, in some cases, protect the safety of the spacecraft and its payload instruments. The yearly SOAR reports provide GSFC management, spacecraft projects and designers, as well as flight assurance personnel with both short term and long term in-orbit performance and reliability trends which can indicate areas where design improvements should be made on follow-on spacecraft programs. They also can be used to evaluate the effectiveness of the prelaunch integration and environmental test programs. References: Procedure for the Spacecraft Orbital Anomaly Report (SOAR) System GSFC Report No. 303-PROC-013 (Rev C) Individual Yearly Reports --- Orbital Anomalies In Goddard Spacecraft","Lesson ID":691}
{"Driving Event":"This Lesson Learned is based on Reliability Guideline Number GD-ED-2211 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: The primary benefit is increased mission reliability due to a reduction in design errors occurring during spacecraft development caused by inconsistent coordinate frame definitions. A document will be created early in the development of a spacecraft mission defining Attitude Control System (ACS) coordinate frames which will facilitate data transfer among subsystem engineers, speed documentation and communication during design and analysis reviews, expedite verification of instrument and sensor pointing, and assure that a record of the coordinate frames used will be available throughout mission planning, design, analysis, and flight. Implementation Method: Early in the development stages of a mission program, a document should be created, published, and distributed to all ACS and ACS related mission engineers. This document will list coordinate frame definitions needed for ACS design and analysis. It should also be periodically updated as mission objectives evolve and hardware changes are made. The following discusses ACS coordinate frame definitions and the format for listing them in the ACS Coordinate Frames Definition Document. 1. Overview of Coordinate Frame Definitions for ACS Design and Analysis: ACS coordinate frames contain an origin location and three unit vectors emanating from that origin. quotThe most convenient set of these vectors is a dextral (i.e., right-handed), orthonormal (i.e., mutually perpendicular and of unit length) triadquot [reference 4, p. 6]. Vector quantities can be expressed as projections onto each of the three triad unit vectors of a coordinate frame. Triads or frames can be related to each other through the use of rotation matrices [reference 4, pp. 8-10], thus permitting the expression of vectors in any desired frame. With the use of coordinate frames and vectors, the orientation and changes in orientation of spacecraft, celestial bodies, instruments, mechanisms, and other ACS related hardware and objects can be described. An overall base coordinate frame must be defined relative to which all other coordinate frames (discussed below) are defined. In many cases, this overall base frame will be an inertial frame which is used to determine overall mission success. For example, if the primary mission of the spacecraft is to point instruments at the sun, a good choice for the overall base frame might be the heliocentric reference frame [reference 7, p. 29] since the sun's motion can be easily established in this frame. Typically, within the ACS subsystem, several design issues must be addressed. These design issues can often be arranged into categories, such as overall spacecraft pointing; environmental disturbances; spacecraft mass properties; sensor, actuator, and instrument motion; and flexible body dynamics. A category reference frame should be established to address each design issue. For example, when modeling environmental disturbances in Earth orbit, an Earth centered inertial frame is usually used as the category reference frame. For defining the spacecraft mass properties, sensor, actuator, and instrument motion, and flexible body dynamics the category reference is some sort of spacecraft body fixed coordinate frame. If information is to be transferred between these ACS categories, transformations can be established through the overall base coordinate frame discussed above. Additional coordinate frames may be needed to define the motion or effect to be modeled within an ACS category. The effect to be analyzed may be defined in terms of an intermediate axis with this intermediate axis related back to the category reference frame. The coordinate frames needed for defining spacecraft motion within the orbital plane provide a good example of this process. A frame which is fixed to the spacecraft is defined first. This frame is used to define the motion of the spacecraft relative to the orbit plane. Then, a frame which is fixed to the orbital plane is used to define the motion of the orbit plane relative to an inertial frame. The result will determine the spacecraft motion relative to the inertial frame. Another example of the use of intermediate axes for addressing ACS design issues is the relationship among sensor and instrument reference frames. One axis of these frames is almost always defined along the boresight of the sensor or instrument. The other two axes should match some other characteristics (e.g., parallel to the edges of a square field of view). The origin is at any convenient point. The relationships of the nominal and quottrackingquot (a frame that moves with the boresight to track the sensor motion) boresight frames to the category reference can be achieved in many different ways depending on accuracy and knowledge requirements. Several intermediate frames might be needed to achieve these relationships. Often, both the nominal and tracking boresight frames must be related to a payload interface frame, and all requirements of alignment are specified between this interface frame and another frame, the spacecraft optical frame. Typically, the interface frame axes are nominally parallel to the spacecraft optical axes, and the optical axes are defined with respect to an optical master reference cube. The nominal position of this cube relative to the spacecraft mechanical build axes (used for defining hardware locations within the spacecraft) must be defined next. Finally, this mechanical build frame may be used as the category reference or is then related to the category reference. The figure below shows the nominal orientations of these frames used in the SOHO spacecraft [reference 1, p. 2.8]. This example demonstrates the process of how coordinate frames are used to define the sensor and instrument pointing relative to its category reference frame. [D] A discussion of the frames needed to model how actuators are used for attitude control is presented as a final example of the use of intermediate frames. Momentum wheels, control moment gyros (CMG's), torque rods, and thrusters are commonly used control actuators. Frames are needed to represent the nominal orientation and location, misalignments produced when installing, and movement of the actuators. Also, rotation matrices which relate these frames to the category reference, usually the spacecraft ACS axes, must be determined. As a specific example, consider the frames needed in distributing control torques among a reaction wheel set containing 4 wheels. The wheels are usually aligned in a pyramid configuration as shown below. A frame is first defined for each wheel with one axis along the spin axis of each wheel. Then, rotation matrices are created relating each wheel frame to the spacecraft ACS frame (called roll, pitch, and yaw for this case). This example demonstrates how intermediate and category frames are used to relate the orientation and motion of actuators (in this case, reaction wheels) to achieve desired torques. [D] 2. Document Format A suggested format or outline for the coordinate frame definitions document is summarized below. However, this format is only a guide, and the user may need to change or add to the format depending on the spacecraft mission. Since the choices of ACS coordinate frames to be defined are dependent on the overall spacecraft pointing objectives and the proposed ACS mission hardware required, these topics should be discussed first. To avoid any ambiguity, coordinate system symbols and nomenclature to be used should be listed next. Specific coordinate frame definitions should follow -- an overall base frame, category reference frames, and frames needed within each category. Finally, a way of relating all the coordinate frame definitions should be included. ACS Coordinate Frames Definition Outline Document Title Table of Contents Mission Objectives, Requirements, and Criteria for Success State overall spacecraft pointing objectives and specifications Overview of ACS Hardware State what instruments, control actuators, and other mechanisms are being used for sensing, data collection, and control actuation Nomenclature and Symbols Discuss the nomenclature and symbols to be used for the coordinate frame definitions Overall Base Frame Definition Define a frame to which all other frames are referenced. Category Frames Group design issues into appropriate categories, e.g., spacecraft, instrument, and sensor pointing, actuator sizing, environmental disturbances, spacecraft mass properties, etc. Within each category, a category reference frame should be listed along with all other frames needed to address design and analysis issues. Figures showing the physical relationships among these frames would be helpful. Coordinate Frame Transformations Relate each frame to the overall base frame. The first section of the document (after the table of contents) states the overall mission objectives and the criteria for a successful operation. The objectives include a list of celestial, Earth based, or other bodies to which the spacecraft and instruments must point. A discussion of the pointing accuracy and knowledge error definitions and specifications for performance needs to be given. Orbit parameters, spacecraft mass properties, and any issues that might affect the mission objectives or success criteria are provided in this section. This section will aid the reader in understanding the rationale behind the choice of coordinate frames. The second section of the document contains an overview of ACS hardware. Included in this discussion are locations, orientations, and functions of all ACS related hardware. The locations and orientations are best shown with a figure or a reference to an interface drawing. If the hardware moves or reorients itself (such as solar array rotation to track the sun) relative to the spacecraft, this change is to be documented. The anticipated effects of flexibility should also be considered. Instrument and attitude sensor functions are given in relation to the overall ACS concept. For example, a magnetometer is used to determine the magnetic field of the Earth relative to the spacecraft. The location and orientation of the magnetometer relative to the spacecraft needs to be given, along with a statement of how the magnetometer may be used in conjunction with other ACS hardware and software. The magnetometer output may be used for attitude sensing or for determining when to pulse a torque rod to provide an attitude control moment. These different functions for the magnetometer may result in different coordinate frame choices. The third section of the document needs to discuss the nomenclature and symbols to be used for the coordinate frame definitions. The format may vary depending on the spacecraft mission. An example definition taken from reference 6 [p. 4], and shown below, demonstrates a possible format which may be used for defining reference frames. A descriptive or commonly used name is given first. A one or two letter symbol is listed next, which is also used for labeling the vectors comprising the axes of the frame. Then, a description of the frame is provided, and this description is to contain enough detail to unambiguously locate the frame. Equatorial Inertial Coordinate System, E (E1, E2, E3) This is the basic inertial coordinate system. All other coordinate systems are defined with respect to E. The origin is at the center of the Earth. The E3 axis is in the equatorial plane and it is positive toward the vernal equinox. The E2 axis is perpendicular to the equatorial plane, and it is positive toward the Earth's North Pole. (The E1 axis completes the orthogonal triad.) The vernal equinox position is defined as its mean position at 1950.0. All the frames included in the document are related to the overall base frame. Rotation matrices are commonly used to convert components of vectors from one frame to another, and the development of the mathematics is available in the literature [reference 4, pp. 6-31], [reference 6, pp. 10-20], and [reference 7, pp. 410-420, 758-759]. To avoid any ambiguity in the definitions of coordinate frame rotations and their matrices, a discussion of this topic is to be included at the beginning of this section of the document. This discussion should include definitions of Euler angles, quaternions, direction cosine matrices, or other mathematics to be used to relate the frames. Then, a table or any convenient format is included at the end of the document which contains information relating each frame back to the overall base frame. Finally, figures illustrating the nominal relationships among all these frames and the possible reorientations of the frames during flight is essential and is included in the document. Technical Rationale: Due to the increased complexity of ACS work for spacecraft, a document is needed in the early stages of the project development which contains consistent and well-defined coordinate system definitions. Definitions are needed to accurately communicate within and between various design and analysis disciplines affecting ACS performance. These disciplines include spacecraft pointing, environmental disturbances, spacecraft mass properties, sensors, actuators, and instrument motion, structural dynamics, and mechanisms. Analytical and design mistakes can occur due to communicating erroneous information within and between design and analysis groups. This erroneous communication can be caused by inconsistent or ambiguous coordinate frame definitions. If a document listing coordinate frames to be used for ACS design and analysis is published and adhered to, then many problems can be avoided. For example, an ACS engineer may need to know the mass and inertia of the spacecraft in order to simulate the dynamics. However, when obtaining this information from structural or design engineers, often the ACS and the structural body frames are not consistent. If a mission standard was established early in the program life, both body frames would be consistent, or at least, the creation of a rotation matrix between frames would be readily obtained. Documentation of ACS frames would also be clear, consistent, and complete if this guideline is followed. During preliminary and critical design reviews, much time is spent searching for definitions of ACS frames and information relating those frames. If all the frames are compiled into one document and are related to an overall base frame, considerable time and effort will be saved. Verification of spacecraft, instrument hardware, and other mechanism pointing will be facilitated. Often it is necessary to visually or otherwise make quotsanityquot checks to make sure that component rotations will result in the desired orientation. For example, for Earth orbiting spacecraft it is necessary as part of the mission systems verification to make sure that spacecraft solar arrays quottrackquot the sun. To make this verification, the sun and the solar array normal vectors must be written in the same frame and compared. This process involves several coordinate frame rotations which should be defined in the document generated through this guideline. An accurate record of these coordinate frames will be available throughout mission planning, development, and flight. If during development of hardware and software for flight a technical glitch occurs, it will be necessary to review the ACS design analysis work performed. Without documented ACS coordinate definitions, analyses may be difficult to validate causing additional costs and delays in the mission. Also, ACS engineers will be able to review coordinate frame definitions created with this guideline enabling them to better plan and analyze for future spacecraft missions. References: Berner, C., quotSOHO Solar Terrestrial Science Programme Experiment Interface Document, Part A,quot PLP\/410\/EID A, January 7, 1990. Ford, Terry, Spacecraft PDR Update, quotEOS Pointing Error Budgets, Prediction, and Verification Concept,quot EOS-DN-SE&I-043 Rev A, August, 1993. Frederick, Martin E., quotTropical Rainfall Measurement Mission, Attitude Control System Specification,quot Goddard Space Flight Center, Greenbelt, Maryland, TRMM -712 - 046, August 13, 1993. Hughes, Peter, C., Spacecraft Attitude Dynamics, John Wiley and Sons, Inc., 1986. Kaplan, Marshall, H., Modern Spacecraft Dynamics and Control, John Wiley and Sons, Inc., 1976. Kennel, Hans F. , quotSpace Telescope Coordinate Systems, Symbols, and Nomenclature Definitionsquot, Systems Dynamic Laboratory, George C. Marshall Space Flight Center, Alabama, NASA TM X-73343, September, 1976. Wertz, James R., quotAttitude Geometry,quot Spacecraft Attitude Determination and Control, Kluwer Academic Publishers, Netherlands, 1991.","Lesson ID":692}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1201; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. EEE parts derating can be established as either design policies or from reliability requirements. In general, NASA has taken the approach of establishing derating policies that cover all applications of the various part types in space flight equipment. These policies are available in MIL-STD-975, quotNASA Standard Parts List.quot Table 1 provides typical derating factors from that document. If derating is to be determined from a reliability requirement, the reference document is MIL-HDBK- 217, quotReliability Prediction of Electronic Equipment.quot MIL-HDBK-217 contains the information necessary to quantitatively estimate the effects of stress levels on reliability. Table 1. Typical Part Derating Guidelines PART TYPE RECOMMENDED DERATING LEVEL Capacitors Max. of 60% of rated voltage Resistors Max. of 60% of rated power Semiconductor Devices Max. of 50% of rated power Max. of 75% of rated voltage Max. junction temperature of 110\u00b0C Microcircuits Max. supply voltage of 80% of rated voltage Max. of 75% of rated power Max. junction temperature of 100\u00b0 Inductive Devices Max. of 50% of rated voltage Max. of 60% of rated temperature Relays and Connectors Max. of 50% of rated current NOTE: Maximum junction temperature levels should not be exceeded at any time or during any ground, test, or flight exposure. Thermal design characteristics should preclude exceeding the stated temperature levels. Technical Rationale: The reliability of a EEE part is directly related to the stresses caused by the application, including both the environment and the circuit operation. MIL-HDBK-217 contains specific part failure rate models for a wide variety of part types. The models include factors for calculating the effects of various stresses on the failure rate and thus on part reliability. The types of factors include (for example): environment, quality levels, voltage, frequency, and temperature. Given the extensive tables of factors in MIL-HDBK-217, one can formulate reliability predictions for piece parts. As shown in Figure 1, the plot of piece part failures versus an application stress level such as temperature, voltage, or current indicates decreasing failure rates for lower levels of stress. Therefore, a part's reliability in an application can be increased by decreasing the maximum allowed stress levels from the absolute maximum for which a part is rated. [D]","Lesson ID":676}
{"Driving Event":"This Lesson Learned is based on Reliability Guideline Number GD-ED-2205 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefits: Conscientious adherence to proven concurrent engineering principles and careful design and material selection guidelines in the design, manufacture, and testing of aerospace composites will result in low rejection rates and high product integrity. Successful composite designs can provide design flexibility, lightweight parts, ease of fabrication and installation (generally fewer parts), corrosion resistance, impact resistance, high fatigue strength (compared to metal structures with the same dimensions), and product simplicity when compared to conventional fabricated metal structures. Implementation Method: Introduction: Composites are combinations of two or more distinct materials present as separate phases and combined to form desired structures. They take advantage of the desirable properties of each component. The manufacturing technique used to fabricate a composite structure is dependent upon material performance requirements, structure configuration, and production rates. The composite design and manufacturing methods discussed in this guideline are primarily for structural and mechanical applications and are composed of a resin (matrix) and a fiber reinforcement. Typical reinforcements are shown on Figure 1. [D] Performance of composite materials in aerospace applications is superior to conventional structural materials such as steel and aluminum. Composite materials and their manufacturing processes can be tailored specifically to given design constraints. The superior physical properties of composites allow for design with minimum concern for dimensional stability, corrosion, and crack formation. While it is possible to tailor the properties of a composite structure to minimize problems in these areas, it is imperative that this be taken into consideration during the design process. Composite materials are significantly superior to conventional materials in strength-to-weight ratio, one of the most important requirements of aerospace structures. Design: Concurrent engineering principles (i.e., the team approach to design using designers, thermal and structural analysts, manufacturing engineers, materials process engineers, tool designers, machinists, quality engineers, quality control specialists, and reliability engineers) contribute noticeably to the success of a composite materials program. Designs of composite components which are fault tolerant to known manufacturing conditions and variables should be selected. The success of a composite program is dependent upon establishing material properties early in the program. Establishing an accurate and reliable material property data base is one of the most important steps toward achieving a functional design. Experience indicates that the basic material allowables of a specific composite product should be determined utilizing the manufacturing facilities where production will take place prior to finalizing design. The preferred process should approximate the following: (1) define environmental and performance requirements; (2) review available materials against requirements to determine the family of material to be used; (3) determine materials; (4) determine materials allowables using material processed at the intended manufacturer; (5) proceed with design based on known material allowables; (6) test geometric configurations (i.e., special joints, specific contours, special ply layups, etc.); (7) along with nondestructive evaluation (NDE), use destructive evaluation to determine voids, ply dropoff, resin rich areas, etc., during initial manufacturing process development; (8) begin manufacturing production. Typical mechanical and impact damage properties of selected composites are shown in Tables 1 and 2. Table 1. Typical Mechanical Properties of Selected Composites Material Type Nomenclature Tensile Strength (ksi) Modulus (Msi) Strain (%) Carbon\/Epoxy Glass\/Epoxy Kevlar\u00ae\/Epoxy Carbon\/PEEK Carbon\/Phenolic T300\/934 IM7\/8551-7 P75\/934 AS4\/3501-6 IM6\/3501-6 E-glass\/934 K-49\/7934 IM7\/APC-2 FM5055 245 400 135 100 330 150-170 80-85 419 15-20 20 24 44 10 23 6-8 4 24 2.6-2.8 1.0-1.2 1.62 0.2-0.5 1.0 1.5 2.75 1.85 1.6 1.0-1.2 PEEK= Polyetheretherketone Note: All samples were prepared from 16-ply quasi-isotropic layups. Table 2. Typical Impact Damage Properties of Selected Composites (1), (4) Nomenclature Max Impact Load (lb) Energy at Max Load (ft-lb) Compression After Impact (CAI) (ksi) (2) IM6\/3501 IM7\/SP500 IM7\/F3900 IM7\/977-2 T300\/934 T650-42\/1939-3 IM7\/8551 IM8\/8553 850 1100 1080 1170 560 1010 1240 900 9.2 9.1 9.7 10.3 3.7 8.5 12.1 7.4 23.2 36.2 39.9 47.1 (3) (3) 50 (3) Notes: (1) All samples prepared from 16-ply quasi-isotropic layups. (2) CAI values are normalized to approximately 125 ft-lb impact energy per inch thickness. MSFC M&P Lab data unless noted otherwise. (3) MSFC M&P Lab CAI testing planned for these materials. (4) Hercules data unless otherwise noted. The factors of safety shown in Table 3 should be used in the analysis and design of composites. During design and manufacturing process development, credible accept\/reject criteria and acceptable repair methods should be developed. Table 3. Safety Factors for Composites Item Ultimate Minimum Test Factor Acceptance Test Flight Units Qual Unit Flight Unit Nonprotoflight (1) Structure Protoflight (2) Structure 1.4 2.0 (3) 1.5 2.0 (3) 1.4 1.2 1.05 Notes: (1) Fly separate test article. (2) Fly the article tested. (3) Stress riser or discontinuity Recommended Design and Analysis Guidelines for Composites: During the concept definition phase of the composite part design cycle, all of the critical design parameters are established. Geometric constraints and material considerations are outlined in order to establish the amount of design flexibility allowable. Maximum loads, both mechanical and thermal, are estimated. Weight, cost, and producibility concerns should be considered at this juncture. These factors should then be weighted and balanced to produce an initial design concept. For example, thermal material limitations should be balanced against cost and producibility concerns to select the appropriate composite material. Likewise, the layup of the laminate should be chosen considering not only the desired load capability, but also the thermal environment. High heat transfer areas could be cooled by using additional plies to act as a heat sink. These two factors in turn are offset by weight considerations. Several preliminary analysis and sizing tools can be used at this stage. PANDA, an elastic-plastic composite shell optimization program, is used in the analysis of stiffened panels. For flat composite panels, PASCO is sometimes used for preliminary sizing. The use of a Computer Aided Design (CAD) package is highly desirable in drawing the initial configuration. The configuration is then subjected to stress analysis. Depending on complexity, the part may be subdivided into subcomponents for separate analysis. If required, a structural computer model may be generated. For most parts, a finite element model is generated using PDA\/PATRAN and the surface definitions from the CAD drawing. PATRAN is used as preprocessor and post-processor for MSC\/NASTRAN, which has the capability of analyzing composite plate elements. Aerodynamic, vibroacoustic and thermal loads are obtained from the appropriate discipline areas for input into the stress analysis. The vibroacoustic analysis is performed by dynamics loads engineers using MSC\/NASTRAN as a processor and IDEAS as a preprocessor and post-processor. A temperature profile for the part is provided by thermal engineers using MIDAS, a finite difference thermal analyzer, and thermal material properties supplied by the composites materials engineers. For shells of revolution under axisymmetric loading, BOSOR, a finite difference structural analysis program, may be employed. A simple general shell element finite element program, STAGS, is sometimes used to obtain input loads for BOSOR models. For more detailed analysis at a particular point, SQ5, a point stress laminate analysis program, is used. Edge loads for a critical element from a finite element or finite difference model are input into this program to obtain more detailed results. Thermal effects may be approximated using this program. However, if temperature gradients become excessive, in-house developed software may be required. Although buckling coefficients may be obtained from NASTRAN, NASA-supplied buckling knockdown factors for plates with complex curvature are used to compensate for inaccuracies inherent in the finite element program. Specialized computer programs are used to analyze joints and fasteners and their interface with the composite parts. Bolt programs determine the capability of bolted joints under combined bending, tension and shear applied loads, as well as tension due to preload and differential thermal expansion. Clip analysis programs analyze metal clips using empirical data. Composite joint programs are also employed; for example, BJSFM is used for bearing loads, and JOINT is used for elastoplastic multiple bolt joints. Below is a list of representative commercial computer programs that are available for analyzing stresses and strains in composite materials under various conditions. The ones most often used by MSFC are indicated as: [MSFC]. These computer programs are available from the company or source shown in parentheses. ABAQUS (Hibbitt, Carlson & Solenson, Inc.) ADINA (ADINA Engineering) ANSYS [MSFC] (Swanson Analysis Systems, Inc.) BOSOR [MSFC] (David Bushnell) NASTRAN (MacNeal-Schwendles Corp.) STAGS (COSMIC) CHAMPION (MSFC-used but not commercially available) Critical factors affecting strength and stiffness for fiber are modulus of elasticity, strength, strain to failure, and curvature. Critical factors for the matrix are modulus of elasticity, elongation to failure, stress-strain behavior, void content, and fatigue performance. Manufacturing: Typical aerospace composite manufacturing processes consist of filament winding, fiber placement, pultrusion, tape laying, tape wrapping, press molding, hand layup and resin transfer molding. Typical fiber\/matrix composite uses and processing techniques for various MSFC programs are shown in Table 4 and Table 5, respectively. A summary of composite manufacturing processes is shown in Table 6. Table 4. Typical MSFC Users of Fiber\/Matrix FIBER\/MATRIX USAGE Carbon (Graphite)\/Epoxies 1. Most used material for structural composites 2. Used in trusses, pressure vessels, optical benches, racks 3. Available in low, intermediate, and high modulus forms 4. Damage tolerance typically varies inversely with modulus Glass\/Epoxies 1. Used in pressure vessels and sacrificial layers 2. Used as flame barriers for carbon\/epoxy structures and as galvanic corrosion barrier between carbon\/epoxy, carbon\/phenolics and aluminum components Kevlar\u00ae\/Epoxies 1. Used in pressure vessels and small solid rocket motors 2. Excellent damage tolerance 3. Low compressive strength Fiber-Reinforced Thermoplastics 1. Excellent damage tolerance 2. Good repairability 3. Lower structural performance thermosets Fiber-Reinforced Bismalemides, Phenolics 1. Excellent high temperature properties 2. Used in areas of high heat flux (nozzles, fairings, nosecaps) 3. Requires higher processing temperatures Table 5. Processing Techniques SUPPLIED FORMS PREPARATION METHODS CURING METHODS Prepreg tape of varying widths - unidirectional or fabric Prepreg quottowquot - preimpregnation fiber bundles Dry fiber plus wet resin Fiber-reinforced bulk modulus compound Filament winding-wet winding or prepreg tool Hand layup Tape wrapping Tape laying Pultrusion Polar winding Braiding Resin transfer molding Fiber placement Autoclave\/hydroclave Oven Press Compression molding Table 6. Summary of Composite Manufacturing Processes PROCESS COMPOSITE MATERIAL COMMON USES TYPICAL TOOLING AND\/OR EQUIPMENT Filament Winding Glass\/Epoxy Graphite\/Epoxy Kevlar\u00ae\/Epoxy Carbon\/PEEK Carbon\/Phenolic Thermosets Solid Rocket Motor cases, pressure vessels Removable mandrels, automated lathe, resin bath, heat source, vacuum source, curing oven, autoclave, hydroclave, handling tools, trial fixtures, drill fixtures, and assembly tools. Pultrusion Glass\/Epoxy Graphite\/Epoxy Thermosets Thermoplastics Structural shapes of constant cross-section, e.g., tees, angles, channels, rods, tubing, and squares Pultrusion machine similar to metal extrusion machine, heat source, resin bath, cut-off device. Resin Transfer Molding Glass\/Epoxy Graphite\/Epoxy Kevlar\u00ae\/Epoxy Carbon\/PEEK Carbon\/Phenolic Small to large structures of simple to complex shapes. Ply fibers placed in mold, mold closed, resin injected into mold (heated or room temp.) Low tonnage press, contoured molds (male and female), low- cost tooling using standard production steel, room temperature cure, over or autoclave. Hand Laying Glass\/Epoxy Graphite\/Epoxy Kevlar\u00ae\/Epoxy Carbon\/PEEK Carbon\/Phenolic Small quantity production of test panels, prototype parts, or parts of complex contour Lay-up molds, vacuum bags, vacuum source, autoclave or hydroclave, and curing oven. Mechanized Tape Laying Glass\/Epoxy Graphite\/Epoxy Kevlar\u00ae\/Epoxy Carbon\/PEEK Thermosets Thermoplastics Small to large structures of simple or complex shapes Molds, computer-controlled ply cutting, flat and contoured tape laying, automated ply lamination, autoclave, hydroclave, curing oven. Fully Automatic Tape Laying Glass\/Epoxy Graphite\/Epoxy Kevlar\u00ae\/Epoxy Carbon\/PEEK Carbon\/Phenolic Bismalemides Thermoplastics Small to large structural components of simple to complex shapes Contoured molds, automatic tape laying equipment consists of automatic cutter, broadgood dispenser, trim table, ply transfer table, tape laying, stitching module and contour ply handling system, autoclave, hydroclave, curing oven, handling tools, trim fixture, drill fixture, and assembly tools. Press Molding Glass\/Epoxy Graphite\/Epoxy Kevlar\u00ae\/Epoxy Carbon\/PEEK Carbon\/Phenolic Flat panels, molded components for subscale solid rocket motor ablative materials Planten press molds (top and bottom) and heat source to mold. There are sensitive manufacturing variables that must be closely controlled during composite fabrication. Therefore, using certified and highly skilled technicians is required. Typical manufacturing variables are heat input, cooling input, roller pressure, machine speed, tape tension, curing temperatures and curing pressures. Technicians must understand what to do when one of these variables changes. Properly controlled manufacturing processes will result in proper tensile strength, density, thermal conductivity, and interlaminar shear strength. Tooling: Major factors to be considered in the design and fabrication of tooling for structural and mechanical components are: (1) dimensional tolerance control and configuration stability, (2) location of parts in a structurally reliable assembly to give the lowest possible cost, (3) contour and size of the part, and (4) control of fiber orientation. Other significant factors which control final tool concept selection are cost, tool service life, heat up rate, total energy requirements, production rates and related facility costs. The tooling required to fabricate most composite parts can be subdivided into several major categories including ply layup tools, skin or mold forms, curing aids, handling tools, drilling and trimming tools, assembly tools, molds and mandrels. Additional tooling and equipment are shown in Table 6. Testing: Component, subcomponent, and generic structural tests are performed to verify analysis. Particular component tests may include elements of aerodynamics, vibroacoustic and thermal loading conditions, as well as significant externally applied mechanical loads. Subcomponent tests may be performed for critical areas of the component. Generic tests include flange and stiffened panel tensile tests, damage tolerance tests, and standard temperature effect tensile and compressive coupon tests. Inspection: Quality assurance for composite parts centers on techniques for validating the physical and mechanical properties of a cured composite. However, quality assurance begins long before the end item is tested. A logical approach to quality control follows the fundamentals of composite reaction control: (1) raw material validation reaction control; (2) material characteristics; (3) in-process fabrication\/handling\/tooling effects; (4) cure process control and documentation; (5) post cure machining. Visual inspection is used to inspect bond lines that are visible in the various bond stages and to detect any visible surface discontinuities and\/or delaminations. Mechanical inspection is used to verify design dimensions, acoustics, input resistance, static loads and dynamic loads. Non-destructive evaluation is perhaps the most important inspection technique for determining defects in composites, particularly the defects specified in Table 7. Table 7. NDE Techniques for Detecting Defects in Composite Materials Defect\/ Composite Method* X-ray Ultrasonics Computer Tomography Alcohol Wipe Thermography Eddy Current Dye Penetrant Delaminations\/ All 8 X X X X X Density Variations\/ #5 X X Resin Rich-Resin Poor\/All 8 X X Voids\/#1 X X X Crazing (Micro-cracks)\/ All 8 X X X Wrinkles\/ All 8 X X Conductive Materials\/ #2 X * Composite Methods: 1. Filament winding 2. Fiber placement 3. Pultrusion 4. Tape laying 5. Tape wrapping 6. Press molding 7. Hand layout 8. Resin transfer molding Technical Rationale: MSFC experience with composites includes filament winding, tape laying, fiber placement, hand layup, computerized pultrusion, and automated tape wrapping. Computer programs are available to assist in the composite design process. The mechanical properties and impact damage properties that have been derived from tests of various composite materials can be used by designers to select the proper material and configuration for the job. Research is continuing to expand the available storehouse of design guidelines, leading to the production of reliable aerospace composite components. Valuable references which provide detailed design and analysis parameters for composite materials are provided in this guideline. References: Agarwal, B.D., Broutman, L.J.: quotAnalysis and Performance of Fiber Composites,quot John Wiley and Sons, Inc., Second Edition, 1990. ASM International Handbook Committee: quotComposite, Engineered Materials Handbook,quot Volume 1, Third Printing, August 1989. DOD\/NASA: quotAdvanced Composites Design Guide,quot Volume I-IV, 1989. Jones, W.K.: quotTest Report Graphite\/Bismalemide Allowables Data Base,quot Martin Marietta Composites Technology Group, August 1987. Lubin: quotHandbook of Composite Materials,quot 1982. MSFC-HDBK-505A: quotStructural Strength Program Requirements,quot January 1981. MSFC-HDBK-1453: quotFracture Control Program Requirements,quot October 1987. Morgan, Jr. L., Sigur, W.A.: quotFastening Techniques for Composite Materials,quot Martin Marietta Composites Technology Group, August 1985. NHB 8071.1: quotFracture Control Requirements for Payloads,quot September 1988. Sherrouse, M., Blum, C.: quotRecommend Practices for Composites, Design and Analysis,quot Martin Marietta, Michoud, LA, March 1992. Strong, Dr. A. Brent: quotFundamentals of Composites Manufacturing; Materials; Methods, and Applications,quot Society of Manufacturing Engineers, Dearborn, MI, 1989. Whitney, J.M., Daniel, I.M., Pipes, R.B.: quotExperimental Methods of Fiber Reinforced Composite Materials,quot SESA Monograph Number 4, Prentice-Hall, Englewood Cliffs, NJ, 1982. Applications of Ablative Composites in Solid Rocket Motor Nozzles Reliability Preferred Practice No. PD-ED-1218; Marshall Space Flight Center. Structural Laminate Composites for Space Applications Reliability Preferred Practice No. PD-ED-1217; Marshall Space Flight Center.","Lesson ID":682}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-EC-1102; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Reliability is greatly enhanced because the likelihood of serious mission degradation or spacecraft loss is significantly reduced. Implementation Method: Prepare design requirements which specify mean velocity, mass density, and mass distribution for the impacting particles in terms of the integral fluence. This fluence (sample units m-2) represents the expected number of impacting particles per unit area, above several different mass thresholds for the mission (using the worst case trajectory if more than one is contemplated). The design must then satisfy two separate requirements: (1) that the smallest penetrating particle have a probability of impact below 5%, using the product of fluence with vulnerable area and a Poisson distribution, and (2) that for smaller particles, of which many will impact any given spacecraft surface, the resulting degradation of surface properties (e.g., optical, thermal, dielectric) does not exceed allowable ranges for surface performance (considering, e.g., pitting, spallation, contamination, etc.). In practice, the first of these refers to a sum of probabilities over a variety of vulnerable spacecraft surfaces (each having specific values for area and threshold penetrating mass), allocated so as to make effective use of resources (e.g., shielding mass) and to achieve the desired probability for mission success. For this purpose, experience dictates that a two-surface configuration, of which the outer surface serves as the thermal blanket as well, provides the least massive meteoroid protection. Technical Rationale: For a given mission (specified in terms of geocentric and heliocentric positions as functions of time, for example), the environments comprising impacting solid particles are both independent of mission control and rather uncertain. The flux and fluence of such particles can be evaluated from suitable numerical models (here for space debris and for interplanetary meteoroids, although others may occur, e.g., for Saturn ring particles). The integral fluence typically decreases as mass increases according to a power law, illustrated here using the exponent a: [D] (1) Here F and F1 represent the integral fluences (sample units m-2) for particles with masses greater than m and m1 respectively, accumulated over the mission. Table 1 provides examples of such distributions (where the exponent is not necessarily constant over the range of masses of interest) and additionally specifies mean density and impact velocity. For large particles, the distributions represented by equation (1) or Table 1 imply that the exposed surface area As of a spacecraft subsystem has a probability [D] (2) that no particle larger than the mass ms (corresponding to the fluence F) will hit, where equation (2) is obtained assuming Poisson statistics for the particle impacts. If the surface is designed so that no particle of mass ms or larger, impacting at the mean velocity, can penetrate or lead to other component failure (e.g., by spallation), then the probability of no failure is also Ps (assuming that penetration leads to component failure with unit probability). When Ps is small for each subsystem (as is the case when the area-fluence product in eq. 2 is much less than unity), the sum [D] (3) represents the probability of failure (Pt) of the system, where ps is the conditional probability that the system fails when subsystem s fails. If the values of ps are not independent then equation (3) must be replaced by the appropriate combination of probabilities. Finally, the probability of mission success, considering particle impact alone, becomes (1-Pt), and design must proceed to ensure that this quantity exceeds the 95% probability cited above. To protect a subsystem against those large particles for which equation (2) applies, and for impact velocities larger than a few km\/s, hypervelocity impact experiments show that a two-surface configuration (often named a bumper shield) prevents penetration far more effectively than a single surface of the same mass. This is so because the kinetic energy of impact leads to the vaporization (or liquefaction or disintegration) of the projectile when it hits the outer target surface; the momentum is thereby dispersed over a large area as the vapor expands in the space between the surfaces, and becomes less capable of rupturing the second surface than had the latter been hit directly. Typically a thickness of a few tenths of a millimeter, and a standoff distance of a few centimeters, suffice to prevent penetration of a spacecraft structural wall by a milligram particle arriving normally at 15 km\/s. For a sample configuration, Figure 1 displays the threshold penetration mass as a function of impact velocity. Such a figure can be used to verify by analysis that the design does not fail for the mass necessary for equations (1) through (3) to provide the required probability; and a parametric set of such figures spanning a suitable design space can be used to select the design appropriate for a given spacecraft assembly. In this design process, the uncertainties in penetration threshold and the variability thereof with angle of incidence (Fig. 1 and related data are commonly presented for normal impact, oblique impacts being less well characterized) must be considered, possibly by application of margin to some measure of shield effectiveness (the use of Poisson statistics for probability of impact is intended to cover only environment uncertainties, not shielding ones). In many cases, thermal blankets of a single design and standoff will serve as an appropriate bumper shield for much of the spacecraft body. Analytic formulations for hypervelocity penetration, and for bumper spacing and other parameters, should be selected carefully for relevance to the specific impact regime (e.g., projectile speed, direction, density, etc.). The resulting design should be verified by testing whenever possible, and the tests should span or simulate the range of expected projectile sizes and velocities. For much smaller particles, the power-law distribution (eq. 1) ensures that the area-fluence product exceeds unity for most exposed spacecraft surfaces, and that numerous small particles will strike the surface. For surfaces which are shielded as described above, these smaller particles are of no consequence, except as they alter the thermal properties of the surface; the thermal control design must provide enough latitude that these changes do not lead to internal temperatures beyond the acceptable range for flight. For other surfaces, concern arises only if a few critical surface properties must be maintained; for example, structural integrity and magnetic cleanliness are not threatened by these small impacts. Among such critical properties, optical quality is often the most serious, as in lenses or mirrors whose performance can be degraded by pitting, erosion, or contamination. For such components, ad hoc solutions to the particle impact problem, possibly involving articulating covers, may be necessary if analysis demonstrates that the particle fluence represents a significant hazard to unprotected surfaces. Typically, if a specific fluence value is required for design purposes in these cases, a margin of a factor 2 is applied to the nominal values (e.g., Table 1) to account for the uncertainty in the environment of these smaller particles. Table 1. Integral fluence of cometary meteoroids as a function of particle mass for three subsets of the Galileo mission (columns two and three include interplanetary meteoroids near Jupiter, as focused by Jupiter's gravitational field). Particle Mass-M (grams) Integral Fluence(1) Received during Transit* (Particles-m-2 of mass greater than M) Integral Fluence(2) Received during Orbit** (Particles-m-2 of mass greater than M) Mission Integral Fluence(3) (Particles-m-2 of mass greater than M) 10-12 10-10 10-8 10-6 10-5 10-4 10-3 10-2 10-1 10-0 1.06 x 104 4.27 x 103 5.37 x 102 21.2 1.33 8.15 x 10-2 4.99 x 10-3 3.06 x 10-4 1.87 x 10-5 1.15 x 10-6 7.89 x 103 3.17 x 103 3.99 x 102 15.7 9.6 x 10-1 5.9 x 10-2 3.6 x 10-3 2.2 x 10-4 1.36 x 10-5 8.3 x 10-7 1.85 x 104 7.44 x 103 9.36 x 102 36.9 2.29 1.41 x 10-1 8.59 x 10-3 5.26 x 10-4 3.23 x 10-5 1.98 x 10-6 Mean relative speed (km\/s) 15.9 15.9 15.9 Particle mass density (g\/cm3) (cometary origin) 0.5 0.5 0.5 *Tabulated values envelope the Galileo transfer trajectories including VEEGA, delta VEGA 2 , delta VEGA 3 , and direct. ** Fluence resulting from JOI and the first 5 orbits of the Galileo 79-1 Tour, includes gravitational focusing from Jupiter. (1) 95% confidence environment - 2.0 x fluence spectra (2) 95% confidence environment - 5.6 x fluence spectra (3) 95% confidence environment - 4.4 x fluence spectra Figure 1. Meteoroid critical mass as a function of impact speed for the Cassini propellant tanks, including a bumper shield and fluid within the tanks. The lines are for different densities of the impacting meteoroid, with and without fluid in the tanks, and the power-law segments represent different regimes of failure. (Click image for a larger view) [D]","Lesson ID":679}
{"Driving Event":"This Lesson Learned is based on Reliability Guideline Number GD-ED-2203 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Use of this guideline will ensure continued improvement with the use of microcircuits in circuit designs by incorporating data from previously experienced problems into a design checklist. This will apply the experience base from the past and thus provide improved reliability for future space programs. Technical Rationale: Information gathered from a history base of known problem areas is presented in easy-to-use checklist form to be used by designers, etc. The checklists are separated into three categories, based on device technology (TTL, CMOS and memory). The guideline can then be used as a reference to avoid incorrect utilization of these component types in circuit design applications which may result in potentially poor reliability. TTL DESIGN CHECKLIST 1 Only gates from the same package should be connected in parallel. 2 Take note not to exceed fan-out limit (maximum number of circuits fed input signals from a single output terminal). 3 Check pin compatibility when using devices from different families or manufacturers. 4 Check manufacturer interchangeability for minor functional differences. 5 Maintain equal loading in ac and dc terms on multiple output devices with internal feedback. 6 The dynamic threshold of low-power schottky (LS) gates varies between 1.1 V and 1.4 V depending on circuit configuration; therefore, slow rise times (greater than 50 nanoseconds) will possibly cause pattern sensitivity. 7 Gates with outputs driving transmission lines should be situated close to the board periphery. 8 Consider full-range temperature effects on switching characteristics relative to design application. 9 Use pull-up resistors on devices with open collector gates. 10 Consider the frequency dependency of power dissipation when the operating frequency is greater than 1 to 2 MHz. 11 If decoded outputs from counters, particularly from ripple counters, are being used as clocks to drive counters or memory devices, the decoded outputs of interest should be examined for multiple pulses at counter transitions that might ambiguously operate the driven counters or memory devices, and corrective measures should be taken to non-ambiguously operate the driven circuits. 12 Take note that low-power, low-power Schottky, and Schottky TTL circuits are known to fail when exposed to 5 microjoules or more of electrostatic discharge (ESD) energy. 13 Consider \"current dumping\" effects when a multiple input gate is terminated to a single high impedance source such as a 150-ohm line. 14 All unused input pins should be tied to high- or low-logic levels, depending on the circuit application. When devices approaching their maximum speed for TTL are used, unused inputs should be \"commoned\" to used inputs rather than tied high; whereas for low-power Schottky devices with diode inputs, the unused ones can be directly connected to VCC. 15 Provide isolation for test points so that any foreseeable occurrence, such as shorting between, grounding or external excitation at the test points will not disrupt operational use of the circuit being monitored by the test points. 16 Consider potential problems involving the use of multiple flip-flops controlled by one or more asynchronous output. 17 Check interfacing parameters (fan-out, loading, and threshold) when using devices from different families. CMOS DESIGN CHECKLIST 1 Allow for hold-time and setup-time requirements of CMOS flip-flops, registers, and latches. Inputs to CMOS devices must be stable before and remain stable even after the active clock pulse edge. 2 Take adequate precautions to avoid ESD damage. 3 Account for possible incompatibilities with similar part numbers from different manufacturers when establishing parts lists. 4 Investigate the package choice\/reliability tradeoff for each design application. 5 When using single-stage (unbuffered) multiple-input CMOS devices, consider that both dynamic and static performance of these circuits can deteriorate under certain logic conditions to the extent that logic systems display pattern sensitivity. 6 Protect signal inputs against overvoltage spikes and input currents exceeding ratings, i.e. many CMOS devices have ten milliamperes as the maximum allowable input current. Consider that if the overvoltage spike is greater than the supply voltage, the parasitic PNP or NPN transistors become forward biased and latch-up can occur. 7 Excessive current through switches results in latching and destructive breakdown; therefore, protective circuitry is essential. 8 Consider the noise margin when using 5-volt supply levels. CMOS has an order of magnitude less energy noise margin than TTL (approximately 0.4 nanojoules for CMOS and 4.0 nanojoules for standard TTL). 9 The power supply should switch on by itself first before signal inputs are applied, since damage may occur if the diode between input and VDD is forward biased. 10 Slowly rising or falling input signals can lead to multiple triggering, particularly if the supply voltage is poorly regulated, and also to higher supply (IDD) currents. 11 Maximum power dissipation of the device could be exceeded if input rise and fall times are greater than 15 microseconds, (depending on device type) especially using high current drivers with high supply voltages. 12 Terminate all unused inputs; a floating input can turn a CMOS device on, causing faulty operation and possible damage, and also uses increased power since both p- and n-transistors are partially conducting. 13 Ensure that interfacing parameters between CMOS and other logic families are correct, particularly with regard to loading and thresholds. 14 Keep interconnections short or use terminations, as long interconnections in high speed systems behave like transmission lines, which can cause reflections and ringing. 15 Do not use CMOS gates as linear amplifiers; this can destroy buffer gates, cause failure of the device to operate below 4 volts, and make supplier interchangeability even more problematical. 16 Avoid long, closely spaced, parallel traces on PCB's to minimize crosstalk. 17 Flip-flops with transmission gate inputs are particularly prone to malfunction if the inputs are driven above and below the supply voltages. This can occur when interfacing from other logic families and from distant boards. 18 Try not to design to typical values because of the large part-to-part process variations. In many cases guaranteed values are several orders of magnitude larger than typical values. 19 Reduce ground\/power supply inductance (power\/ground planes) and use sufficient decoupling capacitors, as simultaneous switching of multiple outputs causes noise and voltage drops on power supplies. MEMORY DESIGN CHECKLIST 1 Avoid using parts at their maximum supply voltage tolerance and\/or at their maximum speed. In a large memory system, noise, loading, and skew problems result in reduced apparent working area and reduced effective speed. 2 Consider carefully the difficulty in \"second sourcing\" with memory components, since they are far more complex than standard medium scale integration components (MSI); and very few, if any, have identical replacements. 3 Avoid mixing several technologies within the same memory system. If this is done great care must be taken to ensure that at no time are the pins of any memory component pulled beyond the component's substrate voltage. 4 When read-only memories (ROM's) are used to replace wired logic gates, the outputs may show noise or extra transitions, since the ROM is not guaranteed to give a single output transition for a single input transition. 5 In the use of nichrome fused bipolar programmable read-only memories (PROM's) there has been evidence of fuses growing back after programming and of unblown fuses being subject to decay. Ensure that special freezeout tests and high voltage stressing have been carried out, and also consider the greatly delayed production cycles involved. 6 Take note when using PROM's that the programming operation on devices from the same family are not necessarily compatible. Examples are the 1602 and 1702 devices in which the programming operation forces \"ones\" to \"zeros,\" and the 1602A and 1702A devices which force \"zeros\" to \"ones.\" 7 Caution must be taken when using common bus lines not to allow more than one device to be enabled at a time. System noise and incorrect data problems could result, and depending on output drive capability, physical damage to the device could occur. 8 In order to minimize transmission line problems, the driver elements should be located as closely as possible to the memory elements, keeping the connecting printed circuit lines as short as possible. 9 Asynchronous input signals applied to a ROM should be permitted to change within an access time sufficient to meet setup and hold times, prior to clocking the output register. If this does not occur the contents of the output register may be completely unpredictable. 10 Periodically check PROM programming electrical specifications, since manufacturers often change their recommended programming method to improve programming yields. 11 Ensure the correct programming conditions (voltage, duration, etc.) when programming PROM's. 12 Ensure that shift register drivers have sufficient dumping capabilities, otherwise positive or negative spikes may be coupled from one clock to the opposite phase. Spikes may reach over the substrate voltage and activate parasitic substrated transistors and destroy data. 13 Memory products usually dissipate power at significantly higher levels per package than most large-scale integration (LSI) and MSI components. It is therefore very important that adequate cooling arrangements be made, because the power dissipation per unit area can approach an order of magnitude greater than ordinary TTL. 14 Allow in the design for the ROM\/PROM access time differences from various parts of the array. Differences of four to one have been found for various address locations. 15 Take caution when using dynamic MOS shift registers (SR's) as low-speed power-saving circuits, since data can be lost if the SR clock speed is reduced instantaneously. The lower frequency limit applies only at high ambient temperatures and not at self-heated high-junction temperatures produced at high clock frequencies. 16 Take note that when using floating gate metal oxide semiconductor (MOS) PROM's, bit loss occurs under x-ray and nuclear radiation. In addition, problems of inadequate erasure due to poorly calibrated ultraviolet sources can arise. 17 Take caution when using MOS electrically alterable PROM's, since data loss can occur from cells subjected to greater than 109 accesses. Given an access time of 1 microsecond, the data could be lost within an hour if continuous reads are made from one location. 18 Power supply slew characteristics should be evaluated carefully. Two separate problems have been noted. One problem is that at switch-on, a slowly rising power supply may not initialize the random access memory (RAM) logic correctly so that a subsequent initializing procedure is required. Another problem is that sharp, small supply voltage changes that occur in normal memory system operation can cause data loss in some supplier dynamic memory products. 19 Operating temperatures have to be considered very carefully. Because of their complexity, memory components tend to be more sensitive to temperature extremes than other types of devices. 20 Consider that large MOS memory systems often require error correction and detection (the inclusion of \"Hamming\" error correction codes in the design). This approach improves the effective system reliability by two orders of magnitude, and the associated error indicators simplify scheduled maintenance. 21 Consider access time measurement criteria carefully. While some manufacturers measure access times to the VOL and VOH voltage levels, others measure access to the 1.5 voltage level for both high- and low-level outputs. Additionally, some suppliers specify two output loads in their dc characteristics, but measure access time against one output load. 22 Many dynamic RAM's require a substrate bias supply (VBB) to ensure correct operation. Unless this bias supply is raised before the main supply and dropped after the main supply, high currents may be drawn. Also, if the bias supply is reversed even in a transient mode, the parasitic substrate transistor will draw extremely high currents. Since the internal capacitances of the RAM are terminated to the substrate, very good transient bypassing is required. 23 Take care when using bipolar memory devices (e.g., many ROM\/PROM devices) with PNP transistor low-power Schottky style inputs. It is important that the inputs not be pulled below ground until the PNP device is saturated; otherwise, very long access times will be observed. 24 Allow for input\/output coupling features of static RAM's in the system design. Although possibly not shown on the write-cycle data published by the manufacturers, the input data may appear on the output during the write mode. References: MIL-M-38510 Microcircuits, General Specification for MIL-STD-975 NASA Standard Parts List MIL-STD-978 NASA Parts Applications Handbook MIL-STD-1547 Electronic Parts, Materials and Processes for Space and Launch Vehicles MIL-STD-1562 Lists of Standard Microcircuits","Lesson ID":680}
{"Driving Event":"This Lesson Learned is based on Reliability Guideline Number GD-ED-2207 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefits: The likelihood of successful system operation after long periods of dormancy can be increased by assessing the long term environmental effects on the characteristics of parts and materials, and mitigating the detrimental effects through appropriate parts selection and use of protective design options. Implementation Method: The approach involves detailed examination of the materials, parts, and manufacturing methods used in the design and construction of systems and appropriate consideration of the system's intended environmental factors. The steps involved include the following: Categorize the system or item into constituent components. Define the system or item life environments and consider the effects of environmental factors on the constituent components. Where possible, examine quantitative estimates of dormant failure rates for indications of potential problems. Use published guidelines and checklists for dormant system design considerations. Categorize the System\/Item Into Constituent Components The item under consideration should be itemized by its constituent parts down to the \"component,\" material, and electronic piece-part level, if possible. For the purposes of this guideline, a component is defined as a functional unit viewed as an entity for analysis, manufacturing, maintenance, or record keeping tasks. Materials, parts, and components used in the system may also be characterized into the following general types when in the nonoperating or dormant states: Components or parts with indefinite nonoperating lives which are subject to \"random failure\" mechanisms (Type A). Electronic parts and components are usually associated with this characteristic. Materials and components which degrade at a slow but relatively predictable rate over time (Type B). Many electromechanical and mechanical components, pyrotechnics, and organic materials can be considered to exhibit this characteristic. Materials and components which have known, relatively short, limited shelf lives (Type C). Items with this characteristic are generally well known: batteries, some solar panels, gas generators, etc. Type A Devices The principal failure mechanisms for electronic equipment and parts occurring during non-operative phases of the part's life are caused by latent manufacturing defects or deficiencies in materials rather than specific aging mechanisms. As a result of these latent manufacturing defects, environmental conditions and stresses act upon these defects until sufficient conditions exist for degradation failure to occur. One of the most effective ways to reduce these types of failures is to subject the component or assembly to programs such as environmental stress screening (ESS). Programs such as these should be capable of detecting failure mechanisms including defects in bulk material, metallization, final seals, wire bonding, glassivation, die bonding, oxide, and diffusion as well as general contamination problems. However, an ESS program should be carefully designed to restrict the environmental excursions and stress cycles so as to not induce incipient failures. Types B and C Devices and Materials In general, nonorganic materials such as metals deteriorate by electrochemical processes, and organic materials deteriorate by chemical reactions. Most organic materials used in spacecraft are long-chain polymeric compounds which degrade through the breakdown of the compound into smaller, more volatile fragments, making polymers the most likely to be affected by the vacuum of a hostile space environment. Therefore, organic materials exposed to a vacuum may decompose into volatile products in warmer areas, and redeposit onto relatively cooler surfaces. If the cooler surfaces are thermodynamically or electrically conductive by design, a malfunction is likely to occur. Of particular concern are failure modes that occur because of plasticizers redepositing onto exposed relay contacts preventing proper closing of the circuit. In the absence of oxygen, polymers are more stable at elevated temperatures. However, nylons, polysulfides, cellulosics, acrylics, polyesters, epoxies, and urethanes possess unstable properties in low-pressure or vacuum environments. The stability of the polymer in a vacuum is dependent upon formulation and curing procedures used during the manufacturing processes where plasticizers, mold lubricants, and polymerization catalysts are generally detrimental to long-term reliability. Therefore, the use of devices constructed with polymers that use these agents should be avoided. Nevertheless, exposure to vacuum conditions generally causes no loss of engineering properties in seals or gaskets unless an appreciable loss in mass occurs. Define the System or Item Life Environments and Consider the Effects of Environmental Factors on the Constituent Components The designer should identify and develop the environmental operating conditions and factors that will apply to each phase of the item's life cycle. For instance, if an item is to be stored in a warehouse for most of its life cycle, the environment it sees would be significantly different than a component on an orbiting satellite. The primary environmental factors encountered during storage or nonoperating phases of space systems are listed below. High Temperature Extremes Low Temperature Extremes Temperature Cycling Moisture Low Pressure (Vacuum) Atmospheric Pollutants Thermal Shock Nuclear Radiation Electromagnetic Fields Corrosion Solar Radiation\/Atomic Oxygen Mechanical Shock\/Vibration Mechanical Shock\/Vibration Bacteria, Fungi Static Electrical Charges The relative stress levels experienced by individual components or assemblies during a dormant period are very greatly reduced from operating levels. Consequently, designs for dormant reliability must focus much more heavily on understanding the failure mechanisms which will be experienced in the dormant environments, the factors which cause each of the failure mechanisms to occur, and methods for controlling the occurrence of the failure mechanism. The most important environmental stresses produced by the environmental factors encountered in dormancy are mechanical, chemical, and low thermal (Reference 8). The mechanical stresses are primarily due to inertial forces (during transportation and handling) and thermal-mechanical interactions which introduce differential expansion between materials within a device and between subassemblies and interconnections. Diurnal- and\/or orbital-induced temperature cycles should therefore be as small as possible. Chemical stresses are primarily influenced by contaminants such as halogen ions, residual process chemicals, and water (moisture). In fact, moisture within a device or assembly package is the most important factor for both corrosion and mechanically induced failures (Reference 8). There is a substantial number of design techniques and methods to mitigate the effects of these environmental factors found in sources such as References 7 and 8. Radiation particles, ultra-violet wavelength light exposure, and atomic oxygen are all detrimental to exposed polymeric materials. Solar flare emissions will probably affect exposed surfaces of the materials more sensitive to radiation damage. The results of the Long Duration Exposure Facility have recently been released and indications are that low Earth orbits cause significant wear and erosion to exposed materials. Kapton seems to be highly susceptible to atomic oxygen, and erosion of silverized Teflon is somewhat more than that predicted by ground-based tests. Examine Quantitative Estimates of Nonoperating Failure Rates of Items Considering the Appropriate Environments Examination of historical failure rates of similar items may provide indications of areas for concern. For electronic parts and other mechanical items classified as Type A items, several publications provide methods and historical data for estimating a failure rate in a dormant or nonoperating state. Reference 7 provides a compendium of models for estimating the failure rate for various types of components as a function of environment, part type and quality level, and ambient temperature similar to the methods used in MIL-HDBK-217. Values for base failure rates and modifying parameters were derived from numerous field data sources (which are primarily missile and aircraft system information), and are delineated in the document. Other documents (e.g., Reference 4) also provide estimates of the nonoperating or dormant rate of failure for components that have been derived from historical field and test data. The general characteristics of the failure properties of Types B and C items can usually be described as a period of fairly low rate of failure followed by an increasing propensity to fail as the item begins to degrade or wear out. Therefore, constant failure rates are not applicable to these items, and the designer should consider sources or methods for estimating the life limits or life parameters. Mathematical equations for calculating the individual component reliabilities over a prescribed mission time may also be used. In less complex systems, appropriate reliability block diagrams may be used to aggregate the component reliabilities and to derive the likelihood of the system being able to perform its function over a specified period of time. However, the inherent uncertainty involved in applying the observed nonoperating failure rates of older technology parts to more current components limits the ability to provide an accurate specification for system reliability over long time periods. Use Published Guidelines and Checklists for Dormant System Design Considerations The designer is urged to use published sources such as \"Reliability\/Maintainability\/Testability Design for Dormancy,\" (Reference 8) that provide detailed design guidelines and checklists for reference when designing systems for storage or long periods of nonoperation. Table 1 lists some of the general points that should be considered from an overall system viewpoint. Table 1. General Dormant Reliability Checklist Yes No N\/A Has a packaging, transportation, handling, and storage environmental analysis been completed? Has the dormant mean time between failure attained in service been used as a criterion for component selection? Have the major dormant\/storage failure modes and effects been analyzed? Are adequate integrity checks identified for uncovering dormant\/storage failures prior to flight? Can dormant\/storage failures be readily detected and isolated? Will the equipment withstand any natural combination of the dormant\/storage environments(e.g., shock vibration, acceleration, temperature cycles, humidity, and atomic oxygen.) in the intended application? Have the restrictions in employing dissimilar metals in intimate contact been considered? Have thermal stresses and differential thermal expansion been considered? Is aging a factor considered? Is the production process likely to degrade the dormant\/storage reliability? Are provisions made to prevent the entrapment of moisture or other fluids? Do protective coatings meet requirements? Are limited-life items identified? Was corrosive degradation considered? Technical Rationale: When designing systems with aspects of dormancy in their life cycle profile, consideration must be given to degradation and failure while in the nonoperating state. Items can and will fail during periods of nonoperation. Dormant reliability is defined here as the probability (or likelihood) that an item or system will operate as intended after undergoing a long period of inactivity or nonoperation. Dormant systems may spend 90 percent or more of their life cycle profile in environments that may be detrimental to their survival. Environmental stresses, as well as aging effects, will precipitate failures just as do stresses during operating periods. References: AFWAL-TR-83-2079, \"Weibull Analysis Handbook,\" Air Force Wright Aeronautical Laboratories, United States Air Force, Wright-Patterson AFB, November 1983 EERD-3, \"Nonelectronic Parts Reliability Data,\" Rome Air Development Center, Reliability Analysis Center, 1986 MIL-STD-1540B (USAF), \"Military Standard Test Requirements For Space Vehicles,\" October 10, 1982 NONOP-1, \"Non Operating Reliability Databook,\" Rome Air Development Center, Reliability Analysis Center, 1987 NPRD-3, \"Nonelectronic Parts Reliability Data,\" Rome Air Development Center, 1985 PRC-R-4416, \"Analysis of In-Flight Spacecraft Performance and Anomaly Data,\" October 1984 RADC-TR-85-91, \"Impact of Nonoperating Periods On Equipment Reliability,\" Rome Air Development Center, May 1985 RADC-TR-88-110 \"Reliability\/Maintainability\/Testability Design For Dormancy,\" Rome Air Development Center, May 1988. SD-TR-86-02, \"Analysis of Orbital Satellite Stage,\" Air Force Systems Command, November 1985. \"Dormant Reliability Awareness Seminar,\" The BDM Corporation, May 1986 \"RADC Reliability Engineer's Toolkit,\" Rome Air Development Center, July 1988 Fisher, Dr. William F., and Price, Charles R.: \"Space Station Freedom External Maintenance Task Team Final Report,\" July 1990 \"Reliability & MIL-HDBK-217 Prediction,\" Reliability Review, Volume 10 pp. 7-9, September 1990 Reliability Preferred Practice No. PD-EC-1101: Environmental Factors","Lesson ID":684}
{"Driving Event":"This Lesson Learned is based on Reliability Guideline Number GD-ED-2206 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: The design data provides a list of materials and conditions which are compatible for use with fluorine. The use of this data by design engineers will result in the selection of materials for use with fluorine that can provide safe and reliable system operation. Implementation Method: Generally failures in systems using fluorine are caused by: (1) improper choice of materials and\/or system components; (2) improper fabrication and assembly practices, (ref 1); and (3) improper system preparation and operating procedures, resulting in the presence of contaminants. This guideline applies design considerations to preclude failures caused by improper choice of materials. Design guidelines to address failure causes (2) and (3) are beyond the scope of this document (see Reference 1). The design considerations to be used in selection of materials for use in fluorine systems should consist of: Selection of materials based on property requirements for the application (e.g., strength, thermal properties, welding or brazing characteristics, etc). [Note: This design consideration represents standard design approach and is presented here for completeness only] Selection of materials that can be fabricated without introducing contaminants and\/or entrapped voids. Consideration of effects peculiar to a fluorine environment (e.g., ignition temperature of material in fluorine, fluoride films and exposure to friction, moisture presence and compatibility with hydrogen fluoride, etc). The design considerations of (b) and (c) above are based on extensive test experience from liquid fluorine rocket testing conducted at LeRC, and from materials tests conducted at LeRC and other laboratories. References 1, 2, and 3 present material compatibility with liquid fluorine for metallic and nonmetallic materials, respectively. Table 1 below, extracted from reference 1 and presented here for purposes of illustration, lists the ignition temperatures and ignition delays for metals in fluorine. Table 1. Ignition Temperatures of Metals in Fluorine (a) Technique A Metal Wire diameter, in. Ignition temperature, \u00b0C Average ignition temperature, \u00b0C Max variation from average, percent Aluminum 0.010 0.016 ---- (a) --- Copper 0.0123 645 to 747 692 8.0 Iron 0.014 667 to 677 672 0.8 Molybdenum 0.0149 188 to 220 205 8.3 Monel 0.010 348 to 437 396 12.0 Nickel 0.008 0.0155 0.0154 0.0152 1168 1096 1219 1084 1162 6.0 Stainless Steel 302 0.020 570 to 796 681 13.0 Tungsten 0.0153 260 to 332 283 18.0 Table 1. Ignition Temperatures of Metals in Fluorine-Concluded (a) Technique B Metal Wire diameter, (in) Max wire temperature \u00b0C Ignition delay, sec Ignition temp range \u00b0C Activation energy, kcal\/mole Copper 0.012 905 852 810 767 701 689 0.8 1.0 0.6 0.8 1.2 No ignition 689 to 701 39.5 Iron 0.014 730 676 648 644 618 1.0 1.6 2.0 2.2 No ignition 618 to 644 16.3 Nickel 0.015 1357 1306 1266 1253 0.6 1.2 0.6 No ignition 1253 to 1266 --- The data for Table 1 was obtained from tests using two techniques, techniques A and B. In technique A, an evacuated bomb was filled with gaseous fluorine at atmospheric pressure and the fluorine was increased in temperature by a heated wire. The temperature at which the wire burned is listed in the part of Table 1 for technique A. In technique B, the evacuated bomb was brought to temperature before fluorine introduction. The time required for the reaction to go to completion, the ignition delay, is listed in the part of Table 1 for technique B. In addition, Table 2 was produced from Reference 1 which shows an expanded list of materials and their reactive effects with fluorine. Reference 1 also includes the effects of the presence of water and corrosion, the effects of fluoride films and their characteristics, and specific reaction of fluorine spills. Table 2. Compatibility of Materials in Fluorine Aluminum and aluminum alloys An aluminum trifluorine (AlF3) film is formed on the surface of the surface of the metal or alloy. The melting point of aluminum is below its ignition point with fluorine gas. Iron, iron alloys, steels Ferrous and ferric films are formed at a higher rate and depth than other mild resistant metals. Reaction from moisture and hydrogen fluoride is also greater. Stainless steels Resistant to attack by hydrogen fluoride is greater than most mild steels. A fluoride film is formed with characteristics equivalent to Monel. The film becomes less stable at elevated temperature. Stainless steel welds behave similarly as the parent material. Nickel (A, D, and L), Nickel bearing alloys, & Monel Fluoride films are similar to that on aluminum, but are stable for use at high temperature (1200\u00b0F). Welding does not reduce the corrosion resistance of nickel or Monel if fluxes either are not used or are completely removed. Inconel, Illium, Illium \"R\", and Duranickel are less resistant than either nickel or Monel at higher temperatures but are generally similar to stainless steels. Copper Highly resistant to fluorine attack as are the copper alloys, red brass, and yellow brass. Cupric fluoride film is very stable in the presence of dry fluorine or dry hydrogen fluoride, but hydrolyzes readily in moisture to form hydrofluoric acid. Titanium Poor resistance to hydrogen fluoride. Liquid fluorine has the tendency to be highly reactive with titanium. Gaseous fluorine will attack titanium at temperatures above 300\u00b0F. Silver solder: Nicrobraze Recommended for most of the joining where welding is impractical or impossible. Connections made with this material have been highly reliable. Chromium Four fluorides are formed: 1) divalent, 2) trivalent, 3) tetravalent, and 4) pentavalent (3 an 4 are volatile). When chromium is reacted with fluorine below 300\u00b0F it forms a protective divalent fluoride film. Above 300\u00b0F, the fluoride is converted from a divalent to a volatile tetravalent fluoride form and loses its protective ability. Beryllium Behaves much the same way as nickel in fluoride film formation. Tantalum should not be used at temperatures above 150\u00b0F Lead Forms a nontenacious fluoride film. In passive exposure it has been used successfully as a seal or gasket material. Tin Reacts similarly to lead and can also be used for soft gaskets in cryogenic service. Rhodium, palladium, platinum Can be used on contact with fluorine at room temperature generally without attack. These metals are used in some equipment because they are inert to hydrogen fluoride. The list in the above table shows a variety of metals which are compatible to a certain degree in fluorine. Generally nonmetallic materials are incompatible with fluorine, with the exception of ruby and Teflon (see References 1 & 3). It should be understood by the designer that material selection is dependent on the environmental conditions. To assist the designer in developing a safe fluorine system, Table 3 lists recommended materials to be used under certain operating conditions. Table 3. Recommended Materials for High and Low Pressure Operations HIGH AND ATMOSPHERIC PRESSURE OPERATIONS Materials Preferred High Pressure: (>14.7-1500 psi.) Nickel or Monel More resistant to ignition than steel. These metals are preferred when handling pure fluorine under pressure. Monel piping can even be used at higher pressures than Nickel. Atmospheric Pressure: Copper, Iron, Stainless Steel, and Brass If the piping wall thickness is adequate, i.e., as in standard or extra-strong pipe, the material weight and surface area are large enough to eliminate spontaneous combustion. High & Low Pressure Connections: Welding, Flange joints Through experiments, welding has proved to be highly reliable in high and low pressure. Soft solder and fluxes should not be used, however. Flange joints are preferred when necessary, gaskets must be limited to soft metals, lead, tin, copper or aluminum. Valves Bellows-sealed valves generally can be used up to 100 psi., in 1-inch and larger sizes. The Hoke Monel needle valves or the Kerotest 440-A packed with Teflon or its equivalent have been successful. Metal-seated valves with Monel or aluminum-bronze seat-and-disk combinations have also been used successfully for low pressure valves. Technical Rationale: Certain effects peculiar to a fluorine environment need to be considered by the designer. Fluorine is a highly reactive oxidizing agent; it has the highest oxidation potential of all elements. Fluorine can react with practically all organic and inorganic substances with few exceptions. Exceptions include the inert gases, fluorinated compounds in their highest state of oxidization, and a few fluorinated polymers. Whether a substance will burn spontaneously in fluorine, or whether fluorine will replace an oxidant having a lower oxidizing potential, depends on the following conditions of exposure, (Reference 1): Initial temperature of the region. Reaction is initiated by reaching the ignition temperature or by providing activation energy from impact, friction, high flow, or reaction of contaminants. Initial pressure of the region. It has been found that ignition temperatures are lowered by increasing pressure. Thermal conductivity if the material is a solid. Combustion will not occur if heat of reaction can be removed by conduction and the temperature can be maintained below ignition temperature of material. Exposed surface area with respect to mass of the substance. Generally, surface reactions with most metals will form a fluoride film and inhibit further reaction. Large exposed surface-area-to-mass material forms (fine mesh screen, powered metal, etc.) can have surface reactions that are highly reactive and can increase temperatures to initiate combustion. Kinetic or static exposure. It has been found that kinetic energy from flow dynamics can contribute to activation energy for combustion. Fluorine concentration in the region. Reactivity increases with increased fluorine content of liquid or gaseous mixtures. Fluorine can react combustively with water depending on the size of water droplets. Ice will react combustively with liquid fluorine. In the presence of water, the fluorine will react to form hydrogen fluoride potentially resulting in corrosion. Therefore, the entry of water into the system in any form, even from non-dry purge gases or moisture laden air, is to be avoided. In addition to the selection of materials based on property requirements for the application (i.e. strength, thermal properties, welding or brazing characteristics, etc), the selection of materials for use with fluorine must consider the introduction of contaminants into the system and whether a given material will burn spontaneously in the presence of fluorine. Materials selected must be cleaned free of contaminants and fabricated without introducing contaminants and\/or entrapped voids. The contaminant can be in the form of a material additive or foreign material (ice, moisture, grease, soil, etc.) which unintentionally enters the system. The contaminant can then react with fluorine and cause local temperatures to exceed the ignition temperature for that part of the system, resulting in failure. The presence of voids can lead to trapped contaminants that escape cleaning procedures and therefore must be avoided. References: Schmidt, H. W.: \"Fluorine and Fluorine-Oxygen Mixtures in Rocket Systems,\" NASA SP-3037, 1967. Schmidt, H. W.: \"Compatibility of Metals With Liquid Fluorine At High Pressures and Flow Velocities,\" NACA RM E58D11, 1958. Price Jr., H. G. and Douglass, H. W.: \"Nonmetallic Material Compatibility With Liquid Fluorine,\" NACA RM E57G18, 1957. Slesser, Ph.D. Charles and Schram, Stuart R.: \"Preparation, Properties, and Technology of Fluorine and Organic Fluoro Compounds,\" McGraw-Hill, New York, 1951.","Lesson ID":686}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1202; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefits: Process controls on design, manufacturing, and testing operations reduce component failure rates and improve reliability. The goal is production of power supplies that will operate in space for the mission duration. Implementation Method: There are special requirements in packaging HV power supplies for space use. The power processor should be voltage-partitioned and the low voltage circuits should be separated from the high voltage circuits. This is usually done with a metal wall. There still will be signals transmitted between the sections. All grounds should be isolated to provide a means to predict the currents when transients or arcs occur. When capacitors discharge, there can be current flows of several hundred amperes. The low voltage section should be protected from these current and voltage surges. Table 1 shows recommended design practices used for an 11 kV CTS TWT power supply. All volumes must be vented. The pressure in any unvented volume will decrease gradually and result in corona or arcing. Allow for screens, RF traps, etc.; and count only the holes in the screens. Interior volumes, down to the capped nut plates, must also be vented. Table 1. High Voltage Power Supply Design Guidelines PHYSICAL LAYOUT Voltage Partitioning (Separate high and low voltage components) Isolated Grounds (Provide known current path for transients) Voltage Suppression (Suppress signal from high voltage to low voltage circuits) ELECTRIC FIELDS Solid Dielectric: DC Stress 50 Volts\/MIL AC Stress 10 Volts\/MIL Surface Creepage 8 Volts\/MIL Air or Vacuum Gap 20 Volts\/MIL VENTING >2 cm2 per 1000cc of enclosed volume (screens and RF traps reduce vent size), including: Capped nut plates Dielectric spacers Polyolefin shrinkable tubing High voltage connectors Figure 1 shows the fabrication methods used to build this supply. Round off all edges on metal as well as dielectric materials. Use anti-corona spheres. Void-free encapsulation is important. Remove excess RTV from bolts to keep vent paths open. Use shrink tubing in strips for hold downs, to avoid trapped air. Dielectric separators must be sized correctly for surface creepage. Anti-corona spheres should have a vent hole to eliminate voids in the solder. Dielectric inserts should be slotted to vent the interior volume. [D] Figure 2 illustrates the special construction methods used in the HV compartment for the equipment to operate in the thermal and vacuum environment of space. Table 2 shows the testing methods that should be used to check out the HV power supply. The glass epoxy boards should be scanned ultrasonically to check for density differences. The transformers and components mounted on the boards should be corona-tested. Corona discharges of less than 5 picocoulombs are allowed. Induced voltage in the dielectric testing should be done in vacuum at temperature per MIL-T-27. The corona tests should be repeated to detect internal degradation from the high voltage stress. Be careful to bake out the components at 65 degrees C for 72 hours in the vacuum chamber and cool the components down before the power supply is turned on. [D] Table 2. Testing Corona testing: Transformers Component Configuration on Boards <5 Picocoulombs Electric Testing: Induced voltage (twice-rated voltage) Dielectric withstanding (2.5 times rated AC and DC) Important to perform in vacuum at temperature Thermal Testing: Minimum of 10 temperature cycles at component level Minimum of 3 temperature cycles at box level Initial thermal-vacuum test preceded by bakeout of 65\u00b0C for 72 hours Ultrasonic Scanning of Glass Epoxy Boards (NASA TM X-73432) Technical Rationale: These design criteria were developed experimentally. The various component configurations, board layouts, and component assemblies were tested to 125% of expected working voltage in air, vacuum, and full operating temperature with a requirement that the corona inception measured less than 5 picocoulombs. An example of an early flight failure caused by corona was a short that developed between two pins of a high voltage connector. Gas trapped inside connector voids gradually decreased in pressure until corona discharge began to decompose the insulating material. When the insulating material thickness was reduced to the point that leakage started increasing, a carbon tree formed and a short occurred, disabling the experiment. This can be easily avoided by running corona tests on all high voltage parts to ensure that no gases are trapped in high voltage circuits. References: MIL-T-27, quotTransformers and Inductors (Audio, Power and High-Power Pulse), General Specification for,quot August 8, 1987. NASA CP 2159, quotSpacecraft Transmitter Reliability,quot September 1979. NASA TMX-3287, Lalli, Vincent R., Nueller, Larry A., and Koutnik, Ernest A., quotSystem Reliability Analysis Through Corona Testing,quot September 1975. Presented at Power Electronics Specialist Conference (sponsored by IEEE), Culver City, CA (June 9-11, 1975). NASA TMX-73432, Klima, S. J. and P. J. Riley, quotUltrasonic Evaluation of High Voltage Circuit Boards,quot June 1976. NAS3-17782, Cronin, D. L., quotModeling and Analysis of Power Circuits,quot TRW Systems Group, June 1975. NAVMAT P4855-1, quotNavy Power Supply Reliability Design and Manufacturing Guidelines,quot December 1982. Foster, W.M., quotThermal Test Report for the Space Acceleration Measurement System Circuit Boardsquot, NASA Lewis Code 6730 Internal Report, November 1987.","Lesson ID":677}
{"Driving Event":"This Lesson Learned is based on Reliability Guideline Number GD-ED-2204 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefits: Reliable hardware and software can be designed and developed in a shorter time and at a lower cost and at a short schedule if maximum use is made of a computer-aided concurrent engineering techniques. Operational, manufacturing, assembly, quality, reliability and safety considerations can easily be interjected at the beginning of the design process through the prudent use of the team approach, aided by computer based rapid prototyping techniques, methods, and tools. Implementation Method: Background: Concurrent engineering is the simultaneous and integrated engineering of all design, manufacturing, and operational aspects of a project from the conceptual formulation of the project through project completion. It is a team-engineering process in which all of the specialists who normally get involved in a project combine into a multi-disciplinary task force to carry out a project. They work together, trading ideas, and ensuring what they do early in the project (like major design decisions or changes) will not adversely affect what they do later (like quotmanufacturing inquot quality or supporting flight operations). All disciplines are addressed simultaneously. Until the advent of high-powered, networked computers and communications systems, effective concurrent engineering was an ambitious goal, particularly for large, technically complex aerospace projects. The advent of interactive three-dimensional computer-aided design, solid modeling, simulation, and virtual reality methods has created a naturally adaptive environment for the complex interactions that are required in a truly effective concurrent engineering process. This guideline describes the desirable elements of a successful concurrent engineering process and enumerates the ways computer-aided techniques can facilitate the effective meshing of the simultaneous engineering process with currently available design, analysis, processing and image processing tools. The Concurrent Engineering Process: A key to the success of the concurrent engineering process is to gather together a complete and competent team to carry out the project. All disciplines that will be affected by the hardware and software configurations must be represented. Typical engineering disciplines that must be represented on a concurrent engineering team are: flight hardware or software design, mission operations, manufacturing and assembly, tooling and fixture design, and safety and mission assurance. As shown on Figure 1, consideration of each of these disciplines, coupled with the client, user, or customer requirements is the key to a successful integrated design. The fully integrated design is then subjected to process engineering and production functions to provide operational hardware and software. Concurrent engineering teams must be encouraged to develop a free flow of ideas between team members. The object of the team approach is to provide an environment in which potential problems can be easily and quickly exposed to creative and synergistic problem solving by the innovative engineering and design processes of the team itself. To do this, the hardware and software configurations under consideration must be communicated to all team members with equal rapidity and understanding. This is where computer-aided solid modeling, simulations, kinematic modeling, virtual reality, and graphical computer-aided engineering analysis techniques come into play. [D] The Use of Computer-aided Concurrent Engineering Methods: In recent years, computer-aided design tools that have become available have augmented, and in many instances, replaced the design\u2014build\u2014test, design\u2014build\u2014test cycle. A master model usually takes the form of a three-dimensional, color image of the element, mechanism, system, or component being developed. Software programs now available can be programmed to interface (in varying degrees of seamlessness) with this master model to perform a wide variety of engineering functions. The resulting refined master model can be used to define, design, and provide manufacturing and operational control codes for the tooling, fixtures, and the element itself. On-screen, three-dimensional animated simulations are made possible through sophisticated software coupled with high-speed computers. In many instances, effective use of these simulations will eliminate the need for hard mockups, operational models, and engineering prototypes. High reliability, and a shorter development cycle, are feasible through the use of these systems. Computer Modeling and Integrated Engineering Analysis: Through the use of three-dimensional solid modeling and related computer-based kinematic and dynamic analyses, interference analysis and interface checking can be automated. Engineering analysis procedures such as structural and thermal finite element analyses, mass properties analyses, tolerance analyses, and ergonomic studies can be performed using the master three-dimensional model as an input to currently available engineering analysis software modules. Motions and forces generated in simple or complex mechanisms can be derived accurately without building and testing the actual hardware. Virtual imaging and virtual reality interactive displays can help the concurrent engineering team to establish valid mechanical or human interfaces. Simulations of the robotic mechanisms interaction personnel and with hardware can yield off-line programming codes that will control robots. Three-dimensional solid models of aerospace structures have proven useful for the routing of electrical or fluid lines, the confirmation of manufacturing and maintenance access to structures, and the design of master tooling and fixtures. Rapid transmission of structure designs to other disciplines (propulsion, electrical, manufacturing, and quality) has speeded up the process of team engineering design. Simultaneous electronic linking of documents and specifications with hardware designs and software coding has enhanced traceability and data compatibility with designs in rapidly changing configurations. Solid, three-dimensional prototypes can be created directly from a three-dimensional computer image through stereolithography and laser-fused deposition techniques. The design and configuration of tooling, fixtures and prototypes of these elements can be created through interaction with the master model, and machine instructions can be generated that will produce the master model. Thus, engineering designs can be rapidly converted into manufacturing aids and control codes. By linking engineering, project management, and work flow information to computer aided drawings and models, the speed and reliability of product data management, file management, and work process flow management can be enhanced. Real-Time Participation of the Concurrent Engineering Team in the Computer-Aided Design and Development Process: Availability and proper use of currently available computer-based systems can significantly improve the communication of engineering information among members of the concurrent engineering team. Each member is able to view parts, components, subsystems, and system, as they appear in final form well before hardware is built. Thus, interfaces and interactions between system elements and disciplines can be significantly enhanced. General guidelines for optimum use of these techniques and methodologies are as follows: In planning multiple-organizational support of the computer-aided concurrent engineering process, strive for standardization in the following areas: The manner in which computer-aided drawings and models are identified, constructed, and filed. The color coding, layer designations, scale, symbols, graphic ground rules, and format of computer-aided design documents. The quothandshakingquot between computer-aided capabilities of participating organizations. Provide rapid transmission or networking of information and central displays of pictorial, graphical, and text information about the project for concurrent review by all key concurrent engineering design team members. Provide configuration management controls for the master model, with free access for viewing, analysis, and alternate design creation. Put prudent restrictions on changes to the master model. Provide more time in the beginning stages of a project to allow the interactive design process to operate. Permit this longer initial concept definition and design phase to create a faster production and operations phase by freezing the design once all engineering interactions and considerations have been thoroughly input, negotiated, and established. Technical Rationale: The concurrent engineering process by its nature does not require the normal control and review activities historically performed in the management of product development. The degree to which the concurrent engineering process is empowered to proceed with parallel process actions is believed to be directly proportional to potential schedule, cost, and reliability improvements. The use of concurrent engineering practices, coupled with the application of current state-of-the-art three-dimensional solid modeling and analysis tools, has proven to dramatically reduce new project development times while maintaining or further improving quality, reliability, and safety. MSFC has implemented several projects using concurrent engineering techniques and has reduced to practice several software and hardware elements using computer based three-dimensional kinematic and dynamic analysis. Although the project development teams now in operation have not yet completed the development cycle, the concurrent engineering process is working smoothly. Beneficial results are expected. Manufacturing and refurbishment cells using robots that were designed and programmed with kinematic and dynamic simulation techniques were put into operation in record time and are producing high quality results. References: Ashley, Steven: quotDARPA Initiative in Concurrent Engineering,quot Mechanical Engineering, ASME, New York, NY, April 1992. Aukstakalnis, Steve: quotVirtual Reality and Experiential Prototyping of CAD Models,quot Design Net, Ariel Communications, pp. 62-65, January 1992. Babai, Majid et-al: quotMobile Robot Hydroblast System, CAD\/CAM, Robotics and Factories of the Future,quot pp. 350-355, Southbank Press, London, 1991. Bein, Christopher: quotRobot Simulation and Manufacturing, Aerospace Engineering,quot SAE, pp. 11-13, October 1992. Edwards, David E.: quotInteractive Computer Graphics,quot Aerospace America. AIAA, New York, page 41, December 1992. Hartley, John R.: quotConcurrent Engineering,quot Productivity Press, Cambridge, MA, 1990. Hedberg, Sarah: quotConcurrent Engineering,quot The Spang Robinson Report on Intelligent Systems, Vol. 8, No. 4, Wiley, New York, NY, April 1992. Hurwitz, Ken: quotIntegrating 3-D Solids in Design,quot Design Net, Ariel Communications, pp. 49-51, Austin, TX, January 1992. Kramer, Bill: quotThe CAD\/CAM Link to DFM (Design for Manufacturability),quot Design Net, Ariel Communications, pp. 17-51, Austin, TX, February 1992. Kusiak, Andrew: quotConcurrent Engineering: Automation, Tools and Techniques,quot John Wiley & Sons, New York, NY, 1992. Park, Brian V.: quotConcurrent Documentation,quot Design Net, Ariel Communications, pp. 25-30, Austin, TX, January 1992. Wahlin, Greg: quotIntelligent Interference Checking,quot Design Net, Ariel Communications, pp. 35-38, Austin, TX, June 1992.","Lesson ID":681}
{"Driving Event":"This Lesson Learned is based on Reliability Guideline Number GD-ED-2209 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Increases confidence in designs and their operational reliability. Ensures accuracy of design analyses, completeness of requirements in procurement documents and thoroughness of test planning. Ensures functional compatibility of assembly and test fixtures. Implementation Method: Designs must factor in effects of the space environment. Relevant differences between ground test conditions and flight deployment should be identified for consideration at the design and test stages to assure operation with adequate margins. G-negation pickup points can be designed in. Historically, some deployables have passed ground tests but failed in space. Space imposed conditions include thermal gradients and thermally induced loads, outgassing, low moisture, zero gravity and ballooned thermal blankets. Handbook material values do not always apply for the space environment. Physical parameters vary such as solid film lubricant friction which varies with moisture content. The space environment is not easy to simulate in earthbound tests and allowance should be made for expected parameter variations. Deployed appendages should be designed using the following guidelines: Avoid complication; simple designs are more reliable. Avoid single point failures. If unavoidable, assure generous margins. Where practical, design them out or employ redundancy unless redundant complication reduces reliability. Assure redundancy is truly independent, not coupled. Margins - Provide minimum torque\/force margin: Tt = 1.25 Tf + 4.0* Tv where: Tt = minimum total available torque\/force Tf = fixed and non-variable loads such as Ia terms Tv = worst case variable torques\/forces such as coulomb friction and other loads which vary with environmental conditions and operating life. *Factor 4.0 is the Design Goal, reduced where excessive mass, power or volume is required, e.g., motor driven mechanisms. Maintain a minimum factor of 2.0 under worst case degraded conditions. Force analyses should use best available loads and forces and examine the full range of expected minimum and maximum parameter values, make adequate allowance for uncertainty. Torque requirements are higher with high friction, deployment velocity and momentum higher with low friction. Use test verified values where available for such critical parameters as friction (if only handbook values available, multiply by 3 to cover uncertainties), cable flexure torque, bearing drag torque. Include worst case thermal effects, wearout, friction changes and end-of-life conditions. Designs should tolerate moderate increases in friction. Maintain calculated torque\/force margins above 2 with m assumed up to 0.5 for typical material combinations. Friction force estimates are untrustworthy, handbook values represent controlled conditions. Use cautiously, test if possible. Consider case differences between published numbers and actual conditions such as effects of part surface treatments, differences between ground test conditions and space environment (humidity, pressure, loads). Use appropriate fits, alignment tolerances, surface treatments, deburring and hardness differentials to avoid galling which nullifies friction estimates. Temperature effects at deployment should be accounted for, e.g., torque\/force changes at hingelines and separation points from temperature gradients within assemblies, bulk temperature effects and differential temperatures between deployables and mounting structure. Humidity effects, e.g., molybdenum disulfide (MoS2) friction varies and nonmetals change size with moisture content, can affect torque margins and fit clearances. Moly lube should not contain graphite. Rolling element bearing loads for long life devices should be kept below 320,000 psi mean Hertzian stress for launch, 200,000 psi or lower for operation, less if lubrication is marginal. Consider effects on bearing preload, torque and life due to thermal gradients and bulk temperature variations. Analysis. Loads analyses and load sharing between deployed appendages and spacecraft structure can be greatly affected by compliance of typical appendage joints. Examples are bolt preloaded joints, separation joint clamping devices, bearing supported hinge lines, and movable mechanical joints such as gimbals and solar array drives. Accurate stiffness knowledge of these devices is crucial for valid loads analyses. Verification and validation should be addressed in design, and plans made to acquire sufficient data to verify models. Kinematic diagrams should be constructed including all degrees of freedom and constraints. For accurate loads and stress analyses, assure correct component parameters are used in the Finite Element Analysis (e.g., bearing stiffness, friction coupling, compliance of bonded joints, stiffness of movable joints - clearance fit or preloaded, transmissibility across joints). Perform loads analysis based on true compliance of individual members for accurate assessment of load sharing. Cross-check with deflection analyses, compare with measured values. Incorporate proper deployment angles, velocity, acceleration and impacts to size components with adequate predicted margins. Include critical component parameters in analysis based on actual measured unit data where possible, eg. bearing friction, compliance of assemblies. Account for fabrication and assembly variables which affect design parameters used in analysis. Evaluate zero-g case to determine impact on design and verification. Jerking (non-uniform acceleration) can be critical in deployment. Its effects should be evaluated. Stick-slip friction conditions can worsen the condition. Stowed and deployed frequencies should be evaluated. These affect launch loads and Flight Attitude Control. Separation Planes Employ kickoff springs where practical in the separation joints; especially important for long appendages. Use anti-seize, anti-weld coatings, dissimilar materials. Provide retention joint flexure capability to accommodate launch loads, e.g., spherical, vs conical cup-cones. Assure adequate dynamic envelope clearance. Use the following guidelines for wire and cable routing at hingelines. Mechanical design of appendages should allow cabling across the hinges to be left fixed and undisturbed after component deployment testing throughout spacecraft assembly and integration. Provide field joints for connection of hinge and cable subassemblies. Minimize flexure torque through entire travel, allow for temperature effects. Test new designs. Use wire guides and clamps, braided and laced cables to maintain free loop control in 1g testing and launch environment and to avoid snags during deployment. Control chaffing during deploy and stow tests and launch vibration. Use proper cable clamp size for no-slip position control and cushioned clamps for Coax cables. Control Coax cable minimum bend radius. Coax Cable Protection during Component Assembly and Integration and Test Design-in armor protection where possible. Provide takeup allowance for connect\/disconnect without cable kinking. Train personnel in correct handling procedures. Follow planned Coax cable handling procedures, use safe temporary support when free ends are not connected, provide for safe and gentle tie-down, prevent crush. Sharp Edges Eliminate sharp corners that cut through lube coatings, produce galling. Use specific drawing callout to control break and blend of sharp corners on moving elements. This is not always covered by general drawing callouts or implemented under General Workmanship Standards. Double-check workmanship during assembly; visually inspect for sharp corners, handcheck running fits and clearances and verify clearance of chamfers to inside corners. Contamination Control Design-in labyrinth or contact type seals to contain lubricants, minimize outgassing and limit external contamination. Limit Switches for Position Monitoring Switches are prone to misadjustment and failure. Use only to indicate safe\/stow\/deploy positions, not to control deployment sequence. Allow for overtravel and deadband (hysteresis) effects, provide adequate margins for actuation force and stroke. Provide simple, stable adjustability at assembly. Avoid galling of close-fit parts in moving members during assembly or operation. Prefer non-galling metal-metal couples. Provide adequate differential hardness of parts. Substitute anti-galling stainless steel for conventional SST. Provide anti-gall surface treatments to prevent damage in assembly\/disassembly\/adjustment operations. Provide anti-gall treatment for titanium parts and fasteners. Provide adequate clearance fit allowances in moving members to accommodate: Bulk temperature effects, thermal expansion (CTE) mismatch effects and temperature gradient effects. Design slip fit interfaces for thermal expansion takeup. Assure friction control where intentional slip is required. Use surface treatments, lubricants and fit clearances which prevent lockup or cocking where slip is intended. Deployment and Temperature Effects. Determine temperature effects on stowed and deployed frequencies. If explosive deployment devices are used, determine near source shock levels and effects on deployables (instruments, optical devices, etc.). Deploy latches must not rely on appendage momentum; latches should lockup under static (zero velocity) appendage force\/torque. If friction dependent, control surface contamination for predictable friction. Avoid thermally induced misalignment (e.g., differential temperature of deployable boom legs). Consider post-deployment thermal contraction of deployable boom lanyards causing limit switch reactuation at low temperature. Control deployment end-of-travel impact, use energy absorbing dampers where necessary. Use floating pin\/flange arrangement for hinge joints where practical to provide redundant sliding surfaces. If system will be dormant for a long time, it should be designed so all deployable parts can be partially deployed and retracted periodically to prevent \"lockup\" due to stiction, lubricant changes, or adhesion of plastics. Handling - large items Design-in handling fixture attachment points. Locate attachment points to position c.g. for stable lifting. Where feasible, provide for 1g counterbalance attachment on hardware for functional testing. Design-in self-fixturing alignment and assembly guides. Self-aligning guides permit assembly without expensive fixtures, reduce need for highly skilled personnel. Provide self-aligning parts, with lead-in where practicable to protect precision surfaces, interfaces and bearings and minimize assembly debris generation. Provide disassembly features. Plan for unexpected disassembly, rework or reinspection. Design-in pry slots on close fit parts to permit easy separation without damage during typical assembly and disassembly for fit checking, shim selection or end shake checks. Provide puller holes, slots, jacking screw threaded holes or punch holes for disassembly of press fit components. Key electrical connections. Use differently keyed or dissimilar electrical connections for squibs and motors to prevent inadvertent interchange between prime and redundant and prevent malfunction. Use specific fastener hardware designs for appendages. Use plated self-locking nuts that reduce thread wear and reduce probability of galling and thread seizure but withstand few reuses. Fastener seizure and removal degrades critical hardware. Limit reuse of self-locking designs. Threads can become damaged, generate wear particles. Choose head designs for driver engagement appropriate to application, torque requirement and accessibility for tools. Small hex drive screws strip easily, Torque-Set and coinslot drive types are difficult to remove. Torque stripe where appropriate to ensure integrity, permit later verification. Avoid countersunk (flat head) fastener usage where practical; driver engagement is easily damaged. Provide clearance for thermal blankets and tiedowns at moving interfaces. Provide a taping edge or draw string flange to control blanket edges at moving interfaces. Provide adequate clearance for launch environment dynamic deflections with no protrusions or sharp edges to catch blankets. Provide adequate clearance gap with securely taped edges at moving interfaces; minimum one inch between hard surfaces which get blanketed. Lubrication for deployed appendages. Lubrication is crucial for deployables, many of which are mission critical. Key lubricant functions include the separation of surfaces and friction reduction. This is critical because often the deployment forces and kickoff spring forces are kept small to minimize dynamic forces. For sensitive science missions, extremely low outgassing is essential. Most deployables are single use and experience few cycles through test and flight so long wear life issues are not paramount in the lube selection. However, movable joints must sustain ground and launch environments, Flight conditions of sometimes long duration, and then deployment, often at temperature extremes. The clamped separation joints may experience micromotion at interfaces during ground handling, test and launch environments which can disturb surfaces. Lubes must stay in place to effectively separate surfaces, not outgas excessively and minimize friction. Surfaces that must separate or move relative to one another (e.g. hinge line bearings and latching devices) must be designed to preclude the possibility of metal-to-metal adhesion which causes increased friction and, in extreme cases, galling. Launch shifts or on-orbit thermal gradients can produce unexpected added forces at the separation points. To minimize friction problems the following guidelines are followed: Maximize utilization of rolling surfaces, as opposed to sliding motion. Lubrication or separation of all moving surfaces either by a suitable aerospace grease or dry lubricant coating should be used without exception, even for lightly loaded \"friction compatible\" surfaces. On hard mating surfaces where hard coatings are used (such as Type III anodizing on aluminum) loads must be kept below the bearing yield strength of the substrate metal (e.g. 60 ksi for 6061-T6 aluminum). Smooth and polished mating surfaces are preferred. Dissimilar material mating surfaces should have low mutual solid solubility, or at least one of the two should have a heavy dissimilar coating (e.g. nitride, carbide or oxide). Caging devices should be designed to positively preclude relative motion between clamped surfaces when subjected to shipment or launch vibration. Any separation (gapping) under launch loads is undesirable. Small amplitude oscillatory motion between mating surfaces can damage lubricating films and, in the extreme, result in fretting (adhesion) of the surfaces. Two alternatives are available for lubrication - \"wet\" lube with a low vapor pressure aerospace grease and \"dry\" lube by means of bonded or sputtered MoS2 coatings. The wet lube is generally preferred because the lubricating film is self healing and frictional behavior is more consistent and predictable. The grease with the most heritage is Bray 600 series, a synthetic fluorinated oil thickened with micron sized TeflonTM powder. The grease is extremely low outgassing (TML<0.1% and CVCM <0.05% for the standard 125\u00b0C - 24 hour test) making contamination concerns negligible for virtually all S\/C applications. The wet lube usable temperature range is -80\u00b0C to +200\u00b0C. For extreme low temperatures, cryogenic applications and other special circumstances, MoS2 coatings are suitable. For most consistent performance and lowest possible outgassing these films should be applied by the ion sputtering process. Epoxy and polyimide bonded films can be successfully employed with proper application and burnishing to remove excess material. Technical Rationale: Careful and critical review during the design stage can produce better, more reliable designs. Such foresight can help avoid many fabrication, assembly, test and deployment problems. These guidelines highlight often overlooked but recurring troublesome problems. Incorporation of successful practices from past experience can reduce cost, avoid unexpected schedule impacts and improve reliability of new devices. References: GSFC Engineering Directorate paper, \"Spacecraft Deployable Appendages,\" May 1992 MIL-A-83577 General Specification for Moving Mechanical Assemblies for Space and Launch Vehicles","Lesson ID":687}
{"Driving Event":"This Lesson Learned is based on Reliability Guideline Number GD-ED-2213 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Analysis of EEE parts failures during manufacture and usage in flight hardware has proven a useful tool in identifying part infant mortality, assembly processing and manufacturing defects, subtle assembly design overstress, and end of part life. However, the need to conserve essential program resources, combined with continued diminishing program funds, requires that a strategy for managing part failure analysis be established. Such a strategy can ensure that important failure analysis is still performed while making optimum use of available resources. This will provide maximum cost benefit to a program in which budgets are tight. Implementation Method: EEE parts failure analysis is essential in design and development of on-orbit space systems. A complete understanding of when and how these components fail can increase the reliability and chances for mission success of a system and is essential in the design process. Often times limited resources are available for such analysis, and management of those resources is the key. EEE part failure analysis is essential if the hardware is in the developmental stage, as defined by the following criteria: The parts are leading edge technology or based on new technology The part emulates a specific function The part has no reliability data available The system design is evolving or being enhanced prior to hardware manufacturing The parts are currently being manufactured or purchased The assembly hardware is currently being manufactured Failure to identify latent defects, infant mortality, manufacturing process deficiencies, and subtle design overstress conditions may result in additional cost to a program. If these deficiencies are caught in the beginning at the board, system, or field level, the cost of redesign to correct the defects can increase by a factor of ten or more, depending on the amount of rework, retest, and recall of the fleet hardware considered necessary. If the hardware is mature, as defined by the following criteria, a decision whether to perform failure analysis or to trend for generic failure causes should be determined. The following criteria should be utilized: The parts are from a proven technology and reliability data exists; The system design is certified; The hardware has successfully flown more than one mission; The parts have been demonstrated to be reliable and mature; Similar parts are not being installed into assembly hardware; ESD handling, testing and checkout procedures are well established and adequate; The parts are known to have adequate tolerance for Total Ionizing Radiation Dose and Single Event Effects for the mission. Space quality military parts used in the Space Shuttle Orbiter Program have a minimum expected life of ten years. If the part has failed with less than ten years field service life, failure analysis is recommended. If the part has had successful field service over ten years, trending of the part failure should be considered. The trending process itself must ensure that: sufficient investigation is performed to isolate the hardware failure, the process can detect an increasing failure rate, end of part life issues, tolerance shift does not give an undesirable system operational effect, the part is retained to support future trend investigations. If the flight hardware is mature, and the part is over twenty years old, a decision should be made whether the part should be submitted to the trend process or scrapped. This determination should be based on whether the part is obsolete and unavailable (or available in only limited quantities), whether sufficient information is available to make a failure analysis possible, or if failure analysis will provide valuable results for the program. A process flow of the decision process is provided in figure 1. [D] There is also a simple, cost effective way of performing failure analysis which requires delidding a part and examining it under a microscope to look for visible signs of ESD damage or overcurrent conditions. This may be sufficient if the box failed immediately after handling. If delidding does not reveal any of these symptoms, then one may use a Scanning Electron Microscope for more detailed examination of a device or component. If a device fails parametrically rather than functionally then analysis on the integrated tester may give clues about the failure modes. Each of these procedures adds a different value to the program. The investigator can request the appropriate level of analysis. Finally, a quotreality checkquot of the decision to failure analyze, failure trend or scrap the part should be made using the following criteria: Has the box failed immediately after handling? (It may be due to ESD damage to a device). Can random failures be tolerated? Have all sources of usage history, i.e. program, NASA Institutional, and Government - Industry Data Exchange Program been examined for related information to determine if a failure trend is indicated? Have other similar equipment impacts been evaluated and coordinated? Has the part provided quotreasonable, expected servicequot? Have all sources of processing errors, subtle overstress, and mishandling been considered? Is the equipment providing reasonable support to program goals? Will the equipment continue to support program goals in the foreseeable future? This criteria allows the designer or end item user to determine the most feasible and cost effective approach for their hardware and program. Sometimes a reality check can provide a simple means of identifying and resolving technical problems. Technical Rationale: This guideline provides a strategy for assessing part failure analysis as used in the Orbiter Program. This strategy has the benefit of a program that has redundant hardware\/function, meets the fail operational-fail safe requirement, and can tolerate random failures and system maintenance while supporting its program goal.","Lesson ID":688}
{"Driving Event":"This Lesson Learned is based on Reliability Guideline Number GD-AP-2301 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Consideration of the solar, albedo, and earth radiation thermal inputs, including seasonal variation with tolerances, is required to accurately predict the thermal environment of orbiting devices. Implementation Method: SOLAR CONSTANT The nominal solar constant value is 1367.5 W\/m2. The variation of the earth-sun distance causes a \u00b1 3.5% seasonal variation from nominal. The accuracy of the solar constant is taken as \u00b1 0.5%. The following are the values for various seasons in the northern hemisphere. NOMINAL 1367.5 W\/m2 WINTER 1422.0 W\/m2 (NOM + 4.0%) SUMMER 1318.0 W\/m2 (NOM - 4.0%) ALBEDO FACTOR* The nominal albedo factor is 0.30. The variation around the nominal should be \u00b1 0.05. No variation during the sunlit portion of a given orbit should be assumed unless extremely light weight items are being considered. Programs that compute albedo energy should use 0.35 (hot case), 0.30 (nominal case), and 0.25 (cold case), respectively. *Note: Since earth temperature and albedo vary with latitude, as the orbit approaches either extreme of a polar or equatorial orbit, further study of the literature should be made. (see AIAA-87-1596) EARTH EMITTED ENERGY * The nominal earth temperature for earth emitted IR energy is 255 degrees K. This temperature produces a heating rate of 241 W\/m2. A reasonable variation can be obtained by maintaining consistency using the following relationship between Solar, Albedo, and Earth Emitted Energy: Earth Emitted Energy = [(1-Albedo Factor)x Solar Constant] \/ 4.0 Table 1 shows the variations in Earth Emitted Energy that result from using the above recommended Solar and Albedo ranges. Software programs that compute Earth Emitted Energy should use the appropriate hot, nominal, or cold case Solar and Albedo values; and the corresponding black body Earth temperature to achieve an energy balance. REFERENCES FOR QUICK CHECKS OR SIMPLE CALCULATIONS Hand calculations should be made to verify that computer outputs of heating values for flat surfaces of known orientation and minimal reflected inputs from other surfaces are reasonable. Hand calculations also may be necessary when time does not permit a computer study. A check of incident Albedo energy to a flat plate at various altitudes and orientations can be made by using TN-D 1842 quotEarth Reflected Solar Radiation Incident Upon an Arbitrary Oriented Spinning Flat Plate,quot by F. Cunningham. Figures 1 through 9 show the orbit-averaged incident Earth and Albedo energies to an Earth-oriented flat plate at various altitudes and orbit\/sun angles. Eclipse factors for elliptical orbits are provided in quotCalculation of the Eclipse Factor for Elliptical Satellite Orbitsquot, by F. Cunningham. A hand calculation of incident Earth Emitted Energy to a flat plate at various attitudes and altitudes also is possible. Figure 10 shows the instantaneous geometric shape factor for a planar surface as a function of altitude and attitude (h\/R is the ratio of the orbit altitude to the Earth radius). The earth radius is 6,365 km. The incident Earth Emitted Energy is found by multiplying the shape factor times the black body emissive power at the earth temperature. For an altitude of 1,000 km and a flat plate whose normal is 90 degrees to the nadir (l= 90); h\/R = 0.157, which gives a shape factor of 0.19. The Earth Emitted Energy incident on the plate is 0.19 x 241 W\/m2or 46 W\/m2. *NOTE: Since earth temperature and albedo vary with latitude, as the orbit approaches either extreme of a polar or equatorial orbit, further study of the literature should be made (see AIAA-87-1596). RECOMMENDED SOLAR AND ALBEDO RANGES* SOLAR CONSTANT (W\/m2) ALBEDO FACTOR EARTH EMITTED ENERGY (W\/m2) EQUIV. EARTH TEMP (\u00b0K) NOMINAL 1368 0.25 0.30 0.35 256 239 222 258 254 250 WINTER SOLSTICE 1422 0.25 0.30 0.35 267 249 231 262 258 253 SUMMER SOLSTICE 1318 0.25 0.30 0.35 247 231 214 256 251 246 *For use in Orbit Average Analyses EQUIVALENT SINK TECHNIQUE The equivalent sink technique can be used by replacing all surrounding surface radiant interchanges and the absorbed Solar and Earth energies to node i with a single radiation coupling to a single node at temperature T sink. To derive the equation for this sink temperature, first consider an energy balance at node i where all the inputs are treated as gross inputs and node i has a view to space of 1.0. (1) [D] From planetary flux program (TRASYS or SSPTA) From thermal program (SINDA) results obtained from Geometric Math Model (GMM) radiation exchange program Where: [D] Next consider the equivalent sink energy balance situation:[D] (2) [D] Solving (1) for [D] and setting equal to the right side of (2) gives: (3) [D] The equivalent sink for node i may be determined from the detailed thermal math model by determining the adiabatic temperature of node i when node i is disconnected from internal heat paths and heat dissipations. For a transient situation, node i must be an arithmetic node or a low mass node. Technical Rationale: Thermal analysis of an earth orbiting spacecraft requires the accounting of incident thermal energy from all external sources. The most significant external sources of energy incident on the spacecraft are the sun, the thermal radiation of the earth, and the solar energy reflected from the earth (albedo). The modification of the energy incident on the spacecraft due to the earth-sun distance variation, and the accuracy of the measurements of the solar constant, are of sufficient magnitude to be important parameters in performing a thermal analysis.","Lesson ID":693}
{"Driving Event":"This Lesson Learned is based on Reliability Guideline Number GD-ED-2202 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: This guideline identifies design considerations and reliability requirements to assure reliable performance and to avoid cost overruns due to redesign and operational failures. Implementation Method: Component information. The design of thick-film microelectronic circuits requires information on specifying components with established reliability. The components used in thick-film microelectronic circuits are somewhat different from the sealed or encapsulated, fully tested discrete components used to fabricate circuits on printed wiring boards. The components fall into the categories of (a) thick-film resistors, (b) thin-film resistors, (c) ceramic capacitors, (d) semiconductors, and (e) thick-film conductors. Circuit partitioning. Several factors should be considered when partitioning the system into individual microelectronic circuits. Each of the circuits should be a separate and complete function which can be tested with the addition of a minimum number of external components, and should have the minimum number of input-output pins. If a system consists of two signal paths which must track, the partitioning should be done such that the corresponding circuits of each channel are in one thick-film microelectronic circuit. This will ensure that the circuit elements of both channels will be at the same temperature and therefore increase the tracking accuracy. Packages available. There are several package types that are currently available in industry. The packages that are used for space flight application shall meet MIL-H-38534 requirements. Power dissipation. The junction temperature is a function of the case temperature and the power dissipation within the package. The case temperature is a function of the internal power dissipation of the microelectronic circuit, the printed wiring board loading, the thermal impedances from the package case to the outside world, and the operating ambient temperature of the chassis. Thermal impedance of packages, substrates, and semiconductors all affect the thermal gradient from the junction to the outside world. Therefore, the choice of package and the distribution of power within the package will affect the maximum allowable power of the circuit with either a fixed maximum case or ambient temperature. Worst case analysis. A worst case analysis ensures that the circuit will function over the maximum operating temperature with the worst possible combination of component variables. The worst case analysis shall be performed in accordance with the applicable program requirements. The worst case analyses shall include the individual components. Before an actual worst case analysis is started, the following preliminary considerations must be made: Physical limitations. There are three factors to consider: (1) the number of required pin-outs must be available in the desired type of package and a key pin should be included in the pin count; (2) the number of components in the circuit shall not exceed the number of components specified as the maximum number that can go into that particular type of package, and (3) the use of non-established reliability components in the circuit design should be avoided. Power dissipation within the circuit. The worst case power dissipation within the circuit must be calculated. External factors. External factors affecting circuit performance must be identified before starting the worst case analysis; e.g., (1) the power supply tolerance should be known, (2) the worst case loading of the circuiti\u0301s outputs must be considered, and (3) the decoupling requirements must be considered. Testing. Most hybrid microelectronic devices are custom made for their particular applications. However, the part operation should be precisely defined by electrical characteristics which include all necessary parameters with test conditions, parameter minima and maxima, and parameter typical values. All active and passive elements of the hybrid should have electrical characteristics derated according to the appropriate derating factors listed in MIL-STD-975 for NASA standard parts. Derating will increase the safety margin between the operating stress level and the actual failure level for the constituent hybrid parts and will provide added protection for system anomalies unforeseen by the application engineer. Dynamic trimming. The thick-film microelectronic circuits are dynamically trimmed using automatic laser trim system. Power supply settings, input conditions, and output requirements must be defined prior to dynamic trimming. All resistors involved in a trim must be referenced, along with the output reaction to the trimming of each resistor. Radiation Hardness Testing. The components used in the thick-film hybrids are required to undergo radiation hardness testing when radiation tolerances are specified in the detail specification, which may include dose rate and latchup, total dose, and neutron irradiation as applicable. Circuit quality level. The hybrid microelectronic circuits shall be screened to meet the requirements of MIL-STD-883, Class S or B depending on the program requirements. As a minimum, the following screening steps are essential in accordance with MIL-STD-883 applicable test methods, to ensure the quality and reliability. They are, (a) Die Visual Inspection, (b) Substrate Visual Inspection, (c) Element Evaluation, (d) Package Evaluation, and (e) Quality Conformance Evaluation including groups A, B, C, D, and E testings of MIL-STD-883 specifications. Technical Rationale: This document and JSC contractor paper, JSC 25471, provide the information and guidance to circuit designers for specifying devices which will be developed and produced as thick-film hybrid circuits. In order to ensure a reliable circuit at the lowest cost, there are several areas that require special consideration when designing a thick-film hybrid circuit. Use of these two documents should allow the engineer to spend less time researching standards and more time designing reliable microcircuits. References: JSC 25471, Electrical Design Considerations for Thick-film Microcircuits MIL-M-38510 Microcircuits, General Specifications for MIL-H-38534 Hybrid Microcircuits, General Specifications for MIL-STD-975 NASA Standards Parts List MIL-HDBK-978 NASA Parts Applications Hand Book MIL-STD-1772 Certification Requirements for Hybrid Microcircuit Facilities and Lines MIL-STD-883 Test Methods and Procedures for Microelectronics","Lesson ID":678}
{"Driving Event":"This Lesson Learned is based on Reliability Guideline Number GD-ED-2208 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefits: This guideline compliments Reliability Guideline GD-ED-2206, \"Selection of Compatible Materials for Use With Gaseous and Liquid Fluorine\". The use of these guidelines will benefit a designer in choosing the correct materials, proper fabrication, and assembly of the components for safe and reliable operation. Implementation Method: The effect of elemental fluorine and fluorine-oxygen (FLOX) mixtures with most materials is reactive under suitable conditions. As addressed in the Reliability Guideline GD-ED-2206 \"Selection of Compatible Materials for Use With Gaseous and Liquid Fluorine\", no organic material is totally resistant to elemental fluorine. Failures in fluorine systems are due to improper fabrication, assembly, and cleaning\/removal of contaminants. The major cause of failures in fluorine systems is due to weld defects, trapped moisture, foreign and incompatible materials. Fabrication The following conditions should be followed to preclude any failure due to improper fabrication of fluid system components: Machine parts, castings,and purchased parts. Any parts that contain scales or oxides must be cleaned and passivated. Porous casting must be avoided since foreign material is difficult to remove from the surface of the material. Soldering and brazing parts. Joints should be free from pits, pockets, and crevices. During soldering and brazing flux should never be used, silver solder or nicro-braze are preferred. If any flux is deposited from the solder it must be completely removed from the system. Welding or welded component parts. All welds must be free of pinholes, slag, cracks, and crater defects, and have 100% penetration of the welded zones. Welded components with pockets, surface flaking, flux, or slag cannot be permitted. Welded parts and connections must be properly cleaned and passivated prior to service. Tubing connections and bend radius. The bend radius of tubing should be as large as possible at high flow rate areas. Avoid using sharp angle connections, 90\u00b0 or 45\u00b0 pipe fitting connections. All parts (internal and external surfaces) should be visually inspected for pits, discontinuities, and inclusions. It is also recommended that components be x-rayed to make certain all material discrepancies are found. Cleaning Procedure Cleaning of all parts is necessary to remove any possible contaminants that are in the components. A list of common contaminants is shown in Table 1, and the possible reaction occurring under the tested conditions. Table 1. List of common fluorine contaminants Contaminants Gaseous fluorine @ atm. pressure & temperature Gaseous fluorine @ 1500 psi. & atm. temperature Liquid fluorine @ -195.5\u00b0C & atm. pressure Liquid fluorine @ -195.0\u00b0C & 1500 psi. Water no reaction reaction no reaction reaction Ice no reaction N\/A (Not Attempted) explosive N\/A (Not Attempted) Fluorolube HO no reaction reaction no reaction no reaction Molylube no reaction reaction explosive N\/A (Not Attempted) Slag on stainless steel joint no reaction reaction no reaction reaction Flux on silver-solder stainless steel joint no reaction reaction no reaction reaction When cleaning components, the proper solvents should be used to prevent ignition from fluorine exposure. A list of recommended cleaning solvents are shown in table 2 (see Reference 1). Table 2. Recommended Cleaning Solvents Solvent or Cleaner1 Material West Penetone TPC Solvent All metals Halon TFE Teflon TFE Teflon FEP Nickel-filled Teflon Acetone Kel F-81 Plaskon 2000 Halon TVS 1Soap and water are preferred for final cleaning of all materials listed, since elastomers absorb solvents. All solvents must be completely removed after cleaning. West Penetone TPC solvent should be used for vapor degreasing of individual parts. General procedures should be followed when preparing metal parts for cleaning and assembly. The following list, which is detailed in reference 1, shows the recommended procedure for cleaning metallic components. All components (valves, pumps, etc.) should be disassembled, and any parts incompatible with solvents, such as gaskets and O-rings, must be removed. Any amount of scale, slag, flux, etc., must be removed from the surface that will come in contact with the fluorine. The surface can be cleaned with nitric acid or abrasive cleaner. The final result should leave the surface bright and the base metal exposed. Care should be taken to avoid disturbing metal-to-metal sealed joints. There should be no sign of the foreign material on the metal. All solvents must be removed from the cleaned surface such that there is no sign of residue. Piping and components that are visually clean should be dipped into a nitric acid bath solution (10 - 25% nitric acid). Once removed all components should be flushed with deionized water and thoroughly dried. When needed, components may be vapor degreased, solvent bath degreased, and hand wiped. After hand-wiping the component should be immersed in a nitric acid bath or solvent and thoroughly flushed and dried. Vapor degreasing nozzles should be used for components with holes, ports, or complex configurations. To increase drying time and aid in removal of any liquid, helium or dry nitrogen should be used. Valves and complex components can be heated in a vacuum chamber to ensure all liquid or moisture is removed. Components should be immediately used or packaged to prevent recontamination. Final preparation, after assembly of components, is to passivate the system with a small amount of fluorine gas. Fluorine will react with the metal to form a metal fluoride film. A slight pressure of helium should be maintained in the system to prevent any contamination from moisture. (Note: After final assembly and passivation avoid sharp tapping or rapping of components. The tapping, rapping or movement of passivated components may cause flaking of the fluoride film inside the components which may result in a reaction point.) If components are being processed and cleaned, they should be immediately used or packaged in an approved contaminant free plastic bag. Silica gel packets should be contained with the cleaned components to reduce any moisture contamination during storage. Technical Rationale: Due to the extreme reactivity of fluorine with certain materials it is necessary that the designer and technicians become knowledgeable with fluorine material compatibility, fabrication, and assembly of components. Carelessness during fabrication or failure to remove contaminants will result in some form of reaction (e.g., fire, explosion). With this understanding of the chemical reactions with fluorine and other materials, system designers will be able to prevent critical failures in the system. This will reduce the unnecessary risks involved in developing fluorine systems. References: Schmidt, H. W., Fluorine and Fluorine-Oxygen Mixtures in Rocket Systems, NASA SP-3037, 1967. Price Jr., H. G. and Douglass, H. W., Nonmetallic Material Compatibility With Liquid Fluorine, NACA RM E57G18, 1957. Slesser, Ph.D. Charles and Schram, Stuart R., Preparation, Properties, and Technology of Fluorine and Organic Fluoro Compounds, McGraw-Hill, New York, 1951. Reliability Preferred Practice GD-ED-2206 Selection of Compatible Materials for Use With Gaseous and Liquid Fluorine Reliability Preferred Practice PD-ED-1224 Design Considerations for Fluid Tubing Systems","Lesson ID":683}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number GSE-3008 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Proper control of electrostatic discharge can significantly reduce the possibility of: Inadvertent ignition of solid propellants, explosives and flammable\/combustible materials, Inadvertent actuation of electronic devices\/systems Personnel shock or injury and Ground Support Equipment (GSE) hardware\/equipment damage that could lead to flight hardware damage. Implementation Method: Electrostatic controls are implemented at KSC to reduce the effects of ESD during the following operations: General STS and Payload Operations - The percent relative humidity in an operational area is recorded every four hours prior to the start and during operations involving exposed solid propellants, open flammable\/combustible fluid systems and category A Electro-explosive Devices (EED) when the Faraday (electrically conductive shield) cap is removed or firing circuits to EEDs are exposed. At or below 50% RH, bonding and grounding measures are verified. In addition, non-conductive materials in the area and personnel not wearing personnel grounding devices are checked with an electrostatic meter to ensure voltages greater than 350 volts are not present. Electrostatic scanning, not exceeding one hour intervals, is performed during the operation when at any time: additional personnel, equipment or hardware are introduced into the immediate area, the RH decreases, or the handling of non-conductive materials is required. At or below 30% RH, operations involving exposed solid propellant, except Solid Rocket Booster (SRB) segments, or open flammable\/combustible fluid system and category A EEDs (with Faraday caps removed or firing circuits exposed) are not permitted. In the Orbiter Processing facility (OPF), the RH is controlled to within 40 - 50% thus minimizing the effects of ESD. STS SRB Processing - Segment processing may continue below 50% RH using the following guidelines, segment processing is not permitted at or below 10%: Between 50% and 30% RH the above requirements apply. With proper approval, operations may continue at RH levels below 30% down to 10%. In addition to the above requirement, electronic scanning is required to to be accomplished at 10 minute intervals if the propellant is exposed, and at 30 minute intervals if the propellant is covered. At no time will operations continue on the segments with propellant exposed and a potential of 350 volts or greater is measured on the segment case, propellant, or any equipment\/personnel within five feet of exposed propellant. When the segment and rings with shipping covers are installed (propellant protected by a Faraday cage), the following guidelines apply: A reading of one kilovolt or less on the case is acceptable and work may continue. A reading of greater than one kilovolt, but less than four kilovolts on the case requires all segment processing to cease and personnel will stand back four feet. An electrostatic scan will be repeated every five minutes and recorded. If the reading of one kilovolt or up to four kilovolts exists for 30 minutes, connection to facility ground will be verified. If this connection is open, then the ground will be reconnected thru a resistor (1 Meg ohm +\/-20%). Processing may continue when the electrostatic scan indicates less than one kilovolt. An electrostatic reading of four kilovolts or greater requires all work to stop. All personnel will evacuate to a location 500 feet from the processing area. Designated personnel may re-enter for electrostatic scan. This scan is repeated not less than every 15 minutes. No attempt to check grounds will be performed. If, after an hour, readings still exceed four kilovolts, then a separate ground with a resistor (1 Meg ohm +\/- 20%) in line may be connected to another ground point on the segment case. Work may resume when a reading of one kilovolt or less is obtained and all grounds have been rechecked. Launch Processing System (LPS) Operations - LPS operators coming in contact with the LPS hardware subsystems are required to wear approved grounding wrist straps during test and launch processing operations in environmental conditions below 45% relative humidity. LPS system, maintenance, or support personnel coming in contact with low voltage LPS hardware Line Replaceable Unit (LRU) \/ Components are required to wear approved grounding wrist straps at all times. LPS \/ Checkout, Control and Monitor Subsystem (CCMS) console stations are equipped with approved terminated ground cables containing quick connect \/ disconnect type wrist strap snaps. Systems, maintenance or support personnel will connect the grounding lead clip to a conductive surface on the LPS grounded hardware structure. Testing stations are available for proper go\/no go testing of the approved grounding cable and wrist straps. Logistics - The effects of ESD on static sensitive Line Replaceable Units (LRU's) during transportation and storage is alleviated with the use of transparent electrostatic-shielding bags. This packaging scheme affords static protection against both external static fields and internal triboelectric charge. All programmable read-only memories (PROM's) are transported and stored in static-shielding tubes or approved foam and shielding bags for distribution to installation in LPS hardware sets. These tubes protect against triboelectric charging and direct discharge yielding a dynamic response rating of less than 1 millisecond. All integrated circuits (IC's) for temporary staging are placed (leads inserted) on crosslink, noncorrosive, high density, conductive foam. This foam ensures that all device leads are kept at the same potential, thereby protecting the device from ESD damage. Other - inspection, testing and repairs of static sensitive electronic components or LRU'sare performed at approved ESD work stations. These work stations, designed to bleed off static charges, utilizes static dissipative table mats electrically connected to a static dissipative floor mat which is connected to ground thru a series resistor (1 Meg ohm +\/-20%). The operator connects a wrist strap, to a single point ground, to make himself equal to the same potential as the components that are on the table, thus, prohibiting static discharge on conductive components. Technical Rationale:Fundamentals of Electrostatics - To insure successful implementation of proper guarding against harmful effects of ESD, familiarity with the concepts of electrostatics and ESD is necessary. Here, the basic elements are briefly discussed. For more extensive discussion, refer to books listed in the references. The main basic elements of ESD are&colon. electric charges, electric field, electrostatic potential, capacitance, charge generation and charge removal. Electric Charges - Experiments have shown that when two dissimilar objects are brought into contact with each other and then separated, the two objects become charged. The classic example is the rubbing of a silk cloth on a glass rod where the charge is visually evident when the charged objects cause the hair on your arm to stand up or cause small bits of paper to be attracted to the charged objects. If two corks are charged by the glass rod, the corks will repel each other because of like charges. Conversely, if one cork is charged by the glass rod and the other is charged by the silk (opposite charges), the corks will attract each other. The charge on these objects is due to an excess or deficiency of electrons on their surfaces. These charges are referred to as static electricity. This is because they can remain stationary on an object for substantial long periods of time. It is to be noted that this sudden transfer of charge from one body to another (by oppositely charged bodies being brought into close proximity) is called electrostatic discharge or the better known acronym \"ESD\". Lightning is a very high energy form of ESD. The interactions between electric charges are described by Coulomb's law: F=kq1q2\/r. Where F is the magnitude of the force, k is the proportionally constant, q1 & q2are the charges on the object and r is the distance between them. Electric Field - describes the influence of an isolated charge on other charges in its vicinity. This electric field is the direction and magnitude of the force exerted by the charge on a unit charge at any point in its environment. The field strength (E) of an object is force(F)\/charge(q). A good example of electrostatic field is when a person generates a charge on a balloon and then holds it above his head to make his hair stand up. The balloon never touches the hair, but an electrostatic field has been created. Electrostatic Potential - the amount of energy (work) per unit charge required to move a charge from one point to another in a field. The movement of the charge (q) along a distance (X) requires work (W). Thus the equation W=FX and, substituting the forementioned, W=qEX or W\/q=EX . This work per unit charge is the potential difference expressed in volts. Thus the formula E=V\/d, where E is the electric field intensity, V is the electric potential and d is the distance between the potential voltages. Ideally, we want to make sure that all charges remain at the same level or same potential so that no ESD (zap) occurs. Capacitance - the ratio between the charge on two plates and the potential difference between them, or, C= Q\/V. In the case of two parallel plates this capacitance C=eA\/d where A is the area of the plates and d is the distance between the plates (potential voltages) and, e is the dielectric constant. Where typical capacitance (C) values for humans ranges from 50 to 500 picofarads (pf) and dielectric constants of 1 (air and insulators) to 10 (insulators). The energy stored in a capacitor is given by the expression E= 1\/2CV2 or 1\/2Q2\/C. Charge Generation - charging that occurs as a result of contact and frictional motion is referred to as triboelectricity. To describe, whenever two materials (one must be an insulator) are brought together and then separated, there will be a flow of electrons from one material to the other. The material giving up the electrons becomes positively charged while the material accepting the electrons becomes negatively charged. Charge Removal - dissipation of electrostatic potential with the use of soft grounding, static dissipative materials and air ionizers. Listed below are some of the more common materials and their polarity (+ or -) in the triboelectric series. Asbestos Acquires a more positive charge Glass Human Hair Nylon Wool Aluminum Paper Polyurethane Cotton Neutral reference point Wood Steel Sealing Wax Hard Rubber Mylar Epoxy Glass Nickel, Copper, Silver Brass, Stainless Steel Acrylic Polystyrene Foam Polyurethane Foam Polyester Polyethylene Polypropylene PVC (vinyl)Teflon Silicone Rubber Acquires a more negative charge When the charged object is an insulator, the charge can last for extended periods of time. This is true because insulators are poor conductors of electricity. Conversely, when the charged object is a conductor, the charge will decay rather quickly. The factors affecting the magnitude of the rate of charge generation are: Relative position in the triboelectric series. Intimacy of contact (proximity of the materials). Coefficient of friction between materials. Rate of separation. The factors affecting the magnitude of a rate of discharge (dissipation) are: Conductivity of the materials. Relative humidity. Moisture on the surfaces of the materials. Rate of recombination. Some typical electrostatic potential (volts) generated for typical events with various levels of relative humidity (RH) are respectively: Walking across a carpet 35,000 volts @ 10% RH 15,000 volts @ 40% RH 7,500 volts @ 50% RH Walking across a vinyl floor 12,000 volts @ 10% RH 5,000 volts @ 40% RH 3,000 volts @ 50% RH Pulling tape quickly from its roll 10,000 volts @ 30% RH ESD is not normally a concern when the relative humidity is greater than 50% RH because moisture in the air will act as a high resistance bleeder. This will then dissipate voltage potentials on the surface before they can build up to a level of approximately 350 volts and result in ESD. A few materials such as teflon, vinyl, etc. do not absorb moisture and therefore, will not bleed off readily even in environments above 50% RH and should be avoided where ESD is a concern. Environments below 50% RH require special attention for selection of and use of tapes, plastic films and electrostatic flooring material. Operations below 30% RH should be carefully assessed and avoided when possible. At levels below 30% RH, additional precautions shall be employed (e.g., air ionizers, humidifiers). Voltages, especially on large surfaces, should be dissipated using a high resistance resistor (1 Meg ohm +\/- 20%) in series with the ground wire until the charge is eliminated before going directly to ground. Note: Surface resistivity changes exponentially with humidity changes. Therefore, relative humidity levels maintained between 40% and 60% are recommended. References: Electrostatic Discharge Control Program for Protection of Electrical and Electronic Parts, Assemblies and Equipment, MIL-STD-1686B. Electrostatic Discharge Control Handbook for Protection of Electrical and Electronic Parts, Assemblies and Equipment, MIL-HDBK-263A. Requirements for Electrostatic Discharge Control, NHB 5300.4(3L) ESD Program Management by G. Theodore Dangelmayer of AT&T. Investigation Analysis of the ESD Protection in the Facilities at the John F. Kennedy Space Center by Peter Stonefield, LSOC QE. Passive Static Protection: Theory and Practice by George R. Berbeco. KSC Ground Operations Safety Plan, GP-1098G. SPC Standard Practice Instruction (SPI) QA-016(3)K entitled Receiving Inspection of Parts and Materials (SPC procured & Government furnished). SPC Standard Practice Instruction (SPI) LP-021(5)K entitled Electrostatic Discharge Prevention (to LPS). SPC Standard Practice Instruction (SPI) LG-661(7)K entitled Preservation, Packaging, and Packing of Materials.","Lesson ID":685}
{"Driving Event":"This Lesson Learned is based on Reliability Guideline Number GD-AP-2302 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Thermal analysis when used throughout the development cycle will (1) provide an optimum thermal design within the constraints of the overall system design, (2) provide temperature distributions and temperature histories to the level of detail required, (3) provide early identification of design problems, and (4) provide the basis for predicting and evaluating thermal performance in test and flight. Implementation Method: Detailed thermal analysis and design should be performed to ensure that the temperatures of all spaceflight components remain within their specified limits during the mission lifetime. To meet this objective, thermal modeling is required beginning at the project conceptual design stage and continuing through preliminary and detailed design stages and environmental testing. Test verified models are used to predict temperatures for the launch phase, and for mission operations. Design Phases During the conceptual design phase the temperature control system can be a major driver in defining the configuration, orientation and power requirements. Simplified calculations, rules of thumb, and experience with similar requirements are useful at this stage, but a computer model of the overall configuration and the location of major components provides the ability to compute component temperatures over the range of anticipated orbital environments and to be able to evaluate and respond quickly to proposed system trade-offs. In the preliminary and detailed design stages the computer models are expanded as more details of the overall system are firmed up. The models are used to support trade studies as needed and to develop and optimize the thermal control system design. Test Phase In preparation for thermal vacuum and thermal balance testing the computer models are modified to predict temperatures in the test environment and to provide the thermal analysis required to develop the test plan and to specify the test hardware. For thermal vacuum tests the models can be used to demonstrate that the test hardware can drive each component to the specified hot and cold temperature levels and to predict the transition times between hot and cold soak periods. The thermal balance tests are designed to verify the accuracy of the computer models and to demonstrate that the thermal control system functions as specified. Since it is often impractical to simulate the orbital environment, the models are used to develop equivalent environments that result in nearly the same temperatures in the test environment as are predicted for flight. If the test temperatures differ significantly from predictions for the test environment, the models are adjusted to try to match the test temperatures. These adjustme nts must have a plausible physical basis if the models are to be considered to be verified by test. Launch Phase For an Expendable Launch Vehicle (ELV) launch, the models are used to predict the payload temperatures from lift-off to orbit insertion. This may include transient heating from the nose fairing until fairing ejection and direct aerodynamic heating immediately followed ejection, solar and earth inputs, spin rate changes, deployment of booms and solar paddles, attitude changes for thruster firings, extended periods in the earth's shadow, etc. For an Space Transportation System (STS) launch, the payload models are placed in a model of the shuttle bay and run for a variety of cases, including (1) launch, (2) on orbit with the bay doors closed, (3) the open door configuration at selected attitudes, such as bay-to-earth, bay-to-sun, and bay-to-space, (4) payload on the remote manipulator system, (5) reentry, and (6) post landing with and without purge air. There are also safety related cases to be analyzed, such as a bay floodlight failed on and the vent door failed to open during reentry. Payload temperature grad ients at touchdown are needed for the analysis of landing loads. Flight Predictions The test verified computer models are used to predict temperatures in flight for use by ground stations for monitoring performance, for planning operations, for verification of the computer models using flight data, and for monitoring degradation of the thermal coatings. Special Purpose Models Reduced thermal models of instruments and other spaceflight hardware are often required by spacecraft thermal designers in order to limit the size of their all-up observatory computer model. The reduced models may be constrained to a small number of surfaces, nodes and couplings. Emphasis should be placed on the accuracy of the temperatures of critical components and the heat flow across the interface with the spacecraft. Thermal analysis of electronic boxes is performed to compute the temperatures and heat flows throughout the box from the mounting interface to the junction temperatures of semiconductors and other components as required. Special purpose computer programs have been developed to facilitate the modeling of circuit boards. STS thermal models, such as Orbiter Payload Thermal Integration Model (OPTIMOD), provide details for subdividing the shuttle bay into surfaces and nodes, adding external surfaces, such as the wings, tail, bay doors, and active thermal control radiators, adding internal structure as needed, and modeling the ascent, entry, and post-landing phases. Special purpose models are developed for providing added detail for a particular component or region of a larger model, such as computing temperature gradients and transient temperatures in thin films and windows. Others are developed for modeling the performance of thermal control louvers, heater pipes, capillary pumped systems, cryogenic instruments, passive radiative coolers, solid and liquid cryogen dewars, etc. Modeling Techniques The computer models are sets of finite difference equations which describe the heat transfer among small, isothermal elements or nodes which together represent the physical hardware. The number and location of these nodes are chosen based on accuracy requirements, convenience in working with complex shapes, and efficient use of engineering and computer time. For a spacecraft in earth orbit the equations are of the form: Heat Stored = Heat In - Heat Out The heat flow at each node is given by: [D] The result is a set of finite difference equations, one for each unknown temperature, with terms for the thermal mass, the heat absorbed on external surface nodes from sunlight, earth reflected sunlight (albedo), and earth emitted infrared radiation, the heat dissipated in electrical components, the heater power for thermal control, and conduction and radiation interchange between node pairs. Solutions are obtained using a general-purpose heat transfer computer program, such as Systems Improved Numerical Differencing Analyzer (SINDA). The bulk of the input data, which is the absorbed energy from the sun and the earth, and the radiation interchange factors are generated by programs such as Thermal Radiation Analyzer System (TRASYS) and Simplified Space Payload Thermal Analyzer (SSPTA). The steps involved in the development of a thermal model are shown in Figure 1. The initial step in the development of the geometric model. This is used in conjunction with the optical properties of the surfaces to generate radiative couplings between surface node pairs. Given the parameters defining the orbit and the orientation of the payload, the geometric model is also used to generate the absorbed solar, earth reflected solar and earth emitted infrared radiation on the external nodes. These data are then input into the heat transfer model for computing transient or steady-state temperatures . Any changes in the geometric model, the surface optical properties and the orbital parameters requires regeneration of the radiative couplings and the absorbed solar and earth radiation. [D] Figure 1. Thermal Model Development To ensure the accuracy of the models requires considerable care and skill, good engineering judgment and applicable experience. Care is required in checking the input data for errors and the caution and warning messages provided by the computer codes. It is very important to keep good records which show the sources of the input data and a log of the computer runs. Skill comes into play in knowing how to use the computer programs, in understanding the theory behind the calculations, and in being well versed in the pitfalls commonly experienced with each program. The experience and judgment comes into play in setting up the model, in checking the output for accuracy, and in interpreting the results. In using TRASYS or SSPTA, the geometric model should be plotted and checked for overlapping surfaces, for surface normals in the proper directions, for surfaces that are misplaced or mis-oriented, for unplanned gaps, for surfaces viewing the backsides of others, etc. The computation of radiative interchange factors, especially the radiative coupling to space should be checked for surfaces that have significant couplings to space but which do not view space. Where it is possible to do so, hand calculation or independent methods should be used to determine if the computed values are reasonably accurate. Similar checks should be made for calculations of absorbed sunlight. Steady state solutions should be checked to verify that the energy balance on each node is within required tolerances and that the heat flow to coupled nodes have reasonable values. Transient temperatures should be plotted to visually check: (1) if the temperature-time characteristics are as expected; (2) if any sudden or unusual variation has a physical explanation; and (3) that thermostats respond as required and that heaters are sized properly. Technical Rationale: The thermal design philosophy at Goddard Space Flight Center is that all temperature limits be met for worst case hot and cold combinations of possible orbital environments, spacecraft or instrument operating modes, and tolerances on all major thermal properties. These variations are stacked, that is each variable is combined in such a way that each contributes to the worst case condition to the extent that such combinations are possible within the mission requirements and constraints. For example, the worst case cold condition for a satellite in earth orbit would probably consist of the following: (1) the orbit oriented such that the percent time in sunlight is a minimum; (2) the spacecraft is oriented toward the sun in a direction that the absorbed sunlight is a minimum; (3) the internal power dissipation is at minimum predicted values; (4) minimum values are selected for the solar constant and the earth albedo factor and a value is selected for the equivalent black body temperature of the earth which is consistent with the assumed values of the solar constant and the albedo factor (see Reliability Preferred Practice Guideline No.GD-AP-2301); (5) minimum solar absorptances and maximum thermal emittances of the thermal coatings are selected; and (6) a value is assumed for the effective emittance or thermal conductance of the multilayer insulation blankets which contributes to the coldest condition. This philosophy is conservative to the extent that the worst case condition as defined above may be unlikely to occur. However, the experience with spacecraft and instruments that have been flown has been that many of the variables do occur in worst case combinations. Experience has also shown that temperatures in test and in flight often vary from predicted values, so that some conservatism is necessary to compensate for inaccuracies in the thermal models. References: quotSINDA\/FLUINT, Systems Improved Numerical Differencing Analyzer and Fluid Integrator, Version 2.5, User's Manual,quot Martin Marietta, MCR-91-1393, December 1992. quotThermal Radiation Analyzer System (TRASYS),quot NASA JSC-22964, April 1988. quotOrbiter\/Payload Thermal Integration Model (OPTIMOD),quot NASA JSC-22437, April 1987. NASA SP-8105, quotSpacecraft Thermal Control,quot May 1973. quotProgram Manual for the Simplified Space Payload Thermal Analyzer (Version 3.0\/VAX,quot Arthur D. Little, Inc., ADL Reference C-89216, October 1986. Reliability Preferred Practice Number PD-ED-1204 Part Junction Temperature Reliability Preferred Practice Number PD-TE-1402 Thermal Cycling Reliability Preferred Practice Number PD-TE-1404 Thermal Test Levels Reliability Preferred Practice Number GD-AP-2301 Earth Orbit Environmental Heating","Lesson ID":695}
{"Driving Event":"This Lesson Learned is based on Reliability Guideline number GD-ED-2201 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: One of the most important considerations when mechanical fasteners are required is the selection of fasteners of certified quality that meet the requirements of the hardware assembly. Proper fastener selection and application is the first step toward building reliable hardware; therefore, a standard approved parts list consisting of a limited number of types and styles will result in optimum performance, reliability, maintainability, and economy. Implementation Method: Fastener reliability begins with the preparation of an approved parts list (APL), consisting of certified parts with proven performance, selected for the appropriate application, and procured only from approved suppliers. To ensure certified quality and reliability, fastener types and styles should be kept to a minimum, with fasteners obtained from an approved source. Fastener cost can be better controlled by implementing, in the initial phases of a program, a plan of consolidation and centralization of efforts related to fastener selection, receiving inspection, testing, and traceability. Providing sufficiently detailed design selection and procurement information for an APL requires that the fasteners be identified, described, and controlled by a Government specification or standard, an industry standard formally adopted by the Government for general applications, or a contractor specification or standard acceptable to the Government. Additionally, precautions should be exercised to ensure, as a minimum, that fasteners are procured from only qualified suppliers based upon surveyed performance. Critical fasteners, generally defined as used in either the primary or secondary load path of a structure, together with specialty fasteners, should be given particular attention to ensure that selection and procurement is only from approved manufacturers. An example of a specialty fastener would be a design created either in-house or by a manufacturer for a very specific and limited application (high strength, temperature, configuration). Care and good engineering judgment should be used at all times during design selection and procurement of fasteners for flight hardware, safety-critical facilities, and mission-essential ground support equipment to ensure that each design is examined from a reliability, maintainability, and producibility aspect. General criteria that should be examined for a suitable selection of fasteners include: Materials. Fasteners intended for critical applications should be made from corrosion and heat resistant steels or alloys such as A286 corrosion resistant steel (CRES), titanium, Inconel 718, or MP35N. Fasteners intended for GSE, noncritical, or non-flight hardware may be made from either 300 series or A286 CRES. The tensile strength for noncritical types of fasteners should be 130 ksi minimum. The maximum expected load (tensile and shear) and criticality for the applicable joint is important in the selection of fastener material. Stress corrosion sensitive fasteners should be avoided (refer to MSFC-Spec-522). Fasteners considered for use in composite structure must be selected to ensure conformance to requirements of material compatibility, acceptable installation procedures, and part configuration. Corrosion resistant steel fasteners should be passivated per MIL-S-5002 or QQ-P-35 during the manufacturing process. The passivation process will prevent rust spots from forming on corrosion resistant steel parts by removing embedded iron particles. Passivation must always be the last operation performed. Environmental conditions (salt spray, temperature, vibration, etc.) both for storage and operation should be considered so that material and finish requirements can be evaluated for galvanic couples. Spacecraft hardware may spend a considerable amount of time on earth due to factors such as assembly, test, and storage due to launch scheduling. Fastener selection should be based upon considerations of weight, cost, and availability. The operational aspects of the installation, extravehicular activity (EVA), intravehicular activity (IVA), maintenance and repair, together with initial assembly may require a unique or specialty fastener. An analysis should be performed early in the design and selection phase as a considerable impact may result to both the hardware design and cost if a specialty fastener is required. EVA\/IVA and Torque requirements. External wrenching fasteners should have a 12 point head for applications with tensile strengths above 180 ksi. Hexagonal heads (6 point) should be used for fasteners of 180 ksi UTS or less. Threads should also conform to MIL-S-8879 requirements \"Screw Threads, Controlled Radius Root with Increased Minor Diameter, General Specification for\". Captive fasteners should be used whenever possible for flight hardware. All nuts, nut plates, and threaded inserts should have an integral prevailing torque locking device. The minimum fastener head size for suited glove operation should be 1.5 inch diameter and .75 inch high. Sizes larger than 2 inches in diameter should be avoided to prevent the fastener from being larger than the maximum grip size of the smallest crewman. Fasteners that will be manipulated by tools or robots in space should have a standardized head size of 7\/16 inch (measured from flat to flat) for 1\/4 inch threaded fasteners, and 3\/4 inch head for 1\/2 inch threads. The thread sizes may be varied independently from the fastener head, thereby reducing or eliminating the requirement for different tool or end effector sizes, but allowing the fastener to be tailored to the application. The minimum head size must be considered in relation to the maximum torque required upon assembly. The assembly and operational aspects of the fastener may require lubrication or a special finish to insure reuse of the fastener during these phases. Lubrication. Silver plating should not be used on any fastener that would be removed and reinstalled more than twice as part of normal operation or maintenance procedures. Silver reacts rapidly with atomic oxygen to form silver oxide, therefore silver plated components should not be used in any application in which the part is directly exposed to atomic oxygen. Due to corrosion potential, silver plated parts must not contact titanium. Dry film lubricant is the preferred method of coating fasteners. Lubricants for fasteners should meet the vacuum stability requirements of JSC SP-R-0022, \"Vacuum Stability Requirements of Polymeric Material for Spacecraft Application\". Fastener procurement and testing. All received fastener shipments should contain reports of tests conducted on the parts at an accredited laboratory in compliance with Public Law 101-592 \"Fastener Safety Act\". All test reports require a similar format such as stated in Public Law 101-592, Section 5. Critical fasteners procured from sources other than the original manufacturer should only be accepted if original chemical and physical certifications can be validated and the lot traceability can be documented. Together with fastener testing, a system for providing traceability of parts to the initial assembly should be maintained, to reduce the time and associated costs of tracking problems concerning suspect hardware. Without traceability, the location of suspect hardware becomes difficult and may make dispositions very subjective and complex, perhaps leading to extensive disassembling of structure or other hardware. To maintain such a level of traceability, lot segregation should be implemented. Technical Rationale: Substandard and counterfeit fasteners in industry have heightened the government's concern about the reliability of hardware procured for use on various projects and programs. In response to this concern about the integrity of fasteners, Public Law 101-592, \"Fastener Safety Act\", has been enacted to provide an improved level of confidence in fasteners by requiring improved manufacturing, testing, certification, and quality assurance for all fasteners sold or delivered within the United States. References: 10107-70915, EVA Bolthead & Socket Interface Study & Definition, ILC Space Systems, Houston, Texas. MSFC-Spec-522, Design Criteria for Controlling Stress Corrosion Cracking, Marshall Space Flight Center.","Lesson ID":675}
{"Driving Event":"This Lesson Learned is based on Reliability Guideline Number GD-ED-2210 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Proper selection of the fiber, fiber-reinforcement form, and polymer matrix will produce a material system that 1) satisfies design property requirements thermal\/physical\/mechanical), 2) facilitates fabrication processes (lay-up and cure) and 3) minimizes program risks (cost, schedule, and technical). Implementation Method: Overview Unlike a monolithic, homogenous material or an alloy, a composite is composed of two or more materials that retain their identity on the macroscopic level. Materials composing a composite can be classified as a reinforcement or strengthening phase and a matrix or binder phase. Reinforcement materials can be ceramics, polymers, or wires. Reinforcement forms can be continuous fibers, discontinuous or chopped fibers, whiskers, particles, platelets, etc. Matrix materials can be polymers, metals, or ceramics. The primary consideration of this guideline is fiber reinforcements and thermoset polymer matrices in the most common product form, a prepreg (pre-impregnated and partially cured) sheet or ply. This is done out of practical considerations, since these composites possess the highest structural efficiency (specific properties) and are the most highly developed in terms of processing methods and material characterization (data base). Much of the information in the guideline is, however, relevant to other manufacturing forms and methods, such as Resin Transfer Molding, Filament Winding, Fiber Placement, Pultrusions, and Injection Molding. The content by volume of fibers in the composite is a critical parameter from which the composite derives thermo\/physical\/mechanical properties. A body of science called micromechanics [references 1-4] exists to predict the properties of composites as a function of fiber volume given the material properties of the reinforcement and matrix. Micromechanics will not be discussed in this article. Fiber reinforcement in a ply can be unidirectional or multidirectional. The latter applies to woven and non-woven fabrics. Choice of reinforcement form is a degree of freedom that can result in better processing and labor savings in part fabrication. Plies with either or both reinforcement scheme are stacked and cured to make a laminate. The ply fiber angles in the laminate are oriented to satisfy application design requirements (stiffness, strength, thermal expansion, etc.). Laminate design\/analysis methods will not be covered in this article. Information on this subject can be found in many publications [references 5-8]. The matrix phase is typically the material that most affects the processing, and most directly the curing of the composite. Choices for polymer matrices include a variety of epoxies, polyimides, and others. The choice of polymer matrix determines to a great degree the operational temperature limits for the composite. The matrix phase also affects other physical properties, such as outgassing and moisture diffusion. Lastly, there are additional considerations that include economic, experience (flight history), and safety considerations that factor into the selection of a composite material. Table 1 summarizes relevant selection considerations for a fiber-reinforced composite with a polymer matrix. A more detailed discussion of the selection considerations follows. Table 1. Composite Selection Considerations Fiber Considerations Thermo\/physical\/mechanical properties and relevance to end application Ply thickness and tow size availability Ply flexibility and part curvature Sizing and surface treatments for matrix bonding and wetting Cost, availability, lead time, and stable supply source Reinforcement Considerations Part curvature Ply thickness Laminate ply orientations Machining Weaving styles (drape) and weaving vendors Cost, availability, lead time, and stable supply source Resin Considerations Fiber sizing compatibility and wetting Cure temperature and related items: laminate residual stresses, tooling expansion, upper use temperature, composite glass transition temperature (Tg), and microcracking Prepeg handling characteristics: tack, drape, outlife Flow characteristics and processing method Mechanical properties: shear and tensile strength, modulus and strain compatibility with the reinforcing phase Physical properties: outgassing, moisture absorption\/diffusivity\/swelling, others Toxicity and health concerns Cost, availability, lead time, and stable supply source Other Considerations (Composite Level) Material characterization data base Flight history Cost, availability, lead time, and stable source Fiber Selection The designer or material specialist has a wide range of fibers from which to make a selection. Often a fiber is selected because of physical properties. For example, graphite or carbon fibers are electrically and thermally conductive, while aramid (Kevlar\u00ae) and glass fibers are non-conductive. In certain applications, such as an antenna reflector, electrical conduction is required. Hence, graphite (carbon) fibers are generally chosen for reflector-type applications. In other applications, for example a radome, radar transmissibility is desired. Here, Kevlar\u00ae and glass fibers are the materials of choice. Fiber selection should also consider mechanical and thermal properties. The salient mechanical properties are modulus and strength. Those for thermal properties include coefficient of thermal expansion (CTE) and thermal conductivity. Table 2 presents typical properties of some commercially available fibers presently utilized for space and spacecraft structures. Table 2. Typical Fiber Properties (Axial Direction) Trade Name\/ Type Young's Modulus (Msi) Tensile Strength (Ksi) CTE (PPM\/\u00b0F) Thermal Conduct. (BTU\/hr- ft-\u00b0F) Density (Lb\/in3) T300 33.5 530 -0.3 5 0.064 AS4 33.5 530 0.065 IM7 41.1 710 -0.5 9 0.065 T50 56.4 350 -0.55 40 0.0654 UHMS 64 550 0.067 P75S 75 300 -0.72 107 0.072 P100S 105 325 -0.8 300 0.078 Kevlar\u00ae 49 18 525 -2.2 5.3 0.052 E-glass 10.5 500 2.8 0.56 0.094 S2-glass 12.6 665 3.1 0.090 Quartz 10 500 0.3 0.0795 K1100 130-145 350-550 -0.9 550-676 .0777-.0813 M46J 63.3 611 -0.5 0.0665 M50J 69 569 -0.55 57 0.0672 M55J 78.2 583 -0.61 90 0.690 M60J 85.3 569 -0.61 88 0.0694 XN-50 75 530 -0.8 100 0.0773 XN-70 105 530 -0.9 180 0.0780 XN-80 114 530 -0.9 235 0.0780 Often figures of merit (FOMs) are used in fiber selection. FOMs are ratios of composite material properties [references 5,6], for which the fibers may be unidirectional or cross plied depending on the application. Some typical FOMs are E\/r, F\/r, E\/r\/a, and Ek\/r, where E, F, r, a, and k denote Young's modulus, strength, density, coefficient of thermal expansion, and thermal conductivity, respectively. Broadly speaking, most structural applications fall into two categories: strength critical and stiffness critical. The choice of fiber must be attuned to the driving design requirement of the application. For example, in primary structure, strength is usually the dominant factor influencing fiber selection. Therefore, F\/r is the appropriate FOM for fiber selection. Whereas in secondary structure having vibration frequency and\/or deflection requirements, stiffness may be the dominant selection factor. In this case E\/r is the pertinent FOM. For dimensionally stable applications, E\/r\/a is the meaningful FOM. For thermal applications, Ek\/r is a relevant FOM. Tensile strength and modulus are controlled principally by the fibers in the composite. Compressive and shear properties, however are derived from both the fiber and matrix and the interface (bond) between them. The thickness of a ply or layer is also determined by the fibers, more specifically the fiber diameter and the number of fibers in bundle or tow. Thin plies (2.5 mils or less) require low tow counts (500 to 1000 filaments), which are not available for some fibers. Ply flexibility, which is a function of fiber modulus and ply thickness, should be considered with respect to part curvature. For example, the brittleness and thickness of a ply with ultra-high modulus carbon fiber may preclude its use in fabricating a deeply curved part. The choice of fiber also can impact the type of reinforcement form possible. For example, ultra-high modulus graphite fibers may present weaving difficulties, which can preclude the availability of certain fabric styles with tight weaves. The availability of fabric woven with high-modulus fibers has improved greatly in the recent past. Lastly, fiber selection must consider wetting, bonding, and material compatibility of the matrix resin. A coating or sizing on the fibers is applied for these purposes. In material selection, one should be aware of the importance of a proper coupling agent between the fibers and resin. This is particularly important for carbon fibers. Coupling agents for carbon fibers are usually proprietary formulations of the fiber producer or the prepreg vendor. Reinforcement Form Choices of fiber reinforcement forms include unidirectional and multidirectional. Selection aspects of each form are discussed below. The most commonly used product containing unidirectional fiber reinforcement is prepreg tape. Unidirectional tape has collimated bundles of fibers called tows, which run in the length or long direction of the tape. Unidirectional tape gives the ability to tailor the fiber orientations from layer to layer in a laminate. This results in design flexibility. Also, the widest choice of fibers are available in unidirectional tape. Unidirectional tape is available in a range of widths. The choice of tape width can facilitate lay-up and can promote efficient material usage. An example of the latter is less wasted material from cutting ply pattern details. When laying up unidirectional tape, the continuity of the fibers should be maintained. End-to-end butt splices that result in fiber discontinuity should be avoided. On the other hand, butting the sides of adjacent layers with parallel fibers is permissible. Use of unidirectional tape to produce parts with deep, double curvature can prove difficult. Lay up may be facilitated by cutting the tape into narrow strips. However, labor increases in doing so. The most common multidirectional reinforcement form is woven fabric. Fabric weave styles can have drastically different draping characteristics, which is an important characteristic in making doubly-curved parts and those with integral flanges and bends. Harness-satin weaves are more drapable than plain weaves. Other desirable characteristics of fabrics include bidirectional properties at a minimum gage, resistance to microcracking (matrix splitting between fibers), and good machining characteristics. In a woven fabric, the fibers will be curved to some degree or another depending on the weave style. Fiber curvature results in decreased composite moduli and strengths, especially in compression. Weaving also reduces the volume available for fibers in the composite. As a result, laminates made from woven fabric composites are less structurally efficient than those made from unidirectional tapes. Recent manufacturing advancements have made possible ultra-thin unidirectional and fabric reinforced composites. These materials have been manufactured in a thickness of one mil or less for unidirectional prepreg and about two mils for fabric prepreg. Such ultra-thin composites are especially attractive for lightly-loaded, minimum gage structures. Here, the weight of the structure and, importantly, the weight savings potential of the composite are directly proportional to layer thinness. Other benefits of ultra-thin composites include less micro cracking under thermal cycling and the potential for more homogeneous laminate stacking sequences for a given laminate thickness. The latter usually results in improved strength due to a more thorough interspection of ply-angle orientations in the laminate stacking. The disadvantages of ultra-thin composites are increased handling difficulty, cost, and lead time. Fabric prepregs may offer labor efficiency in lay ups. For example, a [0\/90] (Fiber angles are 0 degrees and 90 degrees) laminate needs 50% fewer plies to be laid up using an orthogonally woven fabric, since fibers in two directions are obtained with every ply applied. Some fabric prepregs are available with hybrid fibers, such as carbon warp-yarns and Kevlar\u00ae fill-yarns, which may provide more potential design solutions. Theoretically, the possibilities of fiber type and weave style are unlimited. Practically, off-the-shelf choices are limited. Certain non-standard fabrics made from high- and ultra high-modulus fibers can be obtained from specialty weavers. The design use of such fabrics should be tempered by cost and lead-time considerations. Matrix Selection The choice of prepreg matrix resin is of critical importance in fabrication. The composite part quality is extremely dependent on the resin matrix and its handling and cure processing characteristics. The matrix vendor is usually the vendor that makes the prepreg, i.e., incorporates the fibers in the matrix. Handling characteristics are most important during ply lay up. Here the tack and drape of the prepreg are critical properties. If the prepreg is too stiff and boardy, then difficulty will be encountered in making curved parts, such as hollow tubes. Maintenance of ply-to-ply fiber orientations can be affected as well. If the prepreg is too sticky, then positioning and, in particular, repositioning of layer during layup is difficult. The handling characteristics are affected by the cumulative exposure of the resin in the prepreg to room temperature. The time limit at room temperature is called the out-life of the prepreg. For large parts especially, outlife should be considered in resin selection. Some resins have out-lives as long as 30 days; others, only several days. The resin in the prepreg determines the cure temperature of a composite part. Most epoxies and polycyanates cure around either 250\u00b0F or 350\u00b0F. Polyimides cure at higher temperatures. The cure temperature usually determines the glass transition temperature (Tg), which is associated with the useful upper-temperature limit of a composite. (Prudent design practice is to limit the use of a composite to below its Tg. The safe number of degrees below Tg depends upon the magnitude and direction(s) of the applied load with respect to the laminate fiber directions. It is advisable to experimentally confirm the maximum usage temperature of a composite for a particular application.) A higher cure temperature or, alternatively, a post cure generally raises the Tg. However, a high cure temperature results in greater cool down or residual stresses, which arise from CTE mismatches: ply to ply and fiber to matrix. Also for elevated cure temperatures, the thermal expansion effects of cure tooling become more critical, which adds to the difficulty in making parts and achieving desired dimensions. Besides the cure temperature, the prepreg resin determines other important cure characteristics, such as rheology and viscosity. These characteristics affect consolidation of the layers, most notably in the amount of voids or porosity produced during cure. The choice of resin should be compatible with the consolidation process. For example, low-flow systems are usually unsuitable for vacuum-bag\/oven processing. High-flow, low-viscosity systems can present difficulties in net-resin (no bleed) processing, since resin leakage may be difficult to prevent. The resin material also affects the contamination concerns of the composite: outgassing and moisture diffusivity. For space use, a polymeric composite must pass mass-loss and condensibles requirements, such as those defined in SP-R-0022A, MSFC-SPEC-1443 and JSC 0022-A. In addition, moisture absorbed on the ground will be desorbed in orbit. This may result in undesirable shrinkage for parts with strict dimensional stability requirements. The resin must have suitable shear and extensional modulus, strength, and strain for the composite to function correctly. Matrix shear is the mechanism through which stresses are introduced and spread to the fibers. Matrix shear and tensile strength largely factor into the resistance of an unidirectional layer in a laminate to microcracking from thermo-mechanical loads. Also, the resin must have compatible extensional strain with the fibers in the composite. Lastly, the resin material determines the toxicity of the prepreg. Resin systems with carcinogenic compounds and other unsafe ingredients should be avoided. Other Considerations These considerations deal with the economics and experience with a composite. Economic considerations include cost and availability (lead time). Experience considerations include extent of data bases and previous successful flight applications. Some space applications are given in publications [9] and [10]. The importance of the stability of the material supplier or vendor should also be taken into account, as a long term source of supply is highly desirable and sometimes essential. References: Z. Hashin and B.W. Rosen, \"The Elastic Moduli of Fiber-Reinforced Materials\", ASME Journal of Applied Mechanics, Vol. 31, 1964, pp. 223-232. Z. Hashin, \"Theory of Composite Materials\", NASA CR-1974, 1972. R.M. Christensen, Mechanics of Composite Materials, John Wiley and Sons, New York, 1979. Z. Hashin,\"Analysis of Composite Materials - A Survey\", ASME Journal of Applied Mechanics, Vol. 50, 1983, pp. 481-505. DOD\/NASA Advanced Composites Design Guide, Air Force Wright Aeronautical Laboratories, Dayton, OH, prepared by Rockwell International Corporation, 1983 (distribution limited). Military Handbook,\"Polymer Matrix Composites\", MIL-HDBK-17-3C, 4 November 1992. R.M. Jones, Mechanics of Composite Materials, Hemisphere Publishing Corporation, New York, Washington, Philadelphia, and London, 1975. S.W. Tsai, Composites Design, Fourth Edition, Think Composites, Dayton, Paris, and Tokyo, 1988. M.M.Schwarz, Editor In Chief, Composite Materials Handbook, McGraw-Hill, Inc., 2nd ed., 1992. Engineered Materials Handbook, Vol.1 - Composites, ASM International, The ASM Composite Materials Collection, Metals Park, OH. Structural Laminate Composites for Space Applications, Reliability Preferred Practice PD-ED-1217. Selection of Spacecraft Materials and Supporting Vacuum Outgassing Data, Reliability Preferred Practice PT-TE-1410.","Lesson ID":689}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1108; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Super Ni-Cd batteries are perishable and their reliability is directly related to prudent handling and storage procedures. The development and implementation of appropriate project-unique procedures based on a set of proven guidelines assure that the optimum performance of Super Ni-Cd batteries is not degraded due to inappropriate handling and storage. Implementation Method: The Super Ni-Cd cell is an advanced Ni-Cd cell design developed by Hughes Aircraft company. It is constructed of electrodeposited positive (nickel electrodes), and negative plates (cadmium electrodes). The separator material is an inert polymer impregnated zirconium cloth interleaved with the plates and serves to insulate the positive plates from the negative plates and retain the electrolyte. The interelectrode spacing was increased in the Super Ni-Cd design to permit greater than 4 ml\/Ah of electrolyte. This is about 31 percent more electrolyte than in the conventional Ni-Cd cell. The plates are connected to the respective cell terminals which are attached to a cell cover and inserted in a steel case and welded shut. The electrolyte is normally 31 percent concentration of potassium hydroxide with Hughes Aircraft proprietary additives. It is added though the \"fill tube\" which is fitted with a pressure gauge. After the cell satisfactorily completes its manufacturing and acceptance testing, the fill tube is pinched off and welded closed. The manufacture of a hermetically sealed Super Ni-Cd cell is predicated on a delicate balance between the active material, the relative state-of-charge of the active material between the positive and negative plates at the time the cell is sealed, the amount of electrolyte placed in the cell at closure, the properties of the separator material, and the free volume allowed by the case design. The Super Ni-Cd cell, which has no free or excess electrolyte, is referred to as an \"electrolyte starved\" design. The primary prerequisite for a sealed-electrolyte starved cell to operate safely is that the positive plates be limiting on charge so that only oxygen is generated during overcharge. During charge some of the current is utilized in the generation of oxygen gas and when in overcharge, all the current is used in generating oxygen. This causes the cell pressure to increase to a level that is dependent on the recombination rate of oxygen at the negative electrode, the rate of diffusion of the oxygen through the separator, the amount of electrolyte in the cell, and the cell free volume. The cell pressure at 20 degrees C can typically be in the range of 50 to 65 PSIG. The negative plates of a cell contain approximately 50 percent more capacity than the positive electrode. Of this \"excess\" negative capacity, approximately 60 percent remains uncharged when the positive plates are fully charged. This uncharged material is referred to as \"overcharge protection\" and is required to prevent the plates from becoming fully charged and generating hydrogen gas. The remainder of the excess negative is in the charged state when the cell is fully discharged and provides over-discharge protection. It is referred to as precharge. On discharge, when the cell voltage drops below 1 volt, the positive plates are limiting, thereby leaving charged cadmium material to react with any residual oxygen when the cell is completely discharged. Typical pressure of fully discharged cells is 3 to 5 PSIG. A second reason for the positive plates to be limiting on discharge is to prevent the effects of negative capacity fading, which occurs during normal use, from causing losses in cell capacity. It is thought that capacity fading is related to the sizes of the cadmium crystals. It is most important that the overcharge protection is available for the entire life of the cell. Should the negative plates become fully charged, hydrogen gas is generated during overcharge and there is no effective mechanism within the cell for the recombination of H2 gas. If a cell is over discharged (potential reversed) H2 gas is generated at the positive electrode at a rate dependent upon the discharge rate. Because of the limited free space in a sealed cell, a cell that is reversed can quickly build up pressure and rupture the cell case or battery package. The Super Ni-Cd cell is a highly complex, interactive electro-chemical device where the present and future performance is totally dependent on its past history. This history includes the attributes and characteristics of the raw materials, the processing of these materials into components, the assembly of these components into a sealed cell, and all testing, handling, and storage. Consequently, a cell or battery is classified as perishable and treated accordingly. Since Super Ni-Cd batteries can be irreversibly degraded by improper use and handling, the following guidelines were developed for the use of battery engineers in developing project-unique Battery Handling and Storage Procedure and Requirement Documents. Guideline No. 1 - Flight batteries should be maintained charged in cold storage at a temperature of 0 degrees C (\u00b1 3 degrees C) and on trickle charge at a rate of C\/100 until required for installation into the spacecraft for battery\/spacecraft integration testing and for launch preparations. When a battery is placed in cold storage, it should be fully charged and wrapped with an anti-static bag and closed. This bag should be placed in another anti-static bag along with packets of desiccant. A battery stored by this method, up to three years after cell activation, is expected to provide several years of nominal performance in orbit. Guideline No. 2 - Flight batteries should not be subjected to extended spacecraft integration and test activities. The open circuit and intermittent use of Ni-Cd batteries during extended spacecraft integration and testing activities are known to significantly accelerate the degradation of batteries. Results from controlled tests have shown permanent and irreversible changes unlike anything observed after several years of spacecraft flight operations. Degradation is observed initially as an increase in cell overcharge voltage at low temperatures which is indicative of loss in overcharge protection. Also, NASA integration and testing use promotes significant cadmium migration. Both of these are recognized as the dominate wear-out mechanisms which determine battery life. Guideline No. 3 - Batteries that have been on open circuit for periods greater than 4 hours following a charge at a level of C\/100, should be discharged for 5 minutes at a 1.0 amp rate and then subjected to a top-off charge before operations are resumed. The use of charged batteries after an open stand should be initiated with a 5 minute discharge at a 1.0 amp rate prior to initiating battery charge as defined above. Typically, the discharge is done with spacecraft load and in concert with the spacecraft ground power console. During normal cycling use, the battery is discharged followed by a recharge and some overcharge. In this mode, there is always a partial pressure of oxygen from the overcharge with oxygen recombination occurring at the negative electrode. In a relatively short time on open circuit, the oxygen recombines and the internal cell pressure returns to a vacuum. Charging cells that are fully charged in the absence of oxygen creates an \"unnature\" condition, since there is no oxygen available to react with the negative electrodes. Past experience shows that this technique reduces the effects of open circuit stand on performance. Guideline No. 4 - For short-term storage of up to 60 days, the flight battery may be stored charged and open-circuited with the temperature controlled at 18 degrees C (\u00b1 5 degrees C). A top-off charge is applied to the battery biweekly (every 3-4 days). Trickle charge at low rates is preferred to open circuit stand for a battery. There are degradation mechanisms associated with this storage method, but data from controlled tests indicate that this is much less detrimental than prolonged open circuit stand. Guideline No. 5 - The preferred operational temperature for Super Ni-Cd batteries is 18 degrees C (\u00b1 5 degrees C). The periods when the batteries are exposed to temperatures above 23 degrees C should be minimized. Under no circumstances should the battery temperature exceed 30 degrees C with the exception of non-operational periods during Thermal Vacuum Testing (e.g. Hot Balance) where the allowed temperature should not exceed 33 degrees C. When testing is performed off of the spacecraft, the batteries should be mounted on a thermal cooling cart to maintain the battery in the required temperature range. When installed in the spacecraft prior to launch, the battery temperature should be maintained by the use of dedicated cooling air directed onto the battery or its baseplate when possible. Battery temperatures should be monitored via sensors installed in the battery assembly. Guideline No. 6 - A battery stored at cold temperatures and on trickle charge for a period greater than 30 days should be \"reconditioned\" prior to placing it in use. The reconditioning cycle at 18 degrees C is defined as follows: Warm battery at room temperature for minimum of 16-24 hours Discharge the battery at C\/2 constant rate until the first cell reaches 1.0 V Drain each cell with a 1 ohm resistor until each cell's voltage is less than .03 V or for 16 hours (+0\/-1 hour) whichever occurs first. Recharge at C\/20 rate for 40 hours (\u00b1 4 hours) Repeat steps (b) and (c) Recharge at C\/10 rate for 20 (\u00b1 1 hour) Note! * Never short a Super Ni-Cd cell or battery * Monitor and maintain battery temperature at 18 degrees C (\u00b15 degrees C) during the reconditioning cycle. Guideline No. 7- Batteries once removed from cold storage must be reconditioned every 30 days as described in Guideline No. 6. Guideline No. 8 - Flight batteries must be discharged and left on open-circuit stand during shipment. Batteries are packaged to control the temperature to 5 degrees C (\u00b1 5 degrees C). The shipping container is equipped with temperature recorders to provide assurances that flight batteries have not been exposed to temperatures exceeding 25 degrees C. Upon arrival at its destination, the battery is recharged and put on trickle charge. A Super Ni-Cd battery can deliver very high currents if shorted. High currents would create a safety hazard as well as destroy the battery due to the excessive heat that would be generated. Guideline No. 9 - The final reconditioning of flight batteries, using battery conditioning steps (b) thru (f) of Guideline No. 6, should be performed at least 14 days prior to spacecraft launch. Upon completion of the reconditioning, flight batteries are maintained on a C\/100 trickle charge rate until launch. The reconditioning cycle restores the battery discharge voltage to \"like new\" condition by enhancing the formation of small cadmium crystals and electrolyte redistribution. A complete discharge establishes capacity balance for all cells within a battery. The low rate trickle ensures that the battery is maintained at full state of charge for launch. Guideline No. 10 - The design of flight batteries should include the following provisions for ground console interfacing with the batteries while integrated in the spacecraft. Signal lines for monitoring total battery voltage, charge and discharge currents, battery temperatures, and individual cell voltages Capability to charge and discharge the battery from the ground test console Capability to place a resistor across each individual cell Capability is provided to monitor the state of health of batteries and to discharge, charge, trickle charge and recondition batteries without powering up the spacecraft in order to meet guidelines to minimize degradation of the batteries. Guideline No. 11 - A log book should be maintained on each flight battery including the complete test histories of each cell, of the assembled battery, and of all integration and test and launch site activities. Each log book identifies the project and battery and individual cell serial numbers. Chronological (date and time) entries for all test sequences, summary of observations, identification of related computer stored records, malfunctions, names of responsible test personnel, and references to test procedures controlling all tests are recorded. Technical Rationale: Super Ni-Cd batteries can be damaged and irreversibly degraded through improper use and handling prior to launch. The guidelines provided above were developed over years of experience in the use, handling, and testing of Ni-Cd batteries. Following these guidelines ensures reliable operation of flight batteries by precluding irreversible degradation from handling and storage, and promoting the proper reconditioning and preparations for launch. References: GSFC-FAST AURORAL Snapshot Explorer (FAST) Super Ni-Cd Battery Handling Plan (FAST-PROC-004) of February 1994","Lesson ID":694}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1218; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefits: Adhering to proven design practices and process controls during manufacture of ablative composite nozzle components will result in a high quality product with few rejects. Successful design and manufacturing of ablative composite materials for solid motor nozzles provides for proper transfer of the combustion gases from the burning propellant surface through the nozzle without damage to the metal structure. Use of a properly controlled manufacturing process will result in the proper density, percent resin content, compressive strength, interlaminar shear strength, thermal conductivity, coefficient of thermal expansion, and tensile strength. Implementation: The increased interest in carbon-phenolic composite materials at NASA is due to the use of these materials as the ablative materials in the Solid Rocket Motor (SRM) nozzle of the Space Shuttle and potential follow-on solid rocket motor upgrades. The practices discussed here are the current industry standards, and, however successful, much work is yet to be done. Most of the manufacturing practices have evolved by the trial and error method and could benefit greatly from further scientific investigation. Almost all of the nozzle materials and processes need continued research and development efforts as NASA strives for optimal performance from advanced materials. In the design of ablative nozzle components, considerable attention should be given to thermo-structural, thermochemical, process modeling and other computer predictive and analysis codes. Various computer based analytical and simulation programs are available and have been used successfully in characterizing ablative materials and their erosion, char, and thermal protection characteristics. Typical programs that have been used for this purpose are: Charring Material Ablator (CMA), Aerothermal Chemical Equilibrium (ACE), Momentum and Energy Integral Techniques (MEIT) (ACE and MEIT are used in conjunction with the CMA program), and PATRAN (geometry of nozzle, a general model for structural and thermal analysis). Computational Fluid Dynamics (CFD) is a discipline that is finding increasing usage in evaluating the exhaust flow in SRM nozzles and in determining potential heat transfer to nozzle components. These techniques are important tools for the designer who is applying ablative composites to solid rocket motor nozzles. [D] As shown on Figures 1 and 2, the aluminum structure of the SRM nozzle is protected from the heat of the expanding gasses by a series of carbon cloth phenolic rings backed up by glass or silica cloth phenolic rings. The glass and silica cloth phenolic backup rings are provided for structural, insulation, and galvanic corrosion protection. In lieu of one single ring, a series of rings is used for ease of manufacture and handling. Factors of safety for ablative carbon cloth phenolic vary between approximately 1.5 and 2.0 for erosion and are usually about 1.25 for char, depending upon the location of the ablative carbon cloth phenolic in the nozzle. Generally, the factors of safety in the entrance section of the nozzle are higher than in the exit section. The optimum angle between the plies and the flame surface in SRM nozzles using ablative carbon cloth phenolic has been proven to be between 30 degrees and 60 degrees, depending upon the location, contour and heating conditions at various sections of the nozzle. [D] Manufacture of Carbon Cloth: The carbon cloth used to fabricate composite solid rocket motor nozzles is impregnated with the binder or matrix prior to wrap and cure. This preimpregnated material is commonly called quotprepregquot in the composite industry. The diversity of the manufacturing process requires six different vendors before final material is produced. These vendors: 1) produce rayon thread; 2) weave cloth; 3) carbonize cloth; 4) produce resin; 5) produce carbon fillers; and 6) impregnate carbon cloth with resin and filler (production of prepreg). Constant monitoring of all phases of the manufacturing process is required to ensure satisfactory quality. The rayon thread is manufactured, then woven into cloth 60 in. wide. The rayon cloth is carbonized by slowly heating to 1000 deg. to 1500 deg. C in an inert atmosphere. Critical factors to be controlled in this process are the rate of temperature increase, time, and maintenance of an inert atmosphere in the oven. After carbonization, the carbon-cloth is impregnated by drawing it through a heated container of phenolic resin and carbon filler to form prepreg. Critical factors that must be carefully controlled in the preimpregnation process are temperature of the resin\/filler mixture, tension and speed of the cloth through the resin\/filler mixture, pressure on the roller to ensure penetration of resin into the cloth, oven temperature after impregnation to remove volatiles, and control staging of the resin. The prepreg should meet the uncured material acceptance test data properties shown in Table 1 and the cured material acceptance test data properties shown in Table 2. However, it should be pointed out that since the structural minimum - maximum properties shown on Table 2 vary by factors greater than 2 indicate that additional material, process and cure controls improvements are required to narrow the variation in material capabilities. Table 1. Uncured Material Properties of Carbon Phenolic Property Percent by Weight Retest Properties Percent by Weight 1\/ Minimum Maximum Minimum Maximum Cloth content Dry resign solids Volatile content Carbon filler content Resin flow 47.0 32.0 3.5 8.0 10.0 60.0 37.0 6.0 16.0 20.0 \u2014 \u2014 3.5 \u2014 8.0 \u2014 \u2014 6.5 \u2014 23.0 1\/ Procuring activity verification of potential extension of material shelf life after six months from date of supplier manufacture The prepreg material has a six-month shelf life from date of manufacture. Potential shelf life may be extended if the material meets the retest properties of Table 1. The prepreg tape rolls should be cut on a 45 deg. bias in widths of 3 in. and 12 in. The bias cut allows the cloth to stretch and conform to the different mandrels, and the narrow widths help avoid wrinkling and folding of the material during the wrapping process. The rolled prepreg is bagged with desiccant and stored in an environmentally controlled cold storage until it is required for processing. Glass Cloth Phenolic: The glass cloth phenolic shown in Figure 2 is used to provide structural integrity, a corrosion barrier, and insulation. It is fabricated in a manner similar to that of carbon cloth phenolic. The product should conform to the uncured material acceptance test data properties and the cured material acceptance test data properties shown in reference 5. Table 2. Cured Material Physical and Mechanical Properties of Carbon Phenolic (At Room Temperature Unless Otherwise Specified) Property Limits Minimum Maximum Density, grams per cubic centimeter (g\/cc) Resin content, percent Compressive strength, psi (edgewise) warp direction fill direction Interlaminar double shear strength, psi Thermal conductivity, Btu\/ft-hr-degrees F at 250 deg. F across ply with ply Coefficient of thermal expansion in\/in-degrees F x 10 exp -6 at 400 deg. F across ply with ply Flexural strength, psi warp direction fill direction Tensile strength, psi (edgewise) warp direction fill direction 1.4 30.0 25,000 20,000 3,500 0.10 0.10 5.0 2.0 25,000 20,000 15,000 10,000 1.52 38.5 65,000 55,000 8,000 1.1 1.1 20.0 9.0 55,000 55,000 40,000 35,000 Silica Cloth Phenolic: The silica cloth phenolic shown in Figure 2 is also used to provide structural integrity, a corrosion barrier, and insulation. It is fabricated in a manner similar to that of carbon cloth phenolic. The product should conform to the uncured material acceptance test data properties and the cured material acceptance test data properties shown in reference 6. The silica cloth phenolic is a higher purity material than the glass cloth phenolic, and is only used in the cowl ring. Nozzle Ablative Composites Fabrication: The fabrication process for the components of the nozzle includes two tape wrappings and two machining operations. Because of the sensitive variables occurring during tape wrapping of the prepreg tape, a highly skilled operator is required who understands what is required when one of the variables changes. The critical manufacturing variables are heat input, cooling input, roller pressure, machine speed, and tape tension. There are many other random variables that play a less significant role. The material is wrapped onto a mandrel which has been machined to the desired contour of the component as specified in the manufacturing plan. Depending upon the component location, the first wrap could be either bias-cut carbon cloth phenolic, glass cloth phenolic, or silica cloth phenolic tape wrapped on the mandrel at a specified angle (which depends upon the nozzle component) to the centerline of the nozzle. Enough tape should be wrapped to provide machining stock and tag ends after cure. The tape wrapping process places the tape at the proper angle and debulks the tape material to minimize movement of the tape during cure. Debulking of the tape should be achieved by applying heat and pressure at the point of contact with the mandrel or the previous ply. Heat should be applied prior to wrapping to make the tape tacky. The pressure roller forces the fibers to nest and compact (debulk) within the resin\/fabric matrix. CO2 is used to cool the resin to stop further cure, and dimensionally and thermally stabilizes the billet for further processing. All ablative components are cured in a hydroclave except the aft exit cone, outer boot ring, and the cowl, which are cured in an autoclave. After wrapping, the billet and mandrel are vacuum bagged for waterproofing, then installed in a hydroclave for final cure. Curing of the carbon-cloth liner requires a pressure of 1000 psi at 310 deg. F for a minimum of five hours. After the cure cycle, a test ring should be removed and tested to verify the properties of the cured carbon cloth phenolic. The carbon cloth is then machined to configuration. In preparation for the second wrap, a coat of phenolic resin is applied to the machined surface of the first layer of phenolic. The second layer of phenolic tape is wrapped at the desired angle to the nozzle centerline using the same process as described for the carbon-cloth phenolic. The component is vacuum bagged and cured in an autoclave at 250 psi at a temperature of 310 deg. F for approximately four hours. Carbon and glass rings should be removed and tested to verify properties of the cure. The billet is final machined, removed from the mandrel and x-rayed to verify absence of voids, delaminations and low density indications. Following x-ray, the machined component is ready for bonding to the metal housings. Bonding of the machined ablative component to the metal housing is accomplished in a clean environment and requires strict process control. Inspection, Destructive, And Non-Destructive Evaluation: A very important development in nondestructive testing that promises to help maintain the meticulous cleanliness required to ensure bonding of composites to adjacent metallic structures is computer controlled scanning of the metal surface with devices based on Optically Stimulated Electron Emission (OSEE) principle. Computer controlled contamination scanning (CONSCAN) is a system developed by MSFC using the OSEE technique for automated scanning of metal surfaces prior to critical bonding operations. The CONSCAN system provides the sensitivity and spacial resolution necessary when scanning large areas to ensure that surfaces are sufficiently free of contaminants that reduce bond strength. Scanning the surface with CONSCAN provides a map of surface contamination levels, which clearly identifies those areas that require further cleaning. Rescanning after the additional cleaning operation provides results of that recleaning. These data provide a permanent record of surface cleanliness levels. The data records may be used at a later date to help identify the specific process during which contamination occurred and to correlate surface cleanliness levels with subsequent debond locations. The carbon cloth prepreg, glass cloth prepreg, and silica cloth prepreg should be visually inspected to ensure that there are no broken fibers, voids, or lack of resin or filler. Coupons of these materials should also be tested to verify uncured and cured properties. After final machining of both glass cloth and carbon cloth wraps, the materials should be x-rayed to verify absence of voids, delaminations, and low density areas. Defects of this type may be cause for rejection and scrappage. An alcohol wipe may be performed on the finished surface. Collection of alcohol in a spot or line before drying, will indicate a crevice or void in the surface. The x-ray technician should be highly skilled in taking and reading the x-rays to avoid scrapping an expensive component due to erroneous low density indications. Low density indications could be caused by fiber ends not being flush with next butt end and the gap being filled with resin and filler, density variations, and interlaminar resin-rich areas. The tag ends and rings removed after curing should be used to verify mechanical properties. Tag ends and rings could also be used for plasma torch testing to verify the erosion rate and the factor of safety. Technical Rationale: Precision design and manufacturing procedures for ablative material for solid rocket motor nozzles have been developed over a period of 30 years. The design of the ablative material depends upon factors such as the solid propellant composition; combustion gas temperature, velocity and composition; and relative position of the material in the nozzle. Problems that have surfaced over the years were analyzed, improvements proposed; and, when approved through the NASA change board process, were designed, prototyped, ground tested and flown. Information for this practice was derived from a number of sources, including procurement specifications and manufacturing plans for the SRM and RSRM experimental studies, problem reporting and corrective action (PRACA) reports at MSFC, AIAA reports, and from personal interviews and telephone interviews with individuals from MSFC organizations and contractor organizations. References: Hall, William B.: quotStandardization of the Carbon-Phenolic Materials and Processes, Volume I, Experimental Studies,quot Professor of Chemical Engineering, Mississippi State University, August 31, 1988. Kelly, P. and Thompson, A.: quotAIAA 89-2661 Low Density Indications in Radiographs of Solid Rocket Motor Ablatives,quot 25th Joint Propulsion Conference, Morton Thiokol Inc., July 10-12, 1989. TWR-10341 (CD) Rev. D: quotManufacturing Plan for Space Shuttle Redesigned Solid Rocket Motor Project,quot Prepared by Morton Thiokol Inc., Manufacturing Engineering, NASA Contract NAS8-30490. TWR-10341 (CD) Rev C: quotManufacturing Plan for Space Shuttle Redesigned Solid Rocket Motor Project,quot Prepared by Morton Thiokol Inc., Manufacturing Engineering, NASA Contract NAS8-30490. STW5-2651F: quotGlass Cloth Phenolic, Preimpregnated Specifications,quot Morton Thiokol Inc., May 5, 1987. STW5-2652E: quotSilica Cloth Phenolic, Preimpregnated Specification,quot Morton Thiokol, Inc., August 13, 1987. STW5-3279A: quotCarbon Cloth Phenolic, Preimpregnated Specification,quot Morton Thiokol, Inc., May 8, 1987. MSFC: quotProblem Reporting and Corrective Action (PRACA) Systems,quot Run Dated Nov. 1, 1991, PRACA Record Numbers A07293, A08066, A09099, A11024, A11356, A11466, A12155, A12234, A12235, A12242, A12430, A12438, A13394, A09676, A09677, A10979, A11854, A11855, A11054, A11076, A11108, A11133, A11182, A11659, A11686, A12979, A13812. Nichols, R. L.: Solid Propulsion Integrity Program (improvements made through this program), ER41 Solid Propulsion Research and Technology Office, Marshall Space Flight Center, AL. Sutton and Ross: quotRocket Propulsion Elements,quot Fourth Edition, Wiley and Sons. Proceedings of Rocket Technology Subcommittees of The Chemical Propulsion Information Agency, 1989, 1990, 1991.","Lesson ID":672}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PD-ED-1235 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefits: This design employs a simple method of providing protection against the effects of a crane operating at a higher than commanded speed while not introducing unwanted nuisance trips to the crane control system. This improves the reliability of the crane control system by preventing the crane from reacting to unwanted commands that are not operator initiated. The improvement allows the crane to be used with a higher degree of confidence that a critical failure will not result in damage to the load suspended from the load hook. Implementation Method: The design provides protection against damage to a load resulting from a crane drive system experiencing a speed increase caused by an unexpected input created by a failure of the electrical circuitry used to convey the operator stick input to the drive motors. The voltage sensing relay is set to detect a voltage that is larger than the normal operating voltage of the DC motors in the selected speed (slow, medium, or high). When this voltage is experienced, the relay will shut down the crane operation and set the brakes. For example, at KSC while performing stacking and mating operations of the Solid Rocket Motors (SRM), External Tank (ET), or Orbiter during Space Shuttle processing, the crane must be operated in the slow speed mode when within close proximity of a structure. The voltage sensing relay is active during this mode to prevent the shuttle components from impacting a surrounding structure as a result of a control circuitry failure. The relay is deactivated while operating in the medium or high speed modes because the critical load is not near an obstruction. This allows the crane to be operated with a higher degree of confidence and reliability that a critical failure will not result in damage or loss of critical flight hardware during stacking and mating operations. Technical Rationale: With a constant field\/varied armature DC motor (more than one motor, the armatures wired in series) the voltage sensing relay coil should be placed in parallel to the motor armature(s) (see Figure 1.). The relay coil should be fed through a bridge rectifier to insure the input to the relay is consistent regardless of the voltage polarity and direction of current flow present in the armatures. The normally open relay contact should be wired in series with the power supplied to the crane and brake controls. When power is applied to the crane the contact should close and enable the drive control circuitry. The contact will remain closed when the voltage in the motor armature is below the predetermined threshold. When the limit is reached, approximately 115% of the full output of the speed range, the contact will open disabling the crane drive and setting the brakes to stop the crane. To avoid the crane shutting down when in the higher speed range, a time delay relay will be energized by the speed selector switch and by pass the voltage sensing relay. To prevent nuisance trips when the speed selector switch is repositioned from the higher to the lower speed range while the crane is moving, the time delay relay will disable the voltage sensing relay for a short predetermined time period when it is de-energized. [D] References: 69-K-L-11388: quotVehicle Assembly Building 250-Ton Bridge Crane #1 & #2 Electricalquot SAA09FY12-005: quotSystem Assurance Analysis of the 250-Ton Bridge Cranes at the Vehicle Assembly Building, High Bays 1, 2, 3 & 4quot 67-K-L-11348: quotVehicle Assembly Building 175-Ton Bridgequot Crane Electrical. SAA09FY12-006: quotSystem Assurance Analysis of the 175-Ton Bridge Cranes at the Vehicle Assembly Buildingquot","Lesson ID":673}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PD-ED-1223 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefits: Leak free flanges as well as low\/undetectable outgassing of the elastomeric materials can be achieved at pressure levels as low as 10-8 Torr by using well made O-rings in a static vacuum seal environment. The use of O-rings has provided ease for running environmental tests on the ground using space simulation chambers. Implementation Method: The most common type of seal used for sealing vacuum systems is the O-ring. In order for any O-ring to be suitable for high vacuum service, it must have a very low vapor pressure at the service temperature. It must not have any components or materials which will vaporize at the pressures and temperatures to which the joint will be subject. Butyl, Buna-N and Fluorocarbon (Viton\u00ae A) rubber materials have been used to vacuum seal large chambers (15 foot and 25 feet in diameter) at LeRC. These materials can, in well made, clamped O-rings and under temperature controlled conditions, seal vacuum as low as 10-8 Torr. Small (6 foot diameter) and large (50 foot diameter) vacuum chambers have been successfully used on research programs at LeRC to simulate space pressure conditions and environment. Environmental testing, experiments, and pre-flight tests (all requiring large-volume vacuum environment) have been performed at LeRC in these chambers. For this pressure range, the following O-ring design considerations should be followed: Dimensional. To obtain the correct degree of compression for optimum O-ring sealing, careful consideration must be given to the size of the O-ring in relation to the size of the groove space into which the O-ring is being installed. Every groove has a slight gap (diametrical clearance) between the two mating surfaces forming the groove's internal cavity. It is important, therefore, for O-ring volume to be larger than the cavity, allowing seal compression to block the diametrical gap, preventing leakage and providing 25% compression in the O-ring. Butyl rubber has been tested in face type O-ring seals using grooves that provided 15%, 30% and 50% compression. For vertical O-ring applications (as a chamber), it is desirable to use an undercut groove similar to that shown in Figure 1. The O-ring is held firmly in place and has no tendency to drop out of the groove when the chamber is open. [D] Pressure. Total clamping pressure on the O-ring due both to the effects of vacuum on the parts being closed, and the effects of bolts or clamps used with the O-ring, should be approximately 800 pounds per lineal inch of O-ring. If the O-ring cannot resist increasingly high pressure, part of the O-ring will be forced (extruded) into the diametrical gap, causing tearing, pre-mature failure and leakage. To minimize O-ring movement and accompanying wear within the groove in face sealing, involving either internal or external pressure, the O-ring should always be seated against the low pressure side of the groove. The use of two O-rings on the chamber's sealing surface has proven successful in holding the required pressure applied on the 15 foot diameter seal as illustrated in Figure 2. The reason for the two O-ring design is that it is possible to pump out the space between the two O-rings. The effect of this technique is to make use of the outer O-ring for holding a relatively crude vacuum and subject the inner O-ring to only a small differential between the high vacuum system on its inner face and the partial vacuum on its outer face. As a result of this double pumped system, the leakage per O-ring can be greatly reduced. [D] Vapor Pressure. The O-ring must have a very low vapor pressure at the service temperature. It must not have any components which will vaporize at the pressures to which the joint will be subject. Resilient organic material such as Viton\u00ae A is most commonly used to produce and hold vacuum as low as 10-9 Torr. Temperature. The vapor pressure of most or all organic materials is proportional to temperature. It is therefore very important that O-ring's temperature be limited. The best of the materials must be held below 250\u00b0F, and for minimum outgassing an even lower temperature is recommended. For temperatures held below 65\u00b0F, it is possible to use carefully constructed O-ring joints at pressures as low as 10-9 Torr. Excessive heat, over time, degrades O-ring materials physically, and\/or chemically, which may render them non-functional as seals. The O-ring temperature must be reduced to values between zero and -10\u00b0F during ultra vacuum operation. Surface. It is important that the groove surfaces be so ground and polished that no residual tool marks or scratches occur at right angles to the length of the groove. Even minute scratches can produce a leak, which is difficult to locate and repair. The mating flanges, which are flat and serve to compress the O-ring must have, at the point where the O-ring contacts them, an equally good finish. The surface finish in the O-ring groove and on the flat mating flange must be at least 32 micro inch and preferably 16 micro inch. Permeability. In vacuum applications, high material resistance to gas permeation is directly equated with low vacuum leakage of the O-ring. Butyl and Fluorocarbon excel as the most impermeable performers. Increased O-ring compression reduces permeability by increasing the length of the path the gas has to travel (width of ring) and decreasing the area available to the entry of the gas (groove depth). Increased compression also tends to force the rubber into any small irregularities in the mating metal surface, and thus prevents leakage around the seal. Vacuum Weight Loss. It is particularly important in many space and other vacuum applications that optical surfaces and electrical contact surfaces remain clean to serve their intended purpose. Some rubber compounds contain small quantities of oil or other ingredients that become volatile under high vacuum conditions and deposit as a thin film on all the surrounding surfaces. Table 1 indicates the weight loss of several compounds due to vacuum exposure. Where sensitive surfaces are involved, the higher weight loss compounds should be avoided. In the low weight compounds, the small amount of volatile material that is indicated is primarily water vapor which is not likely to deposit on nearby warm surfaces. Table 1. Weight Loss of Compounds in Vacuum Test Samples: Approximately 0.075 thick Time: 336 hours (two weeks) Vacuum Level: Approximately 1 x 10 -8 torr Room Temperature Compound Number Polymer Percent Weight Loss Compound Number Polymer Percent Weight Loss B612-70 C873-70 E515-80 E529-60 E692-75 L449-65 L677-70 N406-60 Butyl Neoprene Ethylene Propylene Ethylene Propylene Ethylene Propylene Fluorosilicone Fluorosilicone Nitrile 0.18 0.13 0.39 0.92 0.76 0.28 0.25 3.45 N674-70 P648-90 S455-70 S604-70 V747-75 V884-75 V894-90 Nitrile Polyurethane Silicone Silicone Fluorocarbon Fluorocarbon Fluorocarbon 1.06 1.29 0.03 0.31 0.09 0.07 0.07 Vacuum Seal Considerations. The rate of flow of gases from the pressure side to the vacuum side of a vacuum seal depends to a great extent on how the seal is designed. As mentioned earlier in this document, increasing the compression reduces the leak rate. Lubricating the O-rings with a high vacuum grease also reduces the leak rate significantly. The vacuum grease aids the seal by filling microscopic pits and grooves produced by small irregularities in the mating metal surface. The O-ring should first be cleaned to remove all dirt and foreign material utilizing a small amount of Alcohol on a cloth as a cleaning agent, and should be given a very thin coat of vacuum grease (i. e., Apiezon grease) applied by drawing it through fingers slightly coated with vacuum grease. It should be noted that vacuum grease should not be depended upon to provide any sort of vacuum seal. Vacuum Leak Approximation. The leak rate of a gas through an O-ring seal may be roughly approximated when the permeability of the gas through a particular material is known for the temperature at which the seal must function. The following formula is useful for this approximation: L ~ 0.7 F D P Q (1-S)2 L = Approximate leak rate of the seal,std. cc\/sec. F = Permeability rate of the gas through the elastomer at the anticipated temperature, std. cc cm\/cm2 sec bar. (example: Butyl's 2 permeability at 77\u00b0F with Acetylene is 1.26 x 10-8 std. cc cm\/cm2 sec bar) D = Inside diameter of the O-ring, inches. P = Pressure differential across the seal, lb\/in2. Q = Factor depending on the percent compression and whether the O-ring is lubricated or dry (from figure 3 below) S = Percent compression on the O-ring cross section expressed as a decimal (i.e. for 20% compression, S = 0.20) Note: This formula is a rough order of magnitude approximation and is based on the following assumptions: The cross section of a compressed O-ring is rectangular. The cross section area of a compressed O-ring is the same as its area in the free condition. The permeability rate of a gas through an O-ring is proportional to the pressure differential across the seal. [D] Static Seal Cross Section Calculation. To calculate correct cross section dimensions for static seals, list the gland depth and multiply by the minimum and maximum compression requirements (listed in Table A, Section 3 of Reference 5). For Inside Diameter (I.D., or hole diameter) calculation, list the diameter of the part the O-ring will be stretched over during installation, and reduce this figure by 1 to 5% to undersize the O-ring's I.D, allowing for stretch. Vacuum Feedthroughs. Many types of vacuum feedthroughs are available from suppliers as Varian Vacuum Products (Reference 6). They are designed for pressure as low as 10-11 Torr and provide leak-free performance in high and ultrahigh vacuum systems. With ceramic-to-metal seal construction, applications for these feedthroughs include: Instrument and Thermocouple Leads, RF Power Input, Coaxial Input, Mask and Substrate Handling, Target Movement, Liquid Cooling, High Voltage Conduction and High Current conduction. As an example for using one type of feedthrough, electrical circuits carried into and out of ultrahigh vacuum systems must be of ceramic-to-metal seal construction. A tight bond is made between a ceramic and a kovar transition sleeve which is then welded into the stainless steel of the vacuum vessels. The actual electrical feedthroughs come through the center of the ceramic insulator and are bonded to it by special bonding techniques to achieve gas tightness. It is important that electrical leads inside ultrahigh vacuum systems must be insulated by means of non-outgassing materials. These leads should be limited to ceramic beads since all of the elastomeric type insulating materials outgas a considerable amount in vacuum systems. Rotating Seals. O-rings are used as seals for rotating shafts, with the turning shaft protruding through the internal diameter of the O-ring. The inside surface of the O-ring is continuously exposed to friction generated heat from the rotating shaft. The most important factors to consider when designing rotating seal glands are frictional heat buildup, O-ring stretch, compression, application temperature limits, and shaft glandular machining. O-rings should be comprised of compounds featuring maximum heat resistance and minimum friction generating properties. To help minimize O-ring heat buildup, the following mechanical design safeguards should be considered where applicable: Reduce compression to 0.002 inch to minimize friction. Select the O-ring with the smallest possible cross section. Select an O-ring comprised of a hard, self-lubricating compound (such as graphite). Avoid applications requiring lower than -40\u00b0F, or higher than +250\u00b0F operating temperatures. Locate the gland as close as possible to the lubricating fluid and as far away as possible from the shaft support bearings. Assure that relative motion occurs only between the O-ring internal diameter and the rotating shaft, not between the O-ring and the gland. This can be accomplished by minimizing eccentric shaft rotation (machining shafts concentric to within 0.0005 inch TIR); by finishing shaft surfaces to 16 micro inch (for smooth, non-abrasive running); and machining gland surfaces to a rougher 32 micro inch (to discourage O-ring movement within the gland). Technical Rationale: Vacuum chambers (ranging from 6 to 50 feet in diameter) have been utilized at LeRC for over 30 years to simulate space conditions. The reliable, reusable, long lasting, and round configuration vacuum seals demonstrate the success of using rubber O-rings to vacuum seal these small and large chambers. Environmental testing, experiments, and pre-flight tests have been fruitfully conducted in these chambers in space simulated environment. These practices were gained from LeRC's experience with vacuum seals and sources listed in the references. References: Robert C. Finke, Arthur D. Holmes, and Thomas A. Keller, quotSpace Environment Facility for Electric Propulsion Systems Researchquot, NASA TN D-2774, Lewis Research Center, Cleveland, Ohio, May 1965. The Boeing Company, quotPractical Vacuum Systems Designquot, Seattle, Washington, 1962. The Boeing Company, quotUltra High Vacuum Theory and Designquot, Seattle, Washington, 1963. Parker Seals, quotParker O-Ring Handbookquot, ORD 5700, Parker Seal Group, O-Ring Division, Lexington, KY, 1991. Apple Rubber Products, quotSeal Design Catalogquot, Apple Rubber Products Inc., Lancaster, NY, 1989. Varian Vacuum Products, quotVarian Vacuum Products 1991\/1992 Catalogquot, Lexington, Massachusetts, 1991. Donald J. Santeler, Donald W. Jones, David H. Holkeboer, and Frank Pagano, quotVacuum Technology and Space Simulationquot, NASA SP-105, Washington, D.C., 1966. quotStatic Cryogenic Seals for Launch Vehicle Applicationsquot PD-ED-1208.","Lesson ID":674}
{"Driving Event":"This Lesson Learned is based on Reliability Practice Number PD-ED-1233 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefits: This practice enables spacecraft to meet these stringent cleanliness level requirements of state-of-the-art scientific instruments. It also serves to maintain the inherent efficiency and reliability of the instrument by minimizing degradation of critical surfaces and sensors due to undesired condensation of molecular and accumulation of particulate contamination layers. Implementation Method: General This Contamination Control Program and a number of its supporting technologies were developed to meet the stringent cleanliness specifications of the COBE state-of-the-art scientific instruments. These instruments operated at temperatures below 2 degrees Kelvin inside a dewar and required the most stringent surface level cleanliness specifications ever attempted by GSFC and perhaps NASA. These low temperatures required innovative contamination control measures to prevent condensation of outgassing materials on critical cold optical and non-optical surfaces. This program as defined in the following begins with the early design phases where cleanliness specifications are established and continues through the entire flight program where contamination of flight hardware is monitored and controlled from fabrication through integration and testing, transportation to and handling at the launch site, and the launch and early orbit phases as appropriate. The COBE stringent cleanliness specifications were initially met and maintained. Early observations from COBE show that the instruments are operating nominally. Optical scattering, principally caused by particulate and molecular contamination, is an order of magnitude smaller than originally budgeted with the spacecraft's contamination specifications. Cleanliness Specifications Establish cleanliness specifications during the early design phases. The most stringent cleanliness specifications are established as required for critical surfaces, usually cold surfaces such as optical surfaces, apertures, forebaffles, detectors, etc. These specifications are usually based on theoretical instrument performance degradation studies, contamination data from previous spacecraft missions, and in some cases from the space environment where cold optics can be coated with molecular layers of contamination from high-energy atomic oxygen bombardment or particulate contamination from micrometeoroid collisions with the spacecraft. Less stringent contamination specification requirements are established for less critical spacecraft and instrument surfaces and components. Stringent cleanliness specifications usually require the design of special contamination control domes and covers to protect critical surfaces during spacecraft qualification testing, transportation to and preparations for launch at the launch site, and during the launch and early orbital outgassing period. These domes and covers are deployed or detached from the spacecraft during the early orbits. Where appropriate, special instrumentation such as scatterometers or quartz crystal microbalances (QCM) are incorporated into the design of instruments to monitor contamination of critical surfaces or areas generated during spacecraft testing and launch activities. Selection and Testing of Materials Material selected for use in flight hardware is tested for its outgassing properties in accordance with ASTM E-595-77\/84. Only materials that meet the criteria of ASTM E-595-77\/84 [i.e., have a total mass loss (TML) < 1.0% and a collected volatile condensable mass (CVCM) <0.10%] are approved for use in a space environment. Instruments with more stringent contamination control specifications may require more stringent material selection criteria. Refer to related Reliability Preferred Practice No. PT-TE-1410, Selection of Spacecraft Materials and Supporting Vacuum Outgassing Data, for additional information on material selection and supporting vacuum outgassing data. Maintaining Clean Surfaces Spacecraft surface cleanliness levels are maintained throughout fabrication, integration, environmental qualification, and launch operations. These cleanliness levels are achieved through initial component level cleaning in a precision cleaning facility along with routine cleaning of the entire spacecraft. The cleaning facility is a 10,000 or better laminar-flow clean tent or clean-room equipped with an exhaust bench for chemical cleaning, an ultrasonic cleaning station, and contamination inspection stations. Standard cleaning procedures include a combination of thermal bakeouts, solvent rising, vacuuming, gaseous nitrogen blasting, vibration testing, and ultrasonic techniques. Flight components are required to undergo a thermal bakeout to reduce potential contamination due to outgassing. The following three inspection techniques are used to verify levels of cleanliness of flight hardware. First, the component is visually inspected using a minimum 100 footcandle intensity white light and a long wave black light to determine the presence of molecular and particular contamination. Second, tape lift samples are taken and analyzed to provide a statistical estimate of the total number and size distribution of particles per square foot present on the test sample. Third, molecular contamination levels are verified by analyzing a solvent wash using infrared and mass spectrometry techniques. These analyses verify that contaminants are within specified limits and provide data to help pinpoint the source of contaminant and whether material substitutions should be made. Contamination Control Procedures Special contamination control procedures are followed during component, subsystem, and spacecraft level flight environmental qualification test programs. These tests include thermal vacuum cycling, three axis vibration, acoustic bombardment, microphonics, and electromagnetic compatibility. Each test presents its own challenge for cleanliness control. An additional challenge is the transportation of the flight hardware from one test chamber or test facility to the next one. Each test chamber or test facility should be capable of maintaining a Class 10,000 or better environment and all test equipment and test fixturing brought into the test chamber or test facility is cleaned according to strict project procedures. During moves between test chambers or test facilities, the flight hardware is double bagged in clean antistatic nylon film. Once inside the clean area, the outer bag is removed and the environment is stabilized prior to removing the inner bag and exposing the flight hardware. If the test chamber or test facility is not a cleanroom, the bags remain on the flight hardware throughout the test. The bags are purged with Class 100 air conditioned atmospheric air to maintain thermal specifications on the flight hardware. A primary contamination control objective during thermal vacuum testing is to determine the possibility of the spacecraft self-contaminating its instruments during either launch or on-orbit. Secondary objectives are to (1) bake out the entire spacecraft during the first three days of hot-soak conditions, (2) measure the amount of condensed contamination throughout each phase of the test, and (3) determine the chemical makeup of the residue collected on cold surfaces in the chamber. This data is combined with a statistical on-orbit outgassing model of the spacecraft to determine an optimum outgassing period prior to deploying or removing contamination control covers from critical hardware. Contamination monitoring techniques used in the thermal vacuum testing include (1) the placement of quartz crystal microbalances around the spacecraft to provide a real-time means of measuring the quantity of outgassing contaminates throughout the testing, (2) the use of a residual gas analyzer to measure the types and quantity of gas molecules and their outgassing rates. Cold fingers, scavenger plates, and witness mirrors are used to collect contaminates that will condense on critical surfaces. The contaminates are analyzed using infrared and spectrometer techniques to identify the outgassing materials and their quantities. Primary contamination control objectives during vibration\/acoustic testing are (1) to measure the generated debris and spacecraft self-contamination, (2) to analyze the effectiveness of contamination control covers, and (3) to assess the possibility of debris created during the launch reaching critical instrument surfaces. Contamination is monitored by placing witness plates containing nylon disks coated with transfer adhesive at critical locations usually at the same locations as the witness mirrors used in the thermal vacuum testing. The witness plates collect debris which is analyzed to identify the type and quantity of debris at the various locations of interest. In addition many tape-lift samples are taken at various locations. These samples can show the source and migration of debris. One source of debris generation that has been identified by this technique is scraping interaction between hardware. The problem is corrected by either separating the hardware or by installing an isolating layer of nylon or teflon material to provide a smooth surface that will not shed during launch. Contamination Control During Transport The spacecraft is transported to the launch site in a specially designed and built trailer to control the temperature, pressure, humidity, and cleanliness of the environment while protecting it from induced vibrations and stresses. The filtration system used in the transporter enables the pressure to stabilize at equilibrium during both takeoff and landing of transport aircraft. The spacecraft is completely covered and sealed inside two specially constructed Llumalloy-HSC bags prior to mounting the spacecraft inside an outer hard box which is a part of the transporter system. The acceptance tests of the bags include particle counts, tapelift samples, and rinse residue tests to ensure that the bags meet the project contamination specifications. A breathable air purge line equipped with a desiccant and a 2 micron particulate filter is inserted into the inner bag to provide positive pressure between the inner bags and the outer box. A thick outer bag equipped with three High Efficiency Particle Air (HEPA) filters is then placed around the double-bagged spacecraft and supported by a cage to add further weather protection. The HEPA filters protect the spacecraft from the incoming air supplied by a HVAC system which consists of dual air conditioner and heaters powered by diesel generators. The HEPA filter system and the outer bag ensure a less than Class 1000 environment around the spacecraft during transportation. Contamination measurements are again taken when the spacecraft is unbagged at the launch site to verify surface cleanliness levels. Contamination Control at the Launch Site At the launch site the spacecraft is placed inside a laminar-flow clean room or tent ranging between Class 100 to Class 1000 for final integration and launch preparations. The launch gantry which may have normal contamination levels of Class 100,000 must be carefully cleaned so as to lower the contamination levels to Class 10,000. The fairing of the launch vehicle is submitted to the same contamination levels and inspection techniques as the external surfaces of the spacecraft. The spacecraft is double bagged and purged with Grade C gaseous nitrogen during transportation to the gantry. The purge is then changed to conditioned air. The clean bags and the purge remain until just before the fairing is installed. A \"shower\" cap can be installed over the spacecraft to protect exposed instruments and dewars until the second half of the fairing is installed. Once the fairing is installed, an air-conditioned line containing a HEPA filter to maintain Class 100 air is connected. The air flow inside the fairing is sampled for 20 minute time periods to measure the air quality around the exposed spacecraft. Technical Rationale: A variety of instruments including the three state-of-the-art instruments flown on the COBE spacecraft require stringent surface level cleanliness control to protect critical surfaces and components from particulate and molecular contamination. The diffuse infrared background experiment (DIRBE) and the differential microwave radiometer experiment (FIRAS) flown on COBE operate at temperatures below 2 degrees Kelvin (-456.07 degrees F) inside the dewar. This requires stringent contamination control to prevent condensation of outgassing materials on critical cold optical components. The FIRAS is a modified Michelson interferometer that operates in the wavelength range from 0.1 to 10 mm to determine the spectrum of the cosmic background radiation. It utilizes a polished aluminum input skyhorn to direct cosmic radiation into the optical system. Particulate or molecular contamination in excess of level 300A would decrease off-axis rejection performance of the skyhorn and possibly destroy tiny elements inside the bolometer detectors. The DIRBE measures diffuse galactic radiation in the wavelength range from 1 to 300 microns. The first optical element in this off-axis Gregorian system is a super polished, gold-coated aluminum parabolic mirror that was cleaned and maintained at level 100A to minimize radiation scattering. The differential microwave radiometer instrument (DMR) flown on COBE has three individual receiver heads positioned around the periphery of the dewar to determine whether the cosmic background radiation is equally bright in all directions. The DMR antennas operate at wavelengths of 3.3, 5.7, and 9.6 millimeters, respectively to map the entire sky. The internal surfaces of the corrugated horns were protected from particulate contamination at all times to preserve the cleanliness of the horn throats and the switching mechanism that is used to calibrate each receiver on orbit. A particle of 80 microns in length would cause blockage in the horns and interrupt signal throughput. References: Barney, Richard D., \"Contamination Control Program for the Cosmic Background Explorer\", Journal of the IES, March\/April 1991. \"Selection of Spacecraft Materials and Supporting Vacuum Outgassing Data,\" Reliability Preferred Practice PT-TE-1410.","Lesson ID":670}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1220; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: In an unassembled state, ferromagnetic parts can be exposed to stronger AC demagnetizing fields, as high as 60 mT (600 Gauss), thus assuring a lower level of remanent magnetization than can be achieved after the parts are mounted on assemblies. Attaining a low level of remanent magnetization minimizes the adverse effects of unwanted fields. In those cases where magnetic compensation may be required, the ability to apply high level fields to an unmounted part enables the utilization of techniques to stabilize the magnetic moment of the part. Implementation Method: The part being demagnetized is placed in a controlled AC magnetic field and rotated on all three of its axes as the field is exponentially increased and then returned exponentially to its lowest level. During this process, the ambient magnetic field must be reduced to near zero intensity (< 500 nT) while the parts are being demagnetized. This condition can be established either through the use of a triaxial coil system, to generate nulling fields, or by placing the parts in a magnetically shielded container. Effective demagnetization cannot be achieved in the presence of the earth's field (0.05 mT) because a significant number of magnetic domains will remain aligned along the ambient field vector and result in a residual dipole moment. After the demagnetization process is completed, the part and the assembly to which it is mounted should not be exposed to magnetic fields in excess of 2 mT. This control assures that any subsequent demagnetization of the assembly at 5 mT will be adequate. The size and configuration of the demagnetizing coil may vary depending upon the specific parts being treated. However, in most cases, a simple solenoid provides the adequate flexibility for such items as connectors, fasteners, and small parts. In some cases a commercial 60 Hz magnetic tape degausser can be used. For a solenoid, the wire size and number of turns are determined by the size of the AC source (voltage and current capacity). Series capacitors are used to tune the coil for resonance. The physical access to the center of the solenoid must be adequate to allow for the rotation of the part on all three of its axes while exposed to the demagnetizing field. At JPL two systems are in use to provide a near zero static magnetic field environment for high level demagnetization. For smaller test items, a double walled mumetal shield can, approximately 60 cm in diameter and 120 cm long, is used. Within the shield can, the AC demagnetizing field is generated by a solenoid. Larger test items are treated in a zero DC environment produced by a triaxial Helmholtz coil system having a maximum diameter of 3.6 meters. AC fields up to 10 mT are generated by a coil pair 2 meters in diameter contained within the triaxial system. Other demagnetizing solenoids and coils available for use include the following: 14 cm i.d. coil 42 cm i.d. coil 60 cm i.d. solenoid 116 cm i.d. Helmholtz Max. Field1 60 mT 50 mT 24 mT 0.6 mT Wire Size 20 AWG 20 AWG 10 AWG 10 AWG Windings 1 2 3 2\/coil Turns 1600 1368 426 58\/coil Ohms\/Winding 30.5 25.7 3.1 0.8 L\/Winding 506 mH 100 mH 57.5 mH 9.6 mH Series Capacitance 14 uf 80 uf 14 uf \u2014 Coil Construction 10 mT\/amp 2.8 mT\/amp 1.2 mT\/amp .08 mT\/amp Weight 4.5 kg 10 kg 5.3 kg 58 kg 1 230 volts at 60 Hz Technical Rationale: Ferromagnetic materials, such as the alloys of nickel and cobalt, are of concern because they exhibit hysteresis and have permeabilities which are dependent upon the ambient field strength and temperature. Parts made of these materials exhibit dipole moments which can create disturbance torques and also produce unwanted external magnetic fields. The demagnetization process has either of two objectives: first, to reduce the remanent dipole moment to its lowest practical level or second, to stabilize the moment with respect to the expected environmental extremes for temperature and field exposure. Because of the potential adverse effects of strong magnetic fields on electronic components, spacecraft assemblies are not exposed to demagnetizing fields in excess of 5 mT (50 Gauss). This level of demagnetizing field is based on the conservative assumption that the spacecraft hardware will not be exposed to magnetizing fields in excess of 1-2 mT. Frequently, in the process of fabrication, parts made of ferromagnetic materials are exposed to magnetic fields far in excess of 1-2 mT and, in some cases, are received in a saturated state. Ideally, the demagnetization process should remove the saturated remanence by a complete randomization of the domains in the material. However this typically requires a much higher field intensity than the 5 mT demagnetization field used on completed assemblies and subsystems. In those cases where demagnetization is not adequate, the magnetic moment of the part must be stabilized and compensation obtained through the addition of an equal but oppositely directed dipole moment (a permanent magnet). For this technique to be effective a strong magnetizing field must be applied to make sure that the ferromagnetic part is in a saturated state prior to compensation. This would not be practical to do with the part installed on a completed assembly. References: \"Magnetic Field Restraints For Spacecraft Systems And Subsystems\", N68-11295, Goddard Space Flight Center, Greenbelt, Maryland, February 1967","Lesson ID":671}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1217; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefits: Conscientious adherence to proven procedures in the design, manufacture, and test of aerospace structural composites will result in low rejection rates and high product integrity. In specific applications, successful composite design provides design flexibility, increased strength to weight ratio, dimensional stability under thermal loading, light weight, ease of fabrication and installation, corrosion resistance, impact resistance, high fatigue strength (compared to metal structures with the same dimensions), and product simplicity when compared to conventional fabricated metal structures. Implementation Method: Design Practices. The most important concept in deriving acceptable structural laminate composite parts is the multidisciplinary approach to design wherein the material composition, filament orientation, and fabrication procedures are custom tailored to the specific part configuration. From the beginning of design analysis to the completion and flight of composite components, the integration of material structure and formulation with configuration and environmental considerations is essential. More than in any other product manufacturing discipline, composite development requires the designer to simultaneously consider the following: configuration, operational environment, tooling, quality, reliability, safety, nondestructive evaluation, and material characteristics. The physical properties of structural laminate composites tend to deteriorate due to environmental conditions after manufacturing. Therefore, design requirements must include, to a greater degree than in conventional structures, the operational environment (transportation, prelaunch, launch) and the storage environment. The matrix or binder composition, filament composition and form, and the specific manufacturing procedures used will heavily influence the acceptability of the final integrated unit. Since the structural properties of the material are so strongly dependent upon the part fabrication process and tooling, design of the part and tooling configuration must be concurrent. This principle can be seen by comparing the conventional metals design, manufacturing, and testing procedure (Figure 1) with the corresponding cycle for structural laminate composites (Figure 2). [D] Figure 2 illustrates two important points: (1) part design and tool design go hand-in-hand; and (2) the manufacturing and fabrication process includes simultaneous production of the composite and fabrication of the structure. For structural space applications, composites must be designed properly and built properly. An important example of the need for laminate-unique considerations in the design process is that the design of the part and its manufacturing tooling include tag ends or trim area that must be removed and subjected to acceptance testing. It is common practice to use a safety factor of 1.5 for structural laminate composites. A safety factor of 2.0 is recommended for the materials located around fasteners. [D] The structural strength of the final design is dependent upon filament strength, matrix or resin strength, and fiber orientation (which should generally be in the direction of the applied force). The strength of the part is based on the interaction of fiber and matrix in a process that depends upon ply or layer thicknesses and percent of fiber volume. Typical fiber tensile strengths range from 200,000 to 800,000 psi while matrix tensile strengths range from 2000 to 5000 psi. When these two elements are combined into a graphite epoxy structural laminate, a composite tensile strength close to 98 percent of the uniaxial fiber strength is achievable. Part design must include the evaluation of coupon, section, and prototype tests in order to assure that part configuration\/material interactions are taken into account in the final configuration. Structural algorithms using finite element methods are used early in the design process, and these are supplemented by results from tests of prototype parts. Graphite epoxy composite materials exhibit stress-strain relationships with less than 2 percent elongation and without the usual elastic-plastic behavior of metals. Where metals usually require only two design properties, modulus and Poisson's ratio, composite design will require five or more distinct directional variations of these properties. Thermal expansion properties can be designed so that zero expansion may be achieved, such as for optical benches. The resin used to bind the composite materials can typically absorb up to 5 percent by weight of water, which can affect dimensional stability of the composites. Ultraviolet radiation and atomic oxygen in space will increase aging and thereby decrease service life of the composite when left unprotected. This iterative and integral design process will ensure a successful structural laminate composite part or assembly design. Manufacturing Practices. The matrices and fibers for structural laminate composites can be applied to a mold sequentially or the filament can be preimpregnated with the matrix material. The latter is the more common practice for aerospace structural laminates. Developing the correct process flow prior to production is crucial to modern composite manufacturing. Critical factors in the manual or automated lay-up of composites are the indexing or orientation of the filament and the sequencing of layer application. Curing temperature, pressure, and ramp rates are critical as they affect the degree of cross-linking of the polymers in the matrix material, adhesion to the filaments, porosity, filament spacing, and resulting overall strength and integrity of the final part. Lifetime of preimpregnated materials is an important consideration because acceptable properties can only be maintained for ten days to one month at room temperature or a material-dependent range of six months to two years in cold storage. Timing of the preimpregnation process, therefore, is a critical factor in the planning of the manufacturing process. The manufacturing environment (humidity, temperature, and cleanliness) and the manufacturing process itself must be closely controlled to produce consistently acceptable products. Automation using statistical process control of composite fabrication methods may be the single most important advancement needed to foster the use of composites for aerospace applications. Testing and Nondestructive Evaluation Practices. Integral to the successful manufacturing process for aerospace structural laminates is the need for 100 percent in-process inspection, nondestructive testing, and coupon testing during the initial manufacturing phase. As inspection records are built up, the inspection requirements are reduced until only the problem areas are checked on each component. These problem areas should be defined by production results, design engineers, materials and process engineers, and shop fabricators. Early in the manufacturing process, filaments should be tested for tensile strength, strain rate, modulus of elasticity, density, diameter, stiffness, and surface morphology. Matrix rheology and mechanical performance must be characterized through chemical and physical testing. The preimpregnated material should be tested for resin content, flow rate, volatile content, tackiness, tack retention, and gel time. Filament count, filament spacing, drapability, and temperature exposure tests should also be conducted on the preimpregnated material. Coupons should be fabricated for each part to permit destructive tests (thermal, chemical, and structural) of the material which represents as closely as possible that which is included in the fabricated part. Wherever possible, part extensions should be trimmed off and tested to determine if the material meets strength, chemical, and thermal requirements. The final cured laminate composites should be tested for longitudinal compressive strength, longitudinal and transverse flex strength, longitudinal and transverse tensile strength, longitudinal and transverse shear strength, impact testing, and compression testing after impact testing. Nondestructive testing methods that may be used to verify absences of voids, delaminations, and low density areas are radiography, ultrasonics, thermography, eddy current, and acoustic emissions. Nondestructive tests that may be used to verify cleanliness for bonding composites to adjacent metallic structures are Fourier Transform Infra Red (FTIR) spectroscopy, Non-Volatile Residue (NVR) analysis, X-ray Florescence (XRF), and Ellipsometry. Nondestructive evaluation is an important inspection technique for determining defects without destroying the component. The typical evaluation (NDE) technique for detecting defects in composites are shown in Table 1. Development of accept\/reject criteria should be accomplished during the manufacturing and testing phase prior to production phase of the composite component. Technical Rationale: Experience with structural laminate composites on the Space Shuttle External Tank, Space Shuttle Solid Rocket Motor Filament wound case, Advanced X-ray Astrophysics Facility, Solar X-ray Telescope, International Space Station, and related composite applied research and product improvement projects has included experience with graphite\/phenolics, glass\/phenolics, graphite\/epoxies, and graphite\/bismalemides. Table 1. NDE Techniques for Detecting Defects in Composite Materials Defect Composite Method X-Ray Ultrasonics Computer Tomography Alcohol Wipe Thermography Eddy Current Dye Penetrant Delaminations X X X X X Density Variations X X Resin Rich\/ Resin Poor X X Voids X X X Crazing (Microcracks) X X X Wrinkles X X Conductive Materials X Both woven fabric and tape forms have been used as reinforcing materials. Research and applications of composite materials at MSFC and by its prime contractors and subcontractors have included many other types and applications of composites. Several of these, such as filament winding, and pultrusion, fiber placement, and automated tape laying, are being considered for future design practices. Since knowledge of structural graphite epoxy composites is constantly expanding, this practice may also be updated in the future to reflect emerging advancements. References: Agarwal, Bhagwan D. and Lawrence J. Broutman, Analysis and Performance of Fiber Composites, Second Edition, Wiley, New York, 1990. Dow, Marvin B., quotThe ACEE Program and Basic Composites Research at Langley Research Centerquot (1975 to 1986), NASA Reference Publication #1177, October 1987. quotDOD\/NASA Structural Composites Fabrication Guide,quot Lockheed-Georgia Company, Air Force Materials Laboratory, Wright-Patterson Air Force Base, Ohio, 1979. Gause, Dr. Raymond L., quotA Noncontacting Scanning Photoelectron Emission Technique for Bonding Surface Cleanliness Inspection,quot NASA Technical Memorandum #100361, George C. Marshall Space Flight Center, February 1989. Jones, Robert M., Mechanics of Composite Materials, McGraw-Hill, 1975. quotPlastics for Aerospace Vehicles: Part I. Reinforced Plastics,quot Military Handbook 17A, Department of Defense, Washington, D.C., 1971. Schneider, Cecil W., quotLessons Learned on Composite Production Programs,quot Lockheed Aeronautical Systems Company, Marietta, GA, December 1991. Strong, Dr. A. Brent, quotFundamentals of Composites Manufacturing,quot First Edition, Society of Manufacturing Engineers, 1989. quotSpace Shuttle External Tank: Final Report,quot Composite Technology Group, Martin Marietta Michoud Division, 1984.","Lesson ID":669}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1215.5; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefits: Pre-ship review ensures the completeness and readiness of each item of hardware and, if applicable, any associated software or firmware, prior to release for shipment to another facility. By imposing this requirement, any discrepancies or unresolved problems may be identified and corrected while the item remains under supplier purview. This review is beneficial because it provides an independent assessment of product readiness by knowledgeable people not directly involved in the fabrication and test activity. Implementation Method: The purpose of pre-ship review (PSR) is to determine whether the required work on a planned deliverable is complete and acceptable and, where applicable, whether the flight qualification criteria have been attained. This includes checking that all required analyses and tests were performed and that the data package contains all the required documentation. Action is taken to assess the actual performance of the item against the performance requirements. Differences between the designed versus the built hardware are identified, and any additional risks associated with the differences are assessed. Any liens, concerns, unresolved problems, and open issues with the hardware or software are cataloged, and plans to resolve such open issues and complete any unfinished work are assessed. PSR requirements may apply to system contractors, subcontractors, and NASA centers; they are held prior to shipment to an integration or installation facility, a NASA center, the sponsor, or the launch site. System contractor requirements are written to specify PSR and to pass the requirement down to subcontractors. The PSR is performed by a review board and is a customer-controlled review. The review board assesses the status of the deliverable item, recommends whether or not to ship it, makes an independent judgement of the risks, and identifies any concerns which would affect mission success. A representative of the receiving organization is usually present at the review. The planning and documentation process for pre-ship and other technical reviews is described in Reliability Preferred Practice No. PD-ED- 1215.4, Common Review Methods for Engineering Products. The review agenda specific to PSRs typically includes the items listed in Table 1. Table 1 - Pre-Ship Review Agenda Prepare Final Compliance Matrix. Explain any incomplete requirements. Review completeness of all drawing specifications, including incorporation of all engineering change requests (ECRs). Explain any drawings or specifications that are not complete. Determine the status of required analyses-- their completion or plans to complete, and identify any open issues. Discuss and classify any residual risks. Determine the completion status of hardware assembly and verify that the hardware reflects the final completed drawings. Explain each discrepancy in the as-built hardware. Determine the status of required tests-- their completion or plans to complete, and identify any open issues. Discuss and classify any residual risks. Specify the status of required documentation, including plans to provide any documents that are not complete and in the data package. Provide plans to resolve any assurance liens. Identify any ECRs that have not been implemented in the as-built product.. Identify any problem\/failure reports (or equivalent, customer-approved, supplier report formats) on the subject hardware (including electrical and mechanical ground support equipment) or software, as well as on other equipment which could affect it. Provide the plans for resolution. Assess any quotred flagquot problem\/failure reports (PFRs)-- problems, residual risks, and actions taken to manage the risk of an in-flight occurrence. Catalog any waivers of product requirements, including the risk assessment associated with each. Evaluate the readiness of hardware to be integrated with other hardware or the spacecraft. Assess the readiness to ship hardware, including the adequacy of shipping containers, shipping methods, shipping environment control, and monitoring. Identify special instructions for item handling, testing, and training. Review plans for supplier participation after shipment. A sample compliance matrix indicating the open item status of a sample subsystem is provided as Table 2. Table 2 - Galileo Orbiter Attitude & Articulation Control System (AACS) Compliance Matrix [D] * Details on work remaining were explained in the PSR package; Source: Reference 3 (Vol. 2, p XVI-E3) Technical Rationale: Pre-ship review provides a last opportunity for the supplier and the customer to review completion of development work before the product leaves the facility. Correction of liens after this milestone usually has a major schedule impact. The planned increase in supplier participation in NASA programs will likely cause an increase in hardware built at supplier sites. Effective pre-ship controls will help ensure the success of NASA outsourcing plans. Related Practices: Hardware Review\/Certification Requirement, Reliability Preferred Practice No. PD-ED-1215.2 Common Review Methods for Engineering Products, Reliability Preferred Practice No. PD-ED-1215.4. References: quotJPL Standard for Reviews,quot Jet Propulsion Laboratory document JPL-D-10401, May 5, 1995. quotCassini Project: Spacecraft System Review Program,quot Jet Propulsion Laboratory document JPL-D-9926, December 1992. quotOrbiter Preship Review, (Book 2)quot Galileo Project, Jet Propulsion Laboratory document JPL-D-6358, May 10, 1989. quotLaunch Vehicle Review Milestones,quot NASA ELV OI-12, April 1994. quotRequirements and Procedures for Flight Project Forward Review within the Space Experiments Division,quot NASA SED OI-6700- 1, December 1989.","Lesson ID":668}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number GSE-3001 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: The Flow Fuse, otherwise known as an Excess Flow Check Valve, inhibits media flow as a result of sensing a pressure differential which exceeds preset limits. Pressure differentials would be a result of downstream component failure, line rupture, a downstream component failure, line rupture or catastrophic human error. The Flow Fuse is essentially a Check Valve installed in the system such that flow is attempting to travel in the normally blocked direction. A mechanism enabled by pressure equilibrium causes the normal quotcheckquot function to revert to a quotbypassquot function. Upon sensing a shift in pressure differential which exceeds some calibrated setpoint (user defined), the quotbypassquot function is disabled and the valve immediately inhibits flow. The Flow Fuse has extremely rapid response characteristics (tests have proven 10-100 msec), can handle a wide range of applications (50-14000 psi), and has a long proven test and application history. The unique qualities of the Flow Fuse including multiple reset options (manual, automatic or remote), remote position indication and time delayed opening\/closing features make the device adaptable to almost all applications where inadvertent expulsion of media could result in personal injury, loss of production or other catastrophic occurrences. Installation of Flow Fuses will provide extended downstream protection to personnel, equipment and\/or facilities. The prime benefit provided by Flow Fuses will be the ability to produce near ideal quotfailsafequot designs. Flow Fuses, if used to their potential, will minimize the effects of hardware failure through systematic abatement of physical hazards. Additionally, inclusion of these devices will substantially lower failure recovery costs. Implementation Method: Flow Fuses should be installed in Pneumatic and Hydraulic systems for the prevention of loss of life, injury, or flight hardware damage due to expulsion of high pressure gaseous or liquid media. The designer should only implement these devices after a careful review of good safety review considerations. System analysis and subsequent modeling will reveal strategic points for the inclusion of Flow Fuses to maximize protection and provide system fault isolation. As an analogy, these devices will be installed much like circuit breakers used in electrical circuit design. In those applications, main breakers provide global overcurrent protection and branch circuit breakers provide secondary fault isolation (See Figure 1 quotFlo- Fuse Implementation Diagramquot). [D] Technical Rationale: Flow Fuses should be installed in Pneumatic and Hydraulic systems for the prevention of loss of life, injury or flight hardware due to catastrophic hardware failure or human error. These devices are appropriately selected through system modeling to match system operating parameters and installed within flexible or hard-lines as necessary. Flow Fuses should be utilized at both the system and subsystem level where they can serve as narrow field fault isolation devices. In contrast to manual hand valves or other manually actuated shut-off devices, Flow Fuses are automatically tripped and offer multiple reset options and monitor\/control functions. Figure 2 depicts generic fluid distribution system uses and implementation methodologies. [D] References: NCSL 174-73, Naval Coastal Systems Laboratory quotTest and Evaluation of Flow Fuses for Use In Manned Pressure Chambersquot; by Clifford R. Holland, NCSL dated August 1973. Marotta Scientific Controls, Inc.; Product Correlation Sheet. Marotta Scientific Controls, Inc.; quotFLOW FUSESquot dated 23 November 1970 (White Paper).","Lesson ID":660}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number GSE-3007 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: In most instances it is not practical to be fail-safe at any cost. This practice provides guidelines on using redundancy only where it is required. Too much redundancy leads to failures resulting from increased complexity. Mean Time Before Failure (MTBF) is estimated as a function of the number of parts. Minimizing redundancy reduces the number of parts and therefore increases the MTBF. This practice illustrates how to design a system that satisfies the technical requirements but contains cost by minimizing the level of redundancy. Implementation Method: The Operational Intercommunication System - Digital (OIS-D) at the Vehicle Assembly Building (VAB) serves as the mechanism for discussing this practice. The OIS-D is a controlled access, multiuser, multichannel communications system used in support of vehicle test and launch operations. It is a fully digital system that provides 500 user channels of duplex voice communications. OIS-D equipment in the VAB interfaces with the Central Summing Network (CSN) in the Launch Control Center (LCC). OIS-D equipment in the VAB consists of the following: Group Processor Assembly (GPA) Racks Transmission Equipment (DTE) Rack Power Rack, D.C. Chargers, Battery Banks, Battery Disconnects, and D.C. Disconnects End Instruments (EI) The OIS-D will be referred to in the remainder of the report as the voice communication system. System Operation: The telephone system (Figure 1) provides a loose analogy to the voice communication system (Figure 2). The EI is a unit in which one connects a headset and dials up a voice channel. The user can talk and listen over this channel. As a communication device, the EI is analogous to the telephone. The EI is a user-operated, microcomputer-based, communication device. The GPA is the principal rack assembly of the voice communication system. Each GPA transmits and receives voice, status, and signaling data from its associated EIs. The GPA is analogous to a central office. It provides the interface between the End Instruments and the Central Summing Network (CSN). The CSN gathers information from multiple GPAs and sums the information for redistribution. The CSN is analogous to the toll office. [D] [D] Power Distribution: The voice communication system operates on a floating 48V DC power source. This power is first converted from 480V AC to 48V DC by a battery charger. It is then routed through circuit breaker distribution panels, and to battery banks where it is stored in case of a power failure. From there the power is distributed to the power supplies used by each chassis, and to the fans used for rack cooling, through power control modules that reside on each of the GPA racks. If 480V AC power fails, the battery banks supply 48V DC for a minimum of one hour. EI operating power (48V DC) is normally supplied by its associated GPA over the data transmission lines. The data transmission lines act as a medium for both the data transmission and power transmission to the EI. Redundancy Policy: The design must satisfy the Ground Support Equipment (GSE) Fail Safe requirement of NSTS 07700, Volume X. The requirement states that all GSE (except primary structure and pressure vessels) shall be designed to sustain a failure without causing loss of vehicle systems or loss of personnel capability. One of the requirements for support of hazardous operations is to have co-located EIs in areas of hazardous operations. The requirement for co-located EIs implies redundant EIs. Furthermore, the fail-safe requirement points towards a redundant implementation. That is, redundant GPAs, redundant power, and redundant Data Transmission Equipment (DTE). The data transmission equipment consists of Fiber Optic Transmitters (FO TX) and Fiber Optic Receivers (FO RX). The power requirements and data transmission equipment requirements are best satisfied through use of redundancy. The GPA requires additional consideration. Figure 3 is an implementation that utilizes redundant GPAs. For illustration purposes assume that each GPA can support four EIs (actually each GPA supports 119 EIs). This implementation satisfies the fail-safe requirement but it is very expensive. The GPA is the most expensive item in the system. Figure 4 introduces an alternative implementation. Observe that in this implementation neighboring EIs have different GPAs. Simply by requiring that co-located EIs have connections to independent GPAs eliminates the need for redundant GPAs. In the event of a failure, the operator could move to a neighboring EI and quotsafequot the system. Therefore Figure 4 is cost effective while also satisfying the fail-safe requirements. [D] [D] Both implementations were considered during the design of OIS-D. Many existing designs conform to Figure 3. The cost of the GPAs made the figure 3 implementation too costly for OIS-D. The Figure 4 implementation was acceptable to the design team because it fit within the cost profile of the system and satisfied the fail-safe requirements. In practice the system has proved to be very reliable. Technical Rationale: In attempting to determine if complete redundancy is needed or if policy decisions can be implemented to alleviate many of the fail-safe concerns, two questions need to be answered: Will it decrease cost? Will it improve the product? The answer to both questions is yes. Eliminating unnecessary redundancy reduces cost. The product is improved because the system MTBF increases with the removal of unnecessary redundancy. These are quantifiable justifications for the implementation of this practice. This practice should also be adhered to when designing Local Area Networks (LANs) and Wide Area Networks (WANs). References: SAA009CU08-026 (Revision A) - System Assurance Analysis of the Operational Intercommunication System - Digital at the Vehicle Assembly Building (VAB).","Lesson ID":661}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number GSE-3009 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Enhances mission reliability and prevents catastrophic mission failure. Use of UPS can prevent equipment damage by giving personnel time to safe a system or to provide power to critical equipment such as oxygen analyzers or emergency lighting until personnel can move to another area. In addition, UPS can be used to provide filtered AC power to equipment and eliminates disturbances in the power such as spikes, undervoltages (dips and sags), outage flicker, and transient noise which can affect system performance. This significantly increases reliability of electronic equipment using AC power. Implementation Method: UPS can be used where loss of power during an operation is considered critical or where loss of power may cause extensive equipment damage or data loss. Technical Rationale: An UPS typically does two things: (1) It either provides power to enable the safe shutdown of equipment and saving data to a nonvolatile medium, or (2) it provides power to equipment over the duration of fault\/failure, enabling equipment to operate continuously. Safe shutdown is completed through embedded programming that communicates shutdown protocol to the user and\/or initiates shutdown procedures automatically at the point of fault\/failure. Continuous operation is primarily a function of load draw and battery type and size. There are a variety of end-user UPS applications, each with a specific price\/performance demand. Some of these needs may be served best by a off-line UPS or an on-line UPS. Most UPS have intelligent features such as automatic battery check, automatic inverter check, AC volts in and out, battery alarm, internal temperature, alarm conditions of internal failures, and the number of power outages. The costs of implementing a UPS safety net can be minimized by choosing the right UPS topology and features for each application. In the networking environment, on-line UPSs are being assigned to critical processing and data traffic nodes, file servers, routers, etc. Off-line UPSs provide protection and power coverage to network printer\/output stations, input\/output terminals, and standalone PCS. Basically, an UPS system converts some or all of the AC power into DC for the battery and then back into AC power for the load. This double conversion has many variations; however, all of the designs incorporate an inverter to convert DC into AC. It is the inverter operation which defines an UPS as on-line or off-line. The inverter in an off-line UPS operates only when needed, conversely, the inverter in an on-line UPS operates continuously. An off-line UPS is inherently more cost effective than an on-line because the inverter is off most of the time. However, when switching from main power to battery power, known as transfer time, an off-line UPS stops providing power to equipment for a few milliseconds (typically up to 4ms). Most modern computer equipment can sustain a power switch time of up to 300ms, but some older equipment may shut down during the transfer time. An on-line UPS has no transfer time because the inverter continuously supplies battery power to the load whether the main power is active or not. An UPS must be served from a dedicated circuit unaffected by other loads, and the breaker serving the circuit must be provided with safeguards to prevent inadvertent or unauthorized turnoff. The UPS battery also requires monitoring; battery failure is the most common UPS problem. Life expectancy in small UPSs is only a few years due to the batteries which are replaced in accordance with the owners manual. Some UPSs contain self-diagnostics or other test features to provide personnel an indication of battery condition or component malfunction. By utilizing these features, problems can be detected before they announce themselves by failure of the unit to provide power. UPS are used at many locations throughout Kennedy Space Center. Some of the locations where UPSs are used are the Crawler Transporter, Orbiter Processing Facility, and Launch Processing System. Crawler Transporter The Crawler Transporter, Figure 1, is used to transport the Mobile Launch Platform and the space shuttle from the Vehicle Assembly Building to launch Pad A or B. [D] The UPS on the Crawler consist of the following major equipment shown in Figure 2. Ferroresonant Transformer Small Charger Batteries Inverter The Crawler Transporter contains a system that operates as an on-line reverse transfer system and has the following operating modes: Normal. Under normal operating conditions, the power path is shown by the black arrows in Figure 2. The load is powered by an AC supply line that has been filtered through a ferroresonant transformer. When AC on-line power is present, the small charger and inverter are normally off. The white arrows show the elements are connected to the system, but are not receiving power. If the battery charge falls below a predetermined level, the small charger will turn on and recharge the batteries. The ferroresonant transformer cleans up the raw line power; filtering out spikes, sags, surges, noise, lightning, and brownouts. Emergency. When AC line power fails or goes out of tolerance, Figure 3, the inverter turns on and supplies AC power from the battery source. The route of power is shown by the black lines. During the transfer process, the load never sees a break in the output of the system during transfer from normal AC line supply to inverter battery supply or back to line. Recharge. When AC power is restored, power flows to both the small charger and ferroresonant transformer. The inverter turns off and the small charger is turned on to trickle charge the batteries. Bypass. If the UPS must be taken out of service for maintenance the alternate AC power is not required since maintenance is done when no shuttle transport is taking place. If the UPS goes down during an transport operation, direct AC power or bypass is not fed into equipment because of voltage spikes and dips during operation. Instead, the Crawler is stopped until repairs are made or the unit is replaced. Power sustains the operation of the programmable logic controllers and the man machine interface units. The man machine interface units are cathode ray tube screens used by operators to control and monitor several crawler systems. If a power outage occurs during transport of the space shuttle, the Crawler Transporter propel and\/or jacking system will automatically stop. The UPS provides power so that operators can obtain information from the various crawler systems and to determine what caused the Crawler to stop. This expedites the troubleshooting process by having the programmable logic controllers operational during a system anomaly. The Crawler has two means of AC power either through shore power or during operation where AC power is generated on board through a diesel engine and generator set. In either case, the UPS cleans the AC power from either source to provide power to sensitive electronic equipment such as programmable logic controllers and the man machine interface units. Filtered power precludes against possible equipment damage and provides a smoother operating system, thus improving system reliability. [D] [D] [D] Orbiter Processing Facility An UPS system is in the Orbiter Processing Facility High Bay 3 provide reserve power for 20 minutes to the oxygen deficiency monitors, hazard warning lights, emergency exit lights, environmental monitoring data system, and paging area warning system. The UPS in the Orbiter Processing Facility High Bay 3 consists of the following major equipment shown in Figure 4. The UPS operates as an on-line reverse transfer system shown in Figure 2 has the following modes: Normal. The critical AC load is continuously powered by the UPS inverter. The rectifier\/charger derives power from a utility AC source and supplies DC power to the inverter, while simultaneously float charging the battery. The UPS also provides clean power to equipment by filtering out spikes, sags, surges, noise, lightning, and brownouts. Emergency. Upon failure of utility AC power, the critical AC load is powered by the inverter, which without any switching, obtains its power from the battery plant. There is no interruption in power to the critical load upon failure or restoration of the primary AC source. Recharge. Upon restoration of the utility AC source, the rectifier\/charger powers the inverter and simultaneously recharges the battery. This is an automatic function and will cause no interruption to the critical AC load. Bypass. If the UPS must be taken out of service for maintenance or repair, the static switch will transfer the critical load to an alternate source without an interruption. The static switch is provided as a to draw-out assembly so that the static switch can be electrically isolated for maintenance. Once the load has been transferred to the alternate AC source, retransfer of the load is accomplished by automatically synchronizing the UPS and paralleling the inverter with the alternate AC source, allowing the inverter to ramp into the load and then disconnecting the alternate source. Off-Battery. If the battery only is taken out of service for maintenance, it is disconnected from the rectifier\/charger and inverter by means of a Circuit Breaker. The UPS will continue to function and meet all of the steady state performance criteria specified herein except for the reserve time capability. Launch Control Center UPS The main Uninterruptible Power System (UPS) for the Launch Control Center (LCC) provides quality uninterruptible 208 VAC 60 Hz 3 phase power for electronic loads to distribution panels for the Record and Playback Subsystem (RPS), the Complex Control Subsystem (CCS), and the Checkout Control & Monitor Subsystem (CCMS). The UPS is critical because it supplies power to the CCMS which is required to safe the Space Shuttle critical systems. Examining the critical loads, half of the consoles operate off UPS 1 bus while the other half operate off UPS 2 bus. The individual racks operate either off both buses or the active operate off one bus and the standby operate off the other UPS bus. The UPS consist of the following major equipment: Uninterruptible Power Modules (UPMs) Power Processors including rectifier\/chargers and inverters. UPM Battery Banks, one each per UPM plus one spare, including batteries and battery racks. UPS Bypass Output Switchboard, including system metering and system status displays. Vendor UPS Equipment The UPS is designed to operate as an on-line reverse transfer system in the following modes: Normal. The critical load bus is continuously supplied by the UPMs which derive power from the commercial AC source through a primary power supply system and simultaneously float charge the batteries. The UPMs filter AC power to sensitive electronic equipment. Emergency. Upon failure of the primary AC power, the critical load is supplied by the inverter portion of the UPM's, which, without any switching, shall obtain power from the storage batteries. There is no interruption to the critical bus upon failure or restoration of the commercial AC source. Upon restoration of primary AC power, the rectifier\/charger power the inverters and simultaneously recharge the batteries. This is an automatic function and causes no interruption to the critical load. Bypass. If the UPS must be taken out of service for maintenance or repair of multiple internal failures, the static switch transfers the load to the alternate AC power without an interruption. The static switch is provided as a draw-out assembly so that the static switch can be electrically isolated for maintenance once the load has been transferred to the alternate AC power. (The static switch is also capable of providing fault clearing current to the load when the alternate AC power is available.) Retransfer of the load is accomplished by automatically synchronizing the UPS to the alternate source, paralleling the inverters with the alternate source, and then disconnecting the alternate source. Non-Redundant. If one of the UPM's is taken off-line, but the load demand does not exceed the capacity on the UPM's remaining on-line, the UPS will continue to furnish conditioned power from the inverters and operate in a non-redundant mode. Emergency and bypass modes shall operate as described above. NOTE: INPUT SOURCE IS TWO INDEPENDENT SOURCES, 1 FOR UPS 2nd FOR STATIC BYPASS INPUT. Basic Requirements of an UPS System Lightning and surge protection. The unit should meet the requirements of IEEE standard 587 Category A or B. These requirements require the unit to withstand surges of 6000 V without damage to itself, and preventing the surge from reaching the protected load. Isolation. The UPS should have grounding and bonding provisions to reduce neutral-to-ground noise to zero, thereby preventing common mode noise from reaching the protected equipment. Line noise can cause possible malfunction to equipment. Voltage regulation. Equipment voltage requirements must be maintained within the limits prescribed by the manufacturer. Continuous, no-break power. A true UPS continuously serves the load through the UPS support battery, and the load never sees a power break when utility power is lost. Some units are standby power systems, whereby the load is transferred to the UPS only when utility power is lost or deviates from prescribed power quality parameters. A continuous no-break power unit must be used if no power interruption, even of a momentary nature, can be tolerated by the load. Output power waveform. Electronic equipment and computers are designed with the assumption that input power is an AC sine wave. All UPSs transform DC battery power from a constant output, straight line, to a variable output, sine wave, or a reasonable approximation thereof. With some low cost units, a quotreasonable approximationquot may be an abrupt square wave. It is important to adhere to the requirements prescribed by the manufacturer of the protected equipment. Load rating basis. More than 90% of computer equipment employs input switching-mode power supplies. The UPS load rating should be based on a switching-mode power supply load, rather than some unrelated load such as lighting or motors. References: Valerie A. Price, quotUPS systems: Powering Up Process Performance,quot Intech, July 1994, pp. 38-41. Vladi Basch, quotFallacies and Facts of UPS Systems,quot Plant Engineering, June 3, 1993, pp. 72-74. SAA09UP05-001, quotSystem Assurance Analysis of the Uninterruptable Power Supply System at the Orbiter Processing Facility High Bay-3quot SAA09UP01-001, quotSystem Assurance Analysis of the Uninterruptable Power System (Exide) UPS 2, 2A, 3, 3A at the Launch Control Centerquot","Lesson ID":662}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number GSE-3011 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Use of a FOD prevention program will minimize the possibility of damage or loss of flight hardware or injury to personnel due to lost items within the flight hardware elements, resulting in preservation of national resources. Implementation Method: FOD, as it is viewed at KSC, is defined as follows: Damage to, or malfunction of, a launch vehicle or payload caused by any foreign object(s) that are alien to flight systems. FOD may cause material damage or it may make the system or equipment inoperable, unsafe or less efficient. But what is FOD? FOD is somewhat ambiguous, because it varies depending on the situation. A paper clip on a desk is not FOD, because it is not foreign to that environment, but a paper clip in a commercial passenger jet engine or space shuttle main engine could prove catastrophic to either the flight vehicle, crew or both. FOD can consist of staples, paper clips, paper, particles generated from operations such as sanding, drilling and welding, liquids and chemicals, food, clothing, hair, insects, lost screws, nuts and washers, tools such as wrenches and screwdrivers, jewelry such as earrings, bracelets, watches and rings, eye glasses, plastic and rubber, tape, string, tie wraps, safety wire. Anything can be FOD if it is foreign to that environment. Its effect on the environment depends on many things, including a measure of luck. There are numerous facilities at KSC used for servicing and processing the Shuttle and its Payloads, External Tank (ET) and Solid Rocket Boosters (SRB's), and their various components. Each facility has its own unique tasks to perform, and associated hazards, both to the flight hardware and personnel. A FOD prevention program was implemented to improve the reliability of Space Shuttle processing. The primary goals of the FOD program is to: Provide a standardized approach, maintaining awareness, prevention, compliance and continued reinforcement. Ensure operational processing areas maintain a safe, clean, FOD-Free environment. The key to success is in a simple formula. AWARENESS + PREVENTION = COMPLIANCE. Figure 1 describes the attributes for each of these members. A FOD training program was established and a certificate of training is issued to each employee upon completion of the training. The employee signs the certificate as a pledge and personal commitment to help prevent Foreign Object Debris and Damage and to acknowledge their personal responsibility to the space program and flight safety. To attain a successful FOD program, total employee involvement is required. Everyone needs to be responsible. The SPC at KSC utilizes a 10 point plan to implement its FOD program. These 10 points are shown in Figure 2. The success of the FOD program has resulted in a decrease in incidents at the rate of approximately 50% per year. [D] [D] FOD Prevention Guidelines The following are general guidelines in establishing a FOD Prevention program, and can be tailored as needed to the specific requirements of particular work sites. Monitor in service tool Control Kits inventoried 100% each shift. Tooling, parts and equipment stored in a neat and orderly manner. Work area cabinets are maintained in a neat and orderly manner. No chemicals stored in cabinets. All chemicals and empty chemical bottles returned to the proper storage area. All quotHazardous Wastequot trash cans and FOD bags are emptied each shift. Work areas and work levels are clean and free of any debris. No wood, cardboard, bubble wrap, etc. Work area storage racks are maintained in a neat and orderly manner. No chairs on work stands or levels. Exception's are tethered chairs in approved areas. All equipment, tooling, trash cans, parts, etc., located above the floor level are tethered. All cables and flex hoses are routed and secured in an approved manner to prevent damage. All gloves, booties, razor blades, safety wire and miscellaneous items are disposed of in the proper manner. All paperwork turned in at the end of the shift. All emergency egress lanes are clear of any obstacles. Facility deficiencies are reported and recorded in the record log. All safety hazards reported to the supervisor immediately. All backup team members have taken care of assigned areas. Personal items such as watches, rings and eye glasses are either removed prior to entry to clean areas or are secured by taping or tethering. Definitions Clean As You Go - The practice of cleaning assigned tools, parts equipment, worksite, etc. (as practical), during and at the end of an assigned task, and\/or shift, to promote flight safety and ensure that the areas remain safe, clean and FOD-Free. Designate Flight Hardware Operational Processing Area - Sites with flight hardware and processing activities in place in support of Shuttle Processing Operations. Site FOD Monitor - An individual in the flight hardware operational processing area designated to promote FOD awareness, check specific areas of responsibility for potential FOD and\/or hazards, correct discrepancies and report open items to his\/her supervisor for closure. Site FOD Prevention Office - A control center for management support, trend analysis, concerns committees, incident reporting, suggestions, and any other relevant items that meet the objectives of FOD prevention. Site FOD Team - A team consisting of the Site Manager and applicable representatives from other organizations, to perform FOD prevention walkdowns in the flight hardware operational processing areas. Site Manager - An individual who has primary responsibility for processing and\/or maintenance tasks in an operational flight hardware processing area. Tool Control - The method used to ensure that tools are individually marked from other like items, identified to the user and storage location, and inventoried at the beginning and end of each task or shift. Work Area Rules - The requirements for ingress to and egress from the orbiter, external tank (ET), solid rocket booster (SRB), Space Shuttle Main Engine (SSME), and respective operational processing areas. General Requirements The procedures apply to all organizations that support flight hardware processing. The designated flight hardware operational processing areas will be maintained FOD free, clean, and safe at all times. There will be no abandoned debris, tools, parts, equipment, materials, chemicals, shavings, trash, flammables, contaminants, etc.; no ingress or egress obstacles; no unmarked or unidentified tools, parts, equipment, chemicals, etc.; no unsecured or untethered items above ground level; no unkempt areas; no hazards; nothing left in the area that does not have a specific purpose for work in process or functional requirement or is not stored properly. Only authorized personnel with valid requirements to perform work or surveillance will be allowed in the controlled work areas. Personnel entering into the designated flight hardware operational processing area will practice the quotclean as you goquot method, cleaning up assigned tools, parts, equipment, worksite, etc. as practical, during and at the end of the assigned task and\/or shift. Organizations having possession of hardware inventories and\/or tools and equipment will be responsible for those items and have a closed-loop tracking system, with tools and equipment traceable to location and user. The user is responsible for the physical location of all items carried into the flight hardware operational processing area and will be held accountable. Perform random inventory of toolbags upon ingress and egress of the flight element for compliance with the requirements. Report discrepancies. Each employee is expected to practice safety and good housekeeping habits and prevent FOD at all times in the designated flight hardware areas. Each operational processing area will have a FOD control board to hold clipboards for daily checklists and related FOD prevention data. FOD boards will be kept neat and clean. All personnel will view the KSC FOD Prevention Video and sign a personal commitment to quotClean As You Goquot. A copy will be on record in individual administrative files. Site Managers will be appointed by the Site Director. FOD prevention walkdowns will be scheduled on a regular basis in all operational processing areas by the Site Manager and the Site FOD Prevention Office. The Site Manager or delegate will attend all FOD prevention walkdowns. The work area will be checked for potential hazards and anything out of place that could potentially cause damage to flight hardware or injury to personnel. In addition to the scheduled walkdowns, daily walkdowns will be conducted by Site FOD Monitors. Site FOD Monitors will be selected for each shift at regular shift meetings, on a volunteer basis. Alternates will be appointed to cover absenteeism. Monitor duty will last for 1 month and will be in addition to normal work responsibilities. Before an employee can be selected for a second time, each work group member will have the opportunity to serve as Site FOD Monitor. Ensure that FOD prevention is stressed with subcontractors prior to award of contracts, have subcontractors sign a letter agreeing to follow the quotclean as you goquot method, and post a copy of this letter on the jobsite. Incentives As an incentive for good performance, rewards are given out. At SPC, the reward is a quotFOD Buster Chitquot. These chits are good for a $1 credit at the KSC cafeterias or mobile snack trucks. This provides positive reinforcement for the FOD program, and recognizes and encourages continued good performance. Organizations The Shuttle Processing Contractor is a member of National Aerospace FOD Prevention, Inc. The National Aerospace FOD Prevention, Inc. is a non-profit educational association. The organization's primary goal continues to be to promote awareness of the dangers of FOD and provide the aerospace industry with information on preventing foreign object damage to aircraft and aerospace vehicles with proven practices. Members are from military aerospace companies, as well as commercial aerospace companies, the various branches of the military itself, defense contractors and commercial business. A National Aerospace FOD Prevention Conference is held annually. The conferences have speakers on various topics, interactive learning sessions, and exhibitors. Member companies share their FOD program experiences, successes, and training programs with other with other members for the mutual benefit of all concerned. The annual conference promotes FOD prevention by keeping personnel who build or use aerospace products informed about the best practices in eliminating foreign objects. Topics discussed at the conferences and in the newsletter include Preventive Practices, Measuring Performance, Training, Material Handling and Parts Protection, House Keeping, Tool Accountability, Hardware Control, Lost Items, Hazardous Materials, Design Considerations, Assembly Operations, Reporting & Investigation. The National Aerospace FOD Board of Directors and the National Aerospace FOD Prevention Conference have been vital sources for disseminating current and effective FOD prevention ideas and techniques. Conclusions All flight hardware operational processing personnel are responsible for supporting the Site FOD Monitors and their supervisors to ensure the effectiveness of FOD prevention. Compliance will be monitored by random walkdowns conducted in addition to the scheduled walkdowns. The KSC\/SPC FOD program has been successful. By involving all hands-on employees, the Shuttle processing operations FOD Prevention Program has been able to Lead by Example. Operational areas reflect pride in ownership, accountability and a safe, clean work environment. Awareness has significantly improved and Hazards have been reduced. Astronauts are reporting exceptionally clean Orbiters. Technical Rationale: A FOD program reduces costs in lost tools, damaged equipment, schedule impacts due to rework, and reducing unnecessary risks in a business that is inherently risky. References: National Aerospace FOD Prevention Newsletter - FAST, P.O. Box 5489, Pine Mtn., CA 93222 Kennedy Space Center Handbook for the Foreign Object Control Program - KHB 5330.10","Lesson ID":666}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PD-ED-1229 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Selection of the optimum electric motor for space flight operations results in a safe, reliable, effective, efficient, and economical electric motor power source for space flight. Brushless direct current motors provide the lightest weight alternative for most applications. Implementation Method: Four principal types of electric motors are suitable for in-space applications; AC Induction Motors, Brush Direct Current (BDC) Motors, Brushless Direct Current (BLDC) Motors, and Stepper Motors. Table 1 shows the most predominant applications for each type of motor. [D] Generally AC Induction Motors are used for constant speed applications where a fixed frequency power source such as 60 Hz or 400 Hz is available in the spacecraft. Typical applications are fans and pumps. Motor construction consists of windings on the stationary part of the motor and copper shorting bars on the iron laminations of the armature. The AC voltage applied to the windings induces a current in the armature of the rotor, creating a magnetic field. This field reacts with the field in the stationary part of the motor to create torque. These motors are rugged with no wear out mechanisms other than the bearings. The BDC motors use commutators and carbon brushes to apply current through the windings as the motor rotates. The BDC motor uses wound elements in the rotor and permanent magnets attached to a stationary stator ring. In a BDC motor, electrically separated motor windings are connected to the commutator ring. Current is carried by spring loaded brushes, through the commutator into the windings of the rotor. The current in the windings creates magnetic fields, which react with the stator's permanent magnetic field. These magnetic repulsion causes the rotor to rotate. This rotation causes the brushes to make and break connections through the commutator with different windings pairs. The moving magnetic field provides the torque necessary to rotate the motor's armature. The BLDC motor uses electronic commutation to control the current through the windings. The BLDC motors use permanent magnets on the rotor. The BLDC motors contains rotor position sensor electronics so that the power input wave form to the windings is in sequence with the proper rotor position. Motor efficiency is enhanced because there is no power loss in the brushes. In the BLDC motor, the stator is wound with electromagnetic coils that are connected in a multiphase configuration, which provides the rotating field, and the armature consists of a soft iron core with permanent magnet poles. Sensing devices define the rotor position. The commutation logic and switching electronics convert the rotor position information to the correct excitation for the stator phases. Sensing devices include hall-effect transducers, absolute encoders, optical encoders, and resolvers. The electronic controller can be separate or packaged with the motor. BLDC motors are preferred over BDC motors for most space environments. If BDC motors are used, the qualification of brush motors for the space environment is both expensive and time consuming. The advantages and disadvantages of the two types of DC motors are listed in Tables 2 and 3. [D] [D] Application gives the designer the intended use and could perhaps optimize an existing design. The no-load speed, stall torque, and the load point are used to establish the motor torque loadline. Knowing the no load speed and available voltage, the designer can establish an initial back EMF constant and the motor torque constant. The stall torque combined with the load point torque helps establish motor size. The duty cycle, temperature, and expected heat sinking are used with the motor size to determine the temperature rise of the motor. The design is optimized to meet the customer's requirements. Since the BLDC and stepper motors are the most predominant motors used for aerospace applications, an expanded listing of applications and requirements is shown in Table 4. [D] Stepper motors are a special case of BLDC Motors. Construction is identical except that they contain no position sensors. Excitation is sequentially applied to the windings, creating the rotating field to produce torque. The advantages are simplicity and compatibility with digital control schemes. Disadvantages are high continuous power dissipation and high ripple torque. The system designer typically requires the motor information listed in Table 5. [D] Technical Rationale: Selection of the appropriate motor for a given application permits more reliable operation, while minimizing weight, power consumption, and thermal dissipation requirements. References Sokira, Thomas J. and Wolfgang Jaffe: 'Brushless DC Motors Electronic Commutation and Controls,' Tab Books, Inc., Blue Ridge Summit, PA, 1990 Dang, Ngon T.: 'Overcoming Brushless DC Motor Limitations,' Electronic Products, Pgs. 63-67, July 1993 'Brushless DC Motor Handbook,' Inland Motor, Kollmorgen Corporation, Radford, VA 1989.","Lesson ID":893}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number GSE-3003 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: The benefit of using dual redundancy in critical KSC Ground Support Equipment (GSE) systems is greater assurance of successful system operation during critical shuttle processing operations in the event of a single equipment failure that would otherwise possibly cause loss of life, vehicle or damage to a vehicle system. By designing in redundancy for critical operations, the system can fail to a quotfail-safequot condition and still achieve operational objectives. Implementation Method: The Orbiter Access Arm (OAA) is a critical GSE system located at Launch Complex 39, Pads A and B, Kennedy Space Center, Florida. The OAA is extended shortly after the shuttle arrives at the launch pad to allow personnel access to the shuttle to make the necessary preparations for launch. Shortly before launch, the astronauts will board the shuttle via the OAA. The OAA provides the only path of ingress and egress to the space shuttle crew cabin for the astronauts. Thus, this system becomes critical to the safety of the crew. A critical system, as it applies to KSC GSE systems, is a system whose loss of overall system function, or improper performance of a system function, could result in loss of life, loss of the shuttle vehicle itself, or damage to a shuttle system. In addition, systems that have been identified as critical must be designed to be fail-safe. Fail-safe design provides the ability to sustain a critical system failure without causing loss of life, loss of the shuttle vehicle, or damage to a shuttle system. This includes the capability to safe the systems and successfully terminate operations, or if required, to continue operations through to completion. Therefore, the OAA system must be able to sustain a failure and still be able to perform its function to completion of the operation. In the event of a single system failure, it must fail to a safe condition, meaning a single failure will not result in loss of life, loss of the shuttle, or damage to a shuttle system. The critical condition is encountered when the OAA is retracted away from the shuttle at T-7:30 minutes in the countdown in preparation for launch. Should an emergency arise, either on board the shuttle or on the launch pad, during the final minutes of the countdown after the OAA is retracted, the OAA will need to be re-extended to allow the astronauts to evacuate the area as quickly as possible. Extension of the OAA is essential to the astronauts safety, as it is the only path available to the crew in the event evacuation of the shuttle is required. The astronauts lives depend on the OAA extending when needed. The probability of 2 redundant components failing during a critical time period is much less likely than 1 component failing during the same period. In the case of the OAA, 2 completely redundant sets of valves, plumbing, and electrical controls are installed. Based on the classical probability theory, assuming no common cause failures, it can be shown that through using dual redundancy the reliability of a system can be increased 1 or more orders of magnitude. Thus redundant system design provides protection against a single failure causing a hazardous condition resulting in loss of life, destruction of a shuttle or damage to a shuttle system. Technical Rationale: Redundancy is defined as multiple ways of performing a function. There are several different types of redundancy used on KSC GSE systems. Depending on the requirements of the application, the type of redundancy to be used will vary. The two primary types of redundancy are described below: Operational or Active quotfully onquot Redundancy - Redundant elements, all of which are fully energized during the system operating cycle. Operational redundancy includes load sharing redundancy wherein redundant elements are connected in such a manner that, on failure of one unit, the remaining redundant elements will continue to perform the system function. Switching out the failed element is not required. Operational redundancy may be either full parallel or quotmajority votequot. Standby Redundancy - A redundant hardware item(s) that are non-operative until they are switched into the system on failure of the primary item(s). Switching can be accomplished by either automatic or manual means. Other categorization of redundancy include: Like Redundancy - Identical hardware items performing the same function. Unlike Redundancy - Nonidentical hardware items performing the same function. Safety features which provide protection for specific failure modes are considered as unlike redundancy for that failure mode; i.e. relief valves which provide protection against overpressurization after failure of a regulator Typically, KSC employs parallel, two component redundancy. It can be shown that the incremental reliability gain is greatest for the first redundant unit and decreases rapidly as more redundant units are added in parallel. Figure 1 provides an example of a basic block diagram of the hydraulic extend circuit for the Orbiter Access Arm (OAA) showing the use of redundancy in a critical shuttle ground support system. [D] A hydraulic reservoir fills 4 hydraulic accumulators. Only 2 accumulators are needed to ensure arm retract and extend, but 2 additional (redundant) accumulators are provided for fail-safe operation in the event of a leak. In the event of a major leak, the launch countdown will stop. If a major leak occurs during an emergency re-extend operation, the 2 redundant accumulators should supply enough hydraulic pressure to ensure full extension of the OAA. In addition, the hydraulic supply system is capable of supplying additional pressure if required. The ensuing discussion will address the primary system only. Design of the system minimizes the likelihood of a common cause failure. The accumulators provide hydraulic fluid to a pilot valve (Primary Hydraulic Extend Pilot Valve) and to the main hydraulic supply valve (Primary Hydraulic Extend Supply Valve). When commanded by LPS (Launch Processing System), the pilot valve supplies hydraulic pressure to the Primary Hydraulic Extend Supply Valve and to the Primary Hydraulic Extend Return Valve, thus opening both valves. Hydraulic fluid from the accumulators then flows thru the Primary Hydraulic Extend Supply Valve to the upper and lower OAA hinges. Each hinge is individually capable of rotating the OAA. Thus the hinges are redundant. Fluid exits the OAA hinges, and returns to the main hydraulic reservoir through the Primary Hydraulic Extend Return Valve. This discussion described the basic operation of the primary hydraulic extend circuit for the OAA. There is a secondary (redundant) set of valves as described above installed in parallel with the primary valves, that simultaneously operate. Operational redundancy ensures that the OAA will operate when needed. A single failure will not result in a catastrophic consequence. References: O'Connor, Patrick quotPractical Reliability Engineeringquot 2nd Edition, Wiley, 1985.","Lesson ID":659}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1205; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Adhering to proven design practices and processing techniques for 2219 Aluminum and Inconel 718 will result in high performance joints, reduced weld defects, reduced weld repair costs, and reduced inspection costs. These practices, if conscientiously applied, will reduce the potential for galvanic corrosion, hot cracking, imperfect bead shape, inclusions, lack of fusion, lack of penetration, microfissuring, mismatch, peaking, porosity, residual stresses, start\/stop defects, and stress corrosion cracking. Implementation Method: Three types of welding for two commonly used materials have been used predominantly at NASA\/MSFC for the welding of aerospace hardware: (1) Gas Tungsten Arc Welding (GTAW) for 2219 aluminum; (2) Variable Polarity Plasma Arc Welding (VPPAW) for 2219 aluminum; and (3) Electron Beam Welding (EBW) for Inconel 718. In Gas Tungsten Arc Welding for 2219 aluminum, heat required to join the aluminum is generated through an electrical arc applied at the joint. An inert atmosphere of helium surrounds the arc to prevent oxidation during the welding process. The type of GTAW covered in this practice is direct current, straight polarity (DCSP) in which the torch serves as the negative electrode (cathode) and the work piece as the positive electrode (anode). In Variable Polarity Plasma Arc Welding for 2219 aluminum, an arc gas (argon) is constricted by an orifice in the torch so that it forms a narrow column of high density gas that carries the arc current. Current is reversed up to 20 percent of the time in a 20 to 25 microsecond cycle to provide a cleaning action to the work piece. Electron Beam Welding is performed in a vacuum and generates heat for fusing adjoining metals by impacting high kinetic energy electrons upon the work piece surface. [Definitions of selected welding terms applicable to the three types of welding are provided at the end of this section.] The three types of welding, along with distinguishing recommended practices for each, are shown in Table 1. Among the important practices that will aid in ensuring high reliability welds are welding in the proper position, use of high purity shield and plasma gasses, proper cleaning of the joint prior to welding, operator certification, and computer control of the welding process. The use of 2-percent thoriated tungsten electrodes for GTAW and VPPAW provides arc stability and increases electrode service life over that of standard tungsten electrodes. Important additional precautions for all three types of welding are use of rigid tooling to reduce weld joint deformation, nonmagnetic tooling to prevent skewing of the arc due to magnetic deflection, and correct and properly marked weld rod and wire. Automation is highly desirable for all three methods to maintain weld uniformity. If tack welds are used to temporarily hold adjoining parts in place, they should be consumed during the welding process. Specific characteristics, parameters, precautions, and criteria for each type of welding are described in the following three paragraphs: 1. Gas Tungsten Arc Welding (GTAW) (DCSP) for 2219 Aluminum As shown in Table 1, the flat (downhand) position is preferred for the best weld uniformity and penetration. Welding in the direct current, straight polarity (DCSP) mode while using high purity helium shield gas provides deep penetration without oxidation or contamination. (Welding in the alternating current mode is particularly suitable for welding thin aluminum as it produces less heat and provides good cathodic cleaning.) Pulsing of the weld current can be used to provide better control for some out-of-position welds. Minimizing the number of weld passes will decrease the tendency for distortion. A pointed tip electrode is used in GTAW. A positive torch quotlead anglequot is desirable for GTAW (DCSP) to provide preheating and more uniform melting. Lower energy inputs generally increase weld strength. GTAW (DCSP) is a preferred process for tack welding of aluminum. GTAW (DCSP) also can be used for welding steels (including stainless steel), titanium, magnesium (with care), and refractory metals. The 2219 aluminum is an excellent alloy for maximum strength in cryogenic applications with good weldability. Table 1. Weld Characteristics\/Parameter\/Criteria for Three Types of Welding CHARACTERISTIC OR PARAMETER RECOMMEND OR STANDARD PRACTICES GAS TUNGSTEN ARC WELDING (2219 Al) VARIABLE POLARITY PLASMA ARC WELDING (2219 Al) ELECTRON BEAM WELDING (INCONEL 718) Preferred Position Flat Vertical Flat Shield Gas Helium (99.999% Purity) Helium (99.999% Purity) Vacuum Plasma Gas N\/A Argon (99.999% Purity) N\/A Backing Required No No In Some Instances (1) Preferred Electrode 2% Thoriated Tungsten 2% Thoriated Tungsten (Tungsten Filament) Appropriate for Repair Yes Not Usually (2) Yes Cleaning Requirements Mechanical Removal of Oxide, Free of Hydrocarbons Mechanical Cleaning Not Required, Degrease Only Special Cleaning for Vacuum Requirements Used for Tack Welding Yes No Yes Computer Control Desirable Essential Desirable Most Prominent Potential Defects Oxide and Tungsten Porosity, Lack of Penetration or Fusion Undercut, Lack of Fusion Improper Seam Tracking, Microfissuring N\/A: Not Applicable Notes: Backing bars are used for EBW in some instances to ensure full penentration without overshooting or to eliminate excessive spatter. VPPAW usually is employed in an initial manufacturing process since it is the most sophisticated method and the most adaptable to automation. Repair of larger seam welds may be appropriate for jobs of sufficient size warranting setup. [D] 2. Variable Polarity Plasma Arc Welding (VPPAW) for 2219 Aluminum Figure 1 shows three variations of plasma arc welding: (1) Straight Polarity; (2) Reverse Polarity; and (3) Variable Polarity. Variable Polarity Plasma Arc Welding retains the high heating capacity of the straight polarity process while offering the part cleaning feature of reverse polarity. A flat-tipped electrode is used in VPPAW. A minimum of reverse cycle time is required to keep electrode erosion low. As in the case of GTAW (DCSP), lower energy inputs generally increase weld strength and minimize distortion. Axial torch rotation to align the arc with the weld joint, and torch designs incorporating self-centering electrodes will compensate for electrode tip erosion and will provide greater accuracy in seam tracking and weld bead uniformity. A positive torch quotlead anglequot of 0 to 3 degrees is desirable for automated welding with VPPAW. Electromagnetic interference caused by the welding process will require shielding or distance separation of computer monitoring and control devices. High purity grades of both the plasma gas and the shield gas are required. VPPAW also can be used for welding steels, Inconel, and other metals. 3. Electron Beam Welding (EBW) of Inconel 718 EBW produces deep, narrow welds with parallel sides and a narrow heat-affected zone. It is performed in a vacuum in most aerospace applications, and a near-zero joint gap is required to ensure fusion of the parts. EBW provides minimum distortion because of low total heat input whether used on thick or thin sections; however, full penetration welds may result in excessive spatter. The vacuum environment requires special cleaning. The size of work to be welded is limited by the size of the vacuum chamber and configuration of the manipulator. While EBW can be used to weld almost any metal, it often is used on high melting point metals including the refractory metals requiring stringent control of oxides. EBW is suitable for welding dissimilar metals and parts of dissimilar mass. DESIGN CONSIDERATIONS FOR WELDED COMPONENTS As will be seen in quotImpact of Nonpractice,quot the concepts of a workable welded part design and a producible and inspectable weld joint configuration are very important to successful welding using any of the three processes described. The design of weld joints and of the special processes, tooling, and equipment needed to weld each configuration is best accomplished through use of a team approach in which the designer consults with materials, stress analysis, weld engineering, manufacturing, and inspection personnel as the welded design evolves. The process to be used to create the weld; the weld's fracture mechanics and fatigue properties in its planned environment; compatibility of the materials to be welded; the desired strength of the completed weld joint; and the method to be used to inspect the weld are among the many important factors that must be considered in weld joint design. Manufacturing, quality assurance, and design engineering personnel working hand-in-hand in this team approach will ensure reliable weld configurations. The need for this team approach cannot be overemphasized. Among the design practices for welding aerospace hardware are: (1) detailed consideration of fracture mechanics and fatigue effects, particularly in welding very thick materials to very thin materials; (2) designing, testing, and qualifying coupons of new weld configurations; (3) locating welds to avoid bending forces that concentrate stresses in the weld bead area; and (4) the design of joints that accommodate adequate visibility, tool access, and inspectability. Conscientious adherence to the team approach to weld configuration and process design will account for these and many other factors that will result in defect-free, inspectable, and reliable welds. NONDESTRUCTIVE EVALUATION OF WELDS In addition to visual inspection, there are a number of methods to inspect welds. These include x-radiography, ultrasonics, eddy current, dye penetrant, and magnetic particle inspection. Real-time inspection can be performed while the welding is being performed in automated systems that incorporate weld bead profiling, infrared detection, and x-ray image display graphics. Although x-radiography is suitable for detecting voids or discontinuities in the weld or the parent material, fine surface cracks often go undetected. Double-walled inspections by this method should be avoided. This method is limited by the welded part configuration because the film used to record the x-ray image must be placed to provide a suitable angle of incidence. Ultrasonics has some physical limitations due to thickness and angle of assembly of parts (angles less than 45 degrees cannot be effectively inspected using ultrasonics). Eddy current inspection, which measures induced current in the weld and parent material in the presence of a magnetic field, requires highly skilled technicians, but is a favored method of weld inspection for many weld NDE situations. Both the ultrasonic and eddy current methods are sensitive to most weld and parent material flaws. Real-time inspection and recording of NDE results, as is done with automated weld bead profiling, provides a permanent record of weld parameters as the weld bead is generated. Automated NDE techniques offer the advantage of on-site correction of welding operations before detrimental effects of inaccurate welding become excessively costly. Technical Rationale: The design and processing recommendations in this practice have evolved over several decades of fabricating large aerospace vehicles and related ground support equipment. Rationale is documented in greater detail in the standards, specifications, technical memoranda, and reports listed as references. General processes are included in References 1, 2, and 7 through 9. Specific experience on VPPAW is described in References 5 and 6. The effect of impurities in plasma arc welding gasses was explored in an in-depth contracted effort by the University of Texas at El Paso (Reference 4). The causes of and remedies for microfissuring of welded Inconel 718 are described in Reference 3. Work is continuing to further explore and document effective practices for welding automation and nondestructive testing procedures. This continuing work will be the basis for additional practices that may be submitted for publication at a later date. References: Publications that contain additional information related to the practice are: Nunes, Jr., A. C., quotA Comparison of the Physics of Gas Tungsten Arc Welding (GTAW), Electron Beam Welding (EBW), and Laser Beam Welding (LBW),quot NASA TM 86503, NASA\/MSFC, August 1985. Yang, H. Q. and Przekwas, A. J., quotA Mathematical Model to Investigate Undercutting and to Optimize Weld Quality,quot CFRDC Report 4095\/2, CFD Research Corporation, June 1990. Nunes, Jr., A. C., quotInterim Report on Microfissuring of Inconel 718.quot NASA TM-82531, NASA\/MSFC, June 1983. McClure, John C., quotThe Effect of Impurity Gasses on Plasma Arc Welded 2219 Aluminum,quot NAS-8-37425, The University of Texas at El Paso, August 1989. Nunes, Jr., A. C., quotThe Variable Polarity Plasma Arc Welding Process: Its Application to the Space Shuttle External Tank - First Interim Report,quot NASA TM-82532, NASA\/MSFC, June 1983. Nunes, Jr., A. C., quotThe Variable Polarity Plasma Arc Welding Process: Its Application to the Space Shuttle External Tank - Second Interim Report,quot NASA TM-86482, NASA\/MSFC, November 1984. Schuerer, Paul H., quotWelding Aluminum Alloys,quot MSFC-SPEC-504C, NASA\/ MSFC, November 1990. Schwinghamer, R. J., quotWelding: The Fusion Welding of Steels, Corrosion and Heat Resistant Alloys,quot MSFC-SPEC-560A, NASA\/MSFC, June 1988. quotWelding, Electron Beam, Process for,quot MIL-W-46132, Department of the Army, February 1989. Definitions of Selected Welding Terms* arc welding (AW). A group of welding processes that produces coalescence of metals by heating them with an arc, with or without the application of pressure, and with or without the use of filler material. arc welding electrode. A component of the welding circuit through which current is conducted and which terminates at the arc. backing. A material or device placed against the back side of the joint to support and retain molten weld metal. The material may be partially fused or remain unfused during welding and may be either metal or nonmetal. defect. A discontinuity or discontinuities that by nature or accumulated effect (for example, total crack length) render a part or product unable to meet minimum applicable acceptance standards or specifications. downhand. A nonstandard term for flat position. flat position. The welding position used to weld from the upper side of the joint. The face of the weld is approximately horizontal. fusion. The melting together of filler metal and base metal (substrate), or of base metal only which results in coalescence. galvanic corrosion. Galvanic corrosion manifests itself in the accelerated corrosion of the more active metal (anode) of a dissimilar metal couple in an electrolyte solution or medium, and decreased corrosive effects on the less active metal (cathode), as compared to the corrosion of the individual metals, when not connected, in the same electrolyte environment. (MIL-STD-889B:7 July 1976) hot cracking. Cracking that develops during solidification. inclusions. Particles or fibers of foreign materials and substances in the completed weld. lead angle. Alignment of the welding device perpendicular (90 degrees) to the weld joint in the direction of travel would represent a zero lead angle. An increase of up to 3 degrees above 90 degrees in the direction of travel represents the recommended positive lead angle. microfissuring. The formation of small cracks in the weld metal or weld heat-affected zone within the grain boundaries or low melting constituent regions resulting from weld thermal stresses that can occur during welding. mismatch (offset). An unintended nonplanar match of parallel work pieces resulting from the welding process. peaking. An unintended angular displacement of the weld joint that can occur during welding. penetration. The depth a weld extends from its face into a joint, exclusive of reinforcement. porosity. Cavity-type discontinuities formed by gas entrapment during solidification. postheating. The application of heat to an assembly after welding. seam tracking. Alignment with respect to the joint of the welding device as it progresses along the interface between the two materials being joined. stress corrosion cracking. Failure of metals by cracking under combined action of corrosion and stress, residual or applied. tack weld. A weld made to hold parts of a weldment in proper alignment until the final welds are made. undercut. A groove melted into the base metal adjacent to the weld and left unfilled by weld metal. vertical position. The position of welding in which the weld axis is approximately vertical. weldability. The capacity of material to be welded under the imposed fabrication conditions into a specific, suitably designed structure and to perform satisfactorily in the intended service. weld axis. A line through the length of a weld, perpendicular to and at the geometric center of its cross-section. weld bead. A weld resulting from a pass. welder certification. Certification in writing that a welder has produced welds meeting prescribed standards. weld pass. A single progression of welding or surfacing along a joint or substrate. The result of a pass is a weld bead. *Adapted from American Welding Society, Inc.; Standard Welding Terms and Definitions; ANSI\/AWS A3.0-85","Lesson ID":663}
{"Driving Event":"Contact with the SOlar Heliospheric Observatory (SOHO) spacecraft was lost in the early morning hours of June 25, 1998, Eastern Daylight Time (EDT), during a planned period of calibrations, maneuvers, and spacecraft reconfigurations. Prior to this the SOHO operations team had concluded two years of extremely successful science operations. A joint European Space Agency (ESA)\/National Aeronautics and Space Administration (NASA) engineering team has been planning and executing recovery efforts since loss of contact with some success to date. ESA and NASA management established the SOHO Mission Interruption Joint Investigation Board to determine the actual or probable cause(s) of the SOHO spacecraft mishap.","Lesson ID":664}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number GSE-3010 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: The major benefits for the use of oil-free vacuum pumps in the LOX\/LH2 transfer system is that these pumps eliminate the danger of oil or oil molecule contamination and can be safely operated unmanned. This results in both cost saving and a reliability improvement in the pumping process. Implementation Method: The implementation of oil-free vacuum pumps has resulted in eliminating the danger of oil contaminants, increased reliability and has resulted in a reduced support costs. Technical Rationale: Oil-free pumps offer many advantages over the oil sealed pumps. The oil-free pumps are light-weight, truly portable, highly versatile, and the absence of fluids means the pump can be operated in any orientation - sideways or upside down. There are a number of considerations that affect the decision of whether to use an oil-free or an oil-sealed pump. First, and most important, is the determination of whether the application is sensitive to oil contamination. If it is determined that the application is oil sensitive, the next consideration is whether or not a foreline trap is sufficient to prevent the backstreaming oil from entering the process chamber in quantities that will cause contamination problems, if not then consideration should be given to use of oil-free pump. Oil-Sealed Type Pumps: The foreline traps (oil-sealed mechanical pump) is one type of pumping system that the LOX\/LH2 system engineers considered for use in the LOX\/LH2 transfer system vacuum jacketed lines. The following paragraphs discuss some of the characteristics of the foreline trap pump and figures 1, 2, and 3 show the creeping surface that can cause oil contamination. Foreline or roughing traps have been used for a number of years in an attempt to stop or reduce the oil backstreaming from oil-sealed mechanical pumps. Although they have had great commercial success in terms of number of units used, they have a number of problems that need be weighed carefully if they are to be considered as a method of stopping the pump oil from entering the chamber. Three types of foreline traps are commercially available: Condensation traps, Cryogenic Absorption traps, absorbent trapping medium Absorption traps, active surface trapping medium All have a potential problem that needs constant consideration. They have room temperature walls which will allow liquid oil to coat the inner surfaces and once the oil has passed through into the system side of the trap, it becomes a vapor source that can no longer be prevented from entering the system. The amount of time required for the surface oil to work its way through the trap will vary with the application. The best way of determining when oil is passing through is to occasionally remove the trap from the pumping line and placing a drop of water inside the tubulation on the system side to see whether it beads or spreads. Once oil is detected on the system side, iti\u0301s time to solvent clean the trap or to bake out the entire trap, walls and all. The time to fully penetrate through the trap will be extended if the mechanical pump is shut off and the trap (fore or roughing line) is air released when the pump is not being used. [D] The LOX\/LH2 System Engineers selected the oil-free type pump shown in figure 4, because this pump incorporates new vibration isolation techniques, new 3-stage pumping technology, simplified construction for easy maintenance and increased reliability. This type pump will probably have higher initial costs than an oil-sealed mechanical pump. Figure 4, shows a picture and Block Diagram of an oil-free pump. Oil-Free Pumps The following paragraphs briefly discuss some of the characteristics and advantages of an oil-free pump. Unique design: The key to this type pump performance is a unique three-stage design, which incorporates a molecular drag module backed by two customized diaphragm modules to provide a constant, dynamic flow of gas. Each module functions selectively in series, automatically carrying the pumping burden within its own pressure\/flow envelope. As each successive stage acquires the primary pumping burden, the previous stage continues pumping in a support capacity. Entirely oil-free: Since no module uses pump fluids, roughing or backing with this type pump introduces no oil to backstream into a system. They require no traps, oil filtration accessories, or special oils as all mechanical pumps do. Since traps are unnecessary, oil-free pumps without a trap can deliver their full pumping speed. Mechanical pumps with traps inevitably experience speed losses. Clean, efficient backing: These type pumps provide highly efficient backing for turbo or diffusion pumps, improving their performance by providing a lower foreline pressure. In most cases, an oil-free pump will help achieve vacuum up to an order of magnitude higher than mechanical type pump. Versatile: Oil-free pumps will pump any gas, including hydrogen and helium, and any condensables, e.g., solvents or water vapor. They never load up with quotmemoryquot gases. Easy to use and repair: The oil-free pump requires no cryogenic or bakeout procedures. Because the molecular drag and diaphragm modules are separate, each can be easily repaired in the field or, if necessary, completely replaced. [D] References: KSC Problem Report Number S70-0817-00-001-0553, dated 5\/9\/89","Lesson ID":665}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1216; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Provides multiple ways of accomplishing a function to improve mission reliability. Implementation Method: The decision to use redundant design techniques should be based on analysis of reliability and test data. Redundancy may prove to be the only available method when other techniques of improving performance (e.g., better components, additional derating, simplification, software debugging) have been exhausted or when methods of item improvements are shown to be more costly than duplications. The use of redundant equipment can allow for repair with no system downtime. Some situations exist in which equipment cannot be maintained (e.g., communication satellites), in which case dormant redundant elements may be a necessary approach to prolong operating time. The application of redundancy is not without penalties. It will increase weight, space, complexity, and time to design, fabricate, assemble, and test. It may also increase costs; however, the costs may be recovered by the increased reliability. Thus, safety and mission reliability is gained at the expense of adding more items to test. The increase in testing time may be reduced by making improvements in the components such as the use of more reliable parts, more derating, design simplification, and software improvements. The incorporation of redundancy into a design must take into account quotcheckable redundancy.quot It is important to be able to functionally test the redundant elements prior to mission start. If this capability is not present, the benefits of redundancy may be defeated by the uncertain functionality. However, if the designer takes into account built-in test planning, inclusion of test points, and packaging, the benefits of active redundancy will be retained. Technical Rationale: As an example, consider how redundancy was used in the transmitters of the Communications Technology Satellite (CTS). The component failure data for the basic nonredundant configuration of the Traveling Wave Tube (TWT) is shown in Table 1. CTS TWT Component Failure Data [D] K A= application factor =>engineering adjustment for use application The TWT serves as the final output stage and driver for the 200W transmitter. Most space applications require long operating times for earth\/satellite communications. Therefore, reliability without maintenance is a major design and manufacturing concern. (The analysis used in this example assumes that the failure rates are constant over time and, therefore, the calculations are used as engineering estimates.) For the nonredundant circuit, the approximate total failure rate is given by: Failure Rate=l~ 27.4x 10 -6 failures \/ hour This rate is then adjusted by an operating factor based on engineering judgement to take into account the space environment, Kop: l total=lK op= (27.4 x 10 -6)(0.33) = 9.04x10 -6 failures \/ hour Using a mission time of 17,520 hours (2 years, the CTS performance goal), the approximate reliability for the nonredundant configuration is: R = e-ltotalt= e- (9.04 x 10-6)(17,520) R = 0.85 For the simple, redundant configuration, the approximate reliability is: Rs= 1- (1-R1)(1-R2),whereR1= R2= 0.85 Rs= 0.98 Obviously, the use of redundancy can greatly enhance the transmitter reliability and give high confidence that the two year CTS performance goal will be met. However, there are additional considerations that need to be taken into account. Specifically, we need to address the additional components added by the redundancy, such as switches, sensors, and\/or activators. In this case, two switches are added in order to activate the redundancy (see Figure 1).The first switch is a coaxial transfer switch with a failure rate of 1.1 x 10-6. The second switch, a waveguide transfer switch, has a failure rate of 1.5 x 10-6. These are the only two components added due to the redundancy. The command receiver\/decoder needs to operate in order to activate the switches. However, if it fails, the whole spacecraft would fail whether the redundancy is present or not. Therefore, the following additional calculations need to be made: lSWI= 1.1 x 10-6 leqTWT= 1.15 x 10-6 (sinceR = 0.98) lSW2= 1.5 x 10-6 Switched Redundant TWT Block Diagram [D] lRED=lSW1+leqTWT+lSW2= (1.5 + 1.15 + 1.1) x 10-6=3.75 x 10-6 RRED= 0.94 Therefore, the total Reliability of the redundant system is approximately 0.94. This is still a big improvement over the single component reliability of 0.85. The success of the CTS spacecraft demonstrated this improved reliability as all CTS transmitters operated beyond their performance goal of 2 years. Both the advantages and disadvantages of redundancy should be considered prior to its use. To repeat, the disadvantages of using redundancy to solve a reliability problem are increased weight, cost, and complexity. Additions of back-up systems and\/or lower level items add the weight and cost of the additional hardware. This weight and cost may be reduced by the application of piece part redundancy. A more harmful effect may be increased complexity which would negate the reliability improvement. For example, sensing, activation, and switching hardware added to use the redundant component may reduce the overall reliability lower than that of the simple string. There are many cases where deliberate redundancy provides reliability improvement with cost reduction. It does not necessarily follow that simple redundancy is the cost effective way to compensate for low reliability. The design engineer has the responsibility to determine what balance of redundancy alternatives is the most effective to use. In the trade-off process, it may be determined that redundancy, by the duplication of hardware, may impact the cost of preventive maintenance. This is a significant factor in life cycle cost considerations for equipment worth. Redundancy may be practical if a designed item is readily available, and more economical than redesign. However, redundancy may be too expensive if the item is costly, or too heavy if spacecraft limitations are exceeded. These are all trade-offs which the designer must consider. References: Dillard, R.B., Reliability for the Engineer, Book Two, Martin Marietta Corporation, 1973. quotElectronic Reliability Design Handbook,quot MIL-HDBK-338-1A, October 1988. Klion, Jerome, A Redundancy Notebook, Rome Air Development Center, RADC-TR-77-287, December 1987. Lalli, Vincent R. and Speck, Carlton E., quotTraveling-Wave Tube Reliability Estimates, Life Tests, and Space Flight Experience,quot NASA TM X-73541, January 1977. quotReliability Modeling and Prediction,quot MIL-STD-756B, November 1981.","Lesson ID":697}
{"Driving Event":"This Lesson Learned is based on Reliability Guideline Number GD-AP-2303 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Consideration of fatigue reliability during the design process can assist in the prevention of failures of structural and mechanical components subject to fluctuating loads in service. Explicit consideration of the reliability of structural and mechanical components provides the means to evaluate alternative designs and to ensure that specified risk levels are met. Probabilistic fatigue analyses may also be applied to life extension of existing structures, and for problem assessment of in-service fatigue failures. Potential applications of this guideline to the Space Shuttle or International Space Station Alpha Programs include: landing gear, control surfaces, main engine components, auxiliary power unit components, external tank and solid rocket booster welds, pressure vessels, propulsion modules, and logistics modules. Implementation Method: A detailed discussion of the procedures for performing a spectral fatigue reliability analysis may be found in reference 1. A quotclassicalquot fatigue approach is described which utilizes the constant amplitude S-N curve characterization of a material's or component's fatigue resistance capability. The applied random loads are characterized by their power spectral density (PSD), and crack initiation locations (or hot spots) are determined by an analytical or experimental stress analysis. A structural dynamic analysis or test is used to determine the harmonic response function, H(w), which relates external loads to nominal internal stress. The mean or average fatigue life, T, is computed using either the Rayleigh [references 2, 3, and 4] or Single-Moment methods [references 5 and 6]. For high-cycle fatigue (high number of cycles) the uncertainty or randomness in the fatigue life due to the random loading is negligible (although load uncertainty is generally problem specific) [reference 2], but considerable uncertainty remains due to intrinsic metallurgical and geometric variations. In the usual deterministic fatigue analysis practice this uncertainty is accounted for by reducing the computed fatigue life by a quotscatter factorquot of 2 to 4 to determine the quotsafequot life. In a probabilistic approach the metallurgical and geometric variations are more rationally included by modeling them as random variables, using data from the S-N curve fitting and\/or from the stress analysis. Sufficient data is necessary for statistical treatment (such as correlation analysis and distribution fitting) and is discussed in reference 1. However, even in cases for which sufficient problem specific data does not yet exist for rigorous statistical treatment, probabilistic risk assessment (PRA) methods may be used to construct distributions for the variables based on experts' opinions of the variables' range and likely values. Such an approach is useful as a first approximation until problem specific data becomes available and has the advantage of formally using the same quotexpert dataquot (engineering experience) that is usually only informally used in selecting the quotscatter factorquot. The resulting expressions for the distribution of the time to failure are generally not amenable to solution by analytic techniques. However, modern numerical structural reliability methods [reference 7] are available for solving these types of problems in several commercial software packages, such as PROBAN [reference 8], STRUREL, and NESSUS. These programs allow the characterization of any number of parameters in a problem as random variables. Usually this requires the characterization of the problem in the form of a mathematical expression or a computer subroutine which relates the input variables to some characteristic output variables which determine the failed or safe state of the system modeled. Simulation methods such as Monte Carlo, importance sampling, latin hypercubes, directional sampling, or axis-orthogonal sampling are also available in PROBAN. A Monte Carlo simulation approach to a Space Shuttle Main Engine fatigue problem is also described in reference 9. These methods are compared and their relative merits are discussed in reference 1. The results of a probabilistic fatigue analysis are usually expressed as the probability of failure as a function of time. For dealing with very high reliabilities, the reliability index, b, is often used as defined by: [D] An example of the change in reliability with time due to fatigue is given in Figure 1. The corresponding plot of reliability index as a function of time is given in Figure 2. The details of this example are given in reference 1. The expected or average time to failure for this example is 1265 seconds, at which time the reliability is 50% and the reliability index is zero. Also shown in Figures 1 and 2 are the times corresponding to the usual definition of quotsafe lifequot determined by using a scatter factor of 2 to 4. Using a scatter factor of 4 results in a safe life of 316 seconds, while a scatter factor of 2 gives a safe life of 632 seconds. Adoption of a reliability approach would allow specification of the safe life as the time at which the reliability or reliability index decreased below some minimum acceptable level. In this example that level was chosen to be the quot3-sigmaquot level, at which the reliability is 99.865% or the reliability index is 3.0. This results in a safe (or allowable) life of 869 seconds, a 37% increase in allowable life compared to the scatter factor of 2 life, and a 175% increase compared to the scatter factor of 4 life. The conservatism inherent in the deterministic scatter factor approach is illustrated more clearly in Figure 2. In this example a scatter factor of 2 corresponds to a reliability index of 5.6, while a scatter factor of 4 corresponds to a reliability index of 11.2. Fatigue Reliability Index as a Function of Time [D] [D] Use of a probabilistic method allows the uncertainty in fatigue life or time to failure to be more explicitly accounted for than is possible in the quotscatter factorquot approach. Sensitivity analysis methods are also available in some of the commercial software packages, allowing the uncertain input variables to be ranked according to their contribution to the uncertainty in the resulting life estimate. This enables a more timely and cost effective design optimization by identifying the most important input parameters upon which resources should be concentrated to gain the greatest increase in life. This approach naturally leads to a design risk assessment and requires the development and selection of a specific criteria for defining acceptable risk or probability of failure. The acceptable risk value should be specified in the appropriate program requirements, but the selection process is a program and policy issue which is beyond the scope of this guideline. Some guidance is available from the various national civil structural requirements codes that have been formulated to provide reliability indices of 3 to 5, depending on the importance of the structure and the consequences of failure [reference 7]. This method is primarily useful as a design evaluation or optimization tool and cannot easily be used to evaluate the remaining life of an in-service component unless instrumentation (such as strain gages, accelerometers, or load cells) is in place to allow collection of data on the actual performance of the component. In cases where the necessary in-service data is available, this method may prove very useful for extending the life of the component or structure beyond its original predicted service life. If inspection of the component or structure by a non-destructive evaluation (NDE) method is feasible, the probabilistic fracture mechanics method described in the companion guideline is more useful for estimating damage and remaining life of in-service components than the fatigue analysis method. A measured crack length provides information about the in-service state of the structure, and the probabilistic fracture analysis may be updated following the inspection to this new information. If inspection is not feasible, the fracture mechanics method has no particular advantage over the fatigue method for in-service assessments. Technical Rationale: The potential loss of strength in structural\/mechanical components due to the cumulative damage effect of fluctuating applied loads is well known. Spectacular failures have resulted from fatigue since the beginning of the industrial revolution. The danger of fatigue in new applications, however, has not always been adequately considered in the design process and continues to be a concern to this day. A classic example is the British Comet airliner, which was one of the first aircraft to employ an aluminum-skin, pressurized fuselage. The loss of three aircraft and many lives in 1953 and 1954 occurred before the potential for fatigue in this application was understood. Results from the theory of stochastic process and modern structural reliability methods enable the design engineer to assess the expected fatigue life of structural and mechanical components subject to randomly varying loads, and to estimate how the probability of failure of the component increases over time. The application of these data will enable optimal designs to be achieved which balance the initial costs of design and fabrication against the expected costs of repair, replacement, and\/or failure. References: NASA Contractor Report, Larsen, C.E., quotProbabilistic Fatigue and Fracture Mechanics Analysis for Structural\/Mechanical Reliabilityquot, To be released, 1994. Crandall, S.H., and Mark, W.D., Random Vibration in Mechanical Systems, Academic Press, New York, 1973 Miles, J.W., quotOn Statistical Fatigue Under Random Loadingquot, Journal of Aeronautical Sciences, Vol. 21, 1954, pp. 753-762 Wirsching, P.H., and Light, M.C., quotFatigue Under Wide Band Random Stressquot, Journal of the Structural Division, ASCE, Vol. 106, No. ST7, July, 1980, paper 15574, pp. 1593-1607 Lutes, L.D., and Larsen, C.E., quotImproved Spectral Method for Variable Amplitude Fatigue Predictionquot, Journal of Structural Engineering, ASCE, Vol. 116, No. 4, April, 1990, paper 24612, pp. 1149-1164 Larsen, C.E., and Lutes, L.D., quotPredicting the Fatigue Life of Offshore Structures by the Single-Moment Spectral Methodquot, Probabilistic Engineering Mechanics, Vol. 6, No. 2, June, 1991, pp. 96-108 Madsen, H.O., Krenk, S., and Lind, N.C., Methods of Structural Safety, Prentice-Hall, Englewood Cliffs, NJ, 1986 PROBAN-2: Example Manual, Report No. 89-2025, A.S Veritas Research, Hovik, Norway, August, 1989 Sutharshana, S., et al., quotProbabilistic High Cycle Fatigue Failure Analysis Applicable to Liquid Propellant Rocket Enginesquot, Proceedings of the AIAA\/ASME\/ASCE\/AHS\/ASC 31st Annual Structures, Structural Dynamics and Materials Conference, April, 1990 Reliability Preferred Practice Guideline Number GD-AP-2304: Fracture Mechanics Reliability","Lesson ID":696}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1210; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: The Earth's space environment (geospace) is uniquely comprised of dynamic and complex regions of interacting plasmas, ionized particles, magnetic fields and electrical currents. Proper grounding\/bonding of the space vehicle's shell and its electronic equipment can provide protection against lightning strikes in geospace, and also can eliminate or control most of its internal electrical and electrostatic hazards. This results in lower failure rates and significant reliability and safety enhancement of space systems and space vehicles. Implementation Method: For space vehicles all sections of the vehicle's outer shell should be bonded together to permit large quantities of electric charge to distribute across the shell by conducting paths. The bonded shell of the space vehicle then acts as an electrical shield to protect internal structures from lightning and atmospheric electricity. Ground wires should be used for individual systems when appropriate. Wires should be adequate to carry a surge without mechanical damage. NASA has established lightning protection requirements for design, and procedures to demonstrate that these requirements are implemented for the Space Shuttle program in NASA document NSTS 07636, which is a subtier to NSTS 07700, Volume X. NSTS 07636 defines the conducted current lightning environment for design, and imposes the requirements that the design must satisfy to ensure the protection of the Space Shuttle from the direct and indirect effects of lightning. A practical approach to lightning protection problems is presented in the appendices of NSTS 07636, which are: Appendix A, \"Conducted Current Lightning Environment\"; Appendix B, \"Lightning Strike Zones\"; Appendix C, \"Test Waveforms and Methods\"; Appendix D, \"Methods for Estimating the Internal Induced Voltage and Current Environment\"; Appendix E, \"Analysis Methodology\", and Appendix F, \"Lightning Bonds\". Bonding and grounding requirements are defined in MIL-B-5087B(ASG), \"Bonding, Electrical, and Lightning Protection for Aerospace Systems\". Table 1 provides typical classifications for electrical bonds from that document. TABLE 1. Electrical Bond Classes of Application1 CLASS APPLICATION MIL-B-5087B(ASG) REFERENCE PARAGRAPH A Antenna installation 3.3.1 C Current path return 3.3.2 H Shock hazard 3.3.3 L Lightning protection 3.3.4 R Rf potentials 3.3.5 S Static charge 3.3.6 1Where a single bond is used to serve two or more classes of application, the design shall conform to the most critical requirement of bonding. Class L bonding requirements are designed to achieve protection against lightning discharge current carried between the extremities of an airborne vehicle without risk of damaging flight controls or producing sparking or voltages within the vehicle in excess of 500 volts. These requirements are based upon a lightning current waveform of 200,000 amperes peak, a width of 5 to 10 microseconds at the 90% point, not less than 20 microseconds width at the 50% point, and a rate of at least 100,000 amperes per microsecond. Test requirements are described in MIL-STD-1757A, \"Lightning Qualification Test Techniques for Aerospace Vehicles and Hardware\" (The term \"aerospace vehicles\" includes fixed\/variable wing aircraft, helicopters, missles, and spacecraft.) This document presents a set of standard test waveforms and techniques for lightning qualification testing of aerospace vehicles and hardware. The test waveforms presented in this document are intended to reproduce the significant effects of the natural environment and are therefore independent of vehicle type or configuration. The tests include high voltage and high current physical damage tests of fuel, structural and electrical hardware, as well as indirect effects associated with lightning strikes to externally mounted electrical hardware. The capability to test hardware and design concepts in a lightning environment has been very limited in the past. However, there are presently test facilities that are able to generate and simulate the levels of voltage, current and charge transfers typical of lightning phenomena. Therefore full scale, full threat lightning tests that meet the requirements of MIL-STD-1757A and NSTS 07636 are now available. Technical Rationale: LIGHTNING ENVIRONMENT. The currents in a lightning flash are conveniently separated into three categories: Return stroke surges with peak currents of up to 200,000 amps or more and with durations on the order of tens of microseconds. Intermediate currents of up to 10,000 amps or more and with durations on the order of milliseconds. Continuing currents of up to 1000 amps and with durations on the order of hundreds of milliseconds. Intermediate and continuing currents are primarily responsible for damage such as hole-burning while return stroke currents mainly produce explosive effects and indirect effects. There are also currents associated with subsequent return strokes and there are phases of return strokes characterized by rapid rates of change. These categories are represented by idealized waveforms designated A,B,C,D, and H. These waveforms and their mathematical definitions are described in Appendix A of NSTS 07636E. The accumulation of electrostatic charges on the electrically isolated bodies could lead to a number of results that might affect the success of a space mission. Breakdown occurs when the electric field exceeds the dielectric strength of the medium. Charge then crosses the dielectric between oppositely-charged bodies. Heat and electromagnetic energy are emitted with the passage of the charge. Besides the electric field strength imposed on the medium, the occurrence and severity of the discharge depend on system geometry and secondary discharge effects. The gaseous medium that surrounds the components of a space vehicle is particularly vulnerable to breakdown in altitudes around 30 km. The dielectric strength of the atmosphere passes through a minimum at the reduced pressures associated with those altitudes. The various field strengths that might be present on the space vehicle can cause atmospheric breakdown. Breakdown could still be possible at much higher altitudes or even in orbit because of residual gases and outgassing materials in the space vehicle that could increase the localized gas pressure until it reached the breakdown region. Air launched spacecraft such as Pegasus must minimize tribo-electric charging even during fair weather. This is done by conductive surfaces and\/or discharge wicks. This is of particular concern when composite fairings are used. Breakdown of the gaseous medium occurs when the electric fields on the vehicle are strong enough to break apart the atoms or molecules of the medium into ions and electrons that then move according to the voltage gradient. If recombination takes place before the ions or electrons impinge on their respective electrodes, the breakdown is considered a partial one and is designated corona. If the gaseous ions impinge on both electrodes, then breakdown of the dielectric between them is complete and is referred to as arcing or an arc discharge. References: NASA, \"Space Shuttle Lightning Protection, Test and Analysis Requirements\", NSTS 07636, REV. E, Sept. 27, 1990. \"Assessment and Control of Electrostatic Charges\", Space Vehicle Design Criteria Environment, NASA SP-8111, May 1974. NASA, Guidelines for Standard Payload Assurance Requirements (SPAR) for GSFC Orbital Projects, NASA SPAR-3, March 1990. DOD-MIL-HDBK-263, Electrostatic Discharge Control (ESD) Handbook for Protection of Electrical and Electronic Parts, Assemblies and Equipment. DOD-STD-1686, Electrostatic Discharge Control (ESD) Control Program for Protection of Electrical and Electro Assemblies and Equipment. MIL-B-5087B(ASG), \"Bonding, Electrical, and Lightning Protection, for Aerospace Systems\", Amendment 3, Dec. 24, 1984. MIL-STD-1757A, \"Lightning Qualification Test Techniques for Aerospace Vehicles and Hardware\", July 20, 1983. NFPA-78, \"Lightning Protection Code of the National Fire Protection Association\", Adopted by the American National Standards Institute (ANSI) as ANSI\/NFPA-78. IEEE 4-1978, \"Standard Techniques for Dielectric Test\", Institute of Electronic Engineers (IEEE). Langley, M.E., \"Lightning Test Capabilities\", Trip Report, Wendover, NV, Thiokol Corp., Wendover Test Facility, NASA MSFC CS21(90-355), Aug. 24, 1990.","Lesson ID":654}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1215.2; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: The Hardware Review\/Certification Requirement (HR\/CR) provides a structured review process for assessing the status of flight hardware and screening for unresolved defects prior to delivery for integration. Implementation Method: After flight hardware has been designed, undergone unit level reviews, fabricated, integrated, and tested, a review board is convened to review the status of the hardware and to certify that the hardware is ready for delivery and is acceptable for mating with the spacecraft. The Project System Engineer\/Instrument Manager is selected to chair the review. Other members of the review board include the Hardware Division Representative, the Quality Assurance Engineer, the Software Assurance Engineer, The Environmental\/Reliability Engineer, and the Product Assurance Manager. The agenda and the scope of the review board is generally defined by the HR\/CR form shown as Figure 1. Using the HR\/CR form as a checklist, the design engineer responsible for the hardware being reviewed addresses the following: The hardware performance and requirements compliance status. That all requirements have been met, or that any requirements that have not been met are covered by approved waivers. That all documentation is current and complete, and includes all approved waivers and Engineering Change Requests (ECRs). That all analyses required to validate environmental requirements have been completed, documented, and approved. That all tests required to qualify the hardware have been successfully completed. That the hardware is acceptable for integration with the spacecraft. If the members of the review board or other participants have any concerns about the flight readiness of the hardware, anyone may write a Request for Action (RFA) against the hardware. These RFAs are reviewed by the Project and a response is prepared. After all RFAs are closed, the board certifies that the hardware is ready for delivery and flight by signing the HR\/CR form. Technical Rationale: A structured review following a predetermined checklist such as the HR\/CR form provides a mechanism for the responsible design engineer to review the status of the hardware and verify that the hardware is in compliance and ready for delivery and spacecraft integration. This process is enhanced by having a review board whose members have not been responsible for the design, fabrication, and testing of the hardware. Board members from the reliability engineering area and the product assurance area can focus this expertise on the completed product. Additionally, the board is able to take a fresh look at the hardware production cycle and to ask questions until they are satisfied that all necessary steps have been completed and that the hardware is acceptable for integration. Related Practices: Common Review Methods for Engineering Products, Reliability Preferred Practice No. PD-ED-1215.4. [D] Figure 1. Hardware Review \/ Certification Requirement Form","Lesson ID":656}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1215.3; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefits: The Critical Design Review (CDR) provides increased assurance that the proposed design, and the planned manufacturing and test methods and procedures, will result in an acceptable product, with minimal project risk. Implementation Method: Responsibilities The responsible project or task manager defines the need to conduct a formal review and initiates action by contacting the convening authority (generally, the next higher management level). The convening authority, in consultation with the responsible manager, appoints the review board and a chair and defines the board charter and schedule. The CDR ensures that all design considerations have been adequately incorporated and that all engineering analyses have been completed. Results of engineering model tests are presented to demonstrate that the hardware and software can be built to perform as planned. In addition, plans are presented for fabrication and testing, including qualification and acceptance. The review board, under direction of the chair, conducts the review and prepares a written report to the responsible manager on the findings and recommendations. The responsible manager then prepares a written response to the convening authority addressing the disposition of the review board findings and recommendations. The convening authority reviews and approves these dispositions. CDR Agenda The following items and issues are addressed at the CDR, where applicable: Functional description and block diagram. Functional requirements and compliance of the design, presented in matrix format with traceability references. Disposition of subassembly\/subsystem Preliminary Design Review (PDR) action items. Compliance of the design with accuracy requirements. Compliance of the design with interface requirements. Compliance of the design with mass requirements. Compliance of the design with power requirements. Compliance of the design with memory requirements. Compliance of the design with environmental requirements. Compliance of the design with project Single Point Failure (SPF) policy. Compliance of the design with maintainability requirements. Status and plans for electronic piece part acquisition. Make or buy decisions and rationale. Compliance with project requirements for inherited hardware and software. Consideration of inheritance review results. Plans for compliance with spares requirements. Status of plan for meeting quality assurance requirements, procedures, and workmanship standards. Status of plan for meeting software assurance requirements. Status or results of plan for meeting reliability analyses requirements. Status or results of plan for meeting safety analyses requirements. Status of plan for meeting documentation requirements. Status of plan for meeting support equipment requirements. Status or results of plan for meeting structural analysis requirements. Status or results of plan for meeting thermal analysis requirements. Fabrication, assembly, and test schedule and constraints. Status or results of plan for meeting calibration requirements. Plans for compliance with testability requirements. Qualification (protoflight) test requirements and implementation plans. Acceptance test requirements and plans. Manufacturing and test facility requirements, availability and acceptability. Certification status and plans. Hazardous operations facility requirements, availability and acceptability. Certification status and plans. Results of detailed peer reviews, conclusions, and implementation plans. Technical Rationale: The CDR provides for the assessment of the design and fabrication plans by a group of knowledgeable persons not directly involved in the activity being reviewed. A formal review can focus many years of experience on the subject at hand. The CDR aids the responsible manager in evaluating the quality of the work and in making important decisions, including those concerning completion of critical milestones and resolution of identified issues. The review process should aid in the identification of problems and the evaluation of design approaches and options. Related Practices: Preliminary Design Review, Reliability Preferred Practice No. PD-ED-1215.1. Subsystem Inheritance Review, Reliability Preferred Practice No. PD-ED-1262. Common Review Methods for Engineering Products, Reliability Preferred Practice No. PD-ED-1215.4 References: JPL Standard Practice Instruction (SPI) 4-16-1. Guidelines for Planning and Conducting Formal Reviews, Jet Propulsion Laboratory document JPL D-10401 (Office of Engineering and Mission Assurance). Technical Reviews and Audits for Systems, Equipment and Computer Software, MIL-STD-1521 (USAF).","Lesson ID":657}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1214; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefits: Grounding procedures used in the design and assembly of electrical and electronic systems will protect personnel and circuits from hazardous currents and damaging fault conditions. Benefits are prevention of potential damage to delicate space flight systems, subsystems and components, and protection of development, operations, and maintenance personnel. Implementation Method: System Grounding Requirements and Design Approaches: The design of electrical and electronic systems should comply with the following as a minimum: (1) a ground reference plane should be established that will hold the grounds for all systems, subsystems, equipment metallic components, surfaces, and electrical and electronic parts at the potential of the base structure; (2) within equipment, power should have dedicated returns; (3) except for a single-point reference, all electrical signal and power grounds should be electrically isolated from each other, and each separately derived electrical system should be electrically connected to structure at only one point; and (4) a dedicated power return should be used except where necessary to support system requirements. The grounding within electrical or electronic enclosures is at the discretion of the circuit designer. The following design approaches should be considered for the design of these systems: (1) within equipment, conditioned electrical power should be DC-isolated from chassis and structure except at a single point; (2) within equipment, the single-point reference should be routed external to the equipment for termination to ground, or routed directly to the chassis for termination; (3) the control power bus return should be independent of the primary electrical power return and should be referenced to the return system at a single point; (4) secondary and tertiary electrical power should be single-point grounded and should be returned to that single reference ground point; (5) when all single-point grounds are not terminated to chassis or structure, secondary and tertiary electrical power should be dc isolated by a minimum of 1 megohm; (6) power conversion performed to supply conditioned power to several devices or functions should reestablish a single-point ground reference for the serviced equipment or functions; (7) equipment should not depend on other equipment for reference or grounding, either signal or power, unless it is also dependent upon the other equipment for its power; (8) signal circuits with frequencies below 2 MHz, with interfaces external to equipment, should be balanced and isolated from chassis; (9) all returns and references should be brought out of equipment on individual connector pins; (10) shield connections should be made to connector shells or to connector pins that are, or will be, grounded when mated; (11) single-ended circuits with the lowest frequency component equal to or above 2 MHz should be coupled by coaxial cable with the shield terminated 360 degrees at each end; and (12) external to an equipment, single-ended electrical signals should be prohibited for signal frequencies below 2 MHz except where electrical isolation is maintained. [D] Schematic Examples: An example of grounding implementation concepts is shown on Figure 1. This figure reflects the stated grounding requirements and design considerations and shows two feeder, cabling and load configurations. At frequencies below 2 MHz (Figures 1 and 2), the emphasis is on circuitry requiring internal grounding with interfaces to external equipment. For frequencies equal to and above 2 MHz, the emphasis is on external connections between equipment and the proper grounding of shielding to prevent electromagnetic coupling. Single-Point\/Multiple-Point Grounding: Although the establishment of a ground reference plane requires a single-point ground, the actual practice of complying with this requirement in a system design is controversial. Modern electronic systems seldom have only one ground plane and, to reduce potential interference, as many ground planes as possible are sometimes used. From Figure 2, a grouping of ground planes connected by the shortest route back to a system ground point where they form an overall system potential reference, could be called a single-point ground system. However, problems with this scheme arise when interconnecting shielded cabling is used having significant lengths with respect to the wavelength of signal frequencies and parasitic capacitance exists between equipment housings or between subsystems and the grounds of other subsystems. It can be argued that a quotmultiple-pointquot ground system, which bonds each subsystem or equipment as directly as possible to a low impedance equipotential ground plane, can minimize these electromagnetic interference problems. An example of such a system is shown in Figure 3 where each subsystem is connected directly to a common ground plane, ideally a flat, equipotential plate. In practice, the selection of a grounding scheme is dependent on the highest significant operating frequency of low-level circuits relative to the physical separation of the equipment. As shown in Figure 4, single-point grounding works best at low frequencies and small dimensions and multiple-point grounding works best at high frequencies and large dimensions. For transitional situations, one or the other may perform better as shown in Figure 4. For this crossover region, hybrid grounds perform best when portions of the low-frequency systems use single-point grounds and the high-frequency portions use multiple-point grounds. Shock Prevention: Proper grounding protects personnel from accidental contact with metallic elements that may have hazardous voltage potentials due to system faults or accidental contact between energized elements and equipment chassis, frame or cabinet structure. Case voltage rise is limited to reduce currents to levels that do not produce adverse reactions and possible secondary effects. Typically, case voltage rise is limited to prevent hazardous currents. Table 1 summarizes the alternating and direct currents and their shock effects. Table 1. Summary Effects of Electrical Shock Alternating Current (60Hz) Direct Current (DC) Reaction (mA) 0.5-1 1-3 3-21 21-40 40-100 > 100 (mA) 0-4 4-15 15-80 80-160 160-300 > 300 Perception Surprise Reflex action Muscular inhibition Respiratory block Usually fatal Bonding: The integrity of interconnected conductive elements is ensured by electrical bonding, a process in which components or modules are electrically connected to provide a low-impedance conductor. Bonding practices should comply with MIL-STD-5087B or with SSP 30245. Bonding procedures require the use of specified clamps, standard parts, bolt and screw attachments, washers and materials to ensure consistent bonding of equipment under various temperatures and corrosion environments. The use of jumper cables is discouraged except across movable vibration or thermal isolation joints. Surface preparation for bonded joints should begin by removing all anodic film, grease, paint, lacquer, or other high-resistance properties from the faying surfaces. A typical bonding hardware configuration is shown in Figure 5. The use of scrapers, abrasives or chemical cleaning methods to provide a clean, smooth bonding surface is dependent on the type of joint (i.e., metal-to-metal, metal-to-nonmetal or nonmetal-to-nonmetal). Example bonding impedances for selected bonding classes are shown in Table 2. [D] [D] Table 2. Example Bonding Impedances and Bonding Class Bonding Class Impedance A (Antenna installation) H (Shock hazard) R (RF potentials) S (Static charge) DC resistance < 2.5 milliohms DC resistance < 100 milliohms DC resistance < 2.5 milliohms Impedance < 100 milliohms up to 1 MHz <1 ohm (conductive structure) < 1000 ohms (composites) < 1000 ohms (conductive subassemblies) 1 ohm (pipe and hose) [D] Cabling\/Connector Grounding: Cabling extending outside grounded enclosures is vulnerable to radiated emissions if cable lengths are a significant portion of the wavelength of the systemi\u0301s highest operating frequencies. Adequate shielding and grounding are required to ensure proper system operation. Figure 6 shows typical grounding practices for shielded cabling and connectors. Shield terminations at connectors are gripped by the connector back shell to provide a low impedance 360 degree connection. Soldered connections are not recommended due to the difficulty in repair and wiring changes, and the use of foil in some cable shielding. Where cabling enters enclosures, the box connector or partition penetration in Figure 6 may be used. For cabling where the overall shield ends in a terminal strip, the termination may look like the configuration shown in Figure 7. [D] [D] [D] Technical Rationale: Through many years of designing and fabricating electrical circuits and electronic devices for launch vehicles, experiments and payloads, the Marshall Space Flight Center has developed procedures and techniques for designing reliable and safe aerospace electronic systems. Design criteria were built upon a solid foundation of industry and government practices. Military standards were used at the outset, and procedures unique to the space program were added as refinements. Practical experience reflected in the standard procedures and techniques resulted in reliable circuits that presented minimum hazard to personnel and equipment. Related Practices: Reliability Preferred Practice No. PD-ED-1202, quotHigh Voltage Power Supply Design and Manufacturing Practices,quot Lewis Research Center. Reliability Preferred Practice No. PD-ED-1210, quotAssessment and Control of Electrical Charges,quot Goddard Space Flight Center. Reliability Preferred Practice No. PD-ED-1206, quotPower Line Filters,quot Goddard Space Flight Center. References: SSP 30240 Revision A, quotSpace Station Grounding Requirements,quot September 1991. MSFC-SPEC-521B, quotElectromagnetic Compatibility Requirements on Payload Equipment and Systems,quot August 15, 1990. MIL-STD-461C, quotElectromagnetic Emission and Susceptibility,quot August 1986. MIL-STD-462, quotElectromagnetic Interference Characteristics,quot July 1967. MIL-STD-463A, quotDefinitions and System of Units, Electromagnetic Compatibility Technology Interference,quot June 1966. MIL-STD-5087B, quotBonding, Electrical and Lightning Protection for Aerospace Systems,quot Amendment 3, December 24, 1984. Denny, Hugh W., quotGrounding for the Control of EMI,quot 1983. White, Donald R.J., quotElectromagnetic Interference and Compatibility,quot Vol.3, quotA Handbook on EMI Control Methods and Techniques,quot 1973. SSP 30242 quotSpace Station Cable\/Wire Design and Control Requirements for Electromagnetic Compatibility, quotSeptember 1991. SSP 30245 quotSpace Station Electrical Bonding Requirements,quot September 1991.","Lesson ID":658}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number GSE-3006 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: The test methods described herein specify conditions obtainable in the laboratory that will give test results similar to actual service conditions. Implementation Method: Design and Testing Considerations. The basic purpose of this practice is to provide a guide to uniform testing of Ground Support Equipment (GSE) and other facility components to assess the ability of the hardware to withstand the environmental stresses it will encounter during its life cycle and to ensure that plans and test results are adequately documented. Tests should be conducted to the maximum extent practicable to ensure operational suitability of the item for the anticipated environmental conditions to be encountered during its required usage. Consideration should be given to natural and induced environments and to combinations and sequences of stresses. The environmental conditions to which GSE is exposed in the KSC area vary considerably by virtue of its location on the center. The environmental conditions of computer equipment installed in an air-conditioned, sound-absorbent room on vibration-isolated floors is negligible compared to the severe conditions a holddown system experiences; i.e., the daily natural environments and the blast of the launch vehicle during lift-off. Designing or testing all equipment to the most severe of these conditions is impractical and expensive. Design and testing should be accomplished with both the actual environmental and reliability requirements in mind. KSC-STD-164 may be used as a guide to define test conditions. Testing Procedures. Test Requirements. - The anticipated environmental conditions should be carefully considered before determining which tests are to be conducted. Generally, only those conditions that reflect launch and prelaunch usage of the test item should be considered. Where possible, data should be obtained on actual operating and field environments to which the GSE will be exposed to aid in the test selection process. When considering the applicable environmental conditions, combined environmental testing should also be considered as a means for more closely simulating service conditions, and in fact, may be the only method of attaining valid test results. Test Sequence. - Those tests that require the successful operation of the test item during exposure to the environment should normally be conducted first, and those tests where the test item remains static throughout the environment should be conducted last. In either case, the test should be conducted in the order of the likely severity on the item; the least severe being conducted first. Unless otherwise stated in the test requirements, the following sequence is recommended; Electromagnetic interference Low temperature High temperature Temperature shock Acoustics Vibration Shock Humidity Rain Icing Solar radiation Fungus Salt fog Sand and dust Explosion Lift-off blast Receiving Inspection. - Prior to conducting any tests, the test item should be subjected to a receiving inspection. This inspection should be made to determine conformance with applicable drawings and specifications to the extent possible without disassembly of the test item. When quality acceptance tests are specified, they should be conducted as part of the receiving inspection. Functional Test. - The functional test is the means by which it can be determined whether or not the environmental tests are adversely affecting the performance capabilities of the test item. Because the functional test is required to monitor the very \"pulse\" of the test item, it is obvious that it must be comprehensive enough to include all possible aspects which could affect the operation of the item. The determination of what checks to make as part of the functional test requires a good understanding of the operation and application of the test item and its possible failure modes. Prior to conducting a functional test, the functional parameters to be monitored should be specified and should include allowable limits on permissible degradation. Installation in Environment Facilities. - The test item should be installed in the test facility at ambient conditions in a manner that will simulate service usage. Install instrumentation in, on, or around the item as required by the test. Plugs, covers, and inspection plates used in service should remain in place. When mechanical or electrical connections are not used, the connections normally protected in service should be adequately covered in the same manner as service usage. The test item should then be functionally tested to determine that no malfunction or damage was caused due to faulty installation or handling. The requirement to conduct a functional test following installation is applicable only when a functional test is required during exposure to the specified environments. Frequency. - Functional tests should be conducted at least three times before and after each test environment. If the functional test performed after an environmental test is satisfactory, the test item should be qualified for the succeeding environment without further testing, provided (1) the succeeding test is started within 72 hours after the previous functional test and (2) installation changes are not required. When a test environment simulates conditions under which the test item would be required to operate during service, the item should be functionally tested at least three times during the test environment. Characteristic Tests. - Tests to establish the basic design characteristic of the item are also required. These tests should not be confused with the functional-type test which is repeated throughout the test program. Characteristic tests are conducted once, generally prior to the environmental tests, unless they are destructive in nature. Examples of characteristic tests for pneumatic components may include proof test, flow test, surge test, and the burst test which is destructive. For electrical components, characteristic tests may include voltage drop test, ampere test, resistance test, and repeatability test. Life Cycle Reliability Testing. - Testing is conducted to provide statistical data for determining the reliability of the test item with a reasonable degree of confidence. Failures that would occur \"once-in-a-thousand\" are looked for in the life-cycle test. After exposure to all the environments the item would normally be exposed to during use with no deterioration of operation found, the life-cycle test can provide a valid method for determining reliability. Failures that occur due to wearing out of parts beyond service life expectancy must not be considered a design failure, but may be considered for establishing maintenance time periods. The number of life cycles to be conducted should be established by the testing agency. Documentation. - The environmental tests required for a particular hardware item should be documented in a test plan or test requirements document. Inspections, data requirements, test tolerances, functional tests, and installation requirements should be indicated along with any deviations from the standard tests established herein. KSC-DF-107 may be used as a guide in preparing the plan. The testing agency should develop a detailed test procedure based upon the test requirements specified in the test plan. Test results should be documented, approved, and published in accordance with KSC-STD-128. Test Methods. Electromagnetic Interference. - The electromagnetic interference test is performed to determine if the electronic or electrical equipment under test will exhibit malfunction or degradation in performance when subjected to undesired external signals. Electrical and electronic equipment includes components that are susceptible to malfunction from external electromagnetic interference. Such interference can change the calculations of a computer, alter the sequence of planned commands of computer programs, and cause recorders to erroneously indicate that a function occured, failed, or even altered the time of the recording function. Components, such as solenoid valves, power contacts, and signal relays that are not susceptible to malfunction from external electrical interference, generate transient pulses when deenergized. These impulses may exceed the normal operating voltage ratings of much associated connecting circuitry as well as transmit electromagnetic interference to external electronic circuits. Low Temperature. - The low temperature test is performed to determine the operational performance of the item at low temperatures which might be encountered during its life cycle. The test item should be functionally tested during exposure to ascertain whether or not the environment causes degradation of performance. Some of the difficulties which may result from low temperature exposure are binding due to differential contraction of parts, loss of resiliency of gaskets, and congealing of lubricants. Testing to this environment is applicable to components not installed in a temperature controlled environment. High Temperature. - The high temperature test is performed to determine the operational performance of the item at high temperatures that might be encountered during its life cycle. The test item should be functionally tested during exposure to ascertain whether or not the environment causes degradation of performance. High temperature conditions may cause permanent setting of packings and gaskets, binding of parts due to differential expansion, and cracking or bulging of rubber and plastic. This test is applicable to components that are not installed in a temperature controlled environment. Temperature Shock. - The temperature shock test is performed to determine the effect of an anticipated sudden change in temperature on the operational performance of an item. Cracking or rupturing of materials (particularly valve seats) due to changes in material characteristics and dimensions is the principal difficulty to be anticipated. A thermal shock is experienced when (1) gases expand upstream or immediately downstream of a pneumatic component, (2) hydraulic fluid is forced through restrictions at high flow, and (3) when cryogenic fluids are used in items that are not gradually chilled down. Acoustics. - The acoustic test is performed to determine the effects on performance that acoustics will have on GSE and other facility hardware located at or near the launch pad at the time of launch vehicle holddown and lift-off. In an acoustic noise field, pressure fluctuations impinge directly on the equipment providing a distributed type of dynamic load. Broadband spectra of these loads contain resonance frequencies of most, if not all, structural components of equipment. The resulting resonant vibration is generally different from that which occurs when excitation is applied only at discrete points. Further, components that are effectively isolated from a mechanical transmission of vibration from the supporting structure will be excited directly. Electronic chatter at friction-held contacts, chafing of wires, cracking and collisions of printed circuit boards, and malfunction\/failure of waveguides and Klystron tubes are examples of acoustically induced problems. Acoustic! test specifications provide guidance for the performance of acoustic tests on GSE or other facility hardware. Acoustic tests are subject to restraints imposed by the capabilities of existing test facilities. Vibration. - Vibration test specifications provide guidance for the performance of vibration tests on GSE or other facility hardware used to support the launch of a space vehicle. These specifications apply to a vibration environment occurring during a launch for the purpose of providing criteria for acceptance and qualification of GSE. The extent of concern is limited to equipment located on and in the proximity of the launch pad, generally within a 300-meter (1000-foot) radius of the launch pad. Shock. - The launch of a space vehicle generates pressure acoustic environments that do not contain shocks. A pressure pulse generated by some engines at the time of ignition does not induce as a response a distinct vibration shock, rather it results in a transient vibration with peak amplitudes that are substantially lower than the peak vibration during a lift-off period. True vibration shocks occurring during a launch are true anomalies caused by collisions between structural elements and by bottoming of vibration isolators. High shocks can be generated by a hard bottoming of vibration isolators that do not have snubbers and that involve metal-on-metal impacts. Whenever possible, the cause of shocks should be corrected rather than trying to qualify equipment for an operation in the shock environment by testing. Exceptional shock occurrences covered by these specifications are those that cannot be corrected by a structure\/isolator redesign or by moving equipment to another location free from shocks. Because there are exceptions, test specifications, testing procedures, and tolerances should be handled on a case-by-case basis. Humidity. - The humidity test is performed to determine the resistance of equipment to the effects of exposure to a warm, highly humid atmosphere such as that encountered in the KSC area. This is an accelerated environmental test, accomplished by the continuous exposure of the equipment to high relative humidity at an elevated temperature. These conditions create a vapor pressure, which is the force behind moisture migration and penetration. Corrosion is one of the principal effects of humidity. Hygroscopic materials are sensitive to moisture and deteriorate rapidly under humid conditions. Many materials lose their functional utility and physical strength and change their important mechanical properties. Insulating materials that absorb moisture may lose their insulating properties. Rain. - The rain test determines the resistance of GSE to the effects of exposure to rainfall rates that are encountered in the KSC area. The rain test determines the capability of equipment or component seals to resist water intrusion and determines the efficiency of protective covers or cases designed to shield the item from rain. Icing. - The icing test is conducted on GSE that is susceptible to the formation of ice on its external surface. This formation can occur during the normal operation of cryogenic systems and during the normal operation of pneumatic systems that require high flow rates and large pressure drops across individual components. Ice will also form on component surfaces that are physically located within the thermal gradient of these systems. For this reason, when selecting components for this test, the moisture and temperature conditions must be considered in relation to the proximity of the component to the system. Each component subjected to this test must be selected judiciously and its physical location must be adequately defined. Damage that can be expected from the accumulation of ice is mechanical binding or sticking, short circuiting of the electrical wiring, and sealing of the vent ports. Solar Radiation (Sunshine). - The solar radiation test is performed to determine the effect of solar radiant energy on equipment. Solar radiant energy causes heating of equipment, photo degradation (such as fading of fabric colors), and cracking of paints, natural rubber, and plastics. The solar radiation test is applicable to any item of equipment that may be exposed to solar radiation during service and that is constructed of materials that may be adversely affected by this environment. Fungus. - The fungus test is performed to determine the susceptibility of GSE to fungus attack and to ascertain the detrimental effects that are incurred when such equipment is subjected to the test environmental condition. During the normal growth of fungi, there is an enzymatic secretion that accelerates a chemical transformation of organic substances. Once attacked, most organic materials will be destroyed by the fungi. Many minerals are also destroyed by these spores. Fungi affect insulation, wood and wood derivatives (paper), some types of seals, lens coatings, as well as many other types of materials. This is an accelerated environmental test; therefore, the temperature and moisture condition are specified to support rapid growth of fungi and accelerated deterioration of materials. Salt Fog. - The salt fog test is performed to determine the resistance of equipment to the effects of a salt atmosphere. The expected damage from exposure to salt fog is primarily corrosion of metals, although in some instances salt deposits may result in clogging or binding of moving parts. This is an accelerated environmental test; therefore the specified concentration of moisture and salt is greater than that found in normal service. Sand and Dust. - The sand and dust test is performed to determine the resistance of equipment to blowing fine sand and dust particles. Because of their abrasive character, sand and dust can affect items into which sand may enter. Sand and dust can also cause parts to bind and can interfere with electrical contacts. Due to the high sand concentrations of the soils at KSC, dust will not be part of this test. The sand and dust test is applicable to those items that are exposed to wind-blown sand conditions common in the KSC area. This is an accelerated accelerated environmental test; therefore the conditions are more severe than those found in normal service. Explosion. - The explosion test is conducted to determine the explosion-producing or explosion-containment characteristics of hardware when operated in a hazardous location. Explosions may be initiated by mechanical or electrical sparking, flashes, temperature, or chemical reactions. Hardware can be placed into one of two categories: (1) intrinsically safe or (2) explosionproof. GSE and other facility hardware located near propellant storage or fueling areas may be considered in a hazardous location due to the possible exposure to high-atmospheric concentrations of hydrogen and hypergol propellants. Dust ignition requirements are not considered to be applicable to GSE or other facility hardware; therefore, dust ignition will not be part of explosion testing. Lift-Off Blast. - The lift-off blast test is performed to determine the effects of rocket engine exhaust on GSE and other facility hardware at the time of launch vehicle holddown and lift-off. The detrimental effects of a blast are due to extremely high temperatures and pressure and the erosion characteristics of the rocket engine exhaust plume. The extent of damage depends on the exposure time, velocity of exhaust gases, type of propellants, and most importantly, the location of the item in relation to the rocket engine exhaust. Blast conditions may cause erosion of hardware surfaces, loss of protective coatings, permanent set or binding of parts, cracking or bulging of rubber and plastic due to high temperatures, and bent or deformed material due to the pressure load. The lift-off blast test should only be performed on those hardware items that cannot be shielded or protected from the lift-off environment. Technical Rationale: The environmental conditions to which equipment is exposed varies considerably by virtue of its location. Designing or testing all equipment to the most severe of these conditions is impractical and expensive. To ensure that reliability goals are met, design and testing must be accomplished with both the actual environmental and reliability requirements in mind. References: KSC-STD-164 Environmental Test Methods for Ground Support Equipment. MIL-STD-810 Environmental Test Methods and Engineering Guidelines. KSC-STD-128 Preparation of Test Reports. KSC-DF-107 DE Technical Documentation Style Guide. KSC-DE-512-SM Guide for Design Engineering of Ground Support Equipment and Facilities for Use at Kennedy Space Center. KSC-STD-G-0003 Qualification of Launch Support and Facility Components.","Lesson ID":651}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1213; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: High performance shielding on wiring harnesses, cables and wires minimizes radiated emissions from hardware that could be picked up by itself or other hardware and interfere with proper operation. Shielding also minimizes the sensitivity of hardware to radiated emissions, from itself or other hardware, that could interfere with proper operation. Implementation Method: Cable shielding that can provide 60 dB or more of shielding effectiveness is used to meet the radiated emission and the radiated susceptibility requirements of GSFC's General Environmental Verification Specification for STS & ELV Payloads, Subsystems, and Components (GEVS-SE). This document contains a baseline for demonstrating by test the satisfactory performance of hardware in the expected mission environments. Connector types should be selected that provide 60 dB or more of shielding, and provide an appropriate method for attaching cable shields and maintaining a low impedance path to chassis or structure ground. Soldering shields to the back of connectors is not a good practice since many cables use both an aluminum foil shield and a braid shield. Also, soldered connections make repairs and wiring changes very difficult. Good practice is to use a solid back shell that tightly grips the shield all the way around and provides complete 360 degree shielding. Cable shields should not be attached to connector pins and grounded on the inside equipment chassis or boxes since this enables shields to conduct outside emissions into the box, and inside emission to the outside, and can cause radiated emission problems. Chassis or box mounted connectors should have a conductive gasket between the mounting surface of the connector and the chassis or box in order to provide an EMI tight seal. The mating surfaces of the connector and the chassis or box should be clean and highly conductive. Technical Rationale: The practice provides a basis for the selection of cable shields and connector types that enable equipments to comply with the References 1 and 2 EMC requirements. Additionally, the proper selection of cable shielding and connector types significantly reduces the possibility of electromagnetic compatibility problems. Related Practices: Power Line Filters - Practice No. PD-ED-1206. EMC Guidelines for Payloads, Subsystems and Components - Guideline No. GT-TE-2401. References: General Environmental Verification Specification For STS & ELV Payloads, Subsystems, And Components (GEVS-SE). Shuttle Orbiter\/Cargo Standard Interfaces Document (JSC 07700 Volume XIV Attachment 1 (ICD 2-19001).","Lesson ID":653}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1211; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: The probability of structural failure during launch and landing is significantly reduced. Implementation Method: Loads due to various sources (steady-state acceleration, transient dynamic, vibro-acoustic) may be computed separately. Then use one of the combination methods listed below to derive the combined load. For acoustically sensitive components, direct acoustic load should be included as well. Technical Rationale: Vibration which causes structural loads can be classified as follows (see Table 1): Vibration due to transient events (liftoff, staging, etc.), typically below 60 Hz, including steady-state acceleration; Random vibration transmitted through mechanical interfaces, typically from 20 to 2000 Hz; Random vibration caused by direct acoustic loading on the surface of the structure, typically from 50 to 10,000 Hz. For primary structure, the steady-state and transient loads typically dominate the vibro-acoustic loads, and the latter are often ignored in practice. For secondary structure, however, the vibro-acoustic loads can be comparable to, or larger than, the steady-state and transient loads. Acoustically sensitive components may have loads which are dominated by their response to direct acoustic excitation. Because the transient and vibro-acoustic loads can be of comparable magnitude, and both are present simultaneously at liftoff, it can be unconservative to design the structure to the transient and vibro-acoustic loads separately. A number of methods are available for assessing the combined load. The following methods are considered acceptable. Method 1: Coupled Transient Analysis with Base Drive Random Depending on the launch vehicle, coupled transient analysis predicts structural loads up to 60 Hz, although in most cases the frequency cutoff is much lower (35 Hz for STS liftoff). Forcing functions for these analyses are adjusted, based on flight data, to assure that the loads envelop the actual flight loads (including transient and mechanically transmitted random vibrations within the frequency range of analysis). Above the cutoff frequency of the coupled transient analysis, mechanically transmitted random vibration loads may be computed using base drive random analysis of the payload structure. The base vibration is specified in terms of power spectral densities of the acceleration in each direction. If possible, the analysis should be performed using input accelerations corresponding to the time of peak transient loads, rather than the maximum random vibration over the entire flight. Accelerations in different directions should be considered uncorrelated, and may be applied simultaneously or one direction at a time. A higher level of damping is acceptable for the random analysis than for the coupled transient. Common practice is to use 3 times the RMS (3 sigma) as the peak load prediction. Peak loads from the coupled transient and base drive random analyses may be combined by a root-sum-square (RSS) approach. When direct acoustic loading on the payload structure is non-negligible, it may be combined with the above load using an RSS approach. Methods for predicting acoustic loading include finite-element based approaches, which are limited to low frequency predictions, and statistical energy methods, which are limited to higher frequency predictions. Method 2: Mass Acceleration Curve A typical mass acceleration curve (MAC) is shown in Figure 1. The MAC is an upper bound acceleration level for all components of a given mass, regardless of location, orientation, or frequency. Applicability is limited to appendage masses up to 500 kg, with frequencies up to approximately 100 Hz. Such a curve can be derived based on analytical and flight data, and includes the effects of both transient and mechanically transmitted random vibration. That is, the load predicted by the curve is already a combination of transient and random vibration. When direct acoustic loading is non-negligible, it may be combined with the MAC load using an RSS approach. Method 3: Coupled Transient Analysis with Modal MAC It is generally accepted that base drive random analysis can be very conservative, because it does not account for impedance effects. These effects can be very significant for the payload modes with large effective mass. An approach which accounts for impedance in an approximate way is based on application of the MAC to the modes of the payload structure. Each mode of the payload may be assigned an acceleration level based on its effective mass. The acceleration level is taken from a curve similar to Figure 1, but the modal MAC is typically lower in level than the MAC which applies to physical appendage masses. Physical loads corresponding to each mode are then derived by scaling the mode shape according to this level. The combined load is obtained as the RSS of the transient load with the modal loads above the transient cutoff frequency. It can be seen that this method is the same as Method 1, except that the base drive random approach is replaced by an RSS of modal loads scaled to the modal MAC. As in the previous two methods, when direct acoustic loading is non-negligible, it should be computed by an appropriate acoustic analysis method, and combined with the transient and random load using the RSS approach. Table 1. Sources of Structural Loads Type of vibration Frequencies (Hz) Types of Analysis From To Steady-state: Transient Vibration 0 60 Coupled transient MAC Mechanically transmitted random 20 2,000 Base drive random Modal MAC Direct acoustic 50 10,000 Finite element (low frequency) Statistical engergy (high frequency) [D]","Lesson ID":652}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number GSE-3004 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Adherence to a design review checklist ensures that reliability and maintainability (R&M) issues, including those requirements necessary to meet the R&M specifications, are considered early in the design phase of a project when the cost is minimal for making changes. This will provide the highest reliability for the minimum cost. Implementation Method: The technical checklist is prepared by Reliability and Maintainability Engineering to ensure that all R&M considerations and issues have been taken into account during the design phase of GSE. The checklist is formatted for ease of use by all engineering disciplines involved. A question format can be used to ensure that critical factors are not overlooked. The following is a list of some of the issues to be considered during a design review: Preliminary Design Review Identification of critical equipment Program plans Preliminary test plans Progress of the design Reliability allocations and predictions Redundancy requirements Maintenance concept: Repair level Stock provisions Built-in-test features Predictions Intermediate Design Reviews Reliability analyses: Allocations Predictions FMECA, FMEA Failure data Growth test data Production assurance data Vendor data Critical Design Review Subsystem and component specifications Test plans and procedures Critical component identification and evaluations Final design configuration Reliability analyses: Predictions Stress Analysis FMECA, FMEA Worst Case Analysis Test results; Environmental and Operational At KSC, LSOC R&M Engineering has developed a checklist to cover reliability, maintainability, safety and quality assurance issues for Space Shuttle GSE development. This checklist is used during the design phase of the GSE projects. R&M concerns and requirements for the Shuttle program are addressed in the checklist and brought to the attention of design and project engineering. Technical Rationale: The checklists have resulted from operational experience with the Shuttle Program. The document which incorporates the checklist also includes a cross reference which relates items on the Reliability and Maintainability Checklists to Shuttle Program requirements. The table of contents of the document has been included with this practice. A sample is also included of some of the items from the Reliability, Quality, Maintainability and Safety Checklists. There are in excess of 60 pages of checklist items which actually comprise the Checklists for Reliability, Quality, Maintainability, and Safety. The format and the topics addressed in the checklist will also work for other applications and the checklist is designed to be tailored to meet the specific needs of the individual programs. The complete checklist is contained in reference 2. PROCEDURE FOR PERFORMING SPC DESIGN REVIEWS, S&R-P-003 TABLE OF CONTENTS (Reference Only) INTRODUCTION 1.0 PROGRAM REQUIREMENTS 2.0 GROUND SUPPORT EQUIPMENT DESIGN REQUIREMENTS 3.0 REFERENCE DOCUMENTS 4.0 RELIABILITY & QUALITY ASSURANCE DESIGN REQUIREMENTS 4.1 GENERAL 4.2 DESIGN FOR RELIABILITY 4.3 BASIC RELIABILITY DESIGN PRINCIPLES 4.3.1 Design Simplicity 4.3.2 Redundancy 4.3.3 Derating 4.3.4 Environmental Design 4.3.5 Self-Healing Items 4.3.6 Parts Selection and Control 4.4 RELIABILITY & QUALITY ASSURANCE DESIGN REVIEW CHECKLIST 5.0 MAINTAINABILITY DESIGN CHARACTERISTICS 5.1 GENERAL 5.2 MAINTAINABILITY DESIGN GUIDELINES 5.2.1 Electrical\/Electronic Equipment Design 5.2.1.1 Cables and Connectors 5.2.1.2 Miniaturization And Modular Design 5.2.2 Mechanical Equipment Design 5.2.3 Fluid Equipment Design 5.2.4 Interchangeability 5.3 MAINTAINABILITY DESIGN REVIEW CHECKLIST 6.0 SAFETY DESIGN REVIEW CHECKLISTS 6.1 GENERAL 6.2 SAFETY DESIGN GUIDELINES 6.3 DESIGN SAFETY CHECKLIST TABLES Table 1 Shuttle Program RM&QA Requirements for Ground System Design Table 2 Shuttle Program RM&QA Technical Requirements and Criteria for GSE Design Table 3 Reliability Design Review Checklist Table 4 Quality Assurance Design Review Checklist Table 5 Maintainability Design Review Checklist Table 6 Generic Hazard Checklist Table 7 Design Safety Checklist [D] [D] [D] [D] References: Reliability Engineering for Electronic Design, Norman F. Fuqua, Marcel Dekker, Inc. 1987, pp. 365-366. Lockheed Space Operations Company, Procedure for Performing SPC Design Reviews, S&R-P-003.","Lesson ID":648}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-EC-1105 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefits: Shielding thickness can be realistically assessed by considering the cumulative probability of component failure due to radiation of solar particles. Implementation Method: JPL computer codes (ref. 2 & 3), simulate the transport of ion fluxes determined from the particle models through specified shielding thicknesses of aluminum to obtain resultant spectra. These spectra are used to calculate device single event effect rates when applied to the laboratory measured cross sections. For low linear energy transfer (LET) threshold devices, proton upset cross sections vs. energy are used to determine upset rates from the proton energy spectra. For higher LET threshold devices the measured upset cross section vs. LET is used with the Heinrich flux for heavy ions to determine single event effect rates. Technical Rationale: Penetrating ions create ionization tracks in silicon components. The heavier ions produce denser ionization tracks. Disposition of the created charge, which depends on the electric field configuration within the device, can lead to the following effects: Recombination without single event effects, Single event upsets, Device latch up, and Spurious signals. Measurements of proton solar event fluences and alpha particle solar event fluences have been obtained for many solar flares. Organizing these data in a statistical manner according to cumulative probability of occurrence for a specified particle event fluence level constitutes the proton and alpha particle models. Solar flare heavy ion data are more difficult to obtain because the lower flux levels and the need for mass discrimination requires more sophisticated instrumentation. The paucity of available data creates the need for a heavy ion model based on solar abundance's. A solar heavy ion model (ref. 4) has been constructed based on the work of Breneman and Stone (ref. 5) who analyzed heavy ion data from 10 solar flares between 1977 and 1982. It has been assumed that the average alpha fluence is predictable from the heavy ion model relative to the other ion species. However, the proton fluence is not predictable from the heavy ion model. The heavy ions are normalized to the alpha particle probability of occurrence fluence levels by requiring that the integrated alpha fluence level from the heavy ion model match the fluence level from the measured alpha statistical distribution model. Complete ion flux spectra are specified in this manner. These spectra can be introduced into transport software to determine shielding requirements and software to determine single event effect rates. Related Practices: Environmental Factors, Practice No. PD-EC-1101 References: SSP 30425 (SSP Natural Environment Definition), Chapter 6. Feynman, J., Spitale, G., Wang, J., Interplanetary Proton Fluence Model: JPL 1991, Jet Propulsion Laboratory IOM 5217-92-23, February 6, 1992. Spitale, G., Feynman, J., Wang, J., Solar Alpha Particle Model: Progress and Problems, Jet Propulsion Laboratory IOM 5217-92-60, March 5, 1992. Croley, D.R., Solar Flare Heavy Ion Model, IEEE Transactions on Nuclear Science, June 22, 1992. Breneman, H., Stone, E. (1985). Solar and Photospheric Abundance from Solar Energetic Particle Measurements, Astrophysical Journal, 299, L57-L61. Adams, et. al., (1981). Cosmic Ray Effects on Microelectronics, Part I: The Near-Earth Particle Environment. NRL Memorandum Report 4506, Naval Research Laboratory, Washington, D.C.","Lesson ID":647}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-EC-1110 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefits: This practice ensures the performance reliability of optical fiber cable assemblies by requiring the selection of optical fiber cable components that have been tested and approved for spaceflight use and by specifying approved assembly and acceptance inspection and test procedures. Implementation: The termination of optical fiber cables used in spaceflight applications is performed in accordance with the GSFC approved training document, Ref. 1, which defines approved material requirements and detailed assembly techniques and procedures. Ref. 1 is used by engineers, senior technicians and those involved in training personnel in the techniques of terminating optical fiber cable. The procedures defined in the Ref. 1 training document are applicable to the following items from the MIL-STD-975 NASA Standard Electrical, Electronic, and Electromechanical Parts List, (NSPL), and the GSFC Preferred Parts List-20, (PPL-20): MIL-T-29504\/4&5 Type II adhesive Optical fiber termini manufactured by Amphenol\/Bendix and used in MIL-C-38999 Series III connectors OC-1008 optical fiber cables manufactured by Brand-Rex This procedure may not be applicable to other types of optical fiber cable and termini which may require different stripping techniques, polishing steps, tools, materials, and assembly instructions, all of which must be documented and controlled when spaceflight hardware is assembled. Personnel are cautioned about the use of parts from manufacturers not specified in the procedure as the use of those parts could result in unreliable cables. Other manufacturer's parts may be used, however, provided they are tested at GSFC, meet GSFC performance requirements, and are interchangeable with approved parts as determined by GSFC. Ref. 1 provides lists of approved materials required by the procedure including part numbers, manufacturer\/source, and specifications. Also included is a list of equipment required by the procedure including model\/part number and manufacturer or source. The assembly of an optical terminus onto an optical fiber cable is performed in the following four steps: Step 1- Equipment Parts, Preparation and Pre-cleaning This step ensures that all tools, materials, and equipment are checked against required part numbers, labeled, calibrated, and cleaned as required. The cleanliness of all parts which come in contact with the adhesive is critical to a reliable bond and end product. All parts which come in contact with the adhesive, including all dispenser parts and mixing pans, as well as the fiber and connector to be bonded, must be thoroughly cleaned with appropriate solvents before bonding. Note that some dispensers used for medical applications are internally coated with silicone for ease of dispensing. Silicone can mix with the adhesive and produce an unreliable bond. After cleaning is performed, care must be taken not to re-contaminate cleaned items by inadvertent contact with dirty surfaces. Also, equipment and setup information, tool part numbers, material lot numbers and other data are recorded in the certification logs in order to provide traceability in the event of problems. Step 2- Optical Fiber Cable Preparation and Stripping The optical fiber outer jacket, strength member, inner jacket, and fiber coating components are prepared for the bonding process by stripping and cleaning and are inspected for correct stripping dimensions before bonding. Cracks, nicks, cuts, excessive chemical strip wicking, or other potential damage to cable components including the fiber and the strength member are inspected after stripping and prior to bonding in accordance with an in-process inspection criteria. Required data including acceptance inspection is recorded in the certification log. Chemical stripping is used to remove the acrylate fiber coating since the fiber can be nicked inadvertently even by trained operators when mechanical stripping is used. Nicks in the fiber are very difficult to detect, and an undetected nick could result in a latent defect which may not become apparent for a considerable length of time. Chemical stripping solutions as well as other chemicals or materials may be limited life items (i.e., their potency may be reduced over time) and are marked, controlled, and handled to ensure that expired chemicals are not used for assembly of spaceflight hardware. Step 3- Terminus To Cable Bonding The optical fiber cable is bonded to the terminus and the excess glass fiber is cleaved in preparation for terminus polishing. Care is exercised to ensure that the temperature-controlled ovens are stabilized at the required temperatures, the stripped cable ends are clean, and that the epoxy does not spill out onto any parts of the terminus except the rear barrel. Cleanliness is critical to a reliable bond and end product. Mixed adhesive systems are degassed (i.e., by use of a centrifuge) before they are applied to optical fibers and connectors to minimize the potential for fiber breakage due to bubbles or voids in the adhesive surrounding the fiber. The proper weighting, mixing, and curing of adhesive systems are critical to a reliable product. Detailed instructions on weighting proportions and tolerances, number of mixing cycles or mixing time, and cure time and temperature with time and temperature tolerances (cure schedule) are included in the engineering documentation. The pot life or working life of an adhesive is determined as a function of temperature. The engineering documentation includes requirements for the adhesive's shortest pot life or working life for the temperature range specified during adhesive application. After connector bonding, inspection criteria is defined in the engineering documentation for the fiber and cable as well as the connector to ensure reliable connectorization. Data such as adhesive lot numbers, room temperature and humidity, and pot life are recorded in the certification log for traceability in the event of problems with the adhesive. The glass transition temperature (Tg) of the adhesive used to bond an optical fiber to an optical connect, contact, substrate, or other piece part is at least 10 degrees C greater than the maximum temperature that the optical assembly will be subjected to, including test and storage temperatures. The Tg of an optical fiber adhesive is controlled to minimize optical performance variations caused by the potential movement of the bonded fiber within the optical assembly after temperature cycling. Step 4- Bonded Terminus Polishing Polishing of a terminus bonded to a cable is accomplished in three stages; course hand polishing and a two step machine fine polishing procedure. Refer to the polishing procedures in Ref. 1. The connector assembly is inspected for excess adhesive on the fiber endface and other parts of the connector, as defined in the engineering documentation, which could interfere with proper operation of the connector. Excessive adhesive on the connector endface can flake off over time and create contamination which can affect performance. Excess adhesive on other connector parts can prevent springs and other mechanisms from operating properly or fitting properly together. The optical fiber is back-lit using a flashlight from the opposite end of the cable assembly without touching the fiber when inspecting a finished fiber optic connector for cracks in the fiber. The polishing process produces a \"flat\" polish and the use of an interferometer is recommended to measure the profile of a fiber endface. The amount of fiber protrusion and the amount of fiber undercut is specified in the engineering documentation. Physical contact connectors, angle polished connectors, or other specialized polished endfaces have specific requirements for endface finishing. The amount of fiber protrusion, amount of fiber undercut, connector endface geometry parameters and tolerances, such as flatness, radius of curvature, vertex offset, or angle, as a minimum, are specified in the engineering documentation. Final Polish Verification Visual examination of the polished, bonded terminus is performed to ensure that the finished termination is of high optical quality and free of unacceptable defects, such as chips, contamination, cracks, scratches, pits, or hackles. A 200X hand held microscope is used and because of the high magnification, the microscope lens and terminus adapter and the polished terminus must be clean. Loose debris or dust is removed by using dry nitrogen. Care is used to insure that lenses of the microscope and the polished terminus are not scratched. Cleaning and inspection is accomplished in accordance with the step by step procedures of Ref. 1. Acceptance Criteria The following define the acceptance criteria: The terminus must have a smoothly polished face and glass fiber free of visible scratches and imperfections which affect optical performance or reliability. No visible scratches on the terminus ceramic face. No fiber edge chips, scratches, pits, or hackles. No contamination. No fiber cracks or cracks anywhere in the ceramic ferrule. No excess epoxy around the fiber or spots of apoxy anywhere on the ceramic face. Optical Performance Verification The optical fiber cable has been terminated on both ends and conforms with all acceptance criteria up to this point. Optical performance verification is performed by conducting a power loss measurement in accordance with a test setup and the procedure defined in Ref. 1. The first step is to perform power loss measurements without the optical fiber cable in the test setup to establish reference measurement values. The second step is to insert the cable to be verified into the test setup without changing anything else in the test setup and repeating the power loss measurement. The difference in the two power loss measurements, is the power loss of the optical fiber cable. Power Loss Acceptance Criteria Power losses of -1.0 dB per terminus or -2.0 dB per cable is the acceptable value for the two termini of each completed cable. In addition acceptable cable length losses for cables less than 34 feet long is 0.1 dB. Acceptable cable length losses for cables longer than 34 feet are based on -0.003 dB per foot of cable length. Cables that fail the power loss acceptance criteria may be repaired by cleaning or additional fine polishing of an terminus or by replacement of a defective terminus if the cable length permits replacement of a terminus. Connector Installation A terminated optical fiber cable is installed into a MIL-C-38999 connector before it is used in a spacecraft harness assembly. The optical fiber terminus is installed into the connector in the same way that a wire contact is installed. Care is exercised to ensure that the termini ends are not touched, contaminated, or scratched during installation. Standard contact extraction tools for the MIL-C-38999 connector are used if the termini are to be removed from the connector. Mechanical strain relief backshells are used as appropriate. Socket termini have springs which allow for movement inside a connector when optical termini are mated together. Care is exercised to ensure that the strain relief allows for a slight movement of all socket termini cables in the harness. Optical fiber cable connector terminations are inspected and cleaned if necessary before each mate. Under no circumstances are 100 mate and demate cycles exceeded without cleaning the fiber optical termination to ensure consistent optical performance. Dust caps which are non-outgassing in laboratory or room environments are used as covers for optical assemblies. Vinyl dust covers are not used. Technical Rationale: The use of components, materials, and techniques used in the fabrication of optical fiber cables that have not been tested and approved for spaceflight use could result in significant loss of performance during the mission. Outgassing of contaminates in space can be a serious problem with optical fiber systems. Also, space radiation can cause significant loss in performance of certain optical fibers. Nicks in the small and fragile glass fiber can result in latent optical defects and failures. References: GSFC Document No. 733-FO-29504-TERM-TRAINING Entitled \"Optical Fiber Cable Termination Procedures For Spaceflight Applications Using MIL-T-29504 Optical Fiber Termini\"","Lesson ID":645}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number GSE-3002 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: This design standard incorporated a fail safe practice that prevents the two potential failures inherent to a water protection system: Lack of water flow when required Inadvertent water flow when not required. Implementation Method: This design implements a practice which might be considered as excessive due to the added expense of the additional water valves and their associated controls. However, applied in an appropriate situation this configuration could prove to be very cost effective. The appropriate application for this design would be where the protected materials are susceptible to ruination from water damage. The loss incurred from fire damage and the lack of fire extinguishing capability is well understood. This configuration provides added security to the user that the system will be available when required. Not as evident is the susceptibility to damage as a result of an inadvertent activation or failure. This arrangement provides the security that a single failure will not result in a water deluge potentially destroying the property it was designed to protect. Technical Rationale: The basis for this configuration is the series-parallel arrangement of the water valves shown in Figure 1. An adequate flow of water should be available to the user through any of the paths involving the ARM and ACTIVATE valves, i.e. all that is required is one ARM valve and one ACTIVATE valve to open (see figure 1 to show available water paths). The valves should be pneumatically or hydraulically controlled through electrically positioned solenoid valves. Each water valve should have its own controlling solenoid valve. The ARM solenoid valves should be controlled open by two parallel redundant controlling devices (relays, programmable logic controllers, etc.) and the ACTIVATE solenoid valves should be controlled open by two other parallel redundant controlling devices. Local and remote valve actuation should be provided with separate ARM and ACTIVATE switches. These arrangements insure that a single failure will not prevent water flow when required or initiate water flow when not desired. [D] References: KSC-STD-F-0004C: Standard for Fire Protection Design for Facilities, John F. Kennedy Space Center, NASA. SAA09SY03B-001: System Assurance Analysis of the Pad Water System at LC-39 Pad B & MLP-1, -2. 79K40019: LOA Facility Water Pad B SMS\/EMCD. 80K55529: LOA Facility Water MLP 1, 2, & 3 SMS\/EMCD.","Lesson ID":650}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number GSE-3005 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Early identification of potential critical items will provide valuable inputs to design engineering for their avoidance and\/or elimination. Critical Items Lists (CIL) provide management with design acceptance rationale for those critical items which could not be eliminated, and identify test and inspection controls to minimize the probability of a failure. Implementation Method: Background GSE at KSC includes equipment and facility systems used to test, checkout, process, handle, and transport Space Shuttle flight hardware at the launch and landing sites. Equipment used at other sites that is common to that used at the launch and landing sites is also included. Prior to conducting the FMEA a criticality assessment is performed to assess each system function. If loss or improper performance of the function, without regard to available redundancy, could result in loss of life\/vehicle or damage to a vehicle system the system is assessed as critical. FMEAs are performed on the hardware associated with the critical functions. The only exceptions are functions assessed as critical due to failure of passive components, such as certain types of structural components. The Failure Modes and Effects Analysis (FMEA) is performed at the lowest level necessary to identify: 1) Single Failure Points (SFP's) which if failed could cause loss of life\/vehicle or damage to a vehicle system; 2) The combined effect of two like or unlike redundant items which could result in loss of life\/vehicle; 3) SFP's in safety or hazard monitoring systems whose failure modes assume the hazardous condition being monitored or combated has already occurred. The FMEA and resulting CIL can be used not only as a check of the systems design for reliability, but can also be used as a driver for the systems design to reduce or eliminate critical items and\/or implement value added maintenance design features. The FMEA\/CIL process plays a key role in reliability management. Reliability management is the activity involved in assuring that proper performance of the system\/equipment and completion of maintenance procedures will minimize the risks associated with the identified failure modes. Reliability management coordinates the analysis of design, development, manufacturing, testing, maintenance, and operations to assure that the system output will support the prescribed program interface\/function. Reliability Management is accomplished through the formulation of reliability plans, the performance of system\/equipment design analysis, the support of classical reliability analysis activities, and project\/system team participation using concurrent engineering methodologies. The principal outputs of the FMEA\/CIL process are the CIL's. Critical Items and Retention Rationale Specific lessons have been learned that will enhance the value of identifying potential critical items early in high-technology, multi-disciplinary aerospace programs and projects. Critical items are identified through the conduct of a FMEA. The FMEA process involves the analysis of each active component (hardware or software element) in a complex system to a specified level, for each possible failure mode. The determination of the \"worst case\" failure effect of that failure on vehicle systems and\/or personnel safety is then determined. If the item could fail in a mode which could directly result in loss of life\/vehicle and\/or damage of a vehicle system, the item is designated as a critical item and categorized according to the severity of the failure effect. SFP's in designated safety or hazard monitoring systems, whose failure modes assume the hazardous condition being monitored or combated has already occurred, are also identified as critical items. The FMEA is most effective when it is performed concurrently with the design process and maintained throughout the life of a program or project. It is the policy of NASA not to permit the retention of SFP's in design unless special conditions result in the application and approval of a waiver or deviation from the Space Shuttle Program (SSP) Configuration Management Requirements. Retention of a SFP requires that a CIL sheet be prepared which identifies the item, Criticality Category, Function, Failure Mode, Failure Cause(s), Failure Mode Number and Failure Effect. The CIL sheet also provides the Acceptance Rationale which describes the components design, test, inspection, failure history, and operational use. The elements of the Acceptance Rationale, as described below, include safety margins, prevention measures, and maintenance\/operational procedures which will ensure that the critical item will not fail in the critical failure mode. The Acceptance Rationale forms the basis for management acceptance of GSE which contains critical items. Design Rationale: Design rationale identifies design features and\/or margins that have been provided in the design of the hardware or software element which minimize or eliminate the probability of occurrence of the failure mode and\/or reduction or elimination of the potential causes of the failure mode. Test Rationale: Test rationale includes specific tests which are accomplished to detect failure modes and\/or causes during acceptance and periodic certification. If turnaround checkout testing is accomplished via Operational and Maintenance Instructions (OMI's) the details of the test, frequency, and OMI number are included. Inspection Rationale: Inspection rationale addresses specific inspection methods,procedures, tools, and techniques which are performed on a pre-operational and\/or post-operational basis to determine whether or not the critical failure modes have occurred. Inspections which minimize the probability of encountering failure modes and their potential causes are also included. Tear-down analysis is excluded as a means for inspection. Failure History: Failure history includes data on previously reported failures and corrective actions for the critical item in the critical failure mode(s) as found in the Problem Reporting and Corrective Action (PRACA) database. Reference is also made to the PRACA database for current data on test failures, unexplained anomalies, and other failures experienced during ground processing activities. Operational Use: Corrective action that would either prevent the particular mode or mitigate it's effect once it has occurred is included as part of the retention rationale. The time required to take the corrective action (timeframe) is also provided. The CIL sheet is presented to project management for approval\/acceptance of the risk associated with the critical items and subsequently to the Program Requirements Control Board (PRCB) with the waiver request (CR). The waiver request identifies the failure modes which do not meet the fail safe requirement from NSTS 07700, Volume X. The fail safe requirement specifies that all GSE (except primary structure and pressure vessels) shall be designed to sustain a failure without causing loss of vehicle systems or loss of personnel capability. Suggestions for Effective CIL Implementation based on KSC experience Correlation of FMEA results with Fault-Tree Analyses and Hazard Analyses: The FMEA\/CIL data can serve as an input to the hazards analysis process. The hazards analysis uses fault trees and is basically a top down approach. It focuses on human errors and considers multiple unrelated failure modes which the FMEA\/CIL ground rules out. Use of the CIL sheets to initiate risk management controls: Preparation of the CIL sheet can be used as an opportunity to coordinate with the cognizant engineering organizations to develop and agree upon appropriate maintenance procedures and operational processes to assure control of the risks associated with the critical items. Subsequently the CIL can be used to initiate closed loop tracking of the test and inspection controls. Use of FMEA\/CIL to develop test and checkout procedures: FMEA\/CIL developed early in design projects can be used as input to develop test procedures, inspection requirements, operational procedures, and trouble shooting guides. The component level analysis performed in the FMEA and the detailed reporting of critical items provides specific information regarding failure scenarios with defined system reactions and expected personnel corrective action. CIL's should be implemented in a way that would not impact important program milestones or create unnecessary work-around in the areas of cost, schedules, or system performance. Example Uses of FMEA\/CIL Use of FMEA for early identification of critical items: The design process for the 325 Ton Bridge Crane installed in the Vehicle Assembly Building at KSC utilized the FMEA process to identify potential critical single failure points in both hardware and software systems. As potential single failure points were identified the reliability engineer coordinated with the NASA and vendor design engineers. The design engineers were made aware of the failure effects, alternative designs were considered, and solutions were implemented. The FMEA process continued through test and acceptance of the equipment with the resulting design having no single failure points. Use of CIL sheets to identify risk to management: The CIL process was utilized during the analysis of the extensible and auxiliary access platforms in the VAB. The analysis was initiated by a design study that indicated that a substantial number of platforms were equipped with hinges that may fail under dynamic loading. Reliability engineering analyzed the systems and identified critical single failure points which, if failed, could allow a platform to fall causing a cascading effect of one platform upon another and resulting in the overloaded hinge scenario as described in the design study. The CIL sheets were used to advise management of the risks associated with platform operations. During presentation of the CIL sheets, Reliability Engineering also made recommendations for alternative fail-safe equipment. Management was able to assess the risks, accept interim controls and identification of new CIL items, and initiate implementation of corrective action. Use of CIL sheets to initiate test and inspection controls: The CIL process has been used at KSC to manage the risks associated with cranes and hoists which, if failed, could cause loss of life or vehicle. CIL sheets for critical gear systems\/components identify test and inspection requirements which are performed in a close-looped tracking operations and maintenance process. Performance of a periodic load test at rated load, verifies the operational integrity of the gear system and periodic ferrographic analysis of the gear lubricant is used to document wear trends and to assist in predicting future failure. Technical Rationale: Extensive analytical work on existing and emerging programs relative to failure identification, management, and control has resulted in well documented, rigorous procedures for the treatment of critical items. Concurrent engineering approaches to program engineering and management have included attention to more details earlier in the design process and at a much lower level than previously attained. Assurance of success means the elimination or reduction of potential failure modes. Elimination or reduction of potential failure modes can only be achieved through the conscientious application of FMEA, critical item identification, and prudent engineering management. The advantages of the FMEA\/CIL process are that it: (1) Systematically identifies all credible failure modes and causes; (2) permits a focus on critical SFP's and levels of redundancy; (3) provides management with risk acceptance rationale for critical failure modes\/causes; (4) initiates control of critical items, associated procedures, and processes; and (5) provides a single, agreed-to listing of all critical items associated with a given project. References: National Space Transportation System Critical Items List, Shuttle Program Critical Items List, Kennedy Space Center Ground Support Equipment, NSTS 08399, Book 4, Revision A, Lyndon B. Johnson Space Center, Houston, TX, November 28, 1988. Problem Reporting and Corrective Action System Requirements, NSTS 08126, Lyndon B. Johnson Space Center, Houston, TX, April 7, 1994. Requirements for the Preparation and Approval of Failure Modes and Effects Analysis (FMEA) and Critical Items List (CIL), NSTS 22206, Revision D, Lyndon B. Johnson Space Center, Houston, TX, December 10, 1993. Space Shuttle Flight and Ground System Specification, FMEA\/CIL Deviation and Waivers, NSTS 07700 Volume X, Book 5, Revision K, Lyndon B. Johnson Space Center, Houston, TX, October 9, 1992. Space Shuttle Program Configuration Requirements, NSTS 07700 Volume IV, Lyndon B. Johnson Space Center, Houston, TX, November 23, 1994. NASA Reliability Preferred Practice PD-ED-1240, Guideline for the Identification, Control and Management of Critical Items.","Lesson ID":649}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1206 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefits: Power line filters minimize the flow of conducted noise currents on power buses emanating from hardware that could interfere with the proper operation of other hardware also operating on the same power buses. Additionally, power line filters minimize the flow of noise currents on power buses into hardware which could interfere with the proper operation of that hardware. Implementation: Power line filters are used to meet the Conducted Emission and Conducted Susceptibility Requirements of GSFC's General Environmental Verification Specification for STS and ELV Payloads, Subsystems, and Components (GEVS-SE). This document contains a baseline for demonstrating by test the satisfactory performance of hardware in the expected mission environments. Technical Rationale: The problems of Conducted Emission and Conducted Susceptibility have been widely recognized for many years. The EMC community and the Department of Defense have collaborated in preparing and in continually reviewing and updating a widely used set of EMC design and test requirements designated MIL-STD-461, 462, and 463. These requirements have been tailored for specific spaceflight application and incorporated by the GSFC into the GEVS-SE document along with specific requirements defined in the Shuttle Orbiter\/Cargo Standard Interfaces Document (JSC 07700 Volume XIV Attachment 1 (ICD 2-19001). References: General Environment Verification Specification For STS and ELV Payloads, Subsystems, and Components (GEVS-SE). Shuttle Orbiter\/Cargo Standard Interfaces Document (JSC 07700 Volume XIV Attachment 1 (ICD 2-19001).","Lesson ID":646}
{"Driving Event":"This Lessons Learned is based on Reliability Practice NO. PD-EC-1101 from NASA Technical Memorandum 4322A, NASA Preferred Reliability Practices for Design and Test. Benefits: Each of the identified environmental factors requires consideration in the design process. This assures that adequate environmental strength is incorporated into the design to ensure reliability. Implementation Method: To ensure a reliability-oriented design, determine the needed environmental resistance of the equipment. The initial requirement is to define the operating environment for the equipment. A Life-Cycle Environment Profile, containing this information, should be developed. A Life-Cycle Environment Profile is a forecast of events and associated environmental conditions that an item experiences from manufacturing to retirement. The life cycle includes the phases that an item will encounter such as: handling, shipping, or storage prior to use; disposition between missions (storage, standby, or transfer to\/from repair sites); geographical locations of expected deployment; and platform environments. The environment or combination of environments the equipment will encounter at each phase should be determined. All deployment scenarios should be described as a baseline to identify the environments most likely to be associated with each life cycle phase. The following factors should also be taken into account: Hardware configuration. Environment(s) that will be encountered. Platform\/hardware interfaces. Interfaces with other equipment. Absolute and relative duration of exposure phase. Probability that environmental condition(s) will occur. Geographical locations. Any other information that will help identify environmental conditions that may impact the item. The steps in developing a Life-Cycle Environment Profile are as follows: Describe anticipated events for an item of equipment, from final factory acceptance through terminal expenditure or removal from inventory. Identify significant natural and induced environments or combination of environments for each anticipated shipping, storage, and logistic event (such as transportation, dormant storage, stand-by, bench handling, and ready modes, etc.). Describe environmental and stress conditions (in narrative and statistical form) to which equipment will be subjected during the life cycle. Data may be derived by calculation, laboratory tests, or operational measurements. Estimated data should be replaced with actual values as determined. The profile should show the number of measurements used to obtain the average value of these stresses and design achievements as well as their variability (expressed as standard deviation). This analysis can be used to: develop environmental design criteria consistent with anticipated operating conditions, evaluate possible effects of change in environmental conditions, and provide traceability for the rationale applied in criteria selection for future use on the same program or other programs. A listing of typical environmental factors is included in Table 1. Table 1: Environmental Coverage Checklist (Typical) Natural Induced Albedo, Planetary IR Clouds Electromagnetic Radiation Electrostatic Discharge Fog Freezing Rain Frost Fungus Gravity, Low Hail Humidity, High Humidity, Hight Ice Ionized Gases Lightning Magnetics, Geo Meteoroids Pollution, Air Pressure, High Pressure, Low, Vacuum Radiation, Cosmic, Solar Rain Salt Spray Sand and Dust Sleet Snow Temperature, High Temperature, Low Wind Acceleration Chemicals Corona Electromagnetic, Laser Electromagnetic Radiation Electrostatic Discharge Explosion Icing Magnetics Moisture Nuclear Radiation Shock, Pyro, Thermal Space Debris Temperature, High, Aero. Heating, Fire Temperature, Low, Aero. Cooling Turbulence Vapor Trails Vibration, Mechanical, Microphonics Vibration, Acoustic Technical Rationale: Given the dependence of equipment reliability on the operating conditions encountered during the life cycle, it is important that such conditions be identified accurately at the beginning of the design process. Environmental factors that strongly influence equipment reliability are included in Table 1, which provides a checklist for environmental coverage (typical). Concurrent (combined) environments may be more detrimental to reliability than the effects of a single environment. In characterizing the design process, design\/test criteria must consider both single and\/or combined environments in anticipation of providing the hardware capability to withstand the hazards identified in the system profile. The effects of typical combined environments are illustrated in a matrix relationship in Figure 1, which shows combinations where the total effect is more damaging than the cumulative effect of each environment acting independently. For example, an item may be exposed to a combination such as temperature, humidity, altitude, shock, and vibration while it is being transported. The acceptance to end-of-life history of an item must be examined for these effects. Table 2 provides reliability considerations for pairs of environmental factors. Each environmental factor that is present requires a determination of its impact on the operational and reliability characteristics of the materials and parts comprising the equipment being designed. Packaging techniques should be identified that afford the necessary protection against the degrading factors. In the environmental stress identification process that precedes selection of environmental strength techniques, it is essential to consider stresses associated with all life intervals of the equipment. This includes operational and maintenance environments as well as the pre-operational environments, when stresses imposed on the parts during manufacturing assembly, inspection, testing, shipping, and installation may have significant impact on equipment reliability. Stresses imposed during the pre-operational phase often are overlooked; however, they may represent a particularly harsh environment that the equipment must withstand. Often, the environments to which systems are exposed during shipping and installation are more severe than those encountered during normal operating conditions. It is probable that some of the environmental strength features that are contained in a system design pertain to conditions that will be encountered in the pre-operational phase rather than during actual operation. Figure 1: Effects of Combined Environments [D] (Click image for a larger view) Table 2: Various Environmental Pairs High Temperature and Humidity High Temperature and Low Pressure High Temperature and Salt Spray High temperature tends to increase the rate of moisture penetration. The general deterioration effects of humidity are increased by high temperatures. Each of these environments depends on the other. For example, as pressure decreases, outgassing of constituents of materials increases; as temperature increases, outgassing increases. Hence, each tends to intensify the effects of the other. High temperature tends to increase the rate of corrosion caused by salt spray. High Temperature and Solar Radiation High Temperature and Fungus High Temperature and Sand and Dust This is a man-independent combination that causes increasing effects on organic materials. A certain degree of high temperature is necessary to permit fungus and microorganisms to grow. However, fungus and microorganisms cannot develop above 160\u00b0F (71\u00b0C). The erosion rate of sand may be accelerated by high temperature. However, high temperature reduces sand and dust penetration. High Temperature and Shock and Vibration High Temperature and Acceleration High Temperature and Explosive Atmosphere Since both environments affect common material properties, they will intensify each other's effects. The degree to which the effect are intensified depends on the magnitude of each environment in combination. Plastics and polymers are more susceptible to this combination than metals, unless extremely high temperatures are involved. This combination produces the same effect as high temperature and shock and vibration. Temperature has minimal effect on the ignition of an explosive atmosphere but does affect the air-vapor ratio, which is an imporant consideration. Low Temperature and Humidity High Temperature and Ozone Relative humidity increases as temperature decreases, and lower temperature may induce moisture condensation. If the temperature is low enough, frost or ice may result. Starting at about 300\u00b0F (150\u00b0C) temperature starts to reduce ozone. Above about 520\u00b0F (270\u00b0C), ozone cannot exist at pressures normally encountered. Low Temperature and Solar Radiation Low Temperature and Low Pressure Low Temperature and Salt Spray Low temperature tends to reduce the effects of solar radiation and vice versa. This combination can accelerate leakage through seals, etc. Low temperature reduces the corrosion rate of salt spray. Low Temperature and Sand and Dust Low Temperature and Fungus Low temperature increases dust penetration. Low temperature reduces fungus growth. At sub-zero temperatures, fungi remain in suspended animation. Low Temperature and Shock and Vibration Low Temperature and Acceleration Low Temperature and Explosive Atmosphere Low temperature tends to intensify the effects of shock and vibration. However, it is a consideration only at very low temperatures. This combination produces the same effect as low temperature and shock and vibration. Temperature has minimal effect on the ignition of an explosive atmosphere but does affect the air-vapor ratio, which is an important consideration. Low Temperature and Ozone Humidity and Low Pressure Humidity and Salt Spray Ozone effects are reduced at lower temperatures but ozone concentration increases with lower temperatures. Humidity increases the effects of low pressure, particularly in relation to electronic or electrical equipment. However, the actual effectiveness of this combination is determined primarily by the temperature. High humidity may dilute the salt concentration and could affect the corrosive action of the salt by increasing the coverage, thereby increasing the conductivity. Humidity and Fungus Humidity and Sand and Dust Humidity and Solar Radiation Humidity helps the growth of fungus and microorganisms but adds nothing to their effects. Sand and dust have a natural affinity for water and this combination increases deterioration. Humidity intensifies the deteriorating effects of solar radiation on organic materials. Humidity and Vibration Humidity and Shock and Acceleration Humidity and Explosive Atmosphere This combination tends to increase the rate of breakdown of electrical material. The periods of shock and acceleration are considered too short for these environments to be affected by humidity. Humidity has no effect on the ignition of an explosive atmosphere but a high humidity will reduce the pressure of an explosion. Humidity and Ozone Low Pressure and Salt Spray Low Pressure and Solar Radiation Ozone meets with moisture to form hydrogen peroxide, which has a greater deteriorating effect on plastics and elastomers than the additive effects of moisture and ozone. This combination is not expected to occur. This combination does not add to the overall effects. Low Pressure and Fungus This combination does not add to the overall effects. Low Pressure and Sand and Dust Low Pressure and Vibration Low Pressure and Shock or Acceleration This combination only occurs in extreme storms during which small dust particles are carried to high altitudes. This combination intensifies effects in all equipment categories but mostly with electronic and electrical equipment. These combinations only become important at the hyperenvironment levels, in combination with high temperature. Low Pressure and Explosive Atmosphere Salt Spray and Fungus Salt Spray and Dust At low pressures, an electrical discharge is easier to develop but the explosive atmosphere is harder to ignite. This is considered an incompatible combination. This will have the same effect as humidity and sand and dust. Salt Spray and Vibration Salt Spray and Shock or Acceleration Salt Spray and Explosive Atmosphere This will have the same combined effect as humidity and vibration. This combinations produce no added effects. This is considered an incompatible combination. Salt Spray and Ozone Solar Radiation and Fungus Solar Radiation and Sand and Dust This combination is similar to but more corrosive than humidity and ozone. Because of the resulting heat from solar radiation, this combination probably produces the same combined effect as high temperature and fungus. Further, the ultraviolet in unfiltered radiation is an effective fungicide. It is suspected that this combination will produce high temperatures. Solar Radiation and Ozone Fungus and Ozone Solar Radiation and Shock or Acceleration This combination increases the rate of oxidation of materials. Fungus is destroyed by ozone. These combinations produce no added effects. Solar Radiation and Vibration Sand and Dust and Vibration Under vibration conditions, solar radiation deteriorates plastics, elastomers, oils, etc., at a higher rate. Vibration might possibly increase the wearing effects of sand and dust. Shock and Vibration Vibration and Acceleration This combination produces no added effects. This combination produces increased effects when encountered with high temperatures and low pressure in the hyperenvironmental ranges. Solar Radiation and Explosive Atmosphere This combination produces no added effects. Environmental stresses affect parts in different ways. Table 3 illustrates the principal effects of typical environments on system parts and materials. High temperatures impose a severe stress on most electronic items, since it can cause catastrophic failure (such as melting of solder joints and burnout of solid-state devices). High temperature also causes progressive deterioration of reliability due primarily to chemical degradation effects. It is often stated that excessive temperature is the primary cause of poor reliability in electronic equipment. In electronic systems design, great emphasis is placed on small size and high part densities. This generally requires a cooling system to provide a path of low thermal resistance from heat-producing elements to an ultimate heat sink of reasonably low temperature. Solid-state parts are rated in terms of maximum junction temperatures. The thermal resistance is usually specified from this point to either case or to free air. Specification of the maximum ambient temperature for which a part is suitable generally is not a sufficient method for part selection, since the surface temperature of a particular part can be greatly influenced by heat radiation or heat conduction effects from nearby parts. These effects can lead to overheating, even though an ambient temperature rating appears not to be exceeded. It is preferable to specify thermal environment ratings such as equipment surface temperatures, thermal resistance paths associated with conduction, convection, and radiation effects, and cooling provisions such as air temperature, pressure, and velocity. In this manner, the true thermal state of the internal components of temperature-sensitive components can be determined. Reliability improvement techniques for high temperature stress include the use of heat dissipation devices, cooling systems, thermal insulation, and heat-withstanding materials. Low temperatures experienced by electronic equipment can cause reliability problems. These problems usually are associated with mechanical system elements. They include mechanical stresses produced by differences in the coefficients of expansion (contraction) of metallic and nonmetallic materials, embrittlement of nonmetallic components, mechanical forces caused by freezing of entrapped moisture, stiffening of liquid constituents, etc. Typical examples include cracking of seams, binding of mechanical linkages, and excessive viscosity of lubricants. Reliability improvement techniques for low temperature stress include the use of heating devices, thermal insulation, and cold-withstanding materials. Table 3: Environmental Effects Environment Principal Effects Typical Failures Induced High Temperature Thermal aging: Oxidation Structural change Chemical reaction Insulation failure; Alteration of electrical properties. Softening, melting, and sublimation Structural failure. Viscosity reduction\/evaporation Loss of lubrication properties. Physical expansion Structural failure; increased mechanical stress; increased wear on moving parts. Low Temperature Increased viscosity and solidification Loss of lubrication properties. Ice formation Alteration of electrical properties. Embrittlement Loss of mechanical strength; cracking, failure. Physical contraction Structural failure; increased wear on moving parts. High relative humidity Moisture absorption Selling, rupture of container; Physical breakdown; Loss of electrical strength; Loss of mechanical strength; Interference with function; Loss of electrical properties; Increased conductivity of insulators.","Lesson ID":643}
{"Driving Event":"This Lessons Learned is based on Relibility Practice number PD-EC-1103 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefits: Ni-Cd batteries are perishable and their ability to satisfactorily complete mission life is directly related to prudent handling and storage procedures. The development and implementation of appropriate project-unique procedures based on a set of proven guidelines assure that the optimum performance of Ni-Cd batteries is not degraded due to inappropriate handling and storage. Implementation: The Ni-Cd cell is constructed of positive plates (nickel electrodes), negative plates (cadmium electrodes), and a separator material that is interleaved with the plates and serves to insulate the positive plates from the negative plates and retain the electrolyte. The plates are connected to the respective cell terminals which are attached to a cell cover and inserted in a steel case and welded shut. The electrolyte is normally 31 percent concentration of potassium hydroxide and is added though the \"fill tube\" which is fitted with a pressure gauge. After the cell satisfactorily completes its manufacturing and acceptance testing, the fill tube is pinched off and welded closed. The manufacture of a hermetically sealed Ni-Cd is predicated on a delicate balance between the active material, the relative state-of-charge of the active material between the positive and negative plates at the time the cell is sealed, the amount of electrolyte placed in the cell at closure, the properties of the separator material, and the free volume allowed by the case design. The aerospace Ni-Cd cell, which has no free or excess electrolyte, is referred to as an \"electrolyte starved\" design. The primary prerequisite for a sealed-electrolyte starved cell to operate safely is that the positive plates be limiting on charge so that only oxygen is generated during overcharge. During charge some of the current is utilized in the generation of oxygen gas and when in overcharge, all the current is used in generating oxygen. This causes the cell pressure to increase to a level that is dependent on the recombination rate of oxygen at the negative electrode, the rate of diffusion of the oxygen through the separator, the amount of electrolyte in the cell, and the cell free volume. The cell pressure at 20 degrees C can typically be in the range of 50 to 65 PSIG. The negative plates of a cell contain approximately 50 percent more capacity than the positive electrode. Of this \"excess\" negative capacity, approximately 60 percent remains uncharged when the positive plates are fully charged. This uncharged material is referred to as \"overcharge protection\" and is required to prevent the plates from becoming fully charged and generating hydrogen gas. The remainder of the excess negative material is in the charged state when the cell is fully discharged and provides over-discharge protection. It is referred to as precharge. On discharge, when the cell voltage drops below 1 volt, the positive plates are limiting, thereby leaving charged cadmium material to react with any residual oxygen when the cell is completely discharged. Typical pressure of fully discharged cells is 3 to 5 PSIG. A second reason for the positive plates to be limiting on discharge is to prevent the effects of negative capacity fading, which occurs during normal use, from causing losses in cell capacity. It is thought that capacity fading is related to the sizes of the cadmium crystals. It is most important that the overcharge protection is available for the entire life of the cell. Should the negative plates become fully charged, hydrogen gas is generated during overcharge and there is no effective mechanism within the cell for the recombination of Hydrogen gas. If a cell is over discharged (potential reversed) Hydrogen gas is generated at the positive electrode at a rate dependent upon the discharge rate. Because of the limited free space in a sealed cell, a cell that is reversed can quickly build up pressure and rupture the cell case or battery package. The Ni-Cd cell is a highly complex, interactive electrochemical device where the present and future performance is totally dependent on its past history. This history includes the attributes and characteristics of the raw materials, the processing of these materials into components, the assembly of these components into a sealed cell, and all testing, handling, and storage. Consequently, a cell or battery is classified as perishable and treated accordingly. Because Ni-Cd batteries can be irreversibly degraded by improper use and handling, the following guidelines were developed for the use of battery engineers in preparing project-specific Battery Handling and Storage Requirement Documents: GUIDELINE NO. 1 - Flight batteries should be maintained in a discharged and shorted condition and stored at cold temperatures when not required for \"critical\" spacecraft testing. The electrochemical activity is at a minimum in the discharged state and when stored at the optimum storage temperature of 0 degrees C. A battery, stored discharged and shorted up to three years since cell activation, is expected to provide several years life of nominal performance in orbit. GUIDELINE NO. 2 - Flight batteries should not be subjected to extended spacecraft integration and test activities. The open circuit and intermittent use of Ni-Cd batteries during extended spacecraft integration and testing activities are known to significantly accelerate the degradation of batteries. Results from controlled tests have shown permanent and irreversible changes unlike anything observed after several years of spacecraft flight operations. Degradation is observed initially as an increase in cell overcharge voltage at low temperatures which is indicative of loss in overcharge protection. Also, integration and testing use promotes significant cadmium migration. Both of these are recognized as the dominate wear-out mechanisms which determine battery life. GUIDELINE NO. 3 - The use of charged batteries after an open stand should be initiated with a 3 to 5 minutes discharge prior to initiating battery charge. Typically the discharge is done with spacecraft load and in concert with the spacecraft ground power console. During normal cycling use, the battery is discharged followed by a recharge and some overcharge. In this mode, there is always a partial pressure of oxygen from the overcharge with oxygen recombination occurring at the negative electrode. In a relatively short time on open circuit, the oxygen recombines and the internal cell pressure returns to a vacuum. Charging cells that are fully charged in the absence of oxygen creates an \"unnatural\" condition, since there is no oxygen available to react with the negative electrodes. Past experience shows that this technique reduces the effects of open circuit stand on performance. GUIDELINE NO. 4 - During periods when the battery is not needed to support spacecraft test and operations, it should be maintained on a low rate trickle charge, (C\/100). Trickle charge at low rates is preferred to open circuit stand for a battery. While there are degradation mechanisms associated with trickle charge, data from controlled tests indicate that this to be much less detrimental than open circuit stand. GUIDELINE NO. 5 - Cooling should be provided to maintain battery temperatures at about 18 degrees C during spacecraft integration and test operations. Exposures to elevated temperatures accelerate cadmium migration and separator breakdown which depletes the overcharge protection in the cells. Since the rate of separator degradation increases by a factor of 3 for every 10 degree C rise in temperature, strict adherence to this guideline is advised. GUIDELINE NO. 6 - A battery stored discharged and shorted for a period greater than 14 days should be activated with a \"reconditioning cycle\" prior to placing it in use. The reconditioning cycle is performed at 20 degrees C and is defined as follows: Recharge at C\/20 (C\/*** indicates recharge or discharge rates in terms of \"name plate\" battery capacity, e.g., C\/20 = 1\/20 of the capacity listed on the battery nameplate) for 40 hours (+\/- 4 hours) Discharge at C\/2 constant current rate until the first cell reaches 1.0 volts. Drain each cell with a 1 ohm resister to less than 0.03 volts. Short each cell for a minimums of 4 hours Recharge battery at C\/20 constant current rate for 40 hours (+\/- 4 hours) GUIDELINE NO. 7 - Charged batteries should not stand on open circuit for more than 14 days. Charging should be initiated only after implementing Guideline No. 3. When cells are on open circuit \"self discharge\" occurs which results in the formation of large cadmium crystals. Controlled tests have shown capacity loss of just under 1% per day at 23 degrees C and about 1.5% at 35 degrees C. The self discharge rate of each cell is not identical, consequently after extended periods of open circuit, there can be an appreciable capacity loss and capacity divergence between cells in a battery. This can be remedied by discharging the battery as described in Guideline No. 3 and trickle charging the battery several hours to bring all cells into balance. GUIDELINE NO. 8 - A battery should be \"reconditioned\" if it has been on open circuit, subjected to intermittent use, i.e., open circuit, trickle charge, occasional discharge, etc., for a cumulative period of 30 days. Reconditioning is effected by performing the following sequence at 20 degrees C: Discharge at C\/2 constant current rate until the first cell reaches 1.0 v\/c. Drain each cell with a 1 ohm resistor until each cell's voltage is less than .03 V\/C. Short each cell for a minimum of 4 hours. Recharge battery at C\/20 constant current rate for 40 hours (+\/- 4 hours). Repeat steps a, b, and c. Charge battery at C\/10 constant current rate for 16 hours ( +\/- 4 hours). Repeat steps a, b, c, and f. Exercising the active material by periodic discharge of each cell followed by a low charge helps retard permanent change in the crystal structure of the cadmium electrodes and forces electrolyte redistributions within the cell. The less frequent the reconditioning cycles, the less effective the reconditioning cycle is in restoring the discharge voltage of a battery. GUIDELINE NO. 9 - Flight batteries should be discharged and cells shorted during shipment. Batteries should be packaged to exclude humidity and control temperatures to 5 degrees C (+\/- 5 degrees C) and the shipping container should be equipped with temperature recorders to provide assurances that flight batteries have not been exposed to temperatures exceeding 25 degrees C. A Ni-Cd battery can deliver very high currents if shorted. High currents would create a safety hazard as well as destroy the battery due to the excessive heat that would be generated. Elevated temperatures enhance the rates of electrochemical reaction and separator hydrolysis. GUIDELINE NO. 10 - The final reconditioning of flight batteries should be performed at least 14 days prior to spacecraft launch. Upon completion of the reconditioning, flight batteries should be kept on low rate trickle charge until launch. Use the reconditioning sequence defined in Guideline No. 8. The reconditioning cycle restores the battery discharge voltage to \"like new\" condition by enhancing the formation of small cadmium crystals and electrolyte redistribution. A complete discharge establishes capacity balance for all cells within a battery. The low rate trickle ensures that the battery is maintained at full state of charge for launch. GUIDELINE NO. 11 - The design of flight batteries should include the following provisions for ground console interfacing with the batteries while integrated in the spacecraft: Signal lines for monitoring total battery voltage, charge and discharge currents, battery temperatures, and individual cell voltages. Capability to charge and discharge the battery from the ground test console Capability to place a resistor and a shorting plug across each individual cell Capability must be provided to monitor the state of health of batteries and to discharge, charge, trickle charge and recondition batteries without powering up the spacecraft in order to meet guidelines to minimize degradation of the batteries. GUIDELINE NO. 12 - A log book should be maintained on each flight battery including the complete test histories of each cell, of the assembled battery, and of all integration and test and launch site activities. Each log book should identify the project and battery and individual cell serial numbers. Chronological (date and time) entries for all test sequences, summary of observations, identification of related computer stored records, malfunctions, names of responsible test personnel, and references to test procedures controlling all tests should be recorded. Since Ni-Cd batteries are perishable, their ability to satisfactorily complete their mission life is directly related to their storage, their ground use, and handling. Historical performance information is required to ensure their flight worthiness at launch time. The referenced document provides additional details concerning the degradation mechanisms of Ni-Cd cells and how these mechanisms are affected by improper ground handling. The reference also includes a synopsis of Ni-Cd cell design and evolution over 30 years of space flight on GSFC satellites along with a chronological review of key elements which influenced the current design of the Ni-Cd cells. Technical Rationale: Ni-Cd batteries can be damaged and irreversibly degraded through improper use and handling prior to launch. The 12 guidelines provided above were developed over many years of experience in the use, handling, and testing of Ni-Cd batteries. Following these guidelines ensures that flight batteries are not irreversibly degraded and have been properly reconditioned and prepared for launch. References: Handbook For Handling And Storage Of Nickel Cadmium Batteries: Lessons Learned - NASA Reference Publication 1326 - February 1994.","Lesson ID":644}
{"Driving Event":"An unanticipated roll torque was imparted to a commercial communications satellite launched in 1989. This torque mandated excessive thruster corrections by the attitude control system until the propellant was prematurely exhausted, resulting in mission failure. Subsequent magnetic characterization tests performed on an engineering model of the large stainless steel propellant tanks revealed that the tanks could be easily magnetized during or after fabrication. The dipole moment of a magnetized tank would interact with the earth's magnetic field. This force would attempt to align the spacecraft with magnetic north, like a compass needle, producing the observed roll torque and requiring excessive attitude corrections by the thrusters. Testing showed that once magnetized, the tank would be capable of retaining a residual field that produces a dipole moment much greater than the 580 A-m2 required to produce the observed torque. The satellite's two stainless steel propellant tanks had been substituted for titanium tanks due to schedule deadlines. Since stainless steel material is generally assumed to be non-magnetic, no magnetic testing was performed. However, it is possible for the stainless steel sheet metal to become residually magnetized, with an associated moment, either by working it into the tanks' hemispheric shape or by exposure to an external magnetic field. As a corrective measure, this moment can be reduced significantly (to approximately 5 A-m2) after manufacturing by subjecting the tanks to a 40 Gauss alternating field and by monitoring subsequent exposure. Additional Keyword(s): Helmholtz coil, demagnetization, magnetic compatibility, attitude control, mission operations Reference(s): Magnetic Test Results of Engineering Model Propellant Tank, P. Narvaez, Jet Propulsion Laboratory IOM 5219-89-341, October 17, 1989. Roll Torque Anomaly Review Committee Findings, K. P. Bhat, August 21, 1989.","Lesson ID":642}
{"Driving Event":"The Mars Climate Orbiter (MCO) Mission objective was to orbit Mars as the first interplanetary weather satellite and provide a communications relay for the Mars Polar Lander (MPL) which is due to reach Mars in December 1999. The MCO was launched on December 11, 1998, and was lost sometime following the spacecraft's entry into Mars occultation during the Mars Orbit Insertion (MOI) maneuver. The spacecraft's carrier signal was last seen at approximately 09:04:52 UTC on Thursday, September 23, 1999.","Lesson ID":641}
{"Driving Event":"On July 31, 1996, at 13:15 MDT, NASA successfully launched and flew the Clipper Graham, DC-XA, vehicle for the fourth time. Following an uneventful takeoff, the Clipper Graham flew for 104 seconds reaching an altitude of 4100 feet and traveling 2800 feet up range before returning to the concrete landing pad, successfully completing all test objectives. Ninety-eight seconds into the flight and at approximately 400 feet, the DC-XA computer commanded landing gear deployment. Over the next five seconds, three of the four legs successfully deployed. Four seconds after the gear deploy command, landing gears 1 and 4 deployed within one-tenth of a second of each other. Then, landing gear 3 deployed one full second later. Landing gear 2 never deployed. Descending from 400 feet, the spacecraft landed safely on three of its four legs. When the weight-on-gear indication was received at 13:17:27 MDT, the engines terminated as programmed and at 13:17:29 MDT, the vehicle toppled toward the position of landing gear 2. Upon impact, the vehicle was destroyed in a series of three explosions spaced over the next 90 seconds. The first explosion at 13:17:30 MDT ignited the composite shell and the avionics rack. At 13:17:40 MDT, ten seconds after the initial explosion, the fire suppression system began dispensing water. A second explosion of liquid oxygen from the aluminum-lithium tank rocked the mishap scene ten seconds after the first explosion. The fire suppression system shut down after the tank ran out of water but before complete fire extinction. Approximately 1 minute after the second explosion, the hydrogen tank exploded. This third explosion scattered the composite material from the aeroshell and hydrogen tank over the mishap scene. The Clipper Graham DC-XA vehicle was totally destroyed by ground impact and ensuing explosions and fires. The vehicle struck the ground on the corner of the vehicle at the undeployed landing gear 2. The upper two-thirds of the composite aeroshell, aluminum-lithium liquid oxygen tank, composite liquid hydrogen tank, composite intertank, avionics, nose cone, and parachute recovery systems were destroyed during the three explosions and ensuing fire. Parts of landing gears 3 and 4 were melted in the fire as well. Landing gears 2 and 1 mechanisms were damaged during the tip over and ensuing fires and explosions. The lower one-third of the vehicle aeroshell, containing the throttlable RL-10 engines and the auxiliary propulsion system, were charred and covered with soot. The RL-10 engines and auxiliary propulsion system were the only items appearing to be recoverable. Videotapes of the flight and still photographs of the wreckage showed that landing gear 2 failed to deploy. This failure was also evident in the helium supply pressure time history. NASA analysts at Kennedy Space Center (KSC) performed a helium pressure decay study and showed the loss of helium to be greater than expected after the start of gear deployment. Also, they estimated the diameter of the hole in the pneumatic system that would be required to achieve the observed helium pressure decay rate. This analysis indicated that if the brake line was disconnected during landing gear deployment, the decay rate would be equivalent to that which was recorded by the flight instrumentation. Also, post mishap inspection found the landing gear to be stowed and the pneumatic brake line not connected. Therefore, the primary cause of the vehicle mishap was that the brake line on the helium pneumatic system for landing gear 2 was not connected. This unconnected brake line prevented the brake mechanism from being pressurized to release the brake and resulted in landing gear 2 not extending. The vehicle became unstable upon landing, toppled onto its side, exploded, and burned.","Lesson ID":638}
{"Driving Event":"The Deep Space 1 (DS1) mission successfully demonstrated the use of an ion engine as a primary spaceflight propulsion system. A few minutes after startup in November 1998, DS1's xenon ion engine shut down unexpectedly. The problem was believed to be a quotgrid short,quot a common problem in ion propulsion. Repeated attempts to restart the engine that same day were unsuccessful. Solar electric propulsion (SEP) imparts a small thrust by passing ions through two closely spaced, charged grids (Figure 1). Should a loose conductive flake bridge the gap between the positive and negative charged grids, it could short the grids leading to automatic shutdown of the engine. Molybdenum flakes commonly peel off the grids late in the ion engine's life. Given the early occurrence of the DS1 anomaly, however, it is possible that a conductive contaminant was introduced during assembly or launch operations. [D] DS1 Xenon Ion Engine Ion propulsion systems in commercial satellites incorporate a quotgrid clear circuit,quot like a patio bug zapper, that is believed to be capable of clearing grid shorts by producing a brief high current that eliminates the conductive source. DS1 was designed with a relatively low power version of this circuit. After the anomaly, DS1 operators executed preplanned low risk contingency evaluation procedures. It was decided not to take the risk associated with the immediate use of the quotgrid clear circuit.quot Approximately two weeks after the engine shutdown anomaly, an engine start planned for evaluation purposes resulted in successful engine operation. Activities during this two-week period are believed to have induced thermal cycling of the grids which removed the short. Since this early anomaly, engine operation has been normal. Additional Keyword(s): debris, contamination, fault protection, New Millennium, short circuit, NSTAR, Mission Operations","Lesson ID":639}
{"Driving Event":"Shortly after separation of the Wide-Field Infrared Explorer (WIRE) spacecraft from the launch vehicle, venting of the secondary cryogen tank was commanded, as planned, to dissipate the heat absorbed by the cryogen since termination of ground cooling. Venting this small amount of hydrogen gas was expected to induce some tumbling of the spacecraft. This tumbling was also expected to be quickly dampened by the attitude control system as the solid hydrogen reached equilibrium with the low space-ambient temperature. Instead, the spacecraft was observed to be tumbling too fast to be countered by the reaction wheels and magnetic torquers--an out-of-control condition. A NASA review board determined (reference 1) that an error in the design of the pyro electronics caused premature release of the telescope cover when the secondary cryogen tank was vented. The cover release permitted a large heat load into the cryostat that caused greater and more prolonged cryogen venting then expected following the transient associated with secondary vent actuation. A \"T\" fitting had been placed at the vent outlet to balance the thrust induced to the spacecraft by the gas flow expected from the planned venting sequence. However, design analysis did not consider the torque effects of worst case transient flows caused by one side of the \"T\" pointing directly at a connector (added as a late design modification during integration). The combined applied torque to the spacecraft from the initial secondary vent transient and the effects of early cover release was greater than the attitude control system capability. An independent analysis performed by a member of the WIRE JPL Review Board (reference 1, appendix E, p. 91) indicated the possibility that the normal secondary vent actuation transient could have exceeded attitude control capability. This could significantly impact early science return since it would take many days to reestablish a stable spacecraft attitude. Venting analyses performed during the design phase considered only the steady state cryogen flows expected during primary mission science pointing. However, the premature release of the instrument cover, and resultant boil-off of the cryogen required for telescope operation, was determined by the review board to be the direct cause of the WIRE mission loss (references 1 and 2). It was also determined that the design characteristics of the cryogen tank vent outlet prevented timely control of spacecraft attitude following the cover release anomaly, and the venting-induced torque deterred any productive efforts to save the mission. Additional Keyword(s): WIRE failure, thrust vector, thrust neutralizer, telemetry, angular velocity, roll rate, magnetic torquer, spacecraft spin, torque rod, impingement, subsystem and instrument development Reference(s): WIRE Mishap Investigation Board Report, NASA, June 8, 1999. Transient Performance of the WIRE Pyro Electronics, Lesson Learned No. 0634, August 12, 1999.","Lesson ID":640}
{"Driving Event":"The Wide-Field Infrared Explorer Mission objective was to conduct a deep infrared, extra galactic science survey. The Wide-Field Infrared Explorer was launched on March 4, 1999, and was observed to be initially tumbling at a rate higher than expected during its initial pass over the Poker Flat, Alaska, ground station. After significant recovery efforts, WIRE was declared a loss on March 8, 1999.","Lesson ID":637}
{"Driving Event":"On June 29, 1999, personnel were removing a Grayloc blind hub that had been used to temporarily isolate a portion of the gaseous hydrogen system. As a result of a sudden release of 2800 psig gaseous nitrogen, sand and debris kicked up from the concrete pad and caused minor injury to two technicians.","Lesson ID":635}
{"Driving Event":"On 7\/12\/99, a mechanic was performing a verification leak test (using a 2900 psig gaseous nitrogen pressure source) of a 1\/2\" hand valve when an incorrect fitting blew out. The mechanic erroneously installed a 1\/2\" AN male fitting into the 1\/2\" NPT female port of the valve body. The fitting was attached to a high pressure flex hose when the failure occurred. This flex hose had Kellum restraints that prevented damage to equipment and injury to personnel.","Lesson ID":636}
{"Driving Event":"The Wide-Field Infrared Explorer (WIRE) was declared a loss only a few days after launch. A NASA review board (reference 1) determined that the telescope aperture cover was unintentionally ejected prior to spacecraft attitude stabilization when the WIRE pyro electronics box was first powered. Without the thermal protection provided by the cover, the solid hydrogen cryogen essential for operation of the telescope rapidly sublimated and vented. The mission loss is attributed to a pyro electronics box design that did not allow for the known transient performance of components. The control logic design utilized a synchronous reset to force the logic into a safe state. However, the start-up time of the crystal clock oscillator was not taken into consideration, leaving the circuit in a non-deterministic state for a time sufficient for pyrotechnic actuation. Likewise, the startup characteristics of the field-programmable gate arrays (FPGAs) were not considered. The FPGAs were not guaranteed to follow their quottruth tablequot until quotstartedquot by an internal charge pump. The electrical transients initially generated by the FPGAs were not blocked from the driver circuitry of the pyros. Prompted by the failure investigation, circuit analysis and test showed that the turn-on transients are sufficient to produce spurious signals that latch-up the control logic to a state that can issue commands to fire cover release pyros. These anomalous characteristics were not detected during subsystem or system functional testing due to the limited fidelity and detection capabilities of the electrical ground support equipment. There was no system-level end-to-end test in an as-flown configuration. [D] WIRE Pyro Electronics Startup Characteristics The design error was exacerbated by the failure of a detailed technical review to penetrate the electronic design of the pyro electronics box. Detailed peer review did not extend to the box and its interfaces with the spacecraft. The Mishap Investigation Board concluded that a peer review, held by knowledgeable people, would have identified the turn-on characteristics that led to the failure. Additional Keyword(s): WIRE failure, WIRE instrument electronics (WIE), cover deployment, pyrotechnic device, pyro arming, pyro firing, pyro circuit, qualification test, test equipment, spurious logic, transient analysis, inadvertent actuation, stray current, sneak circuit, SAFE\/ENABLE-RESET, management and planning, system development, subsystem and instrument development, system integration and test Reference(s): WIRE Mishap Investigation Board Report, NASA, June 8, 1999. Informal Design Reviews Add Value to Formal Design Review Processes, Lesson Learned No. 0582, September 26, 1997.","Lesson ID":634}
{"Driving Event":"During the STS-90 flight, there was a repeated need to access the specimens contained within the Animal Enclosure Modules. The operation to gain access required the mating of equipment and covers that had seals (and sealing surfaces) designed to contain contaminants and particulates. The attachment mechanism to hold these mating surfaces together were simple quarter turn fasteners designed to simplify attachment. In flight, it was discovered that the crew had a difficult time pressing the mating components together (to compress the seals) and engaging the fasteners at the same time.","Lesson ID":632}
{"Driving Event":"In support of obtaining flight certification for space flight experiment, there is a requirement and it is standard practice to perform both safety and verification testing. A similar requirement to provide functional performance testing does not exist. Functional performance testing is left to the discretion of project management or to the payload element developer. Ames Research Center has found that the performance of full functional performance testing helps to characterize hardware parameters, identify weak design and circumvent potential in-flight anomalies.","Lesson ID":633}
{"Driving Event":"Shortly after launch of STS-90, some of the motors\/air-pumps associated with the aquatic habitats exhibited an increased power draw indicating either motor or pump failure. To successfully complete the mission, an in-flight procedure was utilized to cross-link each habitat to an operational air pump. Upon landing and recovery, an investigation was conducted of the failed motor\/air-pump assemblies to determine why some units failed while others performed normally. The investigation determined that all of the units that operated properly were original equipment manufacture units, and the units that failed had all been refurbished.","Lesson ID":627}
{"Driving Event":"During the STS-90 fight, a hold-down strap used to secure an experiment habitat during in-flight operations broke. While the strap used was identical to those used to secure crew members during sleep periods, the strap was not able to withstand the loads that the crew member could apply from a hunched\/pulling position. The strap was never designed to hold the maximum loads that a crew member could apply.","Lesson ID":631}
{"Driving Event":"During the STS-90 flight, one of the experiment habitats located in the shuttle Middeck area experienced a mild over-temperature condition. Post-flight evaluations revealed that the habitat's air inlet filter was partially clogged restricting airflow into the cooling system. Human hair, lint, and miscellaneous debris clogged the filter. Further investigation revealed that many air filters in the Middeck area are similarly blocked and that most payload developers count on the crew to perform daily cleaning of these filters. In order to minimize the impact of the debris and to allow for proper airflow, several design considerations were identified.","Lesson ID":629}
{"Driving Event":"When performing ground based functional testing of space flight hardware, it is difficult to perform accurate thermal testing. This is because natural hot air convection is present during ground based testing, and it is not a factor in the microgravity environment of space flight. There have been several instances where this factor has been forgotten and where the resultant thermal testing was not representative of the in-flight conditions.","Lesson ID":630}
{"Driving Event":"During the STS-90 flight, two of the internal air circulation fans within the Research Animal Holding Facility (RAHF) failed to operate. To successfully complete the mission, an in-flight procedure was utilized to maintain the required air flow. Upon landing and recovery, an investigation was conducted to determine the cause of the failed fans. A small (approximately 6.0 X 0.5 X 0.1 inch) cloth\/velcro strap was found to have been ingested into the RAHF air flow, and was eventually pinched between the fan blade and the rotor housing causing the fan to stop. The cloth strap came loose from another piece of stowage hardware and was apparently ingested into the RAHF through an opening while one of the removable rodent habitats was being removed or replaced. While the RAHF has an inlet filter over the main air inlet to the unit (that would have stopped this strap), it does not have a filter directly in front of the circulation fans that would catch any debris in the system, regardless of source.","Lesson ID":628}
{"Driving Event":"During final assembly of the Deep Space 2 (DS2) Mars Microprobes, each of the two flight probes was inadvertently powered. [D] When Mars 98 lander reaches Mars and the DS2 probes are released from the lander cruise ring, a MOSFET electronic switch will apply battery power to each probe. This switch, whose design heritage is unclear, is to be operated only once during the mission. Two mechanical switches are used to provide hold-off bias voltage to prevent the electronic switch from turning on until the probes are released. Both mechanical switches must be activated to power the probes, which then remain powered unless all system power is lost. Although a safing plug keeps the electronic switch biased to the off condition during early phases of assembly, the design required its removal well before the completion of electrical assembly. The overall system implementation included the following deficiencies and vulnerabilities that were not well understood and were not adequately accounted for in the system design, the Failure Modes and Effects Criticality Analysis (FMECA), and assembly planning: The electronic switch design permitted the probes to be powered if any of the wires connected to the mechanical switches were even partially connected to ground. An estimated resistance to ground of 1.5 megohm or less is sufficient to turn on the switch. The anomaly investigation determined that even the body resistance of the assemblers connecting the wires was sufficient to cause this very sensitive electronic switch to turn on. The design of the mechanical switches allowed an unintentional ground path to the probe aeroshell. This would inadvertently power the probes during assembly, causing loss of the DS2 mission due to an undetected battery depletion prior to launch. The design did not permit the safing plug to remain installed throughout electrical assembly. The electronic switch circuit design required external power while the batteries were being connected. Following completion of the anomaly investigation, design changes were made to electrically isolate the mechanical switches and retain the safing plug in place during electrical installation of these switches. Procedures were changed to require extreme care to avoid stray resistances due to handling following removal of the safing plug. Additional Keyword(s): Power Switch, Design for Testability, Design for Manufacturability, Inherited Design, Sneak Circuit Analysis (SCA), System Integration and Test, Hardware Fabrication and Test, Hardware Safety, System Development Reference(s): JPL Problem\/Failure Report (PFR) No. Z48923, November 8, 1998.","Lesson ID":626}
{"Driving Event":"The Tethered Satellite System (TSS) Satellite Support Assembly (SAA) was inadvertently scheduled for delivery to the Florida Space Institute prior to de-integration of live ordnance. The scheduled delivery resulted from a request for donation of the SAA following utilization of TSS on STS-75. During offload operations of the SAA at Cape Canaveral Air Force Station (CCAS), a technician recognized six NASA Standard Initiators (NSI's) still installed on the hardware. The NSI's were all examined and determined to be \"live\" category B ordnance with Faraday caps installed. Explosive Ordnance Disposal (EOD) personnel then removed the six devices for proper disposition. The remainder of the satellite equipment was subsequently closely examined to verify there were no other hazards. No personnel were exposed to the live NSI's. The event was classified as a \"Close Call\" and entered into the Incident Reporting Information System (IRIS) database for review and implementation of corrective action(s). The cause of this incident was determined to be inadequate configuration control of flight hardware during the de-integration process. This resulted in a loss of accountability for hazardous items integral to the design. This is a situation particular to flight hardware not scheduled for re-flight. Hardware scheduled for re-flight (unlike TSS) possess adequate configuration control of hazardous items.","Lesson ID":623}
{"Driving Event":"The Lewis Spacecraft was procured by NASA via a 1994 contract with TRW, Inc., and launched on 23 August 1997. Contact with the spacecraft was subsequently lost on 26 August 1997. The spacecraft re-entered the atmosphere and was destroyed on 28 September 1997. The Lewis Spacecraft Mission Failure Investigation Board was established to gather and analyze information and determine the facts as to the actual or probable cause(s) of the Lewis Spacecraft Mission Failure. The Board was also tasked to review and assess the \"Faster, Better, Cheaper\" Lewis spacecraft acquisition and management processes used by both NASA and the contractor in order to determine if they may have contributed to the failure. The investigation process used by the Board was to individually interview all persons believed to have had a substantial involvement in the Lewis spacecraft acquisition, development, management, launch, operations and the events that may have led to the eventual loss. These interviews were aimed at not only understanding the facts as they occurred but also at understanding the individual perceptions that may have been instrumental in the decisions and judgments as made on this Program.","Lesson ID":625}
{"Driving Event":"The Scatterometer Electronics Subsystem (SES) for the Sea Winds spacecraft featured six semi-rigid coaxial radio frequency (RF) cables spanning two independent structures within the SES. After two cables failed during the initial SES vibration test, four additional cycles of redesign and test were required before the cables were judged acceptable. Two of the five tests were performed on SES protoflight models (PFM) and three on structural mass models (STM). Each of the six cables required varying degrees of redesign, including changes to cable material, strain relief, mounting configuration, and bonding, that impacted the Sea Winds schedule. [D] The process of cable redesign and retest is complicated by lack of repeatability. Minor uncontrolled variations in cable manufacture, routing, and mounting; JPL quotimprovementsquot in the cable configuration; and differences between the PFM and STM units, alter the dynamic characteristics of the test article. Furthermore, cracks in semi-rigid cables are very difficult to detect while they are installed. Cable failures may not be visually detected until the cables are removed from a test model, but they cannot easily be removed for inspection without damaging the cables and invalidating the vibration test results. If a cable failure was not detected and the SES was launched with a cracked cable, thermal transients could widen that crack, and the resulting signal attenuation could cause loss of science data. Additional Keyword(s): developmental model, coaxial cable, coax cable, waveguide Reference(s): JPL Problem\/Failure Report No. SWD075 J. Forgrave and C. Farguson, quotConcerns Regarding Q-SCAT\/Sea Winds SES Semi-Rigid Cable Qualification Status,quot JPL IOM 5052-98-045 of 3\/1\/98. C. Kuo, quotFatigue Analysis if SES's Coax Cables,quot JPL IOM 352G: 98:025\/CPK of 5\/11\/98.","Lesson ID":624}
{"Driving Event":"At the beginning of Cassini Assembly, Test, and Launch Operations (ATLO), the readiness and condition of the JPL Environmental Test Laboratory equipment was poorly understood. Vibration testing of the massive Cassini spacecraft was performed using facility test equipment that was barely up to the task. Proof mass vibration tests had to be aborted due to instrumentation problems. Since not all elements of the standard instrumentation suite were needed, various test instruments were uncoupled until the configuration provided a workable subset. The amplifier used to drive the shaker was approaching the end of its useful life during the Cassini proof mass vibration tests. The power amplifier includes 3000 power transistors on 10 circuit boards. Several days were spent getting the amplifier operational. Powering the amplifier resulted in multiple failures of the test equipment, including board fires. The resultant uncontrolled shutdown of the shaker would have posed a significant risk had the test been conducted on flight hardware. The Cassini project had to devote resources for repairing and upgrading the test facility so that the flight spacecraft could be tested. Additional Keyword(s): system safety, test instrumentation, dynamics test, acoustic test, test planning, test-induced failure, Management and Planning, System Integration and Test, Hardware Fabrication and Test Reference(s): Cassini Spacecraft Assembly, Test, and Launch Operations (ATLO) Final Report, Volume I, JPL Document D-15701, May 15, 1998, page 151.","Lesson ID":622}
{"Driving Event":"Upon closing a Shuttle AC Motor Valve during a cycling test, the pressure force differential across the valve deformed the Teflon interface a1dapter for a butt joint at the valve outlet port. The valve slipped free at the inlet port and approximately 160 gallons of Freon 113 was sprayed into the room at 250 psig and 56 gpm. Employees there immediately evacuated the room and suffered no ill effects. There was no equipment damage, but the Freon and productivity losses were costly. Flow benches and tooling for several components were supplied together by the original equipment manufacturer (OEM) to transfer repair operations of these components to WSTF. Safety reviews, subsequent modifications, and personnel training for the motor valve addressed only a valve using a slip joint upstream and a butt joint downstream to facility lines. No other configuration of this valve was known to the reviewers or specifically identified by the OEM to WSTF. An engineer new to the project received a valve with a smaller diameter outlet port for which the OEM had used the adapter to make the butt joint with the facility line. Because the adapter was already available among the tooling, the new project engineer believed it had been included in the system reviews, when it had not been. The OEM, in addition, had recently changed the material from which the adapter was made, from stainless steel to Teflon, to avoid scratching the valve, but transferred ownership prior to using the Teflon adapter and realizing its potential for failure. Losses and hazards were maximized because the supply valve to the Freon tank was inaccessible, being in the direction of spray, and there was no isolation valve on the supply tank. In addition, the emergency instructions did not explicitly address significant Freon leakage.","Lesson ID":620}
{"Driving Event":"While performing a functional retest of a Shuttle hatch movement, following a hatch actuator R&R, the GSE support structure failed. As a result, the hatch hinges and hinge arm mechanism were potentially subjected to the full unsupported weight of the hatch.","Lesson ID":614}
{"Driving Event":"In preparation for a scheduled Extra Vehicular Activity (EVA) during STS-80, the crew discovered that they were unable to open the airlock outer hatch.","Lesson ID":615}
{"Driving Event":"To meet environmental requirements, a program decision was made to change the Pressure Sensitive Adhesive used in the J-flap of the segment of the Shuttle Reusable Solid Rocket Motor (RSRM) and the solvent used in the joint cleaning process. A new Pressure Sensitive Adhesive was acquired and a solvent-based cleaning wipe was replaced with an aqueous-based joint cleaning process. Post flight analysis of the RSRM flight article revealed greater than expected erosion, sooting and heat effects on the insulation interfaces.","Lesson ID":613}
{"Driving Event":"Water flow pump impeller blade tips failed during testing at MSFC's Inducer Test Loop (ITL). All three inducer tips were discovered missing during inspection of the pump. An investigation team determined that impeller tip failure was caused by degradation of aluminum impeller material (caused by anodizing and\/or heat treat) and\/or high impeller dynamic flow forces.","Lesson ID":616}
{"Driving Event":"At approximately 4 p.m. on June 7, 1996, a liquid oxygen fire occurred in the \"A\" Leg of the LOX feed system for the 750k lb. position of Test Stand 116 located in the East Test Area of MSFC. The fire occurred as the \"A\" Leg engine shutoff valve reached the \"20T open\" position while closing after completion of the fourth of a series of six planned set point tests. These test were being conducted to provide data for establishing the correct throttle valve setting for subsequent planned hot fire testing of a 650k lb. Thrust Chamber Assembly provided by Rocketdyne. At the time of ignition, the \"A\" Leg shutoff valve had closed far enough to permit it to take control of the LOX flow from the venturi. The LOX fire started in the seat region of the valve, progressed from the engine shutoff valve outlet to the test article within 120 ms, and burned for approximately 25 seconds. For the first 8 seconds, the fire was fed by high pressure LOX. The fire partially consumed the lower part of the engine shutoff valve body, the two elbows and straight pipe section that connected the engine shutoff valve and the test article. The test article, all instrumentation devices, hydraulic fluid lines, control wires and cables on the stand were destroyed. The hydraulic fluid fire primarily charred pipe insulation and coated the test stand and its equipment with soot.","Lesson ID":617}
{"Driving Event":"[D] Wax thermal actuators are high reliability devices used to trigger spacecraft deployment mechanisms. Following launch, the Deep Space 1 (DS-1) solar arrays were released by powering the primary heaters in four high output paraffin (HOP) actuators. The HOP heaters were powered for three minutes and, as designed, the HOPs activated in 70-90 seconds after the heaters were powered. The secondary heaters in the HOPs were not powered. Eighteen days later, a spurious signal issued by the power distribution logic re-powered the primary HOP heaters. After ten minutes of heating, telemetry indicated a short in a HOP that caused the current to increase by approximately 6 amps. Over the next few minutes, all four primary heater circuits failed open, and evidence derived from telemetry indicated that at least three of the four primary heaters bridged to their corresponding secondary heaters. A trace rated for only 1.6 amps in the power distribution circuit board could easily have been damaged by the short-circuit current of 6 amps. Had this resulted in an open circuit in the power distribution board instead of the HOP, the mission could clearly have been jeopardized. Additional Keyword(s): Wax Actuator, HOP Actuator, Electrical Short, Pyro Reference(s): JPL Incident Surprise Anomaly (ISA) No. Z50426","Lesson ID":612}
{"Driving Event":"Since 1980, the Materials Engineering Branch has been involved in operational life testing of spacecraft components. These include encoder lamps and light emitting diodes, calibration lamps, signal amplifiers and support bearings for scanning mechanisms. Many of these life tests were initiated to demonstrate that life sensitive components would meet mission lifetime requirements. Several of the life tests were also used to determine the cause of in-flight failures of components. Besides demonstrating that a component would meet mission lifetime requirements, these life tests also determined useful lifetime and long-term behavior of components. In some cases, the behavior of a component at the beginning of life was used to develop screening techniques to select longer lived parts. Reference(s): 1009454main_0610.pdf by Chuck Powers, 10\/21\/98 (PDF File)","Lesson ID":610}
{"Driving Event":"Careful planning for the acquisition of launch services and interface definition and control is an important success factor for cost and schedule constrained flight projects: Launch service contract stipulations are sometimes retained in a subsequent contract without adequate consideration of their suitability to the applicable flight project. \"Unnecessary baggage\" is a likely consequence of a rush to arrange flight services. In contracting for launch services, the Cassini project accepted the launch service contractor's standard arrangement. This contract retained launch service contractor responsibility for total launch vehicle\/space vehicle (LV\/SV) compatibility and performance. The level of contractor involvement with the spacecraft side of the interface, with an absence of clear decision making authority, was perceived to result in a duplication of effort, negatively influencing project morale. Independently, NASA subsequently directed JPL flight project offices to lead all efforts to ensure mission success. Once the launch services contract is finalized, changes that affect the hardware configuration will likely result in increased program costs. For example, Cassini launch safety analyses indicated the need for changes to LV\/SV hardware and interfaces. Additional Keyword(s): Configuration Management, Configuration Control, Mechanical Interface, Control Drawing, MICD, Spacecraft Integration Reference(s): Cassini Spacecraft Assembly, Test, and Launch Operations (ATLO) Final Report, Volume I, JPL Document D-15701, May 15, 1998, pages 153-4.","Lesson ID":611}
{"Driving Event":"During the terminal countdown for the first attempted launch of Cassini, spacecraft telemetry channels indicated a false alarm condition that delayed verification of spacecraft readiness for launch, and contributed to a delay on the first launch day. In planning for Cassini launch activities, the RED-ALARM strategy was to set critical measurement alarms for telemetry values differing from those expected at liftoff. As expected, pre-launch conditioning generated a number of red alarms, most of which cleared as the spacecraft was brought to the final liftoff state. However, two red alarms did not clear, resulting in the false alarm conditions. This anomaly was traced to erroneous telemetry documentation: the SAFE\/ARM logic states for the two channels whose alarms did not clear were found to be reversed in the data dictionary. The Cassini launch procedure was developed late in the Assemble, Test, and Launch Operations (ATLO) process, and alarm testing with correct parameters was not done. Also, testing of these particular alarms prior to actual launch was not possible at KSC due to safety considerations. The Mars Pathfinder (MPF) project developed their launch procedure early, and subjected it to rigorous, multiple tests during their 18-month ATLO. In this case, additional testing had negligible cost and schedule impact since it was conducted in conjunction with other testing to gain operating hours. Additional Keyword(s): Launch Readiness Review, Operations Readiness Review, Configuration Management, Interface Control Reference(s): Cassini Spacecraft Assembly, Test, and Launch Operations (ATLO) Final Report, Volume I, JPL Document D-15701, May 15, 1998, page 151. JPL Problem\/Failure Report No. Z44319, October 13, 1997.","Lesson ID":609}
{"Driving Event":"The Huygens probe was the European Space Agency's (ESA's) contribution to the joint NASA\/ESA Cassini\/Huygens mission, and it represented the first medium-sized mission of ESA's long-term space science program. This venture required a high degree of collaboration between NASA and ESA's industrial partners in 14 European countries where 10 different languages are spoken. [D] ESA Industrial Partners for the Huygens Probe Control of subsystem interfaces always requires effective interaction between engineers. The complexity of the Cassini\/Huygens interfaces increased the need for clear and unambiguous communication. Since most Europeans use English as a second language, requirements that are clear to JPL engineers may be misinterpreted by foreign partners. When the wording is vague, a requirement or specification may be interpreted many ways. For example, a requirement called for two copies of probe science data to be stored in each of two memory partitions on the dual solid state recorders. Read correctly, this requirement called for a total of eight storage locations, but the lack of a diagram illustrating these assignments confused ESA. Additional Keyword(s): Interpretation, Interface Control, Configuration Management, Joint Venture, International Partners Reference(s): Cassini Spacecraft Assembly, Test, and Launch Operations (ATLO) Final Report, Volume I, JPL Document D-15701, May 15, 1998, page 155.","Lesson ID":608}
{"Driving Event":"The CHeX space flight hardware was damaged at a collaborating university during disassembly and testing after completion of the mission. The cryoprobe, a high value component of the experiment hardware, was dropped approximately 18 inches onto a concrete floor causing significant repairable damage. The drop was caused by failure of the lift fixture during transfer of the cryoprobe to a support structure. Review of the mishap revealed that the lift fixture design was structurally adequate, with load carrying capability of the vertical axis dependent on a double lock-nut system. Prior to the operation, the unassisted lift fixture operator did not detect that the lock nut was missing and that the remaining nut was close to disengagement. This nut did disengage, allowing the flight hardware to drop. The fixture design and test planning were not robust enough to reasonably preclude flight hardware damage. Contributing to the mishap was a failure to follow NASA critical lift procedures for flight hardware, including: Inadequate fail-safe design of the lift fixture. Improper assembly of the lift fixture. Inadequate pre-operation inspection of the lift fixture. Inadequate supervision of the operator. Additional Keyword(s): Human Factors, Crane, Hoist Reference(s): CHeX Hardware Failure Review, 7941:TL-98-007:tl NSS\/GO-1740.9B, NASA Safety Standard for Lifting Devices and Equipment, Nov. 1991 LLIS Number 0267 (JPL #11-115), TOPEX\/POSEIDON Near-Drop Incident LLIS Number 0273 (JPL #11-113), Solar Array Drive (SAD) Drop","Lesson ID":621}
{"Driving Event":"White spots were observed on ten, conformally coated, electrical power subsystem (EPS) printed wiring assemblies. The anomaly was noted when the boards, built as Mars Observer (MO) spares, were withdrawn from long term storage for use as Mars Global Surveyor (MGS) flight hardware. [D] Mealing of MO Spares The spots were identified as quotmealing,quot which involves significant levels of ionic contaminants concentrated primarily at the interface between the conformal coating and the substrate material. Exposure to warm, damp conditions is known to promote the growth of mealing. This growth can cause electrically conductive paths along interfacial surfaces, or between components and traces. Speculated contributors to the problem are: The ionic contaminants may have been imbedded during board manufacture, or at some later time such as during cleaning prior to conformal coating. Moisture normally present within the fiberglass board substrate might also migrate to the interface. Exposure to excess humidity during the 3 years the coated boards were warehoused may have caused atmospheric water vapor to permeate the conformal coating and reach the interface, or prevent dissipation of the moisture from within the board. The ten boards were reworked to remove mealing and eliminate potential electrical anomalies. Narrow strips of conformal coating were removed from critical areas followed by cleaning of the exposed board laminate and touch-up of the conformal coating. Additional Keyword(s): Contamination, Corrosion, Inherited Hardware Reference(s): MGS Problem\/Failure Report (PFR) No. Z20617","Lesson ID":607}
{"Driving Event":"A four inch-diameter cast iron strainer in a 225 psig steam line failed catastrophically, releasing high pressure steam and hurling strainer pieces and attached parts in the equipment building. The steam and projectiles weighing up to 50 lbs. posed life-threatening hazards; however, they caused only minor damage to the steam piping and surrounding equipment. Two employees opening a steam supply valve nearby were not injured. The failure was caused largely by the inappropriate use of material for the strainer. The strainer was manufactured from gray cast iron to ASTM Specification A 126 Class B. A stress analysis was performed by the A&E contractor assuming cast steel construction. The principle stress at the strainer position would not exceed the maximum allowable stress for steel but would for cast iron, as specified in ASME B31.1 (1995 edition). Repeated water hammer effects during operations hastened eventual strainer failure. Upon acceptance of the strainer, material criticality associated with analysis was not recognized as a determining factor in component acceptability. Operating and performance parameters (pressure and temperature) were the principle considerations. Also, the hazard analysis did not address steam line rupture resulting from steam flashing or water hammer. It is common within NASA and industry to dismiss catastrophic failure potential of ASME code-compliant pressure systems as non-credible, given intrinsic safety factors. Procedural problems combined with some malfunctioning steam traps caused the part to be subjected to significant water hammer during system startup. Employees were not instructed explicitly in how to recognize water hammer symptoms.","Lesson ID":606}
{"Driving Event":"During LOX transfer operations in preparation for a Space Shuttle Main Engine (SSME) test (904-362) on the B-1 test stand, a LOX pump (barge #1, pump B) over pressurized, initiating a fire on barge #1. The fire was extinguished and mishap investigation procedures were initiated. The primary cause (determined by the board) was the backing out of a retaining screw during LOX pump B operations. Further investigation highlighted the following: SSC's procurement (post 1988) of pump casings with configurations that were not per design (beveled area around retaining screw area), and Wear rings for the pump are re-used after pump rebuild if no evidence impeller to wear ring wear exists. The incident caused no injuries; however, damage to equipment including the barge, motors, lines, and decking is estimated at approximately $250,000. In addition, the pending SSME test was cancelled and rescheduled.","Lesson ID":605}
{"Driving Event":"The following was originally published by New Scientist magazine and picked up by Reuters. Two different JSC engineers have indicated that these radiation issues can cause concerns for NASA systems. The article is quoted verbatim. (from New Scientist\/Reuters) Microchips are growing smaller, but their diminishing size exacts a price. Tiny circuits are vulnerable to radioactive interference that could cause a simple blip in your cell phone or a far more serious kind of crash, New Scientist magazine reported Saturday. When chips are miniaturized, they require less electrical charge to store each bit of information. Those decreased voltages also mean that the chips are less prepared to cope with low-level ambient radiation. \"Unfortunately, the price we pay for smaller chips is as each chip has less voltage to work with and less charge, it can be more sensitive to some of these soft error events,\" said Robert Bauman, manager for embedded memory and analog reliability at Texas Instruments. Radioactive interference can come from neutrons in the atmosphere or from the materials used in building the computer equipment, such as lead solder, silica molds, and the phosphoric acid used for etching. Those materials all emit radioactive alpha particles. \"There is no simple solution to these things, we need to work with the materials-technology people to insure that the equipment contains fewer radioactive impurities,\" said Chand Viswanathan, professor of electrical engineering with the School of Engineering & Applied Science at the University of California at Los Angeles. Most PCs now use microchips with transistors between 330 and 250 nanometers across. The next generation of microprocessors should shrink to below 180 nanometers, making them more susceptible to interference. A nanometer is one-billionth of a meter, roughly one-hundredth the width of a human hair or the size of one bacterial cell. Aircraft systems could face the worst problems of all, because the risk of interference goes up with the altitude. \"When you are flying five or six miles up, you're subject to more cosmic radiation effects,\" Viswanathan said. Texas Instruments has been working on the problem for almost a decade. \"When you're doing your system design, whether it's memory or high performance DSP, it's important to have this radioactivity problem in mind as you're designing it. None of these problems are insurmountable,\" Bauman said. \"There's always a solution. The question is, what's the cost of solving it, and what's the cost if you don't solve the problem?\" Bauman said. \"The risk depends on the applications and the acceptable error rate-you have to factor that in. The best case is to design the system so there's no error.\" One solution would shield the equipment from potential radiation, but that could prove impractical since some shields would have to be 10 feet thick. Equipment could also be placed in a basement, Bauman suggested. Another solution might be for designers to harden the chips against the effects of radiation, Viswanathan said. \"The bottom line is, because it entails knowing nuclear physics, engineering, and so many varied disciplines, it's not obvious to most people that it's a problem,\" Bauman said. (from NanoSpace 98) Scaled Silicon MOS is not nanotechnology. In contrast, recent measurement by the Naval Research Laboratory and Texas A&M show that nanosized quantum devices (Nanoelectronics) are extremely radiation tolerant and have the potential to lower power and increase speed in advanced signal processing and storage space systems. This was briefed at the NanoSpace 98 conference last week. For details on the nanosized quantum devices, contact Steven Watson of SAIC at (281) 244-1747 or Gary Frazier of Raytheon Systems at (972) 344-3634.","Lesson ID":604}
{"Driving Event":"Several JPL flight projects obtained low cost, commercial quality, hybrid DC-DC power converters from a single vendor which proved unsuitable in some intended applications. The sensitivity of this family of converters to load, ground, and input\/output power conditions was not evident in the vendor documentation. Specific DC-DC power converter design limitations involved several different failure mechanisms including: Use of a sync circuit external to the converter frequently coupled noise into the internal pulse width modulator (PWM), keeping the power FET (field effect transistor) saturated, which led to its eventual failure. [Reference (1)] Imbedded electromagnetic interference (EMI) filters in most of these converter designs lacked a damping resistor; the resulting instability kept the FET saturated until it failed. [Reference (2)] The startup capabilities of these converters were insufficient for the Mars Pathfinder (MPF) mission worst case cold temperature. Slow input voltage rise time resulted in failure of the converter to turn on due to PWM regulator latch-up. A JPL tiger team was able to resolve these problems through external and\/or internal design changes with significant schedule and budget impact. Also see Reference (3) for related vendor issues. Additional Keyword(s): Parts Procurement Reference(s): JPL Problem\/Failure Analysis Reports (PFARs) No. 6419, 6978, and 6950 GSFC Failure Analysis Report (FAR) No. FA78126 \"Commercial Electronic Parts Supplier Evaluation,\" JPL Lesson Learned No. 9-121. C. B. Stell, \"Off the Shelf Power Converter Unit Electrical Performance Evaluation, Jet Propulsion Laboratory, February 2, 1998.","Lesson ID":603}
{"Driving Event":"The Mars Pathfinder (MPF) project experienced initial workmanship problems with hybrid DC-DC power converters from a vendor who supplies primarily low cost commercial parts. Working closely with the vendor to improve manufacturing processes and quality, the MPF project was able to obtain some acceptable parts. This successful MPF experience led the Seawinds, QuickScat, Deep Space 1, Stardust, and Mars 98 projects to purchase similar converters from this vendor. However, vendor process changes since MPF led to significant quality problems with the production lots for these projects. A JPL tiger team was formed to address these quality problems. Significant project costs were incurred in resolving the issues and reworking the converters. The JPL electronic parts procurement practice had been to check the date when the vendor was last surveyed by JPL Quality Assurance. Where no recent survey had been performed, the project funded a new on-site vendor survey. This review of vendor manufacturing processes, procedures, and controls resulted in approval, conditional approval, or disapproval of the vendor. Despite the increased utilization of low cost commercial quality parts, this JPL practice has fallen into disuse due to small projects' budget constraints. Additional Keyword(s): Quality Audit, Supplier Audit","Lesson ID":602}
{"Driving Event":"Innovative, low cost approaches to NASA spaceflight missions may include a reduced inventory of flight hardware spares. However, experience throughout JPL flight project history illustrates the importance of an adequate supply of spare power subsystem modules. Both the Galileo and Deep Space 1 projects sustained major damage to power subsystem modules or assemblies due to spacecraft equipment failures during ground test and integration. Since high voltage and current exist in power subsystems, failures that affect power equipment tend to cause more hardware damage than other electrical failures. Occasionally during ground test, short circuits occur which char spacecraft power subsystem components or vaporize modules to the extent that they are unrepairable. If this occurs close to the launch date, acquisition of replacement units may be impossible without impacting the launch schedule. Additional Keyword(s): PPS, Power Module, Power Converter Unit, PCU, GLL, DS1","Lesson ID":601}
{"Driving Event":"In recent years, performance problems with onboard nickel cadmium (NiCd) rechargeable batteries drastically affected the lifespan of several Department of Defense satellites. NiCd batteries are currently used for an entire class of NASA observatory spacecraft, including TOPEX, Extreme Ultra-Violet Explorer (EUVE), Upper Atmosphere Research Satellite (UARS), and Gamma Ray Observatory (GRO). NASA postulated that optimizing onboard battery performance could extend the life of these batteries, and thus the potential life of the spacecraft. JPL was asked to review existing NiCd battery management techniques to determine their effectiveness in achieving optimal flight performance. A ground battery testbed was created to evaluate the operational parameters affecting battery life, including peak charge current and depth-of-discharge. Environmental factors such as battery operating temperature were also considered. Three existing NiCd batteries were evaluated. The experimental protocol made use of the \"Taguchi Methods of Robust Design\" techniques and applied them to determine the optimum management of battery operation. Testing confirmed that a change in battery management practices reduced the cell-to-cell voltage variations (in this case by 96 percent), which significantly improved the performance of this battery type. Reference(s): J. Blosiu, F. Deligiannis, S. DiStefano, \"Optimization of Battery Operation Management Using Robust Design.,\" (JPL Technical Paper).","Lesson ID":599}
{"Driving Event":"JPL flight projects have a history of susceptibility to corona when exposed to regimes of critical pressure during ground test and flight: Ranger 6 (in-flight): During launch the camera was inadvertently powered. In addition a nearby enclosure was insufficiently vented for boost pressure decay. As the spacecraft passed the critical pressure region, a corona discharge occurred, disabling the camera system. The result was a complete loss of imaging data. 1971- Mariner Mars (ground): During acceptance testing, it was found that a lack of RF breakdown margin at critical pressure necessitated costly design changes. 1971- Mariner Mars (in-flight): Unexpected battery venting caused a brief critical pressure region around the high voltage Canopus star tracker, resulting in a corona discharge. The arc caused a ground-loop current spike that resulted in the permanent loss of 22 telemetry channels in the Flight Data Subsystem (FDS). 1976- Viking 2 (in-flight): The Viking Lander's downlink failed while on the surface of Mars. This suggested that the high voltage power converter developed a corona discharge and high voltage breakdown while in the critical CO2 pressure region present near the surface of Mars. [D] 1976- Voyager (ground): Design verification disclosed voids in certain capacitors which could bleed down to critical pressure after long exposure to vacuum, and could lead to a corona discharge. 1988- Galileo (ground): The vendor's vacuum chamber was purged with dry nitrogen while the extreme ultraviolet (EUV) instrument was powered. This produced a critical pressure region, corona discharge, and failure of the EUV high voltage power supply. 1989- NSCAT (ground): Windings added to a traveling wave tube amplifier (TWTA) transformer for test purposes, resulted in increased voltage in the primary windings, which triggered a corona discharge. 1989- Magellan (in-flight): The pyrotechnic firing which separated the solid rocket motor, used for Venus Orbit Insertion, resulted in a plasma arc, a ground current loop, and destruction of a significant amount of spacecraft memory. 1990- Mars Observer (ground): Due to inadequate insulation of the TWTA, a corona discharge occurred at critical pressure during evacuation of the vacuum chamber. Additional Keyword(s): Electrostatic Discharge Reference(s): JPL D-8208, Design and Fabrication Requirements, Section 3.9: quotHigh Voltage Requirementsquot, Rev. C, March 15, 1997. A. Whittlesey, quotMISR Corona Issues,quot JPL IOM 5215-94-75 (MISR DFM # 380), March 17, 1994. quotProceedings of the Second Workshop on Voltage Breakdown in Electronic Equipment at Low Air Pressures on March 5-7,1969,quot JPL TM-33447, June 30, 1970. quotRF Breakdown in Mariner Mars '71 RFS Components and Circuits,quot JPL Lesson Learned No. 3-115; JPL Problem Failure Report (PFR) No. 100789. quotHigh Voltage Capacitor Used in Voltage Doubler Circuits for Space Applications,quot JPL Lesson Learned No. 3-117. quotTraveling Wave Tube Amplifier on Martian Surface: Failure Due to Corona,quot JPL Lesson Learned No. 3-119; Viking Incident Surprise Anomaly (ISA) Report No. 15643, October 13, 1976. JPL Galileo PFR No. 44450. JPL NSCAT PFR Nos. 52102 & 52103. JPL Mars Observer PFR No. F0745. JPL Magellan PFR #52235.","Lesson ID":598}
{"Driving Event":"The Lewis implementation had a flawed attitude control system (ACS) design and simulation deriving from technically invalid application of a design from an earlier mission. This misapplication ultimately led to the spacecraft failure when the system encountered an untested instability during a \"safe hold.\"","Lesson ID":595}
{"Driving Event":"During the critical initial on orbit operations and checkout phase, ground station personnel did not monitor the Lewis spacecraft continuously for anomalies. This was accepted based on a false belief that the spacecraft had a stable safe-mode that it would switch to automatically if anomalies were not immediately corrected. (In the Lewis implementation, the safe-mode was neither stable nor robust.) The situation was further exacerbated by the fact the spacecraft was in an interim (low altitude) orbit which had high drag and short on-station communications intervals and for which the designers had not carried out modeling.","Lesson ID":597}
{"Driving Event":"The Mars Pathfinder (MPF) avionics and flight software development effort focused on producing a software architecture that would contribute to lower operations cost and minimize the overall project cost. Additional Keyword(s): Software Life Cycle, Life Cycle Cost, Concurrent Engineering Reference(s): Glenn Reeves, \"Mars Pathfinder Flight Software Lessons Learned,\" April 28, 1997. \"Mars Pathfinder Flight Software Development Process,\" JPL Lesson Learned No.10-105, June 4, 1998.","Lesson ID":593}
{"Driving Event":"The SEPICA instrument, one of 9 instruments flown on the ACE Mission, uses isobutane gas as part of its particle detection scheme. Three proportional counters, one associated with each of SEPICA's 3 detectors (1-high resolution, 2-low resolution), were to be held at a constant pressure by the use of a Commercial-Off-The-Shelf (COTS) bi-metallic micro-machined silicon valve assigned to each of the detectors. Following one month of flawless operations, detector operations indicated pressure being maintained slightly higher than pressure set point. It was thought that this state could be attributed to a loss of valve seat tightness or to a fundamental shift in valve baseline response. Approximately 6 months following launch, pressure in the high resolution detector totally decayed to zero at a rate consistent with that of a normal closed-valve rate. Analysis of the pressure decay and the inability to command the valve seems to indicate that the valve associated with this detector is in a closed state and there exists a lack of ability to flow required current across the system to open the valve. Although unproven, analysis seems to indicate the failure is within the valve. Impact of this failure to mission and instrument science is minimal due to a combination of the availability of high resolution data obtained earlier in the mission, the continuing availability of the other 2 SEPICA low resolution detectors, and the availability of complementary science from other ACE instruments. Although pre-mission analysis did indicate inconsistent workmanship in the chosen COTS valves, it was determined that these COTS valves were the only acceptable design approach given mission limitations (e.g., power, mass, etc.) and that the risk mitigation approach to select the best valves through instrument team-led filtering process and the performance of extensive ground testing was consistent with the mission\/instrument class (i.e., mission was Class C and instrument suite was Class D). Considerable experience was gained in extensive pre-launch and post-launch ground testing which was performed at on-orbit thermal and vacuum conditions. However due to safety concerns, the majority of life testing on the spare unit at the University of New Hampshire was performed with nitrogen, rather than the on-orbit isobutane gas. The use of nitrogen did not necessarily fully simulate effects in the on-orbit configuration due to the different properties from the on-board gas. Post-anomaly evaluation also indicated that, although the spare gas system had undergone some level of vibration test, the valves had been replaced afterward. The flight valves that are being tested in the spare have not been vibrated at all and, therefore, may not be an adequate model of the on-orbit valves. The valve manufacturer did supply recommended valve operational boundaries (e.g., duty cycle, power, etc). In some of these areas, the on-orbit valves were operated on or near the manufacturer's recommended boundaries and, in the area of duty cycle, the valves were operated outside of the manufacturer's documented recommendations with verbal confirmation from the manufacturer that the out-of-boundary conditions should be acceptable. The selected valve was a commercial product, is no longer produced by the vendor, and vendor-expertise is no longer available. No on-orbit back-up\/redundancy to control the gas flow, possibly in a degraded fashion, in case of failure of the valves was developed or contemplated.","Lesson ID":594}
{"Driving Event":"The Microgravity Smoldering Combustion protoflight unit was flown on the STS69 shuttle mission. Resulting flight data indicated anomalous readings from two thermocouples. Both channels had noticeable noise, and readings, which were higher than anticipated for the condition. Since the igniter algorithm uses this information to initiate igniter shut-off the igniter was shut off prior to establishing desired conditions in the foam for smoldering completion.","Lesson ID":592}
{"Driving Event":"Two satellites with different propulsion system designs were lost in 1993 and 1994. Limited telemetry was received on the incidents. Subsequent failure investigation focused on possible propulsion feed system design flaws. In both cases, pyrovalves were used to isolate the hydrazine supply until the satellite was separated from the launch vehicle. [D] In accordance with a common design practice for engine feed systems, two pyrovalves were placed in parallel to provide redundancy. With the hydrazine tank isolated, pressurized fuel was present upstream of the pyrovalves (e.g., Point A), but only a dry nitrogen quotpad gasquot at low pressure downstream of the pyrovalves (e.g., Point B). On one spacecraft it was unclear what the gas composition was and whether it was totally vented through the thruster prior to the priming event. During priming of the hydrazine system, the primary pyrovalve was fired to charge propellant lines leading to the engine. When the propellant reached the thruster valves and stopped, it produced a pressure surge. Under certain conditions, this surge could cause exothermic decomposition of the fuel, and tests were conducted to assess if the prevalent conditions were conducive to exothermic decomposition. This particular failure mode was never observed during the failure investigations. However, when the backup pyrovalve was fired a second later during one test, the blow-by of hot gas into the lines between Points A and B detonated the decomposed fuel; this then breached the fuel lines on both sides of the backup pyrovalve. The tests did not exhibit this detonation failure mode when, just prior to firing the backup pyrovalve, the pad gas was evacuated to leave a vacuum downstream of both pyrovalves. Reference(s): GIDEP Advisory No. GH-P-94-01, quotPyrovalve, Titanium, 1\/2quot, Normally Closed Single Initiates,quot Revised May 1, 1995.","Lesson ID":591}
{"Driving Event":"On May 16, 1998, MSFC held an quotOpen Housequot for the public. During the event an elderly woman fell from the rear of a NASA owned and operated utility vehicle, hitting her head on the pavement. The visitor was taken to the hospital and fortunately released with no serious injuries. An investigation determined that the woman requested the vehicle driver to take her to another location within the Center. She sat on the rear bed of the vehicle. When the vehicle moved forward she slipped off. The utility vehicle is a 4 wheel skooter with a small flat bed manufactured by Cushman (see photos below).","Lesson ID":589}
{"Driving Event":"On October 8, 1997, a 7,000-pound Solid Rocket Booster Holddown Post (HDP) slid off a forklift while it was being moved up a slight ramp into the low bay of building M7-505 at the Launch Equipment Test Facility (LETF). Neither damage to the holddown post nor injuries to personnel occurred during this near miss. Root Causes: Design: The less than optimal design of the shipping\/handling pallet and the load restraint configuration of the HDP provided a minimal margin for stability (see figure 1). Procedure: The forklift operator's lack of attention to the HDP configuration and good forklift operating practices contributed to the unstable conditions. Environment: Storage of equipment in the rollup door area hindered the forklift's approach and contributed to the improperly angled entry into the area.","Lesson ID":588}
{"Driving Event":"Recently a quotClose Callquot involving the unintentional over-pressurization of a low pressure system designed to operate at less than 150 p.s.i.g. The system was opened to a pressure of 2300 p.s.i.g. for a fraction of a second until a shop air hose, rated for 300 p.s.i.g., ruptured into two sections. It was fortunate that no one was hurt as the potential for serious injury was very real. The sequence of events was started with a work-around that was initiated to replace the shop air (which was out of specification) in the LubeLok spray booth with compressed air from a supplied Manifold K-bottle Rack. The engineer in charge misread the Rack's pressure gauge and quotassumedquot the output pressure was 160 p.s.i.g. when what he had read off the gauge (see picture) was 160 BAR, approximately the equivalent of 2300 p.s.i.g. Root Causes: Failure to pay attention to details because no one involved took the time to correctly observe the high pressure indicated on the gauge. (see picture) Lack of training and failure to take time to understand the Manifold Rack's design which would have revealed that there was no pressure regulator built into the Rack system. Failure to develop detailed work authorization documents to perform work on a Safety Reviewed system that processes Flight Hardware and which requires quotmaterial specificationsquot. No gauge or pressure indication visible from control valve.","Lesson ID":587}
{"Driving Event":"JPL required the use of a reference antenna to verify the Huygens Probe to Cassini high gain antenna (HGA) RF link. A test had been developed to use right and left-circular polarized (RHCP and LHCP) antennas to verify the polarization of both the Probe and HGA antennas, used for the transfer of science data during the probe's descent to the surface of Titan. JPL purchased an off-the-shelf RHCP conical log spiral antenna for this test; the vendor provided a calibration certificate which certified the candidate ground support equipment (GSE) antenna to be right-circular polarized. When the commercial antenna was used as a reference standard during a spacecraft-level RF compatibility test, it indicated that the spacecraft and probe antenna polarizations were both incorrect. When further investigation between international partners could not substantiate this indication, the GSE reference antenna was tested against other antennas of known polarization and found to be mislabeled. The product featured a biwire winding which effectively reversed the polarization to LHCP, resulting in a left polarized emission from an apparently clockwise-wound spiral antenna. The manufacturer revealed that the antenna labeling was not in accordance with accepted standards, and that the product had been marketed as RHCP for over 10 years. Since the antenna had been used in EMC testing mostly as a broadband source or receiver, users were rarely concerned with polarization. As shown in Figure 1, the physical appearance of the reference antenna structure - a clockwise helix - supports the standard definition of RHCP, but the electrical performance indicates LHCP. [D] A Typical Conical Log Spiral Antenna Additional Keyword(s): COTS, Receiving Inspection Reference(s): Cassini Problem\/Failure Report No. Z23529, October 21, 1996. K. Kellogg & W. Moore, quotProbe-Spacecraft Antenna End-to-End Failure Investigation Report,quot JPL IOM 3360-96-14, October 17, 1996. Lesson Learned #11-121, Ground Support Equipment Failure Caused Damage to SEASAT-A","Lesson ID":586}
{"Driving Event":"Missions using aerobraking employ atmospheric drag to reduce the spacecraft orbit period and lower its apoapsis altitude. The technique requires tight control both on the attitude pointing of the spacecraft while in the atmosphere, and especially on the altitude during each aerobraking drag pass at periapsis (the orbit's closest approach to the planet). Targeting periapsis altitudes is critical to assure that the proper orbital conditions are achieved. The periapsis altitude is controlled by periodically performing small propulsive aerobraking trim maneuvers (ABMs) one-half of the orbit period earlier. This places the spacecraft at the other side of the orbit, near apoapsis, the point in an orbit at which the spacecraft is at furthest distance from the planet. A portion of the Mars Global Surveyor (MGS) spacecraft memory was allocated and managed as storage space for command sequences and programs uplinked from Earth, such as aerobraking maneuvers. These sequence loads are typically created by the flight project's sequence team with inputs from the spacecraft and science operations teams. Extra Burn Anomaly. An unintended repetition of MGS Aerobraking Maneuver #5 occurred after the intentional burn on November 12, 1997. The planned maneuver's objective was to decelerate the spacecraft 0.1 meters per second (m\/s) to enable an aerobraking pass 17 hours later. This maneuver executed as expected. [D] Aerobraking Operations Approximately 3 hours later, the spacecraft unexpectedly repeated the aerobraking maneuver, imparting an additional delta-v to the spacecraft. To avoid a deeper penetration into the Martian atmosphere, the flight team designed, uploaded, and successfully commanded a third quotantidotequot maneuver, which counteracted the effect of the unplanned second maneuver. Although the mission impact of this incident was limited to expenditure of propellant in the 0.5 m\/s remedial burn, occurrence at another time could have been mission catastrophic. The cause of the incident was traced to an incompatibility between ground and flight software. A new version of the ground software had been installed in the ground data system one day earlier than planned without adequate review of the consequences of the schedule change. This new software had been redesigned to improve programming and command efficiency. Certain memory partitions were reassigned in on-board memory, and this software package needed to be installed on the ground system at the previously agreed to time relative to the command uploads. Due to the address changes, the recently executed Aerobraking Maneuver #5 was loaded into the partition originally intended for the next science sequence. Hence, when the spacecraft command data subsystem (CDS) executed quotNext Sequence,quot the Aerobraking Maneuver #5 sequence was still present in memory, and it was performed instead of the science sequence. Reference(s): JPL Incident\/Surprise\/Anomaly (ISA) Number Z44658, November 23, 1997","Lesson ID":584}
{"Driving Event":"[D] MGS Prepared in Vacuum Chamber for System-Level Testing Propulsion systems are normally kept at a net positive pressure. During a regional public service power outage, an unplanned facility power loss occurred during system level thermal-vacuum test of the Mars Global Surveyor (MGS). This resulted in a slight inflow of external unfiltered air into the propulsion system through its Ground Support Equipment (GSE) pressure control system -- a potential contamination concern. Examination of the propulsion test equipment GSE revealed that an open port on its vacuum pump relief valve allowed a small amount of room air back through its cold trap. Had a separate GSE solenoid valve been included immediately downstream of this vacuum pump, the propulsion system would have been safe in the event of total facility power failure. Because the backflow rate into the propulsion system was small and the cold trap temperature was not compromised, there was little concern for contamination. Gas sampling confirmed that there had been no significant contamination of flight hardware. Backup power was restored within one minute, and the system resumed operation as designed. Reference(s): Problem\/Failure Report No. B0PE10","Lesson ID":583}
{"Driving Event":"During testing of a electrical power generating device known as a \"fuel cell\" it was discovered that the electronic dynamic load bank went into oscillations and became very unstable when an attempt was made to utilize it as a \"load\" for the fuel cell. During post test evaluation it was discovered that when these load banks are long coupled to the power supply their performance is erratic. When short coupled they perform as programmed. The question becomes at what length coupling does the problem occur. Presently evaluations were only made at three lengths: five (5) feet, twenty (20) feet, and forty feet per lead. At five feet no problems were noted, at twenty feet and forty feet the load bank was unstable. Research of available literature concerning this load bank does not reveal this problem. Consultations with the manufacturer indicated they were aware of some problems associated with small dynamic load banks using long coupling leads and that this is a characteristic of this type of load bank (small electronic dynamic load banks). This instability has been observed in small electronic dynamic load banks; larger dynamic load banks do not seem to exhibit this phenomenon, and resistive load banks are not prone to this phenomenon. The correlation of this phenomenon to the couping length is still under investigation. A Government-Industry Data Exchange Program (GIDEP) alert has been recommended.","Lesson ID":581}
{"Driving Event":"A small plastic vial stored in liquid nitrogen burst while laboratory workers were inventorying and transferring vials from one dewar to another. During the transfer a vial burst, causing superficial cuts on the hands of two laboratory workers. The vial manufacturer had updated catalog and shipping documents to alert customers that the vials were not recommended for storage in the liquid phase of cyrogenically stored nitrogen. Instead, the manufacturer recommends that the vials be stored only in the gaseous phase of cryogenic nitrogen. The seal on the vials is not adequate to protect against seepage of liquid into the vial which could then burst following removal from the liquid unless adequate precautions were taken to allow the liquid to evaporate and escape slowly. Workers were not wearing the selected PPE at the time of the mishap. The PPE had been removed because it was too bulky to permit manipulation of the small vials. This directly exposed the personnel to low temperature hazards as well as the burst hazard from the cryogen stored vials.","Lesson ID":580}
{"Driving Event":"While mating two electrical power connectors during integration and test of the Mars Global Surveyor (MGS) Electrical Power Subsystem (EPS), a pin on one connector came into contact with the backshell (at spacecraft ground potential) on the other connector. Spacecraft external power was disconnected at the time, but the batteries were charged. A short occurred between a solar panel power return pin and the backshell. The event caused a transient energizing of the power system. The pin was isolated from spacecraft ground by a remote power switch. The shorting of the pin to ground provided a current path around the remote power switch, allowing the batteries to energize the power bus to no more than 22 volts. This short probably existed for only a few milliseconds and did not power any loads connected to the bus. The incident was attributed to the connector mating configuration-the exposed position of a corner pin during a slightly twisted entry. This event caused no damage to flight hardware due to the adequate surge rating of the blocking diodes and inductors. The corrective action was to add a test cable to the positive side of the battery allowing battery voltage to be interrupted prior to and during cable mating or demating. Where use of the test cable was not feasible (e.g., during spacecraft acoustic test), the solution was to discharge the battery prior to any mate\/demate which could cause a turn-on transient. Reference(s): MGS Problem\/Failure Report No. B0RE5V A related lesson is recorded in Magellan Battery Fire, Lesson Learned #4-112 (NASA LLIS #386)","Lesson ID":579}
{"Driving Event":"On August 28, 1997, after the Cassini spacecraft was initially positioned on the launch pad and mated to the Titan IVB\/Centaur launch vehicle, a cooling incident occurred which affected the Huygens Probe. During ground operations, cool air is injected into the probe to prevent internal heat build-up and damage to probe hardware. Prior to movement to the launch pad, cooling was provided without incident by a JPL cart. At the launch pad, cooling air was provided by the facility and routed to the probe through a diverter box provided by JPL, as shown in Figure 1. After mating Cassini to the launch vehicle, cooling air was supplied to the probe at approximately 0.26 kg\/s (35 lbs\/min). This air was routed to the descent module via the European Space Agency (ESA)-furnished ducting whose configuration and effects were not fully communicated. This produced a high-velocity airflow in the vicinity of internal probe insulation. It was later determined that the desired flow in that configuration was 0.04 kg\/sec, and the air flow was adjusted accordingly. [D] Figure 1. Worst Case On-Pad Configuration To assess potential damage from the high airflow, a borescope was used to inspect the area inside the Descent Module (DM) in the vicinity of the air inlet. A tear approximately 5 cm long was seen on a Kapton blanket, along with evidence of foam insulation particles. The spacecraft was removed from the launch pad and returned to the Payload Hazardous Servicing Facility (PHSF) for removal and more detailed inspection of the probe. The probe was cleaned, repaired, re-verified, reinstalled on the spacecraft, and transported back to the launch pad. These unplanned activities resulted in a delay of seven days in the scheduled launch of the Cassini-Huygens mission. A failure review board concluded that, although ESA originally had responsibility for providing cooling air to the probe, the responsibility for supplying cooling to the probe on the launch pad was informally transferred from ESA to JPL without adequately defining and documenting nor implementing the resulting new interface requirement. Thus, no unambiguous assignment of responsibility for interface control existed. In addition, the internal probe cooling configuration at the launch pad, prior to backshell close-out, was changed without adequate review and coordination. These two factors resulted in excessive cooling air velocity within the DM, which caused the damage. Additional Keyword(s): Test & Launch Operations, Requirements Documentation Reference(s): JPL Problem\/Failure Report No. Z44098 Cassini-Huygens Probe On-Pad Cooling Incident: Report of Formal Review Board, JPL Document D-15158, October 24, 1997 Probe Interface Requirements Document (IRD) PD-699-080","Lesson ID":578}
{"Driving Event":"Printed wiring boards (PWBs) for JPL spacecraft flight control systems are produced in the following sequential steps using specialized computer-aided design (CAD) software programs: Schematic Capture. A schematic diagram--a functional representation of the circuit design -- is produced by the JPL circuit designer using one CAD tool. Net List. A functional representation of the PWB interconnections may be generated by a different JPL organization using the same or a different CAD tool. The schematic is compiled to produce a \"net-list,\" which identifies each set of nodes (i.e., set of pins on piece parts) to be electrically connected to form a \"net.\" PWB Design. This net-list is transferred to a PWB design vendor along with physical descriptions of the piece parts. The PWB design vendor may use another CAD program to define the physical PWB layout, including placing and routing. PWB Artwork. Data files from this CAD program are then sent to an artwork vendor who may use yet another CAD program to create the PWB artwork. PWB Fabrication. The artwork and a fabrication drawing are sent to a PWB fabrication vendor to construct the PWB. Errors may be introduced in each step without any indication of CAD\/CAM software incompatibility. The Cassini Telemetry and Control (T&C) module failed during functional bench test in June 1995. Inspection of artwork prepared by the PWB artwork vendor revealed three nodes connected to three other nodes in contradiction to the schematic diagram. The errors occurred in the conversion of the net-list, prepared by JPL using one CAD program, to the vendor artwork, which utilized a different CAD software program. Node reference numbers possessing common \"suffixes\" were interpreted as common nodes without discriminating between the differing \"prefixes.\" The incorrect interconnection of certain gate outputs caused contention-type failures, disabling the telemetry processing circuitry. The corrective action performed by JPL was to rework the stray node connections with trace cutting and haywires, and to replace many parts which may have been damaged when the T&C module was powered for test. Additional Keyword(s): PWB Miswire Reference(s): JPL Problem\/Failure Report No. 61810","Lesson ID":577}
{"Driving Event":"During the machining and removal of tooling tabs located in a small closed pocket on a bulkhead, one of the loose tabs became entrapped in an adjacent corner. The end mill subsequently struck this loose tab, causing ti eject, resulting in damage to the product. The damage was found to include a bent rib and an approximately 2-inch crack The operator was trained but inexperienced in this particular machining operation.Cutter path verifications using software simulations are useful for detecting most types of part \/ tooling collision programming errors, but they cannot anticipate how detached tabs (or other waste material or debris) may fall into the a pocket, tooling, etc., and be struck by the mill. On any automated (or manual) machining process, detached parts or debris must be accounted for so they do not hamper the process.Cost of rework estimated at $10K.Lesson Submitted from the Boeing International Space Station (ISS) Lessons Learned Database:from Boeing ISS dated 4\/14\/97, was entitled \"NC Programming: Tooling Tab Removal\"from Boeing ISS dated 4\/15\/97, was entitled \"Bulkhead Damaged During Final N\/C Milling\"","Lesson ID":575}
{"Driving Event":"When a test fixture was commanded to rotate, the rotation machinery was actuated but the fixture failed to rotate. Visual inspection of the fixture revealed deformation and damage of several fixture components. The drive system had a mechanical stop in place to prevent over-rotation of the fixture cradle. Subsequent analysis indicated that the drive system had sufficient torque capability to overload the drive train should the drive train operate after the mechanical stop was engaged. Damage to the test fixture was estimated at $20K. Lesson Submitted from the Boeing International Space Station (ISS) Lessons Learned Database: From Boeing ISS dated 8\/96, was entitled \"Rotating\/Moving Equipment Mechanical Stops\"","Lesson ID":576}
{"Driving Event":"Mars Global Surveyor incorporated eight potentiometers (pots) used to confirm the position of the solar panels following their deployment away from the main body of the spacecraft. This event was the only time the eight potentiometers were needed in the mission. For each solar panel, the design permitted one of the two inherently low reliability devices to fail without losing the ability to ascertain mechanism position. If a potentiometer failed before launch, and a decision was made not to repair it, this could result in a mission critical single point failure. The flight computer would assume that the solar array had not been deployed and issue commands to reinitiate the deployment sequence. If this occurred at a late phase of the aerobraking maneuver, the mission could be jeopardized. The pots proved nonessential since body rate data generated in flight by the Attitude and Articulation Control Subsystem (AACS) provided quite accurate measures of solar panel deployment position.","Lesson ID":574}
{"Driving Event":"The first in a series of commercial geosynchronous satellites experienced abnormal operation of the bipropellant main engines following initial pressurization of the propellant tanks. Subsequent analysis of contractor test data on engine flows, previously unavailable to the customer, indicated an actual engine mixture ratio slightly higher than the ratio used to determine the propellant loading. This resulted in the depletion of the oxidizer about one minute prior to the end of the final burn required to place the spacecraft on station. The extremely large monopropellant burns required to compensate for the absence of oxidizer may reduce the mission life. The spacecraft was provided with two methods to detect oxidizer depletion: (1) a single accelerometer reading indicating acceleration below a manually set threshold and (2) multiple readings of acceleration values which are time-averaged at 60 percent below the last steady-state value. With the latter method active during the final burn, the depletion was not detected by the onboard software because the average acceleration did not drop below the 60 percent threshold. Severe line pressure oscillations, indicative of intermittent ingestion of oxidizer bubbles, indicated the main engines were still firing. The engines were allowed to operate in this abnormal mode for about 30 seconds before shut down was commanded by ground control to minimize engine damage. Additional Keyword(s): Engine Flow Test Data","Lesson ID":572}
{"Driving Event":"The Mars Global Surveyor (MGS) electrical power system (EPS) design featured a switch on the negative leg of the battery for interrupting battery power. When this switch was opened to place the EPS (and thus the spacecraft) in the unpowered state, a blue light on the ground support equipment (GSE) power bus monitor remained lit, indicating that the spacecraft power bus was still energized. Examination of the design revealed that a residual voltage of almost 2 volts could be expected due to sneak paths both through the GSE grounding system and within the spacecraft telemetry system. Telemetry and control circuitry in the battery charger assembly (BCA), power supply electronics (PSE), and signal conditioning units (SCUs) provides multiple high impedance paths that bypass the main enable plug and the remote power switch and are manifested only in the ground test environment. In this specific design, these paths are necessary for normal flight operation of the power subsystem and command and data handling (C&DH) subsystem, but constrain pre-launch testability. The MGS design criteria define the circuit as \"unpowered\" with a voltage of less than one volt; a higher voltage could have caused: A stressed or blown spacecraft fuse which could have remained undetected. Inadvertent powering of the spacecraft bus without the knowledge of the test crew due to ground equipment. Burnt connector pins caused by scooping of the \"D\"-type connector shell during mate or demate. Reference(s): PFR #B0JK79","Lesson ID":573}
{"Driving Event":"The low pressure buoyancy compensator flex hose failed when it was inadvertently attached to the high pressure port of the SCUBA regulator. When the diver opened the SCUBA bottle for a pre dive check the hose failed causing minor injuries to the diver.","Lesson ID":570}
{"Driving Event":"There was an inadvertent release of nitrogen tetroxide (N2O4) at JSC on April 21, 1994 at Approximately 11:20 am. The release occurred in the Thermochemical Test Area (TTA) during the preparation phase of a simulated altitude test of a small bi-propellant rocket engine. The immediate trigger event was the failure of a three-way solenoid valve. This failure enabled liquid oxidizer (N2O4) to flow in a vent line and the oxidizer burner stack (which was used as a control device to burn off small amounts of N2O4 which might leak or be released from the system). As the system was being charged to the desired operating pressure of 800 psig, the leak rate increased and the burner stack was filled with liquid oxidizer and saturated oxidizer vapor. The system was initially charged to 850 psig, instead of the desired pressure of 800 psig, and was vented to reduce the pressure. Venting resulted in the release of a small cloud of oxidizer from the burner stack. Although this was an indication of anomalous system operation it was mistakenly attributed to an improper setting on the methane supply valve for the N2O4 burner, and test was continued. Other indications that the system was not operating properly were available in the control room, but were not noticed or were misinterpreted. A subsequent attempt to raise system pressure to 800 psig for the test caused the release of a large oxidizer cloud and percolated liquid oxidizer from the burner stack onto the ground area surrounding the burner, resulting in a spill. Subsequent to this incident, several fittings started leaking. Two fittings were successfully tightened, but attempts to tighten the third led to an increase in the leak rate. This fitting ( a mechanical Parker- type flareless, single ferrule fitting) was removed and sent to the materials laboratory for analysis. Leakage was attributed to the collapse of the ferrule component. The ferrule had clearly lost all of its functional integrity and separated into small fragments. All surfaces showed evidence of severe intergranular attack. Chemical analysis identified the ferrule as a 316-type stainless steel. Metallographic examination of a sample piece confirmed that gross intergranular corrosion attack of the ferrule material occurred. In addition, the examination suggested that the grain boundary sensitization may have occurred in the material, increasing the susceptibility of the ferrule to intergranular corrosion. Examination of other fittings removed from the system also revealed at least slight amounts of intergranular corrosion. Discussions with the manufacturer indicated that at least some of the ferrules had been nitrided, a process which may require extended times at temperatures of from 480 degrees C to 590 degrees C. Since austenitic stainless steels becomes susceptible when subjected to temperatures from 480 degrees C to 815 degrees C, the subject ferrules may have inadvertently become susceecptible during the nitriding process.","Lesson ID":571}
{"Driving Event":"The Mars Pathfinder (MPF) project operated under cost and schedule constraints. It employed new approaches for interface definition and control which produced both good and bad results. In simplifying the expensive serial engineering change request (ECR) process, a dedicated JPL interface control drawing (ICD) coordinator was responsible for change control and for assuring that interface changes were approved by cognizant engineers. In addition, the Project Engineering Team met weekly to review all changes. Problems occurred during MPF spacecraft integration and test, however, due to out-of-date or incomplete interface documentation: Electrical connector discrepancies were found between the MPF main wiring harness (delivered in July 1995) and 7 connectors on circuit boards in the Attitude and Information Management (AIM) subsystem. Investigation showed that the main wiring harness was built in accordance with MICDs which had not been updated after interfacing circuit board connectors were changed. This resulted in a connector mismatch--non-mating male-to-male and female-to-female connections. No power subsystem cabling was involved, and the discrepancies were corrected by retrofitting the cabling, or in some cases the boards, before any damage had occurred. For some hardware items, it was discovered that JPL and vendors had each prepared MICDs independently. Additional Keyword(s): Electrical Interface Control Drawing (EICD), Mechanical Interface Control Drawing (MICD) Reference(s): Muirhead, B., Mars Pathfinder Lessons Learned Presentations, April 17, 1997. Mars Pathfinder Problem Log, IR 043306. Mars Pathfinder ATLO Data Package JPL Common Threads Workshop Summary Report, JPL D-13776, May 31, 1996.","Lesson ID":569}
{"Driving Event":"Mars Global Surveyor (MGS) carries two nickel-hydrogen (NiH2) battery assemblies: one mounted to the +Y and one to the -Y propulsion module. Each assembly consists of eight 20Ahr NiH2 common pressure vessels (CPVs) in a honeycomb composite enclosure mounted on an aluminum baseplate. During MGS system test, shortly after installation of the batteries on the spacecraft, an intermittent popping or snapping sound issued from both batteries. This noise was most likely caused by oxygen-hydrogen (H2\/O2) recombination in the battery under the fast charge rate conditions normally present throughout the charge cycle. H2\/O2 recombination is a natural chemical process which occurs mostly during the late charge and early discharge stages of NiH2 battery operation. Audible popping occurs during H2\/O2 recombination when a large enough oxygen bubble is allowed to form on an electrode plate inside the cell stack before it can recombine with hydrogen. When this bubble finally does recombine, a popping sound results. Such popping may induce significant damage to cell plates and may reduce battery cycle life. This phenomenon was exacerbated by the MGS practice of mounting and testing the battery on its side (i.e., horizontally) in a 1 g. environment. Instead of remaining fully contained within the porous electrodes, a small amount of the liquid electrolyte was drawn by the force of gravity to the bottom of the horizontal CPV. The liquid pressure from this pooling of electrolyte promoted the formation of oxygen bubbles large enough to recombine violently. Such pooling cannot occur in a zero g. environment. Use of the flight batteries was judged to represent a low risk to MGS mission success. X-ray inspection showed that the popping had caused some deformation of the cell plates. However, charge retention testing showed no degradation in battery performance, and the item features a heritage design and robust capacity. [D] Figure 1. NiH2 CPV Positioned Vertically (only the upper of two stack sets is shown) Additional Keyword(s): Battery Charging Reference(s): Problem\/Failure Report No. B0M9XU Walker, S., Battery Noise Anomaly Close-Out Engineering Analysis, September 26, 1996","Lesson ID":568}
{"Driving Event":"As a commercial geosynchronous satellite achieved its approximate final orbit, on-orbit testing was initiated to check out the on-board electronics suite. In one test, ground controllers rolled the satellite slightly off of its normal attitude relative to Earth to check the attitude recovery loops. The proper response was for the satellite thrusters to automatically fire a short burst to roll it back. In this instance, however, the satellite responded by firing the thrusters and continuing to fire until the satellite went into a flat spin. The centripetal forces induced by a flat spin can cause structural damage. The cause of this incident has been attributed to the failure of ground controllers to change the gyro sensitivity settings prior to initiating the test. The satellite gyros have two sensitivity settings\u2014fine (0.6 degrees\/sec.) and coarse (5.0 degrees\/sec.). The gyros had earlier been set to fine sensitivity for the transfer orbit, and ground control neglected to change them back to the coarse setting for this test. To check the attitude recovery loops, ground control commanded 1 degree\/sec. of roll. This roll rate exceeded the sensitivity of the gyros, inducing saturation of the attitude control electronics (they could not recognize any level above 0.6 degrees\/sec.) and resulted in a severe spin. Command and Control Subsystem designers did not incorporate software command constraint checks: such checks would have prevented thruster firing with an incompatible gyro sensitivity setting. A contributing factor may have been human fatigue: multiple mission support was combined with this mission\u00bbs ambitious checkout schedule. Additional Keyword(s): Production-line Satellites","Lesson ID":567}
{"Driving Event":"On February 22, 1996, the STS-75 Space Shuttle Columbia was launched at 53\/20:18 GMT. The orbiter was inserted into a 296 km (160 nautical mile) orbit at an inclination of 28.5 degrees. The crew consisted of 7 members, including commander, pilot, 3 mission specialists, 1 payload commander, and 1 payload specialist. The TSS-1R payload was a reflight of TSS-1 in 1994, where deployer mechanism problems limited the tether deployment to slightly less than 300 m. The planned duration of the flight was 14 days. The payload bay configuration consisted of the Tethered Satellite System (TSS) experiments, two U.S. Microgravity Lab pallets (USMP-3), Orbiter Acceleration Research Experiment (OARE) pallet, and Extended Duration Orbiter (EDO) pallet. Deployment of the satellite began at 56\/20:46 GMT. On 57\/01:29:26 GMT, at a tether length of 19.7 km, the satellite tether broke within the 12 m deployer boom, and the satellite separated from the orbiter. The rate of tether deployment was under control of the science computer. At the time of the tether separation, the deployment rate was being ramped down, per timeline, in preparation for halting at 20.7 km tether length. The tether deployment rate was approximately 1 m\/s when it separated. There were no injuries and no damage to the orbiter or its subsystems due to the tether break. The orbiter was located at 2 degrees N latitude and 100.4 degrees W longitude, and was at an altitude of 296 km (160 nautical miles) at the time of tether break. The TSS-1R experiments were in the passive mode, with no current flowing in the tether. The tether had an electric potential of -3500 VDC with respect to the orbiter ground, as planned, during this mode. Telemetry from the orbiter and the satellite was operating prior to, during, and after the tether separation. Video imagery of the tether was available after the separation, but no video coverage exists showing the break itself. Video and still photography were taken during the mission of the failed end of the tether within the boom. The tether remaining in the boom was rewound on the reel during the mission. Post flight inspection of the tether end showed it to be charred, with an apparent final tension failure of a few strands of Kevlar. The TSS-1R Mission Failure Investigation Board established that the tether failed as a result of arcing and burning of the tether, leading to a tensile failure after a significant portion of the tether had burned away. Pictures of the frayed tether end The arc started in the Lower Tether Control Mechanism (LTCM), resulting in a 1 A current discharge to orbiter ground in the LTCM. This event occurred during a passive mode of science operations, with -3500 VDC on the tether conductor. The arc continued intermittently for 9 s, as the breached part of the tether traversed at 1 m\/s through the remaining deployer mechanisms and into the 12 m deployer boom, where the space plasma provided the current return path. This arcing produced significant burning of most of the tether material in the area of the arc. The nominal load on the tether, 65 N (15 lb.), finally separated the tether at the burn location, while it was within the deployer boom. The upper tether section was pulled through the Upper Tether Control Mechanism (UTCM), away from the orbiter at a speed of 3 m\/s, due to tether dynamics and the satellite movement away from the orbiter. The lower section of the tether remained within the boom, and was recovered after the flight. The arc initiated at a breach in the FEP insulation layer of the tether. Pressure within the LTCM, the proximity to a ground plane at the LTCM entry pulley, and the high voltage on the conductor, provided the favorable environment based on pressure-distant relationships (Paschen's Law)* for the conductor to arc through the breach in the tether insulation. Although the damaged area of the insulation was destroyed due to burning, the TSS-1R Mission Failure Investigation Board found sufficient evidence from test and analysis to establish foreign object penetration, or damage to the FEP insulation layer in manufacturing or handling, as the probable cause of the breach of the insulation layer. See the following videos: [D] The satellite and tether moving away from the shuttle [D] Scan of the boom with the slack tether in the shuttle cargo bay Manufacturing and inspection records show that the tether fabrication task was very difficult, and that numerous problems were encountered in the extrusion and braiding processes of this very long tether. The fabrication of the tether was carried out in a normal manufacturing shop environment. Metallic and non-metallic contamination was found within the FEP insulation layer of the flight tether, including the 9 m that had gone through the lower deployer mechanisms prior to the failure. Non-metallic and metallic contamination was also found between the Nomex and insulator layers of several samples of flight tether. EDS analysis revealed foreign material near the failed end. In addition to the contamination found within the tether, debris was found in several locations within the deployer mechanism. Metallic debris, large enough to breach the FEP, was found in the LTCM, the deployer boom assembly, and the reel housing. In the LTCM, a small piece of very fine silver plated wire, aluminum shavings, and unidentified non-metallic debris were found. Small metallic shavings were found attached to the back of small screw holes in the boom assembly. Damage to the copper conductor was found in both the returned flight tether, and in a section of qualification tether examined after a special spark test. This damage appeared to have taken place during fabrication of the tether. The final wind of the tether onto the flight reel was at a tether tension of 50 N. This results in high compression forces on the tether layers deep within the reel. The TSS-1R Mission Failure Investigation Board calculated that compressive forces at the layer where the tether breach was located, were as high as 35 N\/mm for several days after the winding process. This compressive force is more than sufficient to force small debris through the insulation layer of the tether. The TSS-1R Mission Failure Investigation Board found one contributing cause was that the degree of vulnerability of the tether insulation to damage was not fully appreciated. A second contributing cause was high voltage effects on the insulator itself. Concern over the environment inside the LTCM led to the analyses involving Pashcen's Law relating voltage break down propensity as a function of the pressure-distance parameter. * - In 1889 Paschen introduced a generalization to the complex subject of gas break down in the law bearing his name. This law states simply that in a uniform field the sparking potential of a gas depends only upon the product of the gas pressure and the electrode separation. The TSS-1R Mission Failure Investigation Board was able to conclusively eliminate several major areas as causal. They included: Satellite Hardware and Operations Core Science Equipment and Operations Hardware and Operations of the Experiments Mission Operations (Ground and Flight) Induced Loads (static or dynamic) Pyrotechnic Tether Cutters Heating of the Tether During Commanded and Controlled Current Flow Design Changes Made to TSS-1 Aging of the Components (shelf life) Micrometeoroid or Orbital Debris Collision Electrical Storm Activity Reference(s): TSS-1R Mission Failure Investigation Board - Final Report, May 20, 1996.","Lesson ID":566}
{"Driving Event":"A routine hookup and pump testing was being attempted on LOX barge #5 by Test Complex technicians. They were working under a process plan and standard operating procedure as required. The testing was necessary to functionally check the system after repair was performed. The technicians encountered difficulty in making a threaded electrical connection between the 480 VAC shore power cable connector and the LOX barge receptacle. The cable was insufficient in length to make a comfortable hookup. They pulled on it attempting to gain range by decreasing the slack in the line. Although they were successful in mating the connectors, the weight and angle of the cable applied undue stresses. The lead technician was under the impression the connection was adequate due to the fact the associated retaining nut felt to tighten by hand. A strap wrench was therefore used to further tighten the nut. When power was applied to energize the system, a high current arc was produced within the connection. The forces exerted by this arc resulted in the connector plug being forcefully ejected free from the receptacle. This action caused the connector plug to come in contact with the barge access ramp. The chain holding the associated aluminum connector plug moisture\/dust cap was severed. The cap was then propelled and struck a technician working nearby behind the ear.","Lesson ID":563}
{"Driving Event":"The mobile crane was holding a 20 foot section of 36\" diameter pipe while a section of handrail was being removed. Removal of the handrail was necessary in order to remove the section of pipe. While the crane was in operation, one of the crane's outriggers \"leaked down\", and caused a brief uncontrolled movement of the pipe. No damage occurred to the equipment, and property surrounding the crane. Most importantly, there were no injuries to personnel. The crane was not equipped with a \"Positive Mechanical Block (PIN)\" system. Subsequently, it was found that the crane had not been proof load tested for over a year.","Lesson ID":565}
{"Driving Event":"A model under test in the tunnel required the use of a removable shroud to insulate a sensor from heating while the model was being injected into the tunnel flow. Once the model was in the tunnel flow and was ready to collect data, the shroud was released from the model and ejected from the diffuser of the tunnel. The first test used a metal shroud that had been designed with air dams to ensure that it was not aerodynamic. The metal shroud was of sufficient mass and was ejected from the tunnel at sufficient velocity to cause the shroud to travel a long distance placing personnel in its potential path at unacceptable risk. A \"catcher screen\" was install but was not successful in capturing the metal shroud. The metal shroud was replaced with a wooden shroud. The wooden shroud provided the needed heat protection for the sensor and upon release, tumbled, contacted the diffuser walls of the tunnel and disintegrated. The pieces of the wooden shroud either came to rest before reaching the catcher screen or were captured by the catcher screen","Lesson ID":562}
{"Driving Event":"A scan platform anomaly occurred 5 hours before Galileo's August 1993 encounter with the asteroid Ida. During a quiescent period in scan platform activity, it unexpectedly jerked. The fault response sequence interpreted the high rate of scan platform motion as a spacecraft gyro error and turned off the gyros. The flyby continued in cruise mode, using star-based platform pointing. Although the low data rates available from the low gain antenna provided poor insight into spacecraft condition, ground control received indications of at least 5 more incidences of unexpected platform motion during quiescent periods over the next few hours. Ida encounter continued successfully with the gyros off and with no further signs of the anomaly. No conclusive explanation was found despite extensive ground testing and analysis and attempts to recreate the anomaly on the spacecraft. Consistent x-axis data from both gyros suggested that gyro hardware failure was improbable. Analysis did reveal that the anomaly would have aborted the imaging sequence had the additional power drawn during the slew been enough to cause an undervoltage condition. Instead, the first level fault protection (gyros off) allowed the sequence to continue imaging Ida. After the science data had been safely recorded and before the gyros were required, ground control was able to command them back on. This conservative, \"first, do no harm\" approach proved successful. The Galileo architecture did not provide for revolving, short-term storage of downlink data, which would have been useful in compensating for low telemetry data rates. Galileo telemetry provided data needed to troubleshoot the anomaly only once every two hours. Running intermittently, the tape recorder failed to capture any of the scan platform jerks. Subsequent to the Galileo era, some low data rate missions are being designed to provide for some storage of transient data to improve fault visibility to ground control. Additional Keyword(s): System Design, Transient Event Recording Reference(s): ISA 04013G","Lesson ID":560}
{"Driving Event":"In January 1976, a problem became evident during initial testing of the earliest Command & Control Subsystem (CCS) subassemblies for Voyager. Detailed testing revealed multiple, often intermittent, functional failures. The failures were traced to the multi-layer boards (MLB's), specifically the plated-through holes (PTH's). [D] The extent of the problem was determined by subjecting selected subassemblies to a detailed sequence of resistive measurements and temperature cycling. The sequence was designed to stress the PTH's without over-stressing the components installed on the MLB's. MLB fabrication documentation, test history, and theoretical analyses were reviewed. Failure analysis of hard failures, PTH's that exhibited early signs of failures, and PTH's which had appeared acceptable, revealed PTH copper plating that was marginal -- too thin and of insufficient ductility. This incident involved Viking board designs inherited by Voyager. The Voyager boards were fabricated 3-4 months later in a follow-on contract in which the same contractor presumably used the same specification and process. However, micro-photographs of the Voyager boards showed insufficient plating, and metallurgical tests showed insufficient ductility. A metallurgical test was subsequently performed on one of the earlier Viking boards: it showed the copper to be more ductile. Reference(s): quotMJS MLB Failure Investigation Report,quot June 1976. Voyager Problem\/Failure Report No. 36970, Jet Propulsion Laboratory, opened 04\/13\/76, closed 01\/18\/77. Gibbel, M., quotSummary of JPL Printed Circuit Board Failures,quot Jet Propulsion Laboratory Document TETA-029, October 1995.","Lesson ID":561}
{"Driving Event":"Flight software for a recent mission included a safety feature in which the flight computer initiated a command sequence for enabling the thrusters. It also started a countdown timer which limited the duration of the burn. Flight software contained a known defect: whenever numerical computations produced an overflow, the calculations generated false results. When interplanetary mission software was uploaded following conclusion of the first science objective of the mission, the upload failed to include a software patch which had been written to fix the defect. When the thrusters were enabled for a spacecraft pointing maneuver, the flight computer performed calculations which generated a numeric overflow. A floating point interrupt occurred, and the processor generated erroneous commands affecting various spacecraft functions, including the propulsion subsystem and the countdown timer. With this timer not functioning, the thrusters continued to fire after the desired shutdown time. The 15-minute ground response to the fault allowed the loss of too much fuel to continue the mission. An independent watchdog timer*, redundant with the countdown timer, was planned but never implemented due to constrained project resources. Contributing Factors: Inadequate Operational Configuration Management. The functions of configuration management and software performance analysis and repair lacked adequate staffing. Inadequate Redundancy Design and Overflow Detection. Spacecraft hardware and software did not provide redundancy checking on the performance of software, such as fault protection monitors, to detect, diagnose and recover from an overflow condition. Insufficient Processing Capability. The spacecraft computer was selected chiefly for its physical attributes -- principally mass and radiation tolerance -- rather than for its computational power. The decision to omit a watchdog timer was influenced by this hardware limitation. Lack of Post-Launch Anomaly Analysis and Software Repair Capability. Only a single software development and simulation model was available for use by the flight project, and it was used continually after launch to generate flight sequences. This meant that the model was unavailable to generate software revisions to fix known bugs, so various software patches had to be uploaded throughout the mission. * Watchdog Timer: A software module which works in conjunction with a hardware time limiter to anticipate periodic receipt of a system health indication and, in the absence of such indication, initiates a system restart, interrupt, or return to a prior state.","Lesson ID":559}
{"Driving Event":"Serious drawbacks have emerged from the propulsion subsystem design on a series of geosyncronous satellites impacting the on-orbit lifespan of a recent mission. The design uses four separate tanks for the hydrazine load, with a separate check valve for each tank in the pressurization system. Following each orbit-raising maneuver, and until the final burn, this results in propellant transfer from those tanks with check valves having the highest reseat pressures to the tanks with check valves having the lowest. Since orbit raising on this specific mission was done while spinning, this moved the spacecraft spin axis closer to the fuller tanks, which may have resulted in yet further propellant transfer. Differential heating or cooling of the tanks can add to the propellant migration problem. In addition to changing spacecraft dynamics, this transfer of mass may limit the spacecraft's on-orbit life because pressurant gas instead of propellant will be drawn from the first tank to be depleted, leading to early engine shutdown. For interplanetary spacecraft with a similar configuration, such as the Mars 98 lander, propellant transfer or differential draw during cruise may cause dynamic imbalance and\/or reduction of useable propellant. Additional Keyword(s): Bipropellant Propulsion Systems","Lesson ID":558}
{"Driving Event":"A \"maintenance-free\", lead acid battery, of the set in a Uninterruptable Power Supply (UPS) cabinet, exploded during normal operations. The investigation determined that the 6 year old cell was dry and failed internally; other batteries cells were found void of liquid, as well. Battery condition \/capacity was not observable, due to the configuration with continuous supply of normal facility power keeping the batteries charged. Note: When contacting originator, please refer to Lessons Learned ER-LL-97-01","Lesson ID":557}
{"Driving Event":"On April 7, 1997 a solar flare occurred with an associated coronal mass ejection and a \"coronal Moreton wave.\" These phenomena were seen in new and spectacular ways by instruments aboard the NASA\/ESA SOHO spacecraft. NASA, ESA, and NRL scientists queried by the media were excited, and their excitement about the new observations led to media reports that a massive ejection had left the Sun (true), it would hit the Earth (highly probable), at a certain time (wrong), and cause damage and outages to technical systems (highly unlikely.) Meantime, NOAA's Space Environment Center (SEC), utilizing primarily the same types of data with which we have become familiar over the last several solar cycles, regarded the flare (C6 in soft x-rays and 3N in H-alpha) to be ordinary, the coronal mass ejection to be the expected garden variety, time of transit to Earth through slow solar wind to be long, and the terrestrial effects likely to be unremarkable. The unprecedented media saturation and attention gives to this event, and the \"NASA predictions\" (which NASA scientists did not make) appearing as an official government warning, caused many systems operators to be severely shaken, As on example, NOAA's Space Environment Center had a call asking if 747s scheduled to fly across the Atlantic should be kept on the ground at the predicted time of arrival of the storm. This lessons learned document appeared in the June 1997, International STEP Newsletter, Vol. 3, No. 2 and was written by: Ernest Hildner, Director, SEC Art Poland, Project Scientist, SOHO Nicola Fox, ISTP","Lesson ID":556}
{"Driving Event":"During an Extravehicular activity training exercise involving pressurized operations in a Extravehicular Mobility Unit, the subject suffered symptoms of high concentrations of CO2. The primary cause of the physiological symptoms experienced in the training exercise was insufficient air flow to remove carbon dioxide from the facial area of the helmet in the space suit.","Lesson ID":555}
{"Driving Event":"During a thermal vacuum test with a subject in a space suit, the test subject received frost bite on his finger tips, while handling EVA (Extravehicular Activity) tools at -120 degrees F. Under specific conditions the subject in the space suit gloves can be subjected to low temperatures. The Extravehicular tools required difficult functional operation, resulting in extensive handling \/contact time. The EVA tools had high thermal conductivity. The Space suit gloves have minimum insulation in the finger tip areas for increased touch and grasp capabilities. The ensuing investigation revealed that the test team had a low awareness that this hazard existed and that it needed to be controlled.","Lesson ID":554}
{"Driving Event":"A particulate sampling filter was ruptured during use due to excessive differential pressure. The filter was in use in an oxygen system, and the Quality Assurance technician recording the sampling results noted that the failed filter element was not the type required for the procedure, as it was incompatible with the sampling being performed. The failed filter was not the type required by the users. The users had received the filter housing \"cleaned and ready for service\" from another organization. The type of filter element installed was not considered an issue, because both organizations used only one type of filter and presumed that it was the same type. The users thought that the filter was Teflon, which was normal for their use. The actual filter element was cellulose ester. In addition to being incapable of handling the differential pressure, cellulose ester filters are not recommended for use in oxygen service by the manufacturer. Manufacturing, Materials, and Process Technology Division (EM) has recommended a maximum service pressure of 20 psia for cellulose ester filter elements in oxygen service.","Lesson ID":553}
{"Driving Event":"Several randomly sampled exterior street and parking lot light poles were found to have defective electrical grounds that could result in a potentially lethal electric shock hazard if the pole is touched by a person. The hazard is primarily a result of two conditions: The original design of the power distribution circuit lacked an equipment grounding conductor even though the installation met the National Electric Code at the time. The normal breakdown over time of the materials utilized in the supplemental ground rod which was installed to correct the original design deficiency. The poles are energized primarily at night, but can be remotely energized for testing and repair during daylight hours. Certain power distribution system failure modes may result in an energized light pole. While it is unlikely to have a combination of a defective grounding condition and a power system fault, the condition can be lethal if the pole becomes energized. However, the shock hazard can be precluded by the installation of an upgraded supplemental ground to the earth.","Lesson ID":552}
{"Driving Event":"Two technicians were transferring liquid nitrogen from a vendor tanker to a tank trailer. Near the end of the operation, visibility was severely limited due to fog caused by venting nitrogen, leading to a decision to shut down the operation until the visibility improved. While shutting down the transfer operation, the technicians became unconscious due to lack of oxygen but recovered with no ill effects after being rescued by the tanker drivers. Technicians were wearing PPE for protection against frostbite, spills, etc., but did not include equipment to detect lowered oxygen levels or to supply breathing air. At JSC there are a large number of nitrogen containers. The areas surrounding the larger, permanent containers do not normally present pockets in which to trap nitrogen; however, on still days there could be oxygen-deficient areas near the connection the vent, or the 90% fill valve. The smaller portable containers (dewars) could be located in potentially confined areas, also presenting the potential for an oxygen-deficient atmosphere.","Lesson ID":550}
{"Driving Event":"An electric power off (EPO) button for computers was located in a room that required a button to be pushed to exit the room. An individual mistook the EPO button for an exit button and inadvertently cut off the power to the computers in the room. Had this happened during a flight or critical simulation a great deal of data and monitoring could have been lost.","Lesson ID":551}
{"Driving Event":"MIDAS EMI testing was only done at the experiment assembly level, and when problems were found it required extensive re-work.","Lesson ID":544}
{"Driving Event":"The MIDAS ion pump was at the top of its load rating when it was pumping the vacuum chamber. When the chamber was baked, the ion pump went out of range, so once the pump was turned off during this bake, on a prototype unit. This is not recommended for optimum pump operation. Also, when the ion gauge was operated, the pump would go out of range, which was due to water being forced off the walls.","Lesson ID":545}
{"Driving Event":"The original EMI filters on MIDAS were not matched with the power converter, and were not successful in keeping the EMI below the required level.","Lesson ID":543}
{"Driving Event":"On the MIDAS project, thermal analysis for the Shuttle locker payload was performed without the fan in the locked rotor condition (maximum heat dissipation).","Lesson ID":547}
{"Driving Event":"The MIDAS experiment was designed for one atmosphere pressure, and thus venting was not seen as a requirement and was not designed in. However, the specified minimum and maximum pressures on Shuttle and Mir would have produced a potential maximum pressure difference of 4 psi in the worst case. Venting was back-designed into the system after the fact, when this was determined.","Lesson ID":546}
{"Driving Event":"On MIDAS, an ion pump was purchased to be the maintaining pump on a chamber before all vapor and leak loads within the chamber were calculated (or measured). This resulted in the ion pump being at its maximum pumping capacity during normal operation.","Lesson ID":541}
{"Driving Event":"On the MIDAS project, leak detection for the vacuum chamber was done both by helium \"sniffing\" using the RGA, and also by checking the N2 to O2 ratio to see if there was a steady air leak present. In one case, this ratio did not indicate a leak, because the cryopump was preferentially pumping oxygen.","Lesson ID":542}
{"Driving Event":"O-ring manufactured on MIDAS for vacuum seal was made with butt joint instead of 45\u00b0 angle joint.","Lesson ID":537}
{"Driving Event":"On MIDAS, thin ceramic boards (1-inch x 1-inch x .030-inch thick) were bonded to a 1-inch hollow copper cube. The bond was cured at 75C, and then the assembly was cooled to 75K for operation. It was found that some boards would shatter for what seemed like no reason, even though an identical procedure was used for ones that survived many cycles undamaged. It was eventually found that the stresses on the boards were intimately related to their exact mounting configuration. If the boards were mounted on the cube such that two edges were in contact, the shrinkage created by taking the assembly down to cryogenic temperatures caused the edges of the boards to push on each other and stressed the boards to failure at the edges. Thus, testing the epoxy by bonding substrates to flat copper test pieces was not sufficient to ensure a successful bond.","Lesson ID":535}
{"Driving Event":"Clean room certified adhesive tape 5413 was used inadvertently in construction of multi-layer insulation (MLI) blanket for a vacuum chamber (instead of clean room certified adhesive tape 1205). The two tapes look virtually identical and are packaged similarly.","Lesson ID":536}
{"Driving Event":"Several wire bundles and MLI blankets were not explicitly shown in the MIDAS top-level assembly drawing. This made it difficult to assemble the materials list, and also allowed a blanket interference to go unnoticed since the blankets were not shown on the top-level drawing.","Lesson ID":538}
{"Driving Event":"Front panel of a locker designed for use on Mir and Shuttle did not originally have safeties on breakers.","Lesson ID":539}
{"Driving Event":"On MIDAS, the hermetic connectors purchased were not specified on the LaRC PR to be shipped with the inserts installed, and thus the inserts had to be installed by project personnel. This is a tedious procedure, and one that can cause damage to the connectors.","Lesson ID":540}
{"Driving Event":"Space Station Oxygen quick disconnects (QD's) used silicon grease in the flow path of moderate to high pressure oxygen. The auto ignition temperature for this grease is 500 degree Fahrenheit and with pressures of 200 psia and above, adiabatic compression could have caused this grease to ignite, resulting in a catastrophic event on board. The material rating of the silicon grease stated in the Material Identification Usage Agreement (MIUL) was for 30% or less Oxygen concentrations at 14.7 psia or lower pressures, and not that of 100% O2 at elevated pressures. The vendor failed to observe that the test environment used to determine the MIUL rating as listed in the Materials and Processing Technical Information System (MAPTIS) did not match the actual operational environment. The error was caught by NASA materials and process engineers and representatives of Safety, Reliability, and Quality Assurance, but not before some of these QD's had already been shipped for installation in Node 1.","Lesson ID":534}
{"Driving Event":"Due to overall dwindling budgets and severe cutbacks in operational budgets, onsite space is being used whenever possible to house personnel and operations to avoid renting offsite space. In this instance, personnel were located in sections of two buildings designed for main frame type computers. People began to complain about headaches and other ailments as well as the conditioning of the air in these locations. Carbon dioxide concentrations in these areas were evaluated and found to exceed the 1000 ppm recommended by the American Society of Heating, Refrigerating, and Air Conditioning Engineers, Inc. (ASHRAE). ASHRAE 62-1989, \"Ventilation for Acceptable Indoor Air Quality\". Carbon dioxide concentrations exceeding 1000 ppm indicate insufficient make-up air and the possibility of build up of other indoor contaminants.","Lesson ID":532}
{"Driving Event":"An employee walked into a board with nails that was sticking out of the back of a pickup truck. The employee only suffered minor cuts and scratches to the face, but could have injured an eye. Someone else had almost ran into this board earlier, but no one reported the close call. After the close call was finally reported, action was taken to remove the hazard.","Lesson ID":531}
{"Driving Event":"High-temperature strain gage development in GWP Number 29 at NASA Langley was the topic of a paper presented at the annual NASP Technology Review Conference in Monterey, California, April 13-16, 1993. The talk highlighted the Langley developed high-temperature strain gage, focusing on the excellent results being obtained with this gage on various NASP high-temperature test articles.","Lesson ID":515}
{"Driving Event":"An investment casting process has been developed to produce net-shape, superconducting ceramics. In this work, a factorial experiment was performed to determine the critical process parameters for producing cast YBA2CU307 ceramics with optimum properties. The process employed YBA2CU307 powders dispersed in organic carrier liquids and foundry molds developed at, and patented by LaRC. The slips were poured into the molds as in traditional slip casting operations, however, instead of removing the casting from the mold, the molds were destroyed, leaving a cast ceramic shape. The most reliable organic carrier for the YBA2CU307 powder was found to be an acetone\/menhaden fish oil system. The analysis of variance results indicate that careful control of the various casting variables is critical in controlling both the density and porosity of cast YBA2CU307 ceramics. As density and porosity are indications of the current carrying capacity of the superconductor, the optimization of the critical process parameters to produce superconductors with both high densities as well as a porous network permitting the uniform uptake of oxygen throughout the cast superconductor, is of great importance. These results indicate that the properties of cast superconductors may be controlled by understanding the effects of traditional ceramic processing variables such as the particle size distribution of the cast powders and the sintering temperature, as well as their interaction. This work was cited in the August and September 1992 issues of the American Ceramic Society Bulletin. The NASA-Langley Research Center contacts are S.A. Wise and M.W. Hooker, telephone number (757) 864-8068. A full report of this process is contained in the paper \"Effects of Process Variables on the Properties of YBA2CU3O7-X Ceramics Formed by Investment Casting\", authored by M.W. Hooker, T.D. Taylor, and H.D. Leigh, Department of Ceramic engineering, Clemson University, Clemson, SC 29634-0907; and S.A. Wise, J.D. Buckley, P. Vasquez, G.M. Buch, and L.P. Hicks, NASA-Langley Research Center, Hampton, VA 23681","Lesson ID":520}
{"Driving Event":"On 1-15-91 a failure occurred in the 8' Transonic pressure tunnel during testing of a model wing with attached flap. During the test run, the flap peeled away from the wing, broke free, and proceeded down the tunnel. Extensive damage resulted. It is hypothesized that reuse of screws having repeated applications of a thread-locking compound caused the east most flap bracket screws to either lose or never obtain proper preload. Under test conditions the screws loosened, then the east most flap bracket was lost, load was shifted to the flap fitting, the flap fitting sheared, and failure occurred. Of special significance is the fact that a thread-locking compound is always used on the screws that attach the flap brackets to the wing. These screws were reused for all tests and no special effort was made to clean them. The flap bracket screws had received an application of a thread-locking compound approximately thirty minutes prior to final installation in the wing, resulting in dried, but undisturbed, thread-locking compound on the screw threads. Further, an additional coating of a thread-locking compound was applied to the flap bracket screw threads just prior to their actual installation. Torque values shown on drawings were given for a preload of 50% or proof load based on dry threads. It is impossible to predict the actual torque on the bracket under the conditions indicated. The thread-locking compound corporation has provided conflicting information. One individual stated that screws should not be reused after having a thread-locking compound applied; further, a tap should be run into the female threads to clean them prior to a new screw being installed. Other representatives said they had no information about reusing screws. To achieve prescribed torque values, however, prudence would seem to dictate a more conservative approach to the use of a thread-locking compound as well as to the cleaning of threads.","Lesson ID":524}
{"Driving Event":"One of the most important elements for the further improvement of the performance of the magneto-optic imaging instrument is to quantify the contribution of each different mechanism to the obtained image. More experiments were recently performed using a single-layer thick pancake pickup coil so that the distribution of flaw-induced normal magnetic field component may be measured between the test object and the current sheet, as well as at locations above the current sheet. The test used magnetic current sheet, which has very strong skin depth attenuation. As expected, a distribution of strong magnetic fields exists in between the two conducting sheets; no measurable field strength exists above the magnetic current sheet. Further experiments are being conducted with the new pickup coil to establish a firm theoretical base.","Lesson ID":526}
{"Driving Event":"On 8-5-83 a fire occurred in Building 1268A. The fire, which ignited on the building roof, caused no personnel injuries and resulted in damage under $5,000. The fire was the result of cutting torch operations required in the removal of a number of steel i-beams located next to a wood structure. This fire occurred although all reasonable fire prevention measures had been used to protect the facility.","Lesson ID":529}
{"Driving Event":"In situ airborne measurements of the turbulent flux and mean values of O3, CO and CH4 were obtained in the boundary layer over selected wetland systems in Alaska. These measurements were obtained in July-August 1988 as part of the NASA Global Tropospheric Experiment Program's Arctic Boundary Layer Expedition. The flux measurements obtained from this study provide information on the source\/sink distribution of O3 and CH4 over the Yukon-Kuskokwim Delta (YKD) and Alaskan North Slope (ANS) regions of Alaska. The source\/sink distribution over the YKD is qualitatively correlated with surface vegetation type, identified from multispectral scanner imagery. Direct measurements of the spiral variation in the CH4 source strength were obtained over the YKD. The CH4 source strength over the YKD ranged from 2.5 to 85 MG M-2 D-1 during a flux survey flight which spanned a considerable portion of the YKD, a spatially averaged, seasonally adjusted source strength of 51 MG M-2 D-1 was established for the YKD. Indirect CH4 flux estimates obtained over tundra were estimated to be 44 TG\/A based on: the spatially averaged source strength obtained over the YKD current estimates of the global coverage of tundra assuming a similarity between other tundra areas and that of the YKD.","Lesson ID":530}
{"Driving Event":"On January 15, 1991, a failure occurred in the 8' Transonic pressure tunnel during testing of a model wing with attached flap. During the test run, the flap peeled away from the wing, broke free, and proceeded down the tunnel. Extensive damage resulted. It is hypothesized that the east wall flap fitting pin was damaged when the flap was allowed to bend during installation. These pins are stainless steel and approximately 0.38\" square. They are inserted into square holes in the tunnel side plates. When the model was installed, the flap was lifted to complete the attachment, was left unsupported during the attachment process, and deflected in the center. This deflection could have caused the square flap fitting pin to become overstressed. The Metallic Materials Branch did, in fact, identify an area of tensile fracture related to a single load incident, but was unable to conclusively establish when the fracture occurred. In any case, engineering should strive to use the lowest stress concentration configuration feasible. In this instance, a round pin on the flap end fitting would have reduced the stress concentrations from the level present on the square pins and perhaps prevented test failure.","Lesson ID":504}
{"Driving Event":"On 10-15-90 the T-38 Aircraft (N511NA) belonging to LaRC was on a local training flight. At the time of rotation, the rear canopy separated from the aircraft, damaging both the canopy and the vertical stabilizer. The pilot made an uneventful landing. The canopy loss was most probably caused by the failure of the external handle force input to complete latching of the canopy hooks. There is also strong circumstantial evidence that the canopy latching mechanism contains a design deficiency. JSC has fathered two T-38 canopy locking modifications. One modifies the outer access door for the external canopy handle and was on N511NA at the time of the canopy failure. The other modification includes a warning horn which sounds if either canopy switch indicates an unlatch and the throttle is moved past 96%. This modification was not on N511NA at the time of canopy failure.","Lesson ID":507}
{"Driving Event":"Since 1960, the NASA Langley Team has flown a NASA-owned F-106B airplane through thunderstorms about 1500 times at altitudes between 5000 and 40000 feet (1500 to 12000 meters). The airplane, lightning-hardened and outfitted with special instruments, was hit by lightning 714 times. Ground-based NASA RADARs located across the Chesapeake Bay on Wallops Island, Va., Were used to guide the airplane into the upper, and most electrically active, regions of thunderstorms. Considerable attention was paid to protecting the crew during these potentially dangerous missions. When lightning strikes an airplane, it may take more than a second before the extremely fast and interactive electromagnetic effects die away. Currents between 10000 and 200000 amperes may flow through the airplane's metal skin, setting up electromagnetic fields that may propagate into the airplane's interior through open apertures, diffusion, or other mechanisms. Among other significant findings, this research produced data that was the first to actually capture an airplane in the act of triggering a lightning flash.","Lesson ID":512}
{"Driving Event":"For critical applications either run tests to develop actual torque-preload relationship, or use tables which were developed using the actual fastener material, joint material, and lubrication and\/or locking system. On January 15, 1991 a failure occurred in the 8 foot transonic pressure tunnel during testing of a model wing with attached flap. During the test run, the flap peeled away from the wing, broke free, and proceeded down the tunnel. Extensive damage resulted.","Lesson ID":500}
{"Driving Event":"On or about January, 1993, the LOX\/LN2 System (an Oxygen Clean Environment) of the LaRC 7\" High Temperature TUNNEL Was leak checked using K-Bottle nitrogen. At Langley Research Center, only personnel from the Fluid Systems Section of the Operations Support Division are authorized to work on oxygen clean systems. Personnel doing the leak testing were not from the Fluid Systems Office. When Fluid Systems Section personnel became aware of the leak testing, they questioned the use of K-Bottle nitrogen from the standpoint of system contamination. While the LN2 furnished for use in K-Bottles is over 99% pure, the K-Bottle itself, unless specifically tested and posted with appropriate paperwork attesting to that fact, is assumed to be contaminated with rust, hydrocarbons, and\/or various other contamination-causing particles. Langley Handbook 1740.5 governs working with oxygen clean systems.","Lesson ID":501}
{"Driving Event":"On 1-28-93, during normal testing in the Model Preparation Area (MPA) of the 16' Transonic tunnel, oil from a turboprop simulator model was vented into the atmosphere. The vented oil was MIL-7808-H, the same type as used in past model tests. The turboprop simulators have no oil scavenging system, therefore, it is standard practice to vent oil from the simulators. When preparing to clean instrumentation fouled with the vented oil, it was determined that MIL-7808-H oil contains Tricresylphosphate, a hazardous substance absorbable through the skin and capable of causing paralysis. After LaRC Environmental Health Personnel were contacted to determine proper protective measures, the MPA room was cleaned of all residual oil. There were no personnel injuries resulting from this incident.","Lesson ID":506}
{"Driving Event":"On October 29, 1985, a failure occurred in the 16' transonic tunnel during testing of a Lockheed designed powered turboprop model. The model failed while being tested at mach 0.8. The model propeller, spinner, balance, and air motor separated from the model nacelle and impacted the tunnel fan blades. The separated model components were irreparably damaged and all except one of the tunnel fan blades were damaged. The investigating committee found the most probable cause of failure to be high dynamic loading due to loss of one or more prop blades. It was also found that: The model design approach attempted to eliminate blade loss as a credible failure mode. The consequence of blade failure was not considered by Langley, Lewis, or Lockheed.","Lesson ID":523}
{"Driving Event":"Two Langley Research Center employees, Brad Leighty and John Franke, received a certificate and cash award for the disclosure of innovation entitled \"Sidereal Rate Generator,\" LAR-14350-1. This circuit was developed to produce a symmetrically smooth time base for celestial photography from standard 60 Hz power. Normal time is based on the position of the sun. There are approximately 365.25 solar days in the year. A sidereal day is the average time between meridian crossings by a star. There are approximately 366.25 sidereal days in a year. This circuit multiplies standard 60 Hz power cycles and divides by a slightly different number in order to produce a signal that approximates sidereal time with an error of only about 1.8 seconds per year.","Lesson ID":527}
{"Driving Event":"Simulated acoustic emission signals were induced in a thin-walled graphite\/epoxy tube by means of lead breaks (Hsu-Nielson Source). The tube is of similar material and layup to be used by NASA in fabricating the struts of space station freedom. The resulting waveforms were detected by broad band ultrasonic transducers and digitized. Measurements of the velocities of the extensional and flexural modes were made for propagation directions along the tube axis (0 degrees), around the tube circumference (90 degrees) and at an angle or 45 degrees. These velocities were found to be in agreement with classical plate theory.","Lesson ID":509}
{"Driving Event":"During a drop test at the NASA Plum Tree Island Test Facility, a model was severely damaged due to failure of its parachute recovery system. The failure of the recovery system resulted from teflon cloth jamming closed the canopy compartment lockoff flaps. The teflon cloth had been wrapped around the suspension lines to expedite extraction of the folded lines. The parachute contractor design personnel chose to add the cloth because its lubricating effect on the suspension lines and the resultant lowering of the force required to extract the lines. The information concerning the design change and lower opening force was transmitted to the research project engineer by telephone conversation. Significantly, no confirming strip-out load tests were performed with the teflon wrapped lines prior to using them in an actual test. The primary finding of the investigation committee was that teflon cloth jamming prevented the bag from opening and the canopy extracting.","Lesson ID":517}
{"Driving Event":"NASA TM 107442 entitled, \"Monitoring Damage Growth in Titanium Matrix Composites Using Acoustic Emission\", has been published. This work was coauthored by J.G. Bakuckas (National Research Council Research Associate), W.H. Prosser, and W.S. Johnson and is the result of collaborative research between different LaRC offices. The publication describes the use of acoustic emission for the detection of different damage mechanisms such as fiber breakage, matrix cracking and plastic deformation, and fiber debonding in these composites.","Lesson ID":519}
{"Driving Event":"On 1-20-93, contractor technicians were tracing a 1\/4\" stainless steel air line in Building 1247E. The line, part of the 5000 PSI air system, was in an overhead support channel and the technician was tracing it with his fingers while standing on a 4' step ladder. While tracing the line, the pressure of the technician's fingers was sufficient to cause the line to separate at a union fitting. The tubing was clamped into the support channel on one side of the fitting and this section of tubing held fast. On the other side of the fitting the tubing was not clamped into the channel; on this side, after separation, a section of line approximately 10' long whipped into the air and became lodged in other piping in the area. Damage was minor (a 1\/4\" plastic water line was severed) and there were no injuries. Fortunately, neither technician was in the path of the loose tubing. Had they been, serious injury could have occurred. It appears that the cause of the fitting separation was the result of improper assembly of the union. A \"bite\" ferrule in the fitting failed to secure the stainless steel tubing in the union. Thus, the line was only secured by air pressure. Movement of the line for any reason would have been sufficient to cause joint separation.","Lesson ID":525}
{"Driving Event":"In preparation for a test in the tow tank, Naval Underwater Systems Center personnel, who operate the facility under an MOU, sought the recommendations of IRD for the purchase of thirteen wet\/wet pressure transducers with amplified outputs. The IRD recommended manufacturer was Druck and the appropriate specifications for transducers in their product line were provided to NUSC personnel. When the PR reached purchasing, the facility was informed that a GSA contract manufacturer would be the supplier. The GSA contract manufacturer was contacted by both NUSC and the instrument support section, IRD, since the needed items were not part of the GSA contract manufacturer's product line. The GSA contract manufacturer gave assurances that they could custom build the transducers to the required specifications. Twelve of the ordered thirteen transducers were delivered more than two months behind schedule and the thirteenth one-two weeks later. All the transducers passed acceptance tests and met or exceeded the original specifications. The first time the facility introduced a wet test medium (fresh water) into the transducers, the output of two transducers became very erratic and a third leaked water through welded seams in the transducer case. The two with erratic output were returned to the GSA contract manufacturer. The leaking transducer cannot be sent back without shutting down the in-progress test. Before the PR went out, ISS advised purchasing of the questionable quality of the GSA contract manufacturer's products, but according to purchasing, because of the GSA contract system, the GSA contract manufacturer had to be the supplier.","Lesson ID":528}
{"Driving Event":"The National Transonic Facility (NTF) is a transonic wind tunnel primarily intended to provide a high Reynolds Number test capability for aerodynamic research and the development testing of commercial and military aircraft configurations. On 1-18-89, the NTF experienced a Type A mishap, resulting in irreparable damage to all 25 fiberglass fan blades, significant damage to the upstream nacelle region and minor damage to tunnel internals downstream of the fan. The mishap was initiated by local failure (due to fatigue and fracture damage) of the External Thermal Barrier (ETB) retainer, resulting in high energy release of damage causing metallic parts. The Mishap Investigation Board determined that one factor contributing to the mishap was the failure of the Safety Analysis Reporting System. The ETB was not treated as a critical assembly or as a critical item of the ntf drive system (i.e. It was not recognized as a single point failure which could result in a Type A mishap). There were no inspection or maintenance requirements developed for the ETB retainer. A Safety Analysis Report (SAR) was not performed by either the contractor or NASA.","Lesson ID":502}
{"Driving Event":"The measurement of pressure fluctuations in hypersonic flow fields is much more demanding on dynamic pressure sensors than in traditional acoustical applications. Essential sensor specifications for measurement of pressure fluctuations in hypersonic flow are small size (<0.02 in.), height temperature (20000F), frequency response (200 kHz), and 0.01-10 PSI dynamic range. The recent availability of high-temperature optical fibers makes the intensity-modulated fiber optic microphone a promising instrument for obtaining these measurements. Small sensor size is desirable to obtain high frequency response and to reduce spatial averaging errors due to the finite size of the sensor. In order to minimize the correction factors needed to account for the latter, it is desirable to have a sensor diameter at least as small as 0.02 in. For measurements in hypersonic flow. One of the predominant considerations in hypersonic flow is the high-temperature environment to which the sensors will be exposed. Thus, materials used to fabricate such sensors must be stable in the attendant environment. Sensors whose transduction is based on a material (piezoelectric, piezoresistive, magnetostrictive, etc.) Cannot meet the high-temperature requirement with current technology. The condenser microphone has an inherent small-size limitation due to loadings by cable capacitance; further, if a polarization voltage is used, then the necessarily close proximity of the preamplifier to the microphone cartridge will preclude operation at high temperatures. The recent availability of high-temperature optical fibers makes the intensity-modulated fiber optic microphone a promising instrument to fulfill the above requirements.","Lesson ID":514}
{"Driving Event":"On 7-2-91 a LaRC electrical technician was seriously injured while preparing to check a 22kV nitrogen filled power cable in an electrical substation. When the technician came in proximity to an energized switchgear electrical terminal, an arc initiated, jumped to the technician's hand, passed into his arm, and exited from various parts of his lower body as well as from a key ring hanging from his belt. Langley Handbook (LHB) 1710.6, \"Electrical Safety\", defines safe distances for approaching exposed energized circuits. The LaRC investigation determined that the injured technician was less than the LHB 1710.6 mandated 3 feet from the injury causing energized electrical source.","Lesson ID":516}
{"Driving Event":"The Gateway Tether Experiment (GATE) is a single tether satellite system that will develop and test control technology for a tethered system. Originally a free flying tethered system released from a gateway special canister on the orbiter, the system is now one experiment in the Tether Dynamics Explorer (TDE) series launched by a Delta II. The system consists of a Delta II second stage and subsatellite connected by a single tether. The subsatellite contains a motorized reel mechanism that will be the primary means of control actuation. A prototype reel mechanism has been constructed for use in the GATE system and ground tested. The reel mechanism consists of a spool and a level wind mechanism that are driven by independent stepping motors. The spool is designed to hold 1.8 km of 0.075 cm diameter tether. A paper, \"Ground-based Implementation and Verification of Control Laws for Tethered Satellites\", by David A. Gwaltney (NASA Langley Research Center) and Michael E. Greene (Auburn University) was published in the Journal of Guidance, Control, and Dynamics in the edition of January-February, 1992 (pages 271-273). The paper contains system equations and discusses testing and testing results.","Lesson ID":518}
{"Driving Event":"On 11-12-92, research runs were being conducted in the unitary wind tunnel. During one test run, the downstream wood fairing on the model side mount splitter plate came loose and was destroyed as it went down the tunnel. The tunnel was not damaged, however, there was damage to some instrumentation tubing as well as lost research time. Although damage was relatively minor, this failure is significant because it was preventable. Subsequent investigation of the cause of the failure showed that not all of the required fasteners had been installed in the wood fairing, thus causing it to fail. In spite of the fact that the model was inspected more than once prior to the research runs being made, none of the inspectors noticed the missing fasteners. These inspection oversights ultimately led to model failure as well as the failure of the test being run. The damaged instrumentation tubing was replaced. A new wood fairing, this time secured by all required fasteners, was made by the LaRC model shop.","Lesson ID":521}
{"Driving Event":"On 5-2-85, a mishap occurred at the water tunnel at Building 1234. While the tunnel was filled with water for leak checks, the test section door detached from the test section, resulting in 3500 gallons of water escaping the tunnel and the building. Significant damage resulted to the test section door, model support mechanism, test section, flow channel, and the honeycomb flow straighteners. The cause of the accident was the prying action between the door and the adjacent wall. This prying action, which was not considered in the design analysis, created stresses in the lucite door material beyond its flexural strength. There were other errors in the door design, to include: stresses were not combined (however, in the analysis performed - prying action not included - the material strength would have been sufficient for the loads considered). Acrylic materials should not be tapped and threaded (manufacturers recommend use of oversize bolt holes, grommets, and washers to minimize stress from through bolting) as was done with the test section door; and, framing, which could have provided for the load, was not used. The tunnel critical design review stipulated that, due to the effects of vibration, the water tunnel and the jet exit facility should not be run simultaneously. Effects of the jet exit facility vibrations on the water tunnel were not considered in the analysis.","Lesson ID":522}
{"Driving Event":"A maintenance team was removing a gate valve from a high pressure (5000 pounds per square inch) nitrogen trailer at the fill end of the trailer. After the valve bolts were removed and the employee tapped on the valve to loosen it, the valve flew off and hit one of the maintenance employees. The employee was thrown 15 feet through the air and against an I-beam, resulting in a fatality. Preliminary information indicated that the system was not under pressure and the valve gauge reading was zero pressure. [This event occurred during work external to NASA but includes information that is pertinent to NASA operations.]","Lesson ID":499}
{"Driving Event":"A JSC forklift operator struck and broke a 3\/4 natural gas supply line servicing a suspended forced air gas heater in Building 422. The operator was moving a material pallet from the top shelf of storage bin. As he was backing the forklift to lower the load, the extended mast of the forklift struck the natural gas line. Due to the escaping gas, operations were shut down and the facility evacuated. Root cause was the failure to perform a job hazard analysis and eliminate or control those hazards. The layout of storage in close proximity of suspended heaters should have been corrected. Also, scars and scratches on this and other gas lines and heaters is evidence of pervious physical contact.","Lesson ID":498}
{"Driving Event":"A fatal accident involving the Ames\/EFRF T-37B Jet Trainer (NASA 807) occurred east of California City, CA. at approximately 1:15 P.M. (PST) on November 8, 1982. NASA pilot Richard E. Gray was killed. The aircraft was totally destroyed by ground impact and fire. There were no other personnel injuries and no other property damage. Every attempt to establish probable cause has been unsuccessful. In the course of the research support flight, T-37B entered a spin resulting in an uncontrolled flight condition, and the pilot delayed ejection until a successful ejection was no longer possible.","Lesson ID":493}
{"Driving Event":"On January 25, 1984, the National Geotechnical Centrifuge, located at NASA Ames Research Center, experienced a catastrophic failure of the 18,000 horsepower drive motor thrust bearing. The failure permitted the 100 ton drive motor armature to drop, the centrifuge to stop, and resulted in extensive electrical and mechanical damage. Repairs may take one year, and cost estimated at $550,000.","Lesson ID":494}
{"Driving Event":"December 9, 1982, the 80 x 120 foot wind tunnel at the Ames Research Center was undergoing commissioning\/shakedown testing when Vane Set 5 collapsed destroying the vane set, the fan blades of all six drive motors, and damaging the tunnel itself.","Lesson ID":495}
{"Driving Event":"In April 1991, the Galileo spacecraft executed a deployment sequence which was to open the High Gain Antenna (HGA) like an umbrella, but it never reached the fully deployed position. A formal failure investigation attributed the failure to the design of the rib retention mechanism. According to this scenario, the most likely failure mechanism is friction in the pin\/socket interface on the antenna rib midpoint restraint. Preloading of the ribs when the antenna was stowed at the factory damaged the ceramic coating on the pin engaged by the V-groove socket; the coating served to retain the molybdenum disulfide dry lubricant. Accumulated stresses from vibration testing, rib preloading, four cross-country trips, and the post-launch ignition of the upper stage further dispersed the lubricant film. The resulting friction caused asymmetrical deployment, resulting in restraining forces which further reduced the torque available from the deployment drive system. The HGA was largely inherited from an antenna developed for the Tracking Data Relay Satellite (TDRS) system. JPL design changes included substitution of two conical Inconel pin sockets with one conical and one V-groove Inconel socket. Selection of an Earth orbital antenna design, even though proven in that application, was not fully consistent with the Galileo mission. Inheritance and other design reviews failed to reveal the existence of high surface stresses. In addition, a lessons learned on Voyager II to use spring assisted mechanical deployments was not followed. The deep space mission subjected the redesigned antenna to environmental conditions not encountered by TDRS in Earth orbit, and the VEEGA mission profile instituted after Challenger extended both the duration of those conditions and the time to deployment. Galileo illustrates the difficulty of reproducing the spaceflight environment in the ground test of large and complex mechanisms, even when full design review and environmental testing are undertaken. Flight antenna deployment test failed to disclose the problem because (1) vacuum test was performed without the vibration-induced relative motion between the pins and sockets and (2) oxides and contaminants present during ground test on the bare titanium pins lubricated the mechanism. Similarly, ambient ground tests did not reveal the failure mode due to the lower coefficient of friction of the titanium pin\/socket interface in air. Additional testing of the deployment mechanism would only have worn out the deployment drive system. Work-arounds using the Low Gain Antenna, new data compression techniques, and the spacecraft's recorder are expected to meet 70 percent of the mission objectives. Reference(s): \"Galileo HGA Deployment Pin Walkout Analysis Final Report,\" JPL D-9932, July 1992","Lesson ID":492}
{"Driving Event":"International travelers should be prepared to deal with grounding problems that have been experienced by NASA personnel. As an example, several personnel have been electrically shocked while working at the Star City Training Complex and other Russian facilities. Improper or compromised grounding of 220v AC circuits has been found in these reported cases. [While highly unusual for 220v, this event is known to occur in American facilities on occasion.] Verification of grounds has been difficult in some cases, prompting the need for installation of independent ground to earth grounds. Reference(s): NASA JSC Safe Alert dated, 10\/27\/95","Lesson ID":490}
{"Driving Event":"Support contractor personnel contacted high voltage with a paint scraping knife while preparing a cable tray for painting in a facility \/ building transformer enclosure, causing a flash fire. Two of the worker\u00b9s clothing caught fire and nearby combustibles were ignited. Two workers sustained burns to their hands and faces when one of the workers inserted the knife in a vent\/drain slot. This accident did not result in permanent disability or death but the potential is evident. Reference(s): NASA JSC Safe Alert dated, 11\/01\/95","Lesson ID":491}
{"Driving Event":"Technicians were performing a maintenance operation on a Mazak CNC milling machine vacuum pump when a glass oil mist separator bowl burst. The subject bowl was attached to the discharge of a 3 hp Gast pump. This particular pump has the capability of producing 15 psi at the outlet if restricted. The rated pressure of the glass bowl is 5 psi, which is clearly marked with a warning regarding breakage. Prior to the incident, the pump had undergone overhaul and, after reinstalling the pump, the technicians operated it in order to circulate its lubrication oil. Once oil circulation was verified, the pump was restarted and the glass oil separator bowl ruptured. Fortunately, no one was injured by the broken glass. The technicians performing the task stated that there was no known restriction in the discharge piping downstream of the separator. It should also be noted that an identical separator is installed on the inlet of the vacuum pump. The incident prompted an investigation of other similar installations in the facility. The result was that a total of 3 machines are using the same oil separator configuration as the subject machine. These separators are factory installed and are standard equipment on these type of machines. To prevent injury from unanticipated glass fragmentation due to overpressurization of the oil separator, maintenance management personnel decided to install a wire cage around the pump discharge.","Lesson ID":488}
{"Driving Event":"An employee received an electrical shock while unplugging a printer from a 6 receptacle power strip surge protector. The surge protector was located behind some furniture, on the floor, and out of sight of the employee unplugging the printer cord. The surge protector had apparently become stuck to the floor from floor maintenance, the plastic case had separated, and energized electrical components were exposed. When the employee reached back to unplug the cord, he they received a shock from the exposed components.","Lesson ID":489}
{"Driving Event":"The Mars Observer propulsion system design was inherited from an Earth-orbital application and incorporated a pressurization system employing helium to maintain the propellant tanks at a constant pressure. Regulation of propellant tank pressure prevents the tanks from rupturing, which would likely cause loss of the spacecraft. As gases are exchanged, pressure regulators and check valves prevent propellant and oxidizer from entering the pressurization system and causing a hypergolic reaction. Although nominal leakage through regulator check valves is anticipated, the pressurization system is fully isolated from the oxidizer tank early in an Earth-orbital mission following achievement of final orbit. For a Mars mission, however, high propellant usage is not required until months after launch, and substantial amounts of nitrogen tetroxide (NTO) oxidizer may migrate upstream through the check valves. Since the Mars Observer pressurization plumbing was cold for much of the cruise, liquid or gaseous NTO migrating through the check valves could have condensed on the cold tubing. When the pressurization sequence was executed upon Mars encounter, liquid NTO could have mixed rapidly with monomethylhydrazine (MMO) fuel in the pressurization lines. The resulting combustion could have ruptured the tubing, venting the helium pressure tank, damaging Mars Observer or inducing an unrecoverable spin. The Mars Observer Special Review Board identified this scenario as the \"most probable cause\" of the mission failure. Additional Keyword(s): Bipropellant Propulsion System, Propellant Vapor Diffusion Reference(s): \"Adoption of an Earth-Orbital Propulsion System Design for a Planetary Mission,\" Lesson Learned No. 1-110. \"Report of the Mars Observer Mission Failure Investigation Board,\" December 31, 1993.","Lesson ID":485}
{"Driving Event":"As part of the Mars Observer mission failure investigation, the acceptance test lot of the Mars Observer pyro valves were examined for thread erosion. The pyros were suspect because of tests that had been made on European Space Agency (ESA) pyro valves and initiators, which showed that some firings result in the pyrotechnic initiator being ejected from the valve body at speeds of approximately 200 m\/s. The pyro valves and NASA standard initiators (NSIs) used aboard Mars Observer were designed to the same specifications, though they were not identical to the ESA hardware. During lot acceptance test, none of the ten pyro valves tested had failed-- all fired, and none ejected their initiators. Following the Mars Observer failure, examination showed that each of these valves had sustained erosion (burning) of about 50 percent of their threads. The erosion was caused by combustion of the titanium thread material with the combustion products of the initiator. This examination was not required in the original lot acceptance test of the parts. Were the thread loss to cause ejection of an initiator, severe damage to the spacecraft wiring, propellant tanks, and other critical hardware could result. For example, one of the Mars Observer initiators was located such that it would impact the monomethylhydrazine (MMH) propellant tank if it were ejected. The JPL Mars Observer Special Review Board considered a failed pyro valve charge initiator to be a potential cause of the loss of the Mars Observer mission. Reference(s): \"Report of the Mars Observer Mission Failure Investigation Board,\" (Coffey report), December 31, 1993.","Lesson ID":486}
{"Driving Event":"The Mars Observer propulsion system, like much of the Mars Observer spacecraft, followed design practices more common to earth-orbiting communications satellites than to planetary missions. This was consistent with the plan to reduce costs by mandating maximum use of industry practices. A significant weakness of the Mars Observer propulsion system was in the design of the pressurization system, which regulates propellant tank pressures during main engine maneuvers. For conventional earth-orbiters, where the pressurization system is used for apogee boost to establish the proper orbit, the pressurization system is required to function for only a few days following launch. Typically, the pressurization system is then isolated from the propellant tanks. This mission duty cycle makes such spacecraft essentially impervious to regulator leakage and the effects of propellant vapor diffusion within the pressurization system. This is not true of planetary missions such as Mars Observer, which require high propellant flow rates years after launch. With the Earth-orbital design, the Mars Observer propulsion system had inadequate flexibility in pressurization system isolation and marginal control of propellant vapor migration. This design limitation may have contributed to the loss of the Mars Observer mission. Of three likely propulsion-related scenarios identified by the JPL Mars Observer Special Review Board, two could be attributable in part to inadequate review and consideration of the differences between earth-orbiting and planetary propulsion applications. These potential causes were (1) propellant reaction leading to pressurization system line rupture and (2) tank rupture due to regulator leakage. Reference(s): \"Report of the Mars Observer Mission Failure Investigation Board,\" (Coffey report), December 31, 1993. \"Mars Observer Loss of Signal: Special Review Board Report,\" JPL Publication 93-28, November 1993.","Lesson ID":484}
{"Driving Event":"Incompatible materials in propulsion systems have posed a major risk to recent missions: Tungsten Carbide Ball Material: During JPL qualification test of the original candidate Cassini pressure regulator, the tungsten carbide\/nickel regulator ball was tested for compatibility with nitrogen tetroxide (NTO) and monomethyl hydrazine (MMH). Exposure to the NTO oxidizer for 28 days caused substantial corrosion of the ball, and a surface roughness corresponding to a 42% increase in surface area. Another regulator design was therefore installed on Cassini; use of the original design would have caused serious pressurant leakage and possible system contamination problems. Flow Restrictor Braze Material: The pressure sensing ports in the pressure regulators contain flow restrictors which allow the regulator to sense and respond to downstream pressure changes. During the Cassini and MGS regulator heritage reviews, it was discovered that the MO restrictors contained a copper-bearing (AMS-4774) braze and a wax lubricant, neither of which are compatible with NTO propellant vapor. Neither of these materials were listed on the materials list for the regulator. Long term exposure to this vapor could potentially produce enough corrosion products to plug the restrictor orifice, which would likely lead to an inability to sense the downstream pressure and failure to regulate tank pressure. Such extensive exposure of the same regulator to propellant vapors would not normally occur on an Earth-orbital mission where pressurization is only required for a short period immediately following launch. These materials were eliminated in the MGS and Cassini regulator design. One of the credible hypotheses which had earlier been posed for the loss of the MO spacecraft was the plugging of identical flow restrictors due to long term reactions of propellant vapors with an unspecified incompatible material. Teflon Swelling: When the Galileo spacecraft executed 3 large delta V maneuvers with the main 400 Newton engine, restricted helium flow through the check valves caused significant pressure drops in the propellant tanks. The pressurization system is designed to hold the tank pressures constant during propellant flow. Pressure regulator performance was found to be nominal, but the flight propellant tank pressure data indicated significant degradation of both the fuel and oxidizer check valves. Ground tests have shown that swelling of the TFE Teflon valve bushing and PFA Teflon seal due to months of oxidizer exposure duplicates the flight behavior of the oxidizer check valve. Additional Keyword(s): Heritage Hardware, Mars Observer (MO)","Lesson ID":487}
{"Driving Event":"Currently, only one method is available for determining an object's angle of impact against a structure: high speed photography. This method requires a great deal of equipment and produces data, which requires a great deal of time to analyze. Presently, the acoustic emission technique is being used to assess damage caused by the impact of an object. As now used, this technique does not provide information concerning the angle of impact. However, a patent was granted on 3-2-93 for a method for determining the angle of impact of an object on a thin-walled structure through analysis of the acoustic waves which result when the object impacts. Transducers are placed on and in the surface of the structure which sense the impact waves caused in the structure. The waves are recorded and saved for analysis. For source motion normal to the surface, the antisymmetric mode has a large amplitude while that of the symmetric mode is very small. As the source angle increases with respect to the surface normal, the symmetric mode amplitude increases while the antisymmetric mode amplitude decreases. Thus, the angle of impact is determined by measuring the relative amplitudes of these two lowest order modes.","Lesson ID":508}
{"Driving Event":"During laboratory system level integration and testing for a GSFC satellite at a contractor's facility, testing was delayed or reordered because of problems with the Instrument GSE. The Instrument teams arrived the same day that the testing was to start, and when the GSE was hooked up, there were problems. The ensuing troubleshooting process caused delays in the start of testing. In some instances, the test procedure was reordered to workaround the problem.","Lesson ID":482}
{"Driving Event":"The XTE Instrument Development Team experienced monumental problems with the development of the three small proportional counter detectors used in the All Sky Monitor Instrument. This was completely unexpected since the proportional counters were presented by the Instrument Development Team as low-risk heritage detectors that were nearly identical to detectors that had previously flown many times. As it turned out, the heritage vendor was unsuccessful in fabricating a working detector. After an exhaustive search by the Instrument Development Team, a second vendor was located in Finland. It took the new vender over a year to fabricate, test, and deliver the required three flight and one spare detector. Unfortunately, all of the detectors degraded after delivery and they needed multiple rework cycles of several months each to get acceptable flight detectors. The XTE Program Management Team was able to maintain the Mission schedule by installing degraded flight and\/or spare detectors on the spacecraft during Observatory integration, testing, and launch site activities. The flight detectors were finally installed at the launch site.","Lesson ID":479}
{"Driving Event":"A new telephone system went into a total failure condition and remained that way for 10 1\/2 hours. This failure resulted in the entire lab being without telephone service, external calls, internal calls and VMX service. The investigative team concluded that a switch failure caused the system breakdown. A contingency plan containing emergency procedures for a telephone system collapse was created.","Lesson ID":474}
{"Driving Event":"A battery that was left on a charger over the weekend was used to start a gasoline power generator. This battery was connected in series with another battery and the connection on the negative post was hand tightened. When an attempt was made to start the generator, the battery exploded on approximately the fifth click of the starter solenoid. No damage was done to any equipment or facilities and no one was injured. The most probable cause of the accident was the severe overcharging of the battery (64 hours at 20 amp\/hour). This charging created hydrogen, which combined with air or oxygen and an ignition source to form the explosion. One source of ignition could have been the loosely attached connection to the battery terminal. Another possible source may have been an internal short at the battery plates, distorted by the severe overcharge condition.","Lesson ID":473}
{"Driving Event":"During ground operations at KSC, the first United States Microgravity Laboratory (USML-1) experienced canister fit problems with the LiOH flight storage containers. This resulted in significant overtime and nearly caused delay of the orbiter move to the Vehicle Assembly Building (VAB). The cause of the problem was that a fit check of the canisters in container foam was not done in the flight configuration at Huntsville, Alabama.","Lesson ID":475}
{"Driving Event":"One of the first United States Microgravity Laboratory (USML-1) pre-mission timeline constraints addressed the number of hours that a crew member could be scheduled for payload operations. For the first four shifts of the missions, crew members could only be scheduled for 70% of the available time. For the remaining shifts of the mission, 90% of their time was available for experiment operations. The crew's comments indicated that this constraint was very valuable in preventing fatigue and supported the period of time during which space adaptation was occurring. However, because of the learning delay, experiments were unable to achieve science objectives during initial runs. As a result of this mission, it was recommended to continue the use of the timeline constraint for crew utilization and include more time early in the mission for a learning curve for the crew's Zero-G skills.","Lesson ID":476}
{"Driving Event":"The transmit antenna on the Advanced Communications Technology Satellite (ACTS) has the capability to traverse in both elevation (north-south) and azimuth (east-west) directions in order to adjust the alignment between the transmit and receive antennas. The adjustment was to be accomplished by using a bi-axial drive assembly mounted between the transmit antenna and the spacecraft. The bi-axial drive assembly consists of two axial drive mechanisms mounted orthogonally. Each drive mechanism contains a stepper motor capable of rotating a minimum of 0.30 degrees in either direction, in steps of 0.0075 degrees +\/- 0.0015. The structural joint between the bi-axial drive assembly and the transmit antenna was designed to accommodate final adjustments for final positioning or alignment of the transmit antenna. The joint was held by friction with shims via four bolts through large holes to allow for adjusting or shifting of the transmit antenna for final RF alignments. The mechanical joint between the bi-axial drive assembly and its mounting to the spacecraft allowed the transmit antenna to shift locations during launch aboard STS-51. The four bolts did not maintain the proper preload and the joint slipped during launch loading. This has reduced the available design adjustment range for the ACTS transmit antenna.","Lesson ID":478}
{"Driving Event":"In the gathering of test data for IRT fan blades, data was extrapolated for test section airspeeds greater than approximately 200 mph using the 20% air blockage models. A desire was expressed for more accurate results of higher test section airspeeds ranging up to 350 mph using the 20% air blockage models. A temporary method was found which would provide the desired airspeed at a relatively low cost. This new method consisted of replacing the original fan blades, installed in 1944, with a modified set of spares. The modification included reshaping the blade hubs to an increased angle of attack of 5 degrees. The modified fan blade's performance with a reasonable stall margin was calculated to have increased the test section airspeed from 190 mph to 245 mph using the 20% air blockage model. In addition, the drive motor, rated at 5000 hp, only required 2400 hp at 300 mph and maximum rpm. The modified fan blades will take advantage of the remaining horsepower with no alterations of the motor.","Lesson ID":477}
{"Driving Event":"Various times throughout 1960-1975, functional problems were encountered because a set of connectors were unmated or contacts in the connector were deformed as a result of misalignment during mating. The unmated connector condition was the result of deviating from normal processing. Break of inspection sheets were added to applicable logbooks to alert test technicians and engineers of the unmated connectors. When the connector was remated, the condition was verified on the break of inspection sheet. Deformed contacts were often the result of slightly bent pins or the misalignment of pin and socket at the time of mating. Tapered socket entry reduced this problem. Misalignment of replaceable contacts was sometimes caused by wire routing at the rear end of the connector. If inspectors had performed a visual examination of both connectors prior to mating, misalignment of contacts would have been greatly reduced. Further information can also be obtained by contacting the Reliability and Quality Division of Loral Vought Systems at P.O. Box 650003, Dallas, TX, 75265-0003 or calling (214) 603-1000.","Lesson ID":470}
{"Driving Event":"Recessed electrical contacts in connectors, with replaceable pins or sockets, were observed as a result of a functional failure or during visual examination. The contacts were either not properly locked or became unlocked in the connector insert. During connector mating, the mating contact would push the contact backwards. Improper locking was often the result of deformed or broken retention clips. The Scout Program fabricated a set of push test tools. These tools have the proper mating contact and permit the application of an appropriate force on the contact in an assembled connector. After initial wiring and modifications of the electrical connector, a push test was performed on each contact in the connector. Contacts and connectors failing the push test were rejected per established procedures.","Lesson ID":472}
{"Driving Event":"During ground operations at KSC, the first United States Microgravity Laboratory (USML-1) took longer than projected to perform a special module acoustical test. This occurred on the last Mission Sequence Test (MST) day and caused the MST time slice to be shortened. MST days are scheduled as full 12-hour test days and have no room for special tests.","Lesson ID":469}
{"Driving Event":"A number of H2O2 motor valves in the H2O2 fuel system of the Scout Missile experienced leakage due to contamination of the valve's teflon seats. Failed parts analysis revealed minute stainless steel particles embedded in the teflon seats. This contamination prevented complete closure at the poppet to seat interface. Examination of the contamination exposed particles larger than 20 micron. Each valve was protected at the fuel inlet by a 15-20 micron filter. An extensive failure investigation discovered that the contamination was being induced by the stainless steel filter itself. Fabrication of the filter was accomplished by press fitting an inner ring into a larger diameter ring after inserting the meshed screen circular filter. This technique essentially sandwiched the screen between the two rings. Bi-sectioning of several filters revealed that the frayed ends of the meshed filters screen were being temporarily trapped between the rings. Subsequent high pressure fuel flows usage dislodged the particles and the resultant contamination. Since the contamination was being released behind the filter, the filter was ineffective.","Lesson ID":471}
{"Driving Event":"Functional failures were attributed to varying resistance values through crimped electrical connections (contacts, splices, terminals). The variation was from several milliohms to open circuits. Microscopic examination of the cross-section of the crimped area revealed either insufficient crimping or excessive deformation of the wire strands. Samples of the various combinations of crimp connections (connector pins, connector sockets, terminal lugs, or splices) and wire gauges were made using various crimp tools and settings. Cross-sectioning of these samples indicated that the manufacturers' recommended settings and positioners did not always provide the best crimp conditions. Pull test results on similar crimp connections correlated with the cross-section conclusions. In 1975 the Scout Program established its own crimping standard, which specified the crimp tool model, contact positioner, and setting (if applicable) for each connection type (manufacturer and part number), single or double leads, and stranded wire gauge. Crimping on solid buss wire was not considered acceptable. All applicable personnel were trained and certified on crimping and assembling contacts on connectors. Each day a specific crimp tool (serial number, model) was used, two samples of the specific anticipated combination (contact part number, wire gauge(s)) were made and each sample was subjected to a pull test. Both samples had to meet the established pull test requirements, which were based on the wire gauge capability. After meeting the pull test, the production hardware contacts were crimped. If a sample failed, then the tool was rejected per established procedures. Similar crimp contact controls have been imposed on applicable vendors and subcontractors.","Lesson ID":465}
{"Driving Event":"On March 25, 1993 an Atlas\/Centaur launch vehicle (AC-74, Atlas1) inserted a Hughes UHF follow-on spacecraft into orbit with an apogee altitude of 4,967 nmi instead of the targeted nominal of 9,098 nmi. Although functioning normally, the satellite was declared a loss by the Navy due to the unacceptable orbit. The investigation team concluded that the precision regulator in the booster engine system failed. The output pressure of this regulator controls the output power level of the booster engine, which caused the decline in thrust. This failure was caused by the stem screw rotating and decaying the output of the precision regulator. This precision regulator had been reworked twice during its build to repair excessive vent port leakage. The first authorized rework required loosening and retorquing the set screw. The set screw has been redesigned so that it is custom made for each mission. The length of each screw is predetermined and inserted so that rotation is impossible to achieve. Further information can be found in the AC-74 Anomaly Investigation Summary Report.","Lesson ID":463}
{"Driving Event":"On August 22, 1992 an Atlas\/Centaur Launch Vehicle (Atlas 1, Launch AC-71) carrying a Hughes Galaxy I-R Spacecraft was destroyed in flight. The Centaur C-1 engine had failed to achieve full thrust, resulting in an uncontrolled tumble of the vehicle. The guidance system, sensing that the vehicle had not achieved proper acceleration, shutdown both engines and instituted a restart sequence. Once again the C-1 engine failed. Full thrust was achieved by the C-2 engine both times. In lieu of the C-1 thrust failure the vehicle was destroyed by the range safety officer. To start reliably, the RL10 engine requires proper fuel and oxidizer pressure at its pump inlets and the fuel and oxidizer pumps to be at the proper cryogenic temperature. The engine temperature results from a two-stage chilldown process. The prelaunch chilldown is provided by ground dewars supplying pressurized helium. Each RL10 engine receives the flow of helium through a check valve. These valves should close when the flow is terminated to prevent further flow of any gas through the engine via the chilldown ducts exiting the vehicle. The state of the chilldown check valve was not monitored. As a result, the check valve of the C-1 engine was not closed and an ingestion of air occurred which eventually caused the engine to fail. The investigation team also concluded that AC-70's failure is due to the same cause as AC-71. For more information on AC-70, see AC-70 Anomaly Investigation Summary Report. Further details on the AC-71 failure are found in the AC-71 Anomaly Investigation Summary Report.","Lesson ID":467}
{"Driving Event":"During the visual receiving inspection process of the fourth stage Altair IIIA motor for a 1984 launch from the Wallops Flight Facility, a delamination was found in the silica phenolic exit cone liner. A similar delamination was found in a nozzle being processed for a Vandenberg Air Force Base launch. An immediate visual, ultrasonic, and radiographic inspection of the remaining inventory of silica phenolic exit cone liner nozzles found one other nozzle that was suspect. The same inspections were completed concurrently for inventory nozzles that included graphite phenolic exit cone liners. No delamination indications were found in the carbon phenolic exit cone liners. The delamination was determined to be a moisture related problem associated with silica phenolic. A monitoring program was established for the remaining silica phenolic nozzles and carbon phenolic nozzles. This monitoring consisted of storing the nozzle assemblies in the Dallas Scout Logistics Area, monitoring humidity, and attaching gages to one of the carbon phenolic nozzles and a dissected nozzle piece to measure strain on a periodic basis. Visual, ultrasonic, and radiographic inspections were completed at Dallas just prior to shipment to verify that a flightworthy nozzle would be shipped to the field site.","Lesson ID":466}
{"Driving Event":"Motor information was routinely tabulated during the manufacture of solid rocket motors. This information was furnished by the motor vendor (or obtained by resident representatives) from in-process propellant mechanical and ballistic properties testing. Typical properties included stress, strain, density, liquid-strand burn rate, propellant burn rate from subscale motor testing, and peel strength. Once logbooks were available, other parameters were tabulated. Typical properties were motor assembly total weight, propellant weight, case weight, linear weight, insulation weight, igniter propellant weight, igniter assembly weight, and nozzle assembly weight. Post-flight motor performance information was tabulated for all flights (some fourth stage motors were not instrumented). Information items included thrust and chamber pressure. From these items were calculated Isp, total impulse, web burnout time, total burn time, and the pressure integral. Beginning in 1984, age related information was accumulated for the solid rocket motors to aid in engineering evaluation of motor shelf life. Typical information accumulated from storage site inspections, return-to vendor inspections, or launch site receiving inspections which included propellant shore a hardness, radial slot width measurements, and visual inspections of the propellant grain surface and bond lines. As a result of the evaluation of motor shelf life, the Scout Program has been launching vehicles with motors that are well beyond the shelf life established by the motor manufacturer. Motor production to replace aging motors is costly. Use of the tabulated age related information allowed engineering and quality\/reliability personnel to extend motor shelf life. New production was not required. Inventory motors could be flown. Further information can also be obtained by contacting the Reliability and Quality Division of Loral Vought Systems at P.O. Box 650003, Dallas, TX 75265-0003 or calling (214) 603-1000.","Lesson ID":462}
{"Driving Event":"The first United States Microgravity Laboratory (USML-1) pre-mission timeline approximated 20 minutes for the payload crew to activate the payload. Since extra time was necessary for the crew members to adjust to zero-g, the actual payload activation time was approximately 55 minutes. In future flights it is suggested that more time is allotted on the first shift for payload activation.","Lesson ID":464}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) Voyager 2 experienced gyro control problems during launch because its failure protection logic was enabled. Attitude control required data about all three spacecraft axes: roll (R), pitch (P), and yaw (Y). The three 2-axis gyros on Voyager provided data, respectively, about the R-P, P-Y, and Y-R axes. Thus any two gyros together provided the required three axis data, plus a fourth, redundant set of data about an axis common to both gyros. The third gyro acted as backup. The gyros, not needed until just before separation from the Titan\/Centaur, were left \"on\" and thus warmed up during launch to ensure immediate readiness. The failure protection logic, also left enabled during launch, sensed failure by comparing the output of the axis common to both controlling gyros. If not equal, the \"back-up\" replaced one controlling gyro. If still not equal, the gyros were switched again. Continued inequality among all possible gyro pairs caused the logic to look elsewhere for the problem. It was understood a priority that the gyro output would \"saturate\" during launch, and that this saturation output would be at equal limiting values, thus ensuring a valid logic comparison. Instead, however, the output oscillated significantly, causing a mis-comparison. Telemetry then indicated the series of \"gyro swaps\" as the failure protection logic attempted unsuccessfully to pair gyros having equal output. This led Mission Operations to suspect a major failure on Voyager 2.","Lesson ID":409}
{"Driving Event":"Microscopic inspection under 10X magnification of a completed Ranger Central Computer and Sequencer (CC&S) Subsystem revealed a relatively large number of cracked glass cases in axial lead diodes. The fractures frequently extended lengthwise along the glass case from lead entry to lead exit at the opposite end. The fractures usually occur at the edge of heavy accumulations of hard set epoxy based conformal coating and\/or spot bonding materials used to secure the components to substrates. The problem was found to re-occur with several similar types of coating\/bonding materials then and still available. This problem necessitated the development of a new process to soften the coating\/bonding material, and stripping the material away from hundreds of glass diodes. A large number of fractured diodes were replaced. The problem was also evident in other subsystems which had been built prior to discovery of this problem. Subsequent investigations into other applications where these materials were used revealed the existence of cracked glass diode cases in a Mariner Attitude Control (AC) Subsystem under construction at another contractor. The source of the cracked glass problem was traced to an .8% Shrinkage factor during the cure cycle in the coating\/bonding material, which also had very good adhesive properties. Contraction in a heavy application of the hard set coating or spot bonding material which enclosed 50% or more of the diode case diameter literally pulled the glass case apart. Those which do not fracture during the cure cycle may be assumed to be severely stressed, and possibly subject to failure under subsequent environmental exposure, including acceptance testing and flight exposure.","Lesson ID":460}
{"Driving Event":"The excessive torque problem was due to improper assembly. The mechanical stop mounting screws were loose permitting the mechanical stop to move away from the housing toward the control housing.","Lesson ID":454}
{"Driving Event":"A flight life support system battery leaked when a vendor substituted the certified material with a substitute in the manufacturing of the relief valves and the electrolyte decomposed it. The vendor certification was for the original material only. Substitute materials generally require recertification prior to use.","Lesson ID":455}
{"Driving Event":"APU 2 Fuel Pump Heater was cycling high during flight. Detailed analysis of the thermal switch showed extreme wear from the switch bi-metal disc and case. Large amounts of conductive contaminates were found. Analysis showed that they came from the disc and case. It is concluded that excessive vibration caused the wear and in zero gravity particles were free to migrate into the electrical contacts, resulting in a higher disc deflection to open the thermostat contacts. The result is a higher heater turn off temperature.","Lesson ID":449}
{"Driving Event":"When a quick disconnect was checked for compatibility with hydrazine the \"O\" seal disintegrated. It was found to have been made of material other than the required Ethylene-Propylene Rubber (EPR) material. The distributor had provided a certificate of conformance traceable to a seal manufacturers lot number. Upon a request for the manufacturers certificate of conformance they could not provide traceability for 40 pieces of a lot of 500 seals. They provided traceability for 460 of the seals.","Lesson ID":451}
{"Driving Event":"During repressurization of a test chamber, ammonia in a test article heat exchanger froze resulting in rupture of the exchanger. The rupture caused pressure to build up in a second test support unit. This second unit had a pressure relief valve, which was released when the pressure exceeded the upper limit, spilling ammonia into the work environment. The facility had to be evacuated. The root cause of this mishap was failure to treat \"low hazard\" systems, when connected to ammonia systems, as ammonia hazard systems. Had this been done, the design of the relief valve would have been configured to preclude direct venting of the valve into the facility work environment.","Lesson ID":457}
{"Driving Event":"While installing electrical cables into a conduit in the Johnson Space Center Mission Control Room, the conduit was displaced from its mounting, and then contacted and broke a chilled water line. A portion of the room was flooded. The installation procedures did not include details for using sufficient lubrication on the cables being pulled through the conduit. Also, no cautions or warnings were provided to alert the electricians to take additional precautions to prevent accidents in a high value, mission essential area. Other factors that increased the extent of damage included; (1) An emergency plan that did not include water leaks, and (2) No information was available to the maintenance or operations personnel on the location of or access to shutoff systems. The investigation board recommended correcting the deficiencies in the work procedures, emergency plans, and Mission Control allowable work policies. Also recommended was increased training of personnel to include these improvements.","Lesson ID":450}
{"Driving Event":"During an engineering test, organizations external to the test organization were performing maintenance activities in the test vicinity. Welding was being performed in a test facility, which resulted in the deactivation of the facility's fire alarm bells during the first few days of a test. This condition was discovered by chance observation and not during inspection nor during normal pre-test activities.","Lesson ID":458}
{"Driving Event":"The failure analysis of a temperature probe for a cryogenic hydrogen system was investigated by instrumentation systems engineering for effects on the instrumentation system (loss of output from one temperature sensor which is minor). The potential effects of the defective weld (piece of the probe entering the liquid hydrogen system) was not recognized till later as catastrophic.","Lesson ID":452}
{"Driving Event":"Flight deck (left side) smoke detector failed self test. Ground procedures specify alarm must sound within 120 seconds. Flight procedures specify alarm must sound with 15 to 25 seconds after activation.","Lesson ID":453}
{"Driving Event":"Electrical test determined no electrical shorts to case. However, an internal direct short was detected. Attempts to restart pump should not be less than 60 seconds elapsed time.","Lesson ID":456}
{"Driving Event":"Recently on a Goddard Space Flight Center (GSFC) spacecraft program, a contractor had concluded successful live fire tests on the EEDs (Electrical Explosive Devices, also called Pyros). Subsequently it was found that the live fire tests had not only fired the EEDs but had also damaged the drive circuit. The damaged component was the EED circuit fusing element. This component would not provide sufficient energy to fire an EED when required during the mission. This then could have resulted in failure to fire EEDs during the mission. GSFC engineering had mandated that the drive circuit be tested after the live fire test. This drive circuit test was to demonstrate the drive circuit vitality. Fortunately, the mandated tests were done, the damaged parts found and appropriate corrective measures taken. The last paragraph of this document contains a test recommendation to preclude launching with a \"dead\" EED system (typical I&T EED tests may appear to be successful but the typical test can actually damage the EED drive circuit). This paragraph was written as an executive summary with the last paragraph being the summary recommendation. The other paragraphs provide more detailed information on the problem. Early concerns about the Pyro circuit design included unconventional EMI shielding, unconventional EED firing via a ground pulse, firing current sustained after initiation, overcurrent protection by using a resistor (current-time curves were not available from the contractor), and the safing plug location that precludes verification of EED status. The Contractor maintained that the design was the same as that used repeatedly on all of their programs. (It was subsequently discovered that the fire pulse design has not been consistent on their programs.) The contractor also maintained that the design minimized hazard risks and therefore was acceptable. They were insistent that since they had already fabricated the assemblies a change to the design would substantially impact the program. GSFC insisted that as a minimum after any EED test firing, the Contractor must conduct a test to verify the resistance value of the EED fusing resistors. No change was made by the contractor to alter the unconventional EED firing via a ground pulse. [D] During the tests to verify the resistance value of the EED fusing resistor, it was discovered that in one channel the fusing resistor value was 15 times the required value. Therefore, the fusing resistor would no longer activate a flight installed EED. When the assembly was opened, the resistor was found to be charred. Evidence points to this being a result of EED firing via a ground pulse and the EED establishing an internal path to ground that resulted in a sustained current until the pre-arm\/arm path was interrupted by fusing resistor failure. Another fusing resistor was also discolored but had the correct resistance value. The discolored resistor was then further tested to confirm that it could provide additional adequate fire pulses. The Contractor did limited testing and confirmed that the discolored (but correct resistance) fusing resistor was capable of repeatedly providing fire pulses with adequate energy. This result appears to confirm that a measurement of resistance value was adequate to determine drive circuit functionality. The mechanism for the damage appears to be the ground firing pulse combined with the known effect of EED shorting to case during discharge. The enclosed figure is a simplified diagram of the ground firing pulse configuration. The prearm and arm contacts are closed or opened by ground command for extended periods. The duration of positive voltage application is mostly dependent upon intervening operations. However, a minimum duration on the order of a few hundred milliseconds would be expected from the contractor's implementation. The fire pulse is a 40 ms ground activation pulse. If the prearm and arm commands are executed, the EED only needs the fire pulse ground connection to initiate. Once the fire pulse occurs then a \"sneak\" circuit can occur internal to the EED by either the bridge wire shorting to the EED case or by a low resistance plasma path to the case (information seems to indicate that this kind event occurs in about 4 percent of EEDs). If this happens, high current will flow until either the fusing resistor opens or the prearm or arm functions are deactivated. A short duration fire pulse on the positive voltage side would not have caused fusing resistor damage. If the fire pulse were placed on the positive side of the circuit instead of the ground side a high surge current could still occur but only for the duration of the 40ms fire pulse instead of the much longer duration of the prearm and arm relays.","Lesson ID":448}
{"Driving Event":"In the time period of 1960-1975, a generic problem was encountered on several Scout Vehicle components containing elastomer O-Rings. During the Scout Production Procurement, components such as regulators and hydraulic actuators were a source of problems due to leakage after initial acceptance tests. An extensive investigation and long surveillance period determined the cause of the leakages to be the O-Ring set. The type of set used was not the well-known permanent set of an elastomer, but rather a much shorter time duration. This was to allow the elastomer to seat in its permanent position in the groove, allow distribution of lubricant, etc. Corrective action was to allow a time period after component assembly and acceptance testing. Further information can also be obtained by contacting the Reliability and Quality Division of Loral Vought Systems at P.O. Box 650003, Dallas, TX, 75265-0003 or calling (214) 603-1000.","Lesson ID":445}
{"Driving Event":"A roof fire occurred in Cell 23 of Building 35. An Accident Review Team concluded that the cause of the fire was the inoperability of the water quench system used to cool the hot combustion gases exiting the test section. The problem was that the ACROMAG Transmitter was not plugged in and had remained closed. It did not regulate the appropriate amount of quench water for a given hot exhaust temperature. The quench water system had facility alarm and shutdown meters which monitored exhaust gas temperatures downstream of the quench spray station. The high limits for these meters were set too high (800 and 860 degrees F, respectively) and should have been set at 650 degrees F. These meters were designed to monitor the exhaust gas temperatures and shutdown the fuel system if the limits for the exhaust gas temperatures were exceeded.","Lesson ID":442}
{"Driving Event":"The first United States Microgravity Laboratory (USML-1) located in the Spacelab of the shuttle (STS-50) was not continuously monitored due to insufficient notification of the latest flight procedures. The contingency flight procedures allow for Spacelab power-up in the event of system low temperature and power-down when the orbiter proceeds to ground cooling. Due to an anomaly with the orbiter ammonia boiler system, the flight procedures were altered the day before landing with the decision to power-up Spacelab. The flight procedures were altered again on the landing day with the decision to leave Spacelab powered after the orbiter proceeded to ground cooling. The Spacelab was left in this condition when the orbiter was turned over to KSC. Since KSC-Payloads Group was not informed of the condition, they did not monitor Spacelab's activation nor the several hours of power-on operation.","Lesson ID":446}
{"Driving Event":"At the Loral Vought Systems in Dallas, Texas prior logbook test data history was evaluated as part of a normal failure investigation. During this review a trend in data was sometimes observed that indicated a prior drift or shift towards an out-of-tolerance condition. The Scout Program initiated a test data monitoring program on selected assemblies. Design, quality and\/or reliability engineers reviewed the test data after each retest on the assembly or vehicle level. The appropriate engineer maintained supplementary notes. The list of assemblies to be monitored grew as additional parameters were identified. Typical parameters monitored were: Spin-up time, mass unbalance and null voltages on gyros Receiver and transmitter frequencies on beacon transponders Output frequencies of voltage controlled oscillators Resistance measurements on relay assemblies Discharge times at constant current on rechargeable batteries De-spin time on bearings This practice has been in place since the beginning of the Scout Program in 1960.","Lesson ID":447}
{"Driving Event":"During mating of the Magellan Spacecraft connectors within the forward equipment module (a confined space with limited visibility), the technician observed sparks, flames, and smoke. The primary cause was the inadvertent mating of at least two pins of the spacecraft harness connector P2 to connector J3 of Battery 1. The mismate of these connectors created an electrical short circuit within the J3 connector that, using the energy stored in the battery, produced the damage on Battery 1, connector P2 and the battery thermal blanket.","Lesson ID":444}
{"Driving Event":"During the removal of power to a transformer prior to it being serviced, an accidental 2400 Volt line to ground short circuit was created resulting in minor injury to a technician and minor hardware damage. The major contributing factor to this mishap was the use of a drawing that was not adequately checked after additions and changes had been made to the system. The secondary factor was that the technician did not test the voltage on the line side of the potential transformer compartment to verify that the bus was in fact de-energized.","Lesson ID":443}
{"Driving Event":"When the Mars Observer (MO) spacecraft was installed on the launch vehicle at KSC, an air conditioning duct and a Nitrogen purge system were installed at access points to the shroud over the MO spacecraft. Following activities associated with a hurricane, a payload cable inspection showed the spacecraft's external surfaces to be heavily contaminated with particulate matter. This led to delay of the launch, and removal of the spacecraft to the preparation facility for cleaning. The source of the contamination was never identified with certainty, but available evidence pointed to piping in the air conditioning system as the most probable source of the contamination, with the Nitrogen purge system also a possible source. Following replacement of piping in the air conditioning system, a purge of both piping systems, and the addition of a Nitrogen filter, the problem did not re-occur. On the TOPEX project, a similar event was averted at a contractor's facility, after a resident JPL QA representative requested a particle count on the output of a Nitrogen delivery system. The output was found to be heavily contaminated, which necessitated the use of a newly cleaned and tested purge cart. Although pure Nitrogen was manufactured on-site, the delivery system included passage through an aged distribution system, whose interior had deteriorated. Reference(s): PFR #54717","Lesson ID":441}
{"Driving Event":"Following an April 1993 in-flight failure of an Upper Atmosphere Research Satellite (UARS) Earth Sensor Assembly (ESA), the vulnerability of identical ESAs aboard the TOPEX spacecraft was investigated. UARS experienced a sudden in-flight failure of the ESA rotating prism motor attributed to the use of perfluoropolyalkyether (PFPE) based lubricant on titanium bearings. Pure titanium debris produced by spalling of the motor shaft chemically reacted with the fluorocarbon-based lubricant, causing polymerization of the lubricant. In the presence of debris, bearing race-to-ball friction produces enough heat for the titanium to react with the lubricant, given that titanium is very reactive when exposed. The degradation mechanism consists of two steps: (1) the reaction of PFPE molecules with freshly exposed titanium particles to form an acid followed by (2) the reaction of the acid with unreacted PFPE molecules, resulting in cleavage of their molecular bonds. This failure mechanism was confirmed in a life test performed by GSFC on a spare UARS ESA motor. The PFPE oil was suspected of causing problems in at least seven units identical to the TOPEX ESA. Reference(s): \"UARS ESA-1 Failure Study,\" Martin Marietta Corp., August 3, 1993. \"TOPEX Earth Sensor Motor Review,\" June 23, 1994, ITHACO, Inc. \"TOPEX\/Poseidon Earth Sensor Assembly (ESA) Operation,\" Fairchild Space & Defense Memo No. 968:TOPEX:94-032 to Mark Fujishin (JPL), August 19, 1994.","Lesson ID":439}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) The Voyager Photopolarimeter Subsystem on both S\/C-31 and S\/C-32 has a history of analyzer and filter wheel stepping problems. The problem was discovered late in the test program before launch. The problems persisted in Flight with the analyzer wheel becoming unsteppable. Filter wheel could be stepped marginally, but that was also given up. Numerous in-flight operational fixes were tried without success. Failure analysis by the PPS Diagnostic Working Group has traced the probable cause of this anomaly to formation of an insulating \"frictional polymer\" on PPS potentiometer wiper contacts. Such a polymer can be formed by the sliding action of metals in the presence of small quantities of almost any organic molecule. This polymer formation reaction was noted as early as 1958 by the Bell System in researching relay failures. Palladium is a particularly efficient catalyst for this reaction - unfortunately, the PPS wipers are made of a palladium substance. Additional Keyword(s): Contamination, Electrical Contacts Reference(s): ISA's 1392, 1420, 1677, 1720, 1899 (Also see PPS ISA's for VGR-2 Encounter)","Lesson ID":438}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) To prove that electrical connections were properly made, a test of motor control circuits was included after fueling and pressurization of tanks. Commands were issued and executed which \"clicked\" the solenoid pilot valve for Surveyor motor control. Subsequent analysis exposed the fact that the motors could have fired if slightly higher pressure had been present in the fuel tanks. The test observer listening for clicks could have been badly burned and the spacecraft destroyed. Additional Keyword(s): Safety, Hazardous Test, Redudant Protective Elements","Lesson ID":426}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) During the fabrication of the Television Infrared Observation Satellite (TIROS-N) Microwave Sounding Unit, fluids used to clean chassis mounted connector penetrated around and through the connectors to the interior of the chassis causing severe swelling of the conformal coating material and the subsequent fracture of electronic components, dissolution of polyurethane insulation on magnet hookup wire and removal of component identification markings. Additional Keyword(s): Connector Cleaning, Polymers Reference(s): PFR #2649","Lesson ID":430}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) During the Viking program, rust spots were observed on the gold-plated Kovar lids of a number of flat pack Integrated Circuits (I.C.) used in electronic equipment. Although the source was not clearly identified, chlorine apparently initiated the corrosion. The chlorine is presumed to have been within activated solder flux residues from the lead tinning operation. In some cases, the corrosion penetrated through the I.C. lid and was a potential cause of I.C. failure. Although various polymeric coatings were applied over the metallic coatings to interrupt the corrosion cycle, they were all permeable enough to permit water through to the Kovar surface and the corrosion continued. Reference(s): PFR 32492","Lesson ID":434}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) A digital, coded interface was utilized on Voyager for the first time, at JPL, for transferring basic commands between CCS and Power. It was not until the Proof Test Module Spacecraft System Test Phase, in the Spacecraft Assembly Facility, that an incompatibility appeared that prevented reliable commanding from CCS to Power. The problem was caused by spacecraft system noise that resulted in spurious triggering of interface circuit elements. Circuit modifications, in this case, were troublesome. This configuration was adopted late in the subsystem design phase. For simplicity, an existing power supply was used for this circuitry which resulted in the signal return being common with the spacecraft 30V power return. Additional Keyword(s): Electrical Isolations Reference(s): Voyager PFR 39934, 39935, 39940, 39948 SSEF #343.2","Lesson ID":412}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) The pressure regulator in the Viking Orbiter-1 (VO-1) Propulsion Subsystem, after having performed without incident through the completion of the near-Earth midcourse Trajectory Correction Maneuver (TCM), leaked when 265 days later it was brought back on-line by the opening of an explosive valve which had isolated the regulator and propellant tanks from the pressurant tanks through the coast period prior to the near-Mars Trajectory Correction Maneuver. The regulator leakage was detected by virtue of a continual rise in the fuel and oxidizer tank pressures. Propellant tank pressure data show that the regulator had been leak-tight up to the end of the near-Earth Trajectory Correction Maneuver, when the pressurant isolation pyro valve was actuated closed. The near-Mars TCM burn duration was lengthened considerably and an additional unscheduled TCM made. This relieved pressure and increased ullage. After Mars Orbit Insertion (MOI) the regulator was valved off from the pressurant supply. It was elected not to isolate the regulator immediately, then re-open for MOI. The VO-2 approach sequence was also revised, but differently. The pressurant supply was left isolated until MOI, the TCM being made in \"blow down\" mode. An analysis of telemetry data ruled out: a scratch in the regulator poppet or seat, and housing weld failure. Remaining possibilities are: 1) corrosion and\/or residue formation in the regulator circuit - due to propellant migration and\/or pyro valve blowby, and 2) particulate contamination. Additional Keyword(s): Material Compatibility, Propellant Feed System Reference(s): IOM 344S-76-258, September 14, 1976, \"Pressure Regulator Failure Analysis, VO'75 Propulsion Subsystem, PFR 35408,\" G. Yankura to F. C. Vote","Lesson ID":420}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) During a Voyager Radio Frequency Subsystem (RFS) transponder filter capacitor rework, a noise was noted in the Proof Test Model (PTM) subassembly. On opening the power converter interface module, some of the mounting insert caps were found loose inside and others were partially pushed out from the insert ends. A dimensional check showed the mounting screws used may have an interference fit in length. A second possibility exists that longer screws were used at some earlier installation. Fastener inserts used in flight equipment are usually of the capped variety (closed at the bottom) when used in a thru-mounting design. This is done to prevent metallic particles being deposited in the electronics where they can cause electrical shorting or other problems. See also: In-flight failure, \"Receiver 1 Power Converter Failure on Voyager 2\" which was likely caused by this event. Additional Keyword(s): Tolerance Stackup Reference(s): PFR #40215 Voyager Structure Subsystem","Lesson ID":437}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) While in the process of reflow soldering flat pack leads to printed circuit boards during the Voyager program, small black spots were observed on some leads of various CD 4000 series flat packs. Analysis revealed the solder surface of the leads to be poorly wetted, caused by a high phosphorus content in the plated surface, and the solder joints to be substantially weakened. (Some joints when barely touched, fell apart). As a result, suspect flat packs were replaced, wherever found. The Kovar leads of the flat packs are electroless nickel plated to provide a solderable surface. The plating process, which also coplates elemental phosphorus, begins to plate a poor solder surface when the phosphorus content exceeds approximately 7% by weight. Since the nickel depletes at a faster rate than the phosphorus, it is necessary to monitor the plating solution and maintain an acceptably low level of phosphorus. Also, when a poor solder is found to exist as a result of excess phosphorus, platers will usually overplate with tin to regain a solderable surface. This overplate when exposed to the mechanical and thermal stresses of lead forming and reflow soldering will crack and pull away from the phosphorus rich nickel plate below. Reference(s): Part Failure Analysis Report Log 2624","Lesson ID":429}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) Flight qualified electroexplosive devices (squibs) stored from the Viking Orbiter 1975 program were selected for use in the Voyager 1977 mission. A twenty-eight day temperature soak resulted in increased bridgewire resistance for six of the ten samples. This was considered to be indicative of an incipient failure, the possible opening of the bridgewire with subsequent failure to fire upon command. Dissection of the squib which showed the greatest resistance increase revealed corrosion along the top of the bridgewire. None of the Voyager 1977 squibs built to the same specifications by the same manufacturer exhibited this resistance increase in similar testing. The phenomenon was attributed to moisture sealed within the squibs at time of manufacture, which combined with the Boron ignition mix to produce boric acid. Slow corrosion probably occurred with the passage of time. Selected squibs with no bridgewire resistance change were flown on Voyager. Additional Keyword(s): Contamination, Pyrotechnic Reference(s): Voyager PFR 37909","Lesson ID":428}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) On August 21, 1977, the Voyager II Science Boom failed to indicate, by microswitch, that it had deployed completely. Analysis of the spacecraft dynamics during jettison of the expended Solid Rocket Motor (SRM) case indicated that the science boom folding strut was not locked and that the boom momentarily refolded due to impulse from the SRM case separation. Subsequent star mapping using the scan platform-mounted TV cameras ascertained that the boom was within a tenth of a degree of the fully deployed position. Exhaustive tests were conducted to assess candidate causes. The possibilities investigated included equipment interferences, jamming by foreign matter, and excessive friction or binding due to low temperature phenomena. Some discrepancies were discovered, but a specific probable cause could not be identified. Additional contributing factors may have resulted from late incorporation of a number of cabling, thermal blanket, and external surface configuration changes. Reference(s): JPL Problem Failure Report (PFR) 41010\/NASA Experience Bulletin No. 14","Lesson ID":421}
{"Driving Event":"The Voyager 2 scan platform, on which are mounted the spacecraft cameras and several science instruments, is rotated in elevation and azimuth by actuators. Near the end of the Voyager 2 Saturn encounter, the scan platform azimuth actuator exhibited an anomaly. This anomaly was evidenced by the azimuth actuator seizing, causing a scan platform pointing error that resulted in a loss of some data. Through a series of ground commands, the problem was alleviated to the extent that the scan platform could perform its function. A prototype scan platform actuator was life-tested in a laboratory and it failed after approximately the same total number of slewed degrees as the flight unit. Upon disassembly of the test actuator, the problem was determined to be a design flaw in the actuator shaft bearing and gear lubrication system. In addition, dissimilar metal electro-chemical reactions produced corrosion. There was also debris build-up due to a lack of relief ports resulting in the deposition of this debris on the drive gear bearing assembly. For details, refer to \"Voyager Engineering Improvements for Uranus Encounter\" by Howard P. Marderness.","Lesson ID":394}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) During flight welded module fabrication (2) 3SBM relay failures occurred. One relay failed due to a shorted coil, the other failure was due to a broken weld. Subsequent JPL failure analysis on (14) additional flight relays showed failed conditions in one or more of the armature positioning welds. An investigative team visited the vendor to review the failures and the relay manufacturing process\/Quality Assurance (QA) controls. The welding process suffered from a component \"fit\" problem, worn welding fixtures and an absence of weld schedules. The coil lead operation had no instructions that precluded the possibility of coil shorts. The QA coverage lacked a systematic method of keeping records and employing corrective action. Based on the deficiencies found in the manufacturing process and the inability to cull defective relays in a non-destructing manner from the existing flight lots, a re-procurement of flight relays was initiated. The modifications to the fabrication process include: (a) component part inspection prior to kitting, (b) development of weld schedules and weld inspection criteria, and (c) JPL inspection points established at critical stages of relay fabrication. NOTE: This component was selected from the JPL Preferred Parts List. Additional Keyword(s): Wire Welding Reference(s): PAR's 36074, 36841, 36861; Part Failure analysis Reports 2494, 2496, 2603, 2622; IOM #342-76-B-028, Johnson, H. L., \"Disposition and Status of MJS'77 Power Subsystem 3SBM Relay Problems,\" 5 February 1976.","Lesson ID":433}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) The SEASAT-A Synthetic Aperture Radar (SAR) system end-to-end gain varied anomalously during measurements made just prior to SAR shipment to the SEASAT system contractor. Tests to resolve the anomaly traced the cause to the presence of leakage in the sensor signal output which was coherent with the Data Link carrier. (The Data Link in the SAR system is, in effect, an Intermediate Frequency (IF) strip, which converts the radar signal to offset video after transferring the radar signal, with reference signals, through an S-band link.) Phasing and amplitude of the leakage varied with the sensor gain state and with temperature, thereby causing variations in the Data Link resultant carrier level. These variations perturbed the unity gain level required of the system. The system was designed for a fixed known relationship between signal and carrier levels. To alleviate the problem, the sensor was removed from the satellite, and the leakage as attenuated by application of conducting tape. This did not eliminate the effect, but reduced it to acceptable levels. The leakage subsequently remained within these acceptable levels. Additional Keyword(s): Communication Link, Design Verification, Spacecraft Radar Reference(s): SEASAT P\/FR 1287 R. L. Horttor\/B. L. Huneycutt, et al, \"SAR Engineering Assessment Report.\"","Lesson ID":419}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) The SEASAT-A Synthetic Aperture Radar (SAR) Data Link suffered a 25-dB loss in output power during the Sensor Module Thermal Vacuum Test. This failure would have been catastrophic in flight, causing loss of all SAR data. The cause of the failure was a crack in an RF circuit ceramic substrate. The crack opened the DC bias supply to an RF amplifier. Structural analysis of the substrates showed weakening caused by use of a dental drill used for circuit tuning (by removing conductor material) during the final amplifier assembly process. This process inevitably removed some substrate material, by gouging or cracking the substrate. Without this initial damage, the substrate material would have survived the expected thermal environment. Tuning of the flight RF circuit was done without benefit of new artwork. Because of cost and schedule pressures, design changes were made on the brassboard model and implemented on the flight model without benefit of a prototype. (A similar failure had occurred 8 months before during SAR System Thermal Vacuum Test. The earlier failure was originally attributed to an open solder joint in a bias circuit. In hindsight, the actual cause was probably a cracked substrate. At the time of the earlier failure, Voyager launch priorities precluded the assembly of the team, which made the diagnosis of the later failure.) Additional Keyword(s): Fabrication Technique, Environmental Test, Spacecraft Radar Reference(s): SEASAT P\/FRs 1275, 3388","Lesson ID":427}
{"Driving Event":"TOPEX Microwave Radiometer (TMR) Solder plated terminals supplied to a contractor for installation in TMR multilayer boards failed solderability tests, prior to installation. These terminals were found to have exceeded their useful shelf life, (typically 2 years), and were replaced with new ones. Removal and replacement of these terminals after installation would have meant severe penalties in terms of added costs, schedule slippage and\/or potentially destructive rework. ASTROS Instrument When previously built printed wiring board assemblies were removed from long term storage (more than 5 years) for use in new construction, surface deterioration on solder plated terminals necessitated the use of activated (type RA) fluxes to obtain acceptable solder joints. Such acid based fluxes are not normally used due to potential for long term corrosion.","Lesson ID":402}
{"Driving Event":"While on the launch pad, a Viking Spacecraft experienced an anomalous power turn-on during a period when the spacecraft was unattended. The power turn-on resulted in a total discharge of the spacecraft batteries. The most probable cause was induced current resulting from local lightning strikes on the seven miles of cable between the support equipment located in Building AO and in the Launch Complex Trailer at the launch pad. Spacecraft internal power \"ON\" is accomplished by energizing a motorized switch in the spacecraft, which then connects the spacecraft batteries to the power bus. The induced current caused a relay located in the support equipment to connect an emergency battery to the spacecraft motorized switch, which then initiated the power turn-on. Analysis conducted during the investigation disclosed that a possible discrete failure of the relay would have caused the same problem. This failure analysis was not performed prior to the incident. After the deep discharge, the Viking Spacecraft batteries were no longer flight certified and had to be replaced at a considerable expenditure of resources.","Lesson ID":397}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) The Viking Lander relay link transmitter has selectable power output levels of 1, 10, and 30 watts. Inflight checkout of the Lander system was to include operation at each of the power levels. Prior to launch, Orbiter and Lander telecom analysts identified the planned checkout as a problem. With the Lander attached to the Orbiter during interplanetary flight, the separation between the Lander relay transmitting antenna and the Orbiter relay receiving antenna was small enough that the Orbiter relay receiver was subject to overload and possible zenering of input transistors at 30 watts. Prelaunch antenna tests were limited by available modeling capability (use of 1:5 scale; half of the bioshield) and VO-1\/VL-1 mated tests were accomplished under non-flight conditions (Orbiter relay antenna stowed, noisy environment). An inflight test was devised, in which the 1-watt mode was tried and the effect on the available Orbiter relay receiver telemetry points noted. The receiver signal strength telemetry (AGC) was \"saturated.\" An input current telemetry channel, responding to the large overloads was \"calibrated\" at one watt, and on the basis of this, the 10-watt level was deemed safe and was exercised. However, parameter tolerance buildup resulted in too large a risk of relay receiver damage for the 30-Watt checkout to be tried. Because of the absence of testing and the criticality of the Mars-descent data, the initial mission design requirement for 30 watts during descent was re-examined. As a result of this work, the (small) risk of data loss due to atmospheric fading was accepted. Descent was at 10 watts, and subsequent relay passes from Mars' surface were at 30 watts. Additional Keyword(s): Margins, Subsystem Interaction, Antenna Pattern, Communication Link, RF Measurement, Test Methods Reference(s): Viking Project Document VFT-022, \"Viking Orbiter System, Primary Mission Performance Report,\" June 15, 1977. (see section of Relay Radio Subsystem, pp. II-37 to II-39.) Viking Flight Team memo OTAU-15240-FHJT, \"Recommendation Against 30-watt Lander UHF Transmitter Checkout,\" Jim Taylor to R. A. Ploszaj, February 11, 1976. VFT Memo FPAG-15642-EAE, \"RCE 10 Watt Mode in Descent for Mission 1,\" E. A. Euler, 3\/18\/76","Lesson ID":411}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) The potential for mutual interference among the two Viking Orbiters (on Deep Space Network (DSN) channels 9 and 20, with 'backup' on 16) and the two Viking Landers (both on DSN channel 13) was recognized during the link design and test phase. Multiple vehicle interferences can occur when modulation on the carrier of one Viking channel produces sideband energy, which extends into a second channel. In particular, discrete spectrum ranging produces sideband centered about 516 kHz clock and its harmonics, and the orbiter high rate telemetry produces sideband energy centered about 240 kHz subcarrier and its harmonics. Compatibility testing was accomplished at Compatibility Test Area 21 (CTA 21). This testing identified the most severe (likely) interference condition as false uplink RF acquisition by and out-lock vehicle of the uplink sideband intended for a second vehicle during range acquisition. Loss of downlink RF from the first vehicle would also be experienced at the station, due to the vehicle's shift from one-way to two-way mode. Several other conditions, involving degradation of the RF carrier tracking, ranging link delay measurements, and telemetry signal-to-noise ratio, were also identified. The results of the analysis and testing were stated in a recommendation not to fly the backup channel 16 and in various mission rules as to when ranging acquisitions would be possible. Ranging modulation interference to a one-way Orbiter occurred several times during the Viking Extended mission. Downlink carrier lock and telemetry data were lost as predicted. Additional Keyword(s): Multiple Mission Planning Reference(s): JPL letter 339-FVS;fv Fred Stuhr to Mr. H. R. Kowitz of Viking Project Office of the Langley Research Center of NASA, Oct. 4, 1974, reporting the CTA-21 test results. \"Deep Space Network to Viking Orbiter Telecommunications Performance During the Viking Extended Mission, Nov. 1976 Through Feb. 1978\", in DSN Progress Report 42-45, March and April 1978, F. H. J. Taylor.","Lesson ID":410}
{"Driving Event":"(Relevant Historical Lessons Learned) Traveling Wave Tube Amplifier (TWTA) No. 1 on Viking Lander 2 failed to produce an S-band RF downlink when commanded \"ON\" October 13, 1976. The most probable failure model is that the high-voltage power converter developed a corona breakdown. A subsequent attempt to operate this TWTA during the extended mission late in 1978 also failed to produce downlink. From Martian day one (SOL 1) after Lander 2 touchdown, TWTA No. 2 had been used and it had performed very well. On SOL 33, the link was switched to TWTA No. 1 because it ran cooler than No. 2, and the increasing solar angle was beginning to raise the Lander ambient temperature. TWTA No. 1 produced normal carrier and telemetry sidebands; however, the ranging subcarrier was suppressed by noise by 6 to 8 dB. These symptoms continued from SOL 33 to SOL 38. On SOL 39, no signal was observed at the Deep Space Stations after the TWTA \"ON\" command. Subsequent telemetry via the UHF relay link (not involved) showed the TWTA bay temperature did not make its usual climb. The TWTA went through its 90-second cathode warm-up period, and the failure must have occurred shortly after the high-voltage was programmed to come on. Other failure mechanisms examined and discarded include: sequence error, spurious signals on the uplink from the stations, \"power-on\" switch failures, exciter spurious signals, and command link failure. It was concluded the failure was within TWTA No. 1. Reference(s): Viking Incident Surprise Anomaly Report No. 15643 (dated 13 Oct. 1976) JPL IOM 3363-76-059, \"Narrative on the Viking No. 2 Lander TWTA Failure,\" Lloyd Derr to Lee Randolph, 29 Oct. 1976","Lesson ID":404}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) Voyager 2 Receiver 1 operated normally from launch until an inadvertent activation of the on-board command loss routine switched it out and put Receiver 2 into use. Receiver 2 would not lock to the uplink to receive a command to stop the loss routine, and it later was found to have a shorted loop capacitor. Twelve hours later, the routine again selected Receiver 1. The Voyager flight team, knowing the spacecraft was already on the High-Gain Antenna (HGA), transmitted a series of HGA select commands to stop the routine without having any other effect on the spacecraft. The first command of the series was received and stopped the routine. Several receiver telemetry channels began changing unexpectedly between two subsequent HGA select commands, and within 11 seconds the receiver power converter had failed; this was one-half hour after Receiver 1 had been turned back on. Anomalous telemetry data occurred in other subsystems during the receiver failure, with several indications in the photopolarimeter and an in crease in radio frequency noise in one channel of the harmonic radiation experiment of the planetary radio astronomy instrument. The Voyager document, quotVoyager 2 Command Receiver 1 Failure Analysis,quot details the telemetered failure indications and measurements from the other subsystems sent at the same time. It also hypothesizes a failure model fitting all the observations and based on confirming laboratory testing of Voyager assemblies, subsystems, and instruments. Additional Keyword(s): Surveillance, Captive Inserts, Conformal Coatings, Mission Operations Reference(s): Project Document 618-817, quotVoyager 2 Command Receiver 1 Failure Analysis,quot Arthur G. Gussner, Oct. 1979 Voyager Incident Surprise Anomaly (ISA) 1783, and Voyager P\/FR 41029 Receiver Failure Model: The hypothesized failure model asserts that a resistive short from the 30-volt return line to chassis existed somewhere in the spacecraft at the time of the receiver failure. This first short had no effect on operation by itself and could not be detected by telemetry. Then a short to chassis occurred in the receiver, intermittent during the first three seconds and then continuous. This second short completed the short circuit and caused the receiver fuses to open. The location of the short outside the receiver is unknown. The short in the receiver, by itself, would not have caused the failure. The receiver short is believed to have been caused by a metal particle from a captivated insert contacting areas not sufficiently coated by the solithane conformal coating. The inserts are steel, constructed with a disk captivated in the end of the insert to prevent metal shavings from the screw or the insert from entering the electronic housing. The receiver short is believed to have been caused by the conductive end-caps that were pushed out of the inserts by over-length screws when the transponders, containing the receivers, were assembled to the spacecraft bay outer shear plates. As shown in the diagram, if the screw installed in the insert is too long, the captivated metal disk is pushed loose and a quotdonutquot of the insert is pushed loose with it. (The screws may have been too long through tolerance buildup in design, or wrong-length screws could have been inserted during assembly by error.) An examination of Voyager residual hardware revealed that the brush-on solithane conformal coating did not cover all areas, especially areas such as the edges of component leads where they were lap-soldered to circuit traces, bends in leads, the tops of horizontal leads, the edges of etched circuit traces, and the perimeters of transistor cans. [D]","Lesson ID":436}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) The design of phase-locked loop transponders for Deep Space missions is such that the loop is sensitive to uplink modulation components within its bandwidth. In the two-way coherent mode of operation, the frequency reference for the downlink carriers is the loop Voltage-Controlled Oscillator (VCO). On Voyager, the command subcarrier at 512 Hz and the command data at 16 bps modulated on the subcarrier produce a residual phase jitter in the loop VCO when optimum Deep Space Network command carrier suppression factors are used. The downlink carrier jitter degrades the telemetry demodulation process; this effect was imperceptible for S-band downlinks in the past. Command feedthrough was first observed on the experimental X-band transmitter (XTX) downlink on Mariner Venus-Mercury 1973 (MVM'73); however, Voyager was the first mission with the primary telemetry link at X-band. Voyager found that optimum (for command) uplink carrier suppression destroyed X-band telemetry. The Galileo telecommunications system includes inherited Voyager transponders; therefore, Galileo can expect the same command feedthrough problems as have been experienced on Voyager. Galileo does not plan to \"fix\" the problem because the resources to do so are deemed excessive relative to the inconvenience of accommodating to it. The required accommodations (for both Voyager and Galileo) are described below. Additional Keyword(s): Communication Link, Signal Degradation, Spacecraft Commanding, Tracking Loop Filter Reference(s): JPL IOM 3395-79-013, \"Project Galileo Strategy to Accommodate Command Feedthrough Effects,\" R. L. Horttor, 25 January 1979","Lesson ID":418}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) A deficiency was discovered during circuit design verification which might not have shown up during testing. The condition involved capacitors having a large AC voltage between the capacitor body and its surroundings, and the capacitors having air pockets or voids between the body and the outside jacket. The finding is significant because this condition can remain harmless at atmospheric pressure, yet lead to corona and possible failure after months or years in the vacuum of space. To solve an interaction problem between the Voyager Traveling Wave Tube (TWT) and the power supply, the designer added a voltage doubler circuit having capacitors as integral parts of the circuit. The standard high-voltage capacitors initially used have the outside of the body taped to provide a moisture barrier. The doubler operates at 7.2 kHz with an input higher than 300 volts AC. The action of a voltage doubler is such that the two plates of the capacitors used change potential each time the inverter switches. The transformer winding that drives the doubler capacitors is referenced to the TWT collector through a diode bridge. Each winding output is, therefore, near collector voltage on one half cycle and changes by the transformer winding's output voltage (about 700 V) on the next half cycle. When the combined problem of the high AC voltage and the trapped air pockets was realized, the designers specified that modified capacitors, not having the tape wrapping, be procured. These were then specially prepared by vacuum coating with Scotchcast 281.","Lesson ID":417}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) During qualification testing of coaxial cables at cold temperature (-200C for TA) it was found that intermodulation product signal levels were generated. These levels only occurred at the extreme cold temperature. On Viking it had been found that broadband noise could be generated in the mating surfaces of the aluminum four channel track connector. To eliminate that problem the Voyager connector mating parts were made of stainless steel. It was found in testing that there was minute differential expansion between the semi-rigid aluminum coaxial cables and the stainless steel shells that attach to the cables. The problem was eliminated by increasing the fabrication torque from 20 in-lbs to 45 in-lbs to prevent the loosening at extreme temperatures. Additional Keyword(s): Connector Fabrication Techniques, RF Intermodulation, Thermal Expansion Reference(s): Voyager PFR 38668","Lesson ID":416}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) Telemetry data of the Radio Frequency Subsystem Exciter RF output on Mariner Mars '71 (Mariner 9) showed slow degradation after launch. The degradation continued at a very slow rate throughout the interplanetary cruise and the primary mission phases of the mission. By one year after launch, the exciter RF output had degraded sufficiently that the traveling wave tube amplifier power amplifier output had decreased 0.6 dB. The exciter output had decreased 2.6 dB. Investigation, including a review of the circuit design and laboratory testing, determined the exciter output degradation was caused by two RF transistors (2N3364 and 2N3375) being overdriven. Overdriving results in the permissible emitter-to-base voltage being exceeded, causing the emitter-to-base junction to be forced into a zener condition. The zenering causes the beta of the transistor to degrade, which results in a reduction of circuit gain. Reference(s): JPL IOM 3365-72-199, \"Investigation of Mariner 9 Exciter Power Degradation,\" R.S. Hughes, 22 May 1972","Lesson ID":414}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) A commercial data scanner using a bank of reed relays failed during thermal-vacuum testing of the SEASAT-A Synthetic Aperture Radar (SAR) Transmitter subassembly. Transmitter circuits requiring +5 volts were exposed to as high as 31 volts during each scan, resulting in catastrophic failure in the +5 volt circuits of the Transmitter. This problem caused about a two-week slip in the overall schedule, including the loss of 3 days of a one-week thermal-vacuum test and three days to repair the Transmitter. The nature of this problem could have caused the failure to occur anytime the sensor was operated with the ground support equipment as it was configured. The Transmitter GSE was configured with 15 separate regulated power supplies of various voltages. To allow automatic data acquisition of power supply voltage and current readings during the test, a data scanner driven by a computing calculator was implemented. This scanner consists of a bank of reed relays sequentially addressed by the calculator to acquire each power supply terminal voltage. Each power supply terminal was connected to a scanner reed relay switch terminal. The other side of the switches were then tied together to the bus, similar to a multiplexer arrangement. In the thermal-vacuum test, one of the reed relays failed to open. As a result, each succeeding power supply terminal that was scanned became electrically tied to the one connected to the relay that failed to open. The failed relay was connected to +5 volt supply. The other supply voltages ranged up to +31 volts. The JPL calibration Lab uses this type of data scanner at the present time. Additional Keyword(s): GSE Interface FMECA Reference(s): SEASAT SAR P\/FR 4891","Lesson ID":435}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) On Viking Orbiter (VO)'75, a launch pad problem developed involving the flight software program and the Reaction Control System thrusters. The flight software, intended for use only after launch, contained within it a \"safing sequence.\" The intent of the safing sequence was to automatically place the spacecraft in a safe state should some anomaly be detected. The safing sequence included commands to enable the Reaction Control System (RCS) and its thrusters. In spite of procedural safeguards, a problem developed which inadvertently resulted in the issuance of the safing sequence while VO-2 was still on the launch pad. This, in turn, enabled the RCS thrusters. The Attitude Control System then sensed the Earth's rotation, causing the RCS thrusters to fire in an attempt to compensate. Thruster firing continued until disabled by the test team, resulting in a significant loss of N2 attitude control gas. The launch was conducted without replacing the lost gas, rather than take the spacecraft down off the launch vehicle for replenishment. The safing sequence was also inadvertently issued several times during system test, but no adverse consequences resulted. Additional Keyword(s): Ground Operations, Pre-Launch Constraints Reference(s): VO'75 P\/FR # 34869","Lesson ID":403}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) During the final flight acceptance testing of the second Mariner Mars '71 flight RFS, an RF breakdown occurred in one of the exciters at critical pressure. Investigation showed the exciter design had little or no margin to RF breakdown at critical pressure. Costly design modifications, late in the program, were required to correct the design. Also, during thermal-vacuum testing of the MM'71 RFS Proof Test Model, the RF output was found to be a function of the vacuum chamber pressure. The problem was traced to the circulator switch used to select the traveling wave tube amplifier and antenna. Investigation showed that the switch had not been analyzed nor adequately tested by the subcontractor to determine its margin to RF breakdown. Costly design modifications late in the program, were required to achieve an acceptable RF breakdown margin. The MM'71 Exciter RF breakdown investigation also determined that foam should not be used as an RF breakdown suppressant. Reference(s): JPL Technical Memo 33-573 \"MM'71 RFS Subsystem\", R.S. Hughes","Lesson ID":415}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) The Voyager spacecraft system, Ground Data System (GDS) and Mission Operations System (MOS) were designed to accommodate very limited real-time commanding. Early flight experience revealed that frequent real-time commanding was necessary to support mission objectives. The required modification to the GDS and MOS was difficult and these systems still retain limiting characteristics which make real-time command generation more difficult and costly than is desirable.","Lesson ID":425}
{"Driving Event":"(Relevant Historical Lessons Learned) Mariner (M)'69 and Viking Orbiter (VO)'75 had problems because the designs used stepping commands rather than explicit commands. Explicit commands cause a device (such as the scan platform) to move directly to the desired state or position, regardless of its current position. Stepping or incremental commands, however, simply cause the device to move by the commanded increment from its current position to the new position. If the current position is incorrect, the next position and all subsequent positions will be incorrect. When a power problem occurred as M'69 was approaching its Mars fly-by, the scan platform moved inadvertently and the engineering telemetry needed to determine the platform's position was destroyed. The platform then had to be commanded by trial-and-error until Mars appeared in the returning pictures. Had this search not been successful in the short time remaining until Mars encounter, the entire science sequence would have been irretrievably lost. A less serious problem occurred on VO-1 when the position of the camera filter wheel got out of step with the picture-taking sequence. Once out of step, the several frames subsequently exposed were lost due to over\/under-exposure. Correct exposure had to be restored by ground command. Additional Keyword(s): Software Reference(s): M'69 P\/FR Nos. 204634, 204660 VO'75 VISA # 1450 (IOM 3623-BB-167)","Lesson ID":405}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) Shortly after Voyager launch, unexpected translational velocity increments and large non-gravitational acceleration effects were observed in the orbit-determination processing of tracking data. These velocity increments and accelerations were traced to the unbalanced translational accelerations produced by the attitude control system, its response to torques induced by solar pressure, and to the impingement of gas from the pitch thrusters onto other parts of the spacecraft structure. The magnitude of these dynamic effects required that they be modelled in the orbit determination process throughout the flight. This involved additional orbit determination processing and analysis, and necessitated a new operational interface between the Spacecraft Team and Navigation Team. A special in-flight impingement test was performed to provide data for modelling. The pre-flight analysis to recognize or predict the effects and uncertainties from both the unbalanced thrusters and the impingement was inadequate. The result was incomplete flight operations planning by both the Spacecraft and Navigation Teams. Additional Keyword(s): Trajectory Accuracy","Lesson ID":424}
{"Driving Event":"The X-31 is an inherently unstable experimental aircraft. Its dynamic stability is dependent on air data from the Pitot-static system. Unexpected icing of the single-string unheated Pitot-static air data source resulted in the aircraft departing controlled flight and crashing. X-31 Experimental Aircraft","Lesson ID":360}
{"Driving Event":"During the course of its test program at Dryden Flight Research Center, Edwards, CA, the X-31 experimental aircraft was retrofitted with an unheated Pitot-static probe (of the Kiel probe design). Unexpected icing of the single-string Pitot-static air data source resulted in the aircraft departing controlled flight and crashing. X-31 Experimental Aircraft Pitot-Static Probe","Lesson ID":359}
{"Driving Event":"The X-31 experimental aircraft used the egress system from the F-18 fighter aircraft, including its 17 foot diameter main parachute. A test pilot ejected from the X-31 over Edwards Air Force Base, CA. The pilot's calculated descent rate was over 28 feet per second. The parachute landing fall resulted in multiple injuries. X-31 Experimental Aircraft","Lesson ID":361}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) Prior to Helios I launch, the communication links to and from the spacecraft were expected to be degraded because of spin modulation and interferometer effects created by the low-gain antenna elements. The resultant signal, as measured using a mockup, had combined amplitude, phase and frequency modulation, which had not been considered in the link design. The amplitude and phase variations degraded the received uplink and downlink channels (command and telemetry) and created a marginal condition to carrier tracking (doppler). The Helios I low-gain antenna was made of two elements: (a) a linearly-polarized dipole, mounted on top of the spacecraft, parallel to the spacecraft's spin axis; and (b) a circularly polarized antenna mounted on the bottom of the spacecraft, off-set six wavelengths from the spacecraft's spin axis. The composite pattern of the two antennas caused an \"interferometer effect\", with rapidly varying phase and amplitude values occurring over a small but critical portion of the antenna pattern. The \"look angles\" associated with this portion of the pattern were important during some mission phases. Reference(s): JPL TR 32-1526, Vol. XIV \"DSN Progress reports for Jan.-Feb. 1973, pp 149-160 JPL TR 42-1526, Vol. XVIII, \"DSN Progress Reports for Sept.-Oct. 1973, pp 147-162 DSN Progress Report 42-20, Jan-Feb. 1974, pp.154-166 DSN Progress Report 42-23, July-Aug. 1974, pp. 87-91","Lesson ID":407}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) Mariner'71 testing was delayed when replacement of one blown fuse required the removal of a module containing other fuses necessary to the safe testing of the spacecraft, thereby postponing further testing on all the affected components. Fuses for the Data Storage Subsystem (DSS) tape recorder and several other subsystems were located within the power subsystem. During test, several devices, including the tape recorder, were removed from the spacecraft while other tests continued. This would have reduced the electrical load below the level required for stable operation of the power conditioning unit. To ensure stability, a dummy load was connected in place of the DSS that had been removed. However, the load applied had too low an impedance. Whenever spacecraft power was reapplied, the tape recorder fuse blew at its 1 amp design value and successfully protected the power subsystem. The blown tape recorder fuse, along with other fuses were tightly packaged and conformally coated within the power distribution module. To replace the fuse, the entire unit had to be returned to the vendor for 7-10 days. This prevented further testing on all devices whose fuses were also contained within the unit, delaying the test program. Additional Keyword(s): Packaging","Lesson ID":408}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) Immediately after the launch of Viking I, large and unexpected non-gravitational accelerations were seen when the Doppler observations of the spacecraft were processed for orbit determination. These perturbations to the spacecraft dynamics were confirmed by observations of the attitude-control limit-cycle motion. Spacecraft team analysis identified the cause as the venting of outgassing products from porous materials (e.g., parachute, blankets, etc.) in the lander. There was considerable uncertainty in the expected duration of the effect. This uncertainty raised the possibility of large targeting errors at Mars; consequently, the effect was included in the design of the midcourse correction made shortly after departure from Earth. The effect appeared to cease 1 to 2 months after launch, and did not in fact significantly increase targeting errors. The same effect was observed on Viking II.","Lesson ID":423}
{"Driving Event":"During the system assembly process of the S\/N 002 ASTROS Tracker, two external interconnect cables between the Sensor Assembly (SA) and the Electronic Assembly (EA) were cross connected.* Causes of the problem: At the EA end of the cable harness, the design incorporated the use of identical connectors. On the EA, mating connectors were installed side by side. Identification of connectors on the cables was inadequate, and not readily apparent. Inadequate attention was paid to positioning of the connectors during the installation process. Fortunately, the ASTROS Instrument suffered no damage as a result. Repeated Events: On the Galileo Project, a Data Memory System flight unit was severely damaged when two internal cable connectors were transposed. Identical connectors, installed side by side, were cross connected under poor conditions for recognition. In this case, it was necessary to remove and replace twenty-six over stressed transistors. On the TOPEX Project, a similar event occurred at the Satellite System Contractor. Unfortunately, details of that problem are no longer readily available. Due to the nature of the circuitry involved, the effects of the transposition of connectors was relatively minor. On the Cassini Project, a similar event occurred at a supplier facility. Two test cables were reversed during set-up. The unit did not experience any additional stresses as a result.** Additional Keyword(s): Assembly Practices, Cabling Reference(s): *PFR #41718 & **PFR #59732","Lesson ID":431}
{"Driving Event":"The MO Traveling Wave Tube Amplifiers (TWTAs) were not powered during qualification Pyrotechnic Shock testing. As a result, the contractor's operations plan included not powering the beam and cathode heaters of both redundant TWTAs (thus no downlink telemetry) during the critical MO tank pressurization. Although this was a topic of significant debate during the design and manufacturing phases, early cost constraints resulted in decisions not to perform developmental testing and analysis to show whether or not there would be a problem powering the TWTA during the MO Pyrotechnic events. Analysis was performed to determine the lateral and axial capability of the cathode support design when powered off (cold). Actual testing to qualify the TWTA for powered operation (hot) was not performed, also based on programmatic cost constraint decisions. Additional Keyword(s): RF Testing Reference(s): \"MO Design & Implementation Audit\": JPL D-11433 \"MO Loss of Signal: Special Review Board Final Report\": JPL Publication 93-28 \"Report of the MO Mission Failure Investigation Board\" (the Coffey Report)","Lesson ID":432}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) At the time of Mariner 6 scan platform unlatching, which was effected by firing a pyrotechnic squib, several bright objects were seen by the Canopus tracker. This caused the tracker to lose lock on Canopus, causing a roll search to be initiated. For 25 minutes following the first opening of the Viking Orbiter-1 propellant pressurant supply (a pyrotechnic-actuated event), the spacecraft roll axis was commanded to roll inertial hold and the Canopus-loss fault protection software was disabled. During the first part of this period, numerous bright objects were seen by the Canopus tracker. Within a few minutes after completion of the inertial hold period, another bright particle was seen by the tracker, this time causing the spacecraft roll position to change and the on-board software to execute the Canopus-loss fault protection response. Additional Keyword(s): Attitude Control, Science Viewing","Lesson ID":422}
{"Driving Event":"Two Galileo Spacecraft anomalies occurred during the week of September 12, 1994. Several difficulties were encountered during the recovery from these anomalies. The first anomaly was a Data Bulk Unit Memory (DBUM) parity error on the Galileo Command and Data Subsystem (CDS). This nonprivileged error resulted in spacecraft safing but did not bring down either CDS string. In response to this anomaly, the flight team developed a special privileged command program to isolate the failed memory byte. Although this program was almost identical to a recent successfully run program, it required a nonstandard ground system configuration for command translation. This configuration was not established, causing the second anomaly which brought down the CDS A-string and re-executed safing. During the recovery from this second safing, an existing recovery file was left unchanged from a year earlier, even though the one-way light time had doubled. As a result, an inappropriate Telemetry Modulation Unit (TMU) modulation index command was uplinked, causing a short data outage. During both recovery efforts, it was believed that the system fault protection associated with safing had turned off the High Voltage (HV) to the Heavy Ion Counter (HIC). In fact, a patch had been implemented a year earlier, which prevented the fault protection from turning off the HIC HV. A lack of proper configuration management along with an inadequate check of the spacecraft state created this confusion. Since a prolonged lack of HV to the HIC would permanently damage the HIC, the project was forced to consider a risky proposal to switch the HIC to the only remaining working CDS string in an unnecessary attempt to get the HIC HV back on. The overall recovery time was 12 days. Had the spacecraft been in a critical operation mode, this long recovery time could have been more detrimental. A standardized anomaly recovery plan would have helped avoid some of the above problems. Additional Keyword(s): Commanding Reference(s): IOM GLL OET-95-023-GMcS-SRT, Jan. 20, 1995, Spacecraft Anomaly Recovery and Lessons Learned for the CDS Anomalies.","Lesson ID":391}
{"Driving Event":"The National Oceanic and Atmospheric Administration (NOAA) weather satellite NOAA-I (NOAA-13 after launch), was launched on 9 August 1993 from Vandenberg Air Force Base. No anomalies were encountered during flight until 21 August 1993 at which time it was determined from telemetry data that while in full sun, the solar array was inoperative and that the spacecraft was being powered by the batteries. Within six orbits after observance of the anomaly, communication with the spacecraft was found not to be possible and no downlink signal from the spacecraft was thereafter detected. Upon closer examination of recorded spacecraft telemetry data, it was ascertained that the solar array was putting out electrical power, but that no power was being provided to the battery charging unit, and the batteries were not receiving a charge. Cause of the failure surmised by the cognizant operations crew and concluded by the Goddard Space Flight Center (GSFC) NOAA-13 Failure Review Board, was that the solar array bus had shorted to spacecraft ground. Specifically, constant thermal expansion and contraction in excess of previous flights was thought to have caused one or more mounting bolts protruding through the heat sink contained in the battery charging unit to penetrate isolation material and short the solar array output to ground. It is believed that a rise in temperature and resultant increase in temperature excursion were due to greater electrical power required to operate additional instruments added to the spacecraft. Reference(s): NOAA-13 Failure Report, dated August, 1994 by Goddard Space Flight Center","Lesson ID":387}
{"Driving Event":"After a star calibration during the Magellan third extended mission, the X Band telemetry and high rate data were missing from the down link (22 kHz and 960 kHz subcarriers were missing). A subsequent attempt to use the 360 kHz subcarrier also resulted in no significant subcarrier in the down link. The most likely failure is a HA 2520 operational amplifier used as a summing amplifier in the telemetry signal conditioner (although a failure in the phase modulator circuitry is also a possible cause). It failed after 20,600 hours of flight operation and 2,600 power cycles (resulting in 10-15 degree thermal cycles). A prelaunch failure on this component type indicated the possibility that during the repackaging process by the subcontractor of the HA 2520, moisture was trapped inside the electronic component. This moisture would combine with the phosphorus dopant in the glass passivation forming phosphoric acid that would enter through pinholes in the passivation layer and attack the nickel-chromium resistors causing failure. The subsystem contractor did not use a dry gas during the repackaging process; instead air with a moisture content of greater than or equal to 5,000 PPM water was used. The prime contractor, with JPL concurrence, felt that additional screening had been sufficient to identify any other faulty HA 2520 amplifiers. It was concluded that the in-flight failure may be related to stress induced by thermal cycles resulting from on-off power cycling. As a result of this failure, the degraded transmitter B had to be used to return science data at a lower rate for the remainder of the mission. Additional Keyword(s): IC Manufacturing and Packaging Reference(s): PFR #52621","Lesson ID":362}
{"Driving Event":"As originally envisioned, inherited designs were to be used for many of the Mars Observer spacecraft's engineering subsystems. During its eight-plus year development period, however, the Mars Observer mission underwent a number of significant changes. Many of the spacecraft subsystems were so extensively modified for Mars Observer that their heritage was lost. Other subsystems, whose heritage remained intact but which were designed for an earth-orbital environment, were not requalified to verify that they would function properly on an interplanetary mission of three years duration. Examples include: The failure to fully qualify the Traveling Wave Tubes (TWT) in the transmitter power amplifiers for operation during pyro-shock events. The lack of robustness in the design of the bipropellant pressurization system for long duration missions. The use of fault-management software, containing processing algorithms derived from the Defense Meteorological Satellite Program (DMSP), that was not fully understood. Reference(s): Mars Observer Loss of Signal: Special Review Board Final Report: JPL Pub. 93-28 JPL Lesson Learned, No. 3-108, Subject: Mars Observer Pressure Modulator Infrared Radiometer (PMIRR) Cooler Failure During Vibration Testing JPL Lesson Learned, No. 10-102, Subject: Mars Observer Inertial Reference Loss IOM 525-89-344, dated 12\/14\/89, by L. E. Baughman and R. F. Draper, Subject: MMII Inheritance Reviews","Lesson ID":346}
{"Driving Event":"A fire occurred on November 27, 1982 at the Arnold Engineering Development Center as a result of cutting propellants on the floor of a vertical test cell. The propellant being cut was from M-X Stage II and was a Class 1.3,88 weight percent solids, HTPB, Non-HMX type. Combustion was attributed to either impact or friction.","Lesson ID":344}
{"Driving Event":"No Attitude and Articulation Control System (AACS) or fault protection failure has been identified as a likely direct cause of the failure of the Mars Observer (MO) mission. Nevertheless, modification to the MO AACS and fault protection design could have: a) stabilized the spacecraft, and reestablished communications in the postulated \"pressurant\" line burst scenario and b) increased the likelihood of stabilizing the spacecraft after a power-on-reset in the electronic part latch-up scenario. By analyzing MO software algorithms and documentation, as well as performing verification test laboratory simulations of the spacecraft, it became apparent that the MO fault protection suffered from a lack of top-down system engineering design approach. Most fault protection was in the category of low-level redundancy management. It was also determined that the MO fault protection software was never tested on the flight spacecraft before launch. Furthermore, it was determined that in case of excessive attitude control errors, the spacecraft would not be stabilized by the Reaction Control System (RCS) thrusters. No RCS thruster control algorithms were present in the software code, thus there was no functional back-up to the Reaction Wheel Assemblies (RWA) for attitude control. If the RCS thrusters were used directly for control, they could have prevented a spin-up for most \"pressurant\" line burst scenarios. Additional Keyword(s): Software Testing Reference(s): Fault Protection Lessons Learned from Mars Observer Loss of Signal Briefing to Division 34 Staff, Douglas E. Bernard 07\/20\/94. Mars Observer Loss of Signal: Special Review Board Final Report: JPL Pub. 93-28.","Lesson ID":345}
{"Driving Event":"Verification Test Laboratory (VTL) simulations of the Mars Observer spacecraft spin-up were performed to simulate a postulated propellant subsystem breach. The results indicated that even moderately low angular accelerations caused by the postulated propulsion subsystem breach could have triggered a contingency mode entry that would have interfered with the Radio Power Amplifier (RPA) turn-on cycle. Under these circumstances, contingency mode entry would have inhibited downlink until a ground command was sent. In contingency mode, fault protection was not capable of properly configuring the telecommunication subsystem to re-establish downlink autonomously. Contingency mode was a stable state and flight software could have stayed in this mode indefinitely. This angular acceleration level would have caused multi-axis gyro saturation. If multi-axis gyro saturation was entered, flight software would have inhibited all momentum unloading thus preventing the stabilization of the spacecraft. Assuming sun on the array 33% of the time, battery depletion could be expected within 4.5 +\/- 0.5 hours (sooner for even less favorable sun angle). The ground commands to re-activate RPA were not issued until about 4.5 hours after propellant pressurization since spacecraft autonomy was assumed capable to solve the issue. By the time these ground commands were issued, the batteries most likely would have been depleted. The above postulated sequence of mishaps could have been the cause of Mars Observer loss of signal. Additional Keyword(s): Sequence Interaction, Attitude Control Reference(s): Mars Observer Loss of Signal: Special Review Board Final Report: JPL Pub. 93-28 Mars Observer Fault Protection Response in High Spacecraft Spin Rates, IOM MOS 94-159, 06\/17\/94, G. T. Chen to D. E. Bernard.","Lesson ID":343}
{"Driving Event":"Spacelab utilizes racks which must be supported by a special rack ground support kit if the panels are removed for access. This required more manpower and time than would a self supporting rack.","Lesson ID":325}
{"Driving Event":"The propellant fire on November 27, 1982 at the Arnold Engineering Development Center, Tullahoma, Tennessee was a result of cutting propellants on the floor of a vertical test cell designated J4. The propellant being cut was the M-X stage II propellant. It was a class 1.3, 88 percent weight solids, HTPB, non-HMX propellant. The propellant had been subjected to rapid depressurization as the result of the M-X stage II motor failure November 17, 1982. In addition, the propellant fell approximately 250 feet to a concrete floor. The propellant was submerged under 50 feet of water for three days. After the water was pumped off, broken pieces of propellant that could be easily handled and the sludge were removed. The remaining large pieces were being cut to manageable sizes using a procedure patterned after that used for cutting minuteman propellant. At the time of the fire the propellant had been drying for six days. It was established that the propellant sludge had gotten dry and that the most likely cause of ignition was either impact or friction.","Lesson ID":327}
{"Driving Event":"The Hubble Space Telescope did not perform to the requirements of the contract. A spherical aberration was attributed to the spacing between the field lens and the lower mirror of the reflective null corrector. Note that the reflective null corrector is not a part of the HST but is special test equipment used to verify the curvature of the primary mirror, and to aid in the shaping of the telescope mirrors. It was concluded that the problems would likely have been discovered by quality assurance and design oversight if these functions had been conducted in acccordance with the product assurance plan. It was decided to depart from the plan and exclude quality oversight (with the consent of QA) in some areas. There were other problems, which were not as drastic as the spherical aberration which probably would have been discovered also. These problems led to considerable embarrassment to NASA, expenditure of additional funds to determine the cause and plan for on-orbit repair, and a reduced scientific return.","Lesson ID":332}
{"Driving Event":"In ECLSS Flight Experiment (EFE) testing, damage to the pins in electrical connectors occurred as a result of excessive mating\/demating. Schedule delays resulted.","Lesson ID":316}
{"Driving Event":"On the STS 51\/TOS mission, during payload deployment, commands intended to initiate only the primary SUPER*ZIP explosive cord actually resulted in the simultaneous firing of both the primary explosive cord and back-up explosive cord. This simultaneous explosive cord firing resulted in the rupture of a SUPER*ZIP containment tube and the release of contaminants and high energy debris into the orbiter cargo bay.","Lesson ID":342}
{"Driving Event":"An explosion occurred at the test stand complex 500 at MSFC. The explosion was a result of a massive GH2 leak, which occurred in an underground 3.5 inch OD x 0.6 inch thickness wall schedule XX ASTM A106 grade B carbon steel line. This failure was the result of galvanic corrosion over a prolonged period of time and the application of high pressure gas to a resultant thin pipe membrane.","Lesson ID":315}
{"Driving Event":"From the inception of SL-3 until the flight, the experiment complement changed three or four times. These changes occurred during Payload integration and each time required the integration process to start over. This resulted in considerable manpower\/money waste.","Lesson ID":318}
{"Driving Event":"KSC post flight inspections of RSRM-2 (STS 27) showed a 3.5\" x 3.5\" piece of JPS cork missing from the right hand center field joint at 185 degrees indicating debris. An unbond also existed between the EPDM moisture seal and the extruded cork at this missing location. The missing cork was located at the kevlar band buckle, where the JPS cork interface had been cut to fit over the buckle, creating an unvented void area under the cork.","Lesson ID":330}
{"Driving Event":"A characteristic of rotor machinery has been subsynchronous whirl rotor-dynamics, most recently experienced on the SSME. This motion takes the form of whirling or whipping of the flexed rotor at one of the rotor's natural frequencies below the running speed. Both the HPFTP and the HPOTP experience this problem, and a higher performance requirement on these pumps resulted in marginal whirl situations.","Lesson ID":340}
{"Driving Event":"Sneak circuit analysis was performed on Skylab to assure a high probability of freedom from undesired current paths. Forty-four sneak circuits were found on Skylab, along with a number of components that were not necessary for circuit operation and errors in the documentation.","Lesson ID":317}
{"Driving Event":"On the Hubble Space Telescope, the system entered into the Safemode state, and the data to determine why this occurred was not always available in time to evaluate the causes before executing recovery steps. This occurred because the back-up communications for the Safemode Recorder was not designed for the Low Gain Antenna high\/low mode (32 kbps\/500bps) transmit capability.","Lesson ID":333}
{"Driving Event":"The shuttle IUS was not designed to be maintained. Consequently, no electrical connectors were used. During system testing, some components failed. In the process of replacing the failed components, electrical reconnection was made by splicing. Cables that were respliced were shorter in length and less reliable.","Lesson ID":313}
{"Driving Event":"Spacelab did not have standard utility interfaces at each rack, thus each experimenter or the integration organization had to provide design and routing for each required utility (excluding power).","Lesson ID":326}
{"Driving Event":"The accident investigation into the fire and destruction of a Pershing II stage I missile motor in Germany revealed that it was accepted that the propellant (QBJ-29) was insensitive to ESD. The cause of the accident was attributed to ESD. Older ESD sensitivity tests based upon the determination of spark energy, such as the layer test, the dust test, and the human spark test, were found to be inaccurate when U.S. hazard technologists began determining the ESD sensitivity of QBJ-29. It was found that the spark gap tests did not accurately reflect the actual energy delivered to a propellant sample. U.S. technologists, in addition, did not consider how changes in humidity or temperature affected the electrical properties of the propellant samples. Therefore, U.S. investigators borrowed the test techniques, which SNPE has been developing since 1976. The SNPE employed a three-part test methodology based on the RC discharge test, volume resistivity measurements as a function of temperature, and percolation coefficient calculations. While the SNPE test is more discriminating than the older tests, it is itself unreliable.","Lesson ID":328}
{"Driving Event":"Oscillations at the inlet tee in the LOX dome of the main combustion chamber were being caused by the LOX Flowing over the two vane splitter. The vibrations were causing the vanes to crack.","Lesson ID":341}
{"Driving Event":"The ability to measure from an airborne platform turbulence in the daytime convective planetary boundary layer has existed for several years. The accuracy of these measurements is, in many cases, limited by the errors in the air velocity measurements. current measurement techniques are typically limited by: Measurements of ambient air flow made in relatively close proximity to the aircraft and therefore influenced by the flow around the aircraft. A total \"system calibration\" that is not based on physical constants. An inability to make reliable measurements in clouds and in precipitation. Mechanical resonances of the aircraft which may have a detrimental influence on the data quality.","Lesson ID":339}
{"Driving Event":"A uniquely designed external ram air exchanger has been analyzed and performance tested at the NASA Langley Research Center. The heat exchanger is attached externally to an aircraft and is used to cool a laser system within the fuselage. In the limited space available, with a conventional staggered tube array, estimates showed insufficient cooling capacity. Thus, a non-conventional design was developed with larger tube and fin area exposed to the ram air to increase the heat transfer performance. The basic design consists of 28 circular finned aluminum tubes arranged in two parallel banks. Wind tunnel tests were performed to simulate air and liquid flight conditions for both the non-conventional parallel bank arrangement as well as the conventional staggered tube arrangement. Test results are used in a computer model of the heat exchanger to predict the operating performance for the entire flight profile. These analyses predict significantly improved performance over the conventional design and show adequate thermal control margins. Aircraft-borne experiments requiring large electrical power loads create a significant challenge to provide efficient thermal control for a variety of flight environments. Heat dissipation by convection within the aircraft is often limited, so the thermal load must be dumped overboard using an external heat exchanger. Due to aerodynamic restrictions, the allowable heat exchanger area outside the aircraft is usually extremely small. Thus, a heat exchanger with a small frontal area must be designed to meet the stringent thermal requirements of the experiment. For a thorough discussion of this heat exchanger see paper #902019, SAE technical paper series, \"Thermal Control of a LIDAR Laser System Using a Non-Conventional Ram Air Heat Exchanger\", by Brian D. Killough, William Alexander, Jr., and Doyle P. Swofford, all of the NASA Langley Research Center, Hampton, Virginia 23665","Lesson ID":336}
{"Driving Event":"NASA Langley personnel successfully completed for end users a series of shakedown tests for a new dynamic stability instrumentation system. The system replaces a 25-year-old electromechanical analog instrumentation system that is obsolete. The new system is the only one of its kind in the U.S. and required 5 man years of effort for its development. It uses state of the art digital signal processors to acquire balance force and moment data; to compute, display, and plot static and dynamic aerodynamic damping coefficients; and to compute and display spectral information. All of this information is now provided in real-time during wind-on tunnel conditions. A National Aerospace Plane configuration test techniques demonstrator was tested at the unitary plan wind tunnel repeating identical tunnel conditions from a test conducted in 1990 using the old system. Data was taken at two different mach numbers and over several different angles of attack. The new system reproduced the previous data with less observed drift and scatter. NASA Langley is the only research enter in the U.S. currently conducting dynamic stability research. Personnel involved in developing this system are: Dr. Ping Tcheng, Dr. John Tripp, Douglas Wong, Tommy Jordan, Taumi Daniels, and David Hare.","Lesson ID":335}
{"Driving Event":"For many years, LARC has been studying cavity flow fields at supersonic speeds. This research has included various flow visualization wind tunnel tests to document both the cavity surface and off-body flow fields. During one of these tests, water was injected through pressure measurement orifices located on the model surface in an attempt to visualize vortices that typically form above certain cavity configurations. Because of the low static pressure in the tunnel, it was anticipated that the water would vaporize as it exited the orifice and the resulting vapor would be entrained into the vortices and render them visible. This technique did not work, and the water instead flowed along the model surface. Although the water was difficult to discern against the model surface, it was obvious that the water was being entrained by the model surface flows and had a fast response to the cavity flow unsteadiness. This impetus led to the development of a technique that uses colored water as a medium to visualize surface flows over wind tunnel models. The colored water surface flow visualization technique basically involves injecting colored water through the pressure measurement orifice tubes installed in a wind tunnel model. The colored water exits the orifices and flows along the model surfaces to form streaklines. The resulting flow patterns are then photographed for later analysis. This method has several advantages over the conventional oil flow and tuft techniques that can make it a useful procedure for routine testing.","Lesson ID":337}
{"Driving Event":"The S-II stage of saturn had a very intriguing and baffling series of POGO or forced oscillation response culminating in the near disastrous AS-508 flight. The oscillation occurred early in the S-II stage burn and reached large acceleration amplitudes (thrust frame cross beam) of 33 g'S at 16 HZ, and the resulting large pressure oscillations shut the engine down at 160 seconds of S-II burn. POGO was not apparent for the S-II stage (probably because of poor instrumentation) until AS-503. AS-503 had a self-limiting, local POGO-type oscillation near the 480 second flight time. Concern was raised in the POGO working group over this oscillation and potential vehicle problems. After much discussion and analysis, it was generally agreed that the next vehicle could be made POGO safe by increasing the ullage pressure, which would raise the lox line frequency and decrease the gain and thus the instability. AS-504 did not follow predictions; in fact, it did the opposite. Again, the oscillation was self-limiting. A more detailed look at the pump and engine test data revealed that the increase in ullage pressure would bring into play nonlinearities, which would increase the gain and thus the instability. It was becoming clear that many things were missing; more data must be acquired which required improved flight vehicle instrumentation. The ability to model the bulkhead hydroelastic characteristics was very poor and limited to the first mode. Elimination of this shortcoming required updated analysis and a comprehensive hydrostatic test program for data and verification. Additional line and engine tests were required to better define these characteristics, particularly since no analytical approach was available. In order to maintain launch schedules, it was decided to shut down the S-II center engine 60 seconds early and avoid the POGO problem. This appeared to be the answer, since no real performance loss was incurred. AS-505 and AS-506 appeared to confirm this since no POGO was observed; however, the improved instrumentation was not on these flights but was planned for AS-507. The improved instrumentation detected several \"football\" bursts of oscillation during the flight of AS-507 indicating the POGO loop was marginally stable whereas nonlinear analysis was showing stable limit cycles. Further analysis on AS-508 indicated marginal to unstable conditions. The as-508 flight experienced severe POGO: oscillations started at 16 Hz producing an amplitude of 32 g'S or greater. The poor prediction was due to inadequate nonlinear characterization of the system. After the fact, modal analyses were conducted using three flights and test-determined nonlinearities, nonlinear pump gain, nonlinear damping, and pump inlet compliance. Using these nonlinearities, a reasonable analytical duplication of S-II POGO on all flights could be obtained without adjustments other than known vehicle flight-to-flight differences. The ability to accurately predict POGO enabled design fixes to be implemented.","Lesson ID":334}
{"Driving Event":"An explosion at the phillips 66 facility at pasadena, CA prompted this lesson. There have been accidents at MSFC which could probably have been avoided if personnel had been trained properly.","Lesson ID":324}
{"Driving Event":"While mounting a tray inside an instrument rack, the bottom lip of the tray made contact with the prongs of an electrical plug located below the tray. This contact caused electrical sparks which cut a hole in the tray, burned the paint off the tray, and ruined the plug. In order to preclude this electrical hazard from recurring, it is recommended that all U-Ground devices be installed with the ground in the top position. If mounted horizontally, the neutral prong should be in the top position.","Lesson ID":258}
{"Driving Event":"A roof penetration cover exposed to high temperature from an exhaust stack caught fire. The cover appeared to be composed of only sheet metal but, upon further inspection, was actually composed of plywood placed between two thin pieces of sheet metal.","Lesson ID":252}
{"Driving Event":"A Nalge desiccator, National stock number 6640-00-569-7964, vacuum, plastic, 250 MM, violently imploded after being evacuated about 1\/2 hour before the incident. The force of the implosion threw parts and desiccant with sufficient force such that injury could have occurred if personnel were nearby. Although cautions for the use and cleaning of this device were included in the manufacturer's instructions, as near as can be determined the desiccator had been used properly.","Lesson ID":256}
{"Driving Event":"A rubber seal friction force was being measured in an altitude tank between a plate and an inlet flow duct when the mishap occurred. The failure occurred at an inlet test condition of 10.2 psia with a test cell pressure of 3.6 psia. As the inlet pressure was being increased, the mounting studs holding the seal together failed. The investigating committee determined that improperly sized studs were used to hold the rig together. The structure had tapped 1\/2-13 holes to mate with the plate mount pads. 7\/16-14 studs were used for assembly because of the difficulty of getting the 1\/2-13 studs into the tapped holes. Further investigation revealed that the tapped holes contained rust and paint that did not allow the larger studs, designed for the assembly, to be installed.","Lesson ID":294}
{"Driving Event":"A Hypergol technician erred in the removal of a temperature transducer from a 3-inch Hypergol line at the pad \"A\" fuel farm, resulting in a major fuel spill. The installation design of the dry well and temperature transducer provide a means to remove the transducer from the system for replacement or calibration without having to open the fluid volume. The dry well installation design is inadequate to preclude an untrained or careless technician from inadvertently removing the dry well from the Hypergol propellant line by mistake. Additional Comments: OMI V2196 Titled: \"Hyper Fuel System Validation Storage Area-Local Control\/LPS\" has been updated to include the following warning: \"Removing transducers from dry wells may be hazardous. A restaining retainer is designed to prevent removal of dry well while secured in place by set screws. As transducers are being removed from dry wells, PMTG shall visually verify that dry wells are not turning. Wear face shield, apron and rubber gloves and use extreme care to avoid inadvertent loosening of any temperature XDCR dry well, which could release MMH liquid. If A78633 TEMP XDCR dry well is loosened the entire storage tank contents could be released.\"","Lesson ID":299}
{"Driving Event":"Prior to being operated at KSC, SKYLAB hydraulic systems were tested for contamination. If the systems were found to be clean, they were sealed and not retested. After being operated at KSC, a water system pump failed. A new pump was installed and a fluid sample was taken from the failed pump. Analysis of the fluid sample showed gross contamination. It can also be noted that in following missions, water system pumps failed repeatedly, all due to contamination. Fluid system cleanliness levels were not maintained throughout assembly operations. Plumbing, component, or installation cleaning procedures resulted in cleaning to dissimilar specifications, which were not compatible with various hardware. Component tolerances should be such as to allow particulate contamination of specification levels to pass without failing the component. Filtration, with a filter change-out capability after demonstrated life, should be placed in the system to collect particles. Additional Sources: MSFC Documentation of Significant SKYLAB Experiences, Dated 15 Nov 1973","Lesson ID":244}
{"Driving Event":"Operations personnel, in an engine test facility, reported that JP-4 fuel was found leaking in the basement of the building. Emergency staff responding to the call discovered that the fuel had originated from the engine on the main floor and had leaked onto a power panel in the basement. The spill was located on and around a 480VAC motor control center that contained breakers and contactors to power the pumps, blowers, and fans in the building. The building was evacuated due to a potential explosion hazard. The power was turned off and power to the control center terminated. Absorbent pads were placed around the fuel spill for containment and the area barricaded to prevent access. It was determined that the fuel spill originated from an open fuel return low point drain valve, recently added to the facility, that was not put on the facility drawings. Operations personnel performing a walk-through inspection of the facility did not observe the added drain and therefore were not aware of the presence and open valve position of the drain.","Lesson ID":257}
{"Driving Event":"Occupational Safety and Health Administration (OSHA) requirements prohibit having personnel work under suspended loads. Payload processing facilities will be implementing measures to assure strict compliance with OSHA requirements. It is recommended that these requirements be incorporated into present or future operational plans\/designs of lifting and hoisting equipment to avoid costly delays, redesign or modifications to operations.","Lesson ID":261}
{"Driving Event":"The orbiter processing facility (OPF) swing platforms are used to access the space shuttle main engines (SSME's), orbital maneuvering subsystem pods, and engine heat shields. Engine heat shields are removed every flow to perform turbopump torque checks. Heat shields with handling ground support equipment weigh approximately 300 pounds and are very awkward to handle, shaped in a 10-foot semi-circle. High pressure fuel and oxidizer turbopump (HPFTP and HPOTP) LRU operations require the east diving board be extended to provide access to SSME GIMBALLING and to permit pump removal. A design oversight limits LRU lifting operations to one location, level 19 of the OPF. An extended diving board interferes with the direct decent of flight hardware to the floor. To clear the diving boards during pump lowering\/raising, the pumps are manually pulled away from the diving board with tag lines. This procedure side loads the hoist, a violation of standard NSS\/GO-1740.9. If the tag line operator misjudges the clearance past the diving boards, the pumps will be damaged.","Lesson ID":159}
{"Driving Event":"A 125 pound per square inch pressure air line in a ground trench, used to supply test facilities, failed by splitting along the longitudinal weld. The 10 inch diameter steel pipe ruptured for a distance of about 15 feet. As a result of this failure, four manhole covers were blown into the air. The air line that failed was in a covered ground trench and had been in place for about 15 years. During this time, moisture was present from surface water leakage and considerable corrosion had taken place on the pipe outside diameter. Inspection of the failed pipe revealed that the original thickness of 1\/4 inch was reduced to almost zero in some places as a result of the corrosion. The failure was due to the corroded pipe no longer being able to withstand the internal working pressure.","Lesson ID":241}
{"Driving Event":"In the process of pulling a 30 foot long water pump weighing 3 tons out of a pit, two 3\/4 inch eye bolts were screwed into the pump motor base and a cable sling attached to the eye bolts. The pump was pulled out of the pit setting one end on the ground. When starting to lay it down to a horizontal position, one of the eye bolts sheared off, dropping the pump to the ground.","Lesson ID":246}
{"Driving Event":"During the filling of a liquid hydrogen test apparatus mounted in an AJ-2 airplane low-g test facility, an explosion occurred followed by a fire. The cause of the mishap was determined to be a leak due to a loose \"AN\" fitting on a 1\/2 inch vent line that was teed to the fill line of the research package. The ignition source was found to be hydrogen detectors mounted in the airplane near the test rig for safety considerations. Proof of the ignition source was determined by bench testing the detectors. The test consisted of flowing mixtures of hydrogen and air through them to determine if the flame fronts generated by the catalyst would be stopped by the flame arrestors. At a hydrogen volume ratio of 5 percent, the detectors signaled a warning and the flame fronts were stopped by the screens. When the volume ratio was increased to 15 percent, the arrestors failed to confine the flame.","Lesson ID":247}
{"Driving Event":"The principal cause of pressure vessel rupture is overpressurization. This overstressing of the tank could result in failures after experiencing normal temperature pressure cycles. Tanks that contain heater elements are most likely to experience high pressures if the electrical circuitry fails to cut off the heater elements. High-pressure tanks scratched or impacted after proof testing, i.e., during installation, checkout, or crew operation, cause dangerous stress risers leading to potential tank failures.","Lesson ID":249}
{"Driving Event":"Prior to running a test in a facility using liquid oxygen, a check was made on the sequence timer which controls the valving of the system. When the console selector switch was set at \"CHECK\" and the check started, the liquid oxygen fire valve opened and spilled liquid oxygen. Pressure in the supply tank is required during standby to keep air and water vapor out of the system.","Lesson ID":251}
{"Driving Event":"A five liter, glass lined, liquified gas dewar exploded after workers completed a transfer of liquid nitrogen from it. The explosion propelled fragmented glass from both ends of the dewar. Fortunately, no one was in the path of the razor sharp fragments and no injury resulted. The dewar had been in use for only two years and no physical deterioration had been noted.","Lesson ID":254}
{"Driving Event":"The Flexovit grinding wheel, National stock number 3460-00-027-0942, abrasive, resin bound, 7\" by 1\/4\", shape 1397, grit 24, was released from a portable air powered grinder, commonly referred to as a \"Bayflex Grinder\", just after the grinder was turned off. The grinding wheel was propelled across the room by its inertial force created during the grinding operation. The problem is associated with the size of the flat surface on the nut, which is torqued to the flange on the grinder. The grinding wheels were manufactured with two different flat surface sizes for the nut, 1\/16\" and 3\/8\". The 1\/16\" flat surface may allow the grinding wheel to unthread itself from the grinder when the air is cut off. The grinding wheel with the 3\/8\" flat surface is the correct one to use.","Lesson ID":255}
{"Driving Event":"Possible residue build-up in stainless steel tubing, as obtained from the supplier, could cause a blockage in the line. All stainless steel tubing should be inspected for cleanliness prior to use and should be cleaned according to the following procedure for general R&D applications: Blow down with dry air to remove majority of particles. Pass solvent-rinsed, lint-free swab through tubing to dislodge additional particles. Flush tubing with fresh solvent for about 15 seconds. Follow with another dry air blow down. Conduct cursory, visual examination of each cleaned tube to assure that all visible particles are removed. Install tight-fitting, clean, plastic caps on each tubing end. Fasten tag on each tubing section to identify that a cleaning process has been accomplished. Note: This procedure will not provide adequate cleanliness for sensitive pneumatic\/hydraulic applications, oxidizing propellant service, or flight hardware applications.","Lesson ID":260}
{"Driving Event":"In April 1993, the Atmospheric Trace Molecule Spectroscopy (ATMOS) instrument was flown on board the space shuttle Discovery (STS-56) as part of the second Atmospheric Laboratory for Applications and Science (ATLAS-2) mission. While the instrument performed very well during the mission, a very significant event occurred in the course of the flight, which could have resulted in little or no science data being returned from ATMOS. This problem also affected other experiments, but to a lesser degree. The problem involved the shuttle's High Rate Data Telemetry System and the SPACELAB's High Data Rate Recorder (HDRR). Following payload subsystem activation, the ATMOS instrument was successfully powered up and performed the first operation -- an engineering exercise to verify the proper operation of subsystems. The primary ATMOS science data stream is normally transmitted live, or in a delayed record\/dump mode on a high rate data channel. After only a few seconds of transmission the latter stream became extremely noisy and rendered the data scientifically unusable. Subsequently, NASA payload controllers attempted a work-around using the SPACELAB's HDRR and the shuttle's Lower Data Rate Telemetry Channel. This method improved the data quality, but it still contained numerous parity errors. Fortunately, the ATLAS-2 mission was the first flight of a new, dedicated ATMOS recorder subsystem. This mission was originally intended to be an engineering evaluation and test flight for the recorder. The use of this recorder permitted the independent recording of more data than was needed to meet the minimum success criteria of the ATLAS-2 mission. No complete end-to-end test was performed, either prior to or after the flight. Following the mission, KSC performed several tests on the shuttle and SPACELAB telemetry system to determine the cause of the problem. No obvious failure mechanisms were found in either the orbiter's system or in the spacelab subsystem. It has only recently been learned, after several subsystem tests, that there were two or three problem areas in the STS-56 data system, which would explain the loss of data. From the point of view of the ATMOS experiment, the post-flight testing plans, organization, and execution were ineffectively coordinated primarily because of a lack of a single authority figure to emphasize the importance of the testing activities to the success of the ATMOS experiment and the mission. The ATMOS experiment is described in some detail in SSEF # 1-104.","Lesson ID":311}
{"Driving Event":"Two data shield surge protectors, model numbers 85 and s85, failed during use, causing smoke to be emitted and rendering the units unserviceable. The surge protectors had only been in use for 2-3 months. Both units were used as switches to turn the computers on and off.","Lesson ID":253}
{"Driving Event":"While pressurizing the oxidizer propellant tank, a change in ullage pressure of 8 psi occurred and caused the computer program to indicate that the interface and supply valves were closed. At this point, the engineer felt it was safe to close the dome load valve, in reality opening it. He then opened the interface valve, the pressure online with the module was 190 psig, the supply valve was then opened and the pressure spiked to approximately 400 psig, which ruptured the burst disk. The computer program indicated the incorrect status of the system because the control logic limits were not adjusted\/reset prior to starting the operation.","Lesson ID":77}
{"Driving Event":"Three RCS primary thruster injector\/chamber assemblies were damaged when the oven temperature control system malfunctioned and permitted the temperature to reach an estimated 1400 deg F during a cerachrome insulation baking process that should have been limited to 625 deg F. These units should have been rejected at this point, but quality assurance was not notified. As a result, the full extent of damage was not determined until the severe discoloration of titanium alloy and columbium parts was noted during the post-baking weighing process, about three weeks later.","Lesson ID":78}
{"Driving Event":"MLG tire heat generated from max. Braking due to a crosswind landing, heavy orbiter, or long landing, could cause a transfer of heat to continue to the MLG tires after wheel stop, resulting in a delayed tire blowout. An explosive tire rupture caused by increasing tire pressure, cuts, excessive loading, or skidding could injure personnel and\/or damage the orbiter\/chassis hydraulic system\/ground support equipment. Three thermal relief plugs in each MLG tire prevent tire overpressurization, the orbiter anti-skid\/brake control system prevents locked brakes, and the orbiter hydraulic system displacement limiter limits hydraulic fluid loss.","Lesson ID":128}
{"Driving Event":"The quick disconnect\/filter assemblies are designed to provide a disconnect interface and remove all solid particles which exceed 25 microns. The fluids being filtered include hydrazine (N2H4), GN2, lube oil, and water. The ground half QD assemblies interface the GSE at the ground umbilical carriers S70-0757 and S70-0758 which provide structural support and fluid containment. If the QD is mated incorrectly, it may cause the QD to leak N2H4 during fill\/drain operations.","Lesson ID":154}
{"Driving Event":"Three sections of a telescoping tube assembly at Pad B rotating service structure (RSS) fell while being extended to incorporate a planned modification (MOD). The MOD intended to eliminate binding that had been experienced during testing and verification. The falling tubes impacted and severely damaged the RSS and orbital maneuvering system pod covers. The contributing factor to this failure is that the fillet welds on tube \"D\" provided an outward ramp effect that caused excessive wear on the keepers and the eventual bowing of tube \"C\" which allowed less surface contact area between the welded stops and the keepers.","Lesson ID":62}
{"Driving Event":"Criteria for design, performance, launch commit, and other operations have used \"ambient\" conditions as a reference or base for evaluating systems which could be affected by environmental conditions. the term \"ambient\" is not specific and, subsequently, results in misinterpretation. Ambient conditions are a specific set of conditions and should be measured at specific locations and clarified as to the effects of time of day, wind velocities and direction, etc.","Lesson ID":214}
{"Driving Event":"During a crane disassembly, a cable sling broke, dropping a 10 ton crane counterweight. The crane crew was removing the front counterweight from the crane to place it on a flat bed trailer when the mishap occurred. The sling used was a rusty, 4 leg, 5\/8 inch diameter cable about 15 feet long. Only two legs were used during this lifting operation. The investigating committee found that calculations made from a standard table published by U.S. Steel showed that the allowable working load for a new cable of this size using 2 legs was only 5.28 tons. The crane operators, based on their experience and intuition, grossly underestimated the strength of the sling.","Lesson ID":239}
{"Driving Event":"In the early morning hours before launch, a KSC ice team performed an inspection of the Challenger and pad. Their specific aim was to check for the amount and type of ice. They had with them an infrared gun designed to measure surface temperatures. This instrument was focused on the external tank and Solid Rocket Boosters (SRB's) during the course of the survey. The infrared gun indicated temperatures on the right SRB of from seven to nine degrees Fahrenheit, compared to 23 to 25 degrees for the left SRB. This discrepancy was not reported to launch team officials. Later, tests indicated the infrared gun requires a minimum of 40 minutes to stabilize at the temperatures experienced at KSC on the morning of the launch. The gun was focused on the right SRB prior to the time it had stabilized, indicating the readings taken were not reliable. Ice team members displayed a lack of sensitivity to potentially hazardous conditions to which they were evaluating and, nevertheless, should have reported the low readings.","Lesson ID":202}
{"Driving Event":"The Space Shuttle Main Engine (SSME) telemetry system does not show absolute Greenwich Mean Time (GMT), but rather, the number of controller cycles since change in mode. Approximate timing had been established (during the STS 51-L launch process) by aligning the first guidance cycle after engine start with the engine start command time determined by analysis of the General Purpose Computer (GPC) event times. This aligned the SSME event times to the GPC event times to within a few tens of milliseconds, sufficient for normal flight analysis but insufficient for determining event sequencing for a system failure, which involves an interaction between the SSME and the rest of the vehicle. Without precise correlation between multiple data systems, there may be a delay in subsequent anomaly investigations due to timing uncertainties or a need to correct data timing.","Lesson ID":209}
{"Driving Event":"Some of the original equipment manufacturers are not providing sufficient support for out-of-production parts. NASA and its contractors have evolved good systems for identifying and tracking these problems, but the difficulties of ensuring continuing production with small batches of obsolescent or semi-obsolescent parts inevitably will increase with orbiter age. The problem involves balancing the alternatives of purchasing and storage of excess parts, establishing manufacturing facilities and skills at KSC, or potentially facing critical shortages. The heart of the problem is that many manufacturers simply do not want to devote any more manpower or effort to revive production. The study of possible alternative source vendors for critical parts continues but is necessarily a slow and complex process. The 1990 ASAP annual report concerned with structural overhaul and dealt principally with the visit on OV-102 at the Palmdale facility scheduled to begin in June 1991. A review of the major modifications necessary to bring OV-102 up to the standard of OV-105 was included. During the work on OV-102, a \"3-year\" and a \"6-year\" structural inspection will be performed. It is assumed that this will provide the information necessary to define a basic structural overhaul program. This program would then be fitted into available intervals in the launch program up to 1995 for all four orbiters. A second element of longer term maintenance program planning has been defined but apparently is not presently funded. It is known as \"orbiter supportability plan - project 2020\" and is intended to provide a basis for ensuring a rational program for orderly maintenance and support of the fleet through the assembly of the SSF. The outline of the plan properly embraces the interfaces of the existing major contractors and the operating NASA centers, and outlines an organizational support formula. This formula includes detailed line replaceable unit supportability and full structural integrity accountability. The ASAP has an interest in seeing this program go forward as planned.","Lesson ID":222}
{"Driving Event":"A deactivated exhaust gas cooler in a vacuum line collapsed under normal operating conditions of 26 inches of mercury. The cooler was destroyed. There was minor damage to a nearby wall due to negative pressure in the vicinity of the cooler. Skylights in the shop area imploded and a considerable amount of debris was drawn into the piping. The principal cause of the failure was deterioration of the cooler due to age. Poor welding during assembly and inadequate inspection of the cooler were contributing factors.","Lesson ID":233}
{"Driving Event":"A cover plate bolted to the top of a high pressure helium filter was blown off and the contents of the filter (pyrex wool and silica gel) were expelled. The resulting failure occurred because there were only three bolts holding the cover in place instead of the sixteen bolts required to fill all the bolt holes. The filter was pressurized to 1700 pounds per square inch with helium when the pneumatic explosion occurred. Preceeding the accident, as part of a maintenance program, the filter cover was removed for cleaning and reactivation. The bolts were frozen and difficult to remove. After three bolts were removed, the balance of them were cut off. When the cover was reinstalled, the three good bolts were put on but other bolts were not available to complete the bolt hole circle. Without knowledge of the incomplete assembly, the system was pressurized by the test crew resulting in the pneumatic explosion.","Lesson ID":240}
{"Driving Event":"The External Tank (ET) hardware incorporates five categories of instrumentation, sensors, and associated cabling, where the instrumentation data is recorded in the orbiter for transmittal to ground stations. The electrical system provides the propellant level, among other functions. The instrumentation is comprised of 38 sensors which control ullage temperature and pressure, liquid level, LH2 depletion, and vent valve position. During pre-launch propellant loading of the STS 51-L mission, a HIM failure caused a two hour, 20 minute delay while repairs were made. A HIM is used to interface the ET sensors with the launch control computer systems, where it is analyzed by systems engineers. The HIM failure resulted in the loss of all fire detection and hazardous gas measurements, which are required during propellant loading to provide adequate visibility of propellant leaks and fire.","Lesson ID":205}
{"Driving Event":"The space shuttle computer system faces a continuing evolution in flight requirements and increased equipment obsolescence accompanied by greater and more expensive maintenance problems. There is a large list of waiting software change requirements covering such things as the extended duration orbiter missions, crew requested changes, mission-specific changes, and general improvements. Due to the rapid evolution of computer technology, it is difficult to keep any given generation of computer equipment in use for more than a few years. After that, it becomes increasingly difficult to obtain replacement parts. There is also the opportunity to incorporate new capabilities. In the projected 30-year horizon for the space shuttle, it will be necessary to upgrade the system several times. There now are a number of arguments that favor starting a study for long-term space shuttle avionics computer evolution. They are based on the events that can be expected in 8 to 10 years. The hardware in the \"new\" general purpose computer will become obsolete and require replacement in about that time period. Also within that time period, the limit on available memory in the space shuttle computers will have been reached. Expansion with the \"new\" general purpose computer will not be possible without major software changes that would require massive reverification.","Lesson ID":212}
{"Driving Event":"Although the MSFC data bases contain the time histories of most of the pertinent flight dynamic and trajectory variables for each launch, cumulative data for the variables were not available. This made it difficult to quickly determine the actual ranges of flight experience at any given time, as well as, what a reasonable value (within the expected ranges) should be. A computer program which updates the maximum and minimum values at each time point, the flights which produced them, and the means and standard deviations from which the values accumulated from previous flights would be beneficial. The program should include the range of environments, equipment certifications, and flight exposure. The data should be readily available to designers, flight planners, and operational personnel.","Lesson ID":213}
{"Driving Event":"The total elapsed repair turnaround time still can be excessive with a resulting major impact on inventory management. There are several contributing causes for this that were discussed briefly in the 1990 annual report, but one of the key issues is the average time involved in the engineering analysis of failed components. The overall trend of repair turnaround time showed a significant improvement toward the end of the year, but in some cases, notably the components overhauled by the original equipment manufacturers, the time is much too high. Management emphasis currently is being directed to the entire problem of reducing repair turnaround time and should continue.","Lesson ID":221}
{"Driving Event":"During a hardware performance evaluation, Solid Rocket Motor (SRM) clevis and tang sealing surface diameters were assumed to be stable and were not remeasured during refurbishment. Subsequent testing revealed growth in the diameters after hydroproof (and possibly flight) which introduced an unrecognized variable into o-ring squeeze calculations. The static o-ring compression after mating is influenced by these actual hardware dimensions and the degree of segment concentricity, and are critical to hardware performance. During the STS 51-L Investigation, measurements were made on refurbished and reused segments, and the data indicated that segment circumferences at the sealing surfaces change with repeated use.","Lesson ID":224}
{"Driving Event":"The original STS operations baseline plan defined required capabilities for the STS system before it was designed. The operational system would fly 6 flights the first year, 15 the second, 24 the third, and by the sixth year a total of 60 flights per year. To meet this flight rate, turnaround was to be completed in 14 days. The vision of the operational space shuttle was clearly much larger than the resource base eventually established to create the capability. The 1985 mission operations were successful in spite of significant remanifesting and perturbations. However, all trends prior to the STS 51-L mishap indicated that the milestones required to support preparations for the 1986 flight schedule were not being met.","Lesson ID":229}
{"Driving Event":"The Vertical Processing Facility (VPF) in KSC's industrial area is designed to accommodate all vertically processed payloads through cargo integration. The VPF consists of an environmentally controlled high bay and air lock. Two payload workstands with six fixed platforms provide access to payloads in the high bay. The workstand and platforms are currently painted with an epoxy-based paint applied over a zinc galvanized coating that prevents the paint from permanently adhering to the surface. Traffic and normal wear on the workstand causes the paint to flake, creating Foreign Object Debris (F.O.D.) and contamination in the clean room environment.","Lesson ID":234}
{"Driving Event":"Inertial Upper Stage\/Tracking and Data Relay Satellite (IUS\/TDRS) instrumentation design allows active monitoring of only one of two Propellant Tank Assemblies (PTA's) during the countdown phase. The PTA's are isolated from each other until activated after IUS deployment. Therefore, the status of all PTA's can not be determined by monitoring one PTA. Pre-launch preparation procedures permit adequate determination of pre-flight PTA leakage status; pyrotechnic system design adequately protects against inadvertently commanded loss of PTA isolation; and structural design safety factors are adequate. However, no indicator is available to detect a flight-induced anomaly, thereby making the IUS status uncertain.","Lesson ID":206}
{"Driving Event":"A very disorganized system of making, archiving, and reporting natural environmental conditions at KSC has evolved. Several organizations make measurements and archive them in a variety of ways. Different organizations are responsible for transmitting these data to using organizations. The final report of the natural environmental conditions for the launch is the responsibility of another organization. Therefore, it is difficult to determine when and where some of the measurements were made, what type they are, and whether or not the instruments were properly calibrated. Instead of the numerous organizations, each organization that has a requirement for natural atmospheric environmental data should make its requirements known; and one single organization at each launch site should be responsible for the environmental data that could affect a launch.","Lesson ID":207}
{"Driving Event":"All inventory SRM case o-rings were reinspected during the STS 51-L investigation. When reinspected using original inspection equipment (mechanical micrometer), very few out-of-tolerance conditions were identified. However, when reinspected with a laser micrometer with a 0.007-inch measuring beam, numerous small localized out-of-tolerance conditions were detected. All inventory o-rings were also x-rayed, indicating numerous o-ring inclusions. Although tests proved that these conditions did not affect the sealing capability, this does indicate a potential problem and a need for processing and inspection improvements. It was also learned during this investigation that the o-ring material manufacturer had changed material formulations and processing numerous times since starting to produce srm o-ring material. While all these formulations resulted in o-ring material that was in compliance with MIL-R-83248, this lack of standardization could possibly result in application problems and is unacceptable for such a critical item.","Lesson ID":215}
{"Driving Event":"Solid Rocket Motor segments are shipped from the facility in Utah to KSC horizontally on railroad cars. During the assembly process at KSC, it has become necessary to reshape case segments to make them concentric with mating segments. This has resulted in assembly difficulties and eccentric loads on the joint o-rings. Assembly difficulties resulting from the lack of concentricity include the generation of case metal slivers produced by having to force pins into the joint pin holes. The pin-to-pin hole tolerances are such that the pin is difficult to install if the tang and clevis pin holes are not precisely aligned. Case segment ovality (which apparently results from the horizontal shipment on railcars) can cause tight tolerances in the area of the o-ring sealing surface. This can cause assembly difficulties and result in undesirable o-ring squeeze.","Lesson ID":225}
{"Driving Event":"Exhausters were running to provide simulation of altitude conditions in a combustor rig when the mishap occurred. The equipment operators were short-handed and, as a result, a certain amount of confusion existed. A valve at the discharge end of the exhausters was inadvertently closed. The reduced flow caused the inlet pressure to rise because a continuous quantity of air was being supplied to the exhauster inlet from the compressors in the system. As a result, the pressure at the exhauster inlet increased to almost atmospheric. The exhausters then became compressors and generated a discharge pressure level high enough to rupture the inverted, dished head of the exhauster header located 50 feet downstream. The inverted, dished head was 8 feet in diameter and 3\/8 inches thick located 16 inches underneath the floor level. A hole about 30 feet in diameter was blown in the roof of the building located 35 feet above the floor level. A large number of windows were broken and the reinforced concrete floor in the vicinity of the rupture was destroyed.","Lesson ID":238}
{"Driving Event":"Requirements for the operational era was introduced into the system in early 1985. The foundation for the system, operations and maintenance requirements and specifications document, provides a sound base on which to build a mature system as future requirements are defined. Some problems have been encountered while progressing toward a mature system. Implementation of newly defined requirements is not always accomplished according to an agreed upon plan that can be supported by all involved functional areas. Level II also lacks an active closed loop audit system to check the quality of compliance with established requirements. Additionally, there is no baseline postflight turnaround schedule to use as a basis for tracking long-term trends in waivers, deferrals, additions, or deletions to the KSC flow.","Lesson ID":230}
{"Driving Event":"The movement of some requests for software upgrades to crew procedures is a matter of serious concern. The crew already has a very large number of procedures with which to be familiar. Adding to that load, particularly with items that could be handled easily with greater reliability and safety by software, does not seem wise. Procedures such as \"do not touch the keyboard for X seconds after the occurrence of event Y\" can be handled easily by software. If such procedures are contingencies that are employed infrequently, the chance of error when they are needed rises. A review of all computer-related procedures to ascertain whether or not there is significant potential for design-induced human errors should be mounted. This review should include crew representatives, experts on human factors, and members of safety and mission quality organization.","Lesson ID":195}
{"Driving Event":"Ice debris created by the STS 51-L launch was greater than predicted by pre-launch analysis. The trajectories of wind-driven ice falling from the Fixed Service Structure\/Rotating Service Structure (FSS\/RSS) were predicted using aerodynamic analysis methods. These methods accounted for drag retarding the fall and wind velocity imparting a lateral velocity component. The effects of plume aspiration and particle rebound off the mobile launch platform were not included in the analysis. Launch films show that the vehicle rising off the launch pad caused considerable aspiration. This effect drew ice toward the Solid Rocket Booster (SRB) PLUME, with some ice striking the left hand SRB. The actual FSS\/RSS ice movement, as observed on the photographic documentation, did not conform to the predictions in two important respects: 1) the ice generally did not release until after main engine ignition, and 2) the ice translated further toward the vehicle than predicted.","Lesson ID":200}
{"Driving Event":"Leakage of small quantities of toxic propellants, monomethyl hydrazine (MMH) and nitrogen tetroxide (N2O4) from one or more reaction control system (RCS) thrusters could create an environment hazardous to personnel. The aft and forward RCS contain residual MMH and N2O4 under post-flight pressure. RCS thrusters have been known to leak when ambient temperature is low, orbiter valve pressure is low, and\/or if there is no orbiter internal purge.","Lesson ID":148}
{"Driving Event":"The -1 and -2 hypergol spill aspirators vent into the atmosphere when used. These were KSC's first portable models and are now identified to operate only at unconfined areas because of their venting characteristics to the atmosphere. The -3 through -6 aspirators are configured to vent into a facility vent system.","Lesson ID":153}
{"Driving Event":"No platforms have been designed to provide personnel access to the orbiter's lower forward fuselage (foward reaction control system cavity) for repairs, maintenance, and\/or inspections. The use of portable pic-boards (temporary structures) may cause personnel to fall or allow contact between the pic-board and orbiter, resulting in personnel injury and\/or orbiter damage.","Lesson ID":167}
{"Driving Event":"Failure of one or more of these component switches 1S8, 2S8, 3S8, or 4S8 in the closed position would cause a short circuit of relay K11, thus not allowing any of the 16 bucket proximity limit switches on both buckets to stop travel. This can result in damage to flight hardware (payload and\/or vehicle) due to buckets hitting hardware.","Lesson ID":170}
{"Driving Event":"Pilot actuated extend supply and return valves can be reset to the closed position while the access arm is being extended. This could damage the OAA and possibly prevent reextension and crew egress. Position of arm must be monitored during launch countdown. A retract signal from LPS or from the safing panel during an LPS emergency extend mode will cause the extend valves to be reset. In addition, removing the safing panel emergency extend signal prior to full extend, while the LPS or safing panel is in the retract mode, will cause the extend valves to reset.","Lesson ID":172}
{"Driving Event":"Flammable and toxic vapors can be expelled into the deservicing hangar at DFRC, providing a potential for fire, explosion and toxicity above the permissible exposure limits (PEL). No venting is planned, however, pressure bleed vents do exist on these systems and are expected to boil off and vent periodically in short bursts if the fuel cells have been secured.","Lesson ID":173}
{"Driving Event":"The OPF payload bay bridge hoist system spans the length of the shuttle payload bay. Two bridges, mounted on platforms, move on rails. On each bridge are two moveable trolleys, each trolley providing a base for a suspended, telescoping bucket hoist. Each trolley has two-speed (3 ft\/min and 9 ft\/min), direct-drive gear motors and redundant electric brakes. There is potential for flight hardware damage because the bridge cannot stop in short distances.","Lesson ID":174}
{"Driving Event":"The SRM Is the primary propulsive element for the space shuttle. The SRM consists of: an insulated and lined segmented rocket motor case loaded with solid propellant; an ignition system complete with electromechanical safe and arm device, initiator, and load ignitor; a movable nozzle; raceway bracketry; instrumentation; and the necessary integration hardware. Structurally, a SRM is configured with a forward rocket motor segment, two center rocket motor segments, and one aft rocket motor segment. A field joint is that portion of the SRM segment that is assembled\/stacked at KSC to create the finished SRM. These field joints are susceptible to environmental conditions and were not qualification tested to the full range of environments. This led to a lack of complete understanding of the joint design limits.","Lesson ID":175}
{"Driving Event":"The winches are used to lift and lower the FRCS mezzanine access platforms at the 207 foot level of the RSS. Should they fail during retraction or extension operations, the platform could fall and breakaway from its hinge and wire rope tether, resulting in possible damage to the orbiter and\/or injury to personnel. As an interim control, platforms are being tethered with a 1\/2\" nylon rope during all lifting operations.","Lesson ID":181}
{"Driving Event":"The LO2 and LH2 vent and relief valve position indicator switch tolerance allows the valve to indicate \"closed\" when it may be open up to 0.30 inch. This condition could allow undetected ullage gas leakage prior to launch. Hot GO2 may auto-ignite the ET thermal protection system (TPS) after SSME ignition. GH2 in flight can cause fire and loss of TPS which could result in a catastrophic situation. The vent\/relief valve uses a position indicator switch that is highly accurate. However, no matter how accurate, no position indicator can accurately assure closure because leakage rates for qualification and acceptance are roughly 5E-6 lb\/sec. Therefore, a redesign to eliminate the hazard has proven to be virtually impossible.","Lesson ID":184}
{"Driving Event":"The SSME design verification specifications are evaluated by analysis, laboratory testing, subsystem testing, and\/or engine hot fire testing. Tests are planned to expose problems early and consist of over-stress tests, off limits tests, and malfunction tests. The ground test program prior to the STS 51-L accident was questionable. The number of tests per month had decreased during a two year period prior to the accident. The SSME development program specifies a ground hot fire test program that includes multiple engines of the flight configuration, with maintenance and inspections, that demonstrates hot fire operational time far in excess of the orbiter fleet leader engine. It also pursues engine hot fire tests that demonstrate the limits of the engine operational parameters and margins or over-stress tests to verify the full engine capability. Further, margin tests should be conducted to the extent that they reasonably represent potential engine operation in a degraded state.","Lesson ID":185}
{"Driving Event":"The payload bay bridge hoist system is located in the orbiter processing facility, and spans the length of the shuttle payload bay. The two bridges, mounted on platforms, move on rails. On each bridge are two movable trolleys, each providing a base for a suspended telescoping bucket hoist. Maneuvering to any point in the payload bay is possible with the three directions of motion provided by the bridges, trolleys, and buckets. With no mechanical locking device to support the bucket load when cables are disconnected for inspection or replacement, a possibility exists for damage or injury.","Lesson ID":160}
{"Driving Event":"The supply system for the 750 psig GN2 is designed such that pressure may not be removed from flodyne valves for removal\/replacement, a SCAPE operation, without removing pressure which actuates other relevant components. Inadequate isolation capability of actuation pressure could result in loss of valve control, allowing valve to open when it should be closed. This could allow trapped residuals in the cross country line to drain back to the storage area, possibly resulting in a hypergol spill or fire.","Lesson ID":163}
{"Driving Event":"After every launch, personnel are required to climb out and balance on the liquid hydrogen external tank vent line to remove blast covers. After launch, the vent line is covered with a mixture of solid rocket booster residue and sound suppression water, thus making it very dangerous to climb on the line to remove blast covers. The location under the vent line is a 20-foot unprotected drop. Personnel could fall and\/or drop the heavy blast shield cover during the installation\/removal process.","Lesson ID":166}
{"Driving Event":"The primary reason for the use of the putty in the SRM was to act as a thermal barrier in the joints to prevent o-ring erosion resulting from circumferential hot gas flow during motor firing. Prior to the 51-L mishap, the putty was believed to perform such that it would allow pressure to the primary o-ring during the SRM ignition transient. Subsequently, it has been found that humidity and temperature enhance the characteristics of putty relative to its pressure holding characteristics. The uncertainty of these characteristic changes directly affected the ability of the field joint to seal.","Lesson ID":176}
{"Driving Event":"The o-ring used in the SRM case joint is critical to the sealing of the joint, yet is not designated as a critical process. The adequacy of o-ring processing and quality control is questionable even though a number of o-rings in bonded storage were thoroughly analyzed and tested as part of 51-L failure analysis effort and found to be acceptable. The manufacturing process included delivery of the final o-ring rubber material to where the material is cut to the proper lengths and a scarf joint is made. This manufacturing process is a potential problem area as seen by repairs of inclusions and voids in the rubber delivered.","Lesson ID":177}
{"Driving Event":"An unusually high workload at the time of the STS 51-L ground processing caused manpower limitations, and some areas where particular skills were required, were in short supply. The major cause was the necessity of processing four orbiters, while also completing the launch complex 39B activation. Original planning called for OV-103 to be shipped to Vandenberg AFB in September 1985. The shipment was delayed in order to fly OV-103 on an additional flight from KSC. The need to delay the movement of OV-103, in turn, was caused by major work on OV-102 that had traveled to KSC. This resulted in a long processing flow prior to the STS 61-C launch. Problems in processing both orbiters were further increased by a substantial reliance on part cannibalization to support the operations. This was compounded by the STS 61-C activity, which was moved from a planned December 1985 launch to January 12, 1986. This unplanned delay, along with several intermediate launch attempts, created a higher than anticipated demand upon manpower, resulting in schedule limitations. In some skills, such as test conductors and senior engineers, the higher than normal test activities created abnormal demands upon their availability.","Lesson ID":196}
{"Driving Event":"The RCS primary thruster throat ferry flight plug assembly is used to prevent moisture intrusion during the orbiter's ferry operations. This assembly is installed after the orbiter lands and is removed during deservicing operations. After deservicing, the primary engine cover is used during orbiter processing to control and\/or prevent moisture. This cover has a butyl rubber o-ring which acts as a moisture seal, but is incompatible with N2O4. Vapor leakage could cause deterioration of the o-ring, severely limiting the effectiveness of the thruster ferry plug to seal out moisture, as well as contaminating the thruster nozzle.","Lesson ID":152}
{"Driving Event":"The external tank's gaseous hydrogen vent arm provides for venting of the LH2 tank, pneumatics, and electrical services to the ground umilical carrier. The deceleration unit has failed twice. These failures were caused by a low fluid level in the shock absorber. During one launch failure the QD was damaged and broke in half. Several hours after launch, the detanking of the LH2 dewer tank was started and gaseous hydrogen vented out of the broken QD\/pipe, instead of venting to the Pad-A burn pond as designated.","Lesson ID":157}
{"Driving Event":"The QD\/filter assemblies are designed to provide a disconnect interface and remove all solid particles (exceeding 25 microns) from the servicing fluids at various system operating pressures, contaminant capacities, and rated flows. Servicing fluids include O2, H2, freon, coolant water, and potable water. Assemblies consist of a quick disconnect, filter, and associated caps, fittings, seals, and tethered nameplate\/identification tags. The QD has internal bellows which permit movement of a probe assembly that opens flight-half coupling. A pod component failure may cause contamination in the orbiter onboard reactants.","Lesson ID":150}
{"Driving Event":"During MLP vehicle hydraulic power-up, trapped pressure between check valve A77943 and supply valve A77900 could occur if the supply valve is not open. When pressure is locked up, the supply valve has to be opened using a pry bar, sometimes breaking the valve handles. This constitutes an unsafe condition and could result in injury to personnel.","Lesson ID":156}
{"Driving Event":"The orbiter\/ET feedline mating stud tensioner unit exposes personnel to a high pressure source and could result in injury or flight hardware damage. During ratcheting of the nut onto the stud, personnel will be in the vicinity of high-pressure fluid, water, and rust inhibitor at 11,600 psig. Three stud tensioner heads, connected by six hoses through a common manifold, are used to apply a tension load of 64,000 lbs maximum to three cryogenic umbilical separation bolts by means of an air-driven hydraulic pumping unit.","Lesson ID":162}
{"Driving Event":"During processing, employees failed to perform checks of the mandatory inspection points of the o-rings as specified in the acceptance criteria. However, a review of inspection records for the 51-L o-rings indicates there is a high probability that the 51-L o-rings were acceptable for launch","Lesson ID":178}
{"Driving Event":"Because of movement and vibration, debris shields provide inadequate protection against dropped or falling objects. Vibration and movement on workstands causes debris shields to move out of place, leaving flight hardware unprotected. Dropped tools and\/or equipment could cause damage to the SRB's.","Lesson ID":182}
{"Driving Event":"The SRM segments are transported horizontally by standard 200-ton capacity railcars with hydraulic couplers. It was determined that the transportation design requirements for the transportation support equipment exceeded the capabilities of the railcars. There is concern for potential changes to the cases resulting from transportation in the horizontal position. As part of the case joint redesign effort, studies are being conducted to determine the effect of horizontal transportation on case ovality and, in turn, the effect of ovality on the assembly process.","Lesson ID":183}
{"Driving Event":"As a result of lower release mechanism pin hole elongation, there is potential for premature disconnect of the T-0 umbilical carrier plate due to failure of the LO2\/LH2 tail service mast (TSM) lower release mechanism pin hole structure to support the dropweight.","Lesson ID":188}
{"Driving Event":"The KSC work control documentation system, which controls and records space shuttle processing, has evolved from three manned space flight programs: Mercury, Gemini, and Apollo. It provides the key to vehicle configuration control, proper definition and authorization of the work to be performed, the assurance of adequate work having been performed after closeouts, and traceability and accountability for actions performed. Inadequacies were uncovered in the form of a lack of timely closures recorded on completed work items; poor annotation of the steps taken in performing authorized deviations; missing signatures and quality control stamps (an average of 1\/4 of 1% missing); and a lack of traceability.","Lesson ID":189}
{"Driving Event":"The configuration of the portable hypergol checkout panels located on platforms 6E and 6W in the OPF restricts personnel working in the area from egressing to a safe area. The checkout panels (four per high bay; two per platform) have flexhoses and electrical cables that become entangled and cannot easily be maintained in an orderly arrangement. The flexhoses and cables also present a tripping hazard and further hinder emergency egress from the platforms. Additionally, these flexhoses leak and are more prone to failure because of their tendency to kink and twist in this configuration.","Lesson ID":145}
{"Driving Event":"The orbital maneuvering system engine trickle purge system is used to prevent oxidation\/corrosion damage to the OMS engine injector ball joints. A 1.0 - 1.5 SCFM GN2 flow is applied during post-landing ground operations. Undetected loss of GN2 purge to OMS engine injector cavities could eventually corrode the vehicle system.","Lesson ID":147}
{"Driving Event":"Platforms 11A-1 and 11A-6 were retracted to support payload bay door opening. The platforms were not able to be extended for personnel access in support of aft propulsion system pod activities due to an interference when the orbiter payload bay doors were being cycled open and closed. Contact due to interference may cause damage to the payload bay doors and orbiter or personnel may be injured.","Lesson ID":158}
{"Driving Event":"A review of the considerations for the decision to fire the full scale motors in the horizontal position was based mostly on programmatic considerations and the concern of determining the thrust values more accurately. It was not obvious that the effects of this deviation in test and flight configuration received sufficient attention.","Lesson ID":179}
{"Driving Event":"There are no limit switches to prevent the ET intertank access arm from overrunning its extended position should the hydraulics system fail or the snubbers not stop the arm during extension. The mechanical snubbers were not meant to absorb the loads available from the hydraulic system or, more significantly, from the momentum of the arm. This could damage the external tank.","Lesson ID":186}
{"Driving Event":"The ET vent line may not be secured because the deceleration unit latch mechanism fails to latch. This mechanical malfunction of the latching mechanism, possibly resulting from exposure to exhaust blast from the vehicle could cause the ET vent line to rebound and strike the vehicle.","Lesson ID":187}
{"Driving Event":"The use of truss segments, which are preintegrated with distributed systems and verified on the ground instead of erected on-orbit, has reduced technical risk and made the space station a more viable program. The preintegrated truss members (PIT) must be heavier than the original truss elements per running foot because the entire mass of the PIT is subjected to launch loads. PIT members are aluminum I-beams bolted together instead of the more flexible graphite composite elements that previously were part of the design. The heavier construction allows orbit replaceable units (ORUS) to be located in their optimum positions for accessibility. One benefit of the restructured design is that EVA time has been reduced considerably so that EVA targets are now feasible. This has been accomplished by reducing the demand for EVAs and increasing the efficiency of those that must be performed. In the assembly of the PIT sections on-orbit, a capture latch provides final alignment by engaging guide pins after the sections are brought into proximity by the space shuttle remote manipulator arm. Motorized bolts then make the final latch-up. There is a chance that these sections may not line up correctly; therefore, damage may occur to the guide pins and bolts when the motorized bolts engage. Because the PIT sections will be assembled on the ground, the opportunity exists to test the alignment and mating procedures prior to flight.","Lesson ID":191}
{"Driving Event":"The effects of an adverse environmental condition, specifically, unusually cold weather, are not sufficiently well understood. The amount of ice formed by leaving valves open to prevent freezing inside water pipes was greater than expected. After the STS 51-L launch, photographic documentation revealed that ice released from the pad structures after engine ignition translated further toward the vehicle than predicted. The performance of some complex 39B systems was marginal due to the cold. The number of cameras that failed to operate at liftoff was three times that of the historical average. Instrumentation and analytical models were not adequate to define the unusually cold operating environment in which the launch was conducted. Additionally, the effects of such temperatures on the components of a space shuttle standing on the pad have not been sufficiently determined.","Lesson ID":198}
{"Driving Event":"The full-scale ASRM propellant manufacturing facility may not be directly scaleable from the continuous mix pilot plant. Particular problem areas relate to the particle size of the propellant and the screw pump section of the rotofeed. Many parameters and processes for the new facility have not been fully determined. However, another manufacturer has produced a substantial amount of similar solid propellant using continuous production processes, so the basic techniques are familiar. Safety devices are installed on the propellant flow line to limit the spread of fire in case of an accident. The flow line transporting the uncured propellant has several firebreaks to prevent propagation of a fire along the tube. The basic safety device is an explosive-fired guillotine valve that interrupts the flow, with a water spray on the propellant to lower the temperature below the ignition point. In addition, there is a collar in the flow line upstream of the guillotine and on the casting pit side of a firewall that can be blown to allow the propellant to flow out on the floor and prevent pressure buildup. A matter that must be considered is cleanup after an accident involving a dump of uncured propellant on the floor. The continuous mix pilot plant at manufacturer provides a way of proving a new propellant and upgrading the equipment before establishing a full-scale facility at yellow creek. The major differences between the pilot plant and the full-scale facility are equipment size and process control software. The pilot plant production rate is 1,000 to 1,400 pounds\/hour with the full-scale facility producing 20,000 to 26,000 pounds\/hour. The ultimate particle size of the propellant is dependent on parameters such as geometry of piping, length of lines, and fluid working pressures that may not be directly scaleable. There are many challenges such as metering of propellant solids, pre-mix of iron oxide and aluminum, and real-time process control. Upscaling the rotofeed dearator and pump equipment probably presents the greatest challenge.","Lesson ID":201}
{"Driving Event":"The present method of annual calibration of fuel and oxidizer storage area relief valves involves removal of the valves, thus opening the tank to the atmosphere. Large amounts of toxic vapor may be released. During one operation for the N2O4 storage tank relief valve, a greater than expected quantity of N2O4 vapor released (28 gallons compared to the one gallon expected). The extensive dispersion of the vapor cloud exceeded the predesignated clear area of 700 ft. Downwind. Also, several personnel were exposed to the vapor due to unrelated circumstances.","Lesson ID":146}
{"Driving Event":"The SSME vertical installer is used to position the engine for mounting on or removal from the orbiter. During SSME vertical installer operations, it was discovered that the air piston had a scored land ring. This scoring was due to the end of the stop groove being peened over. This peened condition happened when the stops came into hard contact with the end of the grooves. This condition occurs when the piston sticks in the cylinder due to a lack of lubrication and\/or foreign material in the cylinder. Pressure then builds up until the piston breaks free. When the piston breaks free it can travel to the stops with enough momentum to cause this peening condition. A failure of the vertical installer caused by this scoring\/peening could prevent positive control over the SSME and lead to unexpected movement during the installation\/removal process.","Lesson ID":149}
{"Driving Event":"The throat plug and purge adapter assembly, located in the reaction control system (RCS) primary thruster, provides the means for sealing the RCS primary engine throat during activation, decontamination, and purging. The assembly consists of a tubular structure terminating in an expandable seal, which is inserted through the nozzle skirt. The plug is hand operable from the opposite end and expands the seal to a diameter larger than the nozzle throat, providing a positive mechanical interference to preclude blow-out. The plug end gasket is removable to permit inspection for cleanliness or deterioration. The assembly also includes a passage for ducting purge fluid during deactivating and purging to a toxic vapor disposal system. Improperly grounding or a lack of grounding may cause static electricity build-up and electrical sparks which could act as an ignition source for any flammable vapors present.","Lesson ID":151}
{"Driving Event":"The OPF platform 13 tip extension could potentially roll off the end of its track into the payload bay or onto the floor of the OPF. Lock pins must be removed when extending platform 13 and re-inserted prior to use. Personnel are currently aware that the platform will not stop automatically on rollout.","Lesson ID":155}
{"Driving Event":"Non-collapsible handrails are in place on the OPF buckets. When the OPF bucket (platform) is raised to the full up position, the hand rails stress, creating the potential for structural failure. The handrails must meet a 200 pound load requirement in any direction, collapse to prevent system damage (approximately 100 pounds), and must be contained so as not to fall into the orbiter P\/L bay.","Lesson ID":164}
{"Driving Event":"The orbiter heat shield must be lifted through the rear of the swing platforms on platform 10 (coordinate X0=17.37, Y0=20.00). A structural diagonal is in the way and could damage the heat shield. As an interim control, OMI V5043 includes a caution note when moving the heat shield. Until the diagonal brace is repositioned or removed, personnel must use extra caution not to contact the heat shield with the diagonal brace during heat shield movement.","Lesson ID":165}
{"Driving Event":"OSHA requirements for handrails, kickplate, and ladders are not met. Platforms inside the tail service mast (TSM) do not have handrails to prevent personnel from falling from platforms. Kickplates are not placed on platforms with a height of four inches. Rungs on the access ladders are not evenly spaced at twelve inches as required by OSHA.","Lesson ID":171}
{"Driving Event":"A case dimensional change study performed as part of the 51-L failure analysis effort produced the diameter change results. The potential cause for this phenomenon is believed to be material related in three areas and their direct effect on the hydrostatic proof test pressure level chosen for acceptance testing prior to reuse.","Lesson ID":180}
{"Driving Event":"Launch complex 39B demonstrated satisfactory capability during the STS 51-L launch, with a few exceptions. It was anticipated that the initial shuttle launch from LC 39B would uncover minor problems, and some discrepancies between the Pad A and Pad B systems. Damaged or loosened items due to the launch have been identified as candidates for additional pad \"hardening\" and other mechanical\/electrical systems had minor operating differences than those on LC 39A. A freeze plan was first used during STS 51-L, which allowed vehicle operations to safely continue at below freezing temperatures. The freeze plan was successful in that vehicle operations continued but the resulting build-up in ice is not considered desirable for future operations. A water systems protection plan, to eliminate the necessity of continuously running water through pipes in very cold weather to prevent freezing inside, is being studied. If operations below freezing temperatures are essential, water system modifications will be required.","Lesson ID":190}
{"Driving Event":"Photoanalysis of the STS-28 (OV-102, Columbia) flight showed larger body flap deflections than were calculated. The flaps are in a turbulent flow field, which creates a hinge moment spectrum greater than that used in the structural fatigue analysis. The loads are all within the structural limits, but the fatigue analysis shows a reduction of allowable flights from 100 to 77. After the higher hinge moments were observed, additional ground tests were conducted using recalibrated strain gages on the body flap actuator as well as additional instrumentation on the rotors and stators. Three types of loads were applied. It was discovered that an additional load path existed back through the driving gear to the supporting structure. The original equations assumed only four load paths at the actuators. With a fifth load path, it is necessary to develop a new set of equations. It also was discovered that the actuators were more flexible than originally assumed and that the OV-102 (Columbia) actuators were more flexible than those on OV-103 (Discovery) and OV-104 (Atlantis). This is attributable to increased tooth width on the OV-103 and OV-104 actuators. Additional tests are planned to further evaluate the body flap structure.","Lesson ID":192}
{"Driving Event":"The space shuttle system presently includes an autoland system that provides automated guidance capable of navigating the orbiter to the selected landing runway. The increased duration of space shuttle flights as part of the extended duration orbiter program (EDO) has raised the issue of the need to qualify the existing system during actual flights. It also raises the issue of the possible need to fully automate all landing, rollout, and braking functions so that the orbiter could be returned safely from orbit without any crew intervention, if necessary. The existing automated approach guidance system never has been fully flight tested. The second space shuttle flight, STS-2, left the auto mode engaged until the latter part of the team region and demonstrated that the system was capable of returning the vehicle to a flyable energy state from a low energy state. STS-3 left the system in auto until the commander's scheduled takeover at 125 feet. The system was on energy and trajectory at takeover, but the pilot had difficulty getting \"into the loop,\" and an uncomfortable situation developed. The final several thousand feet of the shuttle's descent involves relatively complex flare maneuvers with which a pilot might be expected to have difficulty when retaking command.","Lesson ID":194}
{"Driving Event":"The practice of cannibalization has almost become a standard procedure during orbiter processing due to insufficient spare parts. This causes a significant increase in the overall processing effort. The removal of a needed LRU from the orbiter being cannibalized is an unplanned activity. A second activity, installing the removed LRU in the receiving orbiter, has usually been allowed for in the overall contingency planning; but the process flow time is impacted because it takes longer to cannibalize a part than to retrieve one from storage. When a LRU is obtained and reinstalled in the cannibalized orbiter, it must be retested. The replacement of the removed LRU and its retest are added work. Also, the increase in activity required for the unscheduled removal\/replacement always increases the potential for damage. The follow-on tests that are performed to verify that no damage occurred are another unplanned addition to the workload. Three hundred parts were required during the launch processing of challenger for the STS 51-L mission. Of these, 45 were cannibalized from OV-103. In future decisions on whether to use a spare LRU or cannibalize, the use of a spare, when available, should be considered the first choice. Overall, cannibalization is an inefficient way to process an orbiter.","Lesson ID":197}
{"Driving Event":"The FRR process which leads to the launch decision is a part of a total management system comprised of many reviews. The chain of events which culminated in the STS 51-L accident indicates that the management process applied to critical flight safety issues was inadequate. The basic engineering understanding of the SRB field joint and the effects of operating at low temperatures was lacking. Prior qualification testing and analyses were not adequate to support SRB use in temperature ranges forecasted for the STS 51-L launch. The management tools, including the critical items list, did not adequately protect against the possibility of a fatal mishap. The launch decision followed established directives, but the engineering knowledge base supporting the launch decision was inadequate.","Lesson ID":199}
{"Driving Event":"The environmental control system (ECS) pressure distribution unit pre-operations set-up requires several flexhose connections and leak checks prior to operation. Pressure lines could be misconnected and result in damage to flight hardware or injury to personnel.","Lesson ID":131}
{"Driving Event":"The QD\/filter assemblies are designed to provide a disconnected interface and remove all solid particles from the servicing fluids, which exceed 25 microns in size. The system supports the required operating pressures, contaminant capacities and rated flows. A scupper to support the pod has not been provided for Dryden Flight Research Center. This mishap was caused by a worn or deformed stop pin in the pod latching mechanism. The worn pin allows the latching dog to rotate past the mate position to the demate position. Failure has occurred on several occasions.","Lesson ID":132}
{"Driving Event":"The orbiter PRSD system provides GH2\/GO2 for fuel cell operation. The PRSD H2 T-0 umbilical vent is installed to support controlled venting of the PRSD H2 system during convoy operations. The umbilical vent is connected to the backpressure relief panel by flexhoses. Pressure must be maintained on the PRSD manifold during fuel cell cool down until vent stack and condenser exit temperatures are within 15 degrees Fahrenheit of ambient. Fixed hydrogen leak detection sensors monitor the fuel cell servicing\/deservicing system areas for H2 leaks which could result in damage to vehicle\/facility or personnel injury.","Lesson ID":134}
{"Driving Event":"During bleed down of the 125 psi air system, a process which lasts less than one minute, the noise level at the Pad B gaseous oxygen (GOX) vent arm air receiver outlet vent exceeds permissible OSHA noise exposure limits. A noise hazard survey conducted during the bleed down operation was performed on the air system to determine the noise level near the operator's ear. This survey recorded a noise level of 126.5 DBA. OSHA 1910.95, occupational noise exposure, limits noise exposure for fifteen minutes or less to 115 DBA. A possibility exists for personnel permanent hearing loss.","Lesson ID":138}
{"Driving Event":"The 540A industrial oxygen analyzer continuously monitors the oxygen content from samples of atmosphere. Monitored areas include the orbiter processing facility, vertical assembly building, mobile launch platform, and the pads. When the oxygen level in these areas drops to an unsafe level of 19.5% or less, an audible\/visible alarm is activated to warn personnel to evacuate the area. The oxygen analyzer has a sensing circuit which relays data to a supervisory box assembly which triggers the battery box assembly if an oxygen deficiency is detected. The battery box assembly supplies power to the warning beacon and sends a read out to the complex center console C-2 (in the launch control center). A component failure within the oxygen analyzer due to fatigue\/shorting may cause an erroneous high output signal when the oxygen level is below 19.5%, resulting in no alarm warning. Personnel may enter\/work in the area, unaware of the low oxygen level, and become asphyxiated.","Lesson ID":142}
{"Driving Event":"The 175-ton and two 250-ton VAB cranes are used to perform solid rocket booster (SRB) stacking, external tank (ET)\/SRB mate, and orbiter\/ET mate. The 250-ton and 175-ton cranes operate on crane rails 466 feet and 168 feet above the VAB floor, respectively. Crane motions are controlled from the console of the crane cab. The cab is equipped with four master switches which control movement of main and auxiliary hoist load blocks and trolley and bridge travel. The main and auxiliary hoist and trolley and bridge drives are redundant configurations utilizing motor-generator sets that supply energy to the DC final drive motors.","Lesson ID":135}
{"Driving Event":"The PCT is designed to operate between\/within space shuttle payload processing facilities. Two transporters are used to carry the payload canisters and hardware throughout kennedy space center. Drive power is provided by a 400-horsepower diesel engine. A ground reel clip is used during fuel transfer operations to establish a common ground between the diesel supply tank and the vehicle to be filled. Fueling operations are prohibited during electrical storms within five miles of the transfer site. Flame or spark producing devices, such as matches, lighters, or smoking, are also prohibited in this area.","Lesson ID":136}
{"Driving Event":"The 10-ton crane at the RTGF is used to lift and position radioisotope thermoelectric generators and ground support equipment. Crane electrical component failure increases the risk of load and\/or crane damage. Failure of switches 3 or 4 results in bridge movement and bridge brake will not engage if a BR-1 relay failure occurs. Failure of switches 5 or 6 results in trolley movement and trolley brake will not engage if a BR-2 relay failure occurs. Failure of switches 7 or 8 results in hoist movement and hoist brake will not engage if a BR-3 OR BR-4 relay failure occurs. Failure of switch SW-2 in the fast speed position will result in the hoist operating in the fast speed even if the operator selects slow speed.","Lesson ID":141}
{"Driving Event":"The units contain a vacuum pump driven by 1\/2 HP electric motor, a shutoff valve, a vacuum break valve and an oil trap tank. The -1 and -2 units consist of GFE previously used on the apollo program and modified by the addition of quick disconnect couplings, a vacuum read-out gage, and fluid hoses. Also, replacement of components not compatible with the fuel cell coolant FC-40 and electrical system modifications have been made to meet shuttle program use requirements. The pump has provision for oil separation; however, if the system's volume is sufficiently large, oil vapor may be sucked from the pump into the system.","Lesson ID":130}
{"Driving Event":"The 4-ton monorail crane is used to handle flight related equipment and flight hardware in the operations and checkout building. The crane operator is not able to control the load or terminate all power in an emergency situation because the 4-ton crane lacks required safety devices. The crane operator does not have direct access to the main circuit breaker in the event of crane speed control system failure or other hoisting failure. By removing power to the crane, the crane brakes are set and all system movement is halted.","Lesson ID":137}
{"Driving Event":"The vacuum servicing units provide the capability to evacuate the PRSD tanks and the relief line. The unit consists of a skid mounted frame, electrical and fluid control panels and an electric motor driven vacuum pump. If the vacuum servicing unit is left connected to the suction line, inadvertent opening of manual valve A81992 could subject the pump to 935 psig from the cryo valve panel. This is beyond the unit's capability and could expel pump oil through the vent system.","Lesson ID":129}
{"Driving Event":"Return and supply flexhoses are connected between the ground coolant boom and the LH2 check-out umbilical carrier plate. Because the hoses are too long for such a short connection area, hose kinking occurs. This situation can cause damage to the orbiter avionics systems due to overheating because of loss of freon cooling.","Lesson ID":133}
{"Driving Event":"During and after landing, there are no means aboard the space shuttle orbiter for detection of hazardous gases. A hazardous gas sensing capability internal to orbiter compartments does not exist until the T-0 hookup; then only limited capabilities exist. After landing, a sampling crew approaches the orbiter to check the orbiter's exterior for the presence of toxic\/flammable gases and\/or leaks. Hazardous gases may cause a major problem prior to or during the time the sampling crew performs its checks.","Lesson ID":139}
{"Driving Event":"Solid rocket motor (SRM)\/orbiter processing and stacking requires personnel to perform tasks under suspended loads, increasing risk of injury\/loss of personnel or flight hardware. personnel work under a suspended static load while processing SRM's and while the orbiter is in the vertical position to remove landing gear pins. An engine\/turbo pump change requires personnel to work under the main engine area. Personnel work under a suspended load when the orbiter is mated\/demated to the shuttle carrier aircraft to remove\/install landing gear pins and during installation\/removal of the orbiter's maneuvering system pod.","Lesson ID":140}
{"Driving Event":"The ESP and ECP are designed to support maintenance and replacement of space shuttle main engines (SSME's) while the orbiter is in a vertical position. Both platforms utilize the same hoisting system, located on level B of the mobile launch platform (MLP). A combination of four hoists raise and lower the platforms through the SSME exhaust hole. The platforms are secured to the MLP prior to SSME maintenance\/installation. A design certification review was performed on the platforms. The review identified three non-compliances to design standards as givin by KSC-STD-Z-0002B, standard for design requirments for lifting and hoisting equipment. These are (1) no emergency stop switch, (2) no final upper limit switch, and (3) only one holding brake. However, the upper limit switch was shown to be impractical due to varying heights of the platforms, proximity of the platforms to the tail service mast, and independent operation of the winches. A failure in the hoisting system during raising\/lowering could cause the platform to tip, resulting in damage\/loss of a SSME, ground support equipment, or MLP.","Lesson ID":143}
{"Driving Event":"The Hopkins University Telescope (HUT) experiment was being aligned in the operations and check-out building using a bright light that had been obtained from technicolor government services. After approximately two hours of use without incident, the light bulb shattered, with pieces falling into the HUT experiment, causing contamination. Alignment of the HUT was not a scheduled activity at KSC. Therefore a light source was not furnished with the experiment. Data recorded at KSC indicated that the HUT was not aligned to the cruciform as expected and that a light source would be required.","Lesson ID":68}
{"Driving Event":"During routine operation of the portable purge unit (PPU), the 480 volt power cable connectors exploded and melted, causing the unit to shut down. The explosion was caused when the connectors' overheated multi-point contact band caused the solder to melt, destroying the connectors' Integrity. It is confirmed that the force of the explosion could seriously injure or kill personnel within a 50' radius.","Lesson ID":70}
{"Driving Event":"During preparation for LH2 flow test at the LETF, a section of line was inadvertently over-pressurized, resulting in a protective cap being blown approximately 350 feet away. Post- mishap troubleshooting disclosed that the hazardous GN2 purge orifice at valve A89406 was blocked by corrosion and foreign contamination.","Lesson ID":79}
{"Driving Event":"During detensioning operations of a holddown post, while pressure of approximately 8K to 10K lbs was being applied, a loud \"bang\" was heard. Pressure on the tensioner fell to zero. It was later determined that the loud \"bang\" was the result of thread failure between the puller bar socket and the SRB holddown stud. With only 8 threads engaged, the shear stresses increased to 96,000 psi, as compared to 98,000 psi shear strength of the stud. Examination of the holddown stud revealed that 8 threads sheared on a 135 degree circumferential segment of the holddown stud.","Lesson ID":80}
{"Driving Event":"Personnel in SCAPE are required to have portable backup communications. GP-1098 requires using the buddy system. Also, in the event of loss of RF communications, two people must be designated to observe each other's safety when in a dangerous situation. The system requires a visual contact and a proximity that allows each buddy to help the other in an emergency. When and if communications are lost, the operation shall be terminated immediately and will not resume until communications are restored.","Lesson ID":90}
{"Driving Event":"During rotation of the L\/H OMS pod (LP04) an O2 meter was heard rolling inside the pod. The pod was being raised to a vertical position per V5016. Also a \"light thud\" was heard during the lift. The lift was stopped but it was determined that it would be difficult to remove the meter while it was in this position. The pod was lifted to the vertical position and then the meter was removed.","Lesson ID":97}
{"Driving Event":"Performing work on S70-0613-00-001-0120 to change improperly sized flex hose restraints. When attempting removal of flex hose, gaseous nitrogen was released due to a partially opened valve in the system. Isolation valve A102736 on the F70-0014 panel was closed to stop the gaseous nitrogen flow to the flex hose. The gaseous nitrogen contained small quantities of N2H4 vapors. The work authorizing document did not contain instructions or work stops to verify that there was no pressure on the flex hose.","Lesson ID":104}
{"Driving Event":"During orbiter lift to vertical in the vab transfer isle between high Bays 1 and 2, the right hand OMS engine nozzle cover fell approximately 15 feet to the floor. The cover suffered enough damage to prevent it from being reinstalled. The cover was found to have three holding clamps that were probably defective on installation at the OPF. The left hand cover was inspected and several loose clamps were found and were tightened. Safety gave the ok to continue the lift without the cover.","Lesson ID":105}
{"Driving Event":"The 8 inch T-0 flexhose connects the tail service mast (TSM) with the LH2 carrier plate. Due to mechanical design the interface connection is very poor. The LO2 interface is identical and has experienced leakage in the past. Undetected leakage could cause a major fire resulting loss of life or vehicle.","Lesson ID":107}
{"Driving Event":"The LH2 system maintenance includes a monthly vacuum reading in the annulus space in the overhead vacuum-jacketed (VJ) high point bleed and LH2 fill lines. Access to the read-out ports in the GH2 fill line on side 1 of the MLPS is precarious. There are not adequate tie-off points for body harness and lanyards. The readout ports are 10-12 feet above the floor grating. If a technician uses a ladder for access, or climbs on existing structures to make the reading, he\/she is within inches of exterior handrails and above them. This places him\/her about 40 feet above the vab floor or the pad surface.","Lesson ID":110}
{"Driving Event":"Immediately after becoming airborne at the SLF, the pilot of a KSC NASA helicopter noticed a failure in the No.1 hydraulic system (which supports helicopter flight controls). The loss of this system is an emergency. An inspection was conducted on the hydraulic system which revealed the line was approx. 0.5 inches shorter than required for optimal operation. Due to the curvature of the line passing through the spacer block, the line was not seated flush in its hole. The spacer block, with rotor vibration, caused the hydraulic line to experience strand separation, resulting in a puncture.","Lesson ID":117}
{"Driving Event":"Task leader started hoisting operation with a \"slow micro\" command to take up sling slack until 337 lbs was obtained. A joystick controls hoist movement which may be controlled at a low rate, but only by operator judgement. A switch energizes the hoist motor and disengages the brakes when depressed. If the joystick is in the null position when the button is depressed, load movement will occur with speed dependent on stick position when the brake is released. An overload at 900 lbs in the IPS resulted when \"slow micro\" was requested and the brake button was depressed with the joystick not in the null position.","Lesson ID":122}
{"Driving Event":"The payload bay duct heater adds measured quantities of heat independently to each duct system. This raises the temperature of the process air from the cooling coils to the desired interface temperature leaving the portable purge unit and engine control system room. With no overtemp switches installed, excessive heat from the payload bay duct heaters burned through the duct insulation, causing severe damage with a potential for orbiter damage.","Lesson ID":124}
{"Driving Event":"During the removal of the flight reaction control system (RCS) ferry plugs from the orbiter, between 1\/4 and 3\/4 cup of monomethylhydrazine (MMH) fuel spilled from the thruster. The liquid contacted the gloves and right shoe of the technician pulling the plug. The RCS thruster valve seals have a history of sensitivity to temperatures below 60 deg F. To limit the potential for leakage, the RCS thruster heater power unit should remain on throughout the Dryden Flight Research Facility (DFRF) safing and ferry period, including flight stopovers and KSC offload.","Lesson ID":59}
{"Driving Event":"On November 8, 1985, the forward center segment of a solid rocket motor (SRM) was damaged during forward handling ring removal operations. During the operation leading to this incident, the crane operator was attempting to raise the hook until a load of 11,000 pounds was attained, but the load cell read zero until the segmented ring fractured and the crane was stopped. The load cell system was provided with the crane, but the requirement for its usage is not clear. Loadcell usage is not mentioned in the crane OMRSD nor is it mentioned in the system assurance analysis (SAA).","Lesson ID":61}
{"Driving Event":"A thermal protection system (TPS) technician had an access platform retracted and secured to gain access to the top side of OV-102 left wing. Upon completion of his work, he attempted to extend the platform back to its normal (closed) position. When the platform was approx. Six to eight inches from being in place, the rivets on the hinge failed causing the platform to fall on the orbiter. All hinge platform mounts need to be secured by welds or bolts and lock washers. The present practice of securing the hinge mounts with pop rivets is not adequate to support these platforms.","Lesson ID":67}
{"Driving Event":"Employees were checking for correct phase rotation on cross-hinds AC receptacle. One employee attempted to manually twist a receptacle with a screwdriver. During this action the receptacle faulted either phase to phase or phase to ground. This electrical fault caused an arc flash burn to both employees' eyes.","Lesson ID":69}
{"Driving Event":"Materials were being pulled for issue at the logistics facility using a fork-lift crown manaboard. The operator had already made several issues and was in the process of returning materials to their location. He was looking at the location of his next issue and when he looked up the manaboard was heading for the racks. He immediately hit the brakes but it was too late, the fork-lift hit the shelving support structure and damaged it.","Lesson ID":71}
{"Driving Event":"While dynatube leak checks were completed, manifolds were vented to ambient pressure. This allowed thrusters to leak. After the third flow, engineer positioned ullage valve (V4) to closed, this caused a pressure spike that ruptured the valve burst disk. The engineer was unaware of the failure, which was found during subsequent testing and data review.","Lesson ID":82}
{"Driving Event":"The portable purge units are lifted on and off the MLP. The existing lifting sling design induces stress into the unit's operating components and overstresses the unit's lift points. Cracks are present on the lifting lug plates and elongation of the lifting lug holes has occurred. Failure of these components could result in damage to ground support equipment (GSE).","Lesson ID":85}
{"Driving Event":"During launch and ascent, ice from the ET, SRBs, and orbiter may be dislodged by ignition vibroacoustic or aerodynamic forces and impact the orbiter windows or thermal protection system (TPS) with sufficient force to dislodge TPS or damage windows.","Lesson ID":89}
{"Driving Event":"An access panel located at the aft end of the orbiter just right of the rudder, broke loose from its attaching hardware and the contamination air plenum. The access panel fell and hit the orbiter maneuvering system (OMS) pod handling fixture below. The access panel did not touch the vehicle or the OMS pod. OMS pod removal operations were in progress when the door fell. The door started working loose approximately three weeks prior to the incident, and a trouble call was made. Blue tape was found on the door edges except for the hinged side.","Lesson ID":93}
{"Driving Event":"An APU hydrazine isolation valve assembly was removed and sent to the shipping section of logistics without being properly packaged for safe handling. In addition, there was no Q.A. check sheet and no decontamination tags with safety buy-off as being sniffed at zero parts per million. There was a conditional decontamination tag with the part indicating that it was from a fuel system, and conditionally decontaminated but absorbed or trapped fuel could out-gas. The OPF was called for safety and technical support to come and check out the valve; the valve tested positive for hydrazine and was immediately safed.","Lesson ID":99}
{"Driving Event":"Two employees received caustic electrolyte exposure of hands during removal of two batteries from containers for installation in the ET. Installation was to support OMI S0008. Immediate cleanup procedures were initiated and area cordoned off. Personnel contamination was neutralized and employees reported to medical facility for evaluation. Batteries were relocated to the battery lab. Batteries are of a new design still under qualification testing. Four batteries had been activated, two were installed on the SRB's, the two ET batteries were maintained at ambient temperatures until the time of the incident.","Lesson ID":100}
{"Driving Event":"A vacuum pump isolation valve burst at the Pad B high pressure gas storage battery. The cause of the incident has been attributed to the seepage of pressure from the wheel valves after they were turned off as part of a safing operation. The wheel valve o-ring does not always seat properly. Normally this would not affect the remainder of the system, the seepage pressure would be confined. However, when the vacuum pump was connected to the system, the seepage pressure (1500 psi) was greater than the design capacity of the vacuum pump isolation valve and thus overpressurization occurred.","Lesson ID":102}
{"Driving Event":"The SSME vertical installer is used to position the engine for installation and removal. Failure of this equipment to maintain positive control could lead to unexpected movement. During visual inspection of the air piston and bore of the vertical installer, it was discovered that the air piston had a scored landring. This condition occurs when the piston sticks in the cylinder (due to lack of lubrication and\/or foreign material in the cylinder). Pressure then builds up until the piston breaks free. When the piston breaks free it can travel to the stops with enough momentum to cause sudden uncontrolled movement of the engine.","Lesson ID":113}
{"Driving Event":"On July 13, 1988, hydrazine was being transferred from partially filled drums into LT-44. There were seven drums for a total of 343 gallons. Adding the 134 gallons in LT-44 resulted in 477 gallons - well within the tank's 500 gallon capacity. As the hydrazine was being transferred from the last drum, a mechanic saw liquid spray from the vent hose and immediately closed the vent and fill valves. After securing the area, mechanics reported that all the flags at the top half of the LLI indicated the tanker was full. This suggested the magnetic liquid level gauge's reliability is questionable due to erratic operations.","Lesson ID":120}
{"Driving Event":"During the retraction of the orbiter protection system \"Y\" curtain wall in the console mode, the speed attained after leaving the slow travel transition is excessive. The operator must manipulate a manual valve to reduce air flow to the winch. High impact stops from the rapid movement of the \"Y\" curtain wall during retraction may cause personnel injury and\/or damage to payloads and facility (PAD).","Lesson ID":127}
{"Driving Event":"During the cerachrome insulation baking process of three injector\/chamber assemblies, severe oxidation of the assemblies was observed. The required baking temperature, per MTS 1324, is 600 deg F for 48 hours. It was discovered that the oven had failed, allowing the temperature to reach an estimated 1400 deg F. A proposed design change will reduce the possibility of this happening again. The modification incorporates a direct 440 VAC cut-off initiated by series redundant over-temperature shutoff circuits, as well as, a series redundant shutoff of the temperature control.","Lesson ID":63}
{"Driving Event":"The SRB platform testing began by loading the platform with 32,000 lbs. of sand. The load was lifted off the ground with a four winch slow speed lift. After clearing the ground, a high speed lift was initiated. An observer reported that a second wrap was beginning on the drums. A slow up mode was initiated and after approximately 12 inches of travel the observer reported the drums were coming apart at the end ring welds. The platforms' \"C\" corner dropped then the \"A\" corner dropped. The platform then flipped over, broke the cables and fell to the ground.","Lesson ID":73}
{"Driving Event":"A General Contractor, was in the process of installing a hydraulic elevator at the centaur payload operations control center, (CPOCC) Phase I, Cape Canaveral Air Force Station, when a technician was electrocuted. The electrocution was caused by the victim's own failure to follow safe grounding procedures. For some unknown reason the victim failed to connect the ground wire in the machine room controller. The victim was familiar and educated to the proper safety precautions.","Lesson ID":81}
{"Driving Event":"The portable purge unit when operating, exceeds the recommended 85 DBA. Reference is made to noise hazard survey accomplished by BOC industrial hygiene. The noise level closer than a perimeter of 30 feet exceeds the allowable 85.0 DBA as established by the NASA Hearing Conservation Program. The DBA level near the unit ranges from 91.0 DBA to 99.6 DBA.","Lesson ID":83}
{"Driving Event":"OMRSD S073A.90 thru .230 requires verification of voltages, phasing, and talkbacks to the orbiter. Present talkback verification method for the payload retention latch assembly (PRLA) involves extensive \"hot\" pin jumpering during testing using a 79K07833 breakout box and test leads. Improper jumper procedure by inserting a jumper at an incorrect location could result in inadvertent shorts or cross connection of live 120 volt and 28 volt electrical lines. This improper procedure could cause PRLA electrical system damage, orbiter interface damage and\/or electrical shock\/personnel injury.","Lesson ID":87}
{"Driving Event":"During forward center segment on-load to rail car for transport to the furbishment facility, the segment began to slide out of the confines of the handling sling. Approximately 90% of the segment was suspended 10' to 15' feet above the rail car when the aft end of the segment slipped out of the sling, coming to rest on the rail car. The forward end of the segment stayed suspended approximately 10' above the rail car. No damage to the segment was noted and the rail car received only three scratches by the handling ring. The instability of the segment is due to the difficulty in determining its center of gravity.","Lesson ID":92}
{"Driving Event":"Replacement of the upper floating beam forward roller support shaft was in progress to eliminate a stress corrosion concern. The 5-ton bridge crane and a sling were being used to lift the Pad B PGHM side 2 upper floating beam Z bar off of the Z roller when a small block with two 5\/8\" bolts apparently sheared, allowing Z Bar to travel up, contacting a portion of the upper floating beam causing the web strap to be cut.","Lesson ID":96}
{"Driving Event":"A technician was performing leak checks at ports on the right side of the orbiter (OV-099) using a displacement leak detector. The tygon hose became tangled and the leak detector fell and hit the side of the vehicle damaging seven tiles. The detector was damaged when it finally hit the floor. The bay manager, safety, and the operations desk were notified of the incident, and the area was cleaned of spilled fluid & debris.","Lesson ID":98}
{"Driving Event":"An engineer was utilizing a draeger pump to perform toxic vapor checks on A\/C motor valves on the 207' level of the rotating service structure. When the engineer attempted to retrieve protective apron from the platform, the draeger pump was pulled from the platform and fell, striking the orbiter's FRCS blanket area and landing on the 193' Level.","Lesson ID":103}
{"Driving Event":"Technicians were performing radiographic inspection of the insulation area in the atlas stage thrust section utilizing a 100KV machine. The tubehead was placed inside the thrust area taped into position and exposures were made to the outside. The tape failed to hold the tubehead and it slipped down 6-8 inches hitting a threaded area on a strut. There was only visible damage to the top of 2-3 threads.","Lesson ID":106}
{"Driving Event":"During OMI V9023.F operations, the L\/H payload bay door was noticed to have a slight upward bend in it due to excessive force placed on it through the L\/H AFT PBD support jack. The aft half of the L\/H PBD was raised eight to ten inches higher than the position of the PBD forward segment. An interference problem occurs when trying to insert\/remove the \"C\" frame support hook from the support jack dowel. The interference problem requires the use of more than one technician to force the \"C\" frame support hook on and off the support jack dowel.","Lesson ID":115}
{"Driving Event":"During removal of the H2 tank from the OV-104 mid-body, a crane was used to take up the initial cable slack and transfer the load from the tank struts to the GSE lifting fixture. The move director called for a crane movement of \"up at 1 in\/sec\" and the crane controller relayed the command to the crane operator. The actual lift rate was on the order of \"up at 3 in\/sec\" and a momentary vertical load of 800 lbs was applied to the tank assembly. This load was immediately reduced and the tank bolts removed. The normal transfer load is made up of a 150 lb tank lifting fixture and a 235 lb tank weight.","Lesson ID":121}
{"Driving Event":"The H70-0743 sling assembly consists of a forward and aft spreader beam assembly connected together by a segmented stabilizing frame assembly. With the two mobile crane concept, the sling assembly is used to lift and demate the orbiter to the shuttle carrier aircraft. At the contingency landing site, the two mobile crane concept is used with a 800-ton T-C 4000 truck crane for the aft lift and a 250-ton link belt for the forward lift. Visual observation must be maintained at all times during hoisting operations due to extremely limited clearances between the orbiter and facilities.","Lesson ID":123}
{"Driving Event":"The LH2 vent system valves are located in the flare stack area of Pads A and B. The valve control handles are elevated between 8 and 10 feet above ground. Operational personnel are frequently required to climb up on the 12\", 14\", and 18\" vent lines to operate the valves. The use of safety belts\/harnesses is not practical in this situation since the tether-off point is not available. Also, use of a pipe as a work platform is not in keeping with good safety practice.","Lesson ID":112}
{"Driving Event":"During air-arcing operations under mobile launch platform-1 (MLP), a welder smelled smoke through the hole he was working on and found a fire in the floor insulation of compartment 16B. Investigation revealed that air-arcing under MLP-1 ignited hydraulic fluid that had accumulated in the floor insulation of compartment 16B. Hydraulic pumping units leaked hydraulic fluid onto the insulation for several years. Hot particles released by air-arcing blew into compartment 16B as the welder penetrated the MLP bottom panel, and the fluid ignited.","Lesson ID":118}
{"Driving Event":"On September 25, 1987, The solid rocket motor (SRM) aft segment was being mated to the aft segment handling ring in the H77-0386 stand. The SRM segment and handling ring assembly was hoisted from the stand and moved to the breakover beam. The handling ring was mated to the breakover beam and the SRM segment was tilted to the horizontal position and placed on the rail car. At this time it was noticed that a total of six bolts were missing from the SRM end-ring assembly. It is unknown when or who removed the bolts.","Lesson ID":119}
{"Driving Event":"While an employee was climbing out onto a steel beam to inspect debris nets on the 16th level of the VAB, a beam clamp attached to the employee's belt struck a beam and fell 16 floors to the transfer isle of the VAB. The clamp fell near personnel in the transfer isle. The clamp was not properly tethered. Continuing emphasis is required to ensure that personnel are knowledgeable of and comply with tethering requirements.","Lesson ID":58}
{"Driving Event":"After the towing convoy turned off the runway onto the tow way, the cool tractor\/trailer suddenly stopped. The observer caused the rig to suddenly stop when his hand inadvertently came in contact with the E-STOP switch cover. This caused the boom to oscillate up and down. The boom operator lowered the boom to get maximum extension on the two coolant flex hoses attached to the orbiter. The boom's oscillation caused the flex hoses to be whipped loose before the orbiter could stop. The flex hoses fell to the ground with freon 14 spewing from them.","Lesson ID":64}
{"Driving Event":"A liquid helium dewar used to service payload experiments ruptured and damaged ceiling tiles and a copy machine. In order to service the payload experiments, the dewar converts normal liquid helium to superfluid helium. During this process, air was ingested into the vent line through a valve stem. The ingested air froze, forming a solid blockage. The failure analysis of the liquid helium dewar revealed that 4 of the 8 valves used in the system were not designed for use in vacuum systems.","Lesson ID":66}
{"Driving Event":"During debrazing operations of a purge fitting in an orbiter's aft compartment, the debrazing head separated, causing an electrical arc. This arc caused the debrazing head to heat up, which caused cracking of the debrazing head and damage to the coil and purge fittings.","Lesson ID":72}
{"Driving Event":"A technician was working on the ET access platform, attempting to close the bifold doors on the 155 foot level of Pad B. The brake released on the hoist that was holding the platform that the technician was standing on. The platform gave way and the technician fell about 15 feet. He suffered a broken left ankle and other minor bruises.","Lesson ID":74}
{"Driving Event":"Potential ignition of SRB due to possible arcing at switch or relay contacts or at circuit connections due to inadvertent connection\/misconnection, is controlled by design. Connections are connected within the intertank by electrical plugs and receptacles, which are secured by threaded sleeves. Power and return lines are not routed through adjacent pins on the same connector. The connector dielectric is rated at 1000 VRMS at 60 Hz.","Lesson ID":91}
{"Driving Event":"During removal of the purge adapter from thruster R4D, liquid MMH was observed leaking from the thruster nozzle. When the leak was discovered the OPF high bay hypergolic exhaust fans were actuated, the high bay evacuated, and fire and medical support were requested to stand by. The leaking MMH was caused by a liquid trap present in the fuel suction hose. The trap was formed by excessive hose length, which was routed to the next level above, then down to the purge adapter. The routing and hose length was left over from a previous operation on the left side of the orbiter.","Lesson ID":94}
{"Driving Event":"Technicians were in the process of extending platform 10-2 in OPF HB-1. After extending the platform about 3 feet, the observer noted that the platform would not clear the body flap and signaled a \"halt.\" Before the platform could be stopped, it contacted two tiles, damaging them.","Lesson ID":95}
{"Driving Event":"The proof load test operator installed a 3 leg sling H77-0235 in the tensile machine to proof load test a \"D\" and\/or an \"O\" ring to 72,000 lbs and 52,000 lbs. The tensile puller pump motor stopped and the operator shut down the machine immediately and discovered tensile puller over pulled the \"D\" ring, deforming it, also distorting 3 pins in the tensile puller. The \"D\" ring was distorted beyond a salvageable limit.","Lesson ID":101}
{"Driving Event":"Quick disconnects, utilized for providing gasses to the space shuttle main engine drying\/purge lines and the main propulsion system LH2 prepressurization system are identical and can be cross-connected in the OPF. The MPS heated GN2 purge panel provides heated or unheated GN2 at 645 +\/- 65 psig for engine drying. Should GN2 645 +\/- 65 psig be introduced to the GH2 prepressurization system, flight hardware damage could occur. This condition may or may not be visible on the firing room pressure gages depending upon the status of orbiter power.","Lesson ID":111}
{"Driving Event":"Three breakout boxes were located on the orbiter aft compartment entrance platform. When two technicians entered the aft compartment, these breakout boxes were knocked off of the platform, falling 7.5 feet and striking the space shuttle main engine (SSME) #1 AIR\/GN2 purge line. This fiberglass line was cracked. In addition, the SSME #1 main fuel position actuator was damaged.","Lesson ID":75}
{"Driving Event":"While performing an area walkdown, a supervisor, noticed what looked like paint chips on the pick board in the forward RCS area. After further investigation it was determined that air flowing from a nearby duct was blowing against a thermal protection system (TPS) blanket causing irreparable damage.","Lesson ID":76}
{"Driving Event":"The OPF environmental control system (ECS) supplies conditioned air through ducts to the orbiter to purge and pressurize the forward\/aft compartments and the payload bay. Over-pressurization could occur during ECS purge if the ventdoors are closed. No automatic monitoring and\/or control exists to preclude simultaneous application of ECS purge air while all orbiter vent doors are closed, or to automatically relieve excess pressure under these circumstances.","Lesson ID":84}
{"Driving Event":"The fans are located on the 107 foot level of the rotating service structure (RSS) and controlled from the computer console for ECS in the PTCR. The circuit breakers providing power to the fans are located in the hoist room on the 207 foot level of the RSS; therefore, there is no local control. When maintenance personnel are working on the fans, it is possible that someone could re-apply power to them. Also, if local switches were located immediately outside the locked fan rooms, should a problem arise with the fans that generated excessive noise, smoke, etc. They could be shut down by personnel and reduce damage.","Lesson ID":86}
{"Driving Event":"Extension of the -Y curtain wall with the -Y strut in any position except fully extended, the curtain wall could contact the STS vehicle or the RSS structure. This can result from human error or human error coupled with mechanical failure of the key-lock and interlock valves.","Lesson ID":88}
{"Driving Event":"The helium injection system introduces a controlled flow of helium into the aft end of the feedline to prevent geysers during propellant loading and holds before launch. The helium is supplied from panel S72-0697-08 through one series valve (A78410) and two parallel valves. Failure of the series valve or clogging of the downstream filter could cause loss of bubbling. Loss of helium bubbling prior to 2% full or after 98% full in the external tank (ET) could result in damage due to geysering.","Lesson ID":108}
{"Driving Event":"The A70-1289 work stands were designed for light, mobile work. During maintenance operations on space shuttle main engines (SSME) in the vertical position the stands must be split apart to clear engine ground support equipment (GSE). This reduces work stand stability and availability of work area. Pic boards are utilized to span the open areas when the work stands are in the split configuration.","Lesson ID":109}
{"Driving Event":"The memory and registers of the main engine controller digital computer unit interface must be loaded and read and must provide discrete controls and status indicators compatible with a punched tape reader and teletypewriter interface for automatic program loading. Inadequate grounding of the DCU memory loader (i.e., Ground cables not connected, connected improperly, or in deteriorated condition) could result in electric shock injury to personnel.","Lesson ID":114}
{"Driving Event":"While demating the ET from the SRB's during OMI S0033, TPS foam damage occurred on the +Y forward crossover area. Scraping noises were heard and interference was observed. The operation was stopped while a deviation to the OMI was written to allow north movement of the crane in an attempt to relieve the interference. The operation proceeded but foam damage was unavoidable due to insufficient clearance. This insufficient clearance was due to incorrect installation of support brackets caused by inaccurate OMI procedures.","Lesson ID":116}
{"Driving Event":"The portable purge unit supplies conditioned air through ducts to the orbiter to purge and\/or pressurize the payload bay's forward and aft compartments. Airflow varies between 50 lbs\/min minimum to 100 lbs\/min maximum. Vent door observers are always on station when a vent door is repositioned for a test or TPS tile\/thermal barrier work. Overpressurization may occur if all the orbiter vent doors (normally in the purge position) for a compartment are closed at one time. Control logic program VAM09 also notifies the firing room engineers if both a right hand and left hand purge vent door set is closed.","Lesson ID":125}
{"Driving Event":"Three Pad B ECS chillers condition air for the orbiter and payload changeout room. The ECS chiller GN2 control system, which regulates the amount of cooling provided by each chiller, is controlled by HIM 161 and HIM 213. The auto\/direct mode select control allows chiller GN2 control via the auto or direct mode. Normally, HIM 161 controls chiller temperature\/humidity in the automatic mode. If this mode should fail, chiller control is maintained by switching to the direct mode. If the HIM 161 direct mode fails, there is a potential for partial\/total loss of chiller GN2 control and subsequent orbiter\/payload damage.","Lesson ID":126}
{"Driving Event":"During final closeout operations of the space shuttle orbiter in High Bay 2 of the Orbiter Processing Facility (OPF), a payload bay access platform fell from its stowed position, damaging the orbiter's left payload bay door and injuring a technician. The platform's hoisting cable was previously weakened when technicians used the platform system while it was tagout\/lockout. The weakened cable continued to stretch and break, even though the technicians returned it to its stowed position.","Lesson ID":60}
{"Driving Event":"The shear mode resonant dampening (SMRD) lab is utilized to support the process of applying SMRD material to printed circuit boards. Problems were encountered with one of the ovens (blue M model POM-223) used in the SMRD application process not maintaining the set temperature. A technician sent to investigate opened the front panel to perform a visual inspection and upon closing, a mercury switch mounted close to the chassis inside the front panel arced and exploded.","Lesson ID":65}
{"Driving Event":"Following its arrival at one of the paylaod processing facilities, a payload is removed from the transporter\/container and installed in a test or assembly stand. Facility activities include propellant loading, installation of solid propellant motors, ordnance separation devices, and other explosive or hazardous items. After completing hazardous operations, the payload is transferred to the vertical processing facility and then to the payload changeout room. Leakage or spilling of toxic propellants is a real possibility during payload ground operations and may allow propellant residuals to accumulate in\/on equipment\/flight hardware.","Lesson ID":25}
{"Driving Event":"The G02 supply from the ECLSS GO2 servicing console can be utilized to feed oxygen directly into the astronauts' helmets in support of the flight crew breathing test during OMI S0017 (at T-4 minutes). The existing oxygen panel uses gaseous nitrogen as the regulator \"push\" pressure (6000 psig) to operate the ECLSS servicing console. There is a possibility of nitrogen intrusion into the oxygen feed line if a regulator failure occurs.","Lesson ID":27}
{"Driving Event":"The HVAC chilled water boost pumps are located on the 120-foot level of the rotating service structure (RSS). The start\/stop controls and circuit breakers (disconnects) providing power to the pumps are located in the motor control center at the RSS 215-foot level; therefore, there is no local control. When maintenance personnel are working on the pumps, a possibility exists that someone could re-apply power. The start\/stop controls and circuit breakers can not be locked out, physically, to prevent inadvertant actuation.","Lesson ID":32}
{"Driving Event":"The mass SPEC is used to leak check the SSME heat exchanger (HEX) coil, to evacuate the MPS fuel vacuum jacketed (VJ) lines and for external leak checks using the hand-held probe. The heat exchanger converts liquid oxygen to gaseous oxygen for pressurizing the shuttle external oxygen tank. The MPS fuel line vacuum jackets provide the insulation necessary to meet SSME pre-start pump inlet temperatures. If mass SPEC vacuum is lost for any reason (power loss or belt breakage) vacuum roughing pump oil may be sucked into the SSME heat exchanger (back-streaming) unless the hex is isolated immediately.","Lesson ID":39}
{"Driving Event":"Space shuttle system design necessitated clearance and weight constraints, which in many cases, made SSME access limited. Workarounds and temporary structures have been utilized by maintenance personnel with some success. However, there is still inadequate access to the engine area after landing for installing rain protection plugs or the ferry flight set. Injury to personnel or damage to equipment can occur as the result of actions required to perform post flight maintenance and ferry flight set installation operations.","Lesson ID":40}
{"Driving Event":"The following mishap occurred during preparation of three mighty mouse rockets (2.75\" FFAR) at the NASA Atmospheric Sciences Field Laboratory: The last step before arming the FFAR motors was to replace the activation plug on the payload. With the rocket in position in the launcher tube, the plug used during launcher loading was removed through an access hole in the side of the tube and another plug, attached by a lanyard to a pneumatic withdrawal cylinder, was inserted in the payload. While the worker was performing this lanyard insertion step, the rocket motor ignited and launched. Investigation of the mishap revealed the high probability of a sneak circuit causing the inadvertent firing of the rocket.","Lesson ID":42}
{"Driving Event":"A 65-ton mobile crane was hoisting a 40,000 pound test weight from payload canister #2 to a flatbed truck. The test weight was 8 to 10 feet above the canister doors when the boom of the crane slipped, falling toward the canister and lifting the front wheels off the ground. The test weight contacted the inside of the canister door and slid inside the canister, damaging the side of the canister. One employee sprained his right foot as a result of the mishap when he quickly jumped from the canister door to avoid being hit by the crane boom.","Lesson ID":46}
{"Driving Event":"A hypergol technician erred in the removal of a temperature transducer from a 3-inch hypergol line at the \"Pad A\" fuel farm, resulting in a major fuel spill and hypergol burns to himself. The installation design of the dry well and temperature transducer provides a means to remove the transducer from the system for replacement or calibration without having to \"open\" the fluid volume. The dry well installation design is inadequate to preclude an untrained technician or a careless technician from inadvertently removing the dry well from the hypergol propellant line by mistake.","Lesson ID":51}
{"Driving Event":"The hydraset control console is a self-contained system for the storage, metering, and regulation of compressible GN2. The pneumatic system delivers pressurized GN2 to the accumulator of the hydraset hoist control unit, which controls load movement in small increments. The source for GN2 can be either facility or k-bottle supply. The design of the hydraset remote control console is such that high GN2 pressure may be present in the flexhose between the k-bottle or facility GN2 supply and the remote control console. Disconnecting the flexhose under pressure may damage equipment and\/or injure personnel.","Lesson ID":24}
{"Driving Event":"The geography of KSC facilities does not lend itself to ease of team unity. The launch control center control rooms, from which systems engineers conduct tests, are a considerable distance from the OPF where technicians perform work on the vehicle. The remoteness of the two facilities impedes communications between engineers and technicians. As the program plans new control rooms and equipment, these new rooms could be located in the OPF between the two bays. Having the engineers in close proximity to technicians and the vehicle would improve the overall efficiency of orbiter processing.","Lesson ID":45}
{"Driving Event":"During hydrazine servicing of the left hand SRB tilt system, the fill\/drain quick disconnect (Q.D.) nipple separated during cap removal, allowing the entire 3 1\/2 gallon load to drain onto the MLP deck. The Q.D. nipple separation occurred because of nipple to cap thread seizure, caused by pressure build-up between the Q.D. and cap. Current design allows the possibility of Q.D. nipple removal while trying to remove Q.D. cap. The technician had no visual clue that the nipple was turning because of the scupper installation. The technician was drenched with hydrazine during the incident.","Lesson ID":56}
{"Driving Event":"The launch operations area fuel cell servicing system (FCSS) LH2\/GH2 system provides for the loading of LH2\/GH2 to the orbiter at pads A and B. The LH2 FCSS low pressure sample panel and the fixed service structure FCSS GN2\/GHe service panel are utilized for the helium sweep flow purge to the FCSS hydrogen vent stack. Three critical items are in the GN2\/GHE service panel and two are located in the low pressure sample panel. Failure of a critical item will disable the sweep flow purge to the vent stack, which is performed prior to initiating hydrogen steady state venting from the dewar.","Lesson ID":26}
{"Driving Event":"After the shuttle carrier aircraft\/orbiter reaches its park position within the mate\/demate device, the side access platforms, which parallel the major part of the orbiter fuselage, are lowered into service position to demate the orbiter. Flip down platforms are extended from the side access platforms to allow personnel to reach the 50-1\/50-2 doors. ropes are used to lower the platforms to the orbiter and technicians have minimal control of the speed at which the platforms are lowered. A potential exists for a loss of platform control and subsequent orbiter damage\/personnel injury.","Lesson ID":29}
{"Driving Event":"Post launch checkout and semi-annual GOX vent arm maintenance requires technicians to service the GOX vent arm upper hinge and associated flexhoses. The GOX vent arm upper hinge cover panel must be removed to gain access to the hinge for inspection and maintenance. Once the hinge cover panel is removed, it must be maneuvered past the upper hinge support structure. The configuration requires technicians to perform this task at unprotected heights. Because there are no work platforms or approved tie-off points where a safety lanyard\/harness can be attached, technicians are at risk of a 255-foot fall.","Lesson ID":31}
{"Driving Event":"The main propulsion system's (MPS) LH2 system operations include the transfer of LH2 from the pad storage tank to the orbiter and pressurization of the external tank during drain operations. A leak\/fire during cryogenic loading or draining operations may result in loss of vehicle and\/or life. This risk remains active until shuttle liftoff from the fixed service structure, for a flight readiness firing, or for a countdown demonstration test. LH2 leaks may occur via structure\/component failure, purge loss due to flow restriction (clogs, regulator\/valve fails closed), or flow diversion (relief valve fails open, flexhose ruptures).","Lesson ID":34}
{"Driving Event":"NASA standard initiators (NSI) are used to ignite a charge of boron potassium nitrate pellets, which begin the solid rocket booster (SRB) ignition sequence. These pellets start a pyrogen igniter and its igniter motor flame starts SRB propellent burning. NSI's can not be protected against inadvertant detonation while in excessive radio frequency fields. The electromagnetic interference may cause a premature firing of a NSI, possibly resulting in personnel injury\/loss of life and damage to flight hardware or ground support equipment.","Lesson ID":35}
{"Driving Event":"Fuel cells are connected to the orbiter power busses via a motorized switch. OMI emergency procedures for powering down fuel cells assume redundant ground power is connected to the orbiter and calls for only one disconnect sequence fuel cell 1, 2, then 3. The power to disconnect the FC is delivered through the same busses they are being disconnected from. During a multiple fc failure (i.e. FC 2 & 3) with no ground power connected, the OMI requires FC 1 to be disconnected first. Since FC 1 was the only one operating correctly and suppling the busses with power, switching it off first removed the power needed to disconnect the rest.","Lesson ID":41}
{"Driving Event":"The Firex system components at the VPF are missing numerous identification\/find number tags. These are used to identify components in procedures and work authorization documents when opening, closing and removing components is required. The lack of coordinated numbers between components and the maintenance instructions generated a confusing atmosphere and led the technicians to choose the wrong components. This action resulted in the erroneous activation of the VPF Firex water deluge system.","Lesson ID":48}
{"Driving Event":"The remote manual arming and firing valves are in the \"on\" position when perpendicular to the water lines, which is not the industry norm for hydraulic systems. This contributed to the OPF GSE technicians believing they were closing the valves by positioning them perpendicular to the water line when, in fact, they were opening the valves. This misinterpretation resulted in the activation of zones 1,2,3,4, and 5 of the bay 2 Firex deluge system.","Lesson ID":49}
{"Driving Event":"The nitrogen tetroxide (N2O4) vapor release, which occurred during a storage tank relief valve changeout, greatly exceeded the \"one gallon quantity\" specified in the task OMI V2197, sequence 03-014. Also, sequence 03-074 states, \"total amount of commodity involved: 1 gallon.\" Post incident calculations estimated the total release to have been 28 gallons. The vapor cloud of N2O4 far exceeded the 700-foot clear area called out in the OMI. Unless the magnitude of the release is accurately predicted, the downwind clear area cannot be properly established and personnel may be endangered.","Lesson ID":54}
{"Driving Event":"During the replacement of a faulty flodyne valve, a leak occurred which resulted in a spill of approximately 20 gallons of MMH. Several minutes after the spill was reported, spontaneous combustion of the MMH occurred. The fire detection system high temperature detectors (HAD's) did not activate, therefore, no automatic system activation or alarms occurred during the fire. The locations of the HAD's (roof beam mid-line, one at apex and one each half-way down on roof underside) are unlikely to detect fires occurring near the farm edges, where much of the hypergolic maintenance is performed.","Lesson ID":57}
{"Driving Event":"The payload canister consists of a canister shell and two cargo bay doors driven by air motors. The cargo bay door operations are controlled by a flow control valve with three positions (open, neutral, closed). If the door speed control valve is in the open or closed posititon and the flow valve is inadvertently moved out of neutral, the cargo bay doors will open or close. Unscheduled operation of the payload canister doors could result in personnel injury or damage to a payload or canister door.","Lesson ID":23}
{"Driving Event":"The T-0 vent support assemblies are mounted on the orbiter T-0 Interface to support controlled venting of PRSD tanks after landing. In the event of regulator diaphragm failure, GH2 or GO2 can vent to atmosphere near the orbiter through the back pressure regulators. Leaking GH2 could cause a fire or explosion. Leaking GO2 could contribute to failure of the diaphragm in the back pressure regulator of the FCSS, PRSD T-0 safing system could release GH2 in the vicinity of the orbiter.","Lesson ID":36}
{"Driving Event":"The vacuum servicing units will provide the capability to evacuate the power reactant storage and distribution (PRSD) tanks and relief line. The unit provides a place for GN2 to accumulate, and an ignition source to ignite these gases. Loss of GN2 purge to the vacuum servicing unit could result in fire or explosion leading to flight hardware damage or injury to personnel.","Lesson ID":37}
{"Driving Event":"After landing and prior to fuel cell deactivation, PRSD tank pressures normally will increase. The GH2 pressure will vent from the right side of the orbiter when pressures reach approximately 290 psi. This venting has occurred during roll-in of the orbiter to the OPF and could cause a fire if an ignition source is present.","Lesson ID":38}
{"Driving Event":"A mishap occurred when technicians did not follow the sequence of events specified in the PR disposition for assembly of the thruster and fixture. The T-shaped mounting fixture was secured with only one C-clamp to an access platform's kick plate that had vinyl tape on both sides. The C-clamp was improperly used to prevent rotation and the vinyl tape acted as a lubricant between the clamped surfaces. These conditions allowed the offset weight of the mounting fixture\/thruster assembly to overcome the clamping force and rotate about the single C-clamp and fall.","Lesson ID":43}
{"Driving Event":"Failure of relay K41 to activate or relay K44 to deactivate will disable hardwire safing panel control of both the primary and secondary extend pilot valves A101409 and A101410. The command path for the hardwire safing circuits, which controls the orbiter access arm, runs through these relays. If relay K41 fails to activate or relay K44 fails to deactivate, the OAA would not extend. If a failure occurs, the hardwire safing system would not activate the extension circuit and emergency re-extension could not be accomplished.","Lesson ID":28}
{"Driving Event":"The 1500-pound withdrawal weight for the ET LH2 vent line must be raised to access the withdrawal weight shock absorbers to perform maintenance. Personnel work directly beneath the withdrawal weight, held in place with a 125 psi air-operated winch and 5\/8\" diameter wire rope. The system design does not include a secondary means to secure the weight if the winch or wire rope fails, so workers shore the weights with pieces of wood or other available material that will brace the weights. The improperly used shoring devices could break under the load of the weights, causing injury to personnel.","Lesson ID":33}
{"Driving Event":"During servicing of the oxidizer on the forward reaction control system (FRCS), a ground half quick disconnect (QD) failed. The failure mode was such that an open flow path was created to the outside of the QD and 15 to 20 gallons of oxidizer (N2O4) flowed overboard prior to isolating the flow sources. The failure of the ground-half QD was attributed to an accumulation of iron nitrate lodged between the probe and the dynamic head. The presence of iron nitrate was traced to contaminated fuel.","Lesson ID":55}
{"Driving Event":"During installation of the orbiter GN2 tanks, the H70-0649 lifting adapter is used to raise the GN2 tank from the orbiter processing facility floor to the orbiter payload bay. The adapter is designed for the tank to sit flush in the cradle, but its configuration allows only the GN2 tank boss threads to sit on the adapter cradle. As a result, the tank boss supports the total tank load. This \"improper fit\" condition contributes to the inability to properly secure the GN2 tank during lifting operations, possibly resulting in damage to the tank, the orbiter payload bay, and\/or personnel injury.","Lesson ID":30}
{"Driving Event":"A painter in the utility annex stepped on a pipe, causing it to fracture at the interface of an attached valve. The pipe remained attached to the valve, but the leak sprayed water onto the motor control center located beneath the pipe, causing a short circuit in the switch gear and a subsequent power outage for several facilities. This power outage resulted in the suspension of test operations that were being performed on the hubble space telescope.","Lesson ID":44}
{"Driving Event":"The primary cause of the mishap was an activation (closing) of the fire pump mercoid pressure switch which prematurely started the fire pump. This produced transient pressures that exceeded the 2:1 mechanical advantage of the deluge valves, forcing them open. The switch activation was caused by potable water system pressure fluctuations external to the local facility.","Lesson ID":47}
{"Driving Event":"Premature shutdown of the main and vernier engines occurred as a result of an electrical malfunction in the vehicle's power bus, specifically a short circuit to ground. A Mishap Board investigation concluded the most probable cause of the failure was flight vibration that induced mechanical damage to wiring insulation resulting in a short to ground.","Lesson ID":50}
{"Driving Event":"The \"Call Contractor\" system utilized by the contractor MOD management has the least control of \"how\" a modification is performed. The \"Call Contractor\", utilizing \"good construction practice\", was given free reign in the method to accomplish the project. Drawings and instructions were incomplete. No formal briefings on associated hazards were held, allowing for unknown hazards to jeopardize the safety of the project and the workers. The working relationship between contractor MOD management, contractor DE, NASA DE, and the \"Call Contractor\" is not clearly defined and appears less than adequate.","Lesson ID":52}
{"Driving Event":"The primary cause of the Magellan mishap was the inadvertent mating of at least two pins of the spacecraft harness connector P2 to connector J3 of battery 1. The mismate of these connectors created an electrical short circuit within the J3 connector that resulted in electrical arcs and additional short circuits that, using the energy stored in the battery, produced damage to battery 1, connector P2, and the battery thermal blanket.","Lesson ID":53}
{"Driving Event":"After the spacecraft completed its second Earth flyby, communication signal levels received on Earth decreased and fluctuated unexpectedly. The cause was determined to be interference when the Radio Frequency (RF) radiation angle from the boresight of the Low Gain Antenna (LGA-1) to Earth exceeded 90 degrees causing the signal to pass through the High Gain Antenna tip sunshade. The tip sunshade is constructed of 9 conductive ribs and a circumferential wire supporting an RF transparent shade. Phasing of the direct signal with the signal reflected off the 9 conductive ribs of the sunshade caused multipath signal fluctuations that varied with the rotation of the spacecraft. Since the orbiter telecommunications functional requirements document stated that \"the outer portion of the tip sunshade is RF transparent,\" the LGA antenna pattern tests used a totally RF transparent tip sunshade model, and multipath interference was not detected. Additional Keyword(s): RF Performance Verification Reference(s): ISA# 2125","Lesson ID":350}
{"Driving Event":"Experience on the Soviet Space Station showed that long exposure to space radiation affects the transparency of glass and that this effect is reduced by using quartz glass coated with cerium oxide.","Lesson ID":322}
{"Driving Event":"Data indicates that there have been several deployment failures which were attributable to inadequate design.","Lesson ID":321}
{"Driving Event":"A high pressure steam valve ruptured in the basement of the building, releasing steam that damaged walls and floor tiles. The mishap was caused by dynamic loading to the line resulting from severe water hammer. Heavy rainfall preceeding the incident flooded the steam trench. The steam line enclosed with cool water set up a heat exchange process forming excessive condensate that was put into motion by the building demand. Slugs of water generated dynamic loads in the piping. The cast iron steam valve (Chapman gate valve model 59 1\/2) then ruptured.","Lesson ID":219}
{"Driving Event":"A tube trailer was being filled with oxygen with a 1000 psi differential between the trailer and supply when a flash was observed in the area of the remotely operated control valve. A subsequent rush of gas and fire followed. The fire continued for about 40 seconds and was extinguished by the onrush of gas from the ruptured stainless steel manifold lines that had been burned off. The investigating board concluded that the nylon seats in the valve had deteriorated to the extent that the ball was able to vibrate freely under the high flow conditions present. The vibration would most likely be severe while attempting to flow oxygen against a closed ball valve with missing or deteriorated seats. This would have generated sufficient energy through impact and heat to cause ignition.","Lesson ID":226}
{"Driving Event":"A new vacuum furnace was being checked out when it was inadvertently pressurized to much higher than one atmosphere of argon gas. The furnace door was held closed by 3 clamps designed to seal the door \"o\" rings while pumping a vacuum. Under pressure the door clamps failed. The door swung open, striking a person who was standing next to it. He was thrown to the floor and sustained a head injury.","Lesson ID":228}
{"Driving Event":"During winter operation of a cooling tower that was operating in a standby mode, a large section of the tower collapsed due to an unusual accretion of ice in the central portion of the tower. The dead load of the ice overloaded the structural members and caused the collapse. When the mishap occurred the tower was not running within its design parameters. Valves controlling the minimum water flow to prevent freezing and to inhibit corrosion in the heat exchangers were opened wider than usual to reduce noise because of workmen in the area. An additional pump was also turned on to maintain the required flow. The combination of the increased water flow rate and restricted flow through the pipes returning water to the tower basin created a back pressure sufficient to permit water to flow up the riser pipe and into the tower distribution system. Because the tower was in standby, with no heat load, the water and air temperatures were both low enough to cause the water to freeze. The resulting accumulation of ice created the load that led to the structural failure.","Lesson ID":231}
{"Driving Event":"A test Centaur 1-E tank, on standby, was damaged. The bulkhead between the liquid hydrogen tank and the liquid oxygen tank failed due to a series of events. Air services to the building were shut down for repairs so that the facility switched to an emergency nitrogen supply. Failure to switch back to service air when it became available, led to the mishap. The emergency supply became depleted and two valves in the normal nitrogen purge system failed in the open position releasing the high pressure nitrogen gas from the manifold into the liquid hydrogen tank. The gas flow raised the liquid hydrogen tank pressure to 4.5 psig. That was sufficient to rupture the bulkhead wall.","Lesson ID":237}
{"Driving Event":"A 500 HP service air compressor stayed engaged after a stop command was issued from the central control dispatcher after a test run. The motor came to an abrupt halt and started to burn, causing extensive damage. The primary damage occurred to the compressor motor as the coils were burned. Damage also occurred to the starter in the form of blown fuses and burned contacts. The cause of the mishap was a direct result of an inadvertently bent follower arm on the starter. When the central control dispatcher commanded the control circuitry off, the DC field was turned off but the starter stayed engaged. The angle of the bent follower arm allowed it to fall behind the walking beam assembly preventing the starter from disengaging. The running of the motor out of synchronism without field exitation caused overheating of the cage windings to the point where the motor started to burn.","Lesson ID":227}
{"Driving Event":"A wind turbine was lowered from its tower and secured to a ground level assembly stand. A blade tip was then removed and the work crew broke for lunch. After lunch the rotor brake was released. Personnel on the ground realized the unbalanced rotor condition as the blade came rapidly to the ground. The direct cause of the accident was a failure of several knowledgeable personnel in the immediate area to realize the unbalanced conditions of the rotor. A crane operator was available in the immediate area. The crane should have been used to secure the unbalanced rotor and slowly lower it to the ground. This procedure of lowering an unbalanced rotor has been standard procedure in many blade, spool piece, and tip changes in the past.","Lesson ID":235}
{"Driving Event":"The mishap occurred in the air drive section of a research wind tunnel. During an evening research run, a six foot stepladder was drawn into the wooden drive blades of the tunnel. The stepladder was destroyed and the wooden blades were damage. The investigating committee determined that the principal cause of the mishap was the unsecured stepladder left in the tunnel by day shift personnel who used it for inspection purposes. Factors that contributed to the mishap were: the distraction of tunnel operator\/mechanic by other duties, inadequate checklist elements that would require verification that the tunnel is clear for operation, and no requirement for a pre-run tunnel walk through just prior to a test run.","Lesson ID":193}
{"Driving Event":"The furnace involved was a procedyne high temperature fluidbed furnace with an 1850 degrees F maximum operating temperature. The furnace medium consisted of 1000 lbs of an alumina sand and was set to idle at 1200 F overnight. During the run fluidized media was found to be spewing out of the furnace and running down a wall in the furnace room. During the following investigation the alumina sand showed signs of sintering that suggests overheating conditions in the range of 2000 to 2200 F. Cause of the overheating was found to be the main electrical contactor that had welded shut on 2 of the 3 legs allowing an uninterrupted supply of power to the furnace heater. Further investigation determined that a contributing factor to the mishap was the condition of the retort wall that contained a brittle fracture appearance and evidence of a stress failure rather than a thermal failure at meltdown. The retort failed as a result of the increased thermal stress, due to the continued power supply from the stuck electrical contact, and the inherent mechanical defects in the retort wall that was not able to withstand the 2200 F temperature.","Lesson ID":211}
{"Driving Event":"Before starting up vacuum pumps to lower the pressure in an altitude tank, the reservoirs of the pumps were checked for proper oil level. The levels were found to be low and about 5 to 7 gallons of oil were added to the reservoirs of each pump. The pumps were then turned on to start pumping against their isolation valves. When the valves were opened to the tank to allow high gas flow to the pump inlet, oil was discharged through the vent system to the roof of the building. Because of the pressure build up, an elbow in the vent line separated and spilled oil on the pump room roof and the parking lot next to the building. The investigating committee determined that a false reading was obtained when the oil levels of the pumps were checked prior to starting them up. The missing oil was in the inlet cavities of the pumps and not in the reservoirs where the oil level is measured. When the pumps were started, the excess oil was forced from the inlet cavities to the pump reservoirs, thereby overfilling them.","Lesson ID":216}
{"Driving Event":"A metal halide high intensity light bulb in the O&C high bay ceiling inadvertently exploded. Glass fragments were spewed to the O&C high bay floor, which was clear of personnel and flight hardware at the time of the incident. The subject light fixture was inspected and cleaned of all debris. Metal halide bulbs are very bright and increase the amount of available illumination by 50%. The explosion of the metal halide bulb caused concern so the bulb's fragments were collected and sent to NASA's malfunction lab for evaluation. The malfunction lab observed discoloration of some bulb fragments. According to the lab the discoloration suggests that the lamp was reaching the end of its useful life. It is not known what the manufacturer's recommended life for these particular lamps is, but once they reach that particular number of hours, under continued use, they have an increased propensity to explode. In addition, the lab studied the interface area between the lamp bulb and the metal housing, no anomalies were noted.","Lesson ID":309}
{"Driving Event":"A counterbalance cable had become disengaged from the upper support beam pulley during assembly operations. This was caused by the work scaffold (used to access the upper beam area) making contact with the counterweight. The tension in the cable was relieved, allowing it to slip from the pulley groove. When the load was reestablished, tension was reapplied to the counterbalance cable, pulling the weight free and allowing it to fall.","Lesson ID":223}
{"Driving Event":"A deactivated exhaust gas cooler in a vacuum line collapsed under normal operating conditions of 26 inches of mercury. The cooler was destroyed. There was minor damage to a nearby wall due to negative pressure in the vicinity of the cooler. Skylights in the shop area imploded and a considerable amount of debris was drawn into the piping. The principal cause of the failure was deterioration of the cooler due to age. Poor welding during assembly and inadequate inspection of the cooler were contributing factors.","Lesson ID":232}
{"Driving Event":"An employee was loading a wheeled welding cart onto a truck equipped with a hydraulic lift gate when the welding unit fell from the lift gate. The employee, working alone, pulled the welder onto the lift gate from the vehicle's right side. He then turned the front wheel 90 degrees to help stabilize the welder and chocked the rear wheels with the aluminum ramp. Using the lift gate control on the right side of the vehicle, he raised the gate to the truck bed level. After reaching the truck bed elevation, the welding cart began to shift or slip towards the right side of the vehicle. The high center of gravity of the welder, the inadequacy of the aluminum ramp as a wheel chock, and the adverse slope of the lift gate, all contributed to the instability of the welding cart that resulted in the welder falling from the gate.","Lesson ID":236}
{"Driving Event":"A three inch diameter stainless steel manifold containing hydrogen (0.27 lbs) and air (0.26 lbs) at 350 psia ruptured during experimental operation. The hardware was off-the-shelf, slightly modified, pre-safety checked and analyzed by the supply vendor. The test apparatus was in an altitude tank at simulated altitude conditions at the time of the mishap. Damage was restricted to the manifold and some of the experimental package valves. The cause of the rupture was a detonation of an unplanned hydrogen and air mixture inside the manifold. A contributing factor was the deviation from preplanned test procedure by the test crew while attempting to make the device work. The investigation team determined that the principal cause of the mishap was the lack of backflow prevention devices in the hydrogen and air supplies to the test package. That deficiency permitted the accumulation of the detonation charge within the manifold.","Lesson ID":168}
{"Driving Event":"A fire started at the flight operations aircraft fueling station when a pumping station was in the process of being connected to a new, in-ground, aviation fuel storage tank. Residual fuel had been left in the refueling unit because the connection was to be made with no disruption to any of the unit piping. The workers installing the unit, when faced with a six inch difference in the tank piping from the unit inlet, decided to modify the piping. When the workers broke into the unit piping and saw some residual fuel leaking they assumed the amount to be negligible. A stand was set up within 10 feet of the pipe opening and a grinding operation was started to add a short section of pipe. The investigation committee determined that the ignition source of the fire was from sparks generated by the grinding operation.","Lesson ID":169}
{"Driving Event":"Silicone was used to compensate for the differences in coefficient of thermal expansion between electrical components and the basic epoxy module material. The silicone was transferred in some manner to the module baseplates and resulted in a poor bond and subsequent cracking.","Lesson ID":314}
{"Driving Event":"On August 12, 1990, 7.3 seconds after the SRM separation pyros were activated on Magellan, erroneous alert codes were received by CDS. These alerts were caused by the failure of the AACS Memory B of at least 2K of the TCC244 RAM. JPL was able to build a failure model which accurately matched the symptoms on the spacecraft. Through ground tests, it has been determined that by firing one or more NASA Standard Initiator (NSI) a short to the chassis ground could take place. The short path could be due to the direct contact between the unburned portion of the squib bridgewire with the chassis, or more likely, due to the presence of conductive gases\/materials (plasma generated by detonation) between the squib bridgewire and chassis. When a short occurs, a large current can flow through the ground structure and thus a large differential voltage can be induced across the shorting path. Since the energy available during the short is very large (2.2 J), the intense source of electro magnetic interference can affect sensitive victim electronic circuits causing upsets or damages. The shorting hypotheses are not unique to Magellan. The impact of NSI shorts on space systems is strongly dependent on grounding and cabling configurations of each spacecraft, with potential mission risks. Additional Keyword(s): Shielding Reference(s): PFR 52235, ISA 8899 Magellan Anomaly Investigation, IOM 340-93-JLS 301, dated 12\/9\/93 Summarized Findings and Recommendations of the Mars Observer Investigation Groups, IOM GEC: 250-94-009, dated 1\/28\/94 Mars Observer Loss on Signal: Special Review Board Final Report; JPL Pub. 93-28","Lesson ID":348}
{"Driving Event":"During the successful deployment of the ACTS\/TOS Payload from the STS-51 cargo bay on September 12, 1993, the \"SUPER*ZIP\" pyrotechnic separation joint ruptured, producing debris that caused minor damage. Two explosive cords were initiated and operated in the subsystem (when functioning of one cord was desired), causing considerably more energy to be imparted into this subsystem, resulting in the rupture of the containment tube, doubler plates, lead sheathing, silicone rubber extrusion and in the emission of carbon particles (smoke). One affected plate penetrated through the shuttle orbiter aft bulkhead insulation blanket and punctured a 1\/8 x 1\/2 inch hole in the aft bulkhead. Flight\/crew critical equipment exists immediately behind the bulkhead. Other debris caused at least nine small tears in cargo bay insulation blankets, three gouges in wire tray covers and possibly a gouge in a thermal protection system tile. The primary cause of the separation system anomaly was a circuit design error, which resulted in firing one end of both the primary and back-up cords, rather than firing both ends of the primary cord. The direct cause of the design error could not be determined. This embedded error remained undetected throughout a series of comprehensive requirements, design and certification reviews and systems tests with wide participation by both the government and contractors. The end-to-end system tests, end-to-end verification Ground Support Equipment (GSE), and procedures were established in a manner that validated the erroneous design rather than the end function. This was due in part because of lack of adequate systems engineering in the TOS program and because the SUPER*ZIP end-to-end drawings were spread among several individual drawings and never aggregated into a single end-to-end functional electrical\/mechanical schematic.","Lesson ID":312}
{"Driving Event":"A qualified high voltage electrician was injured when he cut into a 34,500 volt cable that was thought to have been de-energized. The cable was located in a cable tunnel in the substation. The primary cause of the accident was the misidentification of the power cable. This was attributed to the fact that two of the cables had their identifying tags interchanged. Because maintenance personnel felt that they had the right cable identified, there was no attempt to determine by sounding devices, spiking, etc. that the cable they were about to cut was energized. The cable had been previously isolated and no further switching was felt to be deemed necessary.","Lesson ID":210}
{"Driving Event":"A section of a piping system was removed from a test facility for outside pressure testing. The pipe section had an expansion bellows mounted on the end that was not restrained and under nitrogen gas pressure the bellows ruptured injuring several employees. Although the pressure in the system was under the design maximum, it was determined that the primary cause of the accident was failure of the bellows. While properly designed for its application, it was not tested under conditions for which it was designed.","Lesson ID":250}
{"Driving Event":"During a test run on a model in a wind tunnel, several components of a wooden test rig could not withstand the loads on them with the tunnel at maximum speed. Stress calculations made prior to the mishap indicated an acceptable factor of safety. However, the assumptions in the calculations for stress neglected to consider the drag force on a flat plate which is a multiplier to the dynamic pressure, resulting in a force 80 percent higher than was used in the calculations. The stress calculations on the model also made certain assumptions that were not consistent with the quality of its material and construction. The investigating committee found that the failed parts were fabricated from inferior wood with numerous knots and that glue was not used to help keep the parts together. The inferior strength of the wood was not noted initially because the model was painted over when delivered to the test site.","Lesson ID":204}
{"Driving Event":"An electrical contractor employee was driving studs into a Haydite wall with a cartridge powered Ram-Set. The stud went through the wall and traveled approximately 25 feet across the room to hit an employee working on a scaffold about 4 feet off the floor. The stud hit him in the back of the left thigh penetrating approximately one inch into the leg.","Lesson ID":245}
{"Driving Event":"The gaseous nitrogen service coupling of the shuttle orbiter Auxiliary Power Unit (APU) #2 fuel tank was found to be leaking after servicing for shuttle mission STS-3. It was determined that this leakage was the result of contamination\/corrosion at the ground\/airborne Quick Disconnect (QD). The probable source of the contamination was believed to be a stainless steel filter in the Ground Support Equipment (GSE). Moisture being trapped and held between the filter and its support screens had corroded the filter elements thereby causing the filter to fail and allowing contamination to migrate to the QD's where it was deposited on the poppet seat. Sampling of the fluid had been conducted at the GSE cart upstream of the filter. Investigation has shown that there are many types of contamination and corrosion present in the QD's. Leaking of nitrogen from the APU fuel tank could potentially result in the inability to restart the APU for orbiter re-entry. The following actions were proposed to resolve this problem: (1) modification of the Ground Support Equipment (GSE) to provide for fluid sampling at the GSE\/airborne interface, and (2) change the procedures to require filter inspection and replacement on a regular basis.","Lesson ID":13}
{"Driving Event":"In Bldg. 9 at JSC, a 1000-watt quartz immersion heater was being used to heat a small amount of water for a chemical mixing operation in a precious metals shop. The heater, which was not equipped with a safety device to shut it off automatically in case of high temperature caused by the water level falling below the level of the heater element, was inadvertently left on overnight. Once water in the polypropylene bucket had evaporated, the heater's protective quartz sheath melted, and subsequently ignited the bucket, leading to a fire with damages estimated at $350,000 to a NASA facility. A simulation conducted as part of the mishap investigation confirmed the plausibility of this scenario. The mishap investigation board recommended that all equipment with the potential for overheating or causing a fire should be incapable of overheating to an ignition temperature, and there should be adequate safeguards to disconnect power in an anomalous situation. Lesson Revised: June 17, 1997","Lesson ID":14}
{"Driving Event":"Inspection of the Nose Landing Gear (NLG) tire revealed a 1\/4\" cut which appeared to have a small piece of wood embedded in it. The investigation of the tire included: (1) X-Rays that verified the position and size of the wood chip; (2) review of the standard holography inspection data that verified the technique failed to reveal the defect; and (3) sectioning of the tire to determine the origin of the chip. The wood chip came from the cart used to transport the tread gum rubber to the tire builder and was built into the tire. The wood chip became visible only after inflation. All existing orbiter tires were X-Rayed to screen for similar defects and tire inspection techniques were changed to include X-Rays. The wood chip caused a delamination sufficient to produce a tire failure under some worst case, but feasible, landing scenarios (maximum permissible cross wind at KSC). However, the other NLG tire would have supported the orbiter following this failure.","Lesson ID":11}
{"Driving Event":"An explosion occurred during the cleaning operation of a tank containing nitrogen tetroxide and residual hydrazine. The cleaning fluid used was trichloroethylene, considered to be inert and compatible with the chemicals involved. The intensity of the explosion killed two workmen. Bench tests were run with conflicting results and further tests were planned.","Lesson ID":248}
{"Driving Event":"General purpose computer S\/N 00513 at the JAEL test facility operated for 11.5 hours without cooling. The lack of forced air ventilation was caused by an air duct cover left on during installation. According to personnel working in JAEL and the results of JAEL's investigation, the factors which contributed to the problem were inadequate supervision of individuals involved, a lack of discipline in the practice of handling flight equipment, and failure of JAEL and quality assurance personnel to follow and\/or verify existing procedures.","Lesson ID":259}
{"Driving Event":"Mars Observer experienced inertial reference loss on several occasions during its cruise to Mars. Two classes of inertial reference loss have been observed: A. In early January 1993, the flight software was unable to identify any star that transited the celestial sensor assembly field of view. The unidentified stars count exceeded the \"loss logic limit,\" and the fault protection software commanded the spacecraft to the sun coning attitude contingency mode. This occurred three times before a temporary software script to widen the star identification tolerance was uplinked in order to artificially increase the attitude uncertainties, or covariances, used by the software. Design flexibility of the fight computer and software allowed the software patch to be easily performed. It was suspected that the cause was due to the use of the more optimistic gyro noise parameters and values obtained from the in-house test results rather than the manufacturer's specifications. Recovery time: 3 days per occurrence. B. During April and May 1993, three more incidents caused the spacecraft to declare inertial reference loss when the \"sun monitor ephemeris\" test, which compares the expected new position with the measured positions, was violated. An algorithm error in the inherited flight software caused the spacecraft attitude to be incorrectly estimated under certain conditions. A similar problem occurred on the Defense Meteorological Satellite Program (DMSP), an earth orbiting spacecraft built by the same contractor, that was using the same flight software. This algorithm error puts the spacecraft in additional jeopardy when the attitude covariances are large. Since the script that was intended to prevent the January incidents increases the covariances, the script acted as a catalyst for the three April\/May anomalies. The review of the data indicated that no detailed code walk-through was performed on the software patch that widened the star identification tolerance. Recovery time: 5 days per occurrence. Additional Keyword(s): Attitude Determination, Star Scanner","Lesson ID":310}
{"Driving Event":"Following completion of a repair, a work crew laid a hot cotton tar mop on a piece of roofing insulation material on the roof. Although they doused the mop with water, it subsequently ignited spontaneously after approximately two hours and started a fire on the roof. Damage was limited to the mop, the insulation, and a small area of the roof. The undocumented procedure to immerse tar mops in a bucket of water and then lower to the ground after job completion was not performed. To prevent recurrence, the maintenance contractor modified the safety section of the annual roof plan as follows: mops will be disassembled, placed in a sand filled container, lowered to the ground, and disposed of by the environmental support department according to existing regulations. The spontaneous ignition of tar mops is well documented in existing literature, e.g., \"Fire Protection Handbook\", 17th edition.","Lesson ID":265}
{"Driving Event":"A transducer failed a mass spectrometer leak check. The serial number of the transducer was vibro-etched onto the sealing surface causing the leak. The design drawing provided no specifications to preclude the application of the serial number onto the sealing surface.","Lesson ID":293}
{"Driving Event":"Construction personnel were performing renovations to room 194 in building 16A at JSC. The renovation project included installing a suspended ceiling in part of the room. While in process of installing the ceiling, a pipefitter for the facility construction contractor noticed that the fire suppression system sprinkler head fusible link guard on one head was not consistent with the other heads in the room. Since the sprinkler would not operate effectively with this misalignment, the pipefitter tried to correct the problem. As he was attempting to adjust the misaligned guard, the wrench slipped breaking the fusible link on the sprinkler head causing water to be discharged into the room. Although the water pressure was immediately shut off, the broken head continued to drain water for approximately 30 minutes.","Lesson ID":264}
{"Driving Event":"A K-Seal drawing and manufacturing instruction specified measurement of inner and outer diameters, but no measurement of the K-Seal legs. Following the failure of a batch of seals during an Acceptance Test Procedure (ATP), an investigation revealed that they had all yielded and provided insufficient sealing forces. The yielding was caused by thin leg sections that occurred due to no direct measurement of leg thickness during manufacturing. Failure of this K-Seal could result in hot high pressure oxygen leakage during the orbiter launch phase with its associated hazards and also a lack of sufficient oxygen for external tank autogenous pressurization. Note: A drawing of the subject seal is available with the source documentation.","Lesson ID":266}
{"Driving Event":"During burn-in testing of an orbiter General Purpose (Flight) Computer (GPC) in the JSC avionics engineering laboratory, a \"fail to synchronize\" error was detected. This error indicates that the computer is out of synch with other GPCs involved in the test, and may be the result of a computer hardware problem. The GPC in question was discovered to be very hot to the touch, and inspection of internal sensors indicated the GPC had been overheated beyond design limits. An ensuing investigation showed that the unit had operated without cooling for 11.5 hours due to failure to remove the ventilation system air duct cover prior to installation of the GPC in the test bed. This event was a direct result of not following installation procedures described in the Test Preparation Sheet (TPS). Additional factors contributing to this event included: The design of the cover plate for the GPC cooling duct did not prevent installation of the GPC with the cover in place. Most of the cover plates used in the laboratory were modified with additional foam to preclude installation of the GPC without removing the cover. The alarm system used to monitor GPC cooling depended on vacuum sensing instead of positive airflow indications. With the air duct cover in place, the vacuum sensor on the GPC in question showed a normal range reading even though there was no air flowing through the computer. The monitoring of an indirect parameter (vacuum) rather than a direct indication of absence of a critical parameter (cooling air flow) or the existence of the hazardous condition of concern (temperature of the GPC) did not guarantee that proper cooling was provided. Only one junior technician was assigned to install the GPC. This was a violation of instructions on the TPS, which required two technicians to perform this task. As a result, the quality assurance assignee for the task helped to perform the installation procedure rather than performing his intended monitoring function. There was no formal program of training or certification in place for technicians in the laboratory. The training received was principally an undetermined amount of on-the-job training. Factory evaluation of the GPC involved in this event determined that it was fit for use only as a test or prototype unit and not as a flight unit. The difference in cost between a flight GPC and a test GPC is approximately $700,000.","Lesson ID":291}
{"Driving Event":"During the shuttle STS-4 mission, an orbiter (OV-102) hydraulic pump failed. A post flight examination discovered an aluminum particle wedged into one of the high pressure pump gears. The probable source of the particle was determined to be in some drilled oil passages where evidence of burrs were found at the intersection of the holes. The pump manufacturer: Implemented requirements for an inspection of all oil passages prior to assembly. Added a flushing of the pump with clean hydraulic fluid following vibration testing and before continuing further acceptance testing. Reviewed the pump cleaning process.","Lesson ID":295}
{"Driving Event":"During burn-in testing of an orbiter General Purpose (Flight) Computer (GPC) in the JSC avionics engineering laboratory, a \"fail to synchronize\" error was detected. This error indicates that the computer is out of synch with other GPCs involved in the test, and may be the result of a computer hardware problem. The GPC in question was discovered to be very hot to the touch, and inspection of internal sensors indicated the GPC had been overheated beyond design limits. An ensuing investigation showed that the unit had operated without cooling for 11.5 hours due to failure to remove the ventilation system air duct cover prior to installation of the GPC in the test bed. This event was a direct result of not following installation procedures described in the Test Preparation Sheet (TPS). Additional factors contributing to this event included: The design of the cover plate for the GPC cooling duct did not prevent installation of the GPC with the cover in place. Most of the cover plates used in the laboratory were modified with additional foam to preclude installation of the GPC without removing the cover. The alarm system used to monitor GPC cooling depended on vacuum sensing instead of positive airflow indications. With the air duct cover in place, the vacuum sensor on the GPC in question showed a normal range reading even though there was no air flowing through the computer. The monitoring of an indirect parameter (vacuum) rather than a direct indication of absence of a critical parameter (cooling air flow) or the existence of the hazardous condition of concern (temperature of the GPC) did not guarantee that proper cooling was provided. Only one junior technician was assigned to install the GPC. This was a violation of instructions on the TPS, which required two technicians to perform this task. As a result, the quality assurance assignee for the task helped to perform the installation procedure rather than performing his intended monitoring function. There was no formal program of training or certification in place for technicians in the laboratory. The training received was principally an undetermined amount of on-the-job training. Factory evaluation of the GPC involved in this event determined that it was fit for use only as a test or prototype unit and not as a flight unit. The difference in cost between a flight GPC and a test GPC is approximately $700,000.","Lesson ID":292}
{"Driving Event":"External corrosion of tubing material caused leakage in a shuttle orbiter Reaction Control System (RCS) helium Quick Disconnect (QD). Neoprene tape was applied to the tubing in the vicinity of the N2O4 source. The corrosion was due to chemical attack by the products of a chemical reaction between nitrogen tetroxide (N204), propellant oxidizer, and the neoprene tape material. The products formed were nitric acid and various chlorides. Due to the presence of the nearby QD, small quantities of N204 were routinely present in the external environment upon mating and demating of the QD. An integrated materials compatibility assessment would have identified this incompatibility issue.","Lesson ID":203}
{"Driving Event":"During a fire in a precious metal workshop (where hazardous materials were used), fire fighting efforts were delayed while information to determine the compatibility of water as an extinguishing agent was obtained. Additional damage resulted from the delay. The fire department has now been provided a listing of recommended extinguishants to be used in specific locations.","Lesson ID":263}
{"Driving Event":"Two aircraft maintenance personnel were preparing a test run on engine No.2 of a NASA turboprop aircraft at Ellington Field. During the bleeding of air from the engine fuel system, a flash fire occurred. One worker jumped from a ladder and injured his left heel. The other worker burned his hand while attempting to combat the fire. Additional personnel responded to the scene and extinguished the fire with portable fire extinguishers. An investigation of the incident noted the placement of the extinguishers approximately 150 feet from the aircraft. NFPA code recommends placement of no further than 50 feet. Investigators recommended placing the extinguishers within NFPA maximum allowable distances.","Lesson ID":300}
{"Driving Event":"During burn-in testing of an orbiter General Purpose (Flight) Computer (GPC) in the JSC avionics engineering laboratory, a \"fail to synchronize\" error was detected. This error indicates that the computer is out of synch with other GPCs involved in the test, and may be the result of a computer hardware problem. The GPC in question was discovered to be very hot to the touch, and inspection of internal sensors indicated the GPC had been overheated beyond design limits. An ensuing investigation showed that the unit had operated without cooling for 11.5 hours due to failure to remove the ventilation system air duct cover prior to installation of the GPC in the test bed. This event was a direct result of not following installation procedures described in the Test Preparation Sheet (TPS). Additional factors contributing to this event included: The design of the cover plate for the GPC cooling duct did not prevent installation of the GPC with the cover in place. Most of the cover plates used in the laboratory were modified with additional foam to preclude installation of the GPC without removing the cover. The alarm system used to monitor GPC cooling depended on vacuum sensing instead of positive airflow indications. With the air duct cover in place, the vacuum sensor on the GPC in question showed a normal range reading even though there was no air flowing through the computer. The monitoring of an indirect parameter (vacuum) rather than a direct indication of absence of a critical parameter (cooling air flow) or the existence of the hazardous condition of concern (temperature of the GPC) did not guarantee that proper cooling was provided. Only one junior technician was assigned to install the GPC. This was a violation of instructions on the TPS, which required two technicians to perform this task. As a result, the quality assurance assignee for the task helped to perform the installation procedure rather than performing his intended monitoring function. There was no formal program of training or certification in place for technicians in the laboratory. The training received was principally an undetermined amount of on-the-job training. Factory evaluation of the GPC involved in this event determined that it was fit for use only as a test or prototype unit and not as a flight unit. The difference in cost between a flight GPC and a test GPC is approximately $700,000.","Lesson ID":290}
{"Driving Event":"At the White Sands Test Facility (WSTF) a burst disc on a high pressure (9700 psi) oxygen system ruptured at 5700 psi, well below the system and rated pressure of the disc. Ignition of the vent system downstream of the burst disc occurred, partially destroying it. The burst disc was a safety relief device placed in an oxygen recharger pumping system and was subjected to rapid cyclical pressure pulses during recharging operations. It was concluded that the cycling fatigued the burst disc metal much more rapidly than would be expected in a static system application. Although the exact source of the ignition is not known, it was assumed that either particles from the ruptured disc or accumulated debris from the oxygen pumping system impacted the vent system in the presence of the high pressure oxygen that flowed past the ruptured disc. This served as an ignition source for the base vent material (stainless steel) fire, which progated until the venting oxygen pressure fell below the level that would support combustion. The fire then self-extinguished. The design of the vent line was changed to place the burst disc very near the end of the vent line, exterior to the facility, and with the discharge oriented away from personnel access areas. In-line particle filters were relocated closer to the oxygen source to reduce the probability of debris exiting at high velocity from the vent system if a burst disc rupture occurs. All WSTF high pressure oxygen vent system designs were reviewed and two additional systems of similar configuration were eliminated (they were no longer needed).","Lesson ID":298}
{"Driving Event":"A shuttle orbiter General Purpose Computer (GPC) at Input Output Port (IOP) No.2 was voted out of a set with other computers. The computers were exchanged and the computer connected at IOP No.2 also malfunctioned, indicating the problem was with the IOP. A pin solder joint was found to be fractured. The unit was repaired without investigating the cause of the joint failure. Rework procedures were revised to require an investigation of the cause of a failure before any attempt to repair the failed component.","Lesson ID":10}
{"Driving Event":"During post ascent shutdown of an orbiter OV-102 Auxiliary Power Unit (APU) on shuttle mission STS-2, the unit increased in temperature. Flight data indicated stoppage of coolant (water) flow to the APU. Post flight tests indicated proper operation of the coolant control valves and no flow restrictions. During disassembly, a coolant inlet filter interface fitting was found to be cross threaded. It was concluded that this fitting leaked during ascent and while on orbit. The leak caused water to flash freeze in the line, blocking the flow. The ice thawed on entry and removed evidence of the blockage. Initial installation and maintenance procedures were revised to add leak checks and visual inspection for proper alignment of fittings.","Lesson ID":12}
{"Driving Event":"When the shuttle orbiter main propulsion system oxygen manifold was pressurized to obtain gas samples, oxygen line to engine No. 3 also pressurized. The prevalves to all engines were closed and pressurization should not have occurred downstream of the prevalves. A small check valve is provided parallel to each prevalve and allows expanding fluid trapped in the manifold legs of each engine, between the prevalves and the engine valves, to relieve back into the main manifold. Upon removal of the No. 3 check valve, it was discovered that the spring holding it closed was broken and had been installed backwards. The error in installation contributed to additional stresses on the spring during earlier flow tests that lead to this failure. If the faulty installation of the spring had remained undetected and the spring had failed during cryogenic operations, uncontrolled flows into the engine leg could have caused launch delays. An X-Ray technique was developed to inspect existing valves for proper installation of the springs. A mandatory inspection point was added to the fabrication assembly procedures to preclude installation errors for this spring.","Lesson ID":16}
{"Driving Event":"The shuttle orbiter right hand inboard brake failed during the STS-7 landing, even though there was very little braking action. A post-flight tear down and evaluation of the brakes determined the cause of the failure to be defective retainers (washers), which hold together the carbon lining and the carrier plate. These retainers are made from Titanium\/Zirconium\/Molybde-Num (TZM), which is very resistant to high temperature and very brittle. Numerous cracked retainers were found during the inspection. The cracks, in many cases, were not perceptible with the human eye and were only detected by Eddy Current inspection. The retainers were visually inspected and replaced as required before the STS-7 flight. As corrective actions, the supplier implemented the use of a different riveting tool to minimize cracks and a change in the inspection procedure to include a 100% use of the Eddy Current inspection technique.","Lesson ID":18}
{"Driving Event":"A bladder on a shuttle crew emergency rescue equipment inflatable flotation assembly was abraded by the zipper on the flotation sleeve, causing it to leak. Three of the flotation assemblies were flown on the orbiter for two flights and used twice in training sequences, which resulted in the zippers wearing and cutting the bladder where it passes around an emergency oxygen bottle. The corrective action taken was to add a zipper guard flap to all existing sleeves and to units to be manufactured.","Lesson ID":22}
{"Driving Event":"Low flow rates were observed in the shuttle orbiter freon coolant loops when the temperatures in the radiator panels dropped below minus 60 degrees Farenheit during a mission. An investigation of the problem revealed that the system filters were clogged with teflon particles. The origin of the particles was traced to the krytox fluoropolymer thread lubricant grease used during loop assembly. Corrective actions were taken to remove, clean, and replace the system filters, several valves, a flow proportioning module, and a pump assembly.","Lesson ID":9}
{"Driving Event":"In Building 30 at the Johnson Space Center, a contractor electrician received an electrical shock to the hand and forearm from contacting an energized (480 volt AC) power panel lug. A separate contractor, from a remote location that contained the control devices for the power panel, had switched off, tagged, and verified all circuits deenergized. An electrical drawing was used to assure all circuits were included in the safing procedure. However, a modification was performed earlier to add a lug set and wiring to the panel that was not routed through the same remote controls location as the original wires, and was not reflected on the facility master drawing. The injured electrician did not verify the lug was deenergized by testing with a meter or other device. The injury was minor (small entrance and exit burns), but could have resulted in severe injury or death had the current passed through the torso. Corrective actions included updating the facility drawings and emphasis on enforcement of existing procedures for testing circuits as part of the lockout\/tagout process.","Lesson ID":19}
{"Driving Event":"A dual suit pressure controller failed to pressurize a crew coverall during manned suit testing and the shuttle flight STS-37 Terminal Countdown Demonstration Test (TCDT). The coverall is donned by an orbiter crew member during launch and entry. No previous failures of this type had occurred before. Upon disassembly of the suit, a small piece of fabric reinforced elastomer material (from a seal called a neck dam that separates the head and torso parts of the coverall) was found lodged inside the controller on the primary diaphragm assembly seat. Before the TCDT, a rapid replacement of the neck dam was performed. The usual, but undocumented, step in the replacement procedure that called for component removal before changing the neck dam did not occur. The piece of elastomer from the old neck dam remained in the suit as debris and migrated to the diaphragm during the pressure cycling. The corrective actions included: (1) documenting the procedural steps to require component removal, (2) protecting the component area from debris by adding plastic sheeting, and (3) vacuuming the inner volume of the coverall and inspecting it following all maintenance work. A failure of a coverall of this type during flight could result in the loss of the crew member if cabin pressurization failed.","Lesson ID":20}
{"Driving Event":"A shuttle orbiter Auxiliary Power Unit (APU) heater system failed in the \"ON\" condition in flight. A post-flight investigation determined that a heater ground-side wire shorted to the uninsulated part of a wire harness clamp. The automatic shut-off switches were located such that they did not turn off the heater due to the short eliminating the switch from the circuit for the fuel and water lines heaters. The heaters were manually switched \"OFF\" by the crew. The short was caused by an earlier repair that opened the wire harness. When reassembled, the heater wire separated from the bundle, dislocated into the uninsulated part of the clamp, and was pinched by the clamp when it was tightened. Subsequent wear and tear resulted in premature failure of the wire insulation resulting in the short. Had this anomaly remained undetected or manual shut-off not been achieved within five minutes of the occurrence, the hydrazine fuel could have heated to the explosive auto-decomposition temperature within the line. The APU would then have failed and effects of the explosion could potentially have resulted in severe damage to the orbiter. It was further determined that under some failure modes, a shorted condition could remain undetected by both the automatic cut-off sensors and the temperature indicators that alert the crew or ground controllers of over-temperature conditions. Corrective actions included: (1) tying the wire bundles together before tightening the clamp, (2) using a clamp that has all surfaces insulated, and (3) a review of the electrical system design for relocation of temperature sensors.","Lesson ID":17}
{"Driving Event":"During various shuttle orbiter missions, several anomalies occurred which were subsequently attributed to particle contamination within limit switches. In three such instances the particles were metallic substances and of a sufficient size (greater than 0.015 inches) to create a premature state change. In a fourth instance, the particle contamination was non-metallic which resulted in a high contact resistance and the loss of a \"closed\" indication. These switch failures were attributed to contamination from metallic (weld expulsion, less than 0.010 inches), glass from headers, ceramic from insulators, rubber from back-filling equipment, polymers, and polyesters. Limit switches are often used to: (1) prevent systems or components from reaching damaging stress levels and, (2) inhibiting unwanted events or conditions. The primary corrective action to prevent recurrence of these failures was to impose Particle Impact Noise Detection (PIND) testing on all future limit switch manufacturing. additional techniques included improved cleaning processes and the addition of filters to purging and drying fluids to preclude particle introduction into the components.","Lesson ID":21}
{"Driving Event":"Hydraulic fluid leakage was noted at the interface of the flex hose and Rosan fitting on a hydraulic pump. The fittings were a different size at each end of the flex hose. Different size fittings require different torque values, which the specifications did not identify. The hydraulic system is inspected prior to each mission of the shuttle vehicle. Review of the procedure used during installation of the hydraulic system shows that one end of the flex hose was torqued to 120 foot pounds. The installation drawing does not specify that the other end of the flex hose has a smaller fitting that should require a lower torque. Leakage was corrected by a hose replaced and torqued properly.","Lesson ID":15}
{"Driving Event":"On November 21, 1989 two shuttle orbiter tires skidded sufficiently to cause blowouts following the application of brakes during a ground test at Wright Patterson Air Force Base. The skidding was caused by the brakes locking due to the failure of the anti-skid system. This failure was due to the use of non-flight switching valves as part of the test stand. Additional damage occurred to a hydraulic hose and quick disconnect fitting. An investigation also discovered an error in the abort software and the addition of excessively restrictive non-flight orifices in the brake hydralic lines. All of these findings contributed to the failure.","Lesson ID":4}
{"Driving Event":"During two successive missions of the shuttle orbiter OV-99, a television monitor secured by a bracket that was bonded to the wall of the crew module, became detached from the wall (debonded). Following the first incident, it was assumed that an improper bonding technique was the cause of the failure. Remounting was accomplished under close surveillance by quality inspectors. Following the second incident, it was concluded that growth of the structural skin of the wall due to pressurization during flight caused the failure. It was explained that this did not occur on orbiter OV-102 because its wall is thicker and subject to less growth from pressurization. An object as large as a TV monitor detaching from its mount during any phase of a mission could become a hazard to personnel or equipment. The wall section of OV-99 used for mounting the monitor was stiffened with wall doublers to reduce growth from pressurization during launch.","Lesson ID":7}
{"Driving Event":"A pair of shuttle orbiter teleprinter 28 VDC power cable wires shorted together. A short section of wire and insulation ignited and burned releasing a small amount of contaminants within the crew cabin. The burn through produced an open circuit, but was of insufficient duration (150 milliseconds at 50 amps) to open the circuit breaker. The crew manually opened the breaker and removed the cable. An investigation determined the cause of the failure was inproperly designed strain relief at one end of the cable where mated. The resultant flexure of the cable caused 360 degree annular breaks in the insulation of the power wires adjacent to each other. The cable was redesigned to utilize a more effective 90 degree bend strain relief device. The wire insulation material was changed from kapton to the more flexible teflon. Other orbiter cables of similar design were inspected and designs reviewed to preclude problems in similar configurations. This incident involved a non-mission essential component and the crew was potentially exposed to voltages below human shock hazard levels. However, the failure produced an ignition source.","Lesson ID":5}
{"Driving Event":"Following the shuttle mission STS-27, the right side orbital maneuvering system (OMS) pod carrier panel on the orbiter OV-104 was missing. It was concluded that the panel was installed incorrectly. Six flat washers were not installed under the mounting fasteners. This caused damage to the base panel material upon installation. The panel became loose during flight, produced a gap, and was pulled off by the air flow. No additional damage was sustained by the orbiter thermal protection system or other orbiter components. The panel installation procedures did not clearly identify the requirement for the washers. The procedures were revised to include the steps for installing the washers. Approximately 100 orbiter panels of similar configuration were recommended for inspection to assure this anomaly was not present elsewhere within the orbiter fleet.","Lesson ID":6}
{"Driving Event":"A flash fire occurred during a performance record test of the shuttle Extravehicular Mobility Unit (EMU). This fire occurred when a shutoff valve was opened, supplying 6,500 psi oxygen to the EMU. Ignition occurred and a very high temperature oxygen- rich aluminum fire ensued. The shutoff valve melted in the fire, relieving the system pressure and causing the metallic fire to extinguish. Residual fires were extinguished using carbon dioxide extinguishers. A finding of the mishap investigation board was that the most probable ignition site was within the regulator module in a flow restrictor. This flow restrictor consists of two drilled passages, which intersect in a \"V\" shape. Manufacturing practices allow some overdrill at the intersection of these two passages, which may have formed a stagnant volume at the base of the \"V\". This stagnant volume allows compression heating (adiabatic compression detonation) and\/or shock heating, which ruptured and ignited a thin section of aluminum and spread to the other metallic components of the module in the oxygen enriched atmosphere. Other possible ignition mechanisms included (in priority order): Compression and\/or shock heating of contaminant(s) entrapped in the stagnant volume of the flow restrictor (all five other regulators disassembled and inspected showed some particulate debris within the system). Mechanical heating of or by particulate contamination impinging on a surface. Compression and\/or shock heating of one of the silastic o-rings in the shutoff assembly. Testing at White Sands Test Facility was unable to duplicate these events in over 2200 attempts or confirm any of these ignition mechanisms.","Lesson ID":8}
{"Driving Event":"Following the shuttle mission STS-34, it was determined that a vent door actuator operated on two of the three electrical phases. The vent door actuator was replaced. During the failure analysis, a defective solder joint was found on a lead connection to a printed circuit board, analysis indicated the solder was contaminated with room temperature vulcanizer (RTV) silicone potting compound. Records revealed that this defect occurred prior to the requirement to train and certify the solder technicians to the aerospace quality standard DOD-STD-2000.","Lesson ID":2}
{"Driving Event":"While installing electrical cables into a conduit in the Johnson Space Center Mission Control Room, the conduit was displaced from its mounting, and then contacted and broke a chilled water line. A portion of the room was flooded. The installation procedures did not include details for using sufficient lubrication on the cables being pulled through the conduit. Also, no cautions or warnings were provided to alert the electricians to take additional precautions to prevent accidents in a high value, mission essential area. Other factors that increased the extent of damage included; (1) an emergency plan that did not include water leaks, and (2) no information was available to the maintenance or operations personnel on the location of or access to shutoff systems. The investigation board recommended correcting the deficiencies in the work procedures, emergency plans, and mission control allowable work","Lesson ID":3}
{"Driving Event":"During prelaunch check out of shuttle orbiter OV-104 for flight STS-36, the AC2 buss phase a voltage fluctuated between 112 and 122V for one minute. The inverter supplying that buss was removed and replaced. The vendors' inspection of the failed inverter found loose mounting screws on the electrical buss internal to the inverter, which caused the voltage fluctuations. An identical problem had been previously discovered that prompted a change to the manufacturing procedures to include a specified torque for the mounting screws. The failed flight unit had been reworked, but the manufacturing procedural change had not been incorporated into the rework process.","Lesson ID":1}
{"Driving Event":"When the C-Band pulse from the transmitter was present in the antenna panel, the Low Noise Amplifier (LNA) in the receive chain had a long recovery time of up to 200 microseconds. The transmit\/receive module of the antenna received transmit pulse leakage into the LNA which shifted the operating bias and caused the long recovery time before the LNA was enabled. All previous testing of the panel had been done in transmit-only or receive-only modes. Correction of the problem required extensive rework of the panels. Covers, harnesses, and printed wiring boards were removed to gain access to the transmit\/receive modules. Then two resistors were replaced and five capacitors were removed from each of twenty-eight modules in each of the nineteen panels. Additional Keyword(s): RF Performance Verification Reference(s): PFR #56187","Lesson ID":304}
{"Driving Event":"Following installation of a discrete capacitor on an electronic assembly of a non-JPL project, an integrated circuit (IC) on that assembly was found to be inoperative. Further analysis indicated that the IC was damaged and that one of the chip inputs had likely been subjected to an excessively high current (the IC damage was similar to that which results from an Electrostatic Discharge (ESD) condition). It was not clear whether or not the assembly procedures being followed included the use of established techniques designed to protect components from ESD. Additional review concluded, however, that the excessive current likely originated from a residual charge on the capacitor that had just been installed, and which was electrically connected to the IC input that failed. Laboratory tests were conducted and verified that, unless special precautions were taken, capacitors could accumulate a residual charge, through normal handling and storage, that is sufficient to destroy an integrated circuit if allowed to discharge through one of its inputs. The conclusion was that the subject capacitor likely had a residual charge, and when it was electrically connected to the input of the IC, it discharged through the IC itself and damaged the input circuit. Additional Keyword(s): Electronic Parts Handling Reference(s): JPL IOM #523-WRW-91-390, W. R. Woods, Circuit Damage due to Assembly with a Charged Capacitor.","Lesson ID":297}
{"Driving Event":"Loss of Challenger","Lesson ID":329}
{"Driving Event":"Coolant leak developed on the Skylab which was attributed to B-nuts.","Lesson ID":323}
{"Driving Event":"At assembly level acceptance test, 90% of the Topex RIU's used on the discrete command channels experienced malfunctions (glitches). This problem resulted from the decision to do strobing of the power VCC on\/off line rather than using a designated strobe line. This type of unconventional strobing generated a voltage race problem, which translated into an unequal voltage propagation delay internal to the chip, thus causing chip malfunctioning. This design decision dates back to the Voyager project. The RIU glitch phenomena occurred in Voyager, but was considered benign due to slower circuit response required by Voyager. On Topex, resolving the glitch problem required A) screening and assigning of sixteen RIU's to locations less affected by glitches, and B) inserting RC filters on the central unit harness connector to eliminate glitches in spacecraft commands from the central processor. The described costly Topex modifications were necessary to reduce the risk associated with the misuse of this part. Additional Keyword(s): Poseidon Reference(s): PFR #C04068","Lesson ID":296}
{"Driving Event":"On October 7, 1989, during installation of the Pressure Release Devices (PRD) to Galileo's RTGS, the four screws anchoring each PRD failed to pull snug to the RTGS when the assembly crew applied what was considered to be acceptable torque. Further insertion of the screws was halted and washers were added to allow a snug fit. Analysis and a vibration test indicated that the thread engagement was sufficient to proceed with the launch. On October 2, 1990, during installation of the PRD to the Ulysses RTG, the fourth and last attachment screw seized and subsequently sheared. Extensive analysis and consultation with General Electric indicated that a sufficient safety margin existed to proceed with the launch even with the PRD anchored by only three screws. Neither of these incidents in any way compromised the safety or functionality of the PRD\/RTG. On October 16, 1990, a PRD anomaly review board was established to investigate the cause of these anomalies and make recommendations. The board has found that the Galileo anomaly resulted from inexperience with the helicoil locking feature. The Ulysses screw seizure most likely resulted from prior use of an unlubricated cover screw and\/or some earlier degradation of the helicoil. Additional Keyword(s): Fastener Reference(s): JPL D-9625, Galileo\/Ulysses Pressure Release Device (PRD) Anomaly Review Board Report; PFR #54340 AND #54365.","Lesson ID":306}
{"Driving Event":"Early in the MGN flight, REM temperatures exceeded predictions by over 20 degrees C. for selected ranges of spacecraft orientations. During the MGN System Thermal Vacuum Test (STV) in July 1988, the REM exhibited a similar problem in that temperatures were about 25 degrees C. warmer than expected. There were no REM subsystem solar thermal vacuum tests conducted prior to the STV. Since the only solar thermal vacuum test was conducted at the system level, attainable REM orientations during that test were restricted. Following the STV, modifications based solely on analyses by the REM supplier were implemented without any test verification. Current thinking (based on flight data) is that in addition to nozzle entrapment of solar energy, the thermal model was too simplified; and the thermal surface properties of the engines were different than originally thought. The REM high mission temperatures caused two major impacts: 1) the mission attitude profile had to be significantly modified to avoid overheating the REMS, which was a major constraint on mission operations, 2) a major ground test program was required to demonstrate temperature capabilities above the original upper limits. Additional Keyword(s): Design Fix Verification Reference(s): PFR #52226 (ISA #5069), PFR #52227 (ISA #5552)","Lesson ID":349}
{"Driving Event":"Early in the MGN mission, sun viewing bus bays (and associated electronic subsystems) were at least 20 degrees C. hotter than anticipated. This effect increased as the mission continued. Temperatures were at or above flight acceptance levels, and for short periods of time, at or near qualification levels for some bays. Fortunately a special margin test phase during the MGN solar thermal vacuum ground test had demonstrated system operations at these temperatures. Even higher equilibrium temperatures were anticipated as the mission progressed. The apparent solar absorptance increase (derived from the flight temperatures) for MGN is generally global and appears to be approximately twice that expected based on known data bases. Fairly recent theoretical and experimental work shows the possibility that contaminants (organic molecules in particular) outgassed by the spacecraft and\/or solar panels may be the cause of increased absorptance (through interaction with solar ultraviolet radiation) and thus higher temperatures. The MGN effect may be due to the greater ultraviolet energy at Venusian solar distances compared to Earth (about 2 solar constants). The MGN solar panels received only minimal outgassing prior to flight (20 hours). The impacts of these high subsystem temperatures were significant. Extensive unplanned analyses and mission planning activities were required, including spacecraft attitudes to prevent even higher temperatures, and some mapping science was lost. Were it not for the confidence gained during the solar thermal vacuum test at these higher temperatures, significantly more science would have been lost. The long life of MGN is certainly threatened: concerns exist for both electronic part life and solder joint fatigue. Additional Keyword(s): High Temperature Reference(s): PFR # 52228, ISA # 5649","Lesson ID":283}
{"Driving Event":"During confidence testing of the MBB Galileo Ten Newton (N) Engine at MBB in November 1988, rapid increases in combustion chamber temperature were sometimes observed immediately after ignition of the engine. These \"hot starts\" required manual intervention to stop the test before overheating could produce engine damage. Subsequent examination of test data from the previous flight engine acceptance tests revealed that the \"hot start\" phenomena had also been present in those tests. JPL did not witness, or request detailed data from, these earlier tests. The \"hot start\" phenomena was eliminated by moving the engine trim orifices downstream of the engine valve and changing the flight operating mode of the thrusters. The design change was based on empirical testing of several configurations, since the instrumentation available did not allow the nature or cause of the phenomena to be precisely determined. Over 20,000 firings were conducted after the orifice change without further occurrences of \"hot starts\". Other combustion instabilities (NCR 892) and unacceptable thermal performance (NCR's 884, 889, AND 894) were, however, noted in some pulse mode and continuous firings. The Galileo mission was redesigned to avoid continuous firings of the 10 N thrusters and to restrict pulse mode duty cycles so that the impacts of \"hot starts\" or other thermal instabilities, should they occur in flight, would be minimized. The \"hot start\" phenomena is now known, based on subsequent data collected for other spacecraft projects, to be a 30 KHz acoustic instability of the MBB 10 N combustion chamber and injector. It is likely that the instability was triggered by severe ignition transients which were alleviated by the new orifice configuration. Bubbles saturated in the propellant, produced by the original orifice configuration, also appear to be a contributing factor to triggering the instability. Additional Keyword(s): Supplier Testing Reference(s): NCR #883","Lesson ID":351}
{"Driving Event":"Two days prior to the planned delivery of the flight Solar Array Drive, the unit was accidentally dropped on the floor. Final dimensional inspection was being performed on the SAD at the contractor's facility. The device was cradled in its drilling and alignment fixture, but in order to accommodate inspection, was not fastened down. There were no instructions to fasten the SAD to the fixture during manipulation, nor were any warnings posted to indicate that special caution was necessary during the inspection process. There were no documented requirements for quality assurance (QA) or other cognizant personnel to witness the inspection, and none were present. An employee who was unfamiliar with the device tilted the assembly to take a measurement, unaware that the SAD was not fastened to the fixture. The SAD tumbled out of the fixture, rolled across the surface plate, and fell about 40 inches to the floor. Its housing was damaged in at least two areas, and there was concern that the output bearings had also been damaged by the impact. The SAD was disassembled to facilitate damage assessment, and extensive analysis, testing, and inspection were performed to determine its flight worthiness. No evidence of bearing damage was noted, but repair of the damaged housing areas was required. The Material Review Board (MRB) agreed with the proposal to reassemble the SAD without replacement of any major components. Following the reassembly and inspection, flight acceptance tests (including environmental tests) were successfully repeated. The incident resulted in a two month delay in the SAD delivery and considerable cost increase to the program. A major effort was required by the review board and the JPL\/Contractor SAD teams to assess, rework, and retest the SAD to assure its flight worthiness. Reference(s): PFR #55704, MRB 00036","Lesson ID":273}
{"Driving Event":"As part of the preparation for the testing of the TOPEX\/POSEIDON spacecraft, the spacecraft and its thermal vacuum fixturing assembly were being lifted and positioned above the thermal vacuum chamber when the assembly began a slow overturning rotation. The assembly rotated approximately 135 degrees before it was halted by the entanglement of the Spacecraft Horizontal Support Structure (SHSS) with one of the four lifting fixture suspension cables. While resting in this anomalous position, the test team visually determined that the lifting fixture spreader bar (inherited from the Galileo program) had sustained considerable damage and might fail. A decision was made by the Fairchild Systems spacecraft manager to lower the assembly to the chamber floor as quickly as possible to protect the spacecraft and remove the load from the damaged spreader bar. The assembly was lowered to the chamber floor where it was temporarily secured. While no major spacecraft damage resulted from the incident, it would have been catastrophic to the TOPEX\/POSEIDON Program if the satellite had actually been dropped. Additional Keyword(s): Handling, Hardware Safety Reference(s): PFR #53523","Lesson ID":267}
{"Driving Event":"During recent years numerous incidents of failed solder joints in electronic equipment have been identified in hardware fabricated both at JPL and JPL Contractor facilities. Examples include: GALILEO, PFR #52012, Command Data Subsystem: Intermittent failure in solder joints at flat pack lead attachment to the printed wiring board. ASTROS Star Tracker, PFR #33998, Electronic Assembly failure: Solder connection open at a Dual Inline Package Integrated Circuit (DIP IC) lead to the printed wiring board. MAGELLAN, PFR #55263, Data Formatter, Electronic Assembly failure: Solder connection open at a DIP IC lead to printed wiring board. WF\/PC-1 PFR #53914 Microprocessor failure: Solder connection open at a DIP IC lead to printed wiring board. ACRIM II, PFR #44478: Electronic Module solder joints were observed to have stressing\/cracking at the DIP IC lead to printed wiring board interconnect. MLS, PFR #43374: Solder joint on input bias wire had stress cracks. Investigation of the above items reveal a common element of cause. Conformal coating (polymeric substance applied to protect from the environment) material filled the space between the printed circuit board and the bottom of the electronic component, and thermal cycling, and\/or prolonged exposure to solvents, created the large forces required to cause solder joint fracture.","Lesson ID":275}
{"Driving Event":"During functional testing of the S\/N 002 ASTROS Star Tracker Electronic Assembly at Kennedy Space Center, the unit indicated an incorrect brightness level when viewing a test star. Careful inspection of the assembly electronics revealed a hairline crack near the middle of the body of one of the dip components. Investigation showed the crack could be duplicated on this component part type by use of lead bending tools required to form the part leads for installation. The tooling had been previously used successfully on this part type but a different lot number. Additional Keyword(s): Cracked Components Reference(s): PFR #33998, #41720","Lesson ID":268}
{"Driving Event":"On March 24, 1992 the ATMOS instrument, a fourier transform spectrometer, flew on the Atmospheric Laboratory for Applications and Science (ATLAS 1) payload aboard the shuttle (STS) Atlantis with an open problem\/failure report (PFR). The events leading to this state of readiness can be briefly summarized as follows: since the experiment for which this instrument was built was proposed as a low cost effort at a very early time in the STS program, the proposal did not plan for a breadboard or prototype model. The instrument had its maiden flight on the SPACELAB 3 mission in 1985 and was expected to be reflown several more times at 12 month intervals on STS missions. During the hiatus of reflights, caused by the Challenger accident, ATMOS was extensively used for making significant ground based observations. During these operations an infrequent, and apparently randomly occurring failure was observed in the startup sequence, in that the moving slides stopped. The failure could always be overcome by resetting the instrument. In spite of concerted efforts to isolate the cause of this anomaly, the failure mechanism was not identified even though certain suspect parts were exchanged. An in-flight workaround was devised for the ATLAS 1 mission and the instrument was committed to flight, knowing that a non-catastrophic failure might be experienced. In fact, during the course of the ATLAS mission, the slide failure did occur and the workaround was employed successfully. No data was lost and the mission was concluded without further reoccurrences of slide motion problems. The decision to take this risk was reached taking into account the consideration that in a low cost, reflyable instrument the acquisition of a large quantity of quality data was worth the loss of small quantities of specific runs. Reference(s): PFR #52055","Lesson ID":272}
{"Driving Event":"During cruise to Venus, the Magellan star scanner detected false stars. These false star sightings prevented spacecraft attitude updates and occasionally caused false updates. Two causes were identified: 1) High energy solar protons sensed as false stars by the star scanner detector, and 2) Quartz particles, from the spacecraft thermal blanket cloth, were probably ejected when the material was thermal shocked by sudden shading or unshading from the hard ultraviolet light of the sun; these quartz particles can be sensed as false stars when illuminated by the sun. The first problem was solved by revisions to the onboard software in the attitude determination filter. The filtering worked well except during heavy solar flares. The second problem was solved operationally by keeping the star scanner in the spacecraft shade during star scans. The revisions to the onboard software (the fix for the first cause) also helped to reduce the probability of false star detection caused by quartz particle ejection. Additional Keyword(s): Workarounds, Optical Sensors Reference(s): PFR #52222","Lesson ID":269}
{"Driving Event":"During Venus mapping operations at high (over 64 degrees) incidence angles of the sun to the solar panels, a jitter occurred in the solar array drive control loop. This jitter excited a structural resonance in the solar panels, causing severe vibration. The problem was caused by a deficiency, at oblique sun angles, in the algorithm that is used in Flight Software (FSW) to determine whether a solar panel position correction is required. The deficiency was caused by not accounting for high sun incidence angles (geometrical effects) in setting the minimum step size software parameter. As a result, the algorithm continually determined that a correction was required -- first in one direction, then in the reverse, then in the first direction, etc. The jitter was actually present in simulations performed by the flight team before the incident occurred on the spacecraft, but was not recognized because of the plotting scale used. Once recognized, the problem was solved by switching the solar array control to an open-loop mode, i.e., not using the sun sensors, while the celestial geometry was unfavorable. A complete description of the problem can be found in the references. Additional Keyword(s): AACS, Mathematical Models Reference(s): PFR #52242, ISA 8775, ISA 9049, ISA 8536","Lesson ID":358}
{"Driving Event":"During testing of the flight Mars Observer PDS (Serial No. 1) in a thermal vacuum chamber, the subsystem was exposed to a temperature of about -47 degrees Celsius, well below the desired limit of -20 degrees C. The problem was caused by a failure in a temperature controller and was compounded by a chamber operator evaluation error. The failure of the controller during the planned descent to -20 C was detected by an alarm circuit and a \"fail safe\" circuit, both of which functioned properly by closing off the supply of cold gas to the PDS baseplate heat exchanger. The chamber operator overrode the protection circuits, choosing to believe the recently calibrated temperature controller rather than the alarms. The subsystem engineer observed from a separate data source that the hardware was exceeding the specified temperature and requested a test termination. Following analysis, evaluation and test facility corrective actions, the test of the PDS was continued and successfully completed with no further difficulty. Reference(s): PFR #55545 AND #56161 (includes Review Board report)","Lesson ID":274}
{"Driving Event":"The WF\/PC II engineering model camera head did not image properly during initial power-on electrical tests. The malfunction was determined to be a failure of the CCD. After a new CCD was installed, the camera head was again found to be inoperative due to the same type of CCD failure. It was determined that both failures were caused by the use of an ungrounded thermal wire stripper during the CCD assembly process. The strippers had a measured voltage of 32 volts AC on the tips, more than enough to damage the CCDS. Investigation into the cause of the failures revealed that alerts had been issued some six years ago on this particular model of wire stripper. The devices that were destroyed in this event were two of only 28 remaining units in existence (one CCD is required for each of the 8 camera heads in the WF\/PC II flight assembly). Obtaining additional devices would have extreme cost and schedule impact on the WF\/PC II build. Additional Keyword(s): Electrostatic Discharge Reference(s): PFR #53937 and #53934 JPL Quality Assurance Alert QAA 019 (9\/14\/84) Government-Industry Data Exchange Program Problem (GIDEP) Advisory H6-P-90-01 (no date)","Lesson ID":285}
{"Driving Event":"During the launch sequence of the Magellan spacecraft, the two solar panels were observed by the space shuttle astronauts to have deployed, but the \"panels-latched\" telemetry indication was not transmitted. The deployment mechanism Failure Mode Effects and Criticality Analysis (FMECA) had identified the potential for latching indication problems, therefore in the planned launch sequence the panels were rotated such that the subsequent Inertial Upper Stage (IUS) burn would drive the panels toward the latched position. Analysis has shown that the anomaly was due to the combination of marginal microswitch actuation stroke and zero-g effects on the solar array hinge mechanism. This combination caused one or both of the series-wired microswitches to fail to close. During the IUS burn, a small shift of the panels resulted in microswitch closure and provided the proper telemetry indication. Except for the time spent addressing the initial concern, the anomaly did not impact the Magellan mission. Reference(s): PFR #52230 IOM 3524-90-503, From D. Sevilla to B. Wagoner, dated November 5, 1990","Lesson ID":289}
{"Driving Event":"An Attitude and Articulation Control Subsystem (AACS) sequence designed to collect data for calibration of the spacecraft star scanners in the AACS inertial mode (gyros on), was tested on the Galileo test bed simulator. Prior to the transmission and execution of this calibration sequence on the spacecraft, a star misidentification event caused the AACS to switch from the \"inertial\" to the \"cruise\" mode (gyros off). Because of the importance of getting the calibration data and limited open time in the few weeks before venus encounter, it was decided to proceed with the star scanner calibration. The mode change was evaluated and not believed to have an effect on the planned sequence. However, during the execution of the calibration sequence, a spin bearing controller instability occurred due to an unexpected incompatibility between the mode and AACS software. This caused a series of hardware swaps within the AACS, ultimately causing the spacecraft to go into safing. A subsequent test on the Galileo test bed simulator duplicated the spacecraft response. This event occurred twenty-five days before Venus encounter and the difficult recovery process from safing took three weeks. Had this anomaly occurred closer to the encounter, significant impact on science data return could have resulted. Reference(s): PFR #52608","Lesson ID":288}
{"Driving Event":"During flight acceptance vibration testing of the PMIRR radiative cooler assembly, a severe structural failure occurred. As a result of this failure, the detectors and other internal elements of the cooler assembly were severely damaged. The PMIRR cooler assembly is a modification to a flight-proven design which had flown successfully as a part of the thematic mapper instrument for several years. Cost and schedule considerations had dictated the choice of modifying an existing design over designing a custom cooler for the PMIRR instrument. An erroneous assumption was made that the inherited design was acceptable. Investigation into the event by a review board revealed that the failure was the result of the significant increase in vibration test levels required because of the change in launch vehicle for the PMIRR instrument. The thematic mapper had experienced much more benign launch environments and insufficient analysis of the failed component had taken place, particularly in the area, which was inherited from the original design. It was also determined, however, that the original analysis of the unmodified component was flawed in that it assumed an incorrect value for allowable stress for the material and manufacturing processes used. This failure created a major cost and schedule impact to accommodate the reanalysis, rebuilding, and retesting of the cooler assembly. Reference(s): PFR #54605 PMIRR Failure Review Board Report","Lesson ID":271}
{"Driving Event":"During final reassembly and welding of the 400-N Rocket Engine Assembly fuel line (part of the Galileo Retro Propulsion Module - RPM), an arc was seen to jump between the welding head and the RPM oxidizer line (a distance less than 0.1\"). The result of this arc was a pit in the oxidizer line (determined non-critical) and an uncontrolled transient pulse of current which flowed through portions of the spacecraft structure and electronics. It was recognized that this welding procedure was potentially hazardous. This welding procedure had been used when the RPM had been previously assembled on the flight spacecraft and two separate reviews were conducted prior to performing the final weld. Review of the anomaly identified several subsystems (Spin Bearing Assembly ball bearings, oxidizer tubing, encoder electronics, slip rings, RPM rocket engine pressure transducers, and RPM heaters) which were along the potential current paths of the arc from the arc contact point on the oxidizer line. Analysis of these subsystems determined that the subsystems had not been compromised. Tests simulating the worst case conditions on identical ball bearings demonstrated that there was no change to the surface after the current pulse which would degrade the bearing performance. A review of the welding anomaly concluded that the spacecraft was not damaged or overstressed. There was, however, the impact of the additional work and analysis required to respond to the anomaly. Reference(s): PFR #54818 and #54282","Lesson ID":399}
{"Driving Event":"While the Magellan Power Control Unit (PCU) underwent test following rework, an engineer was performing a test of the unit at a contractor facility after hours and without quality assurance (QA) assistance and adequate test procedures. During this continuity and resistance testing, test instrumentation applied reverse polarity voltage to electronic circuitry within the unit. This resulted in three blown fuses and potential damage to other electronic parts. After analysis, repair, and testing the PCU was reinstalled in the Magellan spacecraft at Kennedy Space Center, fortunately with no delay in launch operations. Additional Keyword(s): Subsystem Test Reference(s): Mars #B 16003","Lesson ID":287}
{"Driving Event":"At launch, the Near Infrared Mapping Spectrometer (NIMS) on the Galileo spacecraft had two covers in place to protect the instrument from contamination. Two and a half months after launch, when contamination was deemed to be negligible, an attempt was made to eject the covers. The \"cooler cover\" failed to eject, as determined by not receiving expected temperature changes. Analysis of the data revealed that the temperature of the cooler shield was 38 degrees C., due to the shield heater being energized. This resulted in a temperature differential between the cover and the shield that caused a mechanical distortion sufficient to prevent the cover from ejecting. All ejection tests before launch were conducted with the shield heater unenergized, which was the original in-flight plan. Because of a concern for contamination caused by spacecraft outgassing, a flight rule was modified prior to launch requiring the shield heater to be energized before cover deployment. The flight rule was in error by not requiring the shield heater to be off sometime prior to cover deployment. The shield heater was commanded off and twenty-two minutes later the \"cooler cover\" ejected properly, as shown by the instrument temperature telemetry. Had the \"cooler cover\" not ejected, the NIMS experiment would have been considered a failure. Additional Keyword(s): Testing, Mechanical Devices Reference(s): PFR #52603 Review Board Report, IOM 340-90-030-JLS","Lesson ID":286}
{"Driving Event":"During thermal-vacuum testing of Wide-Field\/Planetary Camera (WF\/PC-1), the sensitivity of the charge coupled device detectors decreased due to contamination. It was subsequently determined that the source of the contamination was in the instrument, and not in the test equipment. Standard criteria have been used on JPL flight hardware for the selection of materials and processes, for which the selection of outgassing characteristics were of prime consideration. The criteria have required that organic materials have a total mass loss of less than one percent and a collected volatile condensable mass of less than 0.1 percent when tested in accordance with ASTM method E595-77. These standard criteria are no longer adequate and have resulted in the reduction of the useful wavelength ranges of instruments such as WF\/PC. These instruments have orders of magnitude increases in susceptibility to contamination because of the low temperatures at which the optics and sensors operate. The standard techniques of boiling off the contamination with flash heating has not proven to be effective, either because the time constant for return of the contamination is too short (minutes to hours) or because polymerization causes the contamination to be permanently adhered. Reference(s): PFR # 53912.","Lesson ID":352}
{"Driving Event":"During final propellant loading operations for the Galileo retro propulsion module in preparations for launch at Kennedy Space Center, an oxidizer loading flex line developed a small leak. No damage to the spacecraft (protected by plastic) or to personnel (protected by scape suits) occurred from the highly toxic, volatile nitrogen tetroxide oxidizer dripping and vaporizing from the line. Microscopic examination of the flex line leak area revealed that the leak was caused by an electrostatic charge generated by the flow of the non-conductive oxidizer through the teflon flex line, discharging to the wire mesh covering. Initial damage may have been caused by carbonized tracks in the teflon line developed during the line cleaning process. Approved procedures for cleaning, proof and leak testing had been performed on the flex line prior to use in the loading process. This particular line was approximately twelve years old. Additional Keyword(s): ESD Reference(s): PFR #54310","Lesson ID":217}
{"Driving Event":"During a continuity test of the Galileo Computer Data System (CDS) wiring harness, after a wiring modification, an open circuit was detected between two connectors. Investigation revealed that a wire had pulled out of a crimped contact barrel in a connector, causing the open. Further analysis revealed that the problem was caused by a crimp contact sized for No. 20 AWG wire being used for a No. 28 AWG wire. The fabrication error was difficult to detect because the crimp connection failed only after extensive handling stress to the harness. The resolution of the problem was to color band the smaller crimp contacts for positive identification, and the development of a pull-test tool for 100% verification of each crimped wire in a connector. No crimped contact failures have reoccurred at JPL since the inception of this practice in 1984. Reference(s): PFR #40886 and PFR #41229","Lesson ID":302}
{"Driving Event":"The extreme Radio Frequency (RF) reflections due to the building environment at the Air Force Eastern Test Range (AFETR) hindered system measurements on the Voyager flight radio and antenna. The intended measurements were to be made using a small directive RF probe mounted on the antenna reflector. Previous repeatable JPL measurements in the JPL Spacecraft Assembly Facility high bay led to an erroneous assumption that the Voyager antenna system and its RF probe were not strongly affected by the building environment. At the AFETR, the location and the movement of overhead cranes caused noticeable RF variations. Additional Keyword(s): Performance Verification","Lesson ID":381}
{"Driving Event":"In an effort to take advantage of spare telemetry channels in the Command and Data System (CDS) hardware, the Attitude Reference Unit (ARU) motor current telemetry was added to the CDS analog telemetry channels of the Magellan (MGN) Spacecraft. This addition was made late in the design of the spacecraft and utilized the spacecraft chassis for the ARU motor current telemetry signal return path which was in direct violation of VRM 2-260, \"Electrical Grounding and Interfacing\" specification. A waiver of the VRM 2-260 requirements for this design was not initiated. Subsequent failure of the chassis ground path, caused by a poor mechanical connection at the attitude and articulation control subsystem single point ground, resulted in substantial damage to the MGN CDS analog telemetry circuitry. This required rework of the CDS, resulting in a late delivery to the spacecraft at Kennedy Space Center. Reference(s): Martin Marrieta Aerospace Group MARS #B16065. JPL IOM 5211-89-305, \"Removal of Red Flag Rating from MGN Mars #B16065,\" dated 25 April 1989, by M. Boyles, J. Quinn.","Lesson ID":379}
{"Driving Event":"During final preparations for the Magellan launch at Kennedy Space Center, the Solid Rocket Motor (SRM) Explosive Transfer Assembly (ETA) lines were incorrectly assembled to the inert ports of the Safe and Arm (S&A) devices. The assembly error was caused by unclear procedures, an improperly labeled diagram in a field service manual, no cognizant personnel familiar with the S&A device in attendance and inadequate mechanical locking of the plug in the S&A inert port. The assembly technician had second thoughts and concerns over the correctness of the installation. At the manufacturing facility he examined the S&A device data package and checked with knowledgeable engineering personnel to verify that the assembly was in error. Had the error not been corrected, the solid rocket motor would have failed to ignite at the time of Venus orbit insertion. Additional Keyword(s): Propulsion","Lesson ID":382}
{"Driving Event":"During Magellan prelaunch activity at Kennedy Space Center, a technician, attempting to connect a test battery to the spacecraft, inadvertently shorted the battery connector to a wrong harness connector. The resultant battery short circuit destroyed the test battery, the battery wiring harness, the flight harness connector and ignited the thermal blanket. The use of Kapton insulated wire in the battery wiring harness was a significant contributor to the cause of the fire and resultant destruction of the harness. As a result of the event, the spacecraft was impounded until a NASA review board conducted an investigation. Fortunately all spacecraft damage was repairable; however, this resulted in over a week's impact on an already tight schedule. The event was caused by: The connector connection had to be made with no direct visual access because of the location and thermal blanket obstruction. The connectors were thought to be designed to prevent pin contact until the alignment keys of the connectors were sufficiently engaged to ensure a correct connection. This was not the case and sufficient contact was made between at least two pins of the mismated connectors to cause the short and resultant damage. Reference(s): Magellan Investigation Board Report, 3\/24\/89","Lesson ID":386}
{"Driving Event":"For the last several years, JPL has required the use of hydraulic Hydra-Sets when lifting spacecraft flight hardware with cranes. The Hydra-Set is a crane hook mounted device that permits precision raising and lowering, avoiding the shocks and stresses associated with attempting small movement using the crane on\/off controls. Recently, two events occurred involving Hydra-Set usage. One involved hydraulic oil leakage onto the Delta Star instrument due to the Hydra-Set up pump handle breaking off internally during an assembly activity during launch preparations at McDonnell Douglas. The second was with the Magellan Spacecraft during launch preparation at KSC when a Hydra-Set seal burst because of an overload due to using the wrong size Hydra-Set. Fortunately, neither event caused any catastrophic damage. *Hydra-Set is a trademark of Del Mar Avionics Co., Irvine, CA.","Lesson ID":385}
{"Driving Event":"The Galileo Photopolarimeter Radiometer (PPR) subsystem cover was damaged on three separate occasions during assembly and test operations. The PPR cover is very delicate and has sharp corners that make it vulnerable to snagging. The damage occurred during thermal blanket operations which required access to areas behind the PPR location and was caused by a technician's protective clothing snagging on the sharp edges of the PPR cover. After the first incident, when damage was relatively minor and easily repaired, the workers were cautioned to avoid this problem. In the second incident, damage was serious and required rework. A protective guard was then built to protect the cover. The third incident happened after this protective guard had been removed to permit further thermal blanket fitting activity. All of the incidents occurred even though the work was being performed by well trained, experienced and highly qualified technicians under the watchful eye of QA personnel. After the third incident, the mechanical assembly procedures were revised to require a second technician (buddy system) to continuously monitor and provide a shielding arm or hand to protect sensitive areas not observable by the technician doing the work. Additional Keyword(s): Hardware Integration Reference(s): PFRS # 45429, 45463, and 45482","Lesson ID":355}
{"Driving Event":"During subsystem level testing of the Magellan Command and Data Subsystem (CDS), the test support equipment indicated an extra event for the relay controlling Critical Enable (CE) Event B03. It was theorized that a short between two specific pins of the CE relay could have caused the observed failure. When the relay was probed to verify the cause, the failure characteristic disappeared. Close visual inspection revealed a fine hairlike structure lying on one relay pin and possibly making contact with others. The object was removed and analyzed using a Scanning Electron Microscope (SEM) and an Energy Dispersive Spectrometer (EDS). The analysis revealed that the object was a conductive metal fiber, identical in diameter (.0003\"), surface characteristics and composition to metal fibers woven into the fabric of elastic Electrostatic Discharge (ESD) wrist straps. Reference(s): PFR #44931","Lesson ID":301}
{"Driving Event":"Memory Keep Alive (MKA) current draw in excess of the maximum specification was observed in the Galileo Attitude and Articulation Control Subsystem (AACS) on the spacecraft in the Spacecraft Assembly Facility (SAF) prior to the scheduled 1986 launch. This occurred again during subsystem test of modifications made to the AACS in preparation for the Galileo VEEGA Mission. Excessive MKA current draw had the potential of endangering the integrity of both AACS memories by pulling the MKA voltage below the minimum required for memory retention. It also had the potential for causing loss of contents of both AACS memories by blowing the MKA supply fuses in the power subsystem. Investigation led to the discovery of forty-one (41) sneak paths between the 10 volt MKA supply and the memory's unpowered 5 volt TTL interface supply. These sneak paths resulted in the 5 volt supply voltage being raised sufficiently to partially turn on many of the forty-one 78L12 interface drivers such that they were in an intermediate logic state, allowing each to draw as much as 30 milliamps of current. This provided the potential to draw as much as three times the maximum specified AACS MKA current. Reference(s): PFR # 45982 and #50424.","Lesson ID":392}
{"Driving Event":"The SEASAT Spacecraft failed in orbit due to a massive and progressive short in the slip ring assembly connecting the rotating solar array to the power subsystem. The most probable cause of this short was the initiation of an arc between adjacent slip ring brush assemblies. The slip ring assembly was connected into the power system such that the adjacent brush assemblies were of opposite polarity, an arrangement particularly prone to shorting. The SEASAT prime contractor was aware of instances of slip ring failures due to shorting on other projects, but did not communicate this information to the SEASAT project office. This lack of communication may have been the result of the classified nature of the other projects. The failure to give the slip ring assembly the attention it deserved was rooted in the contract structure and the SEASAT implementation policy. SEASAT was a dual contract; a fixed price for the Agena bus containing flight proven subsystems and a cost-plus award fee for the payload module which was integrated with the Agena bus. By contract, implementation plan, and resource constraints, JPL had no significant oversight of the Agena bus. The failure review board established that the Agena power, attitude control, and data subsystems were substantially modified, but were treated as closely similar designs not requiring requalification. This consideration of the Agena bus as flight-proven standard equipment led to the failure to report significant component failures, waiving tests and weak compliance with specifications. In addition, the Failure Mode Effects and Criticality Analysis (FMECA) conducted on the power system did not consider shorts as a potential failure mode. Additional Keyword(s): Inherited Equipment, Slip Rings","Lesson ID":371}
{"Driving Event":"The initial Voyager Spacecraft Trajectory Correction Maneuver (TCM) delivered approximately 21 percent less velocity change than had been predicted. Since the spacecraft telemetry indicated that pointing accuracy, thruster performance, and spacecraft equipment all were normal, it was suspected that the degradation was due to exhaust plume impingement effects. Subsequent analysis indicated that pre-flight models underestimated the effects of plume impingement due to over-simplified geometry models and inadequate characterization of rarefied gas dynamics flow fields. Reference(s): PFR #41003.","Lesson ID":377}
{"Driving Event":"During system level testing, repeated Attitude and Articulation Control Subsystem (AACS) checksum errors occurred without the presence of actual memory content errors (miscompares). These checksum errors occurred only when in one of the four possible CPU-memory configurations and only when the Command and Data Subsystem (CDS) was accessing the off-line memory. Extensive troubleshooting on the spacecraft showed that the anomalous checksum errors were being caused by both AACS memories placing data on the data bus at the same time (bus contention). After further subsystem testing and analysis, subsystem engineers determined that the bus contentions were caused by electromagnetic coupling within the AACS intra-subsystem harness while simultaneously accessing both AACS memories. Specifically, data being placed on the data bus by the on-line memory induced noise on the address lines which caused the off-line memory to turn on its data line drivers during an off-line CDS Direct Memory Access (DMA) cycle. The noise coupling between the Address and Data lines occurred in spite of AACS bay harness design which was in compliance with JPL and Galileo design standards. Further, the limited fidelity CDS simulator used during subsystem testing prevented finding the problem prior to spacecraft integration. Additional Keyword(s): Circuit Noise Reference(s): PFR #44836.","Lesson ID":383}
{"Driving Event":"During testing of the Galileo orbiter, an anomaly occurred at infrequent intervals: an unexpected Power On Reset (POR) event would reinitialize the attitude control subsystem. The POR was recognized as a serious, potentially catastrophic problem, and high priority was given to isolating a cause and verifying a fix. Despite exhaustive investigations and significant design changes to improve noise immunity, the problem continued to occur, infrequently but persistently. Ultimately, a cause and cure were identified. Although exhaustive test and analysis of ground paths had been carried out, the noise source was identified as a capacitive coupling path between flight subsystem ground and support equipment ground. When spacecraft power surges such as turning on the Travelling Wave Tube Amplifier (TWTA) occurred, the two grounds would experience a transient oscillatory voltage difference of over seven (7) volts. The \"AC Ground Loop\" fed the transient into the POR sensing circuit and occasionally triggered it. Eliminating the capacitor in the support equipment solved the problem. Additional Keyword(s): Grounding","Lesson ID":281}
{"Driving Event":"IRAS was a cooperative Dutch Space Agency\/NASA undertaking in which the spacecraft bus was built in Europe, then integrated with the NASA Infrared Telescope. The new challenges to contamination control were related to the extremely low temperatures (3 degrees Kelvin) required to achieve successful low noise infrared signal detector operation in the focal plane assembly. At these low temperatures, all gases except helium are solid. There are two separate contamination problems. The first is caused by air leakage into the plumbing when the system is cold and sub-atmospheric, resulting in plugged vents, tubes and valves, creating major safety problems or system malfunction. The solution includes care in the selection of transfer line and flight plumbing hardware, control of procedures, and use of purge covers to maintain a helium atmosphere on the high pressure side of any valve which may allow air leakage into the cold plumbing. The second problem is that exposed surfaces this cold can readily condense vapors from normal outgasing even in the vacuum of space, causing performance degradation by contamination of the optical surfaces or affecting temperature control surfaces. This complicated the development, assembly and test program for IRAS by the need to avoid contamination by any materials that could later evaporate and condense on the cold surfaces. Facility air environments had to be monitored and controlled to avoid contaminants, and handling and shipping equipment required the same extreme precautions. The contamination control situation was further complicated by the air shipments to Europe for integration, back to JPL for space simulator testing, and transportation to Vandenberg Air Force Base for launch. The successful completion of the IRAS mission attests to the success of the design and control measures accomplished. No apparent performance degradation occurred during the mission. Additional Keyword(s): Cryogenics Reference(s): JPL D-842, IRAS Telescope Development: Technical Lessons Learned.","Lesson ID":366}
{"Driving Event":"When the Galileo launch date was delayed from 1986 to 1989 with an increase in mission duration from four to eight years, the RPM design was re-evaluated. It was determined that a significant risk existed of in-flight loss of propulsion capability over the extended mission due to oxidizer flow decay. Flow decay is due to blockage of small oxidizer flow passages and filters by the accumulation of contamination products caused by interaction between the stainless steel lines and components with the nitrogen tetroxide oxidizer. Replacement of most of the stainless steel oxidizer feed system with titanium has alleviated the concern.","Lesson ID":305}
{"Driving Event":"Shortly after Voyager I Jupiter encounter, an anomaly occurred in the cone angle circuitry of the Canopus Star Tracker (CST). The cause of the problem was determined to be a base-emitter or collector-emitter leakage in a transistor circuit that drives the cone angle deflection plates. This problem was duplicated in a spare CST. The most probable cause of the leakage path in the transistor circuitry is believed to be two-fold; 1) a Delrin insulating sleeve decomposed after exposure to Jupiter radiation fields and 2) development of a high resistance path through the Delrin by electrostatic discharge from an ungrounded tungsten radiation shield box. Additional Keyword(s): Grounding Reference(s): Failure Investigation Report EM 343-494","Lesson ID":384}
{"Driving Event":"During a recalibration test of the Galileo NIMS flight instrument in a subsystem vacuum chamber, a facility failure occurred. A liquid nitrogen supply line fitting separated, causing liquid nitrogen to spray on the outside of the chamber, and filling the room with fog. After the break was repaired and in preparation to restart the test, four additional failures occurred, one of which caused the flight instrument to be subjected to a temperature below its qualification limits. These failures can be attributed to substandard liquid nitrogen plumbing, a known idiosyncrasy in a control circuit and human error. Before the flight instrument was permitted to be tested in the subsystem facility, the required safety certification process had been accomplished and a flight projects office waiver had been requested and approved. The reason for requesting to test in a facility other than the JPL environmental test lab was so as not to introduce unknowns into the recalibration process. Additional Keyword(s): Science Instruments","Lesson ID":353}
{"Driving Event":"Following rework of the Galileo Spin Bearing Assembly (SBA), tests were conducted at the system level to assure that the changes made in the SBA did not affect spacecraft operation. Results of the tests showed lower than expected CDS voltages on the despun side of the CDS. These low voltages were isolated to the trace size of the printed wiring board conductors within the main CDS power supply. The problem was corrected by adding conductors in parallel with the power supply printed wiring board traces. Reference(s): PFR #44928","Lesson ID":398}
{"Driving Event":"The Galileo Spacecraft Development Test Model (DTM) included the spare flight antenna subsystem (SXA-1). Informal characterization testing used to validate the analytical model included extensive modal vibration testing. Several organizations were involved in both developing and conducting the tests. At the conclusion of three tests (modal, acoustic, and pyro shock), three problems were identified: 1) the surface mesh, restraining cords, certain fittings, and sunshade were damaged, 2) the number of vibration cycles permitted by Space Transportation System (STS) safety criteria had been exceeded, and 3) the antenna failed to deploy properly due to a cord snag. The first problem, which reduced RF output by 3.4 dB at X-band, was probably caused by fatigue-type wear during modal testing. The second problem was the result of a calculation error during the test and would have precluded the use of the antenna for STS launch without some sort of refurbishment and requalification. The third problem, potentially mission catastrophic, was the third observed occurrence of a snag, indicating underlying design problems. The project declared the SXA-1 antenna nonflight qualified due to gain loss, noncompliance with STS criteria, and questionable deployment reliability.","Lesson ID":368}
{"Driving Event":"To process the Synthetic Aperture Radar (SAR) data received from the SEASAT spacecraft, the project first evaluated contractor proposals for digital processors. They rejected all as too expensive and chose instead to upgrade an existing JPL \"research and development\" (R&D) optical correlator. The R&D correlator did successfully process SEASAT SAR images. However, the project had insufficient funds remaining to include the planned automatically controlled mode. The R&D correlator also proved less reliable than operational equipment, thus did not process the expected volume of data.","Lesson ID":276}
{"Driving Event":"The Galileo Command Data Subsystem tests uncovered a \"read disturb\" problem of the memory chips which required extensive rework of the flight boards. Due to the extensive rework and short schedule, the conformal coating was removed in large strips rather than in small areas. The flight memory boards were submerged in an alcohol bath, the conformal coating removed, and the failed parts replaced. Subsequently it was discovered that the parts adjacent to those replaced exhibited some fractures in the solder joints. The combination of the prolonged alcohol bath and the subsequent heating of the conformal coating around and under adjacent parts caused the coating to expand and stress the solder joints. Lack of experience with leadless chip carriers was a contributing factor in this event. Additional Keyword(s): Repair","Lesson ID":388}
{"Driving Event":"As Mariner 10 (MVM'73) was nearing encounter with Venus, an uncontrolled oscillation occurred due to spacecraft structural interaction with the Attitude Control Subsystem. The problem was first detected during a platform calibration sequence, which required a series of roll turns using roll gyroscope inertial control, and science scan platform motion. The result was a severe consumption of control gas which would have caused failure of the mission had it continued. The oscillation was due to a control instability exciting a structural mode of the spacecraft. The primary cause of the resonance was attributed to the flexibility of the solar panels. Additional Keyword(s): Flexible Body Analysis Reference(s): PFR #5024.","Lesson ID":400}
{"Driving Event":"During a walk-through of the Galileo Spacecraft System fault protection implementation a possible \"deadly embrace\" in the flight software was uncovered. A deadly embrace is a continuous software looping operation that may preclude the achievement of an acceptable spacecraft state. Refer to IOM GLL-BGL-85-003 for additional details.","Lesson ID":369}
{"Driving Event":"During system tests, lower than expected voltages were measured at subsystem power interfaces indicating excessive voltage drop in either the interconnecting cables or the power subsystem. Subsequent testing isolated the excessive voltage drop to the power subsystem. Power system subassembly tests demonstrated that the voltage drop was across the relay welded modules in the power distribution assemblies and was caused by the high resistivity of the nickel ribbon used for electrical interconnections in these modules. These measured voltage drops were verified by JPL analysis.","Lesson ID":280}
{"Driving Event":"Within minutes after the launch of the first Mariner '64 spacecraft to Mars, it was determined that there were mechanical problems with the deployment of the solar panels and other appendages. The spacecraft eventually went dead from loss of electrical power when the battery power was depleted. Analysis of the incident indicated a failure in the honeycomb shroud (nose cone) structure due to a lack of proper venting. Internal pressures in the honeycomb structure itself, built up during the rapid change of ambient pressure during launch, combined with high shroud temperatures due to frictional forces in the near earth atmosphere, caused the shroud to break up. It was established that the shroud contractor had not performed a combined thermal vacuum test that represented the launch profile conditions. Additional Keyword(s): Materials, Outgassing","Lesson ID":356}
{"Driving Event":"Problems due to waveform irregularities and the resultant induced noise on the Voyager Spacecraft system interfaces were not validated until after in excess of 500 hours of system testing had been completed. The problem manifested itself in the following two ways: A digital, coded interface design was utilized on the Voyager Spacecraft for transferring command data between the Computer Command Subsystem (CCS) and the power subsystem. This interface, under certain spacecraft system loading configurations with the support equipment disconnected, resulted in several cases of either \"no response\" or \"incorrect response\" to commands. The problem was traced to the 2.4 kHz power subsystem waveform transitions (variable with system load configuration) coupling into the command circuits via its circuit returns causing spurious clock pulses. A related but not identical problem occurred on the CCS to the Attitude and Articulation Control Subsystem (AACS) Command Interface. In this case, waveform transition irregularities of the 2.4 kHz clock signal (again, variable with system load configuration) could, under certain conditions, result in trigger circuits interpreting these irregularities as clock pulses. To correct these problems required circuit modifications to all affected subsystems which entailed extensive regression testing. Details can be found in Voyager PFR 39802 and IOM 3132-76-179.","Lesson ID":390}
{"Driving Event":"The Drop Dynamics Module (DDM) is a Class C experiment which is flown on the Shuttle (STS). On its first flight, one of the set of seven commercial power supplies used by the DDM failed when an internal short caused the main circuit breaker to trip. Repeated attempts to energize the system were unsuccessful and an in-flight work-around was accomplished by the JPL payload specialist. Although the location of the failure was known, failure analysis did not determine the cause since the internal damage to the two failed transistors precluded a reconstruction of the event. Circuit analysis did indicate an over-stressed design. However, this condition had not prevented several hundred power supply turn-ons prior to the failure and several thousand turn-ons of the set of power supplies. In addition, the work-around solution to the power supply failure was to rewire the configuration such that two of the remaining power supplies would assume the load of the failed power supply. Those two power supplies successfully picked up the extra load. Since this failure occurred after launch, the possibility of a vibration-induced failure cannot be disregarded. The DDM was designed and implemented prior to the release of JPL document D-1489 (Flight Project Document FPO 600-3), entitled \"Payload Classification Product Assurance Provisions.\" This document provides a description of the principal product assurance elements and the specific provisions which are to be applied as a function of payload class. Additional Keyword(s): Reliability","Lesson ID":370}
{"Driving Event":"After several months of flight experience, the Viking project adopted a simple single-number criterion for managing the risk in selecting \"optimum\" downlink science data rates in the face of varying telecom performance. The rule, developed with inputs from the Deep Space Network and the Telecommunications Systems Section, is to pick from the available set the highest rate that the downlink can support at that time, assuming the downlink is 32% (1 dB) less capable than the best estimate of performance. After a further period of validation, the project widely disseminated this rule and used it consistently in sequence planning. The conclusions at the end of the project were (a) the chosen rule was right for an S-band downlink and the Viking science data, and (b) this approach provided a good balance between the total data received and the total data lost. Additional Keyword(s): Operations Planning","Lesson ID":375}
{"Driving Event":"The SIR-B Shuttle Mission 41-G exhibited a SIR-B transmitter radiated power drop of 8-10 dB shortly after transmitter turn-on. A corresponding increase in the reverse power (as noted in the telemetry) and a drop in received echo amplitude were also noted. Troubleshooting performed at KSC after Shuttle landing revealed a low resistance path (approximately 5 ohms) from the center conductor of the antenna cable to the coax shield. The cable assembly (AE9492) was part of the antenna system, which was provided as GFE by the Johnson Space Center who returned it to the manufacturer for failure analysis. The manufacturer found that a sliver of metal was embedded in the teflon dielectric of the connector.","Lesson ID":396}
{"Driving Event":"Over a period of several years, design optimizations were made to the Galileo Spacecraft system including the increase in the Retro Propulsion Module (RPM) tank load from 84% to 94%. This was to assure adequate propellant to accomplish the mission objectives and was done late in the spacecraft development cycle. However, the change resulted in a high degree of coupling between the RPM tank pressure and the spacecraft system power demand due to the spacecraft power dissipation mechanism. During the cruise phase, the spacecraft power demand will be low and the excess electrical power is to be dissipated by shunt heaters located near the RPM tanks. The power dissipation increases the RPM tanks temperature with a concomitant rise in the RPM tank pressure. The RPM design is such that relatively small temperature increases combined with the low ullage (tanks nearly full), will cause a dangerous increase in the internal RPM tank pressure. The shunt heater circuit already had a requirement for a minimum dissipation level in order to assure adequate power margin for blowing fuses in case of a spacecraft fault. The RPM tank pressure concern now added an upper limit on the shunt heat dissipations. Maintaining this dissipation within the required range causes a significant impact to the spacecraft system fault detection and control software. In addition, the operational sequence design after launch and during the cruise will be more complex and require the use of additional resources.","Lesson ID":364}
{"Driving Event":"During the prime Voyager mission, Voyager 2 suffered two potentially mission-catastrophic faults. These were: 1) failure of the spacecraft receiver plus significant degradation in the signal acquisition capability of the redundant spacecraft receiver, and 2) the azimuth scan platform actuator ceased operation. A significant contribution to the successful recovery from these faults was the availability of spare spacecraft hardware and associated support equipment, which was used to simulate postulated failures plus evaluate and validate proposed solutions and workaround procedures. The specific details of the corrections and workarounds are described in the paper entitled \"Voyager Engineering Improvements for Uranus Encounter\" by Howard P. Marderness. Additional Keyword(s): Mission Operations","Lesson ID":284}
{"Driving Event":"The Voyager Spacecraft utilized a super-zip separation band initiated by a Pyro Switching Unit (PSU) for separation from the launch vehicle. Initiation of either of the two redundant Mild Detonating Fuses (MDF) in the super-zip separation band would cause separation, while detonation of both MDFs could rupture the tube containing the MDFs and probably contaminate the spacecraft. Telemetry from both Voyagers 1 and 2 indicated that both MDFs received current from the PSU. Current to the secondary MDF should have occurred only if the primary MDF failed to cause separation from the launch vehicle. The anomalous telemetry signal indicating a current to the secondary MDF was traced to a primary detonator post-fire short to the spacecraft frame which resulted in a reverse current through the PSU's sensing circuit caused by a noise decoupling RC network between the PSU common and the spacecraft frame. The anomaly was reproduced in the laboratory thus verifying that the secondary MDF did not detonate.","Lesson ID":367}
{"Driving Event":"After completion of the Voyager primary mission (Jupiter and Saturn encounters), a follow-on mission to encounter Uranus and Neptune was made possible by the DSN arraying antennas and the project incorporating the following: A spacecraft design which enabled the implementation of an image motion compensation capability which made possible extremely long image exposures while minimizing image smear. A spacecraft design which enables utilization of redundant hardware, such as the Flight Data System memory, to increase the sequence software on-board storage capacity. This capability has been developed and tested for potential future use to enhance science return. The specific details of the types of spacecraft system and subsystem designs to accomplish this are described in the paper entitled \"Voyager Engineering Improvements for Uranus Encounter\" by Howard P. Marderness.","Lesson ID":401}
{"Driving Event":"After some two days of flight aboard Spacelab 3, the Atmospheric Trace Molecule Spectroscopy (ATMOS) instrument failed when the laser did not turn on for occultation 75. The laser failed due to a high voltage arc-over, which resulted from a pressure loss in the laser housing. Investigation revealed that the pressure loss was caused by use of machine screws of excessive length. The housing had been modified, based on a Material Review Board decision, which resulted in threaded holes, which were of a different length than the original design drawings. Machine screws were used which matched the original design drawing but were too long when used in the as-built configuration, causing the integrity of the housing to be violated. Additional Keyword(s): Leak Testing","Lesson ID":393}
{"Driving Event":"A JPL built balloon gondola, weighing approximately 4000 pounds and carrying a complement of five scientific instruments, free-fell from an altitude of 102,000 feet. The gondola and all five instruments valued at $10M were totally destroyed upon impact. An accident review board concluded that the free-fall resulted from a structural failure of a \"clevis base adapter\" which attached the gondola to the parachute, and that the adapter failed because of excessive loads imposed on it by unusual parachute\/gondola dynamics during the flight termination sequence. It was found that the design of the adapter met all requirements of the National Scientific Balloon Facility (NSBF), a NASA operated center for high altitude balloon support to scientific investigators. Investigative efforts subsequent to the accident found the NSBF requirements to be insufficient and also revealed that the flight termination sequence and its dynamics were not understood by NSBF. It is noteworthy that this flight was not the first flight of this type of balloon-borne payload, and that in several prior flight terminations, heavy stresses had been encountered that resulted in structural damage to gondolas, but not in catastrophic failures. For more details on the event refer to the report of the accident review board, JPL document D-1114.","Lesson ID":372}
{"Driving Event":"The Galileo flight control slip ring test fixture bearings had once been lubricated with a synthetic lubricant. This was eventually replaced with KG80 oil to simulate actual Spin Bearing Assembly (SBA) operating conditions in space. After approximately 3 months of life testing (under vacuum) at 3 RPM, the bearing lubricant had a thick, black, gooey appearance and the bearing friction torque was higher than expected. It was discovered that even with careful cleaning prior to the test, some of the original synthetic lubricant remained in the porous, phenolic ball retainer. Under vacuum, this residual synthetic lubricant migrated to the surface, reacting with the KG80 to form the black gooey material. A new bearing with a nonporous steel ball retainer was installed.","Lesson ID":303}
{"Driving Event":"During the process of cleaning the Galileo slip rings, the PCA cleaning fluid obtained from JPL stores was found to contain chemical and particulate contaminants.","Lesson ID":357}
{"Driving Event":"The Galileo Spacecraft was shipped to the launch site in a custom made transporter with the RHUs (Radioisotope Heating Units) installed. Removal of the heat from the RHUs required external cooling to an ambient air temperature between 48 degrees and 59 degrees F., which was provided by the transporter air conditioning system. The spacecraft also had an internal purge system which protected sensitive elements from uncontrolled humidity and airborne contamination during shipment. Upon arrival at The Cape, the transporter was placed indoors under guard in environmentally controlled conditions. Once inside the transporter air conditioners were transferred to facility power and the purge gas supply was transferred to facility nitrogen. The pressurized enclosure seal of the transporter door was relieved. Since the S\/C was not to begin processing until after the year-end holiday interval at KSC, it remained in the controlled environment under guard with periodic monitoring until after the holidays when the mechanical crew arrived and commenced KSC operations. When the transporter was opened, puddles of water were noted on the floor of the transporter and external spacecraft surfaces exhibited corrosion, characteristic evidence of excessive humidity. The conclusion after intensive inspection and extensive additional analysis by all subsystem cognizant personnel was that only external and cleanable damage occurred. Additional Keyword(s): Environmental Control","Lesson ID":376}
{"Driving Event":"This event involved both Voyager radio receivers. The failure occurred when a flight operations software command loss routine switched the S\/C configuration from Receiver 1 to Receiver 2. Receiver 1 had operated normally from launch until the inadvertent switch to Receiver 2 and subsequent controlled switch back to Receiver 1. The Receiver 1 power converter failed 11 seconds after the switch back. Other subsystem telemetry was also noted to be anomalous during this short time. Receiver 2 on first use after the inadvertent switch was discovered to have a shorted loop capacitor and thus unable to lock to normal uplink. After the Receiver 1 failure, the spacecraft switched Receiver 2 on. Receiver 2 has subsequently continued to support the mission. Its use required special Deep Space Network (DSN) uplink acquisition tuning procedures and periodic in-flight receiver best lock frequency checks to compensate for the failed loop capacitor. The analysis indicates that the short circuit within Receiver 1 was screws. The metal particle contacted components insufficiently coated by the solithane conformal coating.","Lesson ID":389}
{"Driving Event":"Viking orbiter flight radio modules developed short circuits caused by solder balls shorting terminal lugs to ground. For solderability and several other reasons, a design change had been made to the proven Mariner design. Solving the solder ball problem required $250k (in the mid-1970s) for the rework of one flight subsystem and several assembled and tested modules. Additional Keyword(s): Fabrication, Soldering","Lesson ID":308}
{"Driving Event":"Before the first Mercury encounter, the MVM'73 high gain antenna suddenly lost 3 dB in gain and changed from circular to linear in polarization. Ground testing on a similar antenna determined that a short circuit within the S-band feed cavity reproduced these effects as well as the observed changes in internal antenna temperature and standing wave ratio. Successful anomaly resolution during the flight included an induced temperature change by solar illumination to \"heal\" the antenna, permitting the planned mission. The development organization was very instrumental in the correction of the problem. They theorize that either a short circuit occurred as the result of particles or chips left in the cavity after antenna assembly or a combination of tolerance build-up and thermal effects caused a dimensional change. Additional Keyword(s): Operations","Lesson ID":395}
{"Driving Event":"One Voyager 20-watt Solid State Amplifier (SSA) failed to operate upon application of input power during spacecraft system test. The SSA provides RF power for the downlink. This problem had not occurred during many previous power applications to this SSA nor on any other SSA. In flight, this failure would render the SSA useless. Post-test analysis determined that a relay hangup had occurred following the previous application of power. The relay anomaly involves OP-AMP operation below normal voltage, energy stored in capacitors, and the relay switching voltage threshold. The original analysis had not considered decaying stored energy.","Lesson ID":282}
{"Driving Event":"Prior to launch, telecommunication analysts responsible for the Viking Orbiter and the Lander identified that in-flight checkout of the Lander transmitter could be a potential problem. The transmitter outputs are 1, 10, and 30 watts. When the Orbiter and Lander are mated, there is only a small separation between the Lander relay transmitter antenna and the Orbiter relay receiver antenna. The analysts realized that at the higher relay transmitter output levels, the relay receiver would be subject to an overload condition and could suffer possible damage. Prelaunch tests of the antenna geometry and Orbiter\/Lander mated tests were insufficient because of limited modeling capability, nonflight conditions, and noisy environments. To verify a working Lander transmitter output before the first descent to Mars surface, an in-flight test was essential. Engineers, working at the bounds of analysis with nonlinear telemetry, deemed a 10-watt test safe. Because of parameter tolerance buildup, they could not guarantee damage-free testing at the 30-watt level. Therefore, the project decided the critical Lander-1 Mars-descent data would be transmitted at 10 watts, thereby accepting the risk of some data loss due to atmospheric fading. Additional Keyword(s): RF System Design","Lesson ID":378}
{"Driving Event":"For an end-to-end system test of the SEASAT synthetic aperture radar, the development organization assembled a large radar antenna system, made of eight microstrip panels, each about 4 x 7 feet. The system also required a support structure for pointing and rigidity. The tight project schedule did not permit full-scale gain and pattern measurement before shipment of the antenna system to the SEASAT system contractor. The system test failed to meet its primary objective, to image the earth-orbiting Skylab satellite. It did accomplish the backup objective, to image a Learjet plane at 26,000 feet. The antenna was not designed for the heavy rain and severe wind occurring during the test program. Antenna phasing errors and cabling losses may have contributed to post-test antenna gain 6 dB lower and sidelobes 7 dB higher than expected. Without pre-test measurements, it was impossible to ascribe the test degradation either to the antenna or to other factors (such as uncertainties in the Skylab radar cross-section). Additional Keyword(s): Prototype System Development, Cost vs. Risk Tradeoff","Lesson ID":365}
{"Driving Event":"The anomaly happened during Earth occultation on Mariner '71s forty-eighth orbit of Mars. When the DSN reestablished telemetry reception after occultation, several temperature and spacecraft power channels associated with Traveling Wave Tube Amplifier (TWTA) 2 were in alarm. The station confirmed a loss of 0.5 dB in downlink signal level that was indicated in the telemetry. The project elected to switch to the redundant TWTA-1 by ground command about two hours after the first observation. JPL and the subcontractors were never able to pinpoint the cause of the anomaly, even as to location in the tube itself or in the amplifier. Recommendations from the investigators included contingency plans in the event of yet more severe TWTA-1 problems, as they deemed TWTA-2 still operable in the low-power mode. (These TWTA-1 problems never occurred.) During the anomaly investigation, contractor quality assurance programs were reviewed and the process procedures used to assure high quality welds were found to be inadequate. One possible failure model postulated a weld failure in the cathode support structure.","Lesson ID":373}
{"Driving Event":"The Telecommunications Development Laboratory (TDL) shut down after Voyager launch, upon termination of that project's funding. Galileo planned to fund its TDL support at a later date. The Voyager inflight receiver failures required rapid development of operational workaround procedures to accomplish the Jupiter encounter with one spacecraft receiver with limited capability. Reactivation of TDL to a usable state took more than six months because personnel had to be reassigned and equipment had to be retrieved, repaired, and calibrated. Additional Keyword(s): Management, Institutional, RF Performance Verification","Lesson ID":277}
{"Driving Event":"Four days before scheduled launch, both Viking Orbiter receivers exhibited degraded thresholds during a routine precount test on the launch pad. This degradation would directly affect the ability of the Viking Orbiter to receive commands. Subsequent on-pad tests did not convincingly isolate the cause of the noise. Either the launch RF environment or the spacecraft hardware could be the cause of the problem. The decision was made to replace all the microwave components between the radio assembly and the high gain antenna, thus delaying the launch five days. No receiver degradation occurred during the mission. Subsequent tests on the removed microwave hardware and dual-frequency rotary joints showed a possible noisy connector, though not to the degree of severity experienced on the pad. Additional Keyword(s): Launch Operations","Lesson ID":363}
{"Driving Event":"A previous failure of the onboard tape recorder had made the \"full resolution, full frame 117.6 kbps\" mode the primary telecommunications mode at the second Mercury encounter. The increased Mercury to Earth range, relative to first Mercury encounter, required (1) a communications improvement of at least one dB over the performance obtained at the first Mercury encounter, and (2) commitment by the MVM '73 project to a bit error rate higher than .0333. The Telecommunications Division and the Deep Space Network (DSN) worked together to devise an arraying scheme to improve the signal-to-noise ratio. This consisted of real-time arraying of DSS-14, DSS-13, and DSS-12 at Goldstone through microwave connections. Testing one week before encounter showed a signal-to-noise ratio improvement of 0.8 dB; the actual improvement on encounter day was 1.0 dB. In addition, non real-time arraying of the signals from DSS-14 at Goldstone and DSS-43 at Canberra was to be attempted. This would consist of combining the tape-recorded signals from each of these stations to gain additional signal-to-noise ratio. This was accomplished at the DSN's Compatibility Test Area 21 and in the Division 33 Telecommunications Development Laboratory. The bit error rate achieved in real time met the .0333 criterion for more than five hours during the encounter. Additional Keyword(s): Tracking Station","Lesson ID":374}
{"Driving Event":"The Mariner '69 Scan Platform and the Viking Orbiter Imaging Instrument Filter Wheel were operated with relative position stepping commands. In both cases, anomalies caused actual position to become different than the desired position. Because each new position selection is based upon the previous position, all post-anomaly positions were incorrect until corrected via ground based interaction. This resulted in loss of science data. Additional Keyword(s): Design, Operations","Lesson ID":279}
{"Driving Event":"The Viking and Voyager onboard tape recorders contain a mechanism to provide knowledge, via downlink telemetry, of the position of the tape. The project can also command the tape to a desired position by uplink telemetry. The design is such that an intolerable amount of error accumulates during normal use requiring an arduous workaround involving periodic interruption in use to reset the position indicator at a known tape position (i.e. beginning of tape). Additional Keyword(s): Positioning Devices","Lesson ID":380}
{"Driving Event":"Voyager flight operations strategy and system design was based upon a philosophy of very limited real-time ground commanding, assuming the vast majority of activity could be preloaded onto the spacecraft. Flight experience, particularly early in the mission, proved that the need for real-time commanding was significantly greater than planned. The end-to-end system design which was based upon the above strategy was cumbersome to use in a real-time commanding environment.","Lesson ID":270}
{"Driving Event":"Flight sequence timelines for the two concurrently operating Voyager spacecraft were inadequate because of omissions due to failure to consider in a timely manner trajectory data and DSN coverage plans for both spacecraft. Significant lead time is required for planning the allocation of Deep Space Network (DSN) facilities in support of spacecraft tracking, telemetry, and command operations. Conversely, spacecraft sequences are designed far in advance and are dependent upon expected DSN configurations. The entire effect is exacerbated when multiple spacecraft and trajectories must be accommodated.","Lesson ID":278}
{"Driving Event":"The magnitude of both the real-time cruise activities and the work required to perform advanced planning for future activities, such as encounter, landing site certification, test and training, and orbit insertion activities during the Viking mission were significantly underestimated and required an unplanned organizational change during the cruise operations.","Lesson ID":262}
{"Driving Event":"During a one month period, the Active Magnetospheric Particle Tracer Explorer\/Charge Composition Explorer Spacecraft experienced five occasions when the \"Unexecuted Command Counter\" value was anomalous and no explanation could be found. Real-time and delayed commands had all been executed and correctly accounted for in the \"Executed Command Counter\". These counters are only read out in the memory readout at the beginning and\/or end of a pass and not in the normal real-time telemetry. Three possible causes of the anomaly are as follows: The counter incremented anomalously. The counter was incremented by noise or other stimuli. The system received commands from an unidentified source but rejected them for incorrect bit patterns. Additional Keyword(s): Operations","Lesson ID":307}
{"Driving Event":"On May 25, 1983, the ATMOS instrument suffered damage to its optical system as a result of a temporary outage of the special environmental control system due to a failure of the freon compressor. This environmental control system was necessary to meet the stringent humidity requirements of ATMOS while in the Spacecraft Assembly Facility (SAF). The failure caused the temperature in the ATMOS room to rise quickly to 77 degrees F. and the humidity to 66%, a condition which damages the unprotected potassium bromide optics. The design constraint for the ATMOS humidity control is to remain below 40% relative humidity. The loss of control of temperature and humidity were caused by failure modes inherent in the humidity control system design, which were not adequately evaluated. When the failure occurred, no alarm was sounded as no sensors with alarms had been incorporated into the environmental control system.","Lesson ID":354}

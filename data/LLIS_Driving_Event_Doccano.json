{"Driving Event":"While an employee was climbing out onto a steel beam to inspect debris nets on the 16th level of the VAB, a beam clamp attached to the employee's belt struck a beam and fell 16 floors to the transfer isle of the VAB. The clamp fell near personnel in the transfer isle. The clamp was not properly tethered. Continuing emphasis is required to ensure that personnel are knowledgeable of and comply with tethering requirements.","Lesson ID":58}
{"Driving Event":"This Lesson Learned is based on Reliability Guideline Number GT-TE-2404 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: The Fizeau interferometer is used to measure the quality of optical components and systems. It provides a guide for the manufacturing of components, an aid for alignment, and a validation of system performance. Implementation Method: Description of Fizeau Interferometer The basic layout of a Fizeau interferometer is shown in Figure 1 (Reference 1.). A laser source is spatially filtered via a microscope objective and a pinhole. This pinhole is located at the focal point of a collimating lens. Between the pinhole and lens is a beam-splitter. The collimated beam encounters a slightly wedged glass plate. This is the heart of the interferometer. The surface adjacent to the collimating lens is of good optical quality. However, the next surface is of exceptional optical quality, l\/20 peak to valley (PV) or better. This is the reference surface and part of the collimated beam is reflected by this surface. Part of the collimated beam continues on to interrogate the optic being tested. The return beam contains information on aberration introduced by the test optic. The two wavefronts recombine inside the interferometer. The beam-splitter diverts the combined beams toward a recording medium, either film or a TV (CCD or vidicon). An intermediate lens together with the collimating lens forms an image of the test surface onto the recording plane. An observer will see a sharp image of the test surface with an interference (or fringe) pattern running through it. [D] Application of Fizeau Interferometer 1. Testing a Flat Suppose the test object is a plane glass surface whose quality (flatness) we wish to inspect. We must first align the test surface to the interferometer. Most commercial Fizeau interferometers have an quotalign mode.quot This requires the user to center a bright dot (the reflected return) on a crosshair on some viewing screen. Suppose the test surface has a depression in it as illustrated in Figure 2. The flat wavefront from the interferometer is incident on the test surface and reflected back into the interferometer. Note that the reflected portion shown in Figure 2 has picked up twice the surface error inherent in the test surface. This aberrated wavefront returns through the reference plate to combine with the reflected reference. [D] Wherever two coherent wavefronts overlap they interfere with each other. The equation describing interference (Reference 2) is as follows: [D] To obtain good high contrast fringes requires that the reflection off the reference and off the test piece must be equivalent in intensity. Maximum fringe contrast occurs when I1 = I2 . For example, a bare glass test surface reflects 4%. To maximize fringe contrast the reference surface must also reflect 4%. If a 4% reference surface is used to test a mirror (with 90% plus reflectivity), then a very thin beam-splitter (e.g., a pellicle) can be used to reduce the intensity from the test optic. Alternatively, a reference surface having a much higher reflectivity can be used to improve fringe contrast. In the latter case, one will notice that the dark fringes become much thinner, like sharp pencil lines. A sample interferogram of a supposed quotflatquot mirror is shown in Figure 3. If the mirror were flat, equally spaced straight line fringes should be observed (depending on the relative tilt between the reference surface and the test surface). Obviously, the mirror is not very flat at all. Each fringe is a height contour as in a topographical map. (The metric or unit of measure in most Fizeau interferometers is the wavelength of the source. For example, the helium near laser wavelength is 0.6328 microns.) The height difference between each contour or fringe is 1 wave. If knowledge of the surface error or its departure from flatness is desired, we must interpret these fringes as representing half-wave contours! [D] In addition we must know whether the pattern seen in Figure 3 is a hill or a valley on the mirror surface. This can be determined by placing your finger on the front of the reference surface metal support ring (Figure 1) and pressing lightly toward the interferometer housing. If the fringe patterns collapse or contract, the pattern represents a hill or bump. If they expand, the pattern represents a valley. 2. Testing a Lens The setup for testing a lens is illustrated in Figure 4. The lens is carefully aligned to the Fizeau beam. The beam is focused by the lens to an image point. To return the beam back to the interferometer another auxiliary reference surface is needed. In this example a small concave spherical mirror is used. This sphere should be mounted so that X,Y, and Z translation degrees of freedom are available. The center of curvature of the sphere is then made coincident with the focal point of the lens. (Be careful\u2013make sure that the focussed beam is not on the surface of the small retro sphere). The beam is reflected by the reference sphere and returned through the system. [D] The interferogram that is initially seen is likely to be an off-center bull's eye pattern. This means that the reference sphere's center of curvature is not axially coincident with the lens focal point. Use the tip and tilt adjustments on the Fizeau reference surface to center the bull's eye as shown in Figure 5(a), then use the axial translation on the concave sphere to move the interferogram into a best null condition (i.e., minimizing the number of fringes seen over the interferogram), Figure 5(b). Now use the adjustments on the reference flat to introduce tilt fringes as shown in Figure 5(c). It should be noted that the test system has significant spherical aberration. [D] An alternate setup for testing a lens is shown in Figure 6. Here the Fizeau reference surface is a sphere. It is a specially designed positive power lens where rays emerging from the last surface of the lens are normal to that surface. The test lens is aligned to the test beam and oriented so its rear focal point is coincident with the transmission spheres focal point. The beam emerges from the lens as collimated light. A flat auxiliary referencesurface is needed to retro-reflect the test beam back to the interferometer. [D] We note that transmission spheres come in a variety of F-numbers. Since your test lens has a certain F-number, pick a transmission sphere whose F-number provides a beam that either fills or overfills the test lens. Never pick a transmission sphere that underfills because then you are not testing the lens over its full aperture. Aberration content will appear lower than it actually is. Configurations for testing a wide variety of other systems are illustrated in Figure 7. [D] 3. Retrace Error The purpose of the reference sphere in Figure 4 is to return the incoming ray back upon itself so that it follows the same path on the second pass as it did on the first pass. This occurs exactly only when the incoming beam happens to be perfect, i.e. exhibits a spherical wavefront. As aberration accumulates on the first pass through the test system, the match to the reference sphere becomes less perfect. Path deviations appear on the return ray, which is now no longer coincident with the first pass ray. The optical path difference picked up by the second pass ray is not the same as the first pass ray. This is retrace error (also called ray-mapping error) (References 1, 3 and 4). As a consequence, it is no longer true that we can simply divide the results by two to obtain the single pass wavefront aberration from double pass fringe data. There are some visual clues to indicate if retrace error is significant. First, with the room darkened, check to see that the beam diameter of the light returning through the test optic on the second-pass is the same as that for the first pass after setting the null-fringe. Second, examine the irradiance distribution of this second-pass beam at the test optic. If the second-pass beam overfills or underfills the test optic aperture, and\/or the intensity distribution is nonuniform, then retrace error is significant in the test setup. To minimize the effect of retrace error, a different retro optic is usually needed. If retrace error were significant in the case illustrated in Figure 4, then a longer radius of curvature retro sphere is needed and it should be convex instead of concave. This is shown in Figure 8. The longer radius convex surface reduces the angular disparity between the incident and reflected rays. It also reduces the lateral offset between the first and second pass rays at surfaces in the test optic. [D] 4. Collecting and Handling Data It is not the purpose of this guideline to describe methods used to analyze interferograms. That deserves a guideline of its own. However, we will describe the various data collection schemes and how they interface with the analysis software. There are basically three options available to the user: 1) digitizing tablet, 2) automatic fringe following; 3) uniform grid phase measuring. The simplest and least expensive means of selecting and inputting data to an analysis code is via a digitizing tablet. A hard copy of the interferogram is placed on the tablet. The user interfaces with the tablet (and the fringe analysis code) with a digitizing pen or mouse. The code first asks the user to define the pupil. Next, data points for each fringe are entered in proper sequence from low to high contour. Once this data file is entered into the computer, the fringe code can proceed with its analysis and determine aberration content. To avoid the toil of hand digitizing, software packages are commercially available that incorporate a fringe following routine. The interferogram is imaged onto a CCD. A frame-grabber captures the fringe pattern and formats it for the computer. This intensity digitized image is then operated on by the fringe following software. It automatically generates data centered along a fringe. However, the user still must define the fringe order. An alternative approach to fringe following is a phase measuring interferometer (PMI). This is a highly automated data acquisition system. The reference plate of the Fizeau is mounted in a fixture which is piezoelectrically driven, i.e. minute cyclic axial shifts are introduced. (This is equivalent to introducing a piston into the fringe pattern.) The pupil image (with fringes across it) is recorded on a CCD. The CCD is a uniform array of sensors. Each pixel monitors the variation in local irradiance as the reference plate is moved by the actuators. Data is acquired at every pixel for four or five discrete positions of the reference plate during its sweep. This enormous amount of data is fed into a computer where the analysis software calculates the local phase at each pixel. Fringe ordering is done automatically. Plus, the huge amount of data collected on a uniform grid offers a dramatic improvement in accuracy and repeatability. Also note that this method allows the user to analyze the quotnullquot interference pattern, something the first two techniques cannot do. For a particular test setup it is usually a good idea to take four separate interferograms with fringes tilt-biased top, bottom, right, and left respectively. Fringe codes usually have an option whereby several interferograms can be averaged. An interferogram from each fringe bias is entered into the code, and the ensemble average obtained. This average is a better estimate of aberration content than any single interferogram. When testing imaging systems it is a good practice to repeat the test setup at least three times. This is because misalignments in the setup can introduce unwanted aberrations (usually coma). For each setup obtain the four fringe biased data sets mentioned above and calculate the subaverage. Then average these subaverages. 5. Environmental Constraints Vibration, whether induced through the floor into the air-isolated optical table supporting the interferometer or coupled via acoustics, is a major weakness of interferometers. This mechanical noise makes the fringe pattern unstable; it dances around at high frequency. It is hard to do meaningful interferometry under such shaky circumstances. Hence it is very important when establishing a metrology lab to locate it in a quiet area. For example, you would not want to place it between a machine shop and an optical fabrication shop. At times it may even be necessary to come in at night, when everyone else is gone and all other machines are turned off, just to get stable fringes. Another source of trouble is air currents or turbulence from air vents, or thermals (from electronic equipment for example). The fringes don't dance as with mechanical vibration but actually change shape. They meander! When an interferogram is obtained under these circumstances you are not sure how much is the test piece and how much due to changes in the refractive index in the intervening air. Shrouding the work area can be a considerable help. For example, commercial foam board from office supply houses is a useful shrouding material. Also, with a PMI, frame averaging can sometimes reduce the problem considerably. 6. Mounting Sometimes an aberration attributed to a test optic is actually induced by the manner in which the optic is held in a mount. People are sometimes afraid that an optic might fall out, so they clamp it in (or down) good and tight. As a result, the interferogram may show significant aberration (usually astigmatism) even though the optic itself is of excellent quality. So be careful, you want to constrain the test optic with a minimum of force\u2013snug enough so that it doesn't rattle around\u2013but loose enough to avoid stress-induced deformation. Large optics (meter class) have an additional mounting difficulty. They are usually quite heavy and can deform under their own weight (Reference 5). The fringe pattern will show significant astigmatism. Astronomical primary mirrors are particularly susceptible to this. Elaborate fixturing is sometimes required to alleviate the problem. Technical Rationale: All optics to be used on spaceborne or space-related instruments should be tested to validate their performance as required by specification. The Fizeau interferometer is the primary tool in this optical validation process. It provides the standard against which other optics are compared. Therefore proper use of a Fizeau interferometer ensures that the resulting data can be employed as a pass\/fail criteria on the component or system. References J. Geary, Introduction to Optical Testing, Vol. TT 15, SPIE Optical Engineering Press (1993). P. Hariharan, Basics of Interferometry, Academic Press (1992). D. Malacara, Optical Shop Testing, 2nd edition, John Wiley (1991). L. Selberg, quotInterferometer accuracy and precision,quot in SPIE Proceedings, Vol. 749, pp. 8-18 (1987) and in Vol. 1400, pp. 813-820. P. Yoder, Opto-Mechanical System Design,quot Marcel Dekker, Inc., 2nd edition (1993). J. Geary and L. Parker, quotNew test for cylindrical optics,quot Opt. Eng. 26, 8, pp. 813-820.","Lesson ID":717}
{"Driving Event":"This Lesson Learned is based on Reliability Practice Number PD-AP-1312, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. The use of the team approach to fault-tree analysis permits a rapid, intensive, and thorough investigation of space hardware and software anomalies. This approach is specifically applicable when the solution of engineering problems is urgent and when they must be resolved expeditiously to prevent further delays in program schedules. The systematic, focused, highly participative methodology permits quick and accurate identification, recording, and solution of problems. The resulting benefits of the use of this methodology are reduction of analysis time, and precision in identifying and correcting deficiencies. The ultimate result is improved overall system reliability and safety. Implementation Method: Determination that a Team Approach to Fault-Tree Analysis is Required: In situations where program hardware or software anomalies are uncovered which could potentially reduce the possibility of mission success or cause harm to personnel, and where the pressure of schedules requires a rapid and accurate solution of problems, the team approach to fault-tree analysis should be strongly considered. Fault-trees are necessary when the system in question is complex and has many potential contributors to the problem so that the solution defies simple intuition, engineering judgement, or easy elimination of the events that contributed to the problem. The team approach to fault-tree analysis brings all disciplines to bear simultaneously in an interactive but controlled environment. A fault-tree is defined as, quota graphic depiction or model of the rationally conceivable sequences of events within a complex system that could lead ultimately to the observed failure or potential failure.quot It is a systematic approach to fault prevention achieved by postulating potential high level faults, and identifying the primary and secondary causes, down to the lowest piece-part, that could induce the high level fault. A typical arrangement of a fault-tree showing the potential types of quotgatesquot containing Boolean logic is shown on Figure 1. In situations of high urgency and cost or schedule sensitivity, it is often desirable to apply a team approach to development and use of the fault-tree methodology. [D] Fault-Tree Team Methodology: The keys to a successful team approach to a fault-tree analysis are: (1) selection of the right people to participate in the analysis; (2) interactive meetings of these people in a creative but focused environment; (3) thorough documentation of objectives, fault-tree structure, and action items; (4) parallel (but not redundant) participation by all team members; and (5) careful attention to general ground rules for effective team dynamics. All of the preceding must be backed up by a data base containing the hardware\/software configuration, operational time lines, potential failure causes, and exonerating or indicting data. Logic flow networks are built based on the system's design, then laboratory test results, hardware\/software test results, and modeling based on deterministic and\/or probabilistic statistical analyses. These logic flow networks also feed into the information data base that is used by the fault-tree team. An integral part of successful fault-tree methodology is the selection of an orderly structure on which to base the fault-tree and the team participation. The Work Breakdown Structure (WBS) is an ideal starting point for the team as well as for the design. Each event or activity in the WBS is subdivided into its main contributing events or activities, then the tree is subdivided again until the smallest activity that cannot be further subdivided is reached. These final events or activities are the quotleavesquot on the fault-tree. Team Composition: Given the nature of the failure or anomaly being investigated, people should be assembled who have both an intimate disciplinary knowledge and a knowledge of the overall system. Elements heads and subteam leaders should be established for major investigative elements of the work breakdown structure. Important administrative functions to support the team are: (1) the maintenance of a current address, phone, and fax listing of all persons involved; (2) recording daily team meeting minutes; (3) preparation of agenda for the next day, (prepared at the end of the current day); (4) recording of all action items including the name of the person responsible, suspense dates, and the specific action required; and (5) the maintenance of a master schedule of major planned events, based in part on the suspense dates. Team Dynamics and Work Strategy: The entire team should meet together in one location in a meeting to expose all known data related to the anomaly or failure, then the team should meet at least once per day thereafter. Action items should be assigned and as much work as possible should be done in parallel without undue redundancy. Series activities of the team should be avoided. Team interaction is important because the fault-tree is built in a dynamic, contributory fashion. During the fault-tree team activities, the team leader and scribe should keep files of action items, agendas, technical data related to development of the fault-tree, correspondence, administrative reports, the master fault-tree diagram, and the team's schedule. Top management and other related organizations should be kept informed as to the progress of the team. Hand written notes to the key players from the team leader quoten route,quot at key milestones and critical junctures, and on successful completion of the investigation are particularly helpful. Rambling discourses should be avoided. Meetings and discussions must be diplomatically kept on track. The leader should be as democratic as possible in team meetings. No one should be affronted, but in case of an impasse, the team leader must make the decision. Refreshments should be provided occasionally, especially on Saturday or Sunday and after hours. This will boost morale and provide an atmosphere conducive to free discussion. Other General Techniques and Methods: The purpose of the team approach is to provide multidisciplinary perspectives that will uncover details and to resolve cause\/effect relationships which may not be apparent in more narrowly focused detailed engineering analytical and design methods. Therefore, each element of the fault-tree must be doggedly and systematically analyzed, persistently subdivided into it's smallest elements, and pursued to the lowest level. The history of these types of investigations has indicated that a methodical, vigorous assessment is needed to develop and to utilize a fault-tree of sufficient depth. This vigorous assessment will eliminate illogical assumption, identify or eliminate synergistic effects, help to avoid partial fixes and reduce intuitive or random approaches that cannot be substantiated. The team should resist the temptation to preconceive a conclusion or take on a quotpet theoryquot to the exclusion of a systematic, orderly, and vigorous treatment of all elements in the decision tree. The team should avoid any tendency to slow down the analysis process or to assume that a conclusion has been reached when a likely cause candidate has been identified, because this potential candidate could mask the true cause or divert the team's attention from a more fruitful path. Probability and statistics are important disciplines to use in the fault-tree analysis process. The team should have an appreciation of the fact that if it is necessary to stack too many possible events together to eventually postulate the occurrence of the failure, then it is improbable that it occurred in that manner. The references list several computer-aided fault-tree analysis software packages that will aid in performing the statistical analysis and informing the decision tree graphics required to document a fault-tree analysis. Technical Rationale: The team approach to fault-tree analysis described in this practice was used very successfully in a number of in-depth investigations of problems that occurred in propulsion elements of the Space Shuttle, and related facilities and equipment. The procedure was first used in full measure in the investigation of a fire in the casting pit of the Space Shuttle Solid Rocket Motor (SRM) in 1984. It was also used in identifying causes of problems in the SRM propellant mix facility. Several problems and potential problems with the Space Shuttle Main Engine (SSME) were successfully investigated using the team approach to fault-tree analysis. These investigations involved the bearings for the alternate turbopump, and a synchronous vibration problem. Hydrogen leaks in the Space Shuttle Columbia were investigated and successfully resolved in an in-depth and intensive three-month team approach to fault-tree analysis. References Dhillon, Balbir S: quotFault-Tree Analyses,quot (Chapter 20 of quotMechanical Engineers Handbookquot) John Wiley & Sons, New York, NY, 1986. Koren, James: quotComputer-Aided Fault-Tree Analysis (CAFTA) User's Manual,quot Science Applications International Corporation, Los Altos, CA, 1993. Van Fleet, Kevin: quotRisk Spectrum Fault-Tree Software,quot User's Manual, Innovative Software Designs, Inc., Baltimore, MD, 1993. Wild, Tony, Ph.D.: quotTree Master Software,quot User's Manual, Management Sciences Incorporated, Albuquerque, NM, 1994. Schwinghamer, Robert: quotLeak Team's Final Eureka Anthemquot Hydrogen Leak Investigation Team Final Report (Presentation), NASA, Marshall Space Flight Center, A-L, November 8, 1990. Reliability Preferred Practice PD-ED-1208 - quotStatic Cryogenic Seals for Launch Vehicle Applicationsquot","Lesson ID":757}
{"Driving Event":"The primary cause of the Magellan mishap was the inadvertent mating of at least two pins of the spacecraft harness connector P2 to connector J3 of battery 1. The mismate of these connectors created an electrical short circuit within the J3 connector that resulted in electrical arcs and additional short circuits that, using the energy stored in the battery, produced damage to battery 1, connector P2, and the battery thermal blanket.","Lesson ID":53}
{"Driving Event":"The Viking and Voyager onboard tape recorders contain a mechanism to provide knowledge, via downlink telemetry, of the position of the tape. The project can also command the tape to a desired position by uplink telemetry. The design is such that an intolerable amount of error accumulates during normal use requiring an arduous workaround involving periodic interruption in use to reset the position indicator at a known tape position (i.e. beginning of tape). Additional Keyword(s): Positioning Devices","Lesson ID":380}
{"Driving Event":"On February 26, 2010, at 2330 hours, on Complex 39 A Mobile Launch Platform 0' level, the STS-130 Final Inspection Team (FIT) began their T\u20133-hour walk down. The operator, a NASA FIT engineer, started to configure, pressurize, and power up the MacDonald, Detwiller, and Associates (MDA) Prototype Ice Detection Camera (IDC). Figure 1: Overall IDC Configuration The operator reported that the initial GN2 supply cylinder pressure reading was 2,900 psi. He then turned the IDC single-stage regulator gauge valve and observed a pressure increase to 10 psi (the nominal operational pressure setting). After adjusting the IDC rapid-exchange valve and completing the power-up sequence, he observed an immediate loss of system pressure, with the GN2 supply cylinder and pressure regulator reading 0 psi. He then turned off the electrical power, closed the GN2 supply cylinder valve, and proceeded to the pad surface to retrieve a spare GN2 cylinder. When he returned, he moved the IDC outside the west elevator at the Fixed Surface Structure (FSS) 95' level and secured the spare GN2 bottle. But because the FIT was preparing to move to the 255' level, he did not complete the gas and pneumatic connections. Upon arrival at the 255' level, the operator rolled the IDC from the elevator to the southwest corner, where he connected the GN2 gas bottle. While making the connection, he looked at the single-stage regulator gauge but did not touch or adjust it. He opened the GN2 supply cylinder valve slightly and then heard what he described as a \u201cloud whine and a pop.\u201d The panel glass had shattered (see figure 2). Figure 2: Sudden Pressure Change Shattered Display Panel","Lesson ID":4456}
{"Driving Event":"As part of the Space Shuttle Orbiter\u2019s redundancy management system, critical LRUs are provided with redundant power. This allows the LRU to continue to function if one of the Orbiter\u2019s electrical power busses goes down. Separate and redundant busses are wired into the LRU, where internal \u201ceither\/or\u201d circuitry allows the LRU to continue functioning when a bus fails. The OMRSD requires verification of this redundancy as part of the processing flow. This verification drives the performance of serial Orbiter Maintenance Instructions (OMIs) to manually drop the busses and verify that the critical LRUs continue to operate on redundant power. OMIs such as OMI V1161 are serial in the test flow because no other testing can take place while the busses are manually dropped. Mission visibility of critical LRU bus redundancy is extremely limited. There is no health status indication that a particular LRU has the required bus redundancy. During ground testing, the bus drop tests only verify that the required redundancy is available at the time of the test.","Lesson ID":3761}
{"Driving Event":"A shuttle orbiter General Purpose Computer (GPC) at Input Output Port (IOP) No.2 was voted out of a set with other computers. The computers were exchanged and the computer connected at IOP No.2 also malfunctioned, indicating the problem was with the IOP. A pin solder joint was found to be fractured. The unit was repaired without investigating the cause of the joint failure. Rework procedures were revised to require an investigation of the cause of a failure before any attempt to repair the failed component.","Lesson ID":10}
{"Driving Event":"While performing electrical checkout of a newly manufactured electronic component, erratic high-current measurements were noticed. Some technicians in the area believed they also occasionally smelled something burning. While a drawer was removed for other troubleshooting, it was noticed that the wires connected to a contactor were loose. After removing the contactor cover, overheating of the lugged wires and nut\/bolt connection was obvious; there was discoloration typical of high temperatures. The contactor cover was also slightly melted and burned. This high-resistance connection caused overheating when large currents were flowing. The wire lugs were welded to the bolt and the nut could not be removed (or tightened). The contactor had to be replaced and the wires re-lugged. Root cause: Nut tightness check was missed during in-process assembly inspection. The company that assembled the console did not tighten the contactor wires. The nut was spun on to the bolt, but it was not even finger tight.","Lesson ID":1229}
{"Driving Event":"Before the first Mercury encounter, the MVM'73 high gain antenna suddenly lost 3 dB in gain and changed from circular to linear in polarization. Ground testing on a similar antenna determined that a short circuit within the S-band feed cavity reproduced these effects as well as the observed changes in internal antenna temperature and standing wave ratio. Successful anomaly resolution during the flight included an induced temperature change by solar illumination to \"heal\" the antenna, permitting the planned mission. The development organization was very instrumental in the correction of the problem. They theorize that either a short circuit occurred as the result of particles or chips left in the cavity after antenna assembly or a combination of tolerance build-up and thermal effects caused a dimensional change. Additional Keyword(s): Operations","Lesson ID":395}
{"Driving Event":"JPL flight projects have a history of susceptibility to corona when exposed to regimes of critical pressure during ground test and flight: Ranger 6 (in-flight): During launch the camera was inadvertently powered. In addition a nearby enclosure was insufficiently vented for boost pressure decay. As the spacecraft passed the critical pressure region, a corona discharge occurred, disabling the camera system. The result was a complete loss of imaging data. 1971- Mariner Mars (ground): During acceptance testing, it was found that a lack of RF breakdown margin at critical pressure necessitated costly design changes. 1971- Mariner Mars (in-flight): Unexpected battery venting caused a brief critical pressure region around the high voltage Canopus star tracker, resulting in a corona discharge. The arc caused a ground-loop current spike that resulted in the permanent loss of 22 telemetry channels in the Flight Data Subsystem (FDS). 1976- Viking 2 (in-flight): The Viking Lander's downlink failed while on the surface of Mars. This suggested that the high voltage power converter developed a corona discharge and high voltage breakdown while in the critical CO2 pressure region present near the surface of Mars. [D] 1976- Voyager (ground): Design verification disclosed voids in certain capacitors which could bleed down to critical pressure after long exposure to vacuum, and could lead to a corona discharge. 1988- Galileo (ground): The vendor's vacuum chamber was purged with dry nitrogen while the extreme ultraviolet (EUV) instrument was powered. This produced a critical pressure region, corona discharge, and failure of the EUV high voltage power supply. 1989- NSCAT (ground): Windings added to a traveling wave tube amplifier (TWTA) transformer for test purposes, resulted in increased voltage in the primary windings, which triggered a corona discharge. 1989- Magellan (in-flight): The pyrotechnic firing which separated the solid rocket motor, used for Venus Orbit Insertion, resulted in a plasma arc, a ground current loop, and destruction of a significant amount of spacecraft memory. 1990- Mars Observer (ground): Due to inadequate insulation of the TWTA, a corona discharge occurred at critical pressure during evacuation of the vacuum chamber. Additional Keyword(s): Electrostatic Discharge Reference(s): JPL D-8208, Design and Fabrication Requirements, Section 3.9: quotHigh Voltage Requirementsquot, Rev. C, March 15, 1997. A. Whittlesey, quotMISR Corona Issues,quot JPL IOM 5215-94-75 (MISR DFM # 380), March 17, 1994. quotProceedings of the Second Workshop on Voltage Breakdown in Electronic Equipment at Low Air Pressures on March 5-7,1969,quot JPL TM-33447, June 30, 1970. quotRF Breakdown in Mariner Mars '71 RFS Components and Circuits,quot JPL Lesson Learned No. 3-115; JPL Problem Failure Report (PFR) No. 100789. quotHigh Voltage Capacitor Used in Voltage Doubler Circuits for Space Applications,quot JPL Lesson Learned No. 3-117. quotTraveling Wave Tube Amplifier on Martian Surface: Failure Due to Corona,quot JPL Lesson Learned No. 3-119; Viking Incident Surprise Anomaly (ISA) Report No. 15643, October 13, 1976. JPL Galileo PFR No. 44450. JPL NSCAT PFR Nos. 52102 & 52103. JPL Mars Observer PFR No. F0745. JPL Magellan PFR #52235.","Lesson ID":598}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) A deficiency was discovered during circuit design verification which might not have shown up during testing. The condition involved capacitors having a large AC voltage between the capacitor body and its surroundings, and the capacitors having air pockets or voids between the body and the outside jacket. The finding is significant because this condition can remain harmless at atmospheric pressure, yet lead to corona and possible failure after months or years in the vacuum of space. To solve an interaction problem between the Voyager Traveling Wave Tube (TWT) and the power supply, the designer added a voltage doubler circuit having capacitors as integral parts of the circuit. The standard high-voltage capacitors initially used have the outside of the body taped to provide a moisture barrier. The doubler operates at 7.2 kHz with an input higher than 300 volts AC. The action of a voltage doubler is such that the two plates of the capacitors used change potential each time the inverter switches. The transformer winding that drives the doubler capacitors is referenced to the TWT collector through a diode bridge. Each winding output is, therefore, near collector voltage on one half cycle and changes by the transformer winding's output voltage (about 700 V) on the next half cycle. When the combined problem of the high AC voltage and the trapped air pockets was realized, the designers specified that modified capacitors, not having the tape wrapping, be procured. These were then specially prepared by vacuum coating with Scotchcast 281.","Lesson ID":417}
{"Driving Event":"The KSC work control documentation system, which controls and records space shuttle processing, has evolved from three manned space flight programs: Mercury, Gemini, and Apollo. It provides the key to vehicle configuration control, proper definition and authorization of the work to be performed, the assurance of adequate work having been performed after closeouts, and traceability and accountability for actions performed. Inadequacies were uncovered in the form of a lack of timely closures recorded on completed work items; poor annotation of the steps taken in performing authorized deviations; missing signatures and quality control stamps (an average of 1\/4 of 1% missing); and a lack of traceability.","Lesson ID":189}
{"Driving Event":"During integration of the Genesis spacecraft, many flight and ground support equipment (GSE) cables were found to be electrically incompatible with spacecraft systems although they matched the cable wiring diagrams. Several times, testing had to be halted and the system analyzed for possible electrical overstress caused by power having been applied to the wrong pins. Eventually, spacecraft testing was stopped long enough to perform a pin-by-pin comparison of the cable wiring diagrams to the latest unit and system schematics. Once this was completed, errors were identified, the cables were reworked, and the problems were resolved. The accuracy of cable wiring diagrams was a continuing problem on Genesis. Typically, cables are built by cable harness shops to the specifications provided by cable drawings and cable wiring diagrams. Cable design and fabrication may take place concurrently with the design of spacecraft black boxes. As a system design evolves and pin-out requirements change, there is a time lag before the interface control drawing (ICD) is updated and the changes flow back to the cable design and documentation. Should the cables be built to an outdated document, the first powering of a given spacecraft may cause major damage. Since the connectors still mate with their assigned receptacles, the electrical mismatches may not be apparent. Validating the cable harness configuration against unit and system schematics is a very time-consuming activity. If it is delayed until integration and test has already commenced, the task can impact the project schedule. References: JPL Lesson Learned No. 1201, \u201cFlight Hardware Damage Due to Inadequate Planning and Insufficient QA Involvement,\u201d April 25, 2002. JPL Lesson Learned No. 0573, \u201cPower Bus\/GSE Sneak Paths May Energize Spacecraft in the Ground Test Environment,\u201d October 22, 1997.","Lesson ID":1336}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1209; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Heat pipes use the latent heat of vaporization of a working fluid to transfer heat efficiently at a nearly constant temperature. This characteristic can be used to control the temperature of spacecraft components and systems. The Goddard Space Flight Center (GSFC) has chosen ammonia-charged aluminum heat pipes for most near-room temperature (200\u00b0K to 350\u00b0K) applications. The axial groove aluminum pipe is the design of choice, because it is easy to design and relatively easy to fabricate. The aluminum container and axial grooves are extruded in one process. At the operating temperature of unmanned spacecraft, ammonia has the most favorable thermodynamic properties that make it an excellent heat pipe working fluid. Anhydrous ammonia is compatible with the aluminum heat pipe body and wick if proper care is taken in the manufacturing process. Implementation Method: All heat pipes have three physical elements in common. These include an outer container, a small amount of working fluid, and a capillary wick structure. In addition to these basic components, heat pipes may also include gas reservoirs (variable conductance\/diode heat pipes) and liquid or gas traps (diodes). Functionally, the heat pipe consists of three sections: evaporator, condenser section, and adiabatic regions. The evaporator section is mounted to the heat-producing components, while the condenser is thermally coupled to a heat sink or radiator. The adiabatic section allows heat to be transferred from the evaporator to the condenser with very small heat losses and temperature drops. Figure 1 depicts the basic heat pipe. [D] Heat pipes can operate in the fixed conductance, variable conductance, or diode mode. The fixed conductance heat pipe can transfer heat in either direction and operates over broad temperature ranges, but has no inherent temperature control capability. Constant conduction heat pipes allow isothermalization of shelves, radiators and structures; spread heat from high heat dissipating components; and conduct heat away from heat producing devices embedded within instruments and satellites. In the variable conductance heat pipe (VCHP), a small quantity of non-condensable gas (NCG) is loaded into the heat pipe. The VCHP can be used to control the temperature of equipment within very narrow limits; control is possible to less than 1\u00b0K by using careful design techniques. This is accomplished by controlling the location of the NCG\/vapor interface within the condenser end of the heat pipe, thereby varying the active length of the condenser and causing a modulation in the condenser heat rejection capability. Temperature control of the attached device is achieved by an active feedback system consisting of a temperature sensor at the heat source and a controller for a heater at the NCG reservoir. The heater causes the gas in the reservoir to expand, thus moving the gas\/vapor interface. Diode heat pipes permit heat to flow in one direction and inhibit heat flow in the opposite direction. Specific benefits of heat pipes are: 1) heat pipes have enormously more heat transfer capability than other methods on a weight and size basis, 2) heat pipes permit configuration flexibility in contact areas with heat sources and heat sinks, 3) heat can be transported over considerable distances with insignificant temperature drop, 4) capillary pumping in the wick is generated by the heat transfer process and requires no other power or moving parts to pump the condensate, and 5) heat pipes operate satisfactorily in a zero gravity environment. The choice of working fluid is dictated by several considerations, including operating temperature, latent heat of vaporization, liquid viscosity, toxicity, chemical compatibility with container material, wicking system design, and performance requirements. Figures 2 and 3 and Table 1 depict some of the above characteristics for several fluids. The highest performance from a heat pipe is obtained by utilizing a working fluid that has a high surface tension (s), a high latent heat (l), and a low liquid viscosity (n1). These fluid properties are contained in the parameter N1 the Liquid Transport Factor. Figure 4 is a plot of N1 for five typical heat pipe working fluids. These data are used as selection criteria for heat pipe working fluids. Once an application is defined, the heat pipe designer reviews the requirements and selects the best working fluid. Below the freezing point of water and above about 200\u00b0K, ammonia is an excellent working fluid. Regardless of the fluid chosen, minimum purity must be at least 99.999 percent. A careful analysis of the purity of the ammonia should be obtained from an independent laboratory prior to use. [D] [D] [D] Table 1: Comparison of Latent Heat to Specific Heat for Typical Heat Pipe Fluids FLUID PROPERTIES FLUID BOILING POINT &$176;K LATENT HEAT kJ\/kg hfg SPECIFIC HEAT kJ\/kg-\u00b0K cp RATIO K hfg\/cp Helium 4 23 4.60 5 Hydrogen 20 446 9.79 46 Neon 27 87 1.84 47 Oxygen 90 213 1.90 112 Nitrogen 77 198 2.04 97 Argon 87 162 1.14 142 Propane 231 425 2.20 193 Ethane 184 488 2.51 194 Methane 111 509 3.45 147 Toluene 384 363 1.72 211 Acetone 329 518 2.15 241 Heptane 372 318 2.24 142 Ammonia 240 1180 4.80 246 Mercury 630 295 0.14 2107 Water 373 2260 4.18 541 Benzene 353 390 1.73 225 Cesium 943 49 0.24 204 Potassium 1032 1920 0.81 2370 Sodium 1152 3600 1.38 2608 Lithium 1615 19330 4.27 4526 Silver 2450 2350 0.28 8393 [D] The outer container usually consists of a metal tube to provide mechanical support and pressure containment. The chosen design and processing of the container are extremely important in selecting the metal, because they can affect the useful life of the heat pipe. In addition, a compatibility must exist between the pipe material and the working fluid. For heat pipes, working fluid\/container compatibility issues encompass any chemical reactions or diffusion processes occurring between the fluid and wall\/wick materials that can lead to gas formation and\/or corrosion. Table 2 lists the compatibilities of several metals and working fluids. Along with the metal\/fluid compatibility, other considerations in the metal selection are ease of working the material, extrusion capability of the material, and its weldability. Proper container cleaning and heat pipe processing procedures are of extreme importance, since residual contamination within the heat pipe may also lead to gas generation. Steps must also be taken to ensure the purity of the fluid charge; trace amounts of water in ammonia can lead to a reaction with the aluminum container and the formation of hydrogen gas. Chi [reference 1] and B & K Engineering [reference 2] list standard cleaning and filling methods for a variety of working fluid\/wall material combinations. Special consideration must be given to the processing of heat pipes to be used at temperatures below 250\u00b0K. As the temperature drops, the vapor pressure of the fluid falls off. This allows any non-condensable gas created by contamination to expand, thus creating an even larger problem. The heat pipe wick structure provides a porous medium for the formation of liquid menisci (which cause the capillary pumping action) and a vehicle for returning the working fluid from the condenser to the evaporator. To accomplish these wick functions effectively, the designer must provide pores, cavities, or channels of the right size, shape, quantity and location. An optimization technique is used in wick design to find the desired combination of ultimate heat transfer capacity, pumping capability, and temperature drop. The designer must also consider ease of wick fabrication, compatibility with the working fluid, wetting angle and permeability of the selected wick material. Figure 5 depicts a cross-sectional view of an axial groove wick; this design probably is the most commonly used for space application. [D] In addition, X-ray certification of all welds at the end caps and fill tube is required to ensure good weld penetration and the absence of voids. The heat pipe container must be pressure tested to at least twice its maximum expected operating pressures (MEOP) prior to filling [reference 3]. Other qualification procedures include performance tests at adverse tilt angles to demonstrate proper wick function, and gas pocket tests performed with the heat pipe in the reflux mode. Heat pipes should be handled with care, especially those that contain ammonia or other high vapor pressure fluids. They should be treated as any other pressure vessel, and appropriate safety precautions must be exercised. Exposure to ammonia vapor can cause severe irritation to eyes and other mucous membranes. Exposure to ammonia liquid can cause severe burns to the skin. Whenever possible, heat pipes should be stored in a cold, dry environment. This will inhibit any internal chemical reactions which produce non-condensable gas. Technical Rationale: Spacecraft applications to date have been for heat pipes operating between 200\u00b0K and 350\u00b0K. Consequently, a working fluid whose freezing and boiling points encompass this temperature range and has a high latent heat, a low viscosity, and high heat transport capability must be selected. GSFC has selected ammonia as an appropriate working fluid whose fluid properties meet these criteria. However, for safety reasons, the toxicity of ammonia precludes its use in manned environments such as the shuttle cabin [reference 4]. GSFC has selected aluminum alloys, such as 6061 and 6063, for the container material of the heat pipe because of their long-term compatibility with ammonia (see Table 2); heritage; ability to have an extruded axial groove wick structure; ease of fabrication, shaping, and configuring; good thermal compatibility with aluminum radiators and heat sinks; and weldability characteristics. References: Chi, S. W., quotHeat Pipe Theory and Practice,quot Hemisphere Publishing Corp., New York, 1976 Brennan, P. J., and Kroliczek, E. J., quotHeat Pipe Design Handbook,quot B & K Engineering, Inc., Towson, Maryland, 1979 MIL-STD-1522A (USAF), quotMilitary Standard General Requirements for Safe Design and Operation of Pressurized Missile and Space Systems,quot May, 1984 NSTS-1700.7B, quotSafety Policy and Requirements for Payloads Using the Space Transportation Systemquot, January, 1989","Lesson ID":698}
{"Driving Event":"Safety Mishap on the KC-135. An experiment rig that is flown on the KC-135 utilized a quick-release V-band to seal a pressurized chamber. The chamber was used to conduct combustion experiments during the KC-135 flight. The v-band was implemented in order to permit quick and easy access to the chamber interior in order to change samples and access interior components and instrumentation. During the KC-135, the V-band was released when the chamber was still pressurized. Once the V-band was released, the chamber lid was propelled off the chamber and across the plane's cabin area. The lid just missed one of the experiment operators and caused damage to one of the plane's interior lights. The experiment operation procedures had steps to identify relief of pressure, but those were skipped, and the V-band and chamber lid design contain no other lid retention element.","Lesson ID":1069}
{"Driving Event":"Shortly after separation of the Wide-Field Infrared Explorer (WIRE) spacecraft from the launch vehicle, venting of the secondary cryogen tank was commanded, as planned, to dissipate the heat absorbed by the cryogen since termination of ground cooling. Venting this small amount of hydrogen gas was expected to induce some tumbling of the spacecraft. This tumbling was also expected to be quickly dampened by the attitude control system as the solid hydrogen reached equilibrium with the low space-ambient temperature. Instead, the spacecraft was observed to be tumbling too fast to be countered by the reaction wheels and magnetic torquers--an out-of-control condition. A NASA review board determined (reference 1) that an error in the design of the pyro electronics caused premature release of the telescope cover when the secondary cryogen tank was vented. The cover release permitted a large heat load into the cryostat that caused greater and more prolonged cryogen venting then expected following the transient associated with secondary vent actuation. A \"T\" fitting had been placed at the vent outlet to balance the thrust induced to the spacecraft by the gas flow expected from the planned venting sequence. However, design analysis did not consider the torque effects of worst case transient flows caused by one side of the \"T\" pointing directly at a connector (added as a late design modification during integration). The combined applied torque to the spacecraft from the initial secondary vent transient and the effects of early cover release was greater than the attitude control system capability. An independent analysis performed by a member of the WIRE JPL Review Board (reference 1, appendix E, p. 91) indicated the possibility that the normal secondary vent actuation transient could have exceeded attitude control capability. This could significantly impact early science return since it would take many days to reestablish a stable spacecraft attitude. Venting analyses performed during the design phase considered only the steady state cryogen flows expected during primary mission science pointing. However, the premature release of the instrument cover, and resultant boil-off of the cryogen required for telescope operation, was determined by the review board to be the direct cause of the WIRE mission loss (references 1 and 2). It was also determined that the design characteristics of the cryogen tank vent outlet prevented timely control of spacecraft attitude following the cover release anomaly, and the venting-induced torque deterred any productive efforts to save the mission. Additional Keyword(s): WIRE failure, thrust vector, thrust neutralizer, telemetry, angular velocity, roll rate, magnetic torquer, spacecraft spin, torque rod, impingement, subsystem and instrument development Reference(s): WIRE Mishap Investigation Board Report, NASA, June 8, 1999. Transient Performance of the WIRE Pyro Electronics, Lesson Learned No. 0634, August 12, 1999.","Lesson ID":640}
{"Driving Event":"One Voyager 20-watt Solid State Amplifier (SSA) failed to operate upon application of input power during spacecraft system test. The SSA provides RF power for the downlink. This problem had not occurred during many previous power applications to this SSA nor on any other SSA. In flight, this failure would render the SSA useless. Post-test analysis determined that a relay hangup had occurred following the previous application of power. The relay anomaly involves OP-AMP operation below normal voltage, energy stored in capacitors, and the relay switching voltage threshold. The original analysis had not considered decaying stored energy.","Lesson ID":282}
{"Driving Event":"Failure of one or more of these component switches 1S8, 2S8, 3S8, or 4S8 in the closed position would cause a short circuit of relay K11, thus not allowing any of the 16 bucket proximity limit switches on both buckets to stop travel. This can result in damage to flight hardware (payload and\/or vehicle) due to buckets hitting hardware.","Lesson ID":170}
{"Driving Event":"At approximately T+55 seconds the flight of the Strategic Target System (STARS) missile was terminated due to an inadvertent destruct action that occurred during an attempt to transfer control of the Flight Termination System (FTS) command receiver from the ground transmitter site, located at the Kodiak Launch Complex (KLC, Alaska) to the downrange off-axis airborne transmitter aboard a P3 aircraft. This resulted in total loss of the vehicle and the loss of the anticipated data required to meet the mission objectives. At the time of the destruct action, there were no safety problems with the missile or its trajectory. The vehicle was flying nominally and in control until the moment of destruction, and was within all prescribed safety boundaries and corridor limits for debris impact.","Lesson ID":1254}
{"Driving Event":"The Shuttle program\u2019s original specification was that all flight hardware was to be rated to survive a 200k amp lightning strike. When it came to certification testing, the flight elements applied for and were granted waivers to these requirements. It\u2019s unclear whether they would have failed the certification testing or it was too expensive to accomplish. No testing of any kind was done. Thereafter, during the major portion of the vehicles operational life, there were no fact based criteria for accessing the vehicle\u2019s flight worthiness in the wake of a direct or nearby lightning strike.Columbia Accident Investigation Board (CAIB) Report","Lesson ID":4416}
{"Driving Event":"When a quick disconnect was checked for compatibility with hydrazine the \"O\" seal disintegrated. It was found to have been made of material other than the required Ethylene-Propylene Rubber (EPR) material. The distributor had provided a certificate of conformance traceable to a seal manufacturers lot number. Upon a request for the manufacturers certificate of conformance they could not provide traceability for 40 pieces of a lot of 500 seals. They provided traceability for 460 of the seals.","Lesson ID":451}
{"Driving Event":"In the early morning hours before launch, a KSC ice team performed an inspection of the Challenger and pad. Their specific aim was to check for the amount and type of ice. They had with them an infrared gun designed to measure surface temperatures. This instrument was focused on the external tank and Solid Rocket Boosters (SRB's) during the course of the survey. The infrared gun indicated temperatures on the right SRB of from seven to nine degrees Fahrenheit, compared to 23 to 25 degrees for the left SRB. This discrepancy was not reported to launch team officials. Later, tests indicated the infrared gun requires a minimum of 40 minutes to stabilize at the temperatures experienced at KSC on the morning of the launch. The gun was focused on the right SRB prior to the time it had stabilized, indicating the readings taken were not reliable. Ice team members displayed a lack of sensitivity to potentially hazardous conditions to which they were evaluating and, nevertheless, should have reported the low readings.","Lesson ID":202}
{"Driving Event":"While pressurizing the oxidizer propellant tank, a change in ullage pressure of 8 psi occurred and caused the computer program to indicate that the interface and supply valves were closed. At this point, the engineer felt it was safe to close the dome load valve, in reality opening it. He then opened the interface valve, the pressure online with the module was 190 psig, the supply valve was then opened and the pressure spiked to approximately 400 psig, which ruptured the burst disk. The computer program indicated the incorrect status of the system because the control logic limits were not adjusted\/reset prior to starting the operation.","Lesson ID":77}
{"Driving Event":"During Orbiter Processing Facility (OPF) open bay periods the Orbiter Maneuvering System (OMS) pod handling fixture was proof loaded to 20,000 lbs. This required extensive setup, working at heights, working with suspended loads, and the setup of safety clears for two days. The 20,000-lb weights were raised to the handling fixture and then transferred from the crane hook to the handling fixture. The load was then translated full travel path both east and west. Any type of a failure at this point would have caused extensive damage.","Lesson ID":3197}
{"Driving Event":"During orbiter lift to vertical in the vab transfer isle between high Bays 1 and 2, the right hand OMS engine nozzle cover fell approximately 15 feet to the floor. The cover suffered enough damage to prevent it from being reinstalled. The cover was found to have three holding clamps that were probably defective on installation at the OPF. The left hand cover was inspected and several loose clamps were found and were tightened. Safety gave the ok to continue the lift without the cover.","Lesson ID":105}
{"Driving Event":"On April 7, 1997 a solar flare occurred with an associated coronal mass ejection and a \"coronal Moreton wave.\" These phenomena were seen in new and spectacular ways by instruments aboard the NASA\/ESA SOHO spacecraft. NASA, ESA, and NRL scientists queried by the media were excited, and their excitement about the new observations led to media reports that a massive ejection had left the Sun (true), it would hit the Earth (highly probable), at a certain time (wrong), and cause damage and outages to technical systems (highly unlikely.) Meantime, NOAA's Space Environment Center (SEC), utilizing primarily the same types of data with which we have become familiar over the last several solar cycles, regarded the flare (C6 in soft x-rays and 3N in H-alpha) to be ordinary, the coronal mass ejection to be the expected garden variety, time of transit to Earth through slow solar wind to be long, and the terrestrial effects likely to be unremarkable. The unprecedented media saturation and attention gives to this event, and the \"NASA predictions\" (which NASA scientists did not make) appearing as an official government warning, caused many systems operators to be severely shaken, As on example, NOAA's Space Environment Center had a call asking if 747s scheduled to fly across the Atlantic should be kept on the ground at the predicted time of arrival of the storm. This lessons learned document appeared in the June 1997, International STEP Newsletter, Vol. 3, No. 2 and was written by: Ernest Hildner, Director, SEC Art Poland, Project Scientist, SOHO Nicola Fox, ISTP","Lesson ID":556}
{"Driving Event":"After the STS-83 mission metallic particles were found in several locations of the SpaceLab module floor. This FOD was determined to be from the Express Rack Flight experiment, which included a Space Station International Standard Payload Rack. The source of the FOD was determined to be metal particles entrapped in inaccessible areas of the rack. All of the metal particles were trapped in the Spacelab module subfloor so there was no crew exposure to floating metal particles. The incident occurred after Boeing Huntsville had already taken steps to correct the processes that were generating the FOD so there was no impact on the factory operations. While actions to control the FOD in the assembled rack were taken prior to the flight, they were not 100% effective due to the restricted access to the rack interior once the flight experiment was assembled. Based on this incident it is apparent that extraordinary efforts will be required to ensure and maintain the cleanliness of the ISS interior hardware. There are many inaccessible areas where an inspection to ensure \"visibly clean\" will require more than a simple visual inspection.","Lesson ID":1275}
{"Driving Event":"Given the lack of guidance from the Constellation Program in the form of an Audit and Verification Plan, there was a possibility that ambiguous direction from the Ground Operations Project would hinder the verification and successful configuration of audits such as a physical configuration audit or a functional configuration audit (to be replaced by DCR and Systems Acceptance Review).","Lesson ID":4582}
{"Driving Event":"Lack of Dependency Matrix for I-Load Recalculation","Lesson ID":1125}
{"Driving Event":"The quick disconnect\/filter assemblies are designed to provide a disconnect interface and remove all solid particles which exceed 25 microns. The fluids being filtered include hydrazine (N2H4), GN2, lube oil, and water. The ground half QD assemblies interface the GSE at the ground umbilical carriers S70-0757 and S70-0758 which provide structural support and fluid containment. If the QD is mated incorrectly, it may cause the QD to leak N2H4 during fill\/drain operations.","Lesson ID":154}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique Number PM-3 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Effective development of a maintenance concept can enhance the effectiveness of maintenance support planning and aid both logistics planning and design of a maintainable system. The maintenance concept can also provide assessments of cost savings for maintenance activities and resources allowable at each maintenance level. The maintenance concept provides the basis for overall maintainability design requirements for the program, and contains detailed planning of maintenance policy for the operational system. It establishes the scope of maintenance responsibility for each level (echelon) of maintenance and the personnel resources (maintenance manning and skill levels) required to maintain a space system. Early development and application of the maintenance concept in structuring the maintainability plan can eliminate or reduce occurrence of problems that may interrupt system operation. The maintenance concept for a new system must be systematically formulated during the early conceptual design phase of a program to minimize maintenance problems during the operational phase. This proactive approach is being used on Space Station-based experiment development programs at LeRC to incorporate current Space Station Program support principles, prescribed Space Acceleration Measurement System (SAMS) and Combustion Module One (CM-1) operational and repair policy, and identified sparing requirements. Elements This maintenance concept will aid in logistics planning and will guide design by providing the basis for establishment of maintenance support requirements in terms of tasks to be performed, frequency of maintenance, preventive and corrective maintenance downtime, personnel numbers and skill levels, test and support equipment, tools, repair items, and information. Inputs to the maintenance concept should include: a mission profile, system reliability and availability requirements, overall size and weight constraints, and crew considerations. The concept should support the following design elements as they apply to a manned orbital space program where on-orbit and ground maintenance is planned. Repair Policy The repair policy should consider the support to be provided at the maintenance echelons (levels) summarized in Table 1. Table 1. Echelons of Maintenance Organizational Maintenance Depot Maintenance Where Performed On-orbit NASA Center or Contractor System Maintainer Flight Crew Center Engineers and Technicians Basis Repair and retain equipment Repair and return equipment to stock inventory Type of work accomplished Inspect equipment Repair at module, ORU, and component level Remove and replace modules and ORU's Repair and maintain ground support equipment Adjust equipment Calibrate equipment Organizational Maintenance Organizational maintenance is maintenance performed by the using organization (e.g., flight crew) on its own equipment. This maintenance consists of functions and repairs within the capabilities of authorized personnel, skills, tools, and test equipment. Organizational level personnel are generally occupied with the operation and use of the equipment, and have minimum time available for detailed maintenance or diagnostic checkout; consequently, the maintenance at this level is restricted to periodic checks of equipment performance. Cleaning of equipment, front panel adjustments, and the removal and replacement of certain plug-in modules and Orbital Replaceable Units (ORUs), referred to as black boxes, are removed and forwarded to the Depot Level. Depot Maintenance Depot maintenance is maintenance performed at NASA Centers or contractor facilities for completely overhauling and rebuilding the equipment as well as to perform highly complex maintenance actions. The support includes tasks to repair faulty equipment to the part level, if deemed necessary. This level of maintenance provides the necessary standards for equipment calibration purposes, and also serves as the major supply for spares. System Availability Operational Availability (Ao ) is defined as the probability that at an arbitrary point in time, the system is operable, i.e., is quotup.quot It is a function of the frequency of maintenance, active maintenance time, waiting time, logistics time, administrative time, and the ready time of the system, and is expressed as: [D] (1) Where: UPTIME = the total time a system is in an operable state, and TOTAL TIME = the combination of uptime and downtime, in which downtime is the time in which a system spends in an inoperable state. Repair vs. Replacement Policy Normally, on-orbit repair should not be performed on any plug-in modules or ORUs. If any on-orbit repair actions are planned, they should be clearly identified in the concept. At the organizational level, failed items should be either discarded or sent to the NASA Center or contractor for exchange and repair in accordance with repair\/discard policies identified in the system requirements. Corrective maintenance, limited to replacement of faulty ORUs and plug-in modules, should be specified to be performed during the mission period. Prime equipment should be designed to have ready access for maintenance. Quick-opening fasteners should also be specified. Level of Replacement The design for proper level of ORU definition should consider compatible failure rates for hardware parts within the same ORU. Relative ranking of ORU's through reliability and maintainability considerations and mission criticality analysis can also contribute toward the proper level of replacement definitions. The required level of replacement should be specified at the plug-in module and ORU levels. Maintenance and support of a system should involve two-tier maintenance echelons. The first level provides for repair of the end- item on-orbit by replacing select faulty or defective plug-in modules and ORUs identified through use of specified diagnostic procedures. Faulty ORUs should then be evacuated to the second level of the maintenance echelon (depot level), which will be at a NASA Center for repair if deemed necessary. The particular NASA center\/ facility should act as the depot for repair of faulty items. Skill Level Requirements Hardware should be designed to aid on-orbit and ground maintenance, inspection, and repair. Special skills should not be required to maintain a system. The following design features should be incorporated: Plug-in module and ORU design to minimize installation\/removal time and requirements for hand tools, special tools, and maintenance skills. Plug-in modules and ORUs should be designed for corrective maintenance by removal and replacement. Plug-in module and ORU designs requiring preventive maintenance should be optimized with respect to the access, maintenance hours, and maintenance complexity. Software and its associated hardware should be designed so that software revisions\/corrections can be easily installed on-orbit with minimum skill level requirements. Flight crew training for payload flight operation should identify hands-on crewmember training, at the NASA center where the system is built, to familiarize crewmembers with the removal\/replacement of hardware. Spares Philosophy Two basic types of spares should be required to support a maintainable system: development spares and operational spares. Development spares are those that must be identified and acquired to support planned system test activities, integration, assembly, check-out and production. Operational spares are those spares that must be acquired to support on-going operations on-orbit. The quantity of development spares required for each system, and the total quantities to sustain the required availability during the planned test activities, integration, assembly, and check-out test should be determined according to the following: Custom-made components\/parts Long-lead time items The quantity of spares required for each system and the total quantities to sustain the required operational availability on-orbit should be determined according to the following: Items that are critical to system operation Items that have high failure rate Items that have limited life In the initial spares provisioning period and to the maximum extent practical, spares should be purchased directly from the actual manufacturer; i.e., lowest-tier subcontractor, to eliminate the layers of support costs at each tier. The initial provisioning period should cover early test and evaluation, plus a short period of operation, to gain sufficient operational experience with the system. This will provide a basis for fully competitive acquisition of spares. Spares with limited shelf life should be identified and should be acquired periodically to ensure that adequate quantities of spares are available when needed. Spares with expired shelf lives should be removed and replaced. Procurement of spares should be initiated in sufficient advance of need to account for procurement lead time (administrative and production lead time). The location of the spares inventory (on- orbit and on-ground) should be a function of the on-orbit stowage allocation capabilities and requirements. A volume\/weight analysis should be conducted to determine the quantity and types of spare items necessary to sustain satisfactory operational availability. The volume\/weight analysis shall assure available or planned payload volume and weight limits, and planned or available on-board stowage area. Breakout should be addressed during initial provisioning and throughout the replenishment process in accordance with NMI 5900.1, Reference 1. Breakout is the spares procurement directly from the original equipment manufacturer, prime contractor, or other source, whichever proves most cost-effective. A spare item requirement list should be maintained by procurement and technical personnel. Diagnostic\/Testing Principles and Concepts The system should meet the following failure detection requirements as a minimum: The system should have the capability to detect, isolate and support the display of failures to the plug-in module level. Crew observations may be used as a method of failure detection of the following: visual displays, keyboards\/buttons, general lighting, speakers. System design should provide the capability for monitoring, checkout, fault detection, and isolation to the on-orbit repairable level without requiring removal of items. Manual override and\/or inhibit capability for all automatic control functions should be provided for crew safety and to simplify checkout and troubleshooting. All failures of the system should be automatically detected and enunciated either to the flight crew or the ground crew. Accesses and covers should be devoid of sharp corners\/edges and be equipped with grasp areas for safe maintenance activities. Systems\/subsystems\/items should be designed to be functionally, mechanically, electrically, and electronically as independent as practical to facilitate maintenance. The concept should also describe operating\/testing techniques to identify problems and consider the complexity of the various types of items in the space system and associated maintenance personnel skills (for all software, firmware, or hardware). The techniques will identify maintenance problems. In all cases of fault simulation, the safety of personnel and potential damage to system\/equipment should be evaluated in the concept. The concept should request that a safety fault tree analysis be the basis for determining simulation. Also, a Failure Modes, Effects, and Criticality Analysis should be used to evaluate and determine fault simulation. Some of the fundamental maintenance actions to be evaluated, monitored, and recorded are as follows: Preparation and visual inspection time Functional check-out time Diagnostic time: fault locate and fault isolate Repair time: gain access, remove and replace, adjust, align, calibrate, and close access Clean, lubricate, service time Functional check-out of the repair action Responsibilities for Contractor Maintenance The prime contractor's maintainability program should provide controls for assuring adequate maintenance of purchased hardware. Such assurance is achieved through the following: Selection of subcontractors from the standpoint of demonstrated capability to produce a maintainable product. Development of adequate design specifications and test requirements for the subcontractor-produced product. Development of proper maintainability requirements to impose on each subcontractor. Close technical liaison with the subcontractor (both in design and maintainability areas) to minimize communication problems and to facilitate early identification and correction of interface or interrelation design problems. Continuous review and assessment to assure that each subcontractor is implementing his maintainability program effectively. Responsibilities for Payload Maintenance Director of field installations responsible for launch preparation, maintenance, or repair activities should be responsible for maintenance planning and for providing the resources necessary to support the efficient identification of maintenance related problems in accordance with system requirements. These responsibilities include: Implementing a system that will identify, track, and status problems related to routine maintenance activities attributable to the design characteristics of flight hardware and software. Providing information for use in a data collection system to improve the accuracy of quantitative maintainability and availability estimates. This information can be used to identify failure trends influencing reliability growth characteristics during design and to communicate quotlessons learnedquot from ground maintenance experience. Recommending to the Program Manager, responsible for design and development of flight hardware\/software, areas for design improvement to increase the efficiency in ground processing or maintenance operations. The rationale for supporting these recommendations should include factors such as reduction in ground turnaround time and operational support costs. Allocation of Crew Time for Maintenance Actions Crew time for maintenance should be identified in accordance with system complexity, reliability, and criticality of the items to the system and mission requirements. Analytical methods exist which can be used to prioritize and allocate crew time for maintenance actions. References NASA Management Instruction, Spare Parts Acquisition Policy, NMI 5900.1A, NASA Responsible Office: HM\/Procurement Systems Division, Washington, DC, November 6, 1992. NASA Management Instruction, Maintainability and Maintenance Planning Policy, NMI 5350.1A, NASA Responsible Office: Q\/Office of Safety and Mission Quality, Washington, DC, September 26, 1991. NASA Handbook, Maintainability Program Requirements for Space Systems, NHB 5300.4(1E), Reliability, Maintainability, and Quality Assurance Publication, Washington, DC, March 10, 1987. Space Acceleration Measurement System (SAMS) Experiment, SAMS-SS Product Assurance Plan, SAMS-SS-005 (Preliminary), NASA Lewis Research Center, Ohio. Space Acceleration Measurement System (SAMS) Experiment, Express Payload Integration Agreement, SAMS-SS PIA, NASA Lewis Research Center, Ohio. Space Station Program, Space Station Program Definition and Requirements, Sections 3 and 4, SSP 30000, NASA Lewis Research Center, Ohio. Combustion Module One (CM-1) Experiment, Product Assurance Plan, NASA Lewis Research Center, Ohio. Blanchard, Benjamin S., Jr. and Lowery, E. Edward of General Dynamics, Electronics Division, Maintainability Principles and Practices, McGraw-Hill Inc., N.Y., 1969.","Lesson ID":724}
{"Driving Event":"An employee walked into a board with nails that was sticking out of the back of a pickup truck. The employee only suffered minor cuts and scratches to the face, but could have injured an eye. Someone else had almost ran into this board earlier, but no one reported the close call. After the close call was finally reported, action was taken to remove the hazard.","Lesson ID":531}
{"Driving Event":"Premature shutdown of the main and vernier engines occurred as a result of an electrical malfunction in the vehicle's power bus, specifically a short circuit to ground. A Mishap Board investigation concluded the most probable cause of the failure was flight vibration that induced mechanical damage to wiring insulation resulting in a short to ground.","Lesson ID":50}
{"Driving Event":"At the Loral Vought Systems in Dallas, Texas prior logbook test data history was evaluated as part of a normal failure investigation. During this review a trend in data was sometimes observed that indicated a prior drift or shift towards an out-of-tolerance condition. The Scout Program initiated a test data monitoring program on selected assemblies. Design, quality and\/or reliability engineers reviewed the test data after each retest on the assembly or vehicle level. The appropriate engineer maintained supplementary notes. The list of assemblies to be monitored grew as additional parameters were identified. Typical parameters monitored were: Spin-up time, mass unbalance and null voltages on gyros Receiver and transmitter frequencies on beacon transponders Output frequencies of voltage controlled oscillators Resistance measurements on relay assemblies Discharge times at constant current on rechargeable batteries De-spin time on bearings This practice has been in place since the beginning of the Scout Program in 1960.","Lesson ID":447}
{"Driving Event":"The accelerated schedule for the OSP program necessitated that requirements development be conducted before the OSP teams ( NASA centers and the contractors) were fully staffed. This resulted in incomplete requirements that lead to later updates and changes.","Lesson ID":10001}
{"Driving Event":"Ti can be alloyed with aluminum, vanadium, and other elements to produce strong, lightweight alloys suitable for spacecraft structures. However, suspension of Ti MIL-SPECs in the late 1990s appears to have created a window of opportunity for Ti suppliers to cut corners and supply Ti that has not undergone the required material processing. Ti material that has been \u201ccut down\u201d to the desired plate thickness rather than receiving standard thermo-mechanical processing (e.g. hot rolling the material to the procurement-specified plate thickness) may not meet the specified minimum mechanical property values. Two MIL-SPECs governing aerospace\/space-quality Ti materials (MIL-T-9046 and MIL-T-9047) were replaced by approximately 55 Aerospace Material Specification (AMS) industrial standards with various provisions for processing and certification. A TiWG was formed by JPL in November 2009 to coordinate a response to released Government Industry Data Exchange Program (GIDEP) notices concerning non-conforming Ti material delivered to the aerospace supply chain. A comprehensive report was issued by the TiWG (Reference 1). A federal indictment alleged that companies were selling non-conforming, cut-down Ti billet material as forged and rolled sheet, strip, bar, and plate. (See Figure 1 for a schematic of standard wrought Ti processing.) Cutting billet material, which may be in the 5-8 inch thickness range, to thinner cross sections and selling that product as processed plate material is not standard. Concerns included that such cut-down billet might lack the minimum structural strength indicated in the material specification, and that furthermore the accompanying material certification records may not represent properly conducted tests and correctly reported mechanical test values. Figure 1. Fabrication Process for Wrought Ti Alloy. - The complex microstructures of wrought Ti alloys are developed from combined thermal-mechanical processing of as-cast ingots through intermediate to final product forms. The microstructure and hence the mechanical properties of Ti alloys are dependent on the fabrication scheme and the thermal history. Multiple cycles of \u201cwork\u201d (e.g., heating, forging, rolling, and cooling) are required to achieve the desired microstructure required for thin plate and sheet products used for flight applications. Intermediate product forms such as billets may not have been worked sufficiently to produce the microstructure necessary to achieve minimum acceptable specification-based mechanical properties across the entire cross section. (Reference 2, p. 24) The JPL TiWG developed an approach for existing JPL spaceflight projects to assess and disposition the use of Ti in their spaceflight hardware. Approximately 50 JPL spacecraft and instrument projects in various stages of development and mission operations were assessed for non-conforming Ti and ultimately cleared by a combination of refined margin analysis, component testing, and\/or redesign. During the course of the assessment, the TiWG reviewed approximately 1000 Ti certification packages. Slightly more than 10 percent of these certifications were found to contain suspicious omissions or other irregularities. Residual material associated with four such suspicious packages was located and tested, and in all four cases they failed to meet minimum specification values such as yield and ultimate strength, elongation, and\/or reduction in area. The material property non-conformances were relatively minor, and in most cases they fell within the factor of safety employed by JPL design\/analysis practices.. In some cases, additional proof testing or testing of residual material from the same heat\/lot was required to clear certain components. Non-conforming Ti was confirmed to have entered the JPL supply chain from at least two commercial suppliers. Finally, the TiWG identified protective measures that have since been implemented to prevent non-conforming material from finding its way into JPL flight hardware. These measures secure the acquisition of Ti raw material, as well as acquisition of Ti components supplied through subcontracted manufacturers and industry partners. Among the preventive measures employed is the review of material certifications by materials and process engineering specialists before JPL procures material. Some of the JPL personnel involved in the TiWG also participated in writing a NASA handbook (Reference (2)) to aid future NASA program personnel in the process of specifying and certifying Ti alloys for flight applications. References: \u201cReport of the Ti Working Group Concerning the Assessment of Non-Conforming Material as It Affects JPL Flight Projects,\u201d JPL Document No. D-69922, September 20, 2011. NASA-HDBK-6025, Guidelines for the Specification and Certification of Ti Alloys for NASA Flight Applications, April 4, 2014. \u201cCounteracting the Threat of Counterfeit Components,\u201d NEN #1832, NASA Lesson Learned Information System (LLIS), January 15, 2008. \u201cEngineering Drawing Practices, Rev. I,\u201d JPL DocID 35596, August 20, 2012, Paragraphs 3.4.1, 3.4.2, 3.4.3, and 3.4.4. ASME Y14.100M, Engineering Drawing Practices.","Lesson ID":12901}
{"Driving Event":"External corrosion of tubing material caused leakage in a shuttle orbiter Reaction Control System (RCS) helium Quick Disconnect (QD). Neoprene tape was applied to the tubing in the vicinity of the N2O4 source. The corrosion was due to chemical attack by the products of a chemical reaction between nitrogen tetroxide (N204), propellant oxidizer, and the neoprene tape material. The products formed were nitric acid and various chlorides. Due to the presence of the nearby QD, small quantities of N204 were routinely present in the external environment upon mating and demating of the QD. An integrated materials compatibility assessment would have identified this incompatibility issue.","Lesson ID":203}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number GSE-3003 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: The benefit of using dual redundancy in critical KSC Ground Support Equipment (GSE) systems is greater assurance of successful system operation during critical shuttle processing operations in the event of a single equipment failure that would otherwise possibly cause loss of life, vehicle or damage to a vehicle system. By designing in redundancy for critical operations, the system can fail to a quotfail-safequot condition and still achieve operational objectives. Implementation Method: The Orbiter Access Arm (OAA) is a critical GSE system located at Launch Complex 39, Pads A and B, Kennedy Space Center, Florida. The OAA is extended shortly after the shuttle arrives at the launch pad to allow personnel access to the shuttle to make the necessary preparations for launch. Shortly before launch, the astronauts will board the shuttle via the OAA. The OAA provides the only path of ingress and egress to the space shuttle crew cabin for the astronauts. Thus, this system becomes critical to the safety of the crew. A critical system, as it applies to KSC GSE systems, is a system whose loss of overall system function, or improper performance of a system function, could result in loss of life, loss of the shuttle vehicle itself, or damage to a shuttle system. In addition, systems that have been identified as critical must be designed to be fail-safe. Fail-safe design provides the ability to sustain a critical system failure without causing loss of life, loss of the shuttle vehicle, or damage to a shuttle system. This includes the capability to safe the systems and successfully terminate operations, or if required, to continue operations through to completion. Therefore, the OAA system must be able to sustain a failure and still be able to perform its function to completion of the operation. In the event of a single system failure, it must fail to a safe condition, meaning a single failure will not result in loss of life, loss of the shuttle, or damage to a shuttle system. The critical condition is encountered when the OAA is retracted away from the shuttle at T-7:30 minutes in the countdown in preparation for launch. Should an emergency arise, either on board the shuttle or on the launch pad, during the final minutes of the countdown after the OAA is retracted, the OAA will need to be re-extended to allow the astronauts to evacuate the area as quickly as possible. Extension of the OAA is essential to the astronauts safety, as it is the only path available to the crew in the event evacuation of the shuttle is required. The astronauts lives depend on the OAA extending when needed. The probability of 2 redundant components failing during a critical time period is much less likely than 1 component failing during the same period. In the case of the OAA, 2 completely redundant sets of valves, plumbing, and electrical controls are installed. Based on the classical probability theory, assuming no common cause failures, it can be shown that through using dual redundancy the reliability of a system can be increased 1 or more orders of magnitude. Thus redundant system design provides protection against a single failure causing a hazardous condition resulting in loss of life, destruction of a shuttle or damage to a shuttle system. Technical Rationale: Redundancy is defined as multiple ways of performing a function. There are several different types of redundancy used on KSC GSE systems. Depending on the requirements of the application, the type of redundancy to be used will vary. The two primary types of redundancy are described below: Operational or Active quotfully onquot Redundancy - Redundant elements, all of which are fully energized during the system operating cycle. Operational redundancy includes load sharing redundancy wherein redundant elements are connected in such a manner that, on failure of one unit, the remaining redundant elements will continue to perform the system function. Switching out the failed element is not required. Operational redundancy may be either full parallel or quotmajority votequot. Standby Redundancy - A redundant hardware item(s) that are non-operative until they are switched into the system on failure of the primary item(s). Switching can be accomplished by either automatic or manual means. Other categorization of redundancy include: Like Redundancy - Identical hardware items performing the same function. Unlike Redundancy - Nonidentical hardware items performing the same function. Safety features which provide protection for specific failure modes are considered as unlike redundancy for that failure mode; i.e. relief valves which provide protection against overpressurization after failure of a regulator Typically, KSC employs parallel, two component redundancy. It can be shown that the incremental reliability gain is greatest for the first redundant unit and decreases rapidly as more redundant units are added in parallel. Figure 1 provides an example of a basic block diagram of the hydraulic extend circuit for the Orbiter Access Arm (OAA) showing the use of redundancy in a critical shuttle ground support system. [D] A hydraulic reservoir fills 4 hydraulic accumulators. Only 2 accumulators are needed to ensure arm retract and extend, but 2 additional (redundant) accumulators are provided for fail-safe operation in the event of a leak. In the event of a major leak, the launch countdown will stop. If a major leak occurs during an emergency re-extend operation, the 2 redundant accumulators should supply enough hydraulic pressure to ensure full extension of the OAA. In addition, the hydraulic supply system is capable of supplying additional pressure if required. The ensuing discussion will address the primary system only. Design of the system minimizes the likelihood of a common cause failure. The accumulators provide hydraulic fluid to a pilot valve (Primary Hydraulic Extend Pilot Valve) and to the main hydraulic supply valve (Primary Hydraulic Extend Supply Valve). When commanded by LPS (Launch Processing System), the pilot valve supplies hydraulic pressure to the Primary Hydraulic Extend Supply Valve and to the Primary Hydraulic Extend Return Valve, thus opening both valves. Hydraulic fluid from the accumulators then flows thru the Primary Hydraulic Extend Supply Valve to the upper and lower OAA hinges. Each hinge is individually capable of rotating the OAA. Thus the hinges are redundant. Fluid exits the OAA hinges, and returns to the main hydraulic reservoir through the Primary Hydraulic Extend Return Valve. This discussion described the basic operation of the primary hydraulic extend circuit for the OAA. There is a secondary (redundant) set of valves as described above installed in parallel with the primary valves, that simultaneously operate. Operational redundancy ensures that the OAA will operate when needed. A single failure will not result in a catastrophic consequence. References: O'Connor, Patrick quotPractical Reliability Engineeringquot 2nd Edition, Wiley, 1985.","Lesson ID":659}
{"Driving Event":"During the period May-July 1998, one or more of the redundant spacecraft control processors (SCPs) failed in each of three commercial communications satellites. This resulted in one of the satellites being removed from service. Three SCP failures were attributed to intermittent or continuous short circuits caused by the growth of conductive filaments, known as quottin whiskers,quot from the tin-plated surface of an electronic assembly or its cover. Although well known in the past, these recent failures have reminded the space community of the potential risks associated with the use of pure tin-plated finishes on electronic components and assemblies. While pure tin protective coatings are favored by the electronics industry because of their material properties and cost, they are susceptible to the spontaneous growth of single crystal structures -- tin whiskers. Growth occurs with pure tin plating, regardless of the presence of an applied electric field, moisture, or an atmosphere. It may begin soon after plating or may take years to initiate. Tin whiskers are capable of causing electrical failures ranging from parametric deviations to catastrophic short circuits. quotBrightquot pure tin plating has been found to be particularly susceptible to whisker growth, and the U.S. military has discouraged its use. [D] Simulation of Whisker Growth (courtesy of GSFC) [D] Reference(s): NASA Goddard Space Flight Center Tin Whiskers Information Page, http:\/\/nepp.NASA.gov\/whisker\/index.html. quotTin Plating, Whisker Growth,quot GIDEP Alert No. AAN-U-00-11, January 4, 2000. Military specification MIL-T-10727, Tin Plating: Electrodeposited or Hot-Dipped, For Ferrous and Nonferrous Metals (cancelled February 7, 1997) - refer to ASTM B545-1997, Standard Specification for Electrodeposited Coatings of Tin.","Lesson ID":924}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PD-ED-1268, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. Use of precision design; manufacturing; and advanced material selection, fabrication, and treatment techniques will ensure reliable operation of large, high performance liquid hydrogen turbopumps. Many of these practices will also lengthen the operational life of the turbopump, increasing the number of uses before teardown, inspection, refurbishment, and re-assembly for subsequent flights. In addition to higher reliability, lower costs and continued assurance of high performance are resulting benefits. Implementation Method: I. Background: The 85,000 horsepower liquid hydrogen turbopump being flown on each flight of the Space Shuttle represents almost three decades of design, development, and fine-tuning of its performance and reliability. It is a three-stage centrifugal pump driven by a two-stage hot gas turbine. The pump rotates at 37,000 revolutions per minute (RPM) which is over 600 revolutions each second. The high horsepower, high RPM, high flow rates, and high pressures in this turbopump created a unique set of design and engineering challenges to the prime contractor and to NASA (Marshall Space Flight Center). Problems have been encountered over the years that manifested themselves in bearing wear, turbine blade cracking, turbine blade erosion, and rotodynamic issues. In overcoming these problems, specific design features, materials, and fabrication methods have been developed and perfected for the hydrogen turbopump that permit the Space Shuttle Main Engine (SSME) to maintain its unprecedented high performance while exhibiting manned space flight levels of reliability. The practices that have been developed and included in this document are essential to the continued high reliability of the SSME and can also be applied in next-generation turbopumps for reusable and expendable launch vehicles. II. Bearings and Blades The two major components of the fuel turbopump that have required focused engineering and manufacturing attention are the turbopump bearings and the turbine blades. Both the bearings and the blades have performed well in initial firings and flights of the engine, but have resulted in unsatisfactory condition reports when subjected to detailed inspection on disassembly after flight. The bearings have exhibited wear before their expected rated lifetime has been reached, and tiny hairline cracks have been observed in the turbine blades. Fractures in bearing cages were discovered during disassembly inspection of the turbopump in early engines. Investigations indicated that the failures were most likely due to high cycle fatigue; and stress analyses showed a marginal factor of safety on high cycle fatigue for \"infinite\" life. Post disassembly inspection of some engines also revealed rub marks, evidence of wear, and indentations on bearing races and balls. Although the slightly damaged bearings were still suitable for development testing, a bearing wear potential prior to end of rated life still exists. Reliable, long-life fuel turbopump bearings are made possible by sophisticated cooling arrangements and by careful material selection. The fuel pump bearings are cooled by internal flows of liquid hydrogen. The coolant source for pump-end bearings, including an axial load-carrying thrust bearing, is the output of the first impeller of a three-impeller fuel pump. Liquid hydrogen flows from the back face of the impeller through orifices in the impeller hub, through the bearings, and back into the pump inlet. The bearing inner races are clamped to the pump shaft with the bearings free to slide axially within the bearing cartridge. Liquid hydrogen performs the function of a highly effective coolant because all heat is removed from the bearings, resulting in very little, if any, bearing wear. Bearing specifications are very tight, minimizing bearing defects. An alternate bearing material, silicon nitride has successfully demonstrated long life in oxygen turbopumps and the same benefits are expected in hydrogen turbopumps. The provision of ample cross-sectional area and the addition of Fluorinated Ethylene Propylene (FEP) coating to the bearing cages eliminated a bearing cage cracking problem. The turbine blades experience enormous centrifugal force loads as well as high thermal loads at 600 revolutions per second. High cycle fatigue and hydrogen embrittlement effects, have caused small hairline cracks in the turbine blades of the high pressure fuel turbopump. These cracks are an order of magnitude shallower than the critical depth of 0.100 inch, but have persisted throughout the program. Although the hairline cracks are not detrimental to performance, periodic disassembly inspection is needed to continue to monitor this condition. Attention is given to blade porosity after machining (less than or equal to 5 mil pores). Shot peening of blades on the blade-to-wheel interface improves toughness and resistance to cracking. Gold plating of blade shanks resists hydrogen embrittlement. An important design feature in the turbine blade-to-wheel connection is a \"loose\" fit that gives the blades freedom to adapt to dynamic turbine environments. III. Turbopump Seals One of the keys to high reliability liquid hydrogen turbopumps is the use of a variety of compression and flow restricting seals. The compression seals, which include gaskets and piston rings, contain the liquid hydrogen and hot gas inside the pressure vessel or chamber. Flow restricting or flow redirecting seals restrict liquid hydrogen and hot gas flow in one direction and\/or redirect flow in another. The principal types of seals are pump interstage (or \"damping\") seals, fluorocarbon seals, liftoff seals, labyrinth seals, platform seals, and turbine blade tip seals. The interstage seals permit a small amount of liquid hydrogen to flow between impeller stages. A knurled surface on the seals at the impeller interface slows down axial and circumferential flow of liquid hydrogen and traps enough fluid to provide cooling and vibration damping. Stepped fluorocarbon seals that contact ridges around the impeller face on all three pump stages control the amount of propellant flow around the impeller front shrouds. The liftoff seal assembly, which acts as a check valve ---permitting flow in only one direction---prevents hydrogen leakage into the turbine end of the turbopump prior to engine start and after engine cutoff. During engine start, a pressure unbalance develops across the seal to offset the spring load and retract the seal, allowing liquid hydrogen to enter and cool the turbine end. A turbine hub labyrinth seal directs part of the coolant flow from the liftoff seal to the bearings, disc, and coolant liner to cool the turbine end bearings and discs. Forward and aft platform seals restrict flow and enhance cooling balance while maintaining efficiency of the first and second stage turbine wheels. Turbine blade tip seals help direct hot gas flow through the turbine blades, improving turbine efficiency. One of the most critical seals in the high pressure fuel turbopump is the lift-off seal. Avoidance of contamination is important because it must act as a static seal when closed. It must avoid trapping contamination, and work properly repeatedly in the dynamic engine environment. Repeated and consistent response to pressure differentials is required. The seal must resist rubbing and wear while retaining its capability to pass fluids reliably when open and to seal off fluids completely when closed. The seal is a complex component in itself, incorporating 55 springs, guide bushings, carbon nose, adaptor, retainer plate, and additional secondary seals. IV. Materials and Fabrication Methods Because of the hydrogen environment, the wide temperature ranges, the high structural and thermal stresses, and the close tolerances encountered in the turbopump; a thorough knowledge of material properties is necessary, and precision fabrication methods must be used. A variety of manufacturing techniques are used such as TIG (tungsten inert gas) welding, EDM (electrodischarge machining), conventional machining, investment casting, CNC (computer numerically controlled) machining, broaching, grinding, polishing, and burnishing. Directional solidification is used when casting the turbine blades to produce grains parallel to the major operational stresses. Copper and gold coating and plating techniques are used to protect certain critical components such as turbine housing struts and the blade attachment \"firtree\" slots in the turbine discs from hydrogen embrittlement. Replacement of sheet metal components with castings eliminates and\/or reduces potential hardware failures due to welding defects. Replacement of some titanium rotating components with Inconel 718, the addition of a baked-on dry film lubricant, the use of stellite bore inserts, and the use of knurled pump inserts to smooth out and enhance the damping characteristics of coolants resulted in beneficial improvements in turbopump reliability and lifetime. V. Advanced Design and Inspection Methods Advanced computer simulations are now available to characterize the flows, stresses, and thermal environments in rocket engine fuel turbopumps. Computer analyses, well anchored and authenticated by thoroughly instrumented tests, will do much to provide the most reliable and effective turbopump design. Verification of design environments is essential. Advanced computed tomography inspection of critical fuel turbopump components such as the first and second stage turbine blades has been proven to be an effective way to screen the hardware for potential blade failure modes. Sophisticated analytical techniques and precise balancing methods were used in solving a \"subsynchronous whirl\" problem that caused spurious turbopump vibrations. Technical Rationale: Specific design features, materials, and fabrication methods must be used in high performance liquid hydrogen turbopumps to ensure satisfaction of performance requirements while exhibiting manned space flight levels of reliability. References Engineering Change Proposal #11-17R1: Space Shuttle Main Engine, Rocketdyne Division of Rockwell, International, Canoga Park, CA, 1988. Space Transportation System Training Data: Report No. ME-110(a) R1R, Rocketdyne Division of Rockwell, International, Canoga Park, CA, December 1991. \"Space Shuttle Main Engine Instrumented High Pressure Fuel Turbopump Technology Test Bed Testing Results Summary,\" AIAA Report No. 93-1908, June 28-30, 1993. \"Fabrication of the Space Shuttle Main Engine High Pressure Fuel Turbopump,\" Marshall Space Flight Center, Huntsville, AL, April 1994. \"Solution of the Subsynchronous Whirl Problem in the High Pressure Hydrogen Turbomachinery in the Space Shuttle Main Engine,\" Paper # 78-1002, AIAA\/SAE 14th Joint Propulsion Conference, July 25-27, 1978. Reliability Preferred Practice PT-TE-1439, \"Systems Test Considerations for High Performance Liquid Rocket Engines.\" Reliability Preferred Practice PD-ED-1269, \"High Performance Liquid Oxygen Turbopumps.\"","Lesson ID":750}
{"Driving Event":"The XTE Instrument Development Team experienced monumental problems with the development of the three small proportional counter detectors used in the All Sky Monitor Instrument. This was completely unexpected since the proportional counters were presented by the Instrument Development Team as low-risk heritage detectors that were nearly identical to detectors that had previously flown many times. As it turned out, the heritage vendor was unsuccessful in fabricating a working detector. After an exhaustive search by the Instrument Development Team, a second vendor was located in Finland. It took the new vender over a year to fabricate, test, and deliver the required three flight and one spare detector. Unfortunately, all of the detectors degraded after delivery and they needed multiple rework cycles of several months each to get acceptable flight detectors. The XTE Program Management Team was able to maintain the Mission schedule by installing degraded flight and\/or spare detectors on the spacecraft during Observatory integration, testing, and launch site activities. The flight detectors were finally installed at the launch site.","Lesson ID":479}
{"Driving Event":"As originally envisioned, inherited designs were to be used for many of the Mars Observer spacecraft's engineering subsystems. During its eight-plus year development period, however, the Mars Observer mission underwent a number of significant changes. Many of the spacecraft subsystems were so extensively modified for Mars Observer that their heritage was lost. Other subsystems, whose heritage remained intact but which were designed for an earth-orbital environment, were not requalified to verify that they would function properly on an interplanetary mission of three years duration. Examples include: The failure to fully qualify the Traveling Wave Tubes (TWT) in the transmitter power amplifiers for operation during pyro-shock events. The lack of robustness in the design of the bipropellant pressurization system for long duration missions. The use of fault-management software, containing processing algorithms derived from the Defense Meteorological Satellite Program (DMSP), that was not fully understood. Reference(s): Mars Observer Loss of Signal: Special Review Board Final Report: JPL Pub. 93-28 JPL Lesson Learned, No. 3-108, Subject: Mars Observer Pressure Modulator Infrared Radiometer (PMIRR) Cooler Failure During Vibration Testing JPL Lesson Learned, No. 10-102, Subject: Mars Observer Inertial Reference Loss IOM 525-89-344, dated 12\/14\/89, by L. E. Baughman and R. F. Draper, Subject: MMII Inheritance Reviews","Lesson ID":346}
{"Driving Event":"MSL has two lithium ion batteries that are recharged several times per day. These batteries enable the Curiosity rover\u2019s power subsystem to meet the peak power demands of Rover activities when the demand temporarily exceeds the onboard multi-mission radioisotope thermoelectric generator (MMRTG) steady output level of ~100 watts. The flight computers (labeled \u201cRCEs\u201d in Figure 1) are always shut down prior to these recharge cycles. Figure 1. MSL avionics subsystem Six months after landing on Mars (i.e., Mars sol-200), telemetry reported uncorrectable errors in the NAND flash memory (Reference (1)). Analysis revealed that several flight software (FSW) tasks had hung up, leading to an inability of the prime computer (Rover Compute Element (RCE) \u2018A\u2019) to turn off for its normal recharge session. Normally, fault protection would intervene: a watchdog timer would count down to zero and trigger a computer reboot. Instead, the watchdog timers were being reset. This could inexorably lead to a power brown-out of the Rover in three to six days: such loss of commandability that leaves the Rover discharging is a potentially mission-catastrophic event. Within 16 hours of the initial error message, mission controllers at the NASA\/Caltech Jet Propulsion Laboratory (JPL) bypassed the FSW and commanded a swap from RCE-A to the backup computer (RCE-B). Tones (i.e., \u201csignals\u201d) were subsequently received from the Rover confirming that the \u201cbackup\u201d string had become \u201cprime\u201d and had entered safe mode. Information that the new prime computer gathered from the failed computer indicated that errors in the FSW had exacerbated a hardware fault in the flash memory. The MSL Flight Team faced a situation where the Rover was effectively left with \u201csingle string\u201d avionics only 35 days prior to the Mars solar conjunction (when the spacecraft would not be commandable for 25 sols). Also, since the same FSW and flash memory were present in the new prime computer (RCE-B), the remaining string was of questionable reliability. Failure investigation indicated that a single chip in the flash memory array was generating errors during erase cycles, likely due to a connectivity problem on the circuit board, or due to infant mortality of the commercial part. (Pre-flight testing had only erased the NAND ~12 times, as compared to an additional 38 erases (Reference (2)) after launch. The NAND part should have a life of 100,000 cycles.) Spacecraft functionality was recovered by segregating the bad flash memory; a direct hardware reset then rebooted RCE-A to operate with a half-size flash file system. (Because the data storage volume was sized with substantial margin, the loss of half the memory does not impact the mission.) Also, an additional (maximum up-time) watchdog timer was added to the flight software to strengthen fault protection. However, JPL would have been unable to diagnose the problem were it not for an avionics architecture that allowed the non-prime computer to be powered and providing telemetry on its \u201chealth\u201d even when the (RAM-based) FSW was not running on it. References: \u201cDouble Bit Error was observed on NVMCAM NAND on Sol-200,\u201d JPL Incident Surprise Anomaly (ISA) No. 54013, February 27, 2013. James A. Donaldson, \u201cThe MSL Sol-200 Anomaly: \u2018The Perfect Storm\u2019 or \u2018How the MSL Avionics Architecture Enabled the Recovery of the Curiosity Rover\u2019,\u201d September 24, 2013.","Lesson ID":11201}
{"Driving Event":"The following are examples of occurrences that led to this lesson. The design of the Armadillo was supposedly baselined, but GOP personnel could not verify invitation to design reviews. Approximately 20 sets of the stabilization collar and sea anchor GSE are required to ensure worldwide rescue response capability. While expected to work closely with contractor GSE designers, KSC personnel had no authority to direct contractor activities without going through Orion Project Office at JSC. Due to the absence of a formal mechanism, an informal GSE end item requirements sheet review process was established to provide a means for NASA to review and comment to contractor-provided GSE items prior to design.","Lesson ID":5044}
{"Driving Event":"The National Oceanic and Atmospheric Administration (NOAA) weather satellite NOAA-I (NOAA-13 after launch), was launched on 9 August 1993 from Vandenberg Air Force Base. No anomalies were encountered during flight until 21 August 1993 at which time it was determined from telemetry data that while in full sun, the solar array was inoperative and that the spacecraft was being powered by the batteries. Within six orbits after observance of the anomaly, communication with the spacecraft was found not to be possible and no downlink signal from the spacecraft was thereafter detected. Upon closer examination of recorded spacecraft telemetry data, it was ascertained that the solar array was putting out electrical power, but that no power was being provided to the battery charging unit, and the batteries were not receiving a charge. Cause of the failure surmised by the cognizant operations crew and concluded by the Goddard Space Flight Center (GSFC) NOAA-13 Failure Review Board, was that the solar array bus had shorted to spacecraft ground. Specifically, constant thermal expansion and contraction in excess of previous flights was thought to have caused one or more mounting bolts protruding through the heat sink contained in the battery charging unit to penetrate isolation material and short the solar array output to ground. It is believed that a rise in temperature and resultant increase in temperature excursion were due to greater electrical power required to operate additional instruments added to the spacecraft. Reference(s): NOAA-13 Failure Report, dated August, 1994 by Goddard Space Flight Center","Lesson ID":387}
{"Driving Event":"Disassembly inspection of the Space Shuttle Orbiter OV-103 Rudder\/Speed Brake (R\/SB) actuators revealed corrosion, pitting, and wear to varying degrees, along with degradation of the lubricant, Braycote 601. A program decision was made to replace the actuators in OV-103 with the existing spares, a single ship set which had been in controlled storage for the past 17 years. An assessment was performed to address the following two issues, which had been raised within the Program Control Review Board process: Issue 1. Grease separation into its component oil and thickener is known to occur in storage. Its effect on lubricity is not known. Issue 2. Chemical reactions involving the grease and the gear\/housing material, 9310 steel, could lead to formation of Lewis acids, resulting in corrosion, pitting, and cracking. Issue 1 was addressed directly by performing lubricity testing using aged and separated grease obtained from several sources, including grease that had been removed from the OV-103 actuators. Issue 2 was addressed by measuring the thermodynamic characteristics of the corrosion process - the rate constants and activation energy - for the particular material\/lubricant combination. Both issues were shown not relevant with respect to flight safety, and the spare R\/SB actuators that had been installed on OV-103 were declared to be flight worthy. However, the existence of hardware which had exceeded its service life, within the spares inventory, as well as the actuators that had just been replaced in OV-103, raised a concern with respect to maintenance and refurbishment practices within the aging Space Shuttle fleet. This concern is the subject of an ongoing study, and the Lesson Learned is documented herein.","Lesson ID":1478}
{"Driving Event":"The Shuttle Connector Analysis Network (SCAN) system developed by the Space Shuttle Processing organization consisted of a user interface software and database system accessed by workstations throughout KSC to track an orbiter's connector configuration (mated or demated) and system retest verification. By using SCAN, the orbiter system engineers and test conductors could quickly determine the status of orbiter connector configurations. SCAN provided current listings of all demated connectors prior to system power-up. Often connector configurations would change between orbiter power-ups as a result of system troubleshooting or rework that could only be performed while the orbiter was powered down. SCAN also recorded the work authorization document that was used for performing the connector test verification after the mating of the flight hardware. The system engineer would record the system checkout for each active connector pin after the connector was mated for flight. The same process was followed if a connector was demated during ground processing (postflight mate). Ares I-X did not have a SCAN-type system, and tracking of the connector configurations before power-up was difficult. There was also no good way to verify that connector testing had been performed on a flight-mated connector. Figure 1: Graphical wire trace for path continuity Figure 2: SCAN Engineering Reports Menu","Lesson ID":3757}
{"Driving Event":"Certification of the Super Light Weight Tank (SLWT)","Lesson ID":1048}
{"Driving Event":"During the visual receiving inspection process of the fourth stage Altair IIIA motor for a 1984 launch from the Wallops Flight Facility, a delamination was found in the silica phenolic exit cone liner. A similar delamination was found in a nozzle being processed for a Vandenberg Air Force Base launch. An immediate visual, ultrasonic, and radiographic inspection of the remaining inventory of silica phenolic exit cone liner nozzles found one other nozzle that was suspect. The same inspections were completed concurrently for inventory nozzles that included graphite phenolic exit cone liners. No delamination indications were found in the carbon phenolic exit cone liners. The delamination was determined to be a moisture related problem associated with silica phenolic. A monitoring program was established for the remaining silica phenolic nozzles and carbon phenolic nozzles. This monitoring consisted of storing the nozzle assemblies in the Dallas Scout Logistics Area, monitoring humidity, and attaching gages to one of the carbon phenolic nozzles and a dissected nozzle piece to measure strain on a periodic basis. Visual, ultrasonic, and radiographic inspections were completed at Dallas just prior to shipment to verify that a flightworthy nozzle would be shipped to the field site.","Lesson ID":466}
{"Driving Event":"The vendor was required to provide replacements for aged RMS blankets. The vendor outsourced the manufacturing and provided the subcontractor with only cartoon drawings for production. Many of the replacement blankets were not usable because attachment points for Velcro and ground wires were mislocated. The vendor never provided the templates needed for manufacturing. KSC Engineering had to initiate Problem Reports so the blankets could be adjusted for use on the RMS. Figure 1: Cartoon of CCTV Bracket without dimensions or tolerances","Lesson ID":3656}
{"Driving Event":"Initial structural random vibration testing on the Stratospheric Aerosol and Gas Experiment (SAGE) III on the International Space Station (ISS) Instrument Adapter Module (IAM) and Contamination Module Package (CMP) Engineering Development Units (EDUs) showed structural responses high enough to potentially fail the CMP\u2019s Temperature-controlled Quartz Microbalance (TQM) sensors. The CMP was originally hard mounted to the top of the IAM, but this system produced amplified responses in the CMP. To reduce the response, wire rope isolators (WRIs) were installed between the CMP and IAM at the four interface locations. Initial analysis models predicted new responses which did not closely match the test results with the isolators. A stiffness and damping correlation study was done on the WRIs which showed stiffness values different than vendor-published data and non-uniform damping rates across the frequency spectrum of interest. After these variations in the isolators were included in the analysis models, predicted responses more closely matched the test results.","Lesson ID":19101}
{"Driving Event":"The ET vent line may not be secured because the deceleration unit latch mechanism fails to latch. This mechanical malfunction of the latching mechanism, possibly resulting from exposure to exhaust blast from the vehicle could cause the ET vent line to rebound and strike the vehicle.","Lesson ID":187}
{"Driving Event":"Outmoded Design of Space Shuttle General Purpose Computer (GPC) Limit Software and Hardware Upgrades","Lesson ID":1124}
{"Driving Event":"During launch and ascent, ice from the ET, SRBs, and orbiter may be dislodged by ignition vibroacoustic or aerodynamic forces and impact the orbiter windows or thermal protection system (TPS) with sufficient force to dislodge TPS or damage windows.","Lesson ID":89}
{"Driving Event":"In May 2009, a wheeled shipping crate containing an electrical ground support equipment (EGSE) rack for the Aquarius project fell off the lift gate of a contracted commercial transportation van while being unloaded. The van was parked adjacent to the receiving dock at the NASA\/Caltech Jet Propulsion Laboratory (JPL). After the crate was moved to the rear of the vehicle for unloading, the van driver\/operator manipulated the incorrect control on the powered lift gate (Reference (1)). (Figure 1 illustrates the lift gate control system's susceptibility to operator error.) This caused the lift gate to tilt instead of lower. The crate rolled off the lift gate and struck the ground, damaging the hinges and breaking off the lid. Only the crate directly contacted the ground, and the EGSE rack with its 2-inch thick foam padding remained secure within the crate. The shipping crate had four casters, but the locks on the two downhill casters were unlocked during the operation. Figure 1. Lift gate control panel on the truck that was unloading Aquarius EGSE. The diagram below the image shows that the control panel is not well designed to deter operator error. (The yellow label indicates that the dial on the right is a \u201cSlider\u201d control that positions the gate horizontally.) The EGSE rack was being removed from the vehicle because it had not been approved in the final manifest for support equipment to be transported to Argentina for Aquarius integration and test. Since a need to unload the EGSE shipping crate had been not identified to the project until just prior to the incident, there was insufficient time to coordinate and plan the EGSE off-load. Quality Assurance was present during the incident, but System Safety was not notified of this unplanned unloading of Aquarius EGSE. Two individuals were injured as a result of this incident. The first struck his head on the pavement when he fell backward while avoiding the falling equipment. The other suffered a muscle strain while trying to restrain the EGSE rack as it rolled off the tilted lift gate. The container and lid were then moved into the Spacecraft Assembly Facility (SAF) airlock for visual inspection. Visual inspection did not detect any equipment damage other than the detached shipping container lid, and the damaged shipping crate was replaced. The personnel were treated with basic first-aid, and then they returned to work (Reference (2)). The test equipment required recalibration, full functional test, and internal visual inspection. Due to a lingering concern about possible damage, however, replacement EGSE was obtained for use with Aquarius flight equipment (Reference (3)). There exists some residual concern by the Aquarius project due to the risk posed by plans to move JPL Critical Items (JCI) from Argentina to Brazil, and from Brazil to the Vandenberg Air Force Base launch site. JPL has recently revamped the process of preparing and reviewing transportation plans. The process is now reflected in the formal procedures of JPL Security, and preparation of a transportation plan is now a contractual requirement to be added to JPL subcontracts (Reference (4)). Also, the JPL Project and Engineering Management Committee (PEMC) has approved adding a transportation plan requirement to the next release of the JPL Flight Project Practices. (See Recommendation #4.) Documentation in a previous lesson learned (Reference (5)) of damage to JPL flight hardware during international transit led to a security plan requirement (Reference (6)) for shipments outside the continental U.S. References: JPL Mishap Report No. 1887, May 28, 2009. JPL Mishap Report No. 1886, May 28, 2009. quotAquarius EGSE Shipping Mishap,quot JPL Problem\/Failure Report No. 15044, May 28, 2009. quotTransportation Documentation,quot JPL Data Requirement Description (DRD) No. TE-004, April 17, 2009, in quotSubcontract Plans and Documentation for SDRL and DRDs, Rev. 0,quot JPL Document No. DocID 78172, September 15, 2009, p. 132. quotExercise Strict Controls in the Packaging and Oversight of Critical Hardware Shipped by Third-Party Courier Services,quot NASA Lesson Learned No. 1849, NASA Engineering Network, April 1, 2008. quotOff-Site Transportation of Flight Hardware, Rev. 1,quot JPL Document No. DocID 69052, July 8, 2009, Paragraph 2.2. quotShipments of Deliverable Hardware, Rev. 1,quot JPL Document No. 64352, update pending.","Lesson ID":2456}
{"Driving Event":"Hypergolic fluids are toxic liquids that react spontaneously and violently when they contact each other. These fluids are used in many different rocket and aircraft systems for propulsion and hydraulic power including: orbiting satellites, manned spacecraft, military aircraft, and deep space probes. Hypergolic fuels include hydrazine (N2H4) and its derivatives including: monomethylhydrazine (MMH), unsymmetrical dimethylhydrazine (UDMH), and Aerozine 50 (A-50), which is an equal mixture of N2H4 and UDMH. The oxidizer used with these fuels is usually nitrogen tetroxide (N2O4), also known as dinitrogen tetroxide or NTO, and various blends of N2O4 with nitric oxide (NO). Several documented, unintentional hypergolic fluid spills and fires that occurred in support of the Apollo Program, the Space Shuttle Program, and several other programs from approximately 1968 through the spring of 2009 have been studied for the primary purpose of extracting the lessons learned. Hypergolic rocket propellants have proven to be a highly reliable asset in manned and unmanned spaceflight; however, their maintenance on the ground has proven to be relatively difficult. Do the operational risks from possible human errors or hardware failures causing a catastrophic incident outweigh the usefulness of hypergols even though they have been used for the last 50 years of manned and unmanned spaceflight? One would have to say probably not, since hypergols are so widely used in the space industry currently and are being proposed to be used on many vehicles in the future. Therefore, ground operations on hypergol systems have become increasingly scrutinized for possible unknowns, and rightfully so. The data shown in this report are not an example of why we should not be using hypergolic propellants on spacecraft and launch vehicles, but rather illustrate what we can and should do to mitigate possible unforeseen ground operation and\/or design problems.","Lesson ID":2196}
{"Driving Event":"Clean room certified adhesive tape 5413 was used inadvertently in construction of multi-layer insulation (MLI) blanket for a vacuum chamber (instead of clean room certified adhesive tape 1205). The two tapes look virtually identical and are packaged similarly.","Lesson ID":536}
{"Driving Event":"On February 22, 1996, the STS-75 Space Shuttle Columbia was launched at 53\/20:18 GMT. The orbiter was inserted into a 296 km (160 nautical mile) orbit at an inclination of 28.5 degrees. The crew consisted of 7 members, including commander, pilot, 3 mission specialists, 1 payload commander, and 1 payload specialist. The TSS-1R payload was a reflight of TSS-1 in 1994, where deployer mechanism problems limited the tether deployment to slightly less than 300 m. The planned duration of the flight was 14 days. The payload bay configuration consisted of the Tethered Satellite System (TSS) experiments, two U.S. Microgravity Lab pallets (USMP-3), Orbiter Acceleration Research Experiment (OARE) pallet, and Extended Duration Orbiter (EDO) pallet. Deployment of the satellite began at 56\/20:46 GMT. On 57\/01:29:26 GMT, at a tether length of 19.7 km, the satellite tether broke within the 12 m deployer boom, and the satellite separated from the orbiter. The rate of tether deployment was under control of the science computer. At the time of the tether separation, the deployment rate was being ramped down, per timeline, in preparation for halting at 20.7 km tether length. The tether deployment rate was approximately 1 m\/s when it separated. There were no injuries and no damage to the orbiter or its subsystems due to the tether break. The orbiter was located at 2 degrees N latitude and 100.4 degrees W longitude, and was at an altitude of 296 km (160 nautical miles) at the time of tether break. The TSS-1R experiments were in the passive mode, with no current flowing in the tether. The tether had an electric potential of -3500 VDC with respect to the orbiter ground, as planned, during this mode. Telemetry from the orbiter and the satellite was operating prior to, during, and after the tether separation. Video imagery of the tether was available after the separation, but no video coverage exists showing the break itself. Video and still photography were taken during the mission of the failed end of the tether within the boom. The tether remaining in the boom was rewound on the reel during the mission. Post flight inspection of the tether end showed it to be charred, with an apparent final tension failure of a few strands of Kevlar. The TSS-1R Mission Failure Investigation Board established that the tether failed as a result of arcing and burning of the tether, leading to a tensile failure after a significant portion of the tether had burned away. Pictures of the frayed tether end The arc started in the Lower Tether Control Mechanism (LTCM), resulting in a 1 A current discharge to orbiter ground in the LTCM. This event occurred during a passive mode of science operations, with -3500 VDC on the tether conductor. The arc continued intermittently for 9 s, as the breached part of the tether traversed at 1 m\/s through the remaining deployer mechanisms and into the 12 m deployer boom, where the space plasma provided the current return path. This arcing produced significant burning of most of the tether material in the area of the arc. The nominal load on the tether, 65 N (15 lb.), finally separated the tether at the burn location, while it was within the deployer boom. The upper tether section was pulled through the Upper Tether Control Mechanism (UTCM), away from the orbiter at a speed of 3 m\/s, due to tether dynamics and the satellite movement away from the orbiter. The lower section of the tether remained within the boom, and was recovered after the flight. The arc initiated at a breach in the FEP insulation layer of the tether. Pressure within the LTCM, the proximity to a ground plane at the LTCM entry pulley, and the high voltage on the conductor, provided the favorable environment based on pressure-distant relationships (Paschen's Law)* for the conductor to arc through the breach in the tether insulation. Although the damaged area of the insulation was destroyed due to burning, the TSS-1R Mission Failure Investigation Board found sufficient evidence from test and analysis to establish foreign object penetration, or damage to the FEP insulation layer in manufacturing or handling, as the probable cause of the breach of the insulation layer. See the following videos: [D] The satellite and tether moving away from the shuttle [D] Scan of the boom with the slack tether in the shuttle cargo bay Manufacturing and inspection records show that the tether fabrication task was very difficult, and that numerous problems were encountered in the extrusion and braiding processes of this very long tether. The fabrication of the tether was carried out in a normal manufacturing shop environment. Metallic and non-metallic contamination was found within the FEP insulation layer of the flight tether, including the 9 m that had gone through the lower deployer mechanisms prior to the failure. Non-metallic and metallic contamination was also found between the Nomex and insulator layers of several samples of flight tether. EDS analysis revealed foreign material near the failed end. In addition to the contamination found within the tether, debris was found in several locations within the deployer mechanism. Metallic debris, large enough to breach the FEP, was found in the LTCM, the deployer boom assembly, and the reel housing. In the LTCM, a small piece of very fine silver plated wire, aluminum shavings, and unidentified non-metallic debris were found. Small metallic shavings were found attached to the back of small screw holes in the boom assembly. Damage to the copper conductor was found in both the returned flight tether, and in a section of qualification tether examined after a special spark test. This damage appeared to have taken place during fabrication of the tether. The final wind of the tether onto the flight reel was at a tether tension of 50 N. This results in high compression forces on the tether layers deep within the reel. The TSS-1R Mission Failure Investigation Board calculated that compressive forces at the layer where the tether breach was located, were as high as 35 N\/mm for several days after the winding process. This compressive force is more than sufficient to force small debris through the insulation layer of the tether. The TSS-1R Mission Failure Investigation Board found one contributing cause was that the degree of vulnerability of the tether insulation to damage was not fully appreciated. A second contributing cause was high voltage effects on the insulator itself. Concern over the environment inside the LTCM led to the analyses involving Pashcen's Law relating voltage break down propensity as a function of the pressure-distance parameter. * - In 1889 Paschen introduced a generalization to the complex subject of gas break down in the law bearing his name. This law states simply that in a uniform field the sparking potential of a gas depends only upon the product of the gas pressure and the electrode separation. The TSS-1R Mission Failure Investigation Board was able to conclusively eliminate several major areas as causal. They included: Satellite Hardware and Operations Core Science Equipment and Operations Hardware and Operations of the Experiments Mission Operations (Ground and Flight) Induced Loads (static or dynamic) Pyrotechnic Tether Cutters Heating of the Tether During Commanded and Controlled Current Flow Design Changes Made to TSS-1 Aging of the Components (shelf life) Micrometeoroid or Orbital Debris Collision Electrical Storm Activity Reference(s): TSS-1R Mission Failure Investigation Board - Final Report, May 20, 1996.","Lesson ID":566}
{"Driving Event":"This Lesson Learned is based on Reliability Guideline number GD-ED-2201 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: One of the most important considerations when mechanical fasteners are required is the selection of fasteners of certified quality that meet the requirements of the hardware assembly. Proper fastener selection and application is the first step toward building reliable hardware; therefore, a standard approved parts list consisting of a limited number of types and styles will result in optimum performance, reliability, maintainability, and economy. Implementation Method: Fastener reliability begins with the preparation of an approved parts list (APL), consisting of certified parts with proven performance, selected for the appropriate application, and procured only from approved suppliers. To ensure certified quality and reliability, fastener types and styles should be kept to a minimum, with fasteners obtained from an approved source. Fastener cost can be better controlled by implementing, in the initial phases of a program, a plan of consolidation and centralization of efforts related to fastener selection, receiving inspection, testing, and traceability. Providing sufficiently detailed design selection and procurement information for an APL requires that the fasteners be identified, described, and controlled by a Government specification or standard, an industry standard formally adopted by the Government for general applications, or a contractor specification or standard acceptable to the Government. Additionally, precautions should be exercised to ensure, as a minimum, that fasteners are procured from only qualified suppliers based upon surveyed performance. Critical fasteners, generally defined as used in either the primary or secondary load path of a structure, together with specialty fasteners, should be given particular attention to ensure that selection and procurement is only from approved manufacturers. An example of a specialty fastener would be a design created either in-house or by a manufacturer for a very specific and limited application (high strength, temperature, configuration). Care and good engineering judgment should be used at all times during design selection and procurement of fasteners for flight hardware, safety-critical facilities, and mission-essential ground support equipment to ensure that each design is examined from a reliability, maintainability, and producibility aspect. General criteria that should be examined for a suitable selection of fasteners include: Materials. Fasteners intended for critical applications should be made from corrosion and heat resistant steels or alloys such as A286 corrosion resistant steel (CRES), titanium, Inconel 718, or MP35N. Fasteners intended for GSE, noncritical, or non-flight hardware may be made from either 300 series or A286 CRES. The tensile strength for noncritical types of fasteners should be 130 ksi minimum. The maximum expected load (tensile and shear) and criticality for the applicable joint is important in the selection of fastener material. Stress corrosion sensitive fasteners should be avoided (refer to MSFC-Spec-522). Fasteners considered for use in composite structure must be selected to ensure conformance to requirements of material compatibility, acceptable installation procedures, and part configuration. Corrosion resistant steel fasteners should be passivated per MIL-S-5002 or QQ-P-35 during the manufacturing process. The passivation process will prevent rust spots from forming on corrosion resistant steel parts by removing embedded iron particles. Passivation must always be the last operation performed. Environmental conditions (salt spray, temperature, vibration, etc.) both for storage and operation should be considered so that material and finish requirements can be evaluated for galvanic couples. Spacecraft hardware may spend a considerable amount of time on earth due to factors such as assembly, test, and storage due to launch scheduling. Fastener selection should be based upon considerations of weight, cost, and availability. The operational aspects of the installation, extravehicular activity (EVA), intravehicular activity (IVA), maintenance and repair, together with initial assembly may require a unique or specialty fastener. An analysis should be performed early in the design and selection phase as a considerable impact may result to both the hardware design and cost if a specialty fastener is required. EVA\/IVA and Torque requirements. External wrenching fasteners should have a 12 point head for applications with tensile strengths above 180 ksi. Hexagonal heads (6 point) should be used for fasteners of 180 ksi UTS or less. Threads should also conform to MIL-S-8879 requirements \"Screw Threads, Controlled Radius Root with Increased Minor Diameter, General Specification for\". Captive fasteners should be used whenever possible for flight hardware. All nuts, nut plates, and threaded inserts should have an integral prevailing torque locking device. The minimum fastener head size for suited glove operation should be 1.5 inch diameter and .75 inch high. Sizes larger than 2 inches in diameter should be avoided to prevent the fastener from being larger than the maximum grip size of the smallest crewman. Fasteners that will be manipulated by tools or robots in space should have a standardized head size of 7\/16 inch (measured from flat to flat) for 1\/4 inch threaded fasteners, and 3\/4 inch head for 1\/2 inch threads. The thread sizes may be varied independently from the fastener head, thereby reducing or eliminating the requirement for different tool or end effector sizes, but allowing the fastener to be tailored to the application. The minimum head size must be considered in relation to the maximum torque required upon assembly. The assembly and operational aspects of the fastener may require lubrication or a special finish to insure reuse of the fastener during these phases. Lubrication. Silver plating should not be used on any fastener that would be removed and reinstalled more than twice as part of normal operation or maintenance procedures. Silver reacts rapidly with atomic oxygen to form silver oxide, therefore silver plated components should not be used in any application in which the part is directly exposed to atomic oxygen. Due to corrosion potential, silver plated parts must not contact titanium. Dry film lubricant is the preferred method of coating fasteners. Lubricants for fasteners should meet the vacuum stability requirements of JSC SP-R-0022, \"Vacuum Stability Requirements of Polymeric Material for Spacecraft Application\". Fastener procurement and testing. All received fastener shipments should contain reports of tests conducted on the parts at an accredited laboratory in compliance with Public Law 101-592 \"Fastener Safety Act\". All test reports require a similar format such as stated in Public Law 101-592, Section 5. Critical fasteners procured from sources other than the original manufacturer should only be accepted if original chemical and physical certifications can be validated and the lot traceability can be documented. Together with fastener testing, a system for providing traceability of parts to the initial assembly should be maintained, to reduce the time and associated costs of tracking problems concerning suspect hardware. Without traceability, the location of suspect hardware becomes difficult and may make dispositions very subjective and complex, perhaps leading to extensive disassembling of structure or other hardware. To maintain such a level of traceability, lot segregation should be implemented. Technical Rationale: Substandard and counterfeit fasteners in industry have heightened the government's concern about the reliability of hardware procured for use on various projects and programs. In response to this concern about the integrity of fasteners, Public Law 101-592, \"Fastener Safety Act\", has been enacted to provide an improved level of confidence in fasteners by requiring improved manufacturing, testing, certification, and quality assurance for all fasteners sold or delivered within the United States. References: 10107-70915, EVA Bolthead & Socket Interface Study & Definition, ILC Space Systems, Houston, Texas. MSFC-Spec-522, Design Criteria for Controlling Stress Corrosion Cracking, Marshall Space Flight Center.","Lesson ID":675}
{"Driving Event":"The Mars Pathfinder (MPF) project operated under cost and schedule constraints. It employed new approaches for interface definition and control which produced both good and bad results. In simplifying the expensive serial engineering change request (ECR) process, a dedicated JPL interface control drawing (ICD) coordinator was responsible for change control and for assuring that interface changes were approved by cognizant engineers. In addition, the Project Engineering Team met weekly to review all changes. Problems occurred during MPF spacecraft integration and test, however, due to out-of-date or incomplete interface documentation: Electrical connector discrepancies were found between the MPF main wiring harness (delivered in July 1995) and 7 connectors on circuit boards in the Attitude and Information Management (AIM) subsystem. Investigation showed that the main wiring harness was built in accordance with MICDs which had not been updated after interfacing circuit board connectors were changed. This resulted in a connector mismatch--non-mating male-to-male and female-to-female connections. No power subsystem cabling was involved, and the discrepancies were corrected by retrofitting the cabling, or in some cases the boards, before any damage had occurred. For some hardware items, it was discovered that JPL and vendors had each prepared MICDs independently. Additional Keyword(s): Electrical Interface Control Drawing (EICD), Mechanical Interface Control Drawing (MICD) Reference(s): Muirhead, B., Mars Pathfinder Lessons Learned Presentations, April 17, 1997. Mars Pathfinder Problem Log, IR 043306. Mars Pathfinder ATLO Data Package JPL Common Threads Workshop Summary Report, JPL D-13776, May 31, 1996.","Lesson ID":569}
{"Driving Event":"The legacy (manual) methods for managing the implementation of software requirements for the Space Shuttle Program have had a major impact on cost and schedule over the entire software development life cycle.","Lesson ID":3377}
{"Driving Event":"Recently on a Goddard Space Flight Center (GSFC) spacecraft program, a contractor had concluded successful live fire tests on the EEDs (Electrical Explosive Devices, also called Pyros). Subsequently it was found that the live fire tests had not only fired the EEDs but had also damaged the drive circuit. The damaged component was the EED circuit fusing element. This component would not provide sufficient energy to fire an EED when required during the mission. This then could have resulted in failure to fire EEDs during the mission. GSFC engineering had mandated that the drive circuit be tested after the live fire test. This drive circuit test was to demonstrate the drive circuit vitality. Fortunately, the mandated tests were done, the damaged parts found and appropriate corrective measures taken. The last paragraph of this document contains a test recommendation to preclude launching with a \"dead\" EED system (typical I&T EED tests may appear to be successful but the typical test can actually damage the EED drive circuit). This paragraph was written as an executive summary with the last paragraph being the summary recommendation. The other paragraphs provide more detailed information on the problem. Early concerns about the Pyro circuit design included unconventional EMI shielding, unconventional EED firing via a ground pulse, firing current sustained after initiation, overcurrent protection by using a resistor (current-time curves were not available from the contractor), and the safing plug location that precludes verification of EED status. The Contractor maintained that the design was the same as that used repeatedly on all of their programs. (It was subsequently discovered that the fire pulse design has not been consistent on their programs.) The contractor also maintained that the design minimized hazard risks and therefore was acceptable. They were insistent that since they had already fabricated the assemblies a change to the design would substantially impact the program. GSFC insisted that as a minimum after any EED test firing, the Contractor must conduct a test to verify the resistance value of the EED fusing resistors. No change was made by the contractor to alter the unconventional EED firing via a ground pulse. [D] During the tests to verify the resistance value of the EED fusing resistor, it was discovered that in one channel the fusing resistor value was 15 times the required value. Therefore, the fusing resistor would no longer activate a flight installed EED. When the assembly was opened, the resistor was found to be charred. Evidence points to this being a result of EED firing via a ground pulse and the EED establishing an internal path to ground that resulted in a sustained current until the pre-arm\/arm path was interrupted by fusing resistor failure. Another fusing resistor was also discolored but had the correct resistance value. The discolored resistor was then further tested to confirm that it could provide additional adequate fire pulses. The Contractor did limited testing and confirmed that the discolored (but correct resistance) fusing resistor was capable of repeatedly providing fire pulses with adequate energy. This result appears to confirm that a measurement of resistance value was adequate to determine drive circuit functionality. The mechanism for the damage appears to be the ground firing pulse combined with the known effect of EED shorting to case during discharge. The enclosed figure is a simplified diagram of the ground firing pulse configuration. The prearm and arm contacts are closed or opened by ground command for extended periods. The duration of positive voltage application is mostly dependent upon intervening operations. However, a minimum duration on the order of a few hundred milliseconds would be expected from the contractor's implementation. The fire pulse is a 40 ms ground activation pulse. If the prearm and arm commands are executed, the EED only needs the fire pulse ground connection to initiate. Once the fire pulse occurs then a \"sneak\" circuit can occur internal to the EED by either the bridge wire shorting to the EED case or by a low resistance plasma path to the case (information seems to indicate that this kind event occurs in about 4 percent of EEDs). If this happens, high current will flow until either the fusing resistor opens or the prearm or arm functions are deactivated. A short duration fire pulse on the positive voltage side would not have caused fusing resistor damage. If the fire pulse were placed on the positive side of the circuit instead of the ground side a high surge current could still occur but only for the duration of the 40ms fire pulse instead of the much longer duration of the prearm and arm relays.","Lesson ID":448}
{"Driving Event":"The G02 supply from the ECLSS GO2 servicing console can be utilized to feed oxygen directly into the astronauts' helmets in support of the flight crew breathing test during OMI S0017 (at T-4 minutes). The existing oxygen panel uses gaseous nitrogen as the regulator \"push\" pressure (6000 psig) to operate the ECLSS servicing console. There is a possibility of nitrogen intrusion into the oxygen feed line if a regulator failure occurs.","Lesson ID":27}
{"Driving Event":"During the course of its test program at Dryden Flight Research Center, Edwards, CA, the X-31 experimental aircraft was retrofitted with an unheated Pitot-static probe (of the Kiel probe design). Unexpected icing of the single-string Pitot-static air data source resulted in the aircraft departing controlled flight and crashing. X-31 Experimental Aircraft Pitot-Static Probe","Lesson ID":359}
{"Driving Event":"Building Rehab projects are typically done on the second shift (4:00 p.m.-12:00 a.m.) and construction meetings are held every week to discuss the progress of the job. These meeting times and dates are left up to the participants to determine. The contract requires the meeting, but does not dictate a specific time. The Contractor's job superintendent doesn't start work until 4:00 p.m. and when construction meetings start at 3:00 p.m. some valuable input from the field is missing. The Contractor's Project Manager is always in attendance, however the field representation is also required. If the meetings were moved until 4:00 p.m., many of the Government's representatives would not be in attendance due to their work schedule.","Lesson ID":749}
{"Driving Event":"In order to mitigate seal extrusion-related failures in the Primary Reaction Control System (PRCS) pilot-operated valve (POV), an effort was undertaken to develop a redesigned POV (RPOV) pilot seat assembly. The POV controls the flow of hypergolic liquid propellants to the Space Shuttle Orbiter attitude control thrusters. Specifications and selection assistance from suppliers were found to be inadequate for choosing an appropriate grade of PTFE for seal material without further testing. The two PTFE resins under consideration had similar properties per current material procurement specifications. For example, the dimensional stability, tensile strength, and percent elongation requirements were virtually the same. Meaningful properties such as dimensional stability under load (creep), retention of properties at higher operational temperatures, and chemical resistance to propellants were not covered. Resin selection design assistance from commercial resin suppliers for specific applications such as a thruster valve seal was found to be lacking. Resin candidates were also hard to distinguish by most laboratory tests, but each candidate was later found to exhibit unique physical and mechanical properties that made the difference between fabricating a viable versus non-viable seal. Initial RPOV seal fabrication efforts focused on using a pre-sintered, free-flowing extrusion molding PTFE grade per AMS 3658 [1], sold under the trademark of Algoflon(r)-E2 [2]. Seals made from Algoflon-E2 exhibited significant splotchiness, microcracking, and fibrillation after the hot-forming assembly process and seal recession after valve testing. To resolve these issues, an as-sintered, non-free-flowing compression molding PTFE per AMS 3660 [3], sold under the trademark of Teflon(r)-7A [4], was used. [D] Figure 1. Redesigned pilot seal showing overall splotchy appearance and fibrillation around seal id and od after trimming Given the limited utility of material procurement specifications, a squeeze test which allowed the compressive strain to be varied from 15 to 90 percent was devised to better differentiate between resins. Specimens made from the pre-sintered, free-flowing Algoflon-E2 resin produced a lower strength PTFE that was more susceptible to fracturing (Figure 2, bottom). Since Algoflon-E2 consists of coarse, agglomerated particles, fracturing was attributed to adhesive failure along resin particle boundaries. By comparison, a specimen made from the as-sintered, non-free-flowing resin gradually transitioned from fully opaque to translucent material without any evidence of fracturing or splotchiness. [D] Figure 2. Polytetrafluoroethylene squeeze test specimens: Teflon-7A (top, 1 piece) and Algoflon-E2 (bottom, 2 pieces). Notice the fracturing in the Algoflon-E2 specimens. References: Aerospace Material Specification 3658, Revision C. Polytetrafluoroethylene Extrusions, Premium Strength, Sintered and Stress-Relieved Radiographically Inspected. Society of Aerospace Engineers, Warrendale, PA, July 1993. Algoflon(r) is a registered trademark of Ausimont Montedison Group, Milan, Italy. Aerospace Material Specification 3660, Revision C. Polytetrafluoroethylene (PTFE) Moldings, General Purpose Grade, As Sintered. Society of Aerospace Engineers, Warrendale, PA, February 1994. Teflon(r) is a registered trademark of E. I. DuPont and Nemours and Company, Wilmington, DE.","Lesson ID":1039}
{"Driving Event":"The electro-mechanical actuators for several of the orbiter mechanical systems have exhibited torque output degradation over the life of the shuttle program. In some cases, even serviceable spares that had been in logistics storage showed significant degradation, despite the fact that they had not been operated and had been maintained in a controlled environment. This resulted in the need to periodically test and trend the performance of some of the actuators installed in the Orbiters, to ensure the torque output level was sufficient to operate successfully in flight. In some cases, Ground Support Equipment (GSE) had to be developed to enable the test to be done with the actuator still installed in the vehicle. It also resulted in unplanned work when the actuator needed to be replaced, and often required additional re-rigging of the system after the replacement actuator was installed. These actuators all contain torque limiters and motor clutch\/brake assemblies, which were usually the cause of torque output degradation.","Lesson ID":2839}
{"Driving Event":"The portable purge units are lifted on and off the MLP. The existing lifting sling design induces stress into the unit's operating components and overstresses the unit's lift points. Cracks are present on the lifting lug plates and elongation of the lifting lug holes has occurred. Failure of these components could result in damage to ground support equipment (GSE).","Lesson ID":85}
{"Driving Event":"Coil fins on chillers in the VAFB area (Lompoc, CA) corrode quickly because of exposure to sea air. For this reason, a specification was written for a special coating to extend the life of the coils. When corrosion was spotted on the newly installed coils, it was watched closely to see if it continued. The installing subcontractor, coil manufacturer, and coater were notified of the situation. When the corrosion was observed to be spreading, a meeting was held and the parties involved made an inspection at the site.","Lesson ID":2356}
{"Driving Event":"The remote manual arming and firing valves are in the \"on\" position when perpendicular to the water lines, which is not the industry norm for hydraulic systems. This contributed to the OPF GSE technicians believing they were closing the valves by positioning them perpendicular to the water line when, in fact, they were opening the valves. This misinterpretation resulted in the activation of zones 1,2,3,4, and 5 of the bay 2 Firex deluge system.","Lesson ID":49}
{"Driving Event":"GIFTS did not have an instrument co-registration requirement, except that the co-registration be measurable and be determined from the ground data. The GIFTS test plans did not include solar simulations in a chamber to establish the co-registration characteristics prior to flight.","Lesson ID":1530}
{"Driving Event":"When GSFC audited a subcontractor on a Landsat Data Continuity Mission (LDCM) ground system element, the subcontractor was unable to identify a statement of work which flowed down requirements within the documents provided by the prime contractor. While it was later confirmed that a statement of work was in the contract documentation, it did not contain requirements for the subcontractor. The subcontractor was separately given the set of requirements for the entire ground system element, and not for the specific portion that the subcontractor was working on. The prime contractor was a small business and this was their first experience as a prime.","Lesson ID":6756}
{"Driving Event":"The Space Shuttle was developed by NASA to be a largely reusable launch system which could provide frequent access to low earth orbit. Like all previous launch systems, safe reentry for the crew and payload required the use of a thermal protection system (TPS). Unlike previous spacecraft though, the Shuttle\u2019s TPS was exposed from launch, making it sensitive to debris which could be generated by the vehicle on ascent. The most likely and potentially destructive source of debris was considered to be ice, which could build-up anywhere on the External Tank (ET) where there was exposed metal. Ice could form during ground operations after the cryogenic propellants had been loaded and then be knocked loose on ascent. In order to prevent both ice build-up and boil-off of the propellants, the entire ET and all protuberances (orbiter attach points, pressurization lines, propellant feed lines, etc.) were covered with a spray on foam insulation (SOFI) type TPS. Unfortunately the foam was also susceptible to liberation during ascent, and posed a debris risk of its own. In February of 2003, during ascent on STS-107, an ~2 pound piece of foam was liberated from the left ET bipod and impacted the leading edge of Columbia\u2019s left wing. The resulting damage to the Reinforced Carbon-Carbon TPS in that location was severe enough that on reentry a jet of hot gas was able to enter the vehicle. The eventual structural failure of the wing and resultant loss of control led to vehicle break-up, and the loss of the entire crew. Following the Columbia tragedy the Space Shuttle fleet was grounded for two and a half years to determine the root cause of the incident and implement the necessary design changes. On July 26, 2005, Space Shuttle Discovery launched on the Return to Flight (RTF) mission, STS-114. On ascent, the ET shed foam from numerous locations, where the largest piece was twenty-five times greater than the certified limit. The shuttle fleet was grounded again and two separate in-flight anomaly (IFA) teams were established to determine the root cause of each piece of debris. On June 26, 2006 the Space Shuttle Program held the STS-121 Flight Readiness Review (FRR). The ET Project provided a status of the design and process changes addressing the IFA teams\u2019 recommendations for ET-119, the external tank on this next scheduled flight. The FRR board\u2019s responsibility was to determine if the vehicle was acceptable to fly. This was the second Return to Flight mission since the Columbia accident.","Lesson ID":17903}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1257; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Proper design of solid rocket motor case-to-case field joints reduces joint rotation and potential leakage during ignition and operation. With detailed dynamic loads analyses, thermal analyses, careful insulation design, and suitable quotoquot-ring sealing, the leakage of hot combustion gasses through field joints is eliminated. This prevents potentially catastrophic burning or melting of the solid rocket motor and adjacent metal components. Similar benefits are obtained by using improved design practices for case-to-nozzle joints and factory joints between case segments. Implementation Method: 1. Background The Challenger accident (Space Shuttle Flight #51L) which was caused by the escape of hot gasses from case-to-case field joints in the SRM, triggered an in-depth, detailed review of analytical, design, manufacturing, assembly, and testing methods for solid rocket motor field and factory assembly joints. The case-to-case field joint was the primary target of the investigations and subsequent redesign efforts. However, other joints in the motor such as the case-to-nozzle joint and the factory joint between motor segments were thoroughly investigated and redesigned when the investigation allowed for optimization of the noted configurations. Reliable joint performance was achieved by a detailed review of the design drives and by comprehensive analysis, test, and redesign processes. 2. Case-to-Case Field Joint Improvements Space Shuttle Redesigned Solid Rocket Motors (RSRMs) are made up of four segments in which propellant is cast in monolithic form. The four segments are connected by the field joint shown in cross-section on Figure 1. The case portion of each segment consists of two cylinders connected in the center by a factory joint. A dynamic launch and flight load analysis confirmed that the field joint design, which has been the main focus of attention, needed to be modified after the Challenger accident to incorporate several improvements. The most significant of these improvements was the addition of a quotcapturequot feature, which is essentially an added circumferential band that is incorporated as an integral part of the quottangquot on the male side of the three case-to-case field joints. This capture feature creates an interference fit with the inner clevis surface and restricts the movement of the tang away from the two quotoquot-rings on the internal leg of the field joints during initial motor pressurization. The capture feature also incorporates a third quotoquot-ring which potentially serves as a heat barrier to the combustion process, in event of anomalous insulation performance. In addition to the change in the metal parts, the configuration of the internal insulation interface between adjacent segments was changed to permit an interference fit between adjoining insulation elements. This insulation joint is bonded with a pressure sensitive adhesive around its full circumference, and aided in its contact during motor operation with a circumferential quotJquot shaped pressurizing slot in the tang insulation. With the addition of the capture feature and its quotoquot-ring, a second leak check port, which also serves as a vent during assembly and a means of positioning of the primary quotoquot-ring, was added in the redesigned joint. This ensured that a redundant seal existed in the new design. A quotV-2quot fluorocarbon filler material was placed at the clevis tip between the primary and tang quotoquot-rings to reduce the free volume of the joint and limit the quantity of hot gas that would enter the joint in the event of leakage of the quotJquot seal and capture feature quotoquot-ring. In the new design, the inner clevis leg surface is machined to provide a sealing surface for the capture feature quotoquot-ring. The compression of both the primary and secondary quotoquot-rings was increased by increasing the quotoquot-ring diameter by 0.010 inch from the pre-Challenger configuration, and the quotoquot-ring grooves were widened by 0.005 inch to prevent four wall contact by the quotoquot-ring. All sealing surfaces were smoothed to an average roughness of 63 micro inches (63 millionths of an inch). A chamfered clevis leg was provided to aid in the assembly process. Each field joint in the Redesigned Solid Rocket Motor is connected by pins (a cross sectional drawing of one of these pins appears on Figure 1). A key reliability enhancement feature is an increased-length pin with a circumferential pin retainer band. Each pin includes a hole which assists in assembly, and an opening with a dovetail cross-section to assist in pin extraction for refurbishment after flight. The increased pin length causes the dovetail to lie outboard at the outer clevis leg outside diameter. A stress analysis confirmed that this would reduce unit area shear stress on the pin because the dovetail is outside of the high shear area. This modification eliminated the potential for pin deformation. Custom shims were inserted between the inside surface of the outer clevis leg and the outside surface of the tang to maintain a constant gap between the two surfaces and to limit the growth of the metal-to-metal gap at the primary and secondary quotoquot-rings during pressurization. [D] 3. Case-to-Nozzle Joint Improvements Concurrent with the improvements in the case-to-case field joints, case-to-nozzle joints were also improved to obtain higher reliability and to achieve a more robust design. Changes to the insulation configuration, joint adhesive material, quotoquot-ring and quotoquot-ring groove configurations, and the nozzle attachment fasteners provide positive assurance of sealing. As in the instance of the insulation surrounding the case-to-case field joints, a pressurizing slot in the case insulation, coupled with a layer of sealant between the case and nozzle insulation, provides protection against combustion gasses reaching the nozzle or case metal parts. A circumferential slot is located in the case insulation near the interface between the case and nozzle insulation. A circumferential flow baffle is installed in this slot to prevent erosion of the insulation, and a stress-relieving radius former is included at the base of this slot to prevent cracking. To provide an additional margin for reliability, polysulfide adhesive material is used to bond the carbon phenolic nozzle insulation material to the asbestos\/silica-filled, nitrile butadiene rubber insulation in the rocket motor case. A wiper quotoquot-ring in the glass phenolic layer of the nozzle insulation and wiper vent slot in the rubber case insulation were incorporated to prevent entrapment of air in the case-to-nozzle joint during assembly, and to prevent the polysulfide adhesive from contaminating the primary quotoquot-ring. The wiper quotoquot-ring also provided the second of two barriers (the first is the polysulfide material in the insulation joint) to inhibit gas flow to the primary seal. Stress analysis studies and strength testing proved that radial bolts, as well as longitudinal bolts, were required to ensure an impenetrable seal between the nozzle and case metal parts under all environmental and motor performance conditions. Radial bolts ensure that sufficient compression of the primary quotoquot-ring is maintained to provide effective sealing. Increasing the diameter of the quotoquot-ring and redimensioning the quotoquot-ring groove to provide optimum quotoquot-ring squeeze while preventing quotoquot-ring entrapment were required reliability enhancement measures in the RSRM case-to-nozzle joint. 4. Factory Case-to-Case Joints Custom shims, widened quotoquot-ring grooves, slightly larger quotoquot-rings, increased pin length, and revised pin retainer bands were improvements made in the factory case-to-case joints. Because of the continuous insulation and propellant strata over the factory joints, special joint provisions were not required in the insulation. Clevis legs were chamfered and undercut at the leg tips for consistent final configurations after assembly. Technical Rationale: Based on detailed analyses of key design and manufacturing\/assembly drivers, the SRM case-to-case field joints have exhibited satisfactory performance in close to 100 solid rocket motors since the Challenger accident without evidence of hot propellant gas leakage through the insulation to the joint sealing system. The critical parameters associated with the case-to-case field joint, case-to-case factory joint, case-to-nozzle joint, and ignition system mounting joints continue to be closely monitored on a flight-to-flight basis to prevent the occurrence of undesirable hot gas transmission through any of the multiple seals provided. References 360L001 Acceptance Review: Morton Thiokol, Inc. Aerospace Group, Brigham City, Utah, March 14-15, 1988. Design Data Book (DDB) for Space Shuttle Redesigned Solid Rocket Motor (RSRM), Thiokol Corporation, Space Operations, November 1990. quotSpace Shuttle Solid Rocket Motor Program, Lessons Learned,quot AIAA Paper #91-2291-CP, A. A. McCool, George C. Marshall Space Flight Center, Alabama, 1991.","Lesson ID":759}
{"Driving Event":"The slight waviness of nosecone surface variation in the vicinity of the FADS pressure port 3 causes the local pressure measurement to be lower than the other ports. Since the FADS pressure port measurements are used to compute the incoming flow angles, this results in an extra 1 degree of apparent flow angle at transonic speeds.","Lesson ID":1599}
{"Driving Event":"Problems encountered late in the test cycle on some articles, due to lack of rigorous peer review","Lesson ID":1276}
{"Driving Event":"Background: In October 2001 the Payload Safety Review Panel (PSRP) conducted the phase III flight safety review for the Microgravity Science Glovebox (MSG) payload. During the safety review, the PSRP discovered that one of the MSG client payloads, a vibration attenuation device, did not address touch temperature hazards in the event of degradation or loss of an ISS critical service - cooling by the ISS Moderate Temperature Loop (MTL). The client payload was mounted inside the MSG work volume and utilized the ISS Moderate Temperature Loop (MTL) for cooling. The payload organization's (PO) thermal analysis did not cover the MTL failure scenario. The PSRP directed the PO to perform additional thermal analysis for the MTL failure case. The new analysis revealed that the client payload's baseplate could reach a maximum temperature of 68 deg Celsius (154 deg Fahrenheit) which exceeded the NSTS\/ISS 18798B Interpretation Letter (MA2-95-048) maximum allowable temperature (49 deg C) requirement for intentional crew contact. The client payload was therefore not \u201dsafe without services\u201d as required per the NSTS 1700.7B ISS Addendum. In order to protect the crew, the PO added a temperature strip and caution-warning sticker to its payload to serve as the second control of the touch temperature hazard. The MTL was the first control. With the addition of the temperature strip, the client payload now satisfied the NSTS 1700.7B ISS Addendum fault tolerance requirement for a critical hazard. The PO updated its standard payload hazard report to reflect the updated thermal analysis and new second control. In February 2002, the PSRP approved the client payload for flight (STS-111\/UF-2). Root Cause: An integrated approach to the analysis, which would have included the potential for failure of critical services from outside the payload, was not thoroughly performed. The client PO did not include loss of services (MTL degradation or failure) in their original thermal analysis. This omission left a potential touch temperature hazard uncontrolled after a single point failure.","Lesson ID":1367}
{"Driving Event":"A metrology laser is used within the interferometer to measure the interferometer\u00bbs OPD position and change rate so that the FPA collection frames and the corresponding integrations times can be controlled. However, the frames coming out of the ROICs are typically resynchronized with time. Imaging interferometer sensor systems are offering broader capabilities and performance characteristics through the use of large field of view and data throughput. But system performance can easily be compromised by FPAs and ROICs that are not fully compatible with operational capabilities and performance requirements of the interferometer. The FPAs and ROICs should be designed, fabricated, and tested to meet the spectral, spatial, temporal, radiometric, control, and stability requirements needed to achieve the specified performance of the interferometer. FPA technologies can be overstressed by over-extending the longwave spectral cutoff point. This is especially true of long wave FPAs. Keeping the cutoff as short as possible can significantly improve FPA yield and performance and can reduce the cooling requirements for currently available technologies. Thus, the recommendation is to choose FPAs with the shortest cutoff wavelength that will still accomplish the desired science measurements.","Lesson ID":1595}
{"Driving Event":"Radiation Research and Protection Implementation Planning at NASA","Lesson ID":1142}
{"Driving Event":"During forward center segment on-load to rail car for transport to the furbishment facility, the segment began to slide out of the confines of the handling sling. Approximately 90% of the segment was suspended 10' to 15' feet above the rail car when the aft end of the segment slipped out of the sling, coming to rest on the rail car. The forward end of the segment stayed suspended approximately 10' above the rail car. No damage to the segment was noted and the rail car received only three scratches by the handling ring. The instability of the segment is due to the difficulty in determining its center of gravity.","Lesson ID":92}
{"Driving Event":"NASA\u2019s Space Technology Mission Directorate, (STMD) formed an STMD-sponsored ''brazing tiger team\" with metallurgical and manufacturing subject matter experts (SMEs) within the Agency to provide technical assistance on various brazing issues for four STMD-funded activities. The SMEs were from MSFC, LaRC, GSFC, GRC, and the NESC Chief Engineer Office. MSFC was assigned the leadership role. The request came at an opportune time for MSFC since MSFC was in the process of working a brazing issue on the Microgravity Materials Science Research Rack Sample Ampoule Cartridge. The goals for this team of brazing SMEs were to provide real time resolution for the specific brazing issues encountered by each of the four activities, evaluate new technology solutions, and enhance our Agency's knowledge of brazing and brazing processes. Four STMD projects were experiencing brazing issues: \u2022 Cryocooler\/GRC \u2022 Water Phase Change Material (pCM) Heat Exchanger (HX)\/JSC \u2022 Green Propellant Infusion Mission (GPIM)\/GRC \u2022 Nuclear Systems NaK Heater Head\/GRC. During information gathering, JPL engineers presented their lessons learned from the brazing issues resolved on the Deep Space Atomic Clock ion trap tube brazing. JSC proactively offered subject knowledge to the team to assist in developing solutions for the aluminum cold plate dip brazing process. After discussions on the above referenced projects, one onsite visit was made to Mezzo Technologies in Baton Rouge, Louisiana to review the manufacturing processes used for the PCM HX project. Provided here are brief overviews of the primary issues and potential solutions being worked by the respective projects. Additional detail can be provided by the respective project managers. \u2022 The Nuclear Systems NaK Heater Head braze assembly consisted of stainless steel tube, Inconel flange, and copper acceptors. These braze joints were failing as a result of unfilled or starved joints due to thermal expansion mismatch and part movement during brazing. o The solution was to redesign the head assembly using common materials to avoid thermal expansion mismatch. o All joints were redesigned to mechanical or welded joints with the exception of one brazed joint. The redesigned one piece inner heater head assembly will eliminate braze joints and will be used as the backup heater head. The Cryocooler heat exchanger braze assembly consisted of stainless steel manifold sheets and thousands of thin-walled microtubes. The braze issues included excessive flow of the braze alloy causing blockage of the microtubes and erosion of the thin walled tubes due to excessive base metal\/braze alloy interalloying. Under the Cryocooler Project, Mezzo had not progressed any further with regard to brazing challenges. Mezzo milled the tube sheet boss features with the precision and concentricity necessary to enable successful buildup of a trial recuperator core which was subsequently CNC laser welded by Creare, Inc. of Hanover, New Hampshire. Although this trial laser welded core had some small cross-stream leaks, the number of leaks was less than with any other joining technique attempted. The leaks are expected to be repairable by repeating laser welding. There is one additional trial core to be built before the full scale recuperator is manufactured and performance tested. Work was still ongoing. The PCM HX is making changes to thicker wall tubes to minimize base metal erosion or scarring during the braze process and increase structural stability. The thermal performance of the thicker-walled tubes will be assessed. In addition, Mezzo is investigating different braze alloys, the quantity of braze alloy used, and the braze cycle to control inter-diffusion in order to prevent base metal erosion which weakens the tube walls for the thinner wall tube design. GIPM is developing furnace braze processes for the Iridium\/Inconel 625 Injector, an induction braze for the Iridium\/Iridium-Rhenium Injector Chamber, and an EB braze for the Copper\/Inconel 625 Thermal Shunt Injector Spud. Analysis of brazing issues were not complete at the time this lessons learned was written. The team was satisfied that the procedures for dip brazing used on the aluminum cold plate are adequate. However, because dip braze temperatures are close to the melting point of the aluminum structure, questions remain regarding whether the material properties are negatively affected during the dip brazing process. o Witness specimen tensile testing was recommended to assess strength effects o Hardness \u2013 tensile strength curves generated by GSFC were provided for testing o The team recommended that the entire brazing procedure, specifically the amount of time at temperature, should be assessed to identify and mitigate any negative effects of the brazing process on mechanical properties.","Lesson ID":14001}
{"Driving Event":"The Landsat Data Continuity Mission (LDCM) Observatory was powered-up after installing the flight battery and all reported telemetry from the observatory was invalid. Following an extensive investigation, it was determined that an accidental short of the flight battery to the chassis occurred while the observatory single-point ground was lifted, allowing battery current to flow through the observatory chassis and damaging numerous components in the electrical power system boxes and electrical ground support equipment. One root cause of the incident was that the flight battery positive terminal was mated through a connector saver which was not properly insulated, causing a short to the battery case. The non-flight connector saver was provided as part of the battery delivery from the vendor. Since it was not flight hardware, it was not the subject of a government mandatory inspection point (GMIP) at receiving. The first opportunity for government quality assurance personnel to inspect the connector-saver was during the safe-to-mate to the flight battery. Neither the contractor nor government inspections identified the missing insulation on the back of the connector.","Lesson ID":6757}
{"Driving Event":"The Orbiting Carbon Observatory (OCO), an Earth-orbiting satellite mission managed by the NASA\/Caltech Jet Propulsion Laboratory (JPL), was designed to make precise, time-dependent, global measurements of atmospheric carbon dioxide (CO2)\u2014a greenhouse gas related to climate change. OCO was a cost-constrained project, and when the OCO spacecraft was lost due to a launch vehicle separation failure, the follow-on OCO-2 project was intended to feature a design identical to OCO with as few changes as possible. The OCO\/OCO-2 instrument does not measure CO2 directly, but rather the intensity of the sunlight reflected from the presence of CO2 in a column of air. Three spectrometers each use a diffraction grating (Figure 1) to separate the incoming sunlight into a spectrum of multiple component colors. The need to detect very small variations in intensity over a range of 3048 different colors requires high instrument resolution and precision. As the spacecraft follows a near-polar ground track, Earth observations made by the instrument switch periodically between the Nadir, Glint, and Target modes, with the Glint mode suited to observing solar radiance reflected from the ocean surface. Figure 1. The OCO-2 weak band diffraction grating (above) functions similar to the surface of a compact disk or DVD During the initial on-orbit checkout of OCO-2 following the July 2014 launch, it was discovered that the data produced by Glint mode observations did not match the model (Reference (1)). Further investigation (References (2) and (3)) revealed that the instrument design failed to transmit light polarized parallel to the long axis of the aperture slit, as needed for Glint mode. This results in the anomalous (decreased) radiance levels shown in Figure 2. (This anomaly has a much smaller impact on other observation modes, and it only affects Glint mode observations over the ocean\u2014most strongly at solar zenith angles near 52 degrees (i.e., the Brewster angle for seawater).) Figure 2. This plot of actual Glint mode radiance levels received on-orbit shows that they fail to track to the desired polarization. View larger image This design error was discovered neither in the design process, in the review process, nor by the ground test program. The error originated from a decision, made shortly before the OCO Preliminary Design Review (PDR), when a design change was implemented. Specifically, the original requirement to make the design insensitive to polarization could not be met, so the instrument was redesigned for a single polarization. The implications of this modification were not recognized by the JPL or contractor system engineers. The OCO-2 project repeated the OCO build and test activities without performing a critical review or validation of the OCO requirements and design. Factors contributing to the flight anomaly included: When responsibility for OCO Optics Subsystem assembly and test was transferred to JPL from the contractor in November 2006, the Level 4 (Subsystem) and Level 5 (Assembly) requirements were not transferred. JPL selected some Level 3 (Instrument) requirements to use for Level 4 requirements, but the polarization orientation requirement (L3G.279) was not selected. The comment associated with this decision was, \u201cIf we trust vendor data, impossible to miss.\u201d There was a conscious decision that Level 3 test would be sufficient to verify the remaining requirements. (The polarization orientation was also not covered by the Hardware Review & Certification Record (HRCR) process. See Reference (4).) Among the items listed on the Summary of Instrument Changes prepared by the OCO project in March 2003, \u201cpolarization\u201d did not appear. Subsequently, the summary of the June 2004 OCO PDR makes no reference to polarization. (Members of the OCO team felt that they were rushed to PDR and had to select only critical design elements for emphasis\u2014that excluded polarization). The OCO-2 project employed a highly tailored formulation period ending with Critical Design Review (CDR). No System Requirements Review (SRR) or PDR was held, implying a high degree of trust in the work done by the OCO project. Near the beginning of integration and test (I&T) for the OCO mission, the project decided to bring the instrument in-house from the contractor. This resulted in a transfer of I&T and verification and validation (V&V) roles to JPL without adequate continuity of involvement by the instrument designers in test design. The system test of the instrument did not include verification of the absolute polarization angle. There was no opportunity to test the instrument at the Observatory System level prior to launch. Despite the polarization anomaly, OCO-2 is able to achieve the volume and quality of science data specified in Level 1 requirements due to the implementation of an operational workaround. Using attitude control to rotate the entire spacecraft closer to the instrument\u2019s polarization response for the Glint mode operations was sufficient to significantly increase the radiance levels. The potential impact of this workaround on solar array orientation\/battery charging was mitigated by the spacecraft having healthy instrument technical margins (e.g., battery charge rate). The design of the OCO-3 follow-on instrument to be installed aboard the International Space Station has been modified to address the polarization issue. Also, a test to verify the system\u2019s correct polarization will be conducted prior to the first system-level thermal-vacuum test (Reference (5)). References: \u201cGlint data are not consistent with the prelaunch understanding of instrument polarization response,\u201d JPL Incident Surprise Anomaly (ISA) No. 57003, September 11, 2014. \u201cOCO-2 Glint Mode Polarization: Low Signals from Ocean Surfaces at Mid-Range Solar Zenith Angles,\u201c NASA\/Caltech Jet Propulsion Laboratory (JPL), September 15, 2014. Final Report, Independent OCO-2 Polarization Anomaly Assessment Team, NASA\/Caltech Jet Propulsion Laboratory (JPL), January 14, 2015. \u201cHardware Review\/Certification Requirement,\u201d NEN #656, Lesson Learned Information System (LLIS), February 1, 1999. \u201cOCO-2 Lessons are Being Applied,\u201d OCO-3 Critical Design Review (CDR), June 15-16, 2016.","Lesson ID":17001}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number OPS-17 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. Water leaks or ruptures can also spill onto sensitive flight hardware or other equipment. This technique will prevent additional repairs if overhead oil or water leaks occur from facility systems. Most importantly, this technique will decrease the electrical hazard potential to maintenance personnel by restricting the entry of water that can cause short circuits. During hoisting operations, oil can drip onto sensitive flight hardware or other equipment. If a drip pan is used, the pan can catch the oil and it can be inspected to monitor the gearbox for oil loss. Significant oil loss can cause damage to the gearbox assembly. To protect against water intrusion, design facilities with drip pans above electronic equipment as shown in Figure 1. Water sources can come from fluid condensation, firex water, or ruptured fluid lines. [D] Use of this technique could have prevented the loss of air conditioning at the KSC Vehicle Assembly Building, Orbiter Processing Facility, and the Launch Control Center when a water line, located above a main power substation, ruptured and shorted the main buses. This mishap interrupted Shuttle processing and cost considerable resources. Hoists contain gearbox assemblies that are filled with oil for lubrication and gear cooling. Gaskets that seal the gearbox housing parts or shaft seals can deteriorate over time and cause oil to leak out. Startup and vibration can cause bolts that connect the gearbox assembly together to become loose and cause oil to leak out. To capture the oil, pans can be constructed from sheet metal. Metal straps are placed on each end of the pan and loop around the front and rear of the gearbox shown in Figure 2. The oil pan should be deep enough to hold all the oil in the gearbox. However, because of space constraints a shallower pan may be used. The pan area should cover the bottom area of the gearbox. [D] For example, Bridge Buckets, located in each of the Orbiter Processing Facilities, are used by personnel to travel along the length of the Orbiter Cargo Bay for inspections. There are gearbox assemblies at various locations such as the hoisting system and the bridge drive assembly. The bucket hoisting system contains a gearbox assembly on each end of the hoist drum. Each gearbox contains a shallow pan with two straps, one on each end, that loop around the front and rear of the gearbox. This prevents any oil that may drip into the Orbiter Cargo Bay. The 250 Ton Bridge Crane, located in the Vehicle Assembly Building, contains an oil drip pan inside the hook load assembly. This prevents oil that could drip onto Solid Rocket Booster Segments or the Orbiter. Reference: SW-E-0002, Space Shuttle Ground Support Equipment General Design Requirements, section 3.4.3.1.ff","Lesson ID":879}
{"Driving Event":"Early on Saturday, April 21, 2001, a pipe in the secondary water system failed in the basement of Building 8 at the NASA Goddard Space Flight Center. The primary asset damaged by the resulting flood was the NASA photo archive, located immediately below the location where the pipe failed. It took 2 hours to isolate the secondary water system and several more hours for the system to drain through the failed pipe. As a result, much of the basement flooded to a depth of 1-2 inches. Personnel who were working in the building that morning were exposed to an electrocution hazard and had no protective equipment or proper training. No one in the clean-up or recovery crews was authorized to clear the building. Although floods are identified as a significant hazard\/threat in the Goddard Emergency Management Plan, the emergency console had no guidance or preparation for dealing with the hazards presented by this flood.","Lesson ID":1192}
{"Driving Event":"This Lesson Learned is based on Reliability Guideline Number GD-ED-2210 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Proper selection of the fiber, fiber-reinforcement form, and polymer matrix will produce a material system that 1) satisfies design property requirements thermal\/physical\/mechanical), 2) facilitates fabrication processes (lay-up and cure) and 3) minimizes program risks (cost, schedule, and technical). Implementation Method: Overview Unlike a monolithic, homogenous material or an alloy, a composite is composed of two or more materials that retain their identity on the macroscopic level. Materials composing a composite can be classified as a reinforcement or strengthening phase and a matrix or binder phase. Reinforcement materials can be ceramics, polymers, or wires. Reinforcement forms can be continuous fibers, discontinuous or chopped fibers, whiskers, particles, platelets, etc. Matrix materials can be polymers, metals, or ceramics. The primary consideration of this guideline is fiber reinforcements and thermoset polymer matrices in the most common product form, a prepreg (pre-impregnated and partially cured) sheet or ply. This is done out of practical considerations, since these composites possess the highest structural efficiency (specific properties) and are the most highly developed in terms of processing methods and material characterization (data base). Much of the information in the guideline is, however, relevant to other manufacturing forms and methods, such as Resin Transfer Molding, Filament Winding, Fiber Placement, Pultrusions, and Injection Molding. The content by volume of fibers in the composite is a critical parameter from which the composite derives thermo\/physical\/mechanical properties. A body of science called micromechanics [references 1-4] exists to predict the properties of composites as a function of fiber volume given the material properties of the reinforcement and matrix. Micromechanics will not be discussed in this article. Fiber reinforcement in a ply can be unidirectional or multidirectional. The latter applies to woven and non-woven fabrics. Choice of reinforcement form is a degree of freedom that can result in better processing and labor savings in part fabrication. Plies with either or both reinforcement scheme are stacked and cured to make a laminate. The ply fiber angles in the laminate are oriented to satisfy application design requirements (stiffness, strength, thermal expansion, etc.). Laminate design\/analysis methods will not be covered in this article. Information on this subject can be found in many publications [references 5-8]. The matrix phase is typically the material that most affects the processing, and most directly the curing of the composite. Choices for polymer matrices include a variety of epoxies, polyimides, and others. The choice of polymer matrix determines to a great degree the operational temperature limits for the composite. The matrix phase also affects other physical properties, such as outgassing and moisture diffusion. Lastly, there are additional considerations that include economic, experience (flight history), and safety considerations that factor into the selection of a composite material. Table 1 summarizes relevant selection considerations for a fiber-reinforced composite with a polymer matrix. A more detailed discussion of the selection considerations follows. Table 1. Composite Selection Considerations Fiber Considerations Thermo\/physical\/mechanical properties and relevance to end application Ply thickness and tow size availability Ply flexibility and part curvature Sizing and surface treatments for matrix bonding and wetting Cost, availability, lead time, and stable supply source Reinforcement Considerations Part curvature Ply thickness Laminate ply orientations Machining Weaving styles (drape) and weaving vendors Cost, availability, lead time, and stable supply source Resin Considerations Fiber sizing compatibility and wetting Cure temperature and related items: laminate residual stresses, tooling expansion, upper use temperature, composite glass transition temperature (Tg), and microcracking Prepeg handling characteristics: tack, drape, outlife Flow characteristics and processing method Mechanical properties: shear and tensile strength, modulus and strain compatibility with the reinforcing phase Physical properties: outgassing, moisture absorption\/diffusivity\/swelling, others Toxicity and health concerns Cost, availability, lead time, and stable supply source Other Considerations (Composite Level) Material characterization data base Flight history Cost, availability, lead time, and stable source Fiber Selection The designer or material specialist has a wide range of fibers from which to make a selection. Often a fiber is selected because of physical properties. For example, graphite or carbon fibers are electrically and thermally conductive, while aramid (Kevlar\u00ae) and glass fibers are non-conductive. In certain applications, such as an antenna reflector, electrical conduction is required. Hence, graphite (carbon) fibers are generally chosen for reflector-type applications. In other applications, for example a radome, radar transmissibility is desired. Here, Kevlar\u00ae and glass fibers are the materials of choice. Fiber selection should also consider mechanical and thermal properties. The salient mechanical properties are modulus and strength. Those for thermal properties include coefficient of thermal expansion (CTE) and thermal conductivity. Table 2 presents typical properties of some commercially available fibers presently utilized for space and spacecraft structures. Table 2. Typical Fiber Properties (Axial Direction) Trade Name\/ Type Young's Modulus (Msi) Tensile Strength (Ksi) CTE (PPM\/\u00b0F) Thermal Conduct. (BTU\/hr- ft-\u00b0F) Density (Lb\/in3) T300 33.5 530 -0.3 5 0.064 AS4 33.5 530 0.065 IM7 41.1 710 -0.5 9 0.065 T50 56.4 350 -0.55 40 0.0654 UHMS 64 550 0.067 P75S 75 300 -0.72 107 0.072 P100S 105 325 -0.8 300 0.078 Kevlar\u00ae 49 18 525 -2.2 5.3 0.052 E-glass 10.5 500 2.8 0.56 0.094 S2-glass 12.6 665 3.1 0.090 Quartz 10 500 0.3 0.0795 K1100 130-145 350-550 -0.9 550-676 .0777-.0813 M46J 63.3 611 -0.5 0.0665 M50J 69 569 -0.55 57 0.0672 M55J 78.2 583 -0.61 90 0.690 M60J 85.3 569 -0.61 88 0.0694 XN-50 75 530 -0.8 100 0.0773 XN-70 105 530 -0.9 180 0.0780 XN-80 114 530 -0.9 235 0.0780 Often figures of merit (FOMs) are used in fiber selection. FOMs are ratios of composite material properties [references 5,6], for which the fibers may be unidirectional or cross plied depending on the application. Some typical FOMs are E\/r, F\/r, E\/r\/a, and Ek\/r, where E, F, r, a, and k denote Young's modulus, strength, density, coefficient of thermal expansion, and thermal conductivity, respectively. Broadly speaking, most structural applications fall into two categories: strength critical and stiffness critical. The choice of fiber must be attuned to the driving design requirement of the application. For example, in primary structure, strength is usually the dominant factor influencing fiber selection. Therefore, F\/r is the appropriate FOM for fiber selection. Whereas in secondary structure having vibration frequency and\/or deflection requirements, stiffness may be the dominant selection factor. In this case E\/r is the pertinent FOM. For dimensionally stable applications, E\/r\/a is the meaningful FOM. For thermal applications, Ek\/r is a relevant FOM. Tensile strength and modulus are controlled principally by the fibers in the composite. Compressive and shear properties, however are derived from both the fiber and matrix and the interface (bond) between them. The thickness of a ply or layer is also determined by the fibers, more specifically the fiber diameter and the number of fibers in bundle or tow. Thin plies (2.5 mils or less) require low tow counts (500 to 1000 filaments), which are not available for some fibers. Ply flexibility, which is a function of fiber modulus and ply thickness, should be considered with respect to part curvature. For example, the brittleness and thickness of a ply with ultra-high modulus carbon fiber may preclude its use in fabricating a deeply curved part. The choice of fiber also can impact the type of reinforcement form possible. For example, ultra-high modulus graphite fibers may present weaving difficulties, which can preclude the availability of certain fabric styles with tight weaves. The availability of fabric woven with high-modulus fibers has improved greatly in the recent past. Lastly, fiber selection must consider wetting, bonding, and material compatibility of the matrix resin. A coating or sizing on the fibers is applied for these purposes. In material selection, one should be aware of the importance of a proper coupling agent between the fibers and resin. This is particularly important for carbon fibers. Coupling agents for carbon fibers are usually proprietary formulations of the fiber producer or the prepreg vendor. Reinforcement Form Choices of fiber reinforcement forms include unidirectional and multidirectional. Selection aspects of each form are discussed below. The most commonly used product containing unidirectional fiber reinforcement is prepreg tape. Unidirectional tape has collimated bundles of fibers called tows, which run in the length or long direction of the tape. Unidirectional tape gives the ability to tailor the fiber orientations from layer to layer in a laminate. This results in design flexibility. Also, the widest choice of fibers are available in unidirectional tape. Unidirectional tape is available in a range of widths. The choice of tape width can facilitate lay-up and can promote efficient material usage. An example of the latter is less wasted material from cutting ply pattern details. When laying up unidirectional tape, the continuity of the fibers should be maintained. End-to-end butt splices that result in fiber discontinuity should be avoided. On the other hand, butting the sides of adjacent layers with parallel fibers is permissible. Use of unidirectional tape to produce parts with deep, double curvature can prove difficult. Lay up may be facilitated by cutting the tape into narrow strips. However, labor increases in doing so. The most common multidirectional reinforcement form is woven fabric. Fabric weave styles can have drastically different draping characteristics, which is an important characteristic in making doubly-curved parts and those with integral flanges and bends. Harness-satin weaves are more drapable than plain weaves. Other desirable characteristics of fabrics include bidirectional properties at a minimum gage, resistance to microcracking (matrix splitting between fibers), and good machining characteristics. In a woven fabric, the fibers will be curved to some degree or another depending on the weave style. Fiber curvature results in decreased composite moduli and strengths, especially in compression. Weaving also reduces the volume available for fibers in the composite. As a result, laminates made from woven fabric composites are less structurally efficient than those made from unidirectional tapes. Recent manufacturing advancements have made possible ultra-thin unidirectional and fabric reinforced composites. These materials have been manufactured in a thickness of one mil or less for unidirectional prepreg and about two mils for fabric prepreg. Such ultra-thin composites are especially attractive for lightly-loaded, minimum gage structures. Here, the weight of the structure and, importantly, the weight savings potential of the composite are directly proportional to layer thinness. Other benefits of ultra-thin composites include less micro cracking under thermal cycling and the potential for more homogeneous laminate stacking sequences for a given laminate thickness. The latter usually results in improved strength due to a more thorough interspection of ply-angle orientations in the laminate stacking. The disadvantages of ultra-thin composites are increased handling difficulty, cost, and lead time. Fabric prepregs may offer labor efficiency in lay ups. For example, a [0\/90] (Fiber angles are 0 degrees and 90 degrees) laminate needs 50% fewer plies to be laid up using an orthogonally woven fabric, since fibers in two directions are obtained with every ply applied. Some fabric prepregs are available with hybrid fibers, such as carbon warp-yarns and Kevlar\u00ae fill-yarns, which may provide more potential design solutions. Theoretically, the possibilities of fiber type and weave style are unlimited. Practically, off-the-shelf choices are limited. Certain non-standard fabrics made from high- and ultra high-modulus fibers can be obtained from specialty weavers. The design use of such fabrics should be tempered by cost and lead-time considerations. Matrix Selection The choice of prepreg matrix resin is of critical importance in fabrication. The composite part quality is extremely dependent on the resin matrix and its handling and cure processing characteristics. The matrix vendor is usually the vendor that makes the prepreg, i.e., incorporates the fibers in the matrix. Handling characteristics are most important during ply lay up. Here the tack and drape of the prepreg are critical properties. If the prepreg is too stiff and boardy, then difficulty will be encountered in making curved parts, such as hollow tubes. Maintenance of ply-to-ply fiber orientations can be affected as well. If the prepreg is too sticky, then positioning and, in particular, repositioning of layer during layup is difficult. The handling characteristics are affected by the cumulative exposure of the resin in the prepreg to room temperature. The time limit at room temperature is called the out-life of the prepreg. For large parts especially, outlife should be considered in resin selection. Some resins have out-lives as long as 30 days; others, only several days. The resin in the prepreg determines the cure temperature of a composite part. Most epoxies and polycyanates cure around either 250\u00b0F or 350\u00b0F. Polyimides cure at higher temperatures. The cure temperature usually determines the glass transition temperature (Tg), which is associated with the useful upper-temperature limit of a composite. (Prudent design practice is to limit the use of a composite to below its Tg. The safe number of degrees below Tg depends upon the magnitude and direction(s) of the applied load with respect to the laminate fiber directions. It is advisable to experimentally confirm the maximum usage temperature of a composite for a particular application.) A higher cure temperature or, alternatively, a post cure generally raises the Tg. However, a high cure temperature results in greater cool down or residual stresses, which arise from CTE mismatches: ply to ply and fiber to matrix. Also for elevated cure temperatures, the thermal expansion effects of cure tooling become more critical, which adds to the difficulty in making parts and achieving desired dimensions. Besides the cure temperature, the prepreg resin determines other important cure characteristics, such as rheology and viscosity. These characteristics affect consolidation of the layers, most notably in the amount of voids or porosity produced during cure. The choice of resin should be compatible with the consolidation process. For example, low-flow systems are usually unsuitable for vacuum-bag\/oven processing. High-flow, low-viscosity systems can present difficulties in net-resin (no bleed) processing, since resin leakage may be difficult to prevent. The resin material also affects the contamination concerns of the composite: outgassing and moisture diffusivity. For space use, a polymeric composite must pass mass-loss and condensibles requirements, such as those defined in SP-R-0022A, MSFC-SPEC-1443 and JSC 0022-A. In addition, moisture absorbed on the ground will be desorbed in orbit. This may result in undesirable shrinkage for parts with strict dimensional stability requirements. The resin must have suitable shear and extensional modulus, strength, and strain for the composite to function correctly. Matrix shear is the mechanism through which stresses are introduced and spread to the fibers. Matrix shear and tensile strength largely factor into the resistance of an unidirectional layer in a laminate to microcracking from thermo-mechanical loads. Also, the resin must have compatible extensional strain with the fibers in the composite. Lastly, the resin material determines the toxicity of the prepreg. Resin systems with carcinogenic compounds and other unsafe ingredients should be avoided. Other Considerations These considerations deal with the economics and experience with a composite. Economic considerations include cost and availability (lead time). Experience considerations include extent of data bases and previous successful flight applications. Some space applications are given in publications [9] and [10]. The importance of the stability of the material supplier or vendor should also be taken into account, as a long term source of supply is highly desirable and sometimes essential. References: Z. Hashin and B.W. Rosen, \"The Elastic Moduli of Fiber-Reinforced Materials\", ASME Journal of Applied Mechanics, Vol. 31, 1964, pp. 223-232. Z. Hashin, \"Theory of Composite Materials\", NASA CR-1974, 1972. R.M. Christensen, Mechanics of Composite Materials, John Wiley and Sons, New York, 1979. Z. Hashin,\"Analysis of Composite Materials - A Survey\", ASME Journal of Applied Mechanics, Vol. 50, 1983, pp. 481-505. DOD\/NASA Advanced Composites Design Guide, Air Force Wright Aeronautical Laboratories, Dayton, OH, prepared by Rockwell International Corporation, 1983 (distribution limited). Military Handbook,\"Polymer Matrix Composites\", MIL-HDBK-17-3C, 4 November 1992. R.M. Jones, Mechanics of Composite Materials, Hemisphere Publishing Corporation, New York, Washington, Philadelphia, and London, 1975. S.W. Tsai, Composites Design, Fourth Edition, Think Composites, Dayton, Paris, and Tokyo, 1988. M.M.Schwarz, Editor In Chief, Composite Materials Handbook, McGraw-Hill, Inc., 2nd ed., 1992. Engineered Materials Handbook, Vol.1 - Composites, ASM International, The ASM Composite Materials Collection, Metals Park, OH. Structural Laminate Composites for Space Applications, Reliability Preferred Practice PD-ED-1217. Selection of Spacecraft Materials and Supporting Vacuum Outgassing Data, Reliability Preferred Practice PT-TE-1410.","Lesson ID":689}
{"Driving Event":"Rigorous peer reviews of spacecraft bus software resulted in good on-orbit performance. A lack of rigorous peer reviews of the instrument software have resulted in numerous on-orbit patches and changes.","Lesson ID":1294}
{"Driving Event":"During final assembly of the Deep Space 2 (DS2) Mars Microprobes, each of the two flight probes was inadvertently powered. [D] When Mars 98 lander reaches Mars and the DS2 probes are released from the lander cruise ring, a MOSFET electronic switch will apply battery power to each probe. This switch, whose design heritage is unclear, is to be operated only once during the mission. Two mechanical switches are used to provide hold-off bias voltage to prevent the electronic switch from turning on until the probes are released. Both mechanical switches must be activated to power the probes, which then remain powered unless all system power is lost. Although a safing plug keeps the electronic switch biased to the off condition during early phases of assembly, the design required its removal well before the completion of electrical assembly. The overall system implementation included the following deficiencies and vulnerabilities that were not well understood and were not adequately accounted for in the system design, the Failure Modes and Effects Criticality Analysis (FMECA), and assembly planning: The electronic switch design permitted the probes to be powered if any of the wires connected to the mechanical switches were even partially connected to ground. An estimated resistance to ground of 1.5 megohm or less is sufficient to turn on the switch. The anomaly investigation determined that even the body resistance of the assemblers connecting the wires was sufficient to cause this very sensitive electronic switch to turn on. The design of the mechanical switches allowed an unintentional ground path to the probe aeroshell. This would inadvertently power the probes during assembly, causing loss of the DS2 mission due to an undetected battery depletion prior to launch. The design did not permit the safing plug to remain installed throughout electrical assembly. The electronic switch circuit design required external power while the batteries were being connected. Following completion of the anomaly investigation, design changes were made to electrically isolate the mechanical switches and retain the safing plug in place during electrical installation of these switches. Procedures were changed to require extreme care to avoid stray resistances due to handling following removal of the safing plug. Additional Keyword(s): Power Switch, Design for Testability, Design for Manufacturability, Inherited Design, Sneak Circuit Analysis (SCA), System Integration and Test, Hardware Fabrication and Test, Hardware Safety, System Development Reference(s): JPL Problem\/Failure Report (PFR) No. Z48923, November 8, 1998.","Lesson ID":626}
{"Driving Event":"The loss of Advanced Baseline Imager (ABI) cooling capability seen on the GOES-17 weather satellite soon after its launch in March 2018 resulted in a thorough investigation of the loop heat pipe (LHP) thermal control system. One of the possible proximate causes investigated was that NCG-supported vapor bubbles might have blocked the flow regulators that are present at the end of each of the five parallel LHP condenser legs. Since anomalous performance was seen in ground tests of the GOES-17 LHPs, the physics of bubbles in the slow moving liquid (on the order of 1.5 m\/s or 5 ft\/min) was investigated. It was determined that when the radiator was tested on edge and some flow paths were vertical: Counterflow would exist in the vertical condenser passages, meaning that bubbles would not be transported through the serpentine condenser flow passage to the flow regulators. It was determined that when the radiator was tested horizontally and all flow paths were horizontal: Even large vapor bubbles would not fill the tube completely \u2013 leaving a liquid flow path underneath. This plus the fact that the flow regulator was located below the condenser tube eliminated the possibility of bubble transport to the flow regulator. In 0-g, large bubbles would fill the condenser tube and would be transported to the flow regulator with the liquid flow. The difference in behavior means that the effect of large NCG-supported vapor bubbles would be very different in 0-g and in 1-g.","Lesson ID":26703}
{"Driving Event":"During air-arcing operations under mobile launch platform-1 (MLP), a welder smelled smoke through the hole he was working on and found a fire in the floor insulation of compartment 16B. Investigation revealed that air-arcing under MLP-1 ignited hydraulic fluid that had accumulated in the floor insulation of compartment 16B. Hydraulic pumping units leaked hydraulic fluid onto the insulation for several years. Hot particles released by air-arcing blew into compartment 16B as the welder penetrated the MLP bottom panel, and the fluid ignited.","Lesson ID":118}
{"Driving Event":"The Space Shuttle mission STS-80 was launched on October 31, 1996. The mission planned for two EVAs to evaluate tools that would be used for the construction and maintenance of the the International Space Station (ISS). However, when the astronauts attempted to open the outer airlock hatch, the hatch would not unlatch. The decision was made by the mission managers not to attempt the EVAs since they did not want to risk damage to the hatch or seals. When Columbia returned to the Kennedy Space Center (KSC), following the mission, troubleshooting revealed that the outer airlock hatch actuator assembly was faulty. A new actuator assembly was installed on Columbia and the outer airlock hatch opened and closed normally. Troubleshooting on the bench revealed that one of the two Number 4-40 fasteners that hold the no-back\/clutch assembly together had backed out and was lodged between a planetary gear and the ring gear within the actuator gearbox. Furthermore, the second fastener was partially backed out and was loose (no running torque). It was also found that the threaded inserts used with the fasteners were a non-locking type when the drawing specified that a locking threaded insert should be used. Additionally, the vendor drawing did not specify a torque value for these fasteners. To resolve this issue, all actuators in the fleet were reworked to install locking threaded inserts. The vendor drawing was also updated to specify a torque on the fasteners and to verify running torque during the installation. Click here to view a video discussion of this lesson. Click here to view the video transcript.","Lesson ID":4417}
{"Driving Event":"Initially, the Constellation program did not have a leveling system for lifting\/mating the Upper Stage to the First Stage. Later, it was determined that because of center of gravity offset, some amount of leveling was needed to counteract the negative effects of off-center loading. Because the design of lifting GSE was very mature at the time, it was difficult to add active leveling capabilities to the design.","Lesson ID":4999}
{"Driving Event":"There is no requirement, policy or procedure governing the use or disposition of altered ordnance. The original test program, 90PLN-043 Engineering Plan (Effects of Aft Separation Bolt NSI Ejection on SRB Aft Strut External Tank Clevis End Energy Absorber) did not address the disposition of unexpended ordnance. Work Authorization Documents (WAD) do not contain closed-loop accountability for left-over, unused ordnance. Neither the unused unexpended ordnance nor the ammo can in which it was stored were appropriately marked to indicate the altered state of the NSI. Also, the altered condition of the NSI was not easily detectable. A First Article Review was not performed per Shuttle Engineering Directive T35R6. The CAIB NSI Ejection Tests were performed in August 2003 using a strut assembly with clevis installed, which may have given the technicians and engineers a false sense of altered ordnance acceptance. The test conducted within the struts masked the power of an uncontrolled ejecting NSI.","Lesson ID":1582}
{"Driving Event":"The OPF environmental control system (ECS) supplies conditioned air through ducts to the orbiter to purge and pressurize the forward\/aft compartments and the payload bay. Over-pressurization could occur during ECS purge if the ventdoors are closed. No automatic monitoring and\/or control exists to preclude simultaneous application of ECS purge air while all orbiter vent doors are closed, or to automatically relieve excess pressure under these circumstances.","Lesson ID":84}
{"Driving Event":"The total elapsed repair turnaround time still can be excessive with a resulting major impact on inventory management. There are several contributing causes for this that were discussed briefly in the 1990 annual report, but one of the key issues is the average time involved in the engineering analysis of failed components. The overall trend of repair turnaround time showed a significant improvement toward the end of the year, but in some cases, notably the components overhauled by the original equipment manufacturers, the time is much too high. Management emphasis currently is being directed to the entire problem of reducing repair turnaround time and should continue.","Lesson ID":221}
{"Driving Event":"During STS-121 ascent, the Xo 378 bulkhead delta-pressure transducer showed higher than normal pressure differential across the bulkhead. Following the STS-121, ground borescope inspections on FRC3 showed that TCS blankets in the FRCS module were very close to the vents, and were not installed under the Purge Vent Drain (PVD) lines. Design intent is to install the V070-361995-024 Left Hand (LH) and V070-361995-025 Right Hand (RH) Multilayer Insulated blankets (MLI) under PVD drain lines in the FRCS. The blankets contain existing cutouts and cutlines, allowing installation under these lines. When properly installed, the blankets are restrained by the PVD drain lines and cannot billow into the Xo 378 vent areas. Using templates to simulate a Xo378 vent port, TCS Engineering determined that blockage of the vent ports can occur when blankets are installed on top of the drain lines. Improper installation of the TCS blankets was determined to be the cause of the vent anomaly.","Lesson ID":2716}
{"Driving Event":"The Project underwent several significant transitions including going from a proposal team to an implementation\/project team; Principal Investigator (PI)lead academic or science team to a Project Manager (PM)lead hardware development\/delivery team; and PM to PM. Within these transitions the Project struggled with two issues that were major obstacles to implementing a \"project\" oriented environment. First, the Project had difficulty recognizing the incoming PM as an authority over the PI, who in this case was a well-known and respected scientist that germinated the Project concept. The Project team's loyalty to the PI coupled with the abruptness with which PM's were assigned lead the project team to view the incoming PMs as outsiders unfamiliar with the Project's purpose or style who insisted on unfamiliar and time-consuming operating requirements\/processes. Second, the Project, which had originally been a small scientific research team, had difficulty establishing and applying formal\/rigid project management processes. Thus, the inadequate PM involvement during the proposal stage coupled with the un-facilitated\/unmanaged transitions never allowed the team to mature into an integrated project. The result was that the Project's initial planning was off (as described in a companion LL on cost estimating) and the subsequent attempts to redirect it through formal PM processes were unsuccessful.","Lesson ID":1345}
{"Driving Event":"Two technicians were transferring liquid nitrogen from a vendor tanker to a tank trailer. Near the end of the operation, visibility was severely limited due to fog caused by venting nitrogen, leading to a decision to shut down the operation until the visibility improved. While shutting down the transfer operation, the technicians became unconscious due to lack of oxygen but recovered with no ill effects after being rescued by the tanker drivers. Technicians were wearing PPE for protection against frostbite, spills, etc., but did not include equipment to detect lowered oxygen levels or to supply breathing air. At JSC there are a large number of nitrogen containers. The areas surrounding the larger, permanent containers do not normally present pockets in which to trap nitrogen; however, on still days there could be oxygen-deficient areas near the connection the vent, or the 90% fill valve. The smaller portable containers (dewars) could be located in potentially confined areas, also presenting the potential for an oxygen-deficient atmosphere.","Lesson ID":550}
{"Driving Event":"A feedthrough condition occurs after most JPL spacecraft launches during initial acquisition of the downlink signal. The station's downlink signal performance indicators are affected by feedthrough from the uplink to the downlink. This feedthrough source may be uplink transmitter noise or, if there is ranging modulation, it may be components of the uplink ranging channel. In current link designs, the condition does not noticeably degrade the telemetry or ranging signals processed from the downlink for delivery to the project. Feedthrough occurs because of the extremely strong uplink signal over a distance of just a few thousand kilometers; this has the effect of reducing the station's reported value of downlink carrier power or of telemetry signal-to-noise ratio. Saturation effects in the station's receiver software algorithms contribute to the indications of signal degradation. This saturation causes the indicated signal-to-noise ratio to top out at a particular value even when the expected level may be tens of dB higher. One variation on this problem was experienced by both Mars Exploration Rover (MER-A) and Mars Odyssey. The initial acquisition downlinks from both missions experienced post-launch downlink saturation effects that produced lower-than-predicted downlink levels. In this case, uplink ranging data power harmonics feedthrough caused a \"pedestal effect,\" effectively raising the noise floor in the station receiver and degrading a key estimator (Symbol Signal-to-Noise Ratio). A related problem was documented in a lesson learned written on the Voyager mission. Voyager experienced command feedthrough problems because the uplink command modulation index (carrier suppression) that was optimal for commanding tended to degrade X-band telemetry. Link accommodations were successfully implemented by the Voyager mission. The problem described in Reference (1) has since been \"designed out\" with the 16 kHz command subcarrier frequency used by modern transponders in place of the Voyager-era 512 Hz. None of these strong-signal receiver nonlinearities affect the ability of telemetry subsystems to support ongoing activities. However, the apparent downlink signal degradation tends to elicit consternation in a critical phase of the mission if these expected effects have not been thoroughly coordinated between the Flight Project and the Deep Space Network, or if the Flight Control Team (FCT) has not yet become fully familiar with this idiosyncrasy of the mission operations system. References \"Command Feedthrough Problem on Voyager X-Band Downlink,\" NASA Lesson Learned No. 0418, March 7, 1979 Additional Key Words: Communication Link, Spacecraft Commanding; Signal Acquisition; RF Compatibility; RF Interference; Downlink Degradation; RF Interference; Radio Frequency Subsystem; Communications","Lesson ID":1531}
{"Driving Event":"During a materials science investigation process run within the MSG on-board ISS on 7\/23\/02, the SUBSA Eurotherm Controller (Zone 1) on the Process Control Module (PCM) would not take a command to raise the Thermal chamber main heater setpoint above 825 degrees C. Files were uplinked to query setpoint limits in the Eurotherm Controller; a local Mod Bus setpoint limit of 825C was found and confirmed why the anomaly occurred. SUBSA's Investigation Control Software (ICS) was reconfigured to route Zone 1 setpoint temperature commands to Mod Bus 160 instead of Mod Bus 24 in the Eurotherm Controller. The Mod Bus 160 command address does not have a local setpoint limit. The desired setpoint of 845 degrees C was properly configured. After these steps, no further problems were encountered prior to the completion of all on-board experiment processing.","Lesson ID":1319}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1221; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Selection of the optimum battery for space flight applications results in a safe, effective, efficient, and economical power storage capability. The optimum battery also enhances launch operations, minimizes impacts to resources, supports contingency operations, and meets demand loads. Implementation Method: Primary batteries, those which are not recharged are and useful for short duration, are used principally for providing electrical power for launch vehicles. These batteries must have high energy density, high current capabilities, and good reliability. MSFC has had experience with Lithium\/Monoflouride (Li\/CF), Lithium\/Thionyl Chloride (Li\/SOCl2), and Silver\/Zinc (Ag\/Zn) primary batteries. Secondary batteries, those which are discharged and then recharged numerous times, are principally used for spacecraft, satellite, and other long-term space-oriented applications. In space applications, reliability, costs, producibility, responsiveness, risks, safety, and maintainability are more important than high current content. MSFC has had experience with Silver\/Zinc (Ag\/Zn), Nickel\/Hydrogen (Ni\/H2), Nickel\/Cadmium (Ni\/Cd), Nickel\/Metal Hydride (Ni\/MH), and Bi Polar-Lead Acid (Bi-Pb\/Acid). [D] Battery types are selected for specific applications based on a number of factors including specific energy and energy density (see Figures 1 and 2), lifetime, number of cycles, discharge rate, charge retention, shelf life, ruggedness, operating temperature, and other factors. Figure 3 presents these factors for various battery types. Figure 3 should be used by the designer as an initial tool for selecting the required battery type. The design of batteries for space flight should be accompanied by battery level electrical, mechanical and thermal analysis. [D] A typical battery selection flow chart is shown on Figure 4. After the program is identified and electrical power requirements are established, a trade study should be performed to determine the actual battery (primary or secondary) that will fulfill the requirements at a reasonable cost. Cell selection includes charge voltage, discharge capacity, and discharge voltage after cycling. Establishing the battery size is determined by the number of cells required to provide the required electrical power, i.e., a 24-volt battery using a 1.5 volt cell will require 16 cells. Mechanical packaging of the cells into a battery requires such parameters as cell type, number of cells, weight, length, height, temperature requirements, mounting method, vibration environment, electrical feed through, and venting requirements to ensure proper functioning of the battery. Perhaps the most important part of selecting a battery is the selection of a reliable cell\/battery manufacturer. Preferably one that has consistently produced high quality and reliable batteries. Manufacturing engineers should critique the design for producibility and testability early in the design process and make corrective suggestions when problems are discovered. [D] Accelerated life testing of batteries is extremely difficult due to the nature of the chemical reaction between the electrolyte and the positive and negative electrodes. Therefore, preferred type and configuration of the battery should be selected early in the program to allow for lifetime testing. Performance testing of the selected battery can be accomplished in parallel with life testing. Performance testing should be accomplished in an environment to which the battery is expected to be exposed during operation. The battery should demonstrate during testing that it will deliver the required electrical power and will charge and discharge as designed. Technical Rationale: MSFC's aerospace flight battery experience comes from a combination of its own in-house laboratory experience on numerous programs; from coordination with battery manufacturers, prime contractors, and subcontractors for a number of launch vehicles, space vehicles, and experiments; and from many years of participation in NASA\/industry aerospace battery workshops. Two such workshops, hosted by the Marshall Space Flight Center in Huntsville, Alabama, were attended by approximately 200 persons each, representing both Government and industry. Credit must be given to the interdisciplinary efforts of Goddard Space Flight Center, NASA Headquarters, Jet Propulsion Laboratory, Johnson Space Center, Kennedy Space Center, Ames Research Center, Langley Research Center, Lewis Research Center, and their suppliers and contractors, as well as to many academic and nonprofit organizations who have contributed to the battery research leading to this body of knowledge. References: Bykat, Alex, quotDesign of an Expert System for Diagnosis of a Space Borne Battery Based Electric Power System,quot University of Tennessee at Chattanooga, IECEC, Vol. I Aerospace Power Systems Conference, August 1990. Dunlop, J. D., quotNASA Handbook for Nickel-Hydrogen Batteries,quot Preliminary Draft, Goddard Space Flight Center, June 1991. Glover, D.G., quotAerospace Energy Systems Laboratory: Requirements and Design Approach,quot Ames Research Center, Dryden Flight Research Facility, Edwards AFB, CA, NASA Technical Memorandum 100423, 1988. Guthals, D.L. and Olbert, Phil, quotCRRES Battery Workshop,quot Ball Space Systems Division, letters dated March 11 and 16, 1992. Halper, G., Subbarao, S., and Rowlette, J.J., quotThe NASA Aerospace Battery Safety Handbook,quot JPL Publication 86-14, July 15, 1986. Jones, Dr. G.M., quotATM Electrical Power System Post Mission Design and Performance Review,quot George C. Marshall Space Flight Center Report No. 40M22430, February 6, 1975. Kennedy, L. M., quot1990 NASA Aerospace Battery Workshop,quot 1991, NASA Conference Publication 3119, Marshall Space Flight Center, December 4-6, 1990. Linden, David, Handbook of Batteries and Fuel Cells, McGraw Hill Inc., 1984. Manned Space Vehicle Battery Safety Handbook, NASA, Johnson Space Center, JSC 20793, September 1985. MIL-B-81502B(AS), quotBattery, Silver-Zinc-Alkali, General Specification for,quot February 26, 1980. MIL-B-82117D, quotBattery, Storage, Silver-Zinc, Rechargeable, General Specification for,quot July 25, 1983. NASA SP-172, quotBatteries for Space Power Systems,quot NASA 1968.","Lesson ID":714}
{"Driving Event":"On 8\/28\/97, the last working day before Labor Day weekend, a Contractor's was installing a 3\" copper underground compressed air line into a trench approximately 18\" wide and 3 feet deep. After having completed about 100 feet of pipe, the Contractor's crew began a pressure test of the 3\" pipeline for acceptance. The test was performed prior to installation of a secondary fiberglass pipe to cover the 3\" copper pipe and backfill the trench. The specified working pressure of the 3\" copper compressed air line was 125 PSI. The specified test pressure was 188 PSI. While the 3\" copper line was still under pressure test, the crew began to install the secondary fiberglass pipe to encase the 3\" copper primary pipe. As the crew was lowering the pipe into the trench, approximately 2:45 PM, the crew heard the sound of a \"pop\" and then the sound of leaking air coming from a pipe joint coupling. While the 3\" copper line was still under pressure, one worker went into the trench attempting to check the location and the extent of the leak. While the worker was checking the position and direction of the leak from the pipe coupling, the soldered joint failed and the pipeline de-pressurized explosively. An 84-foot section of the pipeline that lead from the bottom of the trench to ground level was propelled approximately 8 to 9 feet longitudinally along the edge of the trench. Air from the explosive depressurization blew sand and soil on the worker in the trench. The sand abraded the worker's arms, chest, and abdominal. The pipe also struck the worker in the left knee and groin area. The worker was taken to the Edwards AFB Hospital for treatment. The worker was released from the hospital after treatment that evening. The worker was wearing personal protective equipment (PPE) including a hardhat, boots, safety glasses, and gloves at the time of the accident.","Lesson ID":1096}
{"Driving Event":"MLG tire heat generated from max. Braking due to a crosswind landing, heavy orbiter, or long landing, could cause a transfer of heat to continue to the MLG tires after wheel stop, resulting in a delayed tire blowout. An explosive tire rupture caused by increasing tire pressure, cuts, excessive loading, or skidding could injure personnel and\/or damage the orbiter\/chassis hydraulic system\/ground support equipment. Three thermal relief plugs in each MLG tire prevent tire overpressurization, the orbiter anti-skid\/brake control system prevents locked brakes, and the orbiter hydraulic system displacement limiter limits hydraulic fluid loss.","Lesson ID":128}
{"Driving Event":"A mishap occurred when technicians did not follow the sequence of events specified in the PR disposition for assembly of the thruster and fixture. The T-shaped mounting fixture was secured with only one C-clamp to an access platform's kick plate that had vinyl tape on both sides. The C-clamp was improperly used to prevent rotation and the vinyl tape acted as a lubricant between the clamped surfaces. These conditions allowed the offset weight of the mounting fixture\/thruster assembly to overcome the clamping force and rotate about the single C-clamp and fall.","Lesson ID":43}
{"Driving Event":"At the time of the mishap, the injured worker and a co-worker were removing 277\/480 volt electrical kilowatt-hour meters for calibration. The meters are associated with the building power distribution system serving Building 4400. Unfortunately, while performing the meter removal task, the affected employee installed the metal cover of a meter panel enclosure onto electrically energized knife switches located within the enclosure. This action caused an electrical short resulting in the arc flash that injured the worker and also caused damage to the meter panel assembly. The worker was not wearing the PPE gloves required to perform the task, (i.e., the worker installed the cover with bare hands.)","Lesson ID":2696}
{"Driving Event":"The original EMI filters on MIDAS were not matched with the power converter, and were not successful in keeping the EMI below the required level.","Lesson ID":543}
{"Driving Event":"Current policy for classification of mishaps, and hence mishap investigation procedures is done by dollar value of loss or injury severity.","Lesson ID":1237}
{"Driving Event":"The Lewis implementation had a flawed attitude control system (ACS) design and simulation deriving from technically invalid application of a design from an earlier mission. This misapplication ultimately led to the spacecraft failure when the system encountered an untested instability during a \"safe hold.\"","Lesson ID":595}
{"Driving Event":"The basis of the Z1 ITS modeling strategy in the preliminary and conceptual design phases was a simplified beam element representation of the primary structure bulkheads and panels. This facilitated rapid, automated beam based stress analysis of the primary structure and decreased the design cycle time as well as manpower loading. The same model was used for both (1) the design dynamic-coupled load analysis and (2) the pre-test model and static test prediction analyses. The pretest model analysis model produced poor correlation with the model test data. The correlation was improved by remodeling critical bulkheads and panels in greater detail using shell elements for the basic web and shell\/beam elements for the upstanding ribs & flanges. Solid elements were also used where \"plate\" proportions did not exist. The increased fidelity of the post-test model led to improved correlation with the static test as well. However, the changes made to the model have forced a re-evaluation of the internal stresses both because of the change in model response and\/or load paths. This re-evaluation came long after the design of the hardware was finalized and manufacturing completed. Any adverse findings from this re-evaluation could lead to costly retrofits or undesired limitations on hardware use during operations.","Lesson ID":1223}
{"Driving Event":"Location of the check valve in the hydraulic filter module prevented ground supply pressure being applied to supply flex hose. This supply flex hose is between the filter module and the hydraulic main pump outlet. The intent of the check valve is to prevent spinning the pump during ground hydraulic testing using ground support equipment (GSE).","Lesson ID":3221}
{"Driving Event":"The purpose of the Standard Autonomous File Server (SAFS) is to provide automated management of large data files without interfering with the assets involved in the acquisition of the data. It operates as a stand-alone solution, monitoring itself, and providing an automated level of fail-over processing to enhance reliability. The successful integration of COTS products into the SAFS system has been key to its becoming accepted as a NASA standard resource for file distribution, and leading to its nomination for NASA's Software of the Year Award in 1999.","Lesson ID":1346}
{"Driving Event":"In a scenario that is most likely to occur on severely time-constrained flight projects, testing is interrupted and test time is lost because of unreported changes to the testbed configuration. During subsystem integration and test (I&T) of Mars Exploration Rover (MER), for example, a software test operator spent two hours at a keyboard preparing for a special MER flight software (FSW) test case. When the test began, the system crashed, and extensive troubleshooting disclosed that the test operator had been unaware that the previous shift had removed the Rover camera from the testbed. Other similar incidents might stem from a loose cable caused by an equipment swap. This problem is exacerbated for projects like MER where system development continues even while testing is underway in dual work shifts. JPL flight system I&T programs typically implement the following steps to minimize lost test time: A meeting is held at the beginning of each I&T shift to brief the incoming team on changes to the testbed configuration. A startup procedure, maintained for each testbed, is continually updated to reflect the current testbed configuration. An on-line reporting tool is used to capture the activities of each test shift, document hand-over instructions to the next shift, report changes to the testbed configuration, and provide links to problem\/failure reports generated during the shift. A spreadsheet reports the status of connectors and cables that have been mated or demated. A walkthrough of the testbed configuration prior to each work shift would likely have prevented the MER test errors. They were not feasible for MER, though, because there were several hundred connectors in each testbed, and not all of them were visible to the operator. References: System Test and Launch Operations (STLO) Guide Executive Summary, Rev. 2, JPL Doc ID 31335, September 18, 2000, Para. II E. Subsystem Integration and Test for PPS, C&DH, and GN&C Subsystems, Rev. 0, JPL Doc ID 65633, December 12, 2003, Paras. 5.11, 6.8. Additional Key Words: subsystem test, test configuration, test bed, test procedure, test plan, ATLO, assemble, test, and launch operations","Lesson ID":1520}
{"Driving Event":"The excessive torque problem was due to improper assembly. The mechanical stop mounting screws were loose permitting the mechanical stop to move away from the housing toward the control housing.","Lesson ID":454}
{"Driving Event":"This Lesson Learned is based on Reliability Guideline Number GD-ED-2203 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Use of this guideline will ensure continued improvement with the use of microcircuits in circuit designs by incorporating data from previously experienced problems into a design checklist. This will apply the experience base from the past and thus provide improved reliability for future space programs. Technical Rationale: Information gathered from a history base of known problem areas is presented in easy-to-use checklist form to be used by designers, etc. The checklists are separated into three categories, based on device technology (TTL, CMOS and memory). The guideline can then be used as a reference to avoid incorrect utilization of these component types in circuit design applications which may result in potentially poor reliability. TTL DESIGN CHECKLIST 1 Only gates from the same package should be connected in parallel. 2 Take note not to exceed fan-out limit (maximum number of circuits fed input signals from a single output terminal). 3 Check pin compatibility when using devices from different families or manufacturers. 4 Check manufacturer interchangeability for minor functional differences. 5 Maintain equal loading in ac and dc terms on multiple output devices with internal feedback. 6 The dynamic threshold of low-power schottky (LS) gates varies between 1.1 V and 1.4 V depending on circuit configuration; therefore, slow rise times (greater than 50 nanoseconds) will possibly cause pattern sensitivity. 7 Gates with outputs driving transmission lines should be situated close to the board periphery. 8 Consider full-range temperature effects on switching characteristics relative to design application. 9 Use pull-up resistors on devices with open collector gates. 10 Consider the frequency dependency of power dissipation when the operating frequency is greater than 1 to 2 MHz. 11 If decoded outputs from counters, particularly from ripple counters, are being used as clocks to drive counters or memory devices, the decoded outputs of interest should be examined for multiple pulses at counter transitions that might ambiguously operate the driven counters or memory devices, and corrective measures should be taken to non-ambiguously operate the driven circuits. 12 Take note that low-power, low-power Schottky, and Schottky TTL circuits are known to fail when exposed to 5 microjoules or more of electrostatic discharge (ESD) energy. 13 Consider \"current dumping\" effects when a multiple input gate is terminated to a single high impedance source such as a 150-ohm line. 14 All unused input pins should be tied to high- or low-logic levels, depending on the circuit application. When devices approaching their maximum speed for TTL are used, unused inputs should be \"commoned\" to used inputs rather than tied high; whereas for low-power Schottky devices with diode inputs, the unused ones can be directly connected to VCC. 15 Provide isolation for test points so that any foreseeable occurrence, such as shorting between, grounding or external excitation at the test points will not disrupt operational use of the circuit being monitored by the test points. 16 Consider potential problems involving the use of multiple flip-flops controlled by one or more asynchronous output. 17 Check interfacing parameters (fan-out, loading, and threshold) when using devices from different families. CMOS DESIGN CHECKLIST 1 Allow for hold-time and setup-time requirements of CMOS flip-flops, registers, and latches. Inputs to CMOS devices must be stable before and remain stable even after the active clock pulse edge. 2 Take adequate precautions to avoid ESD damage. 3 Account for possible incompatibilities with similar part numbers from different manufacturers when establishing parts lists. 4 Investigate the package choice\/reliability tradeoff for each design application. 5 When using single-stage (unbuffered) multiple-input CMOS devices, consider that both dynamic and static performance of these circuits can deteriorate under certain logic conditions to the extent that logic systems display pattern sensitivity. 6 Protect signal inputs against overvoltage spikes and input currents exceeding ratings, i.e. many CMOS devices have ten milliamperes as the maximum allowable input current. Consider that if the overvoltage spike is greater than the supply voltage, the parasitic PNP or NPN transistors become forward biased and latch-up can occur. 7 Excessive current through switches results in latching and destructive breakdown; therefore, protective circuitry is essential. 8 Consider the noise margin when using 5-volt supply levels. CMOS has an order of magnitude less energy noise margin than TTL (approximately 0.4 nanojoules for CMOS and 4.0 nanojoules for standard TTL). 9 The power supply should switch on by itself first before signal inputs are applied, since damage may occur if the diode between input and VDD is forward biased. 10 Slowly rising or falling input signals can lead to multiple triggering, particularly if the supply voltage is poorly regulated, and also to higher supply (IDD) currents. 11 Maximum power dissipation of the device could be exceeded if input rise and fall times are greater than 15 microseconds, (depending on device type) especially using high current drivers with high supply voltages. 12 Terminate all unused inputs; a floating input can turn a CMOS device on, causing faulty operation and possible damage, and also uses increased power since both p- and n-transistors are partially conducting. 13 Ensure that interfacing parameters between CMOS and other logic families are correct, particularly with regard to loading and thresholds. 14 Keep interconnections short or use terminations, as long interconnections in high speed systems behave like transmission lines, which can cause reflections and ringing. 15 Do not use CMOS gates as linear amplifiers; this can destroy buffer gates, cause failure of the device to operate below 4 volts, and make supplier interchangeability even more problematical. 16 Avoid long, closely spaced, parallel traces on PCB's to minimize crosstalk. 17 Flip-flops with transmission gate inputs are particularly prone to malfunction if the inputs are driven above and below the supply voltages. This can occur when interfacing from other logic families and from distant boards. 18 Try not to design to typical values because of the large part-to-part process variations. In many cases guaranteed values are several orders of magnitude larger than typical values. 19 Reduce ground\/power supply inductance (power\/ground planes) and use sufficient decoupling capacitors, as simultaneous switching of multiple outputs causes noise and voltage drops on power supplies. MEMORY DESIGN CHECKLIST 1 Avoid using parts at their maximum supply voltage tolerance and\/or at their maximum speed. In a large memory system, noise, loading, and skew problems result in reduced apparent working area and reduced effective speed. 2 Consider carefully the difficulty in \"second sourcing\" with memory components, since they are far more complex than standard medium scale integration components (MSI); and very few, if any, have identical replacements. 3 Avoid mixing several technologies within the same memory system. If this is done great care must be taken to ensure that at no time are the pins of any memory component pulled beyond the component's substrate voltage. 4 When read-only memories (ROM's) are used to replace wired logic gates, the outputs may show noise or extra transitions, since the ROM is not guaranteed to give a single output transition for a single input transition. 5 In the use of nichrome fused bipolar programmable read-only memories (PROM's) there has been evidence of fuses growing back after programming and of unblown fuses being subject to decay. Ensure that special freezeout tests and high voltage stressing have been carried out, and also consider the greatly delayed production cycles involved. 6 Take note when using PROM's that the programming operation on devices from the same family are not necessarily compatible. Examples are the 1602 and 1702 devices in which the programming operation forces \"ones\" to \"zeros,\" and the 1602A and 1702A devices which force \"zeros\" to \"ones.\" 7 Caution must be taken when using common bus lines not to allow more than one device to be enabled at a time. System noise and incorrect data problems could result, and depending on output drive capability, physical damage to the device could occur. 8 In order to minimize transmission line problems, the driver elements should be located as closely as possible to the memory elements, keeping the connecting printed circuit lines as short as possible. 9 Asynchronous input signals applied to a ROM should be permitted to change within an access time sufficient to meet setup and hold times, prior to clocking the output register. If this does not occur the contents of the output register may be completely unpredictable. 10 Periodically check PROM programming electrical specifications, since manufacturers often change their recommended programming method to improve programming yields. 11 Ensure the correct programming conditions (voltage, duration, etc.) when programming PROM's. 12 Ensure that shift register drivers have sufficient dumping capabilities, otherwise positive or negative spikes may be coupled from one clock to the opposite phase. Spikes may reach over the substrate voltage and activate parasitic substrated transistors and destroy data. 13 Memory products usually dissipate power at significantly higher levels per package than most large-scale integration (LSI) and MSI components. It is therefore very important that adequate cooling arrangements be made, because the power dissipation per unit area can approach an order of magnitude greater than ordinary TTL. 14 Allow in the design for the ROM\/PROM access time differences from various parts of the array. Differences of four to one have been found for various address locations. 15 Take caution when using dynamic MOS shift registers (SR's) as low-speed power-saving circuits, since data can be lost if the SR clock speed is reduced instantaneously. The lower frequency limit applies only at high ambient temperatures and not at self-heated high-junction temperatures produced at high clock frequencies. 16 Take note that when using floating gate metal oxide semiconductor (MOS) PROM's, bit loss occurs under x-ray and nuclear radiation. In addition, problems of inadequate erasure due to poorly calibrated ultraviolet sources can arise. 17 Take caution when using MOS electrically alterable PROM's, since data loss can occur from cells subjected to greater than 109 accesses. Given an access time of 1 microsecond, the data could be lost within an hour if continuous reads are made from one location. 18 Power supply slew characteristics should be evaluated carefully. Two separate problems have been noted. One problem is that at switch-on, a slowly rising power supply may not initialize the random access memory (RAM) logic correctly so that a subsequent initializing procedure is required. Another problem is that sharp, small supply voltage changes that occur in normal memory system operation can cause data loss in some supplier dynamic memory products. 19 Operating temperatures have to be considered very carefully. Because of their complexity, memory components tend to be more sensitive to temperature extremes than other types of devices. 20 Consider that large MOS memory systems often require error correction and detection (the inclusion of \"Hamming\" error correction codes in the design). This approach improves the effective system reliability by two orders of magnitude, and the associated error indicators simplify scheduled maintenance. 21 Consider access time measurement criteria carefully. While some manufacturers measure access times to the VOL and VOH voltage levels, others measure access to the 1.5 voltage level for both high- and low-level outputs. Additionally, some suppliers specify two output loads in their dc characteristics, but measure access time against one output load. 22 Many dynamic RAM's require a substrate bias supply (VBB) to ensure correct operation. Unless this bias supply is raised before the main supply and dropped after the main supply, high currents may be drawn. Also, if the bias supply is reversed even in a transient mode, the parasitic substrate transistor will draw extremely high currents. Since the internal capacitances of the RAM are terminated to the substrate, very good transient bypassing is required. 23 Take care when using bipolar memory devices (e.g., many ROM\/PROM devices) with PNP transistor low-power Schottky style inputs. It is important that the inputs not be pulled below ground until the PNP device is saturated; otherwise, very long access times will be observed. 24 Allow for input\/output coupling features of static RAM's in the system design. Although possibly not shown on the write-cycle data published by the manufacturers, the input data may appear on the output during the write mode. References: MIL-M-38510 Microcircuits, General Specification for MIL-STD-975 NASA Standard Parts List MIL-STD-978 NASA Parts Applications Handbook MIL-STD-1547 Electronic Parts, Materials and Processes for Space and Launch Vehicles MIL-STD-1562 Lists of Standard Microcircuits","Lesson ID":680}
{"Driving Event":"Prior to being operated at KSC, SKYLAB hydraulic systems were tested for contamination. If the systems were found to be clean, they were sealed and not retested. After being operated at KSC, a water system pump failed. A new pump was installed and a fluid sample was taken from the failed pump. Analysis of the fluid sample showed gross contamination. It can also be noted that in following missions, water system pumps failed repeatedly, all due to contamination. Fluid system cleanliness levels were not maintained throughout assembly operations. Plumbing, component, or installation cleaning procedures resulted in cleaning to dissimilar specifications, which were not compatible with various hardware. Component tolerances should be such as to allow particulate contamination of specification levels to pass without failing the component. Filtration, with a filter change-out capability after demonstrated life, should be placed in the system to collect particles. Additional Sources: MSFC Documentation of Significant SKYLAB Experiences, Dated 15 Nov 1973","Lesson ID":244}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number GSE-3008 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Proper control of electrostatic discharge can significantly reduce the possibility of: Inadvertent ignition of solid propellants, explosives and flammable\/combustible materials, Inadvertent actuation of electronic devices\/systems Personnel shock or injury and Ground Support Equipment (GSE) hardware\/equipment damage that could lead to flight hardware damage. Implementation Method: Electrostatic controls are implemented at KSC to reduce the effects of ESD during the following operations: General STS and Payload Operations - The percent relative humidity in an operational area is recorded every four hours prior to the start and during operations involving exposed solid propellants, open flammable\/combustible fluid systems and category A Electro-explosive Devices (EED) when the Faraday (electrically conductive shield) cap is removed or firing circuits to EEDs are exposed. At or below 50% RH, bonding and grounding measures are verified. In addition, non-conductive materials in the area and personnel not wearing personnel grounding devices are checked with an electrostatic meter to ensure voltages greater than 350 volts are not present. Electrostatic scanning, not exceeding one hour intervals, is performed during the operation when at any time: additional personnel, equipment or hardware are introduced into the immediate area, the RH decreases, or the handling of non-conductive materials is required. At or below 30% RH, operations involving exposed solid propellant, except Solid Rocket Booster (SRB) segments, or open flammable\/combustible fluid system and category A EEDs (with Faraday caps removed or firing circuits exposed) are not permitted. In the Orbiter Processing facility (OPF), the RH is controlled to within 40 - 50% thus minimizing the effects of ESD. STS SRB Processing - Segment processing may continue below 50% RH using the following guidelines, segment processing is not permitted at or below 10%: Between 50% and 30% RH the above requirements apply. With proper approval, operations may continue at RH levels below 30% down to 10%. In addition to the above requirement, electronic scanning is required to to be accomplished at 10 minute intervals if the propellant is exposed, and at 30 minute intervals if the propellant is covered. At no time will operations continue on the segments with propellant exposed and a potential of 350 volts or greater is measured on the segment case, propellant, or any equipment\/personnel within five feet of exposed propellant. When the segment and rings with shipping covers are installed (propellant protected by a Faraday cage), the following guidelines apply: A reading of one kilovolt or less on the case is acceptable and work may continue. A reading of greater than one kilovolt, but less than four kilovolts on the case requires all segment processing to cease and personnel will stand back four feet. An electrostatic scan will be repeated every five minutes and recorded. If the reading of one kilovolt or up to four kilovolts exists for 30 minutes, connection to facility ground will be verified. If this connection is open, then the ground will be reconnected thru a resistor (1 Meg ohm +\/-20%). Processing may continue when the electrostatic scan indicates less than one kilovolt. An electrostatic reading of four kilovolts or greater requires all work to stop. All personnel will evacuate to a location 500 feet from the processing area. Designated personnel may re-enter for electrostatic scan. This scan is repeated not less than every 15 minutes. No attempt to check grounds will be performed. If, after an hour, readings still exceed four kilovolts, then a separate ground with a resistor (1 Meg ohm +\/- 20%) in line may be connected to another ground point on the segment case. Work may resume when a reading of one kilovolt or less is obtained and all grounds have been rechecked. Launch Processing System (LPS) Operations - LPS operators coming in contact with the LPS hardware subsystems are required to wear approved grounding wrist straps during test and launch processing operations in environmental conditions below 45% relative humidity. LPS system, maintenance, or support personnel coming in contact with low voltage LPS hardware Line Replaceable Unit (LRU) \/ Components are required to wear approved grounding wrist straps at all times. LPS \/ Checkout, Control and Monitor Subsystem (CCMS) console stations are equipped with approved terminated ground cables containing quick connect \/ disconnect type wrist strap snaps. Systems, maintenance or support personnel will connect the grounding lead clip to a conductive surface on the LPS grounded hardware structure. Testing stations are available for proper go\/no go testing of the approved grounding cable and wrist straps. Logistics - The effects of ESD on static sensitive Line Replaceable Units (LRU's) during transportation and storage is alleviated with the use of transparent electrostatic-shielding bags. This packaging scheme affords static protection against both external static fields and internal triboelectric charge. All programmable read-only memories (PROM's) are transported and stored in static-shielding tubes or approved foam and shielding bags for distribution to installation in LPS hardware sets. These tubes protect against triboelectric charging and direct discharge yielding a dynamic response rating of less than 1 millisecond. All integrated circuits (IC's) for temporary staging are placed (leads inserted) on crosslink, noncorrosive, high density, conductive foam. This foam ensures that all device leads are kept at the same potential, thereby protecting the device from ESD damage. Other - inspection, testing and repairs of static sensitive electronic components or LRU'sare performed at approved ESD work stations. These work stations, designed to bleed off static charges, utilizes static dissipative table mats electrically connected to a static dissipative floor mat which is connected to ground thru a series resistor (1 Meg ohm +\/-20%). The operator connects a wrist strap, to a single point ground, to make himself equal to the same potential as the components that are on the table, thus, prohibiting static discharge on conductive components. Technical Rationale:Fundamentals of Electrostatics - To insure successful implementation of proper guarding against harmful effects of ESD, familiarity with the concepts of electrostatics and ESD is necessary. Here, the basic elements are briefly discussed. For more extensive discussion, refer to books listed in the references. The main basic elements of ESD are&colon. electric charges, electric field, electrostatic potential, capacitance, charge generation and charge removal. Electric Charges - Experiments have shown that when two dissimilar objects are brought into contact with each other and then separated, the two objects become charged. The classic example is the rubbing of a silk cloth on a glass rod where the charge is visually evident when the charged objects cause the hair on your arm to stand up or cause small bits of paper to be attracted to the charged objects. If two corks are charged by the glass rod, the corks will repel each other because of like charges. Conversely, if one cork is charged by the glass rod and the other is charged by the silk (opposite charges), the corks will attract each other. The charge on these objects is due to an excess or deficiency of electrons on their surfaces. These charges are referred to as static electricity. This is because they can remain stationary on an object for substantial long periods of time. It is to be noted that this sudden transfer of charge from one body to another (by oppositely charged bodies being brought into close proximity) is called electrostatic discharge or the better known acronym \"ESD\". Lightning is a very high energy form of ESD. The interactions between electric charges are described by Coulomb's law: F=kq1q2\/r. Where F is the magnitude of the force, k is the proportionally constant, q1 & q2are the charges on the object and r is the distance between them. Electric Field - describes the influence of an isolated charge on other charges in its vicinity. This electric field is the direction and magnitude of the force exerted by the charge on a unit charge at any point in its environment. The field strength (E) of an object is force(F)\/charge(q). A good example of electrostatic field is when a person generates a charge on a balloon and then holds it above his head to make his hair stand up. The balloon never touches the hair, but an electrostatic field has been created. Electrostatic Potential - the amount of energy (work) per unit charge required to move a charge from one point to another in a field. The movement of the charge (q) along a distance (X) requires work (W). Thus the equation W=FX and, substituting the forementioned, W=qEX or W\/q=EX . This work per unit charge is the potential difference expressed in volts. Thus the formula E=V\/d, where E is the electric field intensity, V is the electric potential and d is the distance between the potential voltages. Ideally, we want to make sure that all charges remain at the same level or same potential so that no ESD (zap) occurs. Capacitance - the ratio between the charge on two plates and the potential difference between them, or, C= Q\/V. In the case of two parallel plates this capacitance C=eA\/d where A is the area of the plates and d is the distance between the plates (potential voltages) and, e is the dielectric constant. Where typical capacitance (C) values for humans ranges from 50 to 500 picofarads (pf) and dielectric constants of 1 (air and insulators) to 10 (insulators). The energy stored in a capacitor is given by the expression E= 1\/2CV2 or 1\/2Q2\/C. Charge Generation - charging that occurs as a result of contact and frictional motion is referred to as triboelectricity. To describe, whenever two materials (one must be an insulator) are brought together and then separated, there will be a flow of electrons from one material to the other. The material giving up the electrons becomes positively charged while the material accepting the electrons becomes negatively charged. Charge Removal - dissipation of electrostatic potential with the use of soft grounding, static dissipative materials and air ionizers. Listed below are some of the more common materials and their polarity (+ or -) in the triboelectric series. Asbestos Acquires a more positive charge Glass Human Hair Nylon Wool Aluminum Paper Polyurethane Cotton Neutral reference point Wood Steel Sealing Wax Hard Rubber Mylar Epoxy Glass Nickel, Copper, Silver Brass, Stainless Steel Acrylic Polystyrene Foam Polyurethane Foam Polyester Polyethylene Polypropylene PVC (vinyl)Teflon Silicone Rubber Acquires a more negative charge When the charged object is an insulator, the charge can last for extended periods of time. This is true because insulators are poor conductors of electricity. Conversely, when the charged object is a conductor, the charge will decay rather quickly. The factors affecting the magnitude of the rate of charge generation are: Relative position in the triboelectric series. Intimacy of contact (proximity of the materials). Coefficient of friction between materials. Rate of separation. The factors affecting the magnitude of a rate of discharge (dissipation) are: Conductivity of the materials. Relative humidity. Moisture on the surfaces of the materials. Rate of recombination. Some typical electrostatic potential (volts) generated for typical events with various levels of relative humidity (RH) are respectively: Walking across a carpet 35,000 volts @ 10% RH 15,000 volts @ 40% RH 7,500 volts @ 50% RH Walking across a vinyl floor 12,000 volts @ 10% RH 5,000 volts @ 40% RH 3,000 volts @ 50% RH Pulling tape quickly from its roll 10,000 volts @ 30% RH ESD is not normally a concern when the relative humidity is greater than 50% RH because moisture in the air will act as a high resistance bleeder. This will then dissipate voltage potentials on the surface before they can build up to a level of approximately 350 volts and result in ESD. A few materials such as teflon, vinyl, etc. do not absorb moisture and therefore, will not bleed off readily even in environments above 50% RH and should be avoided where ESD is a concern. Environments below 50% RH require special attention for selection of and use of tapes, plastic films and electrostatic flooring material. Operations below 30% RH should be carefully assessed and avoided when possible. At levels below 30% RH, additional precautions shall be employed (e.g., air ionizers, humidifiers). Voltages, especially on large surfaces, should be dissipated using a high resistance resistor (1 Meg ohm +\/- 20%) in series with the ground wire until the charge is eliminated before going directly to ground. Note: Surface resistivity changes exponentially with humidity changes. Therefore, relative humidity levels maintained between 40% and 60% are recommended. References: Electrostatic Discharge Control Program for Protection of Electrical and Electronic Parts, Assemblies and Equipment, MIL-STD-1686B. Electrostatic Discharge Control Handbook for Protection of Electrical and Electronic Parts, Assemblies and Equipment, MIL-HDBK-263A. Requirements for Electrostatic Discharge Control, NHB 5300.4(3L) ESD Program Management by G. Theodore Dangelmayer of AT&T. Investigation Analysis of the ESD Protection in the Facilities at the John F. Kennedy Space Center by Peter Stonefield, LSOC QE. Passive Static Protection: Theory and Practice by George R. Berbeco. KSC Ground Operations Safety Plan, GP-1098G. SPC Standard Practice Instruction (SPI) QA-016(3)K entitled Receiving Inspection of Parts and Materials (SPC procured & Government furnished). SPC Standard Practice Instruction (SPI) LP-021(5)K entitled Electrostatic Discharge Prevention (to LPS). SPC Standard Practice Instruction (SPI) LG-661(7)K entitled Preservation, Packaging, and Packing of Materials.","Lesson ID":685}
{"Driving Event":"The Challenger (Space Shuttle Flight #51L) accident triggered a detailed review of all of the joints in the Solid Rocket Motor. Analyses showed a potential weakness and potential flow paths for hot gasses through he case-to-nozzle joint that could cause a catastrophic event similar to that encountered in Challenger.","Lesson ID":951}
{"Driving Event":"During a weekly fire pump run for the 3 diesel fire pumps located in the VAB Utility Annex one of the low side pressure reducing valves failed to regulate the pressure from 330 psig to 140 \u00b1 10 psig. The LCC fire suppression water supply loop and all the subsequent wt pipe suppression systems directly connected to the building supply loop were over pressurized in excess of 300 psig. The over pressurization of the entire LCC fire suppression system caused numerous mechanical couplings to partially fail. 28 January 2010, six-inch fire suppression supply pipe coupling separated from elbow at coupling joint in LCC Stairwell 4R99C. Smaller leaks were in LCC firing rooms, hallways, and offices. 300-500 gallons of water released in VAB Low Bay from ruptured sight glass. Immediately prior to the pipe coupling separation, smaller leaks were observed in the LCC launch control firing rooms, as well as in the nearby Vehicle Assembly Building (VAB), Building K6-848. Although no critical electronic launch equipment was damaged, facility damages were estimated at over $706,000, and this does not include repair of LCC Firex system as it was a pre-existing condition, failure was imminent. Figure 1: LCC R Stairwell, Separated Pipe, Damage to wall during separation Figure 2 Pressure Reducing Valves in VAB Utility Annex Mezzanine","Lesson ID":5936}
{"Driving Event":"Many times, blind fasteners were found to be improperly installed. One in particular was detected during the removal of a thermal carrier panel. Loss of this panel would likely result in loss of the vehicle during reentry. When this carrier panel was removed, it was found that some fasteners did not have enough threads engaged. On one fastener, only a single thread was engaged.","Lesson ID":3260}
{"Driving Event":"A fire occurred on November 27, 1982 at the Arnold Engineering Development Center as a result of cutting propellants on the floor of a vertical test cell. The propellant being cut was from M-X Stage II and was a Class 1.3,88 weight percent solids, HTPB, Non-HMX type. Combustion was attributed to either impact or friction.","Lesson ID":344}
{"Driving Event":"The Dryden Flight Research Center's Learjet Model 24, call sign NASA 805, sustained substantial damage during a planned \"touch and go\" landing at the Southern California Air Logistics Base (formerly George Air Force Base), near Victorville, CA on June 7, 2001. There were no injuries to the pilot, co-pilot, or the observer in the course of this event. The Learjet was used on an infrequent basis as a research testbed. The aircraft had just returned to flight status from an extended period in flyable storage. This type of usage did not permit the assigned aircrew to maintain currency. The flight was a scheduled recurrency flight. There was inadequate guidance in the areas of piloting duties, crew pairing, recurrency requirements, and restrictions to carrying passengers. The daily flight supervision process was inadequate to mitigate the lack of DOP-0-300 guidance. The supervisory process did not provide adequate policy, procedures, nor oversight and insight for aircrew conducting flights to ensure significant qualifications, training and currency were met. The direct causes of this mishap were identified as: Over control of the aircraft by the copilot (pilot flying) leading to an aggravated roll oscillation, hard landing, loss of control, and subsequent impact. A significant factor was the copilot's limited total piloting experience, particularly in high performance jet aircraft and in the Learjet. Failure of the pilot in command (pilot not flying) to recognize the deteriorating situation in time to recover the aircraft. A significant factor was the pilot in command's lack of currency in the Learjet, and his low overall experience in the Learjet. The combination of an inexperienced copilot flying an aircraft with a pilot in command who was not current in the aircraft and who had relatively little time in type.","Lesson ID":1377}
{"Driving Event":"The Wide-Field Infrared Explorer (WIRE) was declared a loss only a few days after launch. A NASA review board (reference 1) determined that the telescope aperture cover was unintentionally ejected prior to spacecraft attitude stabilization when the WIRE pyro electronics box was first powered. Without the thermal protection provided by the cover, the solid hydrogen cryogen essential for operation of the telescope rapidly sublimated and vented. The mission loss is attributed to a pyro electronics box design that did not allow for the known transient performance of components. The control logic design utilized a synchronous reset to force the logic into a safe state. However, the start-up time of the crystal clock oscillator was not taken into consideration, leaving the circuit in a non-deterministic state for a time sufficient for pyrotechnic actuation. Likewise, the startup characteristics of the field-programmable gate arrays (FPGAs) were not considered. The FPGAs were not guaranteed to follow their quottruth tablequot until quotstartedquot by an internal charge pump. The electrical transients initially generated by the FPGAs were not blocked from the driver circuitry of the pyros. Prompted by the failure investigation, circuit analysis and test showed that the turn-on transients are sufficient to produce spurious signals that latch-up the control logic to a state that can issue commands to fire cover release pyros. These anomalous characteristics were not detected during subsystem or system functional testing due to the limited fidelity and detection capabilities of the electrical ground support equipment. There was no system-level end-to-end test in an as-flown configuration. [D] WIRE Pyro Electronics Startup Characteristics The design error was exacerbated by the failure of a detailed technical review to penetrate the electronic design of the pyro electronics box. Detailed peer review did not extend to the box and its interfaces with the spacecraft. The Mishap Investigation Board concluded that a peer review, held by knowledgeable people, would have identified the turn-on characteristics that led to the failure. Additional Keyword(s): WIRE failure, WIRE instrument electronics (WIE), cover deployment, pyrotechnic device, pyro arming, pyro firing, pyro circuit, qualification test, test equipment, spurious logic, transient analysis, inadvertent actuation, stray current, sneak circuit, SAFE\/ENABLE-RESET, management and planning, system development, subsystem and instrument development, system integration and test Reference(s): WIRE Mishap Investigation Board Report, NASA, June 8, 1999. Informal Design Reviews Add Value to Formal Design Review Processes, Lesson Learned No. 0582, September 26, 1997.","Lesson ID":634}
{"Driving Event":"An onsite maintenance and operations contractor was tasked to erect scaffolding inside of a wind tunnel test section so that a heavy gas door seal could be replaced. The test section floor is level until it opens into the tunnel where the floor slopes downward. The portion of tunnel that slopes down from the test section is called the contraction wall. One end of the scaffold had to be placed on the down slope. In order to secure the scaffold, three pads were welded onto the test section floor which had a pivoting vertical tube attached to it. The vertical scaffold legs were slid into the tubes. Safety straps were attached to the test section floor because an outrigger section, which extended out over the contraction wall, was installed on the main scaffold. After the completion of work, the onsite maintenance and operations contractor began to take down the scaffold. Four workers were tasked to disassemble the scaffold. Due to the uniqueness of the scaffolding arrangement, the workers were told to wait for their supervisor to coordinate the effort. The workers took it upon themselves to disassemble the scaffold. During the disassembly, with the outrigger section still in place, the safety straps were removed. Two employees were on the scaffold when the straps were removed. As they continued to disassemble the scaffolding, the center of gravity shifted over the outrigger. This caused the scaffolding to topple over since the straps had been removed. Both employees rode the scaffolding to the bottom of the contraction wall. One employee sustained no injuries. The second employee told his co-workers to call 911. He was taken to a local hospital and released with minor injuries. All employees involved had received training on the assembling and disassembling of scaffolding. The crew lead was one of the employees working on the scaffolding. Under normal conditions, the crew lead would supervise the work, but the crew supervisor told the crew lead to not begin disassembly until he was present to supervise the work. The crew lead ignored this request and began disassembly. Because the crew lead was actively involved in the take down, he did not see his error in removing the straps. He only saw the straps as being in his way of removing scaffolding pieces.","Lesson ID":1318}
{"Driving Event":"In the gathering of test data for IRT fan blades, data was extrapolated for test section airspeeds greater than approximately 200 mph using the 20% air blockage models. A desire was expressed for more accurate results of higher test section airspeeds ranging up to 350 mph using the 20% air blockage models. A temporary method was found which would provide the desired airspeed at a relatively low cost. This new method consisted of replacing the original fan blades, installed in 1944, with a modified set of spares. The modification included reshaping the blade hubs to an increased angle of attack of 5 degrees. The modified fan blade's performance with a reasonable stall margin was calculated to have increased the test section airspeed from 190 mph to 245 mph using the 20% air blockage model. In addition, the drive motor, rated at 5000 hp, only required 2400 hp at 300 mph and maximum rpm. The modified fan blades will take advantage of the remaining horsepower with no alterations of the motor.","Lesson ID":477}
{"Driving Event":"After its September 2007 launch, the Dawn spacecraft employed a solar-powered ion propulsion system (IPS) to gain the additional velocity needed to reach Vesta and Ceres, and it will use the IPS to spiral to a low altitude orbit around these asteroids. Compared to chemical rockets, ion engines make very efficient use of onboard fuel because the propulsive energy is derived from the sun. Solar electric propulsion (SEP) technology for navigation beyond Earth orbit was successfully demonstrated from 1998 to 2001 by the Deep Space 1 (DS1) mission, and Dawn planned to use the same IPS design (Figures 1 and 2). .................... Figure 1. Deep Space 1 is lifted from its work platform at NASA Kennedy Space Center, providing a close view of the IPS Figure 2. Hot fire test of the Deep Space 1 IPS The development of the Dawn IPS by the NASA\/Caltech Jet Propulsion Laboratory (JPL) proved much more difficult and expensive than expected. The principal unanticipated problem was a degraded ability to manufacture the DS1-legacy components, principally the ion thrusters and the Power Processor Units (PPUs) (References (1) and (2)). The inherited DS1 components had evolved through informal engineering processes more typical of experiments than development of configuration-controlled flight hardware. Although the Dawn IPS contractor for the ion thrusters and PPUs was the same company that had built the DS1 hardware, and the Dawn thrusters and PPUs were proposed as build-to-print copies of the DS1 designs, the contractor encountered significant management and process problems in delivering the Dawn flight hardware. The contractor problems, which likely were exacerbated by the 6-year lag between these two projects, included: JPL efforts to negotiate a fixed-price or incentive-based contract with the Dawn IPS contractor failed. The resultant cost-plus-fixed-fee contract was overrun by almost 100 percent, and the flight hardware was delivered 8 months late. The Dawn IPS contractor for the ion thrusters believed it could reproduce the assembly processes for the DS1 thrusters, but major cost escalation during fabrication, assembly, and testing of the Dawn IPS revealed that the time lag between the two projects had degraded their capabilities. Also, the vendor that fabricated the DS1 ion thruster plasma screen was no longer in business, and the vendor that performed chem-etching of the DS1 thruster grids did not bid on the Dawn thruster grids. No shock testing of the DS1 thruster had been performed except at the less critical spacecraft level. The DS1 PPU assembly procedures and other information needed to reproduce the hardware had not been adequately documented or retained. Over the 2-1\/2 years of the Dawn IPS build, the IPS contractor for the ion thrusters and PPUs cycled through four general managers and four Electric Propulsion department managers. Each upper-level manager in the contractor's corporate unit was fully aware of a pending sale of the unit by the parent company. These managers were motivated to please their parent company's customers, and there were frequent delays due to reassignment of Dawn resources to these other projects. A total of 40 IPS component and subsystem design reviews, plus the hardware reviews, produced a huge number of action items-- 630. The number would have been more manageable had the required documents-- technical requirements documents (TRDs), interface control drawings (ICDs), mechanical interface control drawings (MICDs)-- been completed on time. The Dawn IPS interface with the spacecraft was complex. Assembly, Test, and Launch Operations (ATLO, aka spacecraft Integration & Test) was delayed pending receipt and installation of the thermal hardware because responsibility for thermal hardware (e.g., heaters, blankets, and platinum resistance thermometers (PRTs)) attached to the IPS components was divided between JPL and the Dawn spacecraft system contractor. Two test-as-you-fly exceptions went undetected prior to launch and were only identified because of problems encountered during the initial spacecraft checkout activities. The latch valve masking should have been installed for the second phase of spacecraft thermal-vacuum testing, and a gimbal problem was not identified due to insufficient testing of the gimbals with the spacecraft prior to launch. These management problems affecting the Dawn IPS development were accompanied by many IPS design implementation, fabrication, and test technical problems with the ion thrusters, grids, cathode magnets, PPUs, digital control and interface units (DCIUs), xenon tank (Reference (3)), and xenon feed system (XFS). References: John Brophy, quotDawn IPS Lessons Learnedquot presentation, December 4, 2007. John Brophy, quotDAWN Ion Propulsion System: Project Element Manager's Report on the Development of the Dawn Ion Propulsion System,quot JPL Document No. D-41251, May 29, 2008. quotCOPV Propellant Tank Failure on the Dawn Spacecraft,quot NASA Lesson Learned No. 1777, NASA Engineering Network, March 7, 2007. https:\/\/llis.nasa.gov\/lesson\/1777 quotInterface Control and Verification,quot NASA Lesson Learned No. 0569, NASA Engineering Network, October 9, 1997. https:\/\/llis.nasa.gov\/lesson\/569","Lesson ID":3396}
{"Driving Event":"During the terminal countdown for the first attempted launch of Cassini, spacecraft telemetry channels indicated a false alarm condition that delayed verification of spacecraft readiness for launch, and contributed to a delay on the first launch day. In planning for Cassini launch activities, the RED-ALARM strategy was to set critical measurement alarms for telemetry values differing from those expected at liftoff. As expected, pre-launch conditioning generated a number of red alarms, most of which cleared as the spacecraft was brought to the final liftoff state. However, two red alarms did not clear, resulting in the false alarm conditions. This anomaly was traced to erroneous telemetry documentation: the SAFE\/ARM logic states for the two channels whose alarms did not clear were found to be reversed in the data dictionary. The Cassini launch procedure was developed late in the Assemble, Test, and Launch Operations (ATLO) process, and alarm testing with correct parameters was not done. Also, testing of these particular alarms prior to actual launch was not possible at KSC due to safety considerations. The Mars Pathfinder (MPF) project developed their launch procedure early, and subjected it to rigorous, multiple tests during their 18-month ATLO. In this case, additional testing had negligible cost and schedule impact since it was conducted in conjunction with other testing to gain operating hours. Additional Keyword(s): Launch Readiness Review, Operations Readiness Review, Configuration Management, Interface Control Reference(s): Cassini Spacecraft Assembly, Test, and Launch Operations (ATLO) Final Report, Volume I, JPL Document D-15701, May 15, 1998, page 151. JPL Problem\/Failure Report No. Z44319, October 13, 1997.","Lesson ID":609}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1422 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Careful attention to detail in ultrasonic testing can result in the identification of very small cracks, debonds, voids or inclusions in aerospace hardware that could be detrimental to mission performance. New ultrasonic technologies are enhancing the accuracy, speed, and cost-effectiveness of this method of nondestructive testing. Implementation: As schematically illustrated on Figures 1, 2, and 3 there are three principal methods of ultrasonic testing of aerospace materials: (1) the pulse-echo method; (2) the through-transmission method; and (3) the pitch-catch method. These three ultrasonic methods use pulses of energy during testing operations. These methods and their principal use in support of MSFC projects and technology programs are described below: 1. The pulse-echo method (Figure 1). In the pulse-echo method, a piezoelectric transducer with its longitudinal axis located perpendicular to and mounted on or near the surface of the test material is used to transmit and receive ultrasonic energy. The ultrasonic waves are reflected by the opposite face of the material or by discontinuities, layers, voids, or inclusions in the material, and received by the same transducer where the reflected energy is converted into an electrical signal. The electrical signal is computer processed for display on a video monitor or TV screen. The display can show the relative thickness of the material, depth into the material where flaws are located, and (with proper scanning hardware and software), where the flaws are located in the X-Y plane. In aerospace applications, the pulse-echo method is used primarily for the detection of flaws in metals, but has been used for first and second bondline interrogation in solid rocket motors (each transmitted\/received wave in Figure 1 represents a pulse of energy). [D] 2. The through-transmission method (Figure 2). In the through-transmission method, an ultrasonic transmitter is used on one side of the material while a detector is placed on the opposite side. Scanning of the material using this method will result in the location of defects, flaws, and inclusions in the X-Y plane. This method is used for nondestructive testing of multi-layered and multicomponent materials as encountered in solid rocket motor case\/insulation\/liner\/propellants, in composite materials, and on highly attenuative materials. (Each transmitted\/received wave in Figure 2 represents a pulse of energy.) [D] 3. The pitch-catch method (Figure 3). The pitch-catch method, in which the ultrasonic energy is transmitted at any angle to the surface of the material and received as reflected energy returning at the reflected angle, is used primarily for cylindrical tubes and other nonlinear parallel sided surfaces. The pitch-catch method can determine depths of the flaw in the material as well as detect the location in the X-Y plane through scanning. (Each transmitted\/received wave in Figure 3 represents a pulse of energy.) [D] All three methods are most effective on parallel sided surfaces, but techniques are being developed to inspect variable thickness materials or parts if and when the variation in thickness relative to the X-Y plane is known precisely. Precautions to be observed in ultrasonic testing include: (1) acoustical impedance matching of the sensors with the subject test material through the use of the correct coupling media; (2) use of air-coupling for moisture-sensitive materials; (3) resolution requirements needed to discriminate between adjacent anomalies; and (4) the use of electronic methods wherever possible to make corrections in distance inaccuracies encountered due to ultrasonic beam spreading; (5) characteristics of the transducer(s); and (6) the dependence of resolution on index, scan speed, repetition frequency, computer speed, etc., when using automated scanning. Water has been the best coupling media because of its ready availability, low viscosity, and its relatively safe use with most spacecraft construction materials. When immersion in water is not practical or desirable due to potential moisture absorption, material contamination, or part sizes and configurations, various forms of squirters bubblers have been devised to introduce a layer of water between the sensor and the material to serve as an acoustic coupler. In the pitch-catch method, a water-based gel has proven to be the most practical coupling agent. For solid propellant rocket motors, an elastomeric material similar to solid rocket propellant is used for acoustic coupling of sensors to the material during testing. Ultrasonic transmitters and receivers encased in a water jet nozzle have been used to provide continuous coupling during testing of large areas by continuously injecting a plane of water between the sensor and the material being tested. The most thoroughly researched application of ultrasonic testing at MSFC has been the detection of bond line failures between the case and insulation, the insulation and liner, and the liner and propellant. Ultrasonic waves can be focused at an oblique angle to establish the integrity of adhesive bonding. These oblique ultrasonic excitations cause standing waves in any unbonded areas which can then be detected by conventional ultrasonic methods. In this manner, weak or kissing bonds can be detected. NASA has had considerable success in detecting imperfections and debonds between the case or insulation and the liner, but work is continuing to develop reliable methods of detecting debonds at the second bondline between the liner and the propellant. In materials that have high attenuation impedance such as solid rocket propellants, relatively low ultrasonic frequencies (50kHz in an available ultrasonic range of 3kHz to 50MHz) are more effective than the high ultrasonic frequencies used for metals. Rapid strides are being made in information processing and display techniques which filter out extraneous acoustic signals and provide improved visual images of ultrasonic testing results. The pulse-echo method regularly reveals defects down to .047 inch in diameter. Through-transmission methods have been able to detect anomalies of .050 inch in diameter, which are far smaller than those which could detrimentally affect a solid rocket motor's performance. Ultrasonic capability to detect flaws depends on the wavelength (derived from the frequency and wave velocity). A general rule of thumb for the detection limit is: the smallest detectable flaw size is half the wavelength. The use of higher frequencies improves the sensitivity to small flaws, however there is an increase in the wave attenuation and the noise due to scattering from the material microstructure. Also, in any ultrasonic test there is a dead zone caused by the finite pulse length. This dead zone leads to the inability to detect flaws near the surfaces of the test materials. Ultrasonic testing personnel should be qualified and certified in accordance with MIL-STD-410E or SNT-TC-1A. Technical Rationale: Selection criteria for NDE techniques, specifically ultrasonic techniques, has been a subject of research by MSFC's Materials and Processes Laboratory for a number of years. These techniques have been verified by Thiokol Corporation, Martin Marietta, Aerojet, SAIC, The Naval Surface Warfare Center, and others. References Bray, Don E. and Don McBride: Nondestructive Testing Techniques, Chapter 11, Ultrasonic Testing of Aerospace Materials, John Wiley and Sons, New York, NY, 1992. Kutz, Myer: Mechanical Engineers' Handbook, Section 27.3; Ultrasonic Methods of Nondestructive Testing, John Wiley and Sons, New York, NY, 1986. Seydel, James, A. and Julian R. Frederick.: A Computer-Processed Pulse-Echo NDT System, Materials Evaluation, November 1973. Whaley, H.L. et. al.: Applications of Frequency Analysis in Ultrasonic Testing, Materials Analysis, January 1975. Smith, A.C. and H. Yang: Ultrasonic Study of Adhesive Bond Quality at a Steel-to-Rubber Interface by Using Quadrature Phase Detection Techniques, Materials Evaluation, December 1989. Green, R. E.: Ultrasonic Testing, Nondestructive Testing Handbook, Volume 7, American Society for Nondestructive Testing, Columbus, OH, 1991. Metals Handbook, Volume 17: Nondestructive Inspection and Quality Control, pp. 231-277, ASM International, Metals Park, OH, 1989. MIL-STD-410E: Nondestructive Testing Personnel Qualification and Certification, Military Standard, January 1991. SNT-TC-1A: Recommended Practice, Personnel Qualification and Certification in Nondestructive Testing, American Society for Nondestructive Testing, Columbus, OH, 1988.","Lesson ID":765}
{"Driving Event":"During subsystem level testing of the Magellan Command and Data Subsystem (CDS), the test support equipment indicated an extra event for the relay controlling Critical Enable (CE) Event B03. It was theorized that a short between two specific pins of the CE relay could have caused the observed failure. When the relay was probed to verify the cause, the failure characteristic disappeared. Close visual inspection revealed a fine hairlike structure lying on one relay pin and possibly making contact with others. The object was removed and analyzed using a Scanning Electron Microscope (SEM) and an Energy Dispersive Spectrometer (EDS). The analysis revealed that the object was a conductive metal fiber, identical in diameter (.0003\"), surface characteristics and composition to metal fibers woven into the fabric of elastic Electrostatic Discharge (ESD) wrist straps. Reference(s): PFR #44931","Lesson ID":301}
{"Driving Event":"The successful 35-minute Jupiter Orbit Insertion (JOI) maneuver on July 4, 2016 allowed the planet Jupiter to capture the Juno spacecraft. The NASA\/Caltech Jet Propulsion Laboratory (JPL) then began preparing for the final major burn designed to change its orbit, with a period of 54 days, to its 14-day nominal operational science orbit. The final major burn to slow Juno and place the spacecraft in a tighter orbit around the planet (Figure 1) was planned as a period reduction maneuver (PRM), sometimes referred to for this mission as a Perijove Reduction Maneuver (although geometric perijove was not being changed by the maneuver). The PRM was intended as a regulated main engine burn in which both the fuel and oxidizer tank pressures are regulated during the burn by a helium pressurization system. This regulatory system is connected to the fuel and oxidizer tanks via passive check valves, and pyrolitic isolation valves in the oxidizer side (Figure 2). Figure 1. Juno\u2019s orbital grid During preparations for the Juno PRM on October 13, 2016, telemetry on tank pressure readings revealed an anomaly during the pre-PRM tank pressurization activity (Reference (1)). A series of check valves between the helium tank and the fuel tanks remained closed for about four minutes after imposition of a positive pressure difference that should have immediately opened them. Further review of telemetry showed the oxidizer check valves had also malfunctioned in the same mode but to a lesser extent during the first few minutes of the prior burn-- the JOI maneuver performed in July. The telemetry further showed unexpected gas-side pressure increases suggestive of unintended upstream flow when the oxidizer tank pressure exceeded the gas-side pressure during the Deep Space Maneuver (DSM-2) performed 45 months earlier. Figure 2. A simplified Juno Propulsion Subsystem block diagram. Juno utilizes a weight-saving and redundant approach to spacecraft propulsion, with a bi-propellant main propulsion system and a monopropellant Reaction Control System. The main propulsion system uses hydrazine as fuel and nitrogen tetroxide as oxidizer. Lower than expected pressures in either the fuel or oxidizer tanks can result in unintended oxidizer-to-fuel mixture ratios in the main engine during the burn, with potential effects ranging from under-performance (to nominal performance) to catastrophic failure. Hence, the \u201cstuck-closed check valve\u201d anomaly eventually led to a decision by the Juno project to forego the PRM altogether. The most likely cause for the pre-PRM fuel check valve anomaly was contamination, with the contaminant consisting of vapor fuel-oxidizer reaction products (FORP). The pre-JOI failure of the oxidizer check valve to immediately open is believed to be caused by excessive oxidizer exposure; but it could also be FORP contamination, with either possibility caused by an oxidizer leak failure that occurred in the previous maneuver (DSM-2). According to this scenario, the earlier oxidizer check valve leak failure (at DSM-2) produced excessive amounts of oxidizer in the gas side leading to: The oxidizer check valves sticking closed (at pre-JOI). The high oxidizer vapor content creating FORP at the fuel check valves. The FORP leading to the subsequent \u201cstuck closed check valve\u201d anomaly at pre-PRM. Because FORP contamination was a well\u2013known failure mode during Juno design and development, multiple safeguards, such as quad-redundant check valves and oxidizer-side pyrolitic isolation valves, were employed. But these measures were obviously insufficient. While an anomaly resolution team determined that the fuel tank could be pressurized and a main engine burn executed in a blowdown mode to execute the PRM-- even in the presence of the anomalous check valves-- the project elected to avoid the risk of possibly attaining a less-than-desirable orbit and remain in the 53-day capture orbit for the remainder of the Juno mission. The higher-than-planned orbital period does not affect the quality of the science collected by Juno during each flyby because the altitude over Jupiter is the same at the time of closest approach. In terms of the total quantity of science return, it has recently been announced (Reference (3)) that the Juno mission will be extended three years until at least July 2021 so it can complete the additional 18 perijoves needed to finish mapping Jupiter. Another outcome of the longer orbit is that Juno will spend less time within Jupiter\u2019s radiation belts on each orbit, reducing the accumulated radiation exposure of the spacecraft. References: \u201cPRM Pressurization Check Valve Issue,\u201d JPL Incident Surprise Anomaly (ISA) No. 60324, JPL-internal document, October 13, 2016. \u201cJuno Check Valve Anomaly Recovery Discussion,\u201d JPL-internal document, Juno Project, December 15, 2016. https:\/\/prs.jpl.nasa.gov\/NET\/DownloadAttachment.aspx?iAttachmentID=60144 (JPL internal access only). \u201cNASA Re-plans Juno's Jupiter Mission,\u201d Jet Propulsion Laboratory, June 6, 2018. https:\/\/www.jpl.nasa.gov\/news\/news.php?feature=7153 .","Lesson ID":28105}
{"Driving Event":"Certification of Block II SSME Testing at 109% for Intact Abort Scenarios","Lesson ID":1006}
{"Driving Event":"The Galileo Photopolarimeter Radiometer (PPR) subsystem cover was damaged on three separate occasions during assembly and test operations. The PPR cover is very delicate and has sharp corners that make it vulnerable to snagging. The damage occurred during thermal blanket operations which required access to areas behind the PPR location and was caused by a technician's protective clothing snagging on the sharp edges of the PPR cover. After the first incident, when damage was relatively minor and easily repaired, the workers were cautioned to avoid this problem. In the second incident, damage was serious and required rework. A protective guard was then built to protect the cover. The third incident happened after this protective guard had been removed to permit further thermal blanket fitting activity. All of the incidents occurred even though the work was being performed by well trained, experienced and highly qualified technicians under the watchful eye of QA personnel. After the third incident, the mechanical assembly procedures were revised to require a second technician (buddy system) to continuously monitor and provide a shielding arm or hand to protect sensitive areas not observable by the technician doing the work. Additional Keyword(s): Hardware Integration Reference(s): PFRS # 45429, 45463, and 45482","Lesson ID":355}
{"Driving Event":"The portable purge unit supplies conditioned air through ducts to the orbiter to purge and\/or pressurize the payload bay's forward and aft compartments. Airflow varies between 50 lbs\/min minimum to 100 lbs\/min maximum. Vent door observers are always on station when a vent door is repositioned for a test or TPS tile\/thermal barrier work. Overpressurization may occur if all the orbiter vent doors (normally in the purge position) for a compartment are closed at one time. Control logic program VAM09 also notifies the firing room engineers if both a right hand and left hand purge vent door set is closed.","Lesson ID":125}
{"Driving Event":"When STS environments were reviewed and used, it became apparent that some body point numbers are 3 digits long, while others are 4, 5, or even 6 digits in length. No underlying system was employed throughout the life of the program. In a few instances, duplicate body point numbers were used for elements such as the Orbiter and the External Tank. This is highly undesirable because it could cause confusion, or even misapplication of inappropriate design environments. In the worst case, this could lead to a catastrophic event if not caught during the design process.","Lesson ID":6357}
{"Driving Event":"During the launch of the NOAA-K weather satellite there was an anomalous deployment of the Very High Frequency Real Time Antenna (VRA) and an incomplete deployment of the -Y Deployable Sunshade. The VRA is a two-stage deployment. Phase 1 deploys 76 degrees followed by the Phase 2, which deploys through an angle of 166 degrees. The Phase 1 slowly deployed to only approximately 58 degrees instead of its planned 76 degrees. The Phase 2 deployed its full 166 degrees. This left the VRA mispointed by approximately 18 degrees. However, this mispointing does not affect data recovery via the VRA. The telemetry indicated the -Y sunshade had not fully deployed. The incomplete sunshade deployment could not by correlated to other indirect observables, since the -Y deployable sunshade is not required for thermal control in the AM orbit.","Lesson ID":909}
{"Driving Event":"Agency-Wide Computer System Vulnerabilities","Lesson ID":1150}
{"Driving Event":"On July 13, 1988, hydrazine was being transferred from partially filled drums into LT-44. There were seven drums for a total of 343 gallons. Adding the 134 gallons in LT-44 resulted in 477 gallons - well within the tank's 500 gallon capacity. As the hydrazine was being transferred from the last drum, a mechanic saw liquid spray from the vent hose and immediately closed the vent and fill valves. After securing the area, mechanics reported that all the flags at the top half of the LLI indicated the tanker was full. This suggested the magnetic liquid level gauge's reliability is questionable due to erratic operations.","Lesson ID":120}
{"Driving Event":"The Orbiter Processing Facility (OPF) Bay 2 Firex Deluge Zone 3 Viking arm valve AV1.3-2 was leaking, and on September 21, 1989, Problem Report (PR) number PV-6-140247 was initiated to replace defective parts. During system leak check operations following valve repair, water flow from zone 3 (directly over the Orbiter) occurred in OPF Bay 2. The time of first flow was established as 10:28 AM on September 24, 1989, as recorded by OPF Water Pump House instrumentation due to diesel pump startup. The Zone 3 water flow over the Orbiter was at a reduced rate, with only a partial nozzle discharge pattern. Shuttle Processing Contract (SPC) Water Systems technicians were cycling the manual arming and firing valves while leak checking the system. Only a few minutes had passed from the time they cracked open (2 turns) the system manual supply valve until they heard about the water flow problem in Bay 2. The SPC Lead Water Systems technician ran into the OPF to see what was wrong and noted the deluge flow. He returned to the manual activation station behind the OPF and found that two SPC ground support equipment (GSE) technicians had opened the manual arming and firing valve to Zones 1, 2, 3, 4, and 5. (It is presumed Zone 3 did not flow additional water and had been deactivated by this time.) The Lead Water Systems technician then closed all the open manual arming and firing valves, as well as the manual supply isolation valves to stop all Bay 2 water flow. The scenario that lead to the two GSE technicians being at the deluge system manual flow control valve station is as follows: After the flow from Zone 3 occurred, the SPC OPF Bay 1 Site Division Manager asked a GSE technician to find someone who could turn the system off. This GSE technician, accompanied by a co-worker, proceeded to the manual activation station behind Bay 2. Upon arrival, they proceeded to position the manual arming and firing valves to Zones 1, 2, 3, 4, and 5 to the \"on\" position, thinking they were turning the firex system off. This turned on deluge system Zones 1, 2, 4, and 5 (Zone 3 had already been deactivated) to the \"full on\" mode. The Lead Water Systems technician then returned to the manual valve panels, proceeded to turn the manual arming and firing valves to the \"off\" position, and then helped his technicians close the manual supply isolation valves to Zones 1 through 5, which stopped all water flow.","Lesson ID":1183}
{"Driving Event":"A battery charger design was reported to have experienced catastrophic component failure during vibration testing, resulting in fractured and broken component leads of heatsink-mounted power devices. A photograph of the failed assembly (Fig. 1) clearly showed a pattern of damage consistent with repeated movement and flexure of the components. The primary cause of the unwanted movement was attributed to a design decision, in which the heatsink was allowed to \"float\" with respect to the printed wiring assembly. A design change, which mechanically bonded the heatsink and the printed wiring assembly together, significantly reduced the incidence of component lead failures during vibration tests. A visual examination of sample components supplied to JSC suggested that the use of unapproved tooling and processes during the component lead forming process was a contributing factor to the observed fractured and separated leads, with numerous sample components exhibiting leads with cracks (Fig. 2). Discussions with the vendor indicated that metallic tools (including a screwdriver) were employed to form the leads. Subsequent improvement in tooling and processes resulted in smoothly formed lead bends, without fractures or significant tooling marks.","Lesson ID":1202}
{"Driving Event":"An electrical test, performed at a contractor facility during acceptance test of the Space Infrared Telescope Facility (SIRTF) propulsion subsystem, caused the failure of 6 pressure transducers. These transducers are used to sense the pressure in propellant lines. The incident occurred when a 500-volt insulation\/isolation resistance test intended for the propellant line heaters and tank heaters was mistakenly applied to all electrical connections in the subsystem. Applying 500 volts to the entire subsystem caused the transducer damage. The transducer circuitry should have been tested at a maximum of 50 volts. The test failure was traced to an error in the acceptance test procedure (ATP). A careful, detailed review of the ATP by the lead propulsion engineer would likely have detected the circuit compatibility error. Additional Key Words: test induced failure, test error, over voltage, excess voltage, voltage rating","Lesson ID":1300}
{"Driving Event":"The first in a series of commercial geosynchronous satellites experienced abnormal operation of the bipropellant main engines following initial pressurization of the propellant tanks. Subsequent analysis of contractor test data on engine flows, previously unavailable to the customer, indicated an actual engine mixture ratio slightly higher than the ratio used to determine the propellant loading. This resulted in the depletion of the oxidizer about one minute prior to the end of the final burn required to place the spacecraft on station. The extremely large monopropellant burns required to compensate for the absence of oxidizer may reduce the mission life. The spacecraft was provided with two methods to detect oxidizer depletion: (1) a single accelerometer reading indicating acceleration below a manually set threshold and (2) multiple readings of acceleration values which are time-averaged at 60 percent below the last steady-state value. With the latter method active during the final burn, the depletion was not detected by the onboard software because the average acceleration did not drop below the 60 percent threshold. Severe line pressure oscillations, indicative of intermittent ingestion of oxidizer bubbles, indicated the main engines were still firing. The engines were allowed to operate in this abnormal mode for about 30 seconds before shut down was commanded by ground control to minimize engine damage. Additional Keyword(s): Engine Flow Test Data","Lesson ID":572}
{"Driving Event":"Contact with the SOlar Heliospheric Observatory (SOHO) spacecraft was lost in the early morning hours of June 25, 1998, Eastern Daylight Time (EDT), during a planned period of calibrations, maneuvers, and spacecraft reconfigurations. Prior to this the SOHO operations team had concluded two years of extremely successful science operations. A joint European Space Agency (ESA)\/National Aeronautics and Space Administration (NASA) engineering team has been planning and executing recovery efforts since loss of contact with some success to date. ESA and NASA management established the SOHO Mission Interruption Joint Investigation Board to determine the actual or probable cause(s) of the SOHO spacecraft mishap.","Lesson ID":664}
{"Driving Event":"For critical applications either run tests to develop actual torque-preload relationship, or use tables which were developed using the actual fastener material, joint material, and lubrication and\/or locking system. On January 15, 1991 a failure occurred in the 8 foot transonic pressure tunnel during testing of a model wing with attached flap. During the test run, the flap peeled away from the wing, broke free, and proceeded down the tunnel. Extensive damage resulted.","Lesson ID":500}
{"Driving Event":"After the shuttle carrier aircraft\/orbiter reaches its park position within the mate\/demate device, the side access platforms, which parallel the major part of the orbiter fuselage, are lowered into service position to demate the orbiter. Flip down platforms are extended from the side access platforms to allow personnel to reach the 50-1\/50-2 doors. ropes are used to lower the platforms to the orbiter and technicians have minimal control of the speed at which the platforms are lowered. A potential exists for a loss of platform control and subsequent orbiter damage\/personnel injury.","Lesson ID":29}
{"Driving Event":"During a hardware performance evaluation, Solid Rocket Motor (SRM) clevis and tang sealing surface diameters were assumed to be stable and were not remeasured during refurbishment. Subsequent testing revealed growth in the diameters after hydroproof (and possibly flight) which introduced an unrecognized variable into o-ring squeeze calculations. The static o-ring compression after mating is influenced by these actual hardware dimensions and the degree of segment concentricity, and are critical to hardware performance. During the STS 51-L Investigation, measurements were made on refurbished and reused segments, and the data indicated that segment circumferences at the sealing surfaces change with repeated use.","Lesson ID":224}
{"Driving Event":"Space Shuttle Main Engine (SSME) test 901-0674 was conducted on November 6, 1991 at 11:31 am CDT. The scheduled 400 second test was terminated by the Command and Data Simulator (CADS) at engine start plus 3.72 seconds when the Low Pressure Fuel pump (LPFP) discharge pressure sensor was disqualified by exceeding its maximum qualification limit of 300 psia. The controller responded by issuing a Major Component Failure (MCF) which initiated the CADS cutoff. The main objectives of test 901-0674 were: reacceptance of flight engine 2032 with replaced oversized piston ring seal wave spring, facility flow meter calibrations, and the greenrun of the following flight hardware: Controller U\/N F48, High Pressure Fuel Turbopump U\/N 2226, Low Pressure Fuel Turbopump U\/N 4018, Low Pressure Oxygen Turbopump U\/N 2035, and Chamber Coolant Valve Actuator (CCVA) S\/N 037-71008. The propellant system chilidown and prestart engine conditioning phase of the test was normal. Post test inspections indicated no external engine or facility damage. Internal borescope inspections revealed heavy erosion of the High Pressure Fuel Turbopump (HPFTP) first stage nozzle and turbine blades. No other internal damage was noted. Post test inspection of the CCV\/CCVA assembly revealed the coupler which links the CCVA to the CCV was missing. Inspection of the CCV also revealed the valve to be fully closed throughout the test.","Lesson ID":1340}
{"Driving Event":"STS 90\/Neurolab was a Spacelab module mission focusing on the effects of microgravity on the nervous system. The mission was flown abroad the Columbia and launched on the 17 of April 1998 and lasted 17 days. The goals of Neurolab were to study basic research questions and to increase the understanding of the mechanisms responsible for neurological and behavioral changes in space. The mission was a joint venture of several space agencies and U.S. research agencies including the National Institutes of Health, the National Science Foundation, and the Office of Naval Research, as well as the space agencies of Canada, France, Germany, and Japan, and the European Space Agency. While the Neurolab mission was an overall success, it experienced several on-orbit hardware failures and problems that could have been minimized or prevented had adequate crew training been accomplished. In fact, the crew had not been used several of the flight system configurations until on-orbit.","Lesson ID":1613}
{"Driving Event":"A 125 pound per square inch pressure air line in a ground trench, used to supply test facilities, failed by splitting along the longitudinal weld. The 10 inch diameter steel pipe ruptured for a distance of about 15 feet. As a result of this failure, four manhole covers were blown into the air. The air line that failed was in a covered ground trench and had been in place for about 15 years. During this time, moisture was present from surface water leakage and considerable corrosion had taken place on the pipe outside diameter. Inspection of the failed pipe revealed that the original thickness of 1\/4 inch was reduced to almost zero in some places as a result of the corrosion. The failure was due to the corroded pipe no longer being able to withstand the internal working pressure.","Lesson ID":241}
{"Driving Event":"See attached PDF.","Lesson ID":26803}
{"Driving Event":"JPL has responsibility for the development, integration, and testing of the payload (including the canister and collector arrays) for the Genesis Project, a mission to collect solar wind particles and return them to Earth. While the Genesis canister was being lifted from the transportation dolly at JPL in preparation for system-level thermal vacuum testing on May 3, 2000, the lift fixture detached at one of the three swivel hoist ring tension fittings. [D] Prior to mounting on the test chamber door, one corner of the canister fell ~5 centimeters (~2 inches) back onto the dolly. Nearby personnel cushioned the fall, and there was no damage to the Canister or support equipment, or serious injury to personnel. Post-incident inspection revealed that the threaded fastener had backed out of the fixture and became detached. Additionally, the fasteners at the other tension fittings, and at the upper hoist point, were found only hand-tight. The lift fixture assembly had been proof tested 8 months earlier. The fixture had been reassembled by the vendor following the proof test and dye penetrant inspection of the swivel hoist fittings. The fixture had last been used to lift the Canister two days prior to this incident. The fixture was visually inspected prior to the May 3, 2000 lift incident, but the hoist rings were not checked for tightness. There is no evidence that the hoist ring fasteners had been properly torqued since the proof test. The procedure governing the canister lift operation (Reference 2) did not require adequate checking of all fasteners prior to attaching the fixture to the hoist. Reference(s): Jet Propulsion Laboratory Problem\/Failure Report No. Z69149, May 3, 2000 JPL Assembly and Inspection Data Sheet (AIDS) No. 216421, May 2, 2000 JPL QA Procedure QAP 61.5, quotQA Inspections of MGSE Used on JCIs.quot","Lesson ID":914}
{"Driving Event":"A tightly capped bottle containing dilute aqua regia chemical waste was stored in a fume hood. Evolved gases resulted in a pressure build-up causing the bottle to explode. The contents sprayed across the room onto the floor. The bottle explosion occurred overnight when the laboratory was unoccupied; however, a potential acid burn exists if an employee was in the room at the time of the bottle explosion. A review of available literature indicates that aqua regia, which is a combination of hydrochloric acid and nitric acid, will oxidize with time resulting in the evolution of Nitrous Oxide (NO2). This reaction is ongoing and is subsequent to the intended use of the mixture. This pressure build-up is normal for this type of mixture.","Lesson ID":945}
{"Driving Event":"Increased Space Shuttle Main Engine (SSME) Power Setting for Intact Aborts","Lesson ID":1078}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) Shortly after Voyager launch, unexpected translational velocity increments and large non-gravitational acceleration effects were observed in the orbit-determination processing of tracking data. These velocity increments and accelerations were traced to the unbalanced translational accelerations produced by the attitude control system, its response to torques induced by solar pressure, and to the impingement of gas from the pitch thrusters onto other parts of the spacecraft structure. The magnitude of these dynamic effects required that they be modelled in the orbit determination process throughout the flight. This involved additional orbit determination processing and analysis, and necessitated a new operational interface between the Spacecraft Team and Navigation Team. A special in-flight impingement test was performed to provide data for modelling. The pre-flight analysis to recognize or predict the effects and uncertainties from both the unbalanced thrusters and the impingement was inadequate. The result was incomplete flight operations planning by both the Spacecraft and Navigation Teams. Additional Keyword(s): Trajectory Accuracy","Lesson ID":424}
{"Driving Event":"Two satellites with different propulsion system designs were lost in 1993 and 1994. Limited telemetry was received on the incidents. Subsequent failure investigation focused on possible propulsion feed system design flaws. In both cases, pyrovalves were used to isolate the hydrazine supply until the satellite was separated from the launch vehicle. [D] In accordance with a common design practice for engine feed systems, two pyrovalves were placed in parallel to provide redundancy. With the hydrazine tank isolated, pressurized fuel was present upstream of the pyrovalves (e.g., Point A), but only a dry nitrogen quotpad gasquot at low pressure downstream of the pyrovalves (e.g., Point B). On one spacecraft it was unclear what the gas composition was and whether it was totally vented through the thruster prior to the priming event. During priming of the hydrazine system, the primary pyrovalve was fired to charge propellant lines leading to the engine. When the propellant reached the thruster valves and stopped, it produced a pressure surge. Under certain conditions, this surge could cause exothermic decomposition of the fuel, and tests were conducted to assess if the prevalent conditions were conducive to exothermic decomposition. This particular failure mode was never observed during the failure investigations. However, when the backup pyrovalve was fired a second later during one test, the blow-by of hot gas into the lines between Points A and B detonated the decomposed fuel; this then breached the fuel lines on both sides of the backup pyrovalve. The tests did not exhibit this detonation failure mode when, just prior to firing the backup pyrovalve, the pad gas was evacuated to leave a vacuum downstream of both pyrovalves. Reference(s): GIDEP Advisory No. GH-P-94-01, quotPyrovalve, Titanium, 1\/2quot, Normally Closed Single Initiates,quot Revised May 1, 1995.","Lesson ID":591}
{"Driving Event":"According to NASA document, Draft NIST Special Publication 800-88 Rev 1, we are required to wipe hard drives that contain NASA data and verify data is removed after the sanitization process. We were instructed by local security personnel to use Darik's Boot and Nuke (DBAN) software. Several issues were encountered and workarounds were required for the freeware version.","Lesson ID":7016}
{"Driving Event":"OMRSD S073A.90 thru .230 requires verification of voltages, phasing, and talkbacks to the orbiter. Present talkback verification method for the payload retention latch assembly (PRLA) involves extensive \"hot\" pin jumpering during testing using a 79K07833 breakout box and test leads. Improper jumper procedure by inserting a jumper at an incorrect location could result in inadvertent shorts or cross connection of live 120 volt and 28 volt electrical lines. This improper procedure could cause PRLA electrical system damage, orbiter interface damage and\/or electrical shock\/personnel injury.","Lesson ID":87}
{"Driving Event":"On April 4, 1990, at approximately 9:05 a.m. EDT, one of the three fuel cells (#3) installed in the Orbiter Atlantis, OV-104, was damaged while an attempt was being made to vent the fuel cell prior to its removal and replacement. Atlantis returned to the Kennedy Space Center (KSC) on March 3, 1990, after successfully completing the STS-36 mission. The vehicle was undergoing processing in the Orbiter Processing Facility (OPF) in preparation for the STS-38 mission in July of this year. Testing and processing was being accomplished by the Shuttle Processing Contractor (SPC) at KSC. The Fuel Cell Single Cell Voltage Test was accomplished on March 30 and 31, and the analysis of the test results indicated there were two degraded internal cells. A decision to remove and replace the fuel cell was subsequently made on April 2 by the Orbiter Project Manager. The accident occurred while attempting to vent the fuel cell with the Orbiter hydrogen (H 2) purge vent port capped. This allowed the H2 pressure to exceed the oxygen (02) pressure in the fuel cell, 2 side of the fuel cell. The Potassium Hydroxide (KOH) was found at the 02 purge port of the fuel cell indicating the ninety-six internal cells, the regulator, and the accumulator would have to be replaced due to the corrosive qualities of KOH. No one was injured and damage was limited to fuel cell #3.","Lesson ID":1182}
{"Driving Event":"The o-ring used in the SRM case joint is critical to the sealing of the joint, yet is not designated as a critical process. The adequacy of o-ring processing and quality control is questionable even though a number of o-rings in bonded storage were thoroughly analyzed and tested as part of 51-L failure analysis effort and found to be acceptable. The manufacturing process included delivery of the final o-ring rubber material to where the material is cut to the proper lengths and a scarf joint is made. This manufacturing process is a potential problem area as seen by repairs of inclusions and voids in the rubber delivered.","Lesson ID":177}
{"Driving Event":"During a drop test at the NASA Plum Tree Island Test Facility, a model was severely damaged due to failure of its parachute recovery system. The failure of the recovery system resulted from teflon cloth jamming closed the canopy compartment lockoff flaps. The teflon cloth had been wrapped around the suspension lines to expedite extraction of the folded lines. The parachute contractor design personnel chose to add the cloth because its lubricating effect on the suspension lines and the resultant lowering of the force required to extract the lines. The information concerning the design change and lower opening force was transmitted to the research project engineer by telephone conversation. Significantly, no confirming strip-out load tests were performed with the teflon wrapped lines prior to using them in an actual test. The primary finding of the investigation committee was that teflon cloth jamming prevented the bag from opening and the canopy extracting.","Lesson ID":517}
{"Driving Event":"As part of routine Tanking operations for STS-128, Pre-Valve (PV12) closure could not be verified at the start of Liquid Hydrogen (LH2) Topping. The launch attempt was scrubbed. During the development a flight rationale, should the next attempt give similar results, it was determined that Gaseous Helium (GHe) used to inert the T-0 Umbilical during drain assist could become trapped in the fill and drain line prior to PV11 closure. This posed a potential for GHe entering the LH2 system if the PV12 relief valve opened. A helium bubble entering the engine system could unload the pump causing an overspeed condition a possible catastrophic failure.","Lesson ID":6146}
{"Driving Event":"CloudSat is an Earth orbiter that uses a radar instrument to advance understanding of cloud abundance, distribution, structure, and radiative properties. Designed and operated by the NASA\/Caltech Jet Propulsion Laboratory (JPL), CloudSat performs 16 orbits each day in formation as part of the A-Train constellation of satellites (currently OCO-2, GCOM-W, Aqua, CloudSat, CALIPSO, PARASOL, and Aura). CloudSat employs two articulating solar arrays to generate 1,000 watts of electrical power to recharge a 40 amp-hr battery. A Power Control Unit (PCU) regulates battery charging and distributes power to the spacecraft over a hardwired power bus and four switchable power buses. CloudSat completed its two-year primary mission successfully. Five years after the 2006 launch into sun-synchronous orbit, the CloudSat spacecraft battery experienced the first of a series of under-voltage (UV) conditions that triggered a spacecraft emergency mode and turned off the spacecraft computer. Telemetry was available in real time only during ground passes. The first and each successive UV event (i.e., UV-3 fault) caused autonomous switching to a lower battery charge rate that required the ground controllers to repeatedly command a higher charge rate. With the battery temperature dropping, ground was unable to repeat these commands for a couple days due to an unrelated ground network problem, and another day without this charge rate commanding would have caused battery discharge, battery freezing, and the loss of the spacecraft. It took 8 weeks to regain enough control of the spacecraft computer to begin recovery efforts. The battery anomaly was attributed (Reference (1)) to \u201cdiffusion-limiting current, a condition caused by corrosion of the positive electrode which results in the net loss of electrolyte (i.e., dry-out of electrolyte in the membrane). The reduced amount of electrolyte reduces the ability to support the current demands and there is a sudden drop in voltage when the diffusion-limit is reached.\u201d This failure mechanism had never before been seen on orbit. The requirements for recovering the spacecraft to normal operations were daunting (Reference (2)): The peak discharge current during the sun-eclipse part of the orbit had to be <5.25 amps, but the spacecraft normally used ~15 amps during eclipse. Only ~2.3 amp-hrs (10% of pre-anomaly performance) was available during the 34-minute eclipse. The Attitude Control System (ACS) had to be powered off during eclipse because it alone used ~7 amps. The spacecraft and the Cloud Radar had to be kept warm enough during the sunlit period so that the thermostatically-controlled heaters would not power on during eclipse. The innovative solution implemented 6 months after the anomaly was to go to a Daylight-Only Operations (DO-Op) Mode in which the 3-axis stabilized spacecraft and nadir-pointing radar were transitioned into a spinning spacecraft during every eclipse (Figure 1). That is, at each umbra exit from eclipse, the power from the solar arrays are used to spin the reaction wheels to quickly orient the science boresight so that the vehicle recovers from hibernation and resumes science data collection in only a few minutes. No science is performed during eclipse, so CloudSat achieves 56 percent of the pre-anomaly science product each orbit. Figure 1. The new nominal operating mode, DO-Op (Daylight-Only Operations), astounded the project team when it was first proposed. References: Nayak, Witkowski, Vane, et al, \u201cCloudSat Anomaly Recovery and Operational Lessons Learned,\u201d 12th International Conference on Space Operations, Stockholm, Sweden, June 2012. http:\/\/www.dtic.mil\/dtic\/tr\/fulltext\/u2\/a568401.pdf Deborah Vane, \u201cCloudSat Battery Anomaly 2011,\u201d JPL project managers\u2019 Pause & Learn session, April 18, 2017.","Lesson ID":22502}
{"Driving Event":"Early in the Shuttle Program, as contamination control was being recognized as a \u201dsystem,\u201d OMRSD requirements were created for the OPF high bays. OMRSD requirements included specific temperature, relative humidity, and airborne particulate ranges that, if exceeded, resulted in an OMRSD violation. However, the normal processing activities within the OPF high bays caused temporary out-of-specification environmental conditions that resulted in OMRSD violations numerous times during every Orbiter processing flow. Examples include opening facility doors to the outside environment for hardware entry, applying waterproofing on tiles, operating overhead cranes, etc. Consequently, contamination control engineering was processing problem reports and waivers and\/or exceptions to the OMRSD requirements for every mission. Eventually, it was realized that the normal Orbiter processing activities were not causing any obvious detriment to the vehicle from a contamination perspective, and therefore, the facility OMRSD requirements were no longer warranted. In addition, these OMRSD requirements were considered unrealistic for the type of operational activities needed to process the Orbiter. Where possible, mitigation efforts were implemented to help reduce the generation or emission of contamination within the facility during certain operational activities (such as the incorporation of a captive air vent system that vented fumes from vacuum pumps and hydraulic aspirators outside of the facility).","Lesson ID":3336}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1206 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefits: Power line filters minimize the flow of conducted noise currents on power buses emanating from hardware that could interfere with the proper operation of other hardware also operating on the same power buses. Additionally, power line filters minimize the flow of noise currents on power buses into hardware which could interfere with the proper operation of that hardware. Implementation: Power line filters are used to meet the Conducted Emission and Conducted Susceptibility Requirements of GSFC's General Environmental Verification Specification for STS and ELV Payloads, Subsystems, and Components (GEVS-SE). This document contains a baseline for demonstrating by test the satisfactory performance of hardware in the expected mission environments. Technical Rationale: The problems of Conducted Emission and Conducted Susceptibility have been widely recognized for many years. The EMC community and the Department of Defense have collaborated in preparing and in continually reviewing and updating a widely used set of EMC design and test requirements designated MIL-STD-461, 462, and 463. These requirements have been tailored for specific spaceflight application and incorporated by the GSFC into the GEVS-SE document along with specific requirements defined in the Shuttle Orbiter\/Cargo Standard Interfaces Document (JSC 07700 Volume XIV Attachment 1 (ICD 2-19001). References: General Environment Verification Specification For STS and ELV Payloads, Subsystems, and Components (GEVS-SE). Shuttle Orbiter\/Cargo Standard Interfaces Document (JSC 07700 Volume XIV Attachment 1 (ICD 2-19001).","Lesson ID":646}
{"Driving Event":"As part of the preparation for the testing of the TOPEX\/POSEIDON spacecraft, the spacecraft and its thermal vacuum fixturing assembly were being lifted and positioned above the thermal vacuum chamber when the assembly began a slow overturning rotation. The assembly rotated approximately 135 degrees before it was halted by the entanglement of the Spacecraft Horizontal Support Structure (SHSS) with one of the four lifting fixture suspension cables. While resting in this anomalous position, the test team visually determined that the lifting fixture spreader bar (inherited from the Galileo program) had sustained considerable damage and might fail. A decision was made by the Fairchild Systems spacecraft manager to lower the assembly to the chamber floor as quickly as possible to protect the spacecraft and remove the load from the damaged spreader bar. The assembly was lowered to the chamber floor where it was temporarily secured. While no major spacecraft damage resulted from the incident, it would have been catastrophic to the TOPEX\/POSEIDON Program if the satellite had actually been dropped. Additional Keyword(s): Handling, Hardware Safety Reference(s): PFR #53523","Lesson ID":267}
{"Driving Event":"The primary cause of the mishap was an activation (closing) of the fire pump mercoid pressure switch which prematurely started the fire pump. This produced transient pressures that exceeded the 2:1 mechanical advantage of the deluge valves, forcing them open. The switch activation was caused by potable water system pressure fluctuations external to the local facility.","Lesson ID":47}
{"Driving Event":"The anomaly happened during Earth occultation on Mariner '71s forty-eighth orbit of Mars. When the DSN reestablished telemetry reception after occultation, several temperature and spacecraft power channels associated with Traveling Wave Tube Amplifier (TWTA) 2 were in alarm. The station confirmed a loss of 0.5 dB in downlink signal level that was indicated in the telemetry. The project elected to switch to the redundant TWTA-1 by ground command about two hours after the first observation. JPL and the subcontractors were never able to pinpoint the cause of the anomaly, even as to location in the tube itself or in the amplifier. Recommendations from the investigators included contingency plans in the event of yet more severe TWTA-1 problems, as they deemed TWTA-2 still operable in the low-power mode. (These TWTA-1 problems never occurred.) During the anomaly investigation, contractor quality assurance programs were reviewed and the process procedures used to assure high quality welds were found to be inadequate. One possible failure model postulated a weld failure in the cathode support structure.","Lesson ID":373}
{"Driving Event":"The full-scale ASRM propellant manufacturing facility may not be directly scaleable from the continuous mix pilot plant. Particular problem areas relate to the particle size of the propellant and the screw pump section of the rotofeed. Many parameters and processes for the new facility have not been fully determined. However, another manufacturer has produced a substantial amount of similar solid propellant using continuous production processes, so the basic techniques are familiar. Safety devices are installed on the propellant flow line to limit the spread of fire in case of an accident. The flow line transporting the uncured propellant has several firebreaks to prevent propagation of a fire along the tube. The basic safety device is an explosive-fired guillotine valve that interrupts the flow, with a water spray on the propellant to lower the temperature below the ignition point. In addition, there is a collar in the flow line upstream of the guillotine and on the casting pit side of a firewall that can be blown to allow the propellant to flow out on the floor and prevent pressure buildup. A matter that must be considered is cleanup after an accident involving a dump of uncured propellant on the floor. The continuous mix pilot plant at manufacturer provides a way of proving a new propellant and upgrading the equipment before establishing a full-scale facility at yellow creek. The major differences between the pilot plant and the full-scale facility are equipment size and process control software. The pilot plant production rate is 1,000 to 1,400 pounds\/hour with the full-scale facility producing 20,000 to 26,000 pounds\/hour. The ultimate particle size of the propellant is dependent on parameters such as geometry of piping, length of lines, and fluid working pressures that may not be directly scaleable. There are many challenges such as metering of propellant solids, pre-mix of iron oxide and aluminum, and real-time process control. Upscaling the rotofeed dearator and pump equipment probably presents the greatest challenge.","Lesson ID":201}
{"Driving Event":"The Hopkins University Telescope (HUT) experiment was being aligned in the operations and check-out building using a bright light that had been obtained from technicolor government services. After approximately two hours of use without incident, the light bulb shattered, with pieces falling into the HUT experiment, causing contamination. Alignment of the HUT was not a scheduled activity at KSC. Therefore a light source was not furnished with the experiment. Data recorded at KSC indicated that the HUT was not aligned to the cruciform as expected and that a light source would be required.","Lesson ID":68}
{"Driving Event":"NASA Pursuit of Shuttle Avionics Upgrades","Lesson ID":1151}
{"Driving Event":"During checkout testing of the single component force balance for the jet exit rig we discovered significant hysteresis in the load cell measurement, much more than would be expected for this type of measurement system. Examination of the screws in the load cell string, and the tolerances on the relevant drawing, led to the conclusion that the mounting blocks and flexures were not adequately attached to each other. Figure 1: A fairly typical load cell string","Lesson ID":18701}
{"Driving Event":"The High Energy Spectroscopic Imager (HESSI) spacecraft primary mission objective is to explore the basic physics of particle acceleration and explosive energy release in solar flares. The HESSI spacecraft was scheduled for a July, 2000, launch on a Pegasus vehicle as part of the Small Explorer Program (SMEX). On March 21, 2000, the HESSI spacecraft was being subjected to a series of vibration tests at JPL as a part of its flight certification program. The structural qualification test, a sine-burst test on a shaker table, subjected the spacecraft to a major overtest condition that resulted in significant structural damage to the spacecraft. The incident has been designated as a Class A mishap since the damage exceeded $1 million. A sine-burst test is a quasi-static load simulation technique. The shaker table in this incident was well over 40 years of age. The fatigue life characteristics of such shaker tables are unknown. The root cause of the overtest condition was the mechanical binding (\"stiction\" or static friction) between the slip table and the granite mass. It resulted from physical contact between a portion of the slip table and the granite mass caused by a mechanical failure in the shaker's support structure. The stiction caused the shaker system to present highly non-linear gain characteristics to the control system making it impossible for the controller to calculate an appropriate forcing function. This particular sine-burst was leading to a higher level qualification test. The resulting overtest level was about 10x that planned for this test, but only about 2.5X the final qualification level. Contributing Factors Identified by the Review Board: At some facilities, older test equipment may have time-related failure modes unknown to the users. Misalignment caused the slip table to exhibit non-linear behavior in that it would bind at low levels of force input. The test personnel did not have existing knowledge that data were available to assess the quality of the transfer function calculated from the self-check prior to initiating the sine-burst test. Post-test review of the transfer function used to generate the shaker drive signal for the test and examination of the drive voltage indicated that the test setup was not operating as expected and that an overtest could occur. A significant contributing factor to the mishap was the lack of a facility validation test using the sine-burst on the shaker table before the spacecraft was mounted. It is industry best practice to do a facility checkout with a simulated mass mock-up before mounting a piece of critical hardware. Such a validation test effectively calibrates the entire test setup. A further contributing factor to the mishap was a mechanical anomaly that occurred in the exciter system. The shaker appears to have shifted in its support cradle after being coupled to the slip table in preparation for this test. The shift is thought to have been caused by the breakage of the outer race of a main trunion bearing. This resulted in a misalignment that brought one area of the slip plate into contact with the granite reaction mass creating a much larger frictional drag than normal. An additional contributing factor to the mishap was the low amplitude of the pre-test self-check. If a higher amplitude self-check had been used, the control software would have more closely approximated the system transfer function and increased the probability of detecting that stiction existed. References Jet Propulsion Laboratory Problem Failure Report (PFR) No. Z68924, March 24, 2000. Report on High Energy Solar Spectroscopic Imager (HESSI) Test Mishap, HESSI Test Mishap Investigation Board, May 18, 2000.","Lesson ID":903}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) During a Voyager Radio Frequency Subsystem (RFS) transponder filter capacitor rework, a noise was noted in the Proof Test Model (PTM) subassembly. On opening the power converter interface module, some of the mounting insert caps were found loose inside and others were partially pushed out from the insert ends. A dimensional check showed the mounting screws used may have an interference fit in length. A second possibility exists that longer screws were used at some earlier installation. Fastener inserts used in flight equipment are usually of the capped variety (closed at the bottom) when used in a thru-mounting design. This is done to prevent metallic particles being deposited in the electronics where they can cause electrical shorting or other problems. See also: In-flight failure, \"Receiver 1 Power Converter Failure on Voyager 2\" which was likely caused by this event. Additional Keyword(s): Tolerance Stackup Reference(s): PFR #40215 Voyager Structure Subsystem","Lesson ID":437}
{"Driving Event":"In Building 30 at the Johnson Space Center, a contractor electrician received an electrical shock to the hand and forearm from contacting an energized (480 volt AC) power panel lug. A separate contractor, from a remote location that contained the control devices for the power panel, had switched off, tagged, and verified all circuits deenergized. An electrical drawing was used to assure all circuits were included in the safing procedure. However, a modification was performed earlier to add a lug set and wiring to the panel that was not routed through the same remote controls location as the original wires, and was not reflected on the facility master drawing. The injured electrician did not verify the lug was deenergized by testing with a meter or other device. The injury was minor (small entrance and exit burns), but could have resulted in severe injury or death had the current passed through the torso. Corrective actions included updating the facility drawings and emphasis on enforcement of existing procedures for testing circuits as part of the lockout\/tagout process.","Lesson ID":19}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1411 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Controlling the operating temperature of parts in a vacuum flight environment will lower the failure rate, improve reliability and extend the life of the parts. Implementation Method: Thermal design is used to control the temperatures of the parts in equipment so that they will not exceed specific maximum safe temperatures and to minimize the parts temperature variations under all environmental conditions in which the equipment will operate. The maximum safe temperatures must be calculated based on a parts stress analysis and must be consistent with the required equipment reliability. It is usually necessary to maximize the heat transferred by only a single mode in order to obtain adequately low thermal resistances within equipment. Even though a complete cooling system may include three modes of heat transfer, each particular heat path will usually emphasize a single mode. Where a single mode dominates, other modes can often be ignored. For example, with conduction as the predominant mode for parts operated in a vacuum, the conductive thermal resistance can be made low by the use of thermal shunts. The heat transferred by radiation and convection is almost negligible. That is, in the electro-thermal analogue, the shunt thermal resistances due to radiation and convection are so large that they are insignificant for design purposes. Figure 1 shows an electrical analog of a thermal system of a typical part. Figure 1: Equivalent Thermal Circuit of a Part [D] For example, consider a linear integrated circuit, Part Number 9716 being used in an A\/D Converter in a vacuum environment. Without a heat shunt, the case to board temperature rise can be about 15oC for the part when dissipating 300 milliWatts. With a metal clad heat shunt, the case to board temperature rise can be reduced to about 5oC for the same conditions. Figure 2 shows the electrical analog of the thermal system with the shunt. Figure 2: Equivalent Thermal Circuit with Heat Sink [D] Additional enhancement can be obtained through the use of printed circuit boards with metal planes for heat conduction and heat straps for other hot spots. This has been found to be an effective method for conducting heat to the spacecraft cold plate. The effect of this design is to reduce the temperature of the board by minimizing the temperature rise from the cold plate to the board. A reduction in board temperature will allow for an increase in thermal shunting capacity for the applicable heat conduction path. Technical Rationale: The failure rates of parts increase with loading or stress level, whether it be thermal, electrical, or mechanical. Stresses below the intensity which causes catastrophic failure result in progressive deterioration of material. The effect of temperature cycling is believed to be extremely significant. Thermal failure of parts is caused by deterioration, due to temperature, of the materials of which the part is made. An old rule of chemistry (the Arrhenius Rate Law) states that the speed of chemical reactions doubles for every 10oC increase in temperature. Parts failure rates are known to increase exponentially with temperature as evidenced in published data. A thermal failure may occur so rapidly as to be considered catastrophic. However, there is always a slow, progressive deterioration of dielectrics, cathode coatings, transistor junctions and many other materials which accelerates with temperature, leading eventually to failure. These effects are cumulative so that failure rate depends to some extent on the entire ground test\/mission thermal history, the temperature-time integral. Thermal failure is, therefore insidious since it is usually impossible to determine the percentage of life remaining in a part. This has a direct bearing on the effects of temperature cycling, which is specified in nearly all specifications for testing parts and equipment, and which may occur during the normal operation of equipment in space, especially if the equipment is power cycled. There are indications that temperature cycling has a very adverse effect on reliability but there exist little quantitative data and no adequate theory by which the effect can be accurately estimated. The true thermal stress is usually at the internal junctions of the part. Since this is internal to the part, it is difficult to measure. The temperature of the accessible outer surface is the most practical index of the thermal condition of the part. Surface or body temperature is a function of the heat dissipation within the part and of its thermal environment, which is a complex function of: (1) coolant type, temperature, pressure and velocity; (2) the configuration, emittances and temperatures of neighboring surfaces; and (3) all conductive heat flow paths surrounding the part. This becomes evident from Figures 1 and 2. References: Electronic Reliability Design Handbook, MIL-HDBK-338-1A, October 1988. Glover, Daniel, Design Considerations for Space Flight Hardware, NASA TM-102300, January 1990. Reliability\/Design Thermal Applications, MIL-HDBK-251, January 1978. Reliability Prediction of Electronic Equipment, MIL-HDBK-217E Notice 1, January 1990. EEE Parts Derating, Reliability Preferred Practice PD-ED-1201 Part Junction Temperature, Reliability Preferred Practice PD-ED-1204 Thermal Test Levels\/Durations, Reliability Preferred Practice PT-TE-1404 Thermal Analysis of Electronic Assemblies to the Piece Part Level, Reliability Preferred Practice PD-AP-1306","Lesson ID":809}
{"Driving Event":"The orbital maneuvering system engine trickle purge system is used to prevent oxidation\/corrosion damage to the OMS engine injector ball joints. A 1.0 - 1.5 SCFM GN2 flow is applied during post-landing ground operations. Undetected loss of GN2 purge to OMS engine injector cavities could eventually corrode the vehicle system.","Lesson ID":147}
{"Driving Event":"[D] Wax thermal actuators are high reliability devices used to trigger spacecraft deployment mechanisms. Following launch, the Deep Space 1 (DS-1) solar arrays were released by powering the primary heaters in four high output paraffin (HOP) actuators. The HOP heaters were powered for three minutes and, as designed, the HOPs activated in 70-90 seconds after the heaters were powered. The secondary heaters in the HOPs were not powered. Eighteen days later, a spurious signal issued by the power distribution logic re-powered the primary HOP heaters. After ten minutes of heating, telemetry indicated a short in a HOP that caused the current to increase by approximately 6 amps. Over the next few minutes, all four primary heater circuits failed open, and evidence derived from telemetry indicated that at least three of the four primary heaters bridged to their corresponding secondary heaters. A trace rated for only 1.6 amps in the power distribution circuit board could easily have been damaged by the short-circuit current of 6 amps. Had this resulted in an open circuit in the power distribution board instead of the HOP, the mission could clearly have been jeopardized. Additional Keyword(s): Wax Actuator, HOP Actuator, Electrical Short, Pyro Reference(s): JPL Incident Surprise Anomaly (ISA) No. Z50426","Lesson ID":612}
{"Driving Event":"This Lesson Learned is based on Reliability Guideline Number GD-AP-2304 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Consideration of fracture mechanics reliability during the design process can assist in the prevention of failures of structural and mechanical components subject to fluctuating loads in service. Explicit consideration of the reliability of structural and mechanical components provides the means to evaluate alternate designs and to ensure that specified risk levels are met. Probabilistic fracture mechanics analyses may also be applied to life extension of existing structures, and for problem assessment of in-service fatigue failures. Potential applications of this method to the Space Shuttle or Space Station include: landing gear, control surfaces, main engine components, auxiliary power unit components, external tank and solid rocket booster welds, pressure vessels, propulsion modules, and logistics modules. The method is also applicable to reusable, Shuttle launched payloads or spacecraft such as Spacelab, Spacehab, EURECA, SPAS and Spartan. Stochastic fracture mechanics analysis provides the basis for analysis consistency between reliability analysis of mechanical systems, such as reliability block diagram analysis, and traditional deterministic fracture mechanics safe life estimation. Implementation Method: The method outlined below is a stochastic elastic fracture mechanics approach (for metallic or ceramic materials) which neglects any crack retardation or acceleration effects. Composites and other materials with insufficient crack growth data or intractable flaw growth characteristics are not considered. The detailed development of this approach is essentially the same as that given in references 1 through 6. The purpose of the simplified approach described herein is to illustrate some of the advantages and typical results of a stochastic fracture mechanics analysis. Discussion of technical implementation details, such as the use of crack growth laws other than the Paris equation (for example, the modified Forman equation [reference 15]), follows in the technical rationale section. For illustration, a Paris crack growth law is assumed, which may be written in the form of a differential equation. For random applied stress processes, a solution can be written in the form of a limit state function, M, as: [D] (1) in which: [D] Failure is defined to occur when the critical crack length, a c, is exceeded, so that at failure M <0. The probability of failure is then the probability that the limit state function is equal to or less than zero: [D] (2) The first term of Equation 1, the integral, essentially defines the fatigue resistance of the structure against a crack growing from an initial size, ao, to critical size ac. This integral must be evaluated numerically in all but the simplest of cases. Particular forms of the geometry function, Y(a), are available for simple configurations in the literature or from general purpose fracture mechanics software packages. For unique structural details, other approaches are available to determine Y(a), such as detailed finite element modeling of the cracked structure. The second term of Equation 1 defines the accumulated quotdamagequot caused by the applied stress process. A random stress process is characterized by its power spectral density and may be described as being narrowband (slowly varying random) or as wideband. In either case closed form approximations for the second term of Equation 1 are available. If the stress process is deterministic or if time histories of the stress process are available time domain methods, such as rainflow cycle identification [reference 10], approximations are available for determining the factors in the second term of Equation 1. It should be noted that all of the terms in Equation 1 may be treated as random or uncertain. This enables the modeling of all the sources of uncertainty pertinent to the problem, such as crack size and location, scatter in crack growth data, etc. Subsequent sensitivity analyses can be used to determine which variables contribute the most to the fatigue life uncertainty and require treatment as random, and which variables may be considered as fixed (deterministic). Sensitivity analysis can also indicate the parameters for which further data collection could reduce the overall uncertainty in the fatigue life. Modern reliability methods, the so-called First-Order Reliability Method (FORM) or Second-Order Reliability Method (SORM), are available in commercial computer programs to solve Equation 2. Monte Carlo or more sophisticated simulation techniques are also available [references 1, 7, 8, and 9]. In particular, PROBAN [1] has been available commercially from Det Norske Veritas (Oslo, Norway) since 1986 and has been used extensively in the offshore oil industry. PROBAN is available for UNIX and VAX\/VMS based workstations. STRUREL is a PC\/Windows based application available from RCP, GmBH, of Munich, Germany. RELACS is a similar package available from REA, Inc., of Golden, Colorado. A NASA-funded application called NESSUS, which runs on UNIX workstations and mainframes, is available from the Lewis Research Center. The commercial codes are recommended because of better user-interfaces and better user support. Monte Carlo approaches generally require direct programming for the solution for the specific problem under study. For a structure or mechanism in service, the results of inspections may be incorporated into the analysis and the estimated failure probabilities updated to show the change in reliability based on the additional information on existing crack size. For each inspection, two outcomes are possible: either no crack is detected, or a crack is detected and its size or length is measured. Figure 1 is an example analysis result (from reference 1) showing reliability as a function of time for which inspections were assumed at 10 and 20 years, with no crack detected at 10 years, but a 4.0 mm crack detected at 20 years. Note that with the new information gained from inspection at t=10 years, the reliability is shown to increase as no crack was found. After inspection at t=20 years, reliability is also shown to increase even though a small crack was detected, but only for a short time. The increase at t=20 years can be attributed to the discovery that the crack length was less than the critical crack length for the structure, but it should also be noted that the reliability decreases much faster with the uncertainty tied to the presence of a flaw. Inspection of structures and the new information that is gained can essentially reset the reliability, and even though a crack may be discovered, this new information can lead to increased inspections, which can lengthen the life of the item. However, a crack detection generally decreases the reliability, as in this case after about t=22 years. [D] Technical Rationale: A stochastic fracture mechanics approach to fatigue gives an estimate of the reliability of structural and mechanical components as a function of time in service and allows the reliability estimate to be updated if the results of in-service inspections and\/or in-service load data are available [references 1 and 2]. The procedure may also be used to optimally schedule inspections, and to compare the adequacy of different inspection types or quality levels [references 1 and 2]. Type and quality of repair techniques may also be compared and selected to maintain a desired reliability level. Updating of these analyses as actual inspections or repairs occur is also possible [references 2 and 3]. The application of in-service reliability estimates is dependent on the availability of some form of flight load data and accessibility to the structure or mechanism for inspection. Without such data no updating of the initial design reliability analysis is possible. The primary intent of this guideline is to make available to the NASA reliability engineering discipline the engineering mechanics-based methods for estimating the reliability of structural and mechanical components. Use of such methods would allow for consistency of models and data between the reliability and structural\/mechanical engineering disciplines within NASA. A stochastic fracture mechanics approach provides a quotphysics-of-failurequot basis for estimating the reliability of components subject to fatigue and fracture. This enables fault tree or reliability block diagram analyses, or probabilistic risk assessments, for structural and mechanical components in spacecraft systems to be performed using the same data and engineering mechanics models as the NASA accepted, deterministic fracture analysis procedures [reference 14]. For example, the mean time to failure for a pressure vessel girth weld (as may be needed for a propulsion system reliability block diagram analysis) estimated using probabilistic fracture mechanics would be rationally consistent with the safe-life analysis performed to meet current NASA fracture control and safe-life analysis requirements. The approach outlined herein is a simplified formulation that neglects load interaction effects, such as retardation, by using the Paris crack growth law. If a Paris equation is properly fit to the basic crack growth data, the resulting deterministic safe life estimate will be more conservative (shorter) than the estimated life resulting from a fracture analysis which incorporates retardation. The current NASA accepted practice in fracture mechanics analysis uses the computer program NASA\/FLAGRO, which includes interaction effects. Load interaction effects may be included in a stochastic fracture mechanics analysis by using crack growth laws such as the modified Forman equation found in NASA\/FLAGRO. For example, a FORM\/SORM formulation which included the modified Forman equation has been used to study aircraft durability and damage tolerance [reference 14]. A direct Monte Carlo solution implementing the modified Forman equation may also be found in references 7, 8, and 9. Issues related to the implementation, applicability, and accuracy of FORM\/SORM and Monte Carlo methods are beyond the scope of this guideline. In general, if a fracture mechanics reliability analysis is to be performed and it has been determined from a preliminary deterministic fracture analysis thatthe Paris formulation is inadequate, the modified Forman equation (as in NASA\/FLAGRO) should be used following either the approach described in reference 14 or in references 7, 8, and 9. Two critical parameters in any fracture analysis, deterministic or stochastic, are the size, location and distribution of initial flaws or cracks, and the ability of nondestructive evaluation (NDE) techniques to detect a flaw or crack smaller than a certain size. NASA has established standard NDE flaw sizes for Space Transportation System (STS) payloads [reference 14]. Two recent NASA research projects, one directed at establishing NDE probability of detection (POD) data, and one directed at gathering initial flaw distribution data, also may provide additional data for modeling initial flaws and NDE quality. Deterministic fracture analysis practice uses relatively large safety or quotscatterquot factors to account for the many inherent sources of uncertainty or error, such as analytic model inadequacies, inaccuracy of stress intensity predictions, and the scatter of experimental crack growth data. Stochastic analysis methods extend the accepted deterministic methods by allowing (or forcing) the analyst to explicitly account for these uncertainties by treating them as random variables (or process or fields), requiring the analyst to consider the likely range and distribution of the parameters. Both the deterministic and the stochastic analysis will suffer from the same shortcomings of model inadequacy, etc. The stochastic model has the advantage of addressing the uncertainties specifically using probability and statistical theory, while the deterministic approach addresses uncertainty in a general manner through the use of the safety or scatter factor. Use of a stochastic approach and a reliability based design criteria can be beneficial in avoiding over- or under-conservatism that may result from the use of a deterministic safety factor approach. References: PROBAN-2: Example Manual, Report No. 89-2025, A.S Veritas Research, Hovik, Norway, August, 1989 Madsen, H.O., Skjong, R.K., and Kirkkemo, F., quotProbabilistic Fatigue Analysis of Offshore Structures - Reliability Updating Through Inspection Resultsquot, A.S Veritas Research, Hovik, Norway Madsen, H.O., Skjong, R.K., Tallin, A.G., and Kirkemo, F., quotProbabilistic Fatigue Crack Growth Analysis of Offshore Structures, with Reliability Updating Through Inspectionquot, Society of Naval Architects and Marine Engineers, Proceedings, Marine Structural Reliability Symposium, Arlington, VA, October 5-6, 1987 Wirsching, P.H., Torng, T.Y., and Martin, W.S., quotAdvanced Fatigue Reliability Analysisquot, International Journal of Fatigue, Vol. 13, No. 5, 1991, pp. 389-394 Wu, Y.-T., Burnside, O.H., and Dominguez, J., quotEfficient Probabilistic Fracture Mechanics Analysisquot, Numerical Methods in Fracture Mechanics: Proceedings of the Fourth International Conference, Luxmoore, A.R., Owen, D.R.J., Rajapakse, Y.P.S., and Kanninen, M.F., Eds., Pineridge Press, Swansea, U.K., 1987 Veers, P.S., Winterstein, S.R., Nelson, D.V., and Cornell, C.A., quotVariable-Amplitude Load Models for Fatigue Damage and Crack Growthquot, Development of Fatigue Loading Spectra, STP 1006, American Society for Testing and Materials, 1989 Sutharshana, S., et al., quotA Probabilistic Fracture Mechanics Approach for Structural Reliability Assessment of Space Flight Systemsquot, Advances in Fatigue Lifetime Predictive Techniques, STP 1122, American Society for Testing and Materials, 1991 Sutharshana, S., et al., quotComputational Methods for Probabilistic Flaw Propagation Analysesquot, Proceedings of the ASCE Structures Congress '91, April, 1991 Moore, N. R., et al., quotAn Improved Approach for Flight Readiness Certification - Probabilistic Models for Flaw Propagation and Turbine Blade Failurequot, JPL Publication 92-32, December, 1992. Matsuishi, M., and Endo, T., quotFatigue of Metals Subjected to Varying Stressquot, Presented to the Japan Society of Mechanical Engineers, Fukuoka, Japan, March, 1968. Fracture Control Requirements for Payloads Using the National Space Transportation System, NHB 8071.1A Fracture Control Requirements for Space Station, SSP 30558 Sigurdsson, G., et al., quotProbabilistic Methods for Durability and Damage Tolerance Analysisquot, presented at the 1992 USAF Aircraft Structural Integrity Program Conference (ASIP), San Antonio, Texas, December 1-3, 1992. quotFatigue Crack Growth Computer Program NASA\/FLAGRO Version 2.0quot, JSC-22267A (Draft), January, 1993. Reliability Preferred Practices Guideline GD-AP-2303: Spectral Fatigue Reliability","Lesson ID":700}
{"Driving Event":"Portable Computer System (PCS) Software is Not Developed Concurrently With Primary International Space Station (ISS) Flight Software Leading to Inadequate Multiple Element Integrated Testing (MEIT)","Lesson ID":1165}
{"Driving Event":"The Lewis Spacecraft was procured by NASA via a 1994 contract with TRW, Inc., and launched on 23 August 1997. Contact with the spacecraft was subsequently lost on 26 August 1997. The spacecraft re-entered the atmosphere and was destroyed on 28 September 1997. The Lewis Spacecraft Mission Failure Investigation Board was established to gather and analyze information and determine the facts as to the actual or probable cause(s) of the Lewis Spacecraft Mission Failure. The Board was also tasked to review and assess the \"Faster, Better, Cheaper\" Lewis spacecraft acquisition and management processes used by both NASA and the contractor in order to determine if they may have contributed to the failure. The investigation process used by the Board was to individually interview all persons believed to have had a substantial involvement in the Lewis spacecraft acquisition, development, management, launch, operations and the events that may have led to the eventual loss. These interviews were aimed at not only understanding the facts as they occurred but also at understanding the individual perceptions that may have been instrumental in the decisions and judgments as made on this Program.","Lesson ID":625}
{"Driving Event":"During a crane disassembly, a cable sling broke, dropping a 10 ton crane counterweight. The crane crew was removing the front counterweight from the crane to place it on a flat bed trailer when the mishap occurred. The sling used was a rusty, 4 leg, 5\/8 inch diameter cable about 15 feet long. Only two legs were used during this lifting operation. The investigating committee found that calculations made from a standard table published by U.S. Steel showed that the allowable working load for a new cable of this size using 2 legs was only 5.28 tons. The crane operators, based on their experience and intuition, grossly underestimated the strength of the sling.","Lesson ID":239}
{"Driving Event":"An electrician suffered burns from an electrical arc when a pre-existing condition in a power distribution panel ultimately led to a ground fault in a 3-phase 480-volt power supply. The pre-existing condition was believed to be an access panel fastener that had penetrated conductor insulation. Power distribution panel designs must allow sufficient internal space within the panel enclosure to route the conductor cables away from fasteners. In the case of this mishap, it appeared that the conductor cables were routed close to the front access panels and dead front where there are multiple fasteners capable of penetrating the cable insulation. A combination of too small a panel plus overcrowded cabling ultimately resulted in fastener penetration of conductor insulation. Control of the cables was complicated further by the sinuous, unrestrained routing of the cables from the floor to the breaker connections (see picture). Periodic power surges (such as by operating high-voltage breakers or by operating pre-programmed power line surge control devices such as reclosures) can physically jar cables (much like a water or air hose experiencing a sudden pressure increase), moving them incrementally closer to fasteners. Short and straight runs of unrestrained cables would not experience this type of response. Repeated removal and reinstallation of the fasteners for panel access due to construction and maintenance activity may have jeopardized the integrity of the electrical cable insulation. Each removal and reinstallation cycle may have further penetrated the insulation.","Lesson ID":1716}
{"Driving Event":"The MO Traveling Wave Tube Amplifiers (TWTAs) were not powered during qualification Pyrotechnic Shock testing. As a result, the contractor's operations plan included not powering the beam and cathode heaters of both redundant TWTAs (thus no downlink telemetry) during the critical MO tank pressurization. Although this was a topic of significant debate during the design and manufacturing phases, early cost constraints resulted in decisions not to perform developmental testing and analysis to show whether or not there would be a problem powering the TWTA during the MO Pyrotechnic events. Analysis was performed to determine the lateral and axial capability of the cathode support design when powered off (cold). Actual testing to qualify the TWTA for powered operation (hot) was not performed, also based on programmatic cost constraint decisions. Additional Keyword(s): RF Testing Reference(s): \"MO Design & Implementation Audit\": JPL D-11433 \"MO Loss of Signal: Special Review Board Final Report\": JPL Publication 93-28 \"Report of the MO Mission Failure Investigation Board\" (the Coffey Report)","Lesson ID":432}
{"Driving Event":"A SUBSA ampoule contained a lithium chloride\/potassium chloride salt encapsulant with an indium antimonide sample. During a gradient freeze processing run, the encapsulant caused the sample to undercool and undergo non-directional solidification; consequently, breaking the quartz ampoule.","Lesson ID":1919}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PD-ED-1235 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefits: This design employs a simple method of providing protection against the effects of a crane operating at a higher than commanded speed while not introducing unwanted nuisance trips to the crane control system. This improves the reliability of the crane control system by preventing the crane from reacting to unwanted commands that are not operator initiated. The improvement allows the crane to be used with a higher degree of confidence that a critical failure will not result in damage to the load suspended from the load hook. Implementation Method: The design provides protection against damage to a load resulting from a crane drive system experiencing a speed increase caused by an unexpected input created by a failure of the electrical circuitry used to convey the operator stick input to the drive motors. The voltage sensing relay is set to detect a voltage that is larger than the normal operating voltage of the DC motors in the selected speed (slow, medium, or high). When this voltage is experienced, the relay will shut down the crane operation and set the brakes. For example, at KSC while performing stacking and mating operations of the Solid Rocket Motors (SRM), External Tank (ET), or Orbiter during Space Shuttle processing, the crane must be operated in the slow speed mode when within close proximity of a structure. The voltage sensing relay is active during this mode to prevent the shuttle components from impacting a surrounding structure as a result of a control circuitry failure. The relay is deactivated while operating in the medium or high speed modes because the critical load is not near an obstruction. This allows the crane to be operated with a higher degree of confidence and reliability that a critical failure will not result in damage or loss of critical flight hardware during stacking and mating operations. Technical Rationale: With a constant field\/varied armature DC motor (more than one motor, the armatures wired in series) the voltage sensing relay coil should be placed in parallel to the motor armature(s) (see Figure 1.). The relay coil should be fed through a bridge rectifier to insure the input to the relay is consistent regardless of the voltage polarity and direction of current flow present in the armatures. The normally open relay contact should be wired in series with the power supplied to the crane and brake controls. When power is applied to the crane the contact should close and enable the drive control circuitry. The contact will remain closed when the voltage in the motor armature is below the predetermined threshold. When the limit is reached, approximately 115% of the full output of the speed range, the contact will open disabling the crane drive and setting the brakes to stop the crane. To avoid the crane shutting down when in the higher speed range, a time delay relay will be energized by the speed selector switch and by pass the voltage sensing relay. To prevent nuisance trips when the speed selector switch is repositioned from the higher to the lower speed range while the crane is moving, the time delay relay will disable the voltage sensing relay for a short predetermined time period when it is de-energized. [D] References: 69-K-L-11388: quotVehicle Assembly Building 250-Ton Bridge Crane #1 & #2 Electricalquot SAA09FY12-005: quotSystem Assurance Analysis of the 250-Ton Bridge Cranes at the Vehicle Assembly Building, High Bays 1, 2, 3 & 4quot 67-K-L-11348: quotVehicle Assembly Building 175-Ton Bridgequot Crane Electrical. SAA09FY12-006: quotSystem Assurance Analysis of the 175-Ton Bridge Cranes at the Vehicle Assembly Buildingquot","Lesson ID":673}
{"Driving Event":"The measurement of pressure fluctuations in hypersonic flow fields is much more demanding on dynamic pressure sensors than in traditional acoustical applications. Essential sensor specifications for measurement of pressure fluctuations in hypersonic flow are small size (<0.02 in.), height temperature (20000F), frequency response (200 kHz), and 0.01-10 PSI dynamic range. The recent availability of high-temperature optical fibers makes the intensity-modulated fiber optic microphone a promising instrument for obtaining these measurements. Small sensor size is desirable to obtain high frequency response and to reduce spatial averaging errors due to the finite size of the sensor. In order to minimize the correction factors needed to account for the latter, it is desirable to have a sensor diameter at least as small as 0.02 in. For measurements in hypersonic flow. One of the predominant considerations in hypersonic flow is the high-temperature environment to which the sensors will be exposed. Thus, materials used to fabricate such sensors must be stable in the attendant environment. Sensors whose transduction is based on a material (piezoelectric, piezoresistive, magnetostrictive, etc.) Cannot meet the high-temperature requirement with current technology. The condenser microphone has an inherent small-size limitation due to loadings by cable capacitance; further, if a polarization voltage is used, then the necessarily close proximity of the preamplifier to the microphone cartridge will preclude operation at high temperatures. The recent availability of high-temperature optical fibers makes the intensity-modulated fiber optic microphone a promising instrument to fulfill the above requirements.","Lesson ID":514}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number GSE-3005 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Early identification of potential critical items will provide valuable inputs to design engineering for their avoidance and\/or elimination. Critical Items Lists (CIL) provide management with design acceptance rationale for those critical items which could not be eliminated, and identify test and inspection controls to minimize the probability of a failure. Implementation Method: Background GSE at KSC includes equipment and facility systems used to test, checkout, process, handle, and transport Space Shuttle flight hardware at the launch and landing sites. Equipment used at other sites that is common to that used at the launch and landing sites is also included. Prior to conducting the FMEA a criticality assessment is performed to assess each system function. If loss or improper performance of the function, without regard to available redundancy, could result in loss of life\/vehicle or damage to a vehicle system the system is assessed as critical. FMEAs are performed on the hardware associated with the critical functions. The only exceptions are functions assessed as critical due to failure of passive components, such as certain types of structural components. The Failure Modes and Effects Analysis (FMEA) is performed at the lowest level necessary to identify: 1) Single Failure Points (SFP's) which if failed could cause loss of life\/vehicle or damage to a vehicle system; 2) The combined effect of two like or unlike redundant items which could result in loss of life\/vehicle; 3) SFP's in safety or hazard monitoring systems whose failure modes assume the hazardous condition being monitored or combated has already occurred. The FMEA and resulting CIL can be used not only as a check of the systems design for reliability, but can also be used as a driver for the systems design to reduce or eliminate critical items and\/or implement value added maintenance design features. The FMEA\/CIL process plays a key role in reliability management. Reliability management is the activity involved in assuring that proper performance of the system\/equipment and completion of maintenance procedures will minimize the risks associated with the identified failure modes. Reliability management coordinates the analysis of design, development, manufacturing, testing, maintenance, and operations to assure that the system output will support the prescribed program interface\/function. Reliability Management is accomplished through the formulation of reliability plans, the performance of system\/equipment design analysis, the support of classical reliability analysis activities, and project\/system team participation using concurrent engineering methodologies. The principal outputs of the FMEA\/CIL process are the CIL's. Critical Items and Retention Rationale Specific lessons have been learned that will enhance the value of identifying potential critical items early in high-technology, multi-disciplinary aerospace programs and projects. Critical items are identified through the conduct of a FMEA. The FMEA process involves the analysis of each active component (hardware or software element) in a complex system to a specified level, for each possible failure mode. The determination of the \"worst case\" failure effect of that failure on vehicle systems and\/or personnel safety is then determined. If the item could fail in a mode which could directly result in loss of life\/vehicle and\/or damage of a vehicle system, the item is designated as a critical item and categorized according to the severity of the failure effect. SFP's in designated safety or hazard monitoring systems, whose failure modes assume the hazardous condition being monitored or combated has already occurred, are also identified as critical items. The FMEA is most effective when it is performed concurrently with the design process and maintained throughout the life of a program or project. It is the policy of NASA not to permit the retention of SFP's in design unless special conditions result in the application and approval of a waiver or deviation from the Space Shuttle Program (SSP) Configuration Management Requirements. Retention of a SFP requires that a CIL sheet be prepared which identifies the item, Criticality Category, Function, Failure Mode, Failure Cause(s), Failure Mode Number and Failure Effect. The CIL sheet also provides the Acceptance Rationale which describes the components design, test, inspection, failure history, and operational use. The elements of the Acceptance Rationale, as described below, include safety margins, prevention measures, and maintenance\/operational procedures which will ensure that the critical item will not fail in the critical failure mode. The Acceptance Rationale forms the basis for management acceptance of GSE which contains critical items. Design Rationale: Design rationale identifies design features and\/or margins that have been provided in the design of the hardware or software element which minimize or eliminate the probability of occurrence of the failure mode and\/or reduction or elimination of the potential causes of the failure mode. Test Rationale: Test rationale includes specific tests which are accomplished to detect failure modes and\/or causes during acceptance and periodic certification. If turnaround checkout testing is accomplished via Operational and Maintenance Instructions (OMI's) the details of the test, frequency, and OMI number are included. Inspection Rationale: Inspection rationale addresses specific inspection methods,procedures, tools, and techniques which are performed on a pre-operational and\/or post-operational basis to determine whether or not the critical failure modes have occurred. Inspections which minimize the probability of encountering failure modes and their potential causes are also included. Tear-down analysis is excluded as a means for inspection. Failure History: Failure history includes data on previously reported failures and corrective actions for the critical item in the critical failure mode(s) as found in the Problem Reporting and Corrective Action (PRACA) database. Reference is also made to the PRACA database for current data on test failures, unexplained anomalies, and other failures experienced during ground processing activities. Operational Use: Corrective action that would either prevent the particular mode or mitigate it's effect once it has occurred is included as part of the retention rationale. The time required to take the corrective action (timeframe) is also provided. The CIL sheet is presented to project management for approval\/acceptance of the risk associated with the critical items and subsequently to the Program Requirements Control Board (PRCB) with the waiver request (CR). The waiver request identifies the failure modes which do not meet the fail safe requirement from NSTS 07700, Volume X. The fail safe requirement specifies that all GSE (except primary structure and pressure vessels) shall be designed to sustain a failure without causing loss of vehicle systems or loss of personnel capability. Suggestions for Effective CIL Implementation based on KSC experience Correlation of FMEA results with Fault-Tree Analyses and Hazard Analyses: The FMEA\/CIL data can serve as an input to the hazards analysis process. The hazards analysis uses fault trees and is basically a top down approach. It focuses on human errors and considers multiple unrelated failure modes which the FMEA\/CIL ground rules out. Use of the CIL sheets to initiate risk management controls: Preparation of the CIL sheet can be used as an opportunity to coordinate with the cognizant engineering organizations to develop and agree upon appropriate maintenance procedures and operational processes to assure control of the risks associated with the critical items. Subsequently the CIL can be used to initiate closed loop tracking of the test and inspection controls. Use of FMEA\/CIL to develop test and checkout procedures: FMEA\/CIL developed early in design projects can be used as input to develop test procedures, inspection requirements, operational procedures, and trouble shooting guides. The component level analysis performed in the FMEA and the detailed reporting of critical items provides specific information regarding failure scenarios with defined system reactions and expected personnel corrective action. CIL's should be implemented in a way that would not impact important program milestones or create unnecessary work-around in the areas of cost, schedules, or system performance. Example Uses of FMEA\/CIL Use of FMEA for early identification of critical items: The design process for the 325 Ton Bridge Crane installed in the Vehicle Assembly Building at KSC utilized the FMEA process to identify potential critical single failure points in both hardware and software systems. As potential single failure points were identified the reliability engineer coordinated with the NASA and vendor design engineers. The design engineers were made aware of the failure effects, alternative designs were considered, and solutions were implemented. The FMEA process continued through test and acceptance of the equipment with the resulting design having no single failure points. Use of CIL sheets to identify risk to management: The CIL process was utilized during the analysis of the extensible and auxiliary access platforms in the VAB. The analysis was initiated by a design study that indicated that a substantial number of platforms were equipped with hinges that may fail under dynamic loading. Reliability engineering analyzed the systems and identified critical single failure points which, if failed, could allow a platform to fall causing a cascading effect of one platform upon another and resulting in the overloaded hinge scenario as described in the design study. The CIL sheets were used to advise management of the risks associated with platform operations. During presentation of the CIL sheets, Reliability Engineering also made recommendations for alternative fail-safe equipment. Management was able to assess the risks, accept interim controls and identification of new CIL items, and initiate implementation of corrective action. Use of CIL sheets to initiate test and inspection controls: The CIL process has been used at KSC to manage the risks associated with cranes and hoists which, if failed, could cause loss of life or vehicle. CIL sheets for critical gear systems\/components identify test and inspection requirements which are performed in a close-looped tracking operations and maintenance process. Performance of a periodic load test at rated load, verifies the operational integrity of the gear system and periodic ferrographic analysis of the gear lubricant is used to document wear trends and to assist in predicting future failure. Technical Rationale: Extensive analytical work on existing and emerging programs relative to failure identification, management, and control has resulted in well documented, rigorous procedures for the treatment of critical items. Concurrent engineering approaches to program engineering and management have included attention to more details earlier in the design process and at a much lower level than previously attained. Assurance of success means the elimination or reduction of potential failure modes. Elimination or reduction of potential failure modes can only be achieved through the conscientious application of FMEA, critical item identification, and prudent engineering management. The advantages of the FMEA\/CIL process are that it: (1) Systematically identifies all credible failure modes and causes; (2) permits a focus on critical SFP's and levels of redundancy; (3) provides management with risk acceptance rationale for critical failure modes\/causes; (4) initiates control of critical items, associated procedures, and processes; and (5) provides a single, agreed-to listing of all critical items associated with a given project. References: National Space Transportation System Critical Items List, Shuttle Program Critical Items List, Kennedy Space Center Ground Support Equipment, NSTS 08399, Book 4, Revision A, Lyndon B. Johnson Space Center, Houston, TX, November 28, 1988. Problem Reporting and Corrective Action System Requirements, NSTS 08126, Lyndon B. Johnson Space Center, Houston, TX, April 7, 1994. Requirements for the Preparation and Approval of Failure Modes and Effects Analysis (FMEA) and Critical Items List (CIL), NSTS 22206, Revision D, Lyndon B. Johnson Space Center, Houston, TX, December 10, 1993. Space Shuttle Flight and Ground System Specification, FMEA\/CIL Deviation and Waivers, NSTS 07700 Volume X, Book 5, Revision K, Lyndon B. Johnson Space Center, Houston, TX, October 9, 1992. Space Shuttle Program Configuration Requirements, NSTS 07700 Volume IV, Lyndon B. Johnson Space Center, Houston, TX, November 23, 1994. NASA Reliability Preferred Practice PD-ED-1240, Guideline for the Identification, Control and Management of Critical Items.","Lesson ID":649}
{"Driving Event":"Loss of Challenger","Lesson ID":329}
{"Driving Event":"The external tank's gaseous hydrogen vent arm provides for venting of the LH2 tank, pneumatics, and electrical services to the ground umilical carrier. The deceleration unit has failed twice. These failures were caused by a low fluid level in the shock absorber. During one launch failure the QD was damaged and broke in half. Several hours after launch, the detanking of the LH2 dewer tank was started and gaseous hydrogen vented out of the broken QD\/pipe, instead of venting to the Pad-A burn pond as designated.","Lesson ID":157}
{"Driving Event":"Significant flaws existed in OSP's implementation approach resulting in a misunderstanding of the S&MA organizational authority","Lesson ID":1511}
{"Driving Event":"This Lesson Learned is based on Reliability Practice No. PD-ED-1239; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. This practice enhances the probability of mission success by controlling temperatures of flight hardware as well as spacecraft charging and RF emissions over the life of the mission. Implementation: Spacecraft and scientific instruments usually contain hardware, including sensitive detectors, which require that temperatures be maintained within specified ranges. A good thermal design is therefore essential to a successful mission. Thermal control coatings is one of several systems, such as thermal blankets and electric heaters, that are used to control temperatures. In space, the operating temperature of a spacecraft is determined by the heat input from the sun, the reflected solar energy from the earth, the background temperature of space, the internal heat generated by the spacecraft and by the emittance and absorptance of spacecraft coatings. Predicting the operating temperature of the spacecraft therefore requires a knowledge of the thermal properties (absorptance and emittance) of the coatings used. In addition to these basic requirements, it is usually necessary to be cognizant of other spacecraft requirements such as spacecraft charging and particulate and molecular contamination requirements in order to choose the proper thermal control coating. It is also important to know how those properties are going to degrade throughout the life of the spacecraft due to exposure to UV, high energy protons and electrons, low energy solar wind protons, and contamination from other parts of the spacecraft. The practice for the selection and application of thermal control coatings includes the following key elements in the selection and application of thermal coatings: 1) The absorptivity and emissivity of particular thermal control coatings are determined and verified by testing. When possible, test measurements are made with the test sample subject to actual flight conditions such as vacuum, temperature, etc. Electromagnetic theory can give useful insights into the absorption and emission of electromagnetic energy from thermal control coatings and how the absorption and emissivity vary as a function of angle, temperature, and wavelength. Maxwells equations can be used to show a theoretical description of the interaction of electromagnetic radiation with spacecraft coatings if one knows the optical constants of conductivity, permittivity, and permeability of the coating. However, in a number of cases, it has been shown that predicted reflectivity and emittance do not agree with test measurements. This can be due to lack of precise data and also due to the fact that electromagnetic theory does not always account for factors that can cause irregularities in the actual performance. Therefore, the absorptivity and emissivity of particular thermal control coatings are determined and verified by testing. 2) Effects of surface roughness and coating thickness are primary considerations in applications of coatings. The surface roughness and the thickness of thermal coatings can have a significant effect upon the emittance and absorptance of the coating. The absorption and emittance will begin to change when the surface is no longer optically smooth; that is when surface defects are much smaller than the wavelength of radiation being absorbed or emitted. When the wavelength becomes comparable to the size of the imperfections, multiple reflections and diffraction effects can occur resulting in changes in the absorption and emittance. Also, if the coating is too thin, the coating becomes partially transparent in the infrared or visible part of the spectrum. This makes the effective emittance or absorption of the coating the sum of the emittance of the coating plus some portion of the emittance of the substrate. It is important to test samples analogous in roughness and thickness (same coating processes and substrate) as used in the space application. Thickness is also a consideration for optimum adhesion and stability during thermal cycling. 3) Flight data is researched and laboratory testing is performed to determine a thermal coating's susceptibility to space radiation and the amount of degradation that can be expected during the lifetime of a mission. Degradation of thermal control coatings in space can manifest itself as changes in emittance, solar absorptance, loss of adhesion, changes in specularity, or changes in electrical conductivity. These changes can be caused by absorption of electromagnetic photons, contamination of the coating by outgassing from other parts of the spacecraft, and by thermal effects on the coatings. The degree to which thermal coatings degrade also depend upon the energy and total contamination that the coatings receive during the mission. It is therefore, necessary to assess the mission radiation environment. This includes the energy fluency at each energy level of protons, the total UV exposure and atomic oxygen exposure level over the life of the mission. From this data, a test program is devised to determine the susceptibility of the coating to each form of radiation as well as to assess the synergistic effects of multiple radiation sources. 4) A detailed analysis of the contamination of the spacecraft is performed in order to determine the amount and type of contaminates expected to develop on surfaces of the spacecraft. Chemical contaminants on surfaces including oxide layers deposited either by absorption or through a chemical reaction with the surface can cause significant changes to the absorptance, emittance and conductivity. These surface contaminants can change the chemical composition of the outer layer and the electrical conductivity thereby increasing the emittance of most metals. Particulate surface contaminates can also affect the thermal properties of coatings. This effect though is usually much less than that caused by chemical contaminants. Particulates tend to scatter incident radiation but since the total area coverage is small they generally do not greatly affect the absorption or emittance unless the contamination becomes excessive. In addition, very thin layers of particulate contamination can have an effect on the emittance of a coating and must be taken into account. 5) Electrical properties are primary considerations used in the selection of thermal control coatings. Electrostatic discharges (ESD) can occur in space between various parts of a spacecraft due to differential charging of the spacecraft caused by energetic charged particles. This ESD is a source of electromagnetic interference (EMI) which can be coupled to electronic circuits and devices. Sensitive ICs can be damaged by several micro-joules (uJ) of ESD and circuits can be upset with only several nano-joules (nJ). This charging phenomena has been blamed for arcing that has caused blown fuses and loss of data transmission on several spacecraft. ESD can also cause electronic parts failure, operational anomalies, degradation of thermal control surfaces, and can also render low energy particle detectors useless. It is recommended that the energy stored by each electrical nonconductive surface be less than milli-joule (3mJ) and that ESD should not be allowed to occur near receivers or antennas operating at frequencies less than 8 GHz or near sensitive circuits. This implies that the spacecraft must be immune to 3 mJ ESD. Differential spacecraft charging is primarily the result of low energy electron flux. High energy electrons penetrate the thin thermal coatings and therefore do not contribute to the differential charging process. The relatively few high energy protons encountered do not penetrate the coatings and therefore contribute to the charging although to a much less extent than the low energy electron flux. This is because the mass of electrons is much less than the mass of protons and they must travel much faster than protons in order to reach the same kinetic energy and hence thermodynamic equilibrium. This means that the total number of electrons passing a given point in a fixed amount of time is greater than for protons, therefore the spacecraft receives a much greater electron flux than proton flux. Finding a coating which satisfies both thermal and electrical conductivity requirements is sometimes difficult to achieve, particularly if a low absorptance high emittance coating is needed. The conductivity of coatings can depend upon a number of factors. First, the length of time the coating has been exposed to vacuum can cause outgassing of volitales and water vapor which can alter the conductivity. Second, the energy of the electron flux can have a bearing on the extent to which a coating will charge since the conductivity is a function of particle energy. And thirdly, the temperature of the coating can also play a significant role in the charging process. Therefore the measurement and the verification of the conductivity of space flight coatings is performed under as close to actual conditions as is possible in a laboratory. In those cases where a coating is applied over a nonconductive substrate, charge control is achieved through the conductivity of the coating. Provisions are made for grounding the edges of the coating. In some cases the substrate is coated with a conductive medium before the thermal coating is applied in order to alleviate a high charge with respect to ground. Refer to the following Figures 1 and 2 for methods for grounding conductive coatings to spacecraft ground. [D] [D] 6) Specific, detailed, and written GSFC approved methods and procedures have been prepared for the selection, handling, and application of each thermal coating used on GSFC instruments and spacecraft. These procedures have been prepared for both paint and tape coatings. The procedures include general considerations on the use and applications of the coatings, formulation where applicable, and complete procurement and acceptance inspection and testing requirements. Acceptance testing includes outgassing tests, electrical charging and erosion characteristic measurements as applicable, adhesion, and optical measurements and degradation. Materials and equipment lists for handling and applying the coatings are provided including safety and toxic considerations and equipment such as air filtration and ventilation hoods etc. Formulation and blending procedures are detailed where applicable as well as surface preparation and cleaning procedures including post coating operations and cleaning and touch up. The application of the coating whether by brush, spraying, or by applications of strips of tape are defined. The procedures require monitoring samples for inspection and testing and in some cases require that monitoring samples be maintained for inspection and testing throughout the life of the coating in space. Storage requirements and shelf life limitations of coating materials must be observed. Curing times can be a factor to be considered in the selection of coatings due to interference with other testing or hardware activities. Complete documentation is maintained of the coating material from delivery to launch of the spacecraft. A procurement log of delivery date, manufacturer's batch and lot numbers, expiration of shelf life date, etc. and incoming inspection and testing data including monitor samples are maintained. A processing work order document is filed in the coating facility to provide a description of the specific coating requirements including required tests and test samples. A complete log of the coating process including any problems and test failures is maintained. Technical Rationale: The reliable operation of a spacecraft and its complement of scientific instruments and equipment require thermal control coatings to maintain temperatures within specified ranges. In addition, these coatings must also control spacecraft charging and ESD. This practice ensures good thermal coating design and application procedures to reliably meet a wide variety of thermal design and ESD requirements. References Handbook of Heat Transfer, (Rohsenow & Hartnett), GSFC Library Reference No. QC320.R528 C.1 Engineering Radiation Heat Transfer, (J. A. Wiebelt), GSFC Library Reference No. QC320.W64 C.1 Radiation Pyrometry and Its Underlaying Principles of Radiant Heat Transfer, GSFC Library Reference No.QC.338.H31 C.7 Thermal Radiation Heat Transfer Vol.1 NASA SP-164 Environmental Testing of Thermal Control Coatings Design Material IITRI Proposal 72-422C Solid State Physics, Ashcroft and Mermin Long Term Performance of Thermal Control Coatings at Geosynchronous Altitudes Hall and Fote Spacecraft Dielectric Materials Properties and Spacecraft Charging A. R. Fredrickson and D. B. Cotts TL 1492 SG2 1986 J. A. Wall and F. L. Bouqet NASA Reference Publication 1121 Entitled quotSolar Absorptance and Thermal Emittance of Some Common Spacecraft Thermal Control Coatingsquot Prepared by John Henniger Individual Procedures For The Formulation, Application And Maintenance Of Thermal Control Coatings Prepared by GSFC Thermal Control Branch","Lesson ID":727}
{"Driving Event":"The International Space Station (ISS) Program uses fiber optic cabling extensively in the audio, video, and high rate data subsystems. KSC accepted fiber that was sub par because we did not have a process to properly inspect and verify the quality of work from the manufacturer.","Lesson ID":1876}
{"Driving Event":"The ISERV payload was developed to provide data and images for the SERVIR team through a downlink from the ISS. Health and status information of the ISERV system was required through the downlink also. The ISERV payload has the capability for issuing commands at predetermined times and accepts file transfers from the WORF. Specific events and obstacles encountered during the design and development of the payload provide the basis of the lessons learned. They are: There were insufficient foundational documents for the ISERV payload due to cost and schedule constraints. The introduction of COTS components and systems into projects challenged the traditional MSFC approach to designing, developing and testing flight hardware. Standard operating procedures have evolved to meet Class A and B projects. The likelihood of more COTS-based or COTS-involved flight programs (Class D) being worked by MSFC Engineering is increasing and this new reality must be integrated into our defined ways of doing work. The procedures and tools are not the same for JSC and MSFC Export Control Offices. Inputs into the Relational Database Management System (RDBMS) were required for payloads to be launched on HTV-3. The inputs were very specific and complicated. MSFC does not use this database at this time. The person coordinating this was not experienced with this process, but was able to get help from a Boeing person at JSC to walk her through. Added complications were that the manifest and Launch \/ Return \/ On-orbit Data Set (LRODS) were still being finalized when Export Control evaluation was needed, due to the shortened schedule and serial development of these products. The team was also dealing with holiday leave during December and early January, which limited the availability of personnel needed for review and approval. An MSFC Export Control Representative could not approve the inputs, so the team had to rely on the JSC Export Control Representative to approve the inputs. He didn\u2019t understand why the approval request was coming to him, which further complicated the situation. The MSFC Export Control Representatives were instrumental in working with the JSC Export Control Representatives to resolve the difficulties and get the process moving in the right direction to closure. As the project was formulating, the MSFC ISS Payloads Office had little time to review and comment on the presentation to HQ and all the affected Engineering organizations were not consulted with in preparation for the HQ presentation. Areas where the presentations needed better coordination included: a. Adequate funding allocations for manpower, materials, and testing b. Better scope of the job to be done c. \u201cReasonableness\u201d of the quote 5. Since the ISS Payload Office project and engineering teams were not included in the preliminary discussions with HQ on the proposal, the team had little knowledge of the system being proposed. In fact, due to space limitations in WORF (which is where the camera\/telescope was to reside), the hardware selection had to be changed before the team was given approval to proceed. We had to do the best with what we were given. Initial size estimates were way off of the final system.","Lesson ID":7217}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) The Voyager Photopolarimeter Subsystem on both S\/C-31 and S\/C-32 has a history of analyzer and filter wheel stepping problems. The problem was discovered late in the test program before launch. The problems persisted in Flight with the analyzer wheel becoming unsteppable. Filter wheel could be stepped marginally, but that was also given up. Numerous in-flight operational fixes were tried without success. Failure analysis by the PPS Diagnostic Working Group has traced the probable cause of this anomaly to formation of an insulating \"frictional polymer\" on PPS potentiometer wiper contacts. Such a polymer can be formed by the sliding action of metals in the presence of small quantities of almost any organic molecule. This polymer formation reaction was noted as early as 1958 by the Bell System in researching relay failures. Palladium is a particularly efficient catalyst for this reaction - unfortunately, the PPS wipers are made of a palladium substance. Additional Keyword(s): Contamination, Electrical Contacts Reference(s): ISA's 1392, 1420, 1677, 1720, 1899 (Also see PPS ISA's for VGR-2 Encounter)","Lesson ID":438}
{"Driving Event":"During Venus mapping operations at high (over 64 degrees) incidence angles of the sun to the solar panels, a jitter occurred in the solar array drive control loop. This jitter excited a structural resonance in the solar panels, causing severe vibration. The problem was caused by a deficiency, at oblique sun angles, in the algorithm that is used in Flight Software (FSW) to determine whether a solar panel position correction is required. The deficiency was caused by not accounting for high sun incidence angles (geometrical effects) in setting the minimum step size software parameter. As a result, the algorithm continually determined that a correction was required -- first in one direction, then in the reverse, then in the first direction, etc. The jitter was actually present in simulations performed by the flight team before the incident occurred on the spacecraft, but was not recognized because of the plotting scale used. Once recognized, the problem was solved by switching the solar array control to an open-loop mode, i.e., not using the sun sensors, while the celestial geometry was unfavorable. A complete description of the problem can be found in the references. Additional Keyword(s): AACS, Mathematical Models Reference(s): PFR #52242, ISA 8775, ISA 9049, ISA 8536","Lesson ID":358}
{"Driving Event":"Validation of Extravehicular Mobility Unit (EMU) Planar Hard Upper Torso (HUT) Capability","Lesson ID":1114}
{"Driving Event":"Spacecraft command file errors pose a threat of triggering an event that cannot be halted before a mission is irreversibly compromised (Reference (1)). A command file error for the purposes of this lesson learned is defined as one of the following, regardless of the effect on the spacecraft: An error in a command file that was sent to the spacecraft, An error in the approval, processing, or uplink of a command file that was sent to the spacecraft, or The omission of a command file that should have been sent to the spacecraft. Implementation of the spacecraft commanding process may vary due to project-specific attributes, such as: Commanding for deep space missions is non-repetitive, as compared to an Earth orbital mission where typical commands may be reused on a routine basis. The JPL mission operations design must be flexible to permit the exploitation of unanticipated science opportunities (e.g., Cassini\u2019s discovery of water jets venting from a polar region during a close flyby of Enceladus in 2005) by modifying planned sequences. In November 2010, a JPL Operations Working Group was formed to provide a forum for the identification, discussion, and implementation of corrective action over a broad range of operational issues across JPL institutional boundaries (Reference (2)). The initial task was to review the command file errors during 2009, identify the associated processes, and draw lessons to be incorporated back into the projects and the institution. The group met over the next three months and documented their findings. The proximate\/root causes were grouped into four major categories of: Loss of rigor (inattention to detail, complacency, inadequate review, procedures not followed, miscommunication, distraction, multitasking). Loss of situational awareness (inadequate knowledge of the spacecraft state as a function of time). Flight team work overload (stress, fatigue, rush in getting task done). Performing nonstandard activities (i.e., doing activities in different ways, first time events on the spacecraft). The themes\/findings fell into nine general categories that were subdivided into development and operations recommendations (see \u201cRecommendations\u201d). The findings and recommendations were then disseminated to projects approaching launch and early cruise operations (Juno, Gravity Recovery and Interior Laboratory (GRAIL), Mars Science Laboratory (MSL), and Nuclear Spectroscopic Telescope Array (NuSTAR)), as well as to ongoing flight missions, so they could proactively evaluate measures for reducing their overall operational error rates. References: Uplink Command Errors (A Cornerstone Lesson), \u201dNASA Lesson Learned No. 1521, April 14, 2005. Grant B. Faris and Larry W. Bryant, \u201cImproving Operations: Metrics to Results,\u201d SpaceOps 2012, Stockholm, June 11-15, 2012. \u201cEarly Involvement of Mission Ops is a Key Success Factor,\u201d NASA Lesson Learned No. 1518, November 1, 2004.","Lesson ID":8302}
{"Driving Event":"The primary Geosynchronous Imaging Fourier Transform Spectrometer (GIFTS) sensor is an imaging interferometer with two large area Focal Plane Arrays (FPAs). Each FPA contains over 16,000 pixels. The pixel data - in the form of electrical signals - experiences large amplitude variations as the interferometer approaches the point of ZPD. The data compresses poorly in the ZPD region because of the large dynamic range and the large frame size of the data. Near real-time compression is difficult, since the data backs up (slows down) while waiting to be compressed. Thus, the data compression scheme used for GIFTS had localized issues that were harder to resolve than a simplified approach of just taking a frame of data and compressing it.","Lesson ID":1594}
{"Driving Event":"Following the recommendations from the X43A Flight 1 MIB, the Pegasus actuator system was redesigned to accommodate the need for greater hinge torque. The analog-based legacy actuator system was redesigned for digital drive of the power output stage to the actuators, an additional actuator was incorporated to provide the necessary torque including margins, and the power supply was increased to provide the required 80+ amps, instead of the previous 40 amp capability. Multiple failures during qualification testing, and the subsequent technical investigations, proved the lack of understanding between the ideal circuit operation and the impact of system implementation.","Lesson ID":1603}
{"Driving Event":"Three RCS primary thruster injector\/chamber assemblies were damaged when the oven temperature control system malfunctioned and permitted the temperature to reach an estimated 1400 deg F during a cerachrome insulation baking process that should have been limited to 625 deg F. These units should have been rejected at this point, but quality assurance was not notified. As a result, the full extent of damage was not determined until the severe discoloration of titanium alloy and columbium parts was noted during the post-baking weighing process, about three weeks later.","Lesson ID":78}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1434 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Since the operational readiness and future performance of space flight batteries at any point in a mission are strongly dependent upon past power cycles and environments, thoroughly instrumented and analyzed ground testing of space flight batteries identical to flight configurations will ensure predictable performance and high reliability of flight batteries. Implementation Method: Real-time, long term mission, power cycle simulations of space flight batteries in ground facility test beds provide an excellent indication of expected performance in flight. Complete verification of a full real-time mission is not possible with long-term missions due to the test lead time. Instead of accelerating the test, the test engineers should quotleadquot the actual mission by a year or two (as long a lead-time as possible while still being able to use flight designs and configurations). This verification is in addition to qualification steps for the designs. Accelerated testing is not common for low earth orbit (LEO) missions but is used for non-LEO missions. The cells are interconnected in the anticipated flight condition and are housed in a thermally controlled chamber which is purged with an inert gas. Preprogramed, computer controlled power supplies and load banks cycle the batteries through the same dormant, power drain, and charging cycles that they would encounter in the space operation. Shading of solar arrays during eclipse periods is simulated by absence of charging current, and charge cycles are simulated during exposure to the sun. Table 1 lists the principal purposes and features of long-term battery simulations. [D] Table 1. Principal Purposes and Features of Long-Term Battery Simulation All cells are instrumented at various locations for current, voltage, temperature, and pressure. Ambient temperature in the chamber is constantly monitored. Voltage and current values are available in real time through digital readouts. Voltage, current, pressure, and temperature are recorded constantly on strip charts. Data are sampled by computer programs which compute and analyze ongoing performance. Table 2 shows the parameters usually recorded and\/or computed for each battery cell from sampled data. Ground testing of batteries and their associated power systems has proven to be a valuable asset for the resolution of in-flight anomalies. Limits testing can be safely simulated on the ground to verify or explore variations in flight performance. [D] Table 2. Recorded and Computed Data Parameters for Each Cell Safety precautions are important in testing of all battery systems because leakage of electrolytes or effluents can be hazardous. Typical precautions and safeguards for nickel-hydrogen (Ni-H2) batteries are shown in Table 3. [D] Table 3. Typical Precautions\/Safeguards for Ni-H 2Battery Testing An important action that will help to ensure a successful test effort is the preparation of a comprehensive test plan before the test begins. The test plan should describe the overall scope and approach to the test operation, and provide a detailed test sequence including the test set up parameters, data handling requirements, and test procedures. The test setup description should include the cell specifications and method of packaging into the battery configuration, the data acquisition and control procedures, and the thermal control system requirements. Test procedures should include cell characterization testing procedures (assuming that the cells have already passed through acceptance testing prior to receipt at the test site), launch scenario simulation procedures, mission simulation procedures, and mission capacity test and reconditioning procedures if required. Technical Rationale: MSFC has conducted multi-year testing of silver-zinc, nickel-cadmium, and nickel-hydrogen batteries since 1986. Some tests that were started in 1986 are still underway at this writing. Test durations are over eight years and counting. MSFC is conducting 8 to 10 tests simultaneously, with up to 400 channels of instrumentation on some tests. To support the Hubble Space Telescope, diode bypass relays on two batteries were opened to simulate an in-flight anomaly. The HST ground tests indicated that strong performance should continue from the HST flight batteries despite the in-flight anomaly. References: Whitt, Thomas and Lorna Jackson: quotBattery and Cell Testing at Marshall Space Flight Center,quot (a presentation), NASA\/MSFC, EB12, Huntsville, AL, 1988. Brewer, Jeffrey, John Pajak, and Lorna Jackson: quotTest Plan for AXAF-I Ni-H2 Battery Mission Simulation Testing,quot NASA\/MSFC, EB71, Huntsville, AL, March 30, 1994. Brewer, Jeffrey, and Thomas Whitt: quotHST Ni-H2 Flight Spare Battery Test,quot NASA\/MSFC, EB12, Huntsville, AL, Huntsville, AL, October 6, 1989. Whitt, Thomas, and Charles Hall: quotHST Ni-H2 Six Battery Mission Simulation Test,quot NASA\/MSFC, EB12, Huntsville, AL, November 2, 1989. Whitt, Thomas, and Jeffrey Brewer: quotFifth Semi-Annual Report on HST Ni-H2 Six Battery and Flight Spare Battery Test,quot NASA\/MSFC, Huntsville, AL, August 8, 1993.","Lesson ID":802}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1431 from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. On spacecraft hardware where risk vs. cost trades permit higher risk (Class C), Voltage and Temperature Margin Testing (VTMT) is an economical alternative to classical worst case analysis (WCA). The major benefits in using VTMT instead of WCA are: Assurance of a systematic method for investigation of potential risks where the parameters are not adequately modeled by worst case analysis. An example is RF circuits which have distributed circuit parameters. Labor savings for units too complex to simulate and which generally require Monte Carlo or root-sum squares analyses. Real-time operation and review of complex circuits, allowing the weighing of alternative design actions. Cost savings from expedited risk assessment. Comparative studies have demonstrated that testing may be completed in less than one-third the time required for analyses. Implementation Method: The VTMT must be designed to achieve adequate variation of circuit parameters through a judicious choice of voltage, temperature, and frequency margin combinations to achieve an optimal, yet realistic check of the design margin. Sufficient margin must be demonstrated at beginning-of-life (BOL) to permit confident performance extrapolation for those conditions that are not achievable at component infancy. These conditions include radiation effects, initial tolerance variations, aging, and unit-to-unit variations defining end-of-life (EOL) conditions. VTMT applies power downstream of voltage regulating devices to permit an adequate range of voltage variations. Optimum limits for voltage and temperature must extend beyond the extremes of the derated part specifications, but must remain within manufacturer device limitations. The test plan pays careful attention to limits; it describes in detail the execution of the tests, including exercising the functional characteristics of the design and assessing the associated circuit parameters against the established pass\/fail criteria. Potential failure modes must be identified prior to VTMT to ensure that no damage occurs to the unit under test. Typically the operational extremes are extended to demonstrate positive flight margins using temperature as the universal test parameter to simulate other parameters such as environmental and end-of-life changes. Thus the item under test is exposed to risk of damage by stress due to high temperature. Hence, the support equipment used to control the temperature and the test parameters must be extremely accurate, especially at maximum temperatures. Technical Rationale: VTMT has long been an important tool for verification of circuit operational limits that are dependent upon part parameter variations. The following techniques form the VTMT repertoire: (1) temperature variation, (2) applied voltage variation, and (3) clock frequency variations for digital circuits. The use of VTMT to simulate worst case functional performance is justified because the effects of voltage, temperature, and frequency upon device performance parameters is similar to the effects of radiation and end-of-life changes. This concept is very well demonstrated quantitatively at the part level, but less quantitatively at the assembly level. The rationale for use of these three test procedures is discussed below. 1. Temperature Variations: As temperature changes, so does the absolute values of the parameters of the individual parts. Temperature is the first order term in almost every variation of part parameters except for initial tolerance variation. Similarly for cables and transmission lines, distributed parameters exist that also vary with temperature. 2. Applied Voltage Variations: Changing the supply voltage to the circuit under test is equivalent to changing the voltage potentials across groups of parts. Thus the potential across each part within a circuit loop changes accordingly whenever the total applied voltage is changed. Varying the applied voltage can check the ability of an analog circuit to operate within specifications and generally can be added linearly to the temperature induced performance changes. 3. Variation of Clock Frequency for Digital Circuits: Varying the frequency of an input clock or pulse train can simulate changes of digital circuit delay parameters which may occur during flight. The limits of design degradation (and limits of absolute failure) with frequency can be determined. This knowledge can be used to determine if sufficient timing margins exist. Often voltage is reduced during the frequency margin testing to achieve even more margin. Clock frequency changes of \u00b125% are typical in performing the VTMT. In forming combinations of two or more of these test tools, considerable attention is given to simulating the effects of operating life, radiation, and initial tolerance. Preventive measures are ascertained from relevant experience, related reliability analyses, or test and manufacturing data that have been obtained on similar units and interfaces. VTMT duration should be sufficient for the devices to reach thermal equilibrium and exhibit steady-state operating conditions. The test requires approximately 3 hours at each temperature level over a 24-hour duration. Measurements before and after the tests are recorded and compared with a predetermined deviation, e.g., less than 15 percent. The test planner consults the failure prevention plan for the flight project to ensure the safety of the hardware. A test matrix may be used to form a safety prevention checklist of critical conditions, and the matrix may provide a catalogue identifying diagnostics and possible failure chain contributors. The VTMT technique is a closed-loop process; it comprises a checklist that is planned, monitored, and evaluated concurrently by quality assurance, reliability, and engineering personnel. Since the voltage, temperature, and frequency variations applied in VTMT can exceed those expected during flight, the additional circuit design margins successfully demonstrated by the test are assumed to encompass the parameter margins expected from radiation and operating life. Calculations can be performed to estimate the final margin. Note that although initial tolerances of parameters disappear when the to-be-flown hardware is the item under test, the initial tolerance variation must be considered in VTMT application to all other units of the same design. Figure 1 is a flow diagram of the VTMT process. [D] References Reliability Analyses Handbook (1990), Jet Propulsion Laboratory, D5703. Reliability Assurance Guidelines for Low Cost\/Short Duration Missions (1995), Jet Propulsion Laboratory, NASA Technical Memorandum 4629.","Lesson ID":771}
{"Driving Event":"A positive experience from rigorously maintaining a well-defined on-line risk management system.","Lesson ID":1296}
{"Driving Event":"The set of six contaminated flex hoses that were found to have been damaged by the Ares I-X launch required field flushing because they contained residual hypergolic propellant. Employees were potentially exposed to hypergolic oxidizer [Nitrogen Tetroxide\/Nitrogen Dioxide (N2O4\/NO2)]. An employee was conducting cleanup operations pursuant to a Standing Work Order (SWO) and verbal direction from the supervisor. The cleanup was part of a management initiative to improve working conditions, efficiencies, and appearances at the Waste and Water Support Building (WWSB). As an employee moved a flexible stainless steel braided hose stored on the east side of the WWSB, a strong odor, similar to chlorine, and a hissing noise were noted. The employee noticed an unidentified orange-colored vapor cloud being released from one of the F\/H flanged ends, which were both capped with a metal blanking flange. Initially, the employee attempted to mitigate the situation by applying water to the flanged end of the F\/H with a garden hose.","Lesson ID":8016}
{"Driving Event":"During prelaunch check out of shuttle orbiter OV-104 for flight STS-36, the AC2 buss phase a voltage fluctuated between 112 and 122V for one minute. The inverter supplying that buss was removed and replaced. The vendors' inspection of the failed inverter found loose mounting screws on the electrical buss internal to the inverter, which caused the voltage fluctuations. An identical problem had been previously discovered that prompted a change to the manufacturing procedures to include a specified torque for the mounting screws. The failed flight unit had been reworked, but the manufacturing procedural change had not been incorporated into the rework process.","Lesson ID":1}
{"Driving Event":"Simulated acoustic emission signals were induced in a thin-walled graphite\/epoxy tube by means of lead breaks (Hsu-Nielson Source). The tube is of similar material and layup to be used by NASA in fabricating the struts of space station freedom. The resulting waveforms were detected by broad band ultrasonic transducers and digitized. Measurements of the velocities of the extensional and flexural modes were made for propagation directions along the tube axis (0 degrees), around the tube circumference (90 degrees) and at an angle or 45 degrees. These velocities were found to be in agreement with classical plate theory.","Lesson ID":509}
{"Driving Event":"Turbine speed must be high enough at the time of main combustion chamber priming to be able to pump hydrogen through the downstream system against the back pressure rise created by the chamber priming, or an engine burnout will occur due to the oxygen rich combustion.","Lesson ID":967}
{"Driving Event":"Early in the definition of the Hinode instruments, interfaces were mandated to be in undesirable locations in the middle of a subsystem in the case of X-Ray Telescope (XRT). Phase A and Phase B are both critical times for a project. Decisions made during these phases of a project define the problems and risks that will be dealt with during the later phases. Lessons Learned need to be incorporated especially during this time. Finding information about difficulties encountered during Skylab in the case of the Narrowband Filter Imager (NFI) blocking filters and during Spacelab 2 in the case of the Tunable Filter (both in the Focal Plane Package) may have allowed the in-flight difficulties with these items to be avoided.","Lesson ID":2297}
{"Driving Event":"The Space Shuttle Main Engine (SSME) telemetry system does not show absolute Greenwich Mean Time (GMT), but rather, the number of controller cycles since change in mode. Approximate timing had been established (during the STS 51-L launch process) by aligning the first guidance cycle after engine start with the engine start command time determined by analysis of the General Purpose Computer (GPC) event times. This aligned the SSME event times to the GPC event times to within a few tens of milliseconds, sufficient for normal flight analysis but insufficient for determining event sequencing for a system failure, which involves an interaction between the SSME and the rest of the vehicle. Without precise correlation between multiple data systems, there may be a delay in subsequent anomaly investigations due to timing uncertainties or a need to correct data timing.","Lesson ID":209}
{"Driving Event":"During bleed down of the 125 psi air system, a process which lasts less than one minute, the noise level at the Pad B gaseous oxygen (GOX) vent arm air receiver outlet vent exceeds permissible OSHA noise exposure limits. A noise hazard survey conducted during the bleed down operation was performed on the air system to determine the noise level near the operator's ear. This survey recorded a noise level of 126.5 DBA. OSHA 1910.95, occupational noise exposure, limits noise exposure for fifteen minutes or less to 115 DBA. A possibility exists for personnel permanent hearing loss.","Lesson ID":138}
{"Driving Event":"Design issues included non-standard coordinate systems, different processing algorithms, and different data architectures. The team eventually resolved the timing interfaces and the end-to-end data flows, but the development of the attitude determination software took longer than expected.","Lesson ID":1593}
{"Driving Event":"While the Magellan Power Control Unit (PCU) underwent test following rework, an engineer was performing a test of the unit at a contractor facility after hours and without quality assurance (QA) assistance and adequate test procedures. During this continuity and resistance testing, test instrumentation applied reverse polarity voltage to electronic circuitry within the unit. This resulted in three blown fuses and potential damage to other electronic parts. After analysis, repair, and testing the PCU was reinstalled in the Magellan spacecraft at Kennedy Space Center, fortunately with no delay in launch operations. Additional Keyword(s): Subsystem Test Reference(s): Mars #B 16003","Lesson ID":287}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number OPS-04 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. This practice greatly reduces the possibility of a vent line fire and\/or explosion during H2 venting operations. It is impractical to supply the large quantities of GHe required to create a non-flammable H2 \/He mixture during H2 venting operations. The upper flammability limits of a gaseous H2\/air mixture is lower with no GHe present. This technique also provides substantial safety benefits. This technique recommends initiating a GHe sweep purge to evacuate air from a vent line prior to venting a H2 system. After the initial venting operation is complete, a second GHe sweep purge should be conducted to evacuate the vent system of residual H2. The upper flammability limits of a gaseous H2\/air mixture is lower with no GHe present (see Figure 1). A flapper valve or check valve used on the vent line will prevent air intrusion into the line during low or intermittent flow conditions. [D] This practice should be included in all new systems operating procedures and changes initiated to applicable existing procedures. System design should be reviewed to include the following as recommended by NASA TM X-52454 (Lewis Research Center): Include a check valve\/flapper valve or other suitable mechanism to exclude air from vent stacks at low or intermittent flow conditions. Extend vent stacks 15 ft. above a building roof. Discontinue use of ordinary hydrocarbon flame arresters which are incapable of quenching a H2 flame. Provide a minimum of a 3-volume exchange (pulse purges) to sweep system prior to introducing hydrogen. Five to 10 volume exchanges to purge a vent system is a commonly acceptable industry practice. Reference: H. Hannah, LSOC 32-30, FCSS Hazardous Commodity Purge Study, dated September 1991","Lesson ID":851}
{"Driving Event":"The flow meter leak check methods used to perform Quick Disconnect (QD) interface integrity verifications were found to be less that adequate to verify the acceptability of the hardware under test.","Lesson ID":4218}
{"Driving Event":"Several unplanned post-launch tests were run on a mission in the post-environmental test timeframe, which, in fact, uncovered several important problems, which needed correction.","Lesson ID":1268}
{"Driving Event":"Following EMC testing at the NASA\/Caltech Jet Propulsion Laboratory (JPL), spaceflight hardware was transported from JPL in Pasadena, California, to the Canadian Space Agency in Toronto, Canada, using a JPL-designated, third-party (independent) courier service. The hardware was an engineering qualification model (flight spare) of the Mast for the Meteorological Experiment (MET), an instrument aboard the Mars Phoenix spacecraft launched in August 2007. The MET Mast is a tubular structure mounting science instruments\/sensors that positions them above the Phoenix spacecraft after landing on Mars. Upon arrival of the package at its destination, the recipient discovered that all shock sensor pairs (20G, 30G, and 50G) mounted to the hardware were tripped, indicating that the hardware was subjected during shipment to shock loadings equivalent to at least 50G. In addition, at least one shock sensor cap was displaced and the shock sensor broken loose from its mounting (Figure 1), allowing the steel balls and springs to roll around inside the carrying case. Figure 1. MET Mast photographed in the shipping container following delivery. The shipped item was a bare mast without mounted science sensors. Reference (1) concluded that the shipping company did not handle the package to prevent excessive shock. The item was mounted to a rigid handling fixture (to which the shock sensors were mounted), which was enclosed in foam within an aluminum shipping container (similar to a golf club hard case), packed within a cardboard box that was badly damaged in transit. It was not skid-mounted for protection during transport and handling, and the tripping and detachment of the shock sensors strongly suggests that the package was not fastened in place during transport. Other JPL projects have experienced problems with unescorted transportation of flight hardware. Following this Phoenix incident, JPL flight projects instituted a practice of preparing a Critical Hardware Handling Plan (CHHP). This planning was initiated on the Phoenix project but was first formalized on the Mars Science Laboratory (MSL) project (Reference (2)). Reference (2) is applicable to the movement and storage of MSL Critical Items (MSLCI) at JPL, and to or from JPL and its suppliers during all phases of development, including pre-launch activities at Kennedy Space Center. The document provides very specific guidelines that apply when MSLCI is to be shipped by independent carrier services instead of being hand-carried to the destination. Reference (2) calls out the requirements of relevant JPL standards, specifications, and procedures governing critical item shipping, including References (3), (4), and (5). Also, the JPL Transportation Survey Form (Reference (2), Appendix A) was updated following this incident: it must be completed to assure that items of concern are addressed before MSLCI is shipped. References: quotShock Sensors Tripped During Transportation (50g),quot Problem\/Failure Report No. 3584, NASA\/Caltech Jet Propulsion Laboratory, January 10, 2006. quotMars Science Laboratory Critical Hardware Handling Plan,quot JPL Document No. D-34659, August 10, 2006. JPL Standard for Systems Safety (D-560), Rev D, JPL Document No. DocID 34880, Paragraph 4.2 quotTransportation and Handlingquot, September 17, 2007. JPL Engineering Specification 501492, quotSafety Requirements for Mechanical Support Equipment for JPL Critical Items Equipment, Rev G,quot JPL Document No. DocID 35412, Section 12.0: Shipping Containers, July 27, 2000. JPL Quality Assurance Procedure QAP 61.10, quotHandling, Movement, Storage, and Shipment of JPL Critical Hardware,quot JPL Document No. DocID 38112, October 4, 2007.","Lesson ID":1849}
{"Driving Event":"When the Galileo launch date was delayed from 1986 to 1989 with an increase in mission duration from four to eight years, the RPM design was re-evaluated. It was determined that a significant risk existed of in-flight loss of propulsion capability over the extended mission due to oxidizer flow decay. Flow decay is due to blockage of small oxidizer flow passages and filters by the accumulation of contamination products caused by interaction between the stainless steel lines and components with the nitrogen tetroxide oxidizer. Replacement of most of the stainless steel oxidizer feed system with titanium has alleviated the concern.","Lesson ID":305}
{"Driving Event":"The JPL Stardust project proved very successful in accomplishing its objective of returning a sample of cometary material. This was due in part to its innovative use of programmatic resource management techniques, and to its firm commitment to managing the work against cost-to-complete (in contrast to merely managing actual costs against planned). NASA budgetary constraints, and a mandate to accomplish more with fewer resources, led in the mid-1990s to a faster, better, cheaper (FBC) paradigm and competitive mission selections. Where NASA-funded spaceflight projects were previously requirement-driven and open-scope, successive JPL projects became severely cost and\/or schedule-constrained. With NASA demonstrating a resolve to cancel projects that fail to demonstrate budget and schedule discipline, managers of essentially fixed-price flight projects have been pressed to exercise tight budget and schedule control. Although there were some significant successes under this new paradigm, problems with balancing project resources and risk led to a number of mission failures (e.g., Mars Climate Orbiter, Mars Polar Lander, Wide-Field Infrared Explorer, Contour). Achieving this culture change for planetary exploration and space science required processes and procedures for implementing quotdesign-to-costquot and quotmanage-to-budget.quot Lessons from JPL flight projects initiated in the 1990s demonstrate that the flight project manager (PM) must maintain a buffer of reserves that will be sufficient to overcome the problems endemic to the latter stages of complex, high risk, system development. Consistent and rigorous reserve management is a preventative practice that assures that the project remains on track. In contrast, it is likely that a PM who spends too much too soon, or delays until no amount of reserves can salvage the project, will be unable to recover from adverse developments. Stardust may have been unique among these flight projects in completing development (Phase D) with the proposed reserve. Stardust project management practices and results may serve as a model for PMs who wish to understand (1) whether project reserves established by a proposal team competing under very tight cost constraints are sufficient, (2) how to develop a plan and criteria for release of reserve, and (3) how to integrate the releases with an earned value management (EVM) system (Reference (1)). Specifically, the Stardust experience provides guidance on how the PM may: 1. Determine the adequate reserves buffer, 2. Develop a plan for expending the reserve in the context of risk, 3. Integrate the reserve plan with EVM and scope, and 4. Control reserve on quotcost-to-goquot (i.e., cost to complete the baseline plan). The Stardust PM implemented a reserves management plan early in Phase B to (1) derive a set of affordable flight system capabilities that matched the prioritized requirements, (2) produce a risk-adjusted scope of work, and (3) generate a work plan based on earning value (Reference (2)). This established a planned cash flow inside the time boundaries to defeat known threats to mission success. Metrics were identified and criteria were pre-determined that would trigger the timely application of additional reserves to mitigating major risks (Figure 1). Planning the allocation of the reserve pool recognized that the risk scenario was only an estimate: some expected problems did not occur, while some expected and unexpected problems did. Implementing the plan in 10 key steps, Stardust: Figure 1. This Stardust performance assessment metric (PAM) plots the accomplishment of monthly earning events (baseline vs. actual) on the left ordinate as both raw counts and a ratio of actual to baseline. The curves (bottom plot) provide the cumulative picture of baseline (green \/long dashes) and critical path events (red\/alternate dash-dot), with the actual (blue\/solid bottom curve) accomplishment falling between. The middle (black\/dashed) curve projects moving the actual progress off the critical path and recapturing schedule slack. If the actual cannot be returned to the baseline within the target schedule completion, the project will fail the schedule and cost (time=$) success criteria. (That is, the schedule must slip, the baseline job cannot be completed as agreed, and cost will certainly increase, resulting in loss of control over the scope.) To avoid this and achieve the baseline (top curve) job, Stardust planned to have adequate schedule and budget reserve. Figure 2. Stardust used a Budget Change Log to translate the project reserve into hard liens (authorized to debit reserves) and from soft liens (not yet authorized to debit reserves). Legend: R\/R = risk reduction; C\/S = change in scope; O\/R = overrun Documented in an agreement (project plan or Mission Definition and Requirements Agreement) co-signed by the customer a clear and unequivocal definition of mission success. The definition included measurable success criteria so that the PM could later prioritize the commitment of reserves. Stardust established a quotperformance bufferquot by defining a three-level project scope hierarchy\u2014primary, secondary, and tertiary. The primary category represents the minimal success statements that make the project worthwhile. The secondary category houses baseline-scope criteria where the achievement of most of them is acceptable. The tertiary category, also in the baseline, contains those criteria that are important but would be the first to be de-scoped in response to unforeseen events. Reviewed the design capabilities against the requirements to determine whether modifications to the existing design (or design of new elements) may be needed to capture the full baseline, and whether such changes can be made within the targeted cost and schedule. A trade study was performed to assess reserves needed to accommodate the uncertainty and to force any necessary de-scope decisions. This resulted in a Stardust review called a Capability vs. Requirements Review (CRR) that assessed the ability of the project to design-to-cost. The initial Significant Risk List (SRL) was generated from the threats and probabilities identified at the CRR. Populated the Work Breakdown Structure (WBS), assessing and adjusting the constituent, low level task plans for risk and the estimated reserve required for each WBS item. The negotiated margins were weighted to reflect the probabilities identified at the CRR, and then summed to produce a risk-adjusted, justifiable, reserve pool. Loaded the integrated schedule network software to determine the critical path and any slack in the project. Added the schedule reserve at the end, protecting the quotschedulequot success criterion. Fully aligned and checked links, paths to deliverables, key events, etc. Next, Stardust loaded the financial software to apply current manpower cost rates, overheads, etc., to produce the time-phased baseline budget (costing plan) and the baseline Earned Value (EV) structure. They performed a quotGoldilocksquot validation to ensure they had a quotjust-rightquot number and spacing of earning events. (Not so few events that the project wouldn't know when it was in trouble, and not so many as to micromanage the activity.) The EVM system was set up early in the preliminary design phase (Phase B) and used to clarify and capture the baseline work plan and validate its consistency with the constrained cost and schedule. This preparation provided the control infrastructure for success in Phase C\/D. Using the results of Step 3, the SRL was updated to include the latest information on probabilities and mitigation options, and to assess the cost-to-mitigate for major risks. Rough-order-of-magnitude (ROM) estimates were prepared for incorporation as quotsoft liensquot into the Budget Change Log used in Step 7. A Budget Change Log (Figure 2) was implemented as the control discipline for release of reserves, ensuring that task plans, contracts, networks, and the EV system were updated expeditiously and were consistent. For JPL subcontracts, the incentive-fee structure and the events that were to earn fee (e.g., risk reduction, change in scope) were clearly designated. The reserve strategy was implemented, getting timely (days, not a week) information from the EVM system on the effectiveness of reserve expenditures in mitigating threats. Swept the project regularly for threats and opportunities to avoid trouble (i.e., to use reserves effectively on risk reductions, changes in scope, or overruns). Updated the SRL and Budget Change Log accordingly. Managed the unencumbered reserves against the cost-to-go. To maintain project control and assure that an acceptable product is delivered on time and within budget, it is essential to continuously monitor remaining costs to the conclusion of the project (cost-to-go). Stardust released reserves both proactively and reactively using the Percent Reserve on Cost-To-Go metric as a quotgovernor.quot Figure 3 provides an example of this index. Note that a 10 percent floor was set as a minimum reserve level, not to be broken until it became clear (e.g., late in development) that the project could be completed within this reserve for quotunknowns.quot A metric like Percent Reserve on Cost-To-Go provides a current picture of the reserve pool's strength against the cost to complete the baseline plan. Figure 3. An example trend in percent Stardust reserves against cost-to-go. This example depicts an initial growth in the percent reserves on cost-to-go, perhaps resulting from favorable early experience where some anticipated risk mitigations were not required. The February 1997 drop after reaching the 20 percent reserves level indicates the project either (1) decided to preemptively address some threats by releasing reserve to mitigate or retire them, or (2) discovered a set of risks that demanded action, such as realizing that a major task element was underbid in the baseline. This drop may prompt a recovery action, such as a de-scope, to increase the pool. The post-April 1997 growth in the index indicates that the project is not being aggressive enough in releasing reserve to mitigate threats, or that it is saving reserve to address an expected need. Absent this level of programmatic resource management discipline, it is not likely that Stardust could have completed development (Phase D) with the original project reserve. The CRR process demonstrated by the Stardust project has been adopted by the ongoing Juno flight project, and the 1996-1999 Stardust approach to managing the work against cost-to-complete is being incorporated into JPL's emerging strategy for cost effective implementation of cost-capped flight projects performed in-house. References: 1. quotEarned Value Management System Description,quot JPL Document No. DocID 67032, November 3, 2006. 2. Kenneth L. Atkins et al, quotStardust: Implementing a New Manage-to-Budget Paradigm,quot Proceedings of the Fourth IAA Conference on Low Cost Spacecraft, Johns-Hopkins University, May 2-5, 2000, also recorded in Acta Astronautica 52 (2003) pp. 87-97, available on-line at http:\/\/www.sciencedirect.com 3. Kenneth L. Atkins, quotHow to Plan and Manage Reserves Effectively,quot IEEE paper #1292, 2004 IEEE Aerospace Conference, March 8-12, 2004, Big Sky, MT. 4. quotNext Generation Launch Technology (NGLT): Clearly Establish Reserves, Schedule Margin, and Spending Profile Early,quot NASA Lesson Learned No. 1527, NASA Engineering Network, July 1, 2004.","Lesson ID":1780}
{"Driving Event":"The Project had several Government partners and each had a their own rules of engagement with regard to agreements and sharing of responsibilities. While some of these differences were cultural, many were driven by higher-level requirements such as treaties and other international agreements. The Project's unfamiliarity with these differences lead to difficult negotiations and un-necessary uncertainty in several of the Project's data requirements.","Lesson ID":1094}
{"Driving Event":"The SRM segments are transported horizontally by standard 200-ton capacity railcars with hydraulic couplers. It was determined that the transportation design requirements for the transportation support equipment exceeded the capabilities of the railcars. There is concern for potential changes to the cases resulting from transportation in the horizontal position. As part of the case joint redesign effort, studies are being conducted to determine the effect of horizontal transportation on case ovality and, in turn, the effect of ovality on the assembly process.","Lesson ID":183}
{"Driving Event":"On June 4, 1990, in High Bay 1 of the Orbiter Processing Facility (OPF) at the Kennedy Space Center (KSC), the aft bridge of the Payload Bay Bridge and Hoist System was moved approximately 78 inches aft of its set position for Payload Bay Door (PLBD) operations. The right-hand PLBD Zero-G System was configured to support a scheduled PLBD closing operation on first shift, June 4, 1990, except the Zero-G weight baskets were left pinned to their weight cages. The right Payload Bay Door (PLBD) was supported by the Zero-G cabling (not pinned to the platform). Movement of the bridge put the Zero-G cabling into tension and at an angle sufficient to shear a portion of the weight basket pulley \"V,\" fray the Zero-G cabling, move the weight basket off its track, and deflect the C-hook approximately 2 to 3 inches. Since the weight basket was pinned, the aft movement of the bridge also caused the right PLBD aft portion to rise approximately 31 to 33 inches (calculated).","Lesson ID":1200}
{"Driving Event":"The X-31 is an inherently unstable experimental aircraft. Its dynamic stability is dependent on air data from the Pitot-static system. Unexpected icing of the single-string unheated Pitot-static air data source resulted in the aircraft departing controlled flight and crashing. X-31 Experimental Aircraft","Lesson ID":360}
{"Driving Event":"The effects of an adverse environmental condition, specifically, unusually cold weather, are not sufficiently well understood. The amount of ice formed by leaving valves open to prevent freezing inside water pipes was greater than expected. After the STS 51-L launch, photographic documentation revealed that ice released from the pad structures after engine ignition translated further toward the vehicle than predicted. The performance of some complex 39B systems was marginal due to the cold. The number of cameras that failed to operate at liftoff was three times that of the historical average. Instrumentation and analytical models were not adequate to define the unusually cold operating environment in which the launch was conducted. Additionally, the effects of such temperatures on the components of a space shuttle standing on the pad have not been sufficiently determined.","Lesson ID":198}
{"Driving Event":"On 1-15-91 a failure occurred in the 8' Transonic pressure tunnel during testing of a model wing with attached flap. During the test run, the flap peeled away from the wing, broke free, and proceeded down the tunnel. Extensive damage resulted. It is hypothesized that reuse of screws having repeated applications of a thread-locking compound caused the east most flap bracket screws to either lose or never obtain proper preload. Under test conditions the screws loosened, then the east most flap bracket was lost, load was shifted to the flap fitting, the flap fitting sheared, and failure occurred. Of special significance is the fact that a thread-locking compound is always used on the screws that attach the flap brackets to the wing. These screws were reused for all tests and no special effort was made to clean them. The flap bracket screws had received an application of a thread-locking compound approximately thirty minutes prior to final installation in the wing, resulting in dried, but undisturbed, thread-locking compound on the screw threads. Further, an additional coating of a thread-locking compound was applied to the flap bracket screw threads just prior to their actual installation. Torque values shown on drawings were given for a preload of 50% or proof load based on dry threads. It is impossible to predict the actual torque on the bracket under the conditions indicated. The thread-locking compound corporation has provided conflicting information. One individual stated that screws should not be reused after having a thread-locking compound applied; further, a tap should be run into the female threads to clean them prior to a new screw being installed. Other representatives said they had no information about reusing screws. To achieve prescribed torque values, however, prudence would seem to dictate a more conservative approach to the use of a thread-locking compound as well as to the cleaning of threads.","Lesson ID":524}
{"Driving Event":"On September 11, 2003, at approximately 2:16 PM, the steam line on the Large Altitude Simulation System (LASS) suffered a catastrophic failure of the 24-inch expansion loop located adjacent to the Test Stand 401 steam ejector exhaust duct. The LASS was being operated to verify its readiness to support an altitude firing of the 4th stage of a Minuteman ICBM scheduled for September 25, 2003. The failure occurred approximately 16 seconds after the LASS was commanded to go to full steam, and resulted in a rupture of a portion of the line that dislocated several pieces of the 24-inch pipe in various directions away from the test stand. The proximate cause of the event was pipe wall corrosion that led to selective thinning of the wall, which resulted in the pipe rupture under pressure. The following observations came from the investigation: During the mishap investigation, evidence of rust scale deposits around steam line drains (or \u201cexhaust ducts\u201d) was observed. This is an indicator that internal corrosion and erosion is taking place in the system. External corrosion products on the pipes were also observed, especially where external insulation trapped water from environmental sources. In piping subject to corrosion, it is difficult to determine the location of old pipe wall thinning in complex installations without 100% surveying. At the same time, Non-Destructive Evaluation techniques for determining steam pipe wall thickness were found to be inconclusive due to the detritus from internal corrosion remaining in place primarily on the inside of pipe walls. In this particular case, an alternative method to assess system integrity - hydrostatic pressure testing of old or modified fluid handling lines - was not an effective means of verification of long-term pressure integrity.","Lesson ID":1391}
{"Driving Event":"As part of the development of requirements for the Constellation Program, methods were also developed to verify that those requirements were met. Verification methods were assigned early in the project life cycle; and for the most part, they were determined by teams or individuals who were not part of the design or implementation team. Later, when these methods were addressed by the engineers responsible for implementing the subsystem design, those engineers preferred different methods or found the ones originally assigned to be impractical.","Lesson ID":5203}
{"Driving Event":"One of the most important elements for the further improvement of the performance of the magneto-optic imaging instrument is to quantify the contribution of each different mechanism to the obtained image. More experiments were recently performed using a single-layer thick pancake pickup coil so that the distribution of flaw-induced normal magnetic field component may be measured between the test object and the current sheet, as well as at locations above the current sheet. The test used magnetic current sheet, which has very strong skin depth attenuation. As expected, a distribution of strong magnetic fields exists in between the two conducting sheets; no measurable field strength exists above the magnetic current sheet. Further experiments are being conducted with the new pickup coil to establish a firm theoretical base.","Lesson ID":526}
{"Driving Event":"The rotator is part of a lifting fixture used during OMS pod installation or removal. The 73D010016-1003 OMS pod rotator was bent on three occasions: In 1991, the rotator was overdriven against the Orbiter deck, causing the screw shaft to bend. In 1992, the rotator was overdriven against the hydraset, causing the screw shaft to bend. In 2004, the lifting-fixture jack screws were overdriven against the rotator, causing the screw shaft to bend.","Lesson ID":3116}
{"Driving Event":"The SEASAT Spacecraft failed in orbit due to a massive and progressive short in the slip ring assembly connecting the rotating solar array to the power subsystem. The most probable cause of this short was the initiation of an arc between adjacent slip ring brush assemblies. The slip ring assembly was connected into the power system such that the adjacent brush assemblies were of opposite polarity, an arrangement particularly prone to shorting. The SEASAT prime contractor was aware of instances of slip ring failures due to shorting on other projects, but did not communicate this information to the SEASAT project office. This lack of communication may have been the result of the classified nature of the other projects. The failure to give the slip ring assembly the attention it deserved was rooted in the contract structure and the SEASAT implementation policy. SEASAT was a dual contract; a fixed price for the Agena bus containing flight proven subsystems and a cost-plus award fee for the payload module which was integrated with the Agena bus. By contract, implementation plan, and resource constraints, JPL had no significant oversight of the Agena bus. The failure review board established that the Agena power, attitude control, and data subsystems were substantially modified, but were treated as closely similar designs not requiring requalification. This consideration of the Agena bus as flight-proven standard equipment led to the failure to report significant component failures, waiving tests and weak compliance with specifications. In addition, the Failure Mode Effects and Criticality Analysis (FMECA) conducted on the power system did not consider shorts as a potential failure mode. Additional Keyword(s): Inherited Equipment, Slip Rings","Lesson ID":371}
{"Driving Event":"During testing of a electrical power generating device known as a \"fuel cell\" it was discovered that the electronic dynamic load bank went into oscillations and became very unstable when an attempt was made to utilize it as a \"load\" for the fuel cell. During post test evaluation it was discovered that when these load banks are long coupled to the power supply their performance is erratic. When short coupled they perform as programmed. The question becomes at what length coupling does the problem occur. Presently evaluations were only made at three lengths: five (5) feet, twenty (20) feet, and forty feet per lead. At five feet no problems were noted, at twenty feet and forty feet the load bank was unstable. Research of available literature concerning this load bank does not reveal this problem. Consultations with the manufacturer indicated they were aware of some problems associated with small dynamic load banks using long coupling leads and that this is a characteristic of this type of load bank (small electronic dynamic load banks). This instability has been observed in small electronic dynamic load banks; larger dynamic load banks do not seem to exhibit this phenomenon, and resistive load banks are not prone to this phenomenon. The correlation of this phenomenon to the couping length is still under investigation. A Government-Industry Data Exchange Program (GIDEP) alert has been recommended.","Lesson ID":581}
{"Driving Event":"This Lessons Learned is based on Reliability Practice No. PD-ED-1208; from NASA Technical Memorandum 4322A, NASA Reliability Preferred Practices for Design and Test. Benefit: Leak-free joints can be achieved in cryogenic lines, joints, valves, and pumps for launch vehicles through the use of proven, state-of-the-art static cryogenic seals. These seals adapt to wide ranges of temperature and continue to seal when subjected to high pressures, in-flight static stresses, and in-flight dynamic loads. Implementation Method: 1. Introduction: Low or zero fluid or gas leakage in flight and ground-based cryogenic systems can be achieved through meticulous joint design and testing, selection of the proper seal configuration and materials, thorough cleaning and inspection of seal and flange surfaces, carefully controlled installation, and carefully controlled fastener tightening procedures. The most widely used and successful cryogenic seal for NASA space flight applications has been the deflection actuated, pressure assisted coated metal seal. High nickel content steel alloys coated with a thin layer of Teflon\u00ae or plated with gold, silver, indium, palladium, lead, copper, nickel, or aluminum have provided good sealing properties at elevated as well as cryogenic temperatures. This practice covers experience with pressure assisted and spring energized cryogenic seals in the SSME and ET. Experience was derived from earlier programs (Saturn I and Saturn V) to develop these effective seals. Although the subject of this practice is cryogenic seals, the pressure assisted and spring energized seals described are also effective over the broad temperature ranges from liquid hydrogen (-423 deg.F) to hot gas (1000\/1200 deg.F). 2. Nonspacer Type, Deflection Activated, Pressure Assisted Seals [D] The nonspacer type seal shown in Figure 1, fits into a groove in the flange. It can be used with a separate spacer to eliminate the need for a seal groove, but a retaining groove is preferred. As shown in Figure 1, these seals have two sealing surfaces that mate with adjoining flanges. Diameters range from 0.55quot to 16.75quot as used in the SSME. Cross sections of the seal ring vary from 0.200quot x 0.164quot to 0.150quot x 0.120quot in radial width and installed length, respectively, and the seals can be made in other diameters and other cross-sectional configurations. They are found throughout the SSME in both cryogenic and hot gas applications. The seals are machined from high nickel alloy steel and coated with either silver or silver with rhodium overcoat. The silver coated seals have a temperature range of -423 deg.F to +1000 deg.F, while the silver with rhodium can be used over a -423 deg.F to +1200 deg.F range. The seals are used in both fuel and oxidizer systems. In installing both the nonspacer type and the spacer type seals, the seals are compressed during joint assembly, which provides a load at the sealing circumference to effect sealing at low pressures. As the pressure increases, it acts on the internal surfaces of the seal, increasing the force on the seal tips to augment sealing capability as pressure increases. The seal coating presses into the flange surfaces, filling microscopic asperities and irregularities in the flange sealing surfaces. The combination of the installation deflection and the pressure on the internal surfaces permits the sealing faces to compensate for joint separation under system pressure and for shrinkage during exposure to cryogenic temperatures. 3. Spacer Type, Deflection Activated, Pressure Assisted Seals [D] This type of seal was originally used on the Saturn program and was later adapted for use on the Space Shuttle. The seal incorporates a flange, drilled to match the mating parts, which provides a positive stop to control seal compression and secondary pressure barriers on each side of the seal to facilitate leak checking. While some seals were originally silver plated, present use is confined to Teflon\u00ae coated high nickel alloy steel seals. The seals are used on the ET and on the piping connecting the Tank to the Orbiter. Most have rated temperatures of -423 deg.F to +350 deg.F except for one which has a -423 deg.F to +800 deg.F rating. A typical seal installation as it is used on the ET is shown on Figure 2. Notice that the seal has both a dual-sided primary seal located at the interior periphery of the seal and a dual-sided secondary pressure barrier just inside the bolt circle. A Teflon\u00ae coated seal is used in the LH2 and GH2 systems while a silver plated seal is used in the LO2 and GO2 systems. 4. The Raco\u00ae\/CreaveyTM Seal Configuration [D] Figure 3 shows the combination Raco\u00ae\/CreaveyTM seal as used for 17-inch diameter feed lines on the ET. The primary Raco\u00ae seal consists of a metal hoop-spring inside an energized Teflon\u00ae jacket. The secondary CreaveyTM seal is a metallic coil spring housed within an energized tubular Teflon\u00ae casing. 5. Recommended Practices a. Design Practices In general design practice, the development of a good leak-free joint design requires an integral look at the design of all the parts: seal(s), flanges, and fasteners. It also requires some foreknowledge of the degree of access required for leak checking, inspection, and potential disassembly and reassembly during downstream operations and particularly on the launch pad. Leak-free joint design is based on the seal maintaining contact between a surface on one flange and the mating surface on the other flange under all operating conditions. The fasteners take the dynamic loads and are installed in a preloaded condition to maintain seal contact with the flange surfaces. The seal in the joint must prevent leakage in excess of the allowable limit. The advantages of deflection actuated, pressure assisted seals are that they maintain a nearly constant fastener loading under pressurized and nonpressurized conditions and that they result in minimum flange deflection at the sealing surface. Sealing surfaces on flanges can be recessed to protect them from damage, and seal grooves can be configured for easy seal installation, centering of the seal, and for error-free assembly. The seal and joint can be designed with detents to prevent misaligned or reverse installation. The design of joint assembly and seal installation tooling, equipment, fixtures, and procedures should proceed concurrent with joint design. The designer must remember that a separable joint is used to permit later disassembly, inspection, and reinsertion of seals or refurbishment\/replacement of systems or components either in the manufacturing shop, on the test stand, or on the launch pad. The joint design and the assembly tooling or fixtures should provide: (1) protection to the seal and mating surface; (2) concentric and accurate seal positioning; and (3) even pressures around the periphery of the seal and joint during the fastener tightening process. Circumferential indexing that will ensure relocation of impressed seal surface deformities over corresponding flange deformities is desirable if the seal is to be reused. A good design practice is not to depend entirely on flange bolt locations to position seal components radially. A notch or groove should be provided to retain the seal. Gaskets, seals, parts, and subassemblies should be designed to preclude improper alignment or rotation. Using seals very close to the same size in the same area should be avoided. The design should be adaptable to using the same size seal (or a very different size) in all locations which are in close proximity. This practice will reduce the potential of installing the incorrect size seal. The following design suggestions pertain to seals for cryogenic and gaseous hydrogen and oxygen: Where feasible, secondary seals with a vent for direct measurement of leakage should be provided. The materials in cryogenic\/gaseous hydrogen seals should be resistant to hydrogen embrittlement. Walls should be provided in the seal groove to carry the seal hoop load when pressurized. Designs of liquid oxygen seals should include LO2 compatible materials. Designs of liquid hydrogen seals should include LH2 compatible materials. Potential flange ovality resulting from flange stresses or temperature cycling must be taken into account in establishing the width of flange sealing surfaces. The seal material(s) must be compatible with any anticipated purge or cleaning material that may contact the seal during its intended use. Purge or cleaning material restrictions should be noted on engineering drawings and in procedural documentation. A seal alignment provision should be incorporated in the design process. Design optimization in metal seals for cryogenics can be accomplished with currently available general purpose finite element analysis programs such as ANSYS (produced by Swanson Analysis Systems, Inc., see reference #13) or by specially programmed finite element models (reference #14). Modeling of seals can take into account surface texture, gas transmission flow methods, seal load distribution, material properties, and dynamic environmental conditions (temperature, pressure, vibration, shock, etc.). New seal designs should be evaluated using these analysis and modeling techniques and qualified before use. (see below). b. Qualification Practices Prior to incorporation into the production design, the entire joint system, which includes the flanges, seal(s), and fasteners, should be qualified for use in the specific environments expected to be encountered in operations. [As part of the qualification procedures for SSME seals, seals of 0.8quot, 1.1quot, and 3.8quot diameter were chilled to -250 deg.F and pressure cycled from ambient pressure to 8,970 psig for 240 cycles while demonstrating their ability to continue to meet leakage requirements. Seals were also subjected to structural verification at pressures up to twice operating pressures after completion of 240 pressure cycles, while still meeting leakage requirements.] If different temperatures, pressures, or gases are used for qualification and\/or leak checking, leak and nonleak conditions must be carefully calibrated and correlated with leak and nonleak conditions in the actual environments expected. These calibrations must be meticulously adhered to in interpreting leak test results. c. Manufacturing Practices Cleanliness and inspection at intermediate manufacturing steps are extremely important in the manufacture of deflection actuated pressure assisted seals as well as for other types of seals used in liquid oxygen and liquid hydrogen environments. Nonspacer type seals are usually silver plated with an initial gold undercoat. The gold undercoat prevents oxidation of the substrate at temperatures above 600 deg.F, when used in hot gas environments, and this prevents blistering of the silver plating. Silver is used for its low compressive yield strength and ductility required for effecting a seal, and for its corrosion resistance. Rhodium overplate is used to prevent bonding of the silver plate to the mating flange surfaces at high temperatures. A chromate coating is used to prevent discoloration of the seal or flange due to tarnishing of the seal's silver plating. Care must be taken to thoroughly clean and inspect each seal between the plating and coating operations. Adherence of the Teflon\u00ae primer coat and subsequent final coat to spacer type seals also requires stringent cleaning and inspection between each operation to prevent inclusions, voids, contamination, and surface defects. d. Inspection Practices Seal and flange mating surfaces should be visually inspected after manufacture and immediately before installation with a 10X magnification device. Very tiny scratches across the face of the seal's coated or plated sealing surface can cause leaks. [In one instance, a scratch .001quot wide and .0005quot deep extending across the radial length of the sealing surface was of sufficient size to cause a Class I leak.] The inspector should look carefully not only for nicks and scratches in seals, but also for metal or foreign particles on the seal or on the mating flange surfaces. NASA problem reports have indicated that, in at least one incidence, metal flange faces were allowed to contact each other and to rub together prior to seal installation, causing fine metal particles to be created which interfered with the seal's ability to seat properly against the flange sealing surface. Optical microscopy up to a power of 50X has been used to detect very small flaws and irregularities in flange and seal surfaces when leakage tests failed. Seal flatness or waviness can be confirmed or detected by the glass test in which the seal is placed against a plate glass sheet and observed from the underside. This method can be used to detect potential nonparallelism or small deviations in seal contact or coating thickness. Precision flat bars can be used with a light source to verify that flange faces are flat. e. Protection Practices Many of the leaks detected from joints of cryogenic and gaseous lines were possibly caused by scratching or nicking of the flange sealing surfaces or the seal, after initial manufacturing and inspection, but before assembly. Post manufacturing, in-transit, and preassembly protection of both the seals and the joint sealing surfaces have proven to be essential in ensuring leak-free or acceptable leakage rate joints. LO2-compatible protection caps or plugs should be used to protect sealing surfaces between manufacturing inspection and final assembly. Liquid oxygen compatibility is required of materials protecting oxidizer system joints because small particles of the protection material can rub off against the seal or flange surface and could lead to a fire or explosion. Cleanliness is more easily maintained with proper protection while the joint is in a disassembled condition. f. Preparation Practices As with in-transit or in-storage protection, thorough cleaning of the seals and flanges, accompanied by preinstallation inspection, is required to ensure leak tight joints. If the flanges are to be in storage for an extended period, they require a protective grease or jelly. If so, this material must be removed and the flange cleaned and reinspected prior to assembly, as this substance may have picked up fine particles during storage. If a protective substance has not been used, thorough visual inspection must take place to ensure that there are no evidences of corrosion. If corrosion exists, it must be removed and the flanges or seals reinspected both dimensionally and visually. g. Installation and Assembly Practices Several of the unacceptable leaks of joints carrying cryogenic fluids reported in NASA's Problem Reporting and Corrective Action (PRACA) system resulted from scratches to the seal or flange faces during the assembly process after preassembly inspection. These scratches may have been caused by the flanges rubbing together or the seal rubbing against corners or edges of the flanges. Several methods have been proposed or implemented to reduce the potential of seal or joint sealing surface damage during assembly. One method is to place Teflon\u00ae shims on both sides of the seal while it is being inserted into place between the flanges, and then to remove the shims once the seal is in place. Procedures have been developed which would not allow the flanges to touch the seal until the bolt torque pulls the flanges together. Special seal retaining or insertion tools and other assembly equipment can be designed to minimize the potential of damage during assembly. Operators must be thoroughly trained and certified in these procedures. To provide uniform compression of the seal and a final uniform load around the seal's circumference, fasteners should be tightened in stages in a prescribed alternating fashion, starting with fasteners located 180 degrees apart. h. Leak Checking Methods The most common method of seal and joint inspection after assembly is the leak test. Several leak detection procedures are used to check the integrity of LH2, GH2, LO2 and GO2 joints and seals: (1) bubble method; (2) gas analysis method; (3) pressure decay method; and (4) flow meter method. The most prominent method of leak testing is the bubble method. In the bubble test, a leak test solution is applied to the periphery of the joint while the interior is being pressurized with liquid helium gas or nitrogen in a manner that has been calibrated against the operational fluid's temperature, pressure, and flow rate to provide acceptable or nonacceptable leak rates. The bubble test method is confined to gaseous systems or cold gas simulations of cryogenic joint pressures and temperatures. Four classes of leakage have been defined. In general, they are: Class I: Steady formation of very small, long persisting bubbles. Class II: Mixture of random size bubbles of moderate persistence. Class III: Large, fast-forming bubbles. Blowing: Bubble formation does not take place because of large gas flow. Another common method of leak detection is the gas analysis method using a mass spectrometer. Although this method will determine that a leak exists, it is difficult to measure or to calculate the leak rate from mass spectrometer test results. Advanced methods of leak detection using palladium sensors, colorimetric methods, and nonintrusive sensors are being studied, but none has yet been as successful in both detecting the leak and indicating its magnitude as the leak test solution method. The solution test method is simple, easy to use, and readily observable with the naked eye. Two precautions are important, however: (1) complete coverage of the joint with the leak test solution; and (2) close observation of the complete periphery of the joint. The technician should observe the leak test solution immediately after application so that a blowing leak is not missed. The general practice is to releak test whenever a joint is disturbed. In the case of the SSME, all joints are leak tested both before and after final hot firing acceptance. A total engine leak test is conducted at final acceptance to determine the total leakage from all 154 joints (80 oxidizer system joints, 44 fuel system joints, and 30 hot gas joints), which must be less than six standard cubic inches per minute. In general, ambient temperature leak checks are not as accurate as testing in the chilled condition. Therefore, at least in initial development and checkout, the system must be cooled to its operating temperature, and realistic pressures and flow rates must be provided to identify potential leak conditions. The alternative is to use a different cryogenic or gas with prior accurate calibration of leakage results with the operational fluids, as mentioned earlier. i. Storage Practices Joints, flanges, or seals in storage must be protected against corrosion and against inadvertent damage of the seal or sealing surfaces. The protection device or substance must be compatible with the fluid for which the joint was designed and with which it will be operated. In-storage protection devices or substances must be completely removed and the parts must be recleaned and inspected prior to assembly. j. Refurbishment and Reuse Practices Seals can be refurbished by replating and reinspecting them to the original manufacturing standards. Seals that are reused without refurbishment should be indexed to provide reassembly in the same position as originally installed. Seals with damaged coating can be stripped and recoated or replated as long as the parent metal seal is dimensionally correct. Technical Rationale: These practices were derived from a review of Unsatisfactory Condition Reports (UCRs) of the PRACA system at Marshall Space Flight Center; from sources listed in the references including professional journal articles, presentations, books on cryogenics, and Government reports; and from over 30 years of experience in designing propulsion systems and stages incorporating cryogenic sealing requirements. References: Allen, P. and H. Becker, quotSealing for Long-Term Space Applicationquot, 3rd Annual AIAA\/GNOS Aerospace Technology Symposium, November 7-8, 1985. American Institute of Aeronautics & Astronautics. Brincka, D. R., quotHigh Pressure Static Seals for Aerospace Applicationsquot, 36th International Astronautical Congress: Stockholm, Sweden, October 7-12, 1985. IAF. Burr, M. E., quotDevelopment of Large Diameter High Pressure, Cryogenic Radial Static Sealsquot, Lubrication Engineering, (December, 1977), 638-643. quotCritical Items List (CIL) MC-ET-RA04b-Hquot, Volume II Propulsion\/Mechanical, Huntsville: NASA, MSFC, May 1, 1991. Daniels, C. M., quotAerospace Cryogenic Static Sealsquot, Lubrication Engineering, (April 1973), 157-167. Daniels, C. M., quotDevelopment of Flightweight Static Face Seals for 75.84 MPa (11,000 psi) Pressure and Cryogenic Temperaturesquot, Lubrication Engineering, (October 1978), 552-562. quotDucts\/Lines, Joints and Orificesquot, Volume XI. Failure Mode and Effect Analysis (RSS-8553-11) Critical Items List (RSS-8740-11): January, 1991. Rockwell International, Rocketdyne Division. quotFailure Modes and Effects Analysis (FMEA) MMC-ET-RA04a-Kquot, Volume II Propulsion\/Mechanical, Huntsville: NASA, MSFC, May 1, 1991. Hunter, Rick C. and Ready J. Johnson, quotGas Transmission Through a Plastically Deformed Metallic Interfacequot, Energy Sources Technology Conference and Exhibition: Houston, January 22-25, 1989. American Society of Mechanical Engineers. Russell, Dr. John M., quotOn the Selection of Materials for Cryogenic Seals and the Testing of Their Performancequot, 1989 NASA\/ASEE Summer Faculty Fellowship Program, August 18, 1989. John F. Kennedy Space Center and University of Central Florida. Schwinghamer, quotLeak Team's Final `Eureka' Anthem,quot Hydrogen Leak Investigation Team Final Report, (Presentation) Huntsville: NASA, MSFC, November 8, 1990. CreaveyTM is a registered trademark of the Creavey Seal Company. Raco\u00ae is a registered trademark of the Furon Company. Teflon\u00ae is a registered trademark of E.I. DuPont de Nemours & Co. Inc. Definitions cryogenics. Temperature region of liquified gases below 123 deg.K (-150 deg.C). ET. External tank. GH2. Gaseous hydrogen. GO2. Gaseous oxygen. high nickel alloy steel. A heat-treatable, nickel-base (53 percent) steel alloy with good properties at both cryogenic and elevated 922 deg.K (1200 deg.F) temperatures. leak. Defined in text. LH2. Liquid hydrogen. LO2. Liquid oxygen. scim. Standard (atmospheric) cubic inches per minute; volumetric flow rate. scratch, nick, or gouge. A damaged area in which material has been removed, or moved, with a resultant decrease in wall thickness. SSME. Space Shuttle Main Engine. static seal. A device used to prevent leakage of a fluid through a mechanical joint in which there is no relative motion of the mating surfaces other than that induced by changes in the operating environment.","Lesson ID":701}
{"Driving Event":"During the launch of the Pegasus\/SCD 1 on February 9, 1993, an incident occurred in the final minute of the countdown where an abort was initiated by the Wallops Flight Facility (WFF) Range Safety Officer (RSO); however, the operation continued with the launch of the Pegasus vehicle. At T minus 0:59, the WFF\/RSO initiated an abort due to an apparent momentary dropout of the Command Destruct Receiver (CDR). The abort call was picked up by the WFF Test Director (TD), who immediately enunciated the abort, at T minus 0:56 and T minus 0:47. The countdown clock was stopped at T minus 0:52 seconds and was not restarted until Pegasus release at T minus 0:00. A contractor Test Conductor (TC) announced the abort at T minus 0:44, and the abort was passed by NASA 1 to the B-52 at approximately T minus 0:34. The B-52 crew replied that the fin batteries were on and that they understood the abort. Following this discussion, the contractor TC rescinded the abort call, and NASA 1 passed the negative on the abort to the B-52 at T minus 0:22. The Pegasus vehicle was then dropped from the B-52 near T minus 0:00 time. Key WFF personnel in the Range Control Center (RCC) were not expecting the drop due to the abort call. However, the drop was observed on video, the alert was sounded that Pegasus had been launched, and all supporting personnel and stations responded immediately. Their timely response allowed the successful completion of this mission. At no time during the flight was the ability to destruct the Pegasus jeopardized.","Lesson ID":1090}
{"Driving Event":"A pilot effort was conducted on the CxP Extravehicular Activity (EVA) Project as part of the Agency\u2019s Earned Value Management Capability Project. This pilot effort drove the identification of the issue regarding inconsistent WBS element nomenclature.","Lesson ID":5862}
{"Driving Event":"Orbiter Avionics Modifications","Lesson ID":1002}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) A commercial data scanner using a bank of reed relays failed during thermal-vacuum testing of the SEASAT-A Synthetic Aperture Radar (SAR) Transmitter subassembly. Transmitter circuits requiring +5 volts were exposed to as high as 31 volts during each scan, resulting in catastrophic failure in the +5 volt circuits of the Transmitter. This problem caused about a two-week slip in the overall schedule, including the loss of 3 days of a one-week thermal-vacuum test and three days to repair the Transmitter. The nature of this problem could have caused the failure to occur anytime the sensor was operated with the ground support equipment as it was configured. The Transmitter GSE was configured with 15 separate regulated power supplies of various voltages. To allow automatic data acquisition of power supply voltage and current readings during the test, a data scanner driven by a computing calculator was implemented. This scanner consists of a bank of reed relays sequentially addressed by the calculator to acquire each power supply terminal voltage. Each power supply terminal was connected to a scanner reed relay switch terminal. The other side of the switches were then tied together to the bus, similar to a multiplexer arrangement. In the thermal-vacuum test, one of the reed relays failed to open. As a result, each succeeding power supply terminal that was scanned became electrically tied to the one connected to the relay that failed to open. The failed relay was connected to +5 volt supply. The other supply voltages ranged up to +31 volts. The JPL calibration Lab uses this type of data scanner at the present time. Additional Keyword(s): GSE Interface FMECA Reference(s): SEASAT SAR P\/FR 4891","Lesson ID":435}
{"Driving Event":"The SSME vertical installer is used to position the engine for installation and removal. Failure of this equipment to maintain positive control could lead to unexpected movement. During visual inspection of the air piston and bore of the vertical installer, it was discovered that the air piston had a scored landring. This condition occurs when the piston sticks in the cylinder (due to lack of lubrication and\/or foreign material in the cylinder). Pressure then builds up until the piston breaks free. When the piston breaks free it can travel to the stops with enough momentum to cause sudden uncontrolled movement of the engine.","Lesson ID":113}
{"Driving Event":"An electrician suffered burns from an electrical arc\/blast when a pre-existing condition in a power distribution panel ultimately led to a ground fault in a 3-phase 480-volt power supply. The pre-existing condition was believed to be an access panel fastener that had penetrated conductor insulation. The response of local emergency resources to the mishap was exemplary, but would have been delayed if the injured worker had not just done his own safety task analysis just before the mishap. The safety task analysis included among other things locating fire alarm pull boxes and extinguishers; who to call in case of an emergency; what hazards were in place in the work area; etc. This safety task analysis is routinely performed before each task to ensure that risks are minimized prior to start of work. Because the worker pulled the alarm box within ten seconds after being injured, emergency response teams responded and were at the scene within 3 minutes of the event. Response was initiated before detectors triggered alarms at the Emergency Operations Center and the fire station. The employee was already showing signs of shock upon arrival of fire protection specialists who administered first aid until the paramedics arrived a couple minutes later. The patient was transported to a downtown hospital\u00bfs burn unit and arrived within 40 minutes of the emergency. At the same time first aid was being administered, additional fire protection specialists began to fight the small fire in the building. The fire was extinguished immediately with a dry chemical extinguisher and before the fire suppression system was triggered. Damage\/loss of mission-critical equipment and facilities was averted. The reported community standard for emergency response is for resources to arrive at the scene within 30 minutes of notification. Without a working fire suppression system in place, total building involvement would have occurred. The presence of onsite resources plus the pre-established response by the employee reduced response time to 3 minutes. Because everything was in place \u00bf employee response, systems in place, and resources ready - the injured employee was stabilized rapidly and the damage incurred was restricted to the failed equipment.","Lesson ID":1721}
{"Driving Event":"The PCT is designed to operate between\/within space shuttle payload processing facilities. Two transporters are used to carry the payload canisters and hardware throughout kennedy space center. Drive power is provided by a 400-horsepower diesel engine. A ground reel clip is used during fuel transfer operations to establish a common ground between the diesel supply tank and the vehicle to be filled. Fueling operations are prohibited during electrical storms within five miles of the transfer site. Flame or spark producing devices, such as matches, lighters, or smoking, are also prohibited in this area.","Lesson ID":136}
{"Driving Event":"Flight scripts are modules of software code used to automate many flight software development and test processes that were previously done manually and repetitively. Because flight scripts are considered to be \"development support\" software (Class D), they are not placed under configuration management (CM) control as early as mission software classified as Class C (Mission Support) or Class B (Mission-Critical). This timing may be appropriate because instituting Mission System Change Control Board (MCCB) control of the scripts too early may impede the flight system development process, but very late initiation of formal control may result in excessive software iterations and may compromise test-as-you-fly fidelity or test procedure accuracy. The solution proven on several recent spaceflight projects is to institute change management of flight scripts prior to Operational Readiness Test (ORT). The Orbiting Carbon Observatory (OCO) project found that the process of flight script development continued for too long (Reference (1)). Given the multiple script authors and the potential impact of changes, the Flight Operations Team should have been in control of the scripts prior to the start of mission rehearsals (i.e., ORT). The Mars Exploration Rover (MER) project should have placed more emphasis on management of the variety and the versions of flight scripts. Developers became accustomed to preparing scripts on their own computer, exchanging them with others, and independently making changes. Hence, the scripts that were run out of home directories were not always sourced in a dependable way to MER workstations. With different versions of scripts found on different workstations-- some of which would not work properly-- processes were not repeatable between workstations. Reference (2) may be a typical example. Because this caused operational issues for MER during Assembly, Test, and Launch Operations (ATLO, aka \"Integration & Test\"), a procedure was successfully implemented during ORTs in which these scripts were delivered to CM, installed on Mission Support Environment workstations, and notification sent to Flight Operations Team support personnel. Accordingly, procedures for the Juno (Reference (3)) and GRAIL (Reference (4)) projects place Class B, Class C, and Class D software under configuration control prior to ORTs. References: P.J. Guske, \"OCO (Orbiting Carbon Observatory) Project Lessons Learned Document (Final),\" JPL Document No. D-26172, July 7, 2009, Paragraph 3.2.5. \"Confusion with upper and lower case letters,\" JPL Problem\/Failure Report No. Z77058, August 7, 2002. \"Juno Project: Mission System Configuration Management Plan, Preliminary Release,\" JPL Document No. D-49338, September 30, 2009, Paragraph 5.6, Page 18. https:\/\/pdms.jpl.nasa.gov\/CMTOOLS\/DocProperties.aspx?objid=tjEvitaempirepdmpdsu-Wqi \"Grail Project Software Management Plan,\" JPL Document No. D-38908, October 9, 2008. http:\/\/charlie-lib.jpl.nasa.gov\/docushare\/dsweb\/Get\/Document-280353\/GRAIL_D38908_Initial_2008-10-09.doc","Lesson ID":2476}
{"Driving Event":"(Relevant Historical Lesson(s) Learned) During the fabrication of the Television Infrared Observation Satellite (TIROS-N) Microwave Sounding Unit, fluids used to clean chassis mounted connector penetrated around and through the connectors to the interior of the chassis causing severe swelling of the conformal coating material and the subsequent fracture of electronic components, dissolution of polyurethane insulation on magnet hookup wire and removal of component identification markings. Additional Keyword(s): Connector Cleaning, Polymers Reference(s): PFR #2649","Lesson ID":430}
{"Driving Event":"Aquarius is a satellite project managed by the NASA\/Caltech Jet Propulsion Laboratory designed to measure variations in global sea surface salinity for Earth climate studies. The primary instrument components, the Radiometer and the Scatterometer, share a single antenna subsystem that includes a 2.5-meter diameter reflector (Figure 1). The Aquarius reflector was damaged during acoustic testing in the JPL acoustic test chamber (Figure 2) on May 23, 2007 (References (1) and (2)). The specific acoustic test that resulted in the over-test incident was Test Run #4, which had planned test level settings of -12dB, -9dB, and -6dB (from the quotfullquot or 0 decibel sound pressure level). The run was aborted by the system during the first (-12dB) run when the sound pressure exceeded limits. Figure 1. Drawing of Aquarius instrument................. (Reflector depicted at top of image.) Figure 2. Test article suspended in the acoustic chamber prior to test. For the acoustic tests, JPL served as the facility operator, and the reflector contractor performed the role of test conductor (as part of their qualification program). Nominal results were obtained from a pre-test of the empty acoustic chamber at the 0 dB level, and also from Test Run #1. Test Run #2 produced an anomaly with the control microphones, but the test conductor decided to proceed to Test Run #3 with further changes to critical control parameters from those recommended by the vendor of the acoustic control software (controller). The anomaly troubleshooting and control parameter change was improperly performed because the flight hardware remained in the test chamber. During Test Run #3, the -9 dB run was aborted by the controller software after 7 seconds. A decision was made to increase the compression rate so acoustic levels would come up slower and better enable the controller. However, the final test-- Test Run #4 at -12 dB-- was manually aborted after a 2-second over-test. Visual inspection of the reflector assembly indicated 9 areas of damage around the periphery of the reflector (Figure 3). The damage apparently resulted during Test Run #4 when the acoustic chamber turned on at itsquotfullquot level (>155dB), which was significantly higher than the 0 decibel level intended for this reflector. This sound pressure level massively over-tested the reflector, and a replacement reflector had to be procured at a cost of approximately $2M. Figure 3. Extent of damage to Aquarius reflector. The cause of the over-test incident was attributed to anomalous behavior of the acoustic test facility due to a deviation from the normal JPL acoustic test procedure (Reference (3)). The test operator accidentally pressed the quotrunquot button on the controller prematurely while adjusting control system displays. The initiation of the data recorder and gas turn-on alerted the operator that the system had entered quotrunquot mode, so he pressed thequotstandbyquot button. The operator then executed the missed steps in the test procedure and then purposely pressed thequotrunquot button again. The test personnel recognized the incipient over-test condition by the sound level, and the operator pressed the quotabort.quot Subsequent investigation showed that the controller did not perform the expected safing checks and responses to protect the test article after the operator failed to follow the correct procedure (Reference (4)). In addition, the controller software used in the JPL test facility had not been upgraded to the most recent version (Reference (5)), and subsequent mishap simulations with updated software successfully triggered the Test Run #4 abort. References: quotAquarius Reflector Damage - Acoustic Environment,quot JPL Problem\/Failure Report No. 6277, May 24, 2007. quotAquarius Reflector Acoustic Testing,quot JPL Problem\/Failure Report No. 6412, June 28, 2007. quotAQUARIUS Radar Reflector Incident, Special Review Board (SRB) Briefing, Rev. 2,\" July 12, 2007. quotMishap Safety Alert 1 - Abort Feature of the Acoustic Chamber Control System Software,quot Aquarius Reflector Mishap Investigation Board, December 6, 2007. quotMishap Safety Alert 2 - Outdated Version of the [vendor\/product name redacted] Acoustic Control Software,quot Aquarius Reflector Mishap Investigation Board, December 6, 2007.","Lesson ID":2419}
{"Driving Event":"Passivation is a phenomenon that can affect the performance of lithium batteries. Under no-load conditions, a passivation layer of lithium chloride (LiCl) forms on the surface of the lithium anode and protects the cells from discharging. This effect is responsible for the battery\u00bbs long shelf life, but the high resistance of the passivation layer may cause the cell's voltage to dip during use when a load is applied. As the battery discharges, the passivation layer dissipates and allows the cell to reach a peak voltage value. Passivation increases along with time and temperature; if the circuit cannot accommodate a voltage delay, the battery pack should be depassivated prior to use. [D] A simulated brownout during testing of the Entry, Descent, and Landing (EDL) flight software caused repetitive rebooting of the Mars Exploration Rover (MER) flight computer. A drop in the bus voltage during the simulated transition from the solar arrays to the primary batteries in the MER Lander caused the software to erroneously assume that the batteries had failed. The Lander contains five primary (non-rechargeable) lithium sulfur dioxide (LiSO2) batteries to support EDL and initial landed operations. The problem was traced to a passivation layer inhibiting the Lander batteries from producing full power during the transition (Reference (1)). Neither the MER circuit design nor the in-flight battery management procedures allowed for an initial output from the primary batteries (about 25 volts) that was significantly less than the 30-volt bus voltage. (Passivation is not usually a concern for secondary (rechargeable) spacecraft batteries because they are in continuous use.) A similar brownout during a mission critical event, such as EDL, could cause power on reset (POR) transients leading to corrupted memory, repeated reboots, and possible loss of mission. References: Jet Propulsion Laboratory (JPL) Problem\/Failure Report No. Z79633, February 28, 2003. Additional Key Words: battery passivation, battery depassivation, RAD6000, VME, battery chemistry, power\/pyro subsystem","Lesson ID":1410}
{"Driving Event":"During the Flight 2A (STS-88) mission, the crew was required to install rack pivot pins on the starboard re-supply\/stowage rack (RSR). During the operation, the mid-bay pivot pin wedge\/fitting assembly on the forward pivot pin was pushed through behind the rack resulting in lost hardware inside the ISS Node (refer to ISS PRACA PR# 1000). A setscrew on the track that receives the pivot pin wedge\/fitting assembly was not installed because the RSR was installed before the setscrew was installed. The purpose of the setscrew was to prevent such a loss. Because the setscrew could not be installed without removing the RSR, the assembly order could not be completed and the engineering was revised to delete the setscrew. MOD was informed of the deletion and advised that the crew would have to hold onto the wedge\/fitting assembly when loosing the bolt on the assembly for installation of the pivot pin. Root cause: MOD procedures included a warning to the crew to hold onto the pivot wedge\/fitting assembly while loosing the bolt, however, the format of the procedure was such that the warning was included after the step that loosened the bolt and wound up an the following page. As a result the crew did not see the warning until too late.","Lesson ID":1204}
{"Driving Event":"Two Command and Data Simulator (CADS) checkout computers located in the CADS room are attached to dedicated UPSs. During Space Shuttle Main Engine (SSME) validation, the UPS for the second CADS computer (GSE for SSME testing) was not functioning. This second CADS computer was a backup and had not been used for 2 years. Review of technical specifications revealed that the UPS batteries require full recharge cycling every 6 months in order to keep the batteries from discharging beyond the safe limit. Procedures to perform this maintenance were not in place.","Lesson ID":3762}
{"Driving Event":"Potential for X-38 Design Knowledge Transfer will be Inadequate When Contractor Selected to Build the Crew Return Vehicle (CRV)","Lesson ID":1167}
{"Driving Event":"After every launch, personnel are required to climb out and balance on the liquid hydrogen external tank vent line to remove blast covers. After launch, the vent line is covered with a mixture of solid rocket booster residue and sound suppression water, thus making it very dangerous to climb on the line to remove blast covers. The location under the vent line is a 20-foot unprotected drop. Personnel could fall and\/or drop the heavy blast shield cover during the installation\/removal process.","Lesson ID":166}
{"Driving Event":"Platforms 11A-1 and 11A-6 were retracted to support payload bay door opening. The platforms were not able to be extended for personnel access in support of aft propulsion system pod activities due to an interference when the orbiter payload bay doors were being cycled open and closed. Contact due to interference may cause damage to the payload bay doors and orbiter or personnel may be injured.","Lesson ID":158}
{"Driving Event":"The Mariner '69 Scan Platform and the Viking Orbiter Imaging Instrument Filter Wheel were operated with relative position stepping commands. In both cases, anomalies caused actual position to become different than the desired position. Because each new position selection is based upon the previous position, all post-anomaly positions were incorrect until corrected via ground based interaction. This resulted in loss of science data. Additional Keyword(s): Design, Operations","Lesson ID":279}
{"Driving Event":"This Lesson Learned is based on Maintainability Technique number PM-4 from NASA Technical Memorandum 4628, Recommended Techniques for Effective Maintainability. In the past, preventive maintenance was performed without any guidance or regard for safety or cost concerns, as long as systems performed their functions. The primary reason for the development of RCM was to implement a preventive maintenance strategy that could adequately address system availability and safety at the lowest possible cost. The RCM process answers and directs preventive maintenance decisions as to the what, where, and when types of questions. Introduction In the past, product development and manufacturing engineering dominated the technical disciplines in the U.S. industrial community with operations and maintenance (O&M) taking a lower priority to corporate success strategies. This priority has dramatically shifted to the point that O&M is now on a par with the development and manufacturing disciplines. Concerns about maintenance and logistics costs caused this shift in priority. A valid question is how to get maximum use of resources committed to the preventive maintenance program. This technique discusses preventive maintenance and defines RCM as part of an effective preventive maintenance program. Some cost-benefit considerations realized through the use of RCM are also illustrated. Introduction to Preventive Maintenance The majority of systems have long been operating in the corrective maintenance mode. Corrective maintenance is the performance of and almost total commitment of resources to unplanned or unexpected maintenance tasks. Preventive maintenance, however, is the pre-planning of inspection and\/or servicing tasks. Corrective approaches restore the functional capabilities of failed or malfunctioning equipment or systems. However, corrective maintenance is more costly than preventive maintenance because of the unplanned interruptions of operations, idle time waiting for spare parts, and haphazard troubleshooting for failure causes. Preventive Maintenance Program In general, when creating a new or upgrading an existing preventive maintenance program, two items of essential information are required: (1) identification of what preventive maintenance tasks are to be performed and (2) when each task should be performed (see Figure 1). [D] Whatever method is used to determine what or if a task is to be performed results in a time-directed, condition-directed, or failure-finding task selection or a run-to-failure decision (as defined above). The next step is to incorporate the preventive maintenance program into the existing operations infrastructure and to ensure that it is implemented in everyday operations. Moreover, a series of questions must be answered before any program can be implemented. Typically, such questions might include the following: Are new procedures or modifications to existing procedures required? Are all the standard materials (tools, filters, etc.) available? Is any special tooling or instrumentation required? Are an appropriate number of people available to conduct the program? Are any capital investments required? Will the new\/upgraded program affect the quantity of on-hand spares required? How long will it take to incorporate the new\/upgraded program into the maintenance management information system (MMIS)? Is the existing MMIS capable of accepting the entire new\/upgraded program (e.g., tracking time sequenced data in condition-directed tasks)? If full shutdown must be periodically planned, do the tasks and task intervals lend themselves to such a schedule? Do new tasks require a cycle that is a common denominator with other existing task intervals? Preventive Maintenance Program Elements Figure 1 is a simplified illustration of a preventive maintenance program development. Many supporting management and technical disciplines are involved in the development of the ideal preventive maintenance program and task packaging, and they are important in supporting the RCM concept that is discussed later in this technique. The important supporting technologies used in the development process are described below. A product malfunction or failure can present a significant learning opportunity in that much technical knowledge can be gained from comprehensive failure reporting, root cause analysis, and corrective action feedback programs. Without such programs, it is virtually impossible to establish proper corrective action or to intelligently decide if any preventive maintenance action is possible. A good failure reporting system is vital to the quotretain or increase mean-time between failuresquot portion of an availability improvement program. To prudently employ condition-directed tasks requires an entire diagnostic technology that is still evolving with new techniques and applications. The technology is dedicated to following, understanding, and contributing to the area generally referred to as quotpredictive maintenance technology.quot Some of the tools that comprise predictive maintenance technology are as follows: Vibration, pulse, and spike energy measurement. Acoustic leak detection. Thermal imaging. Fiber optic inspection. Trace element sensing. Debris analysis. Lubricant analysis. Stress\/strain\/torque measurement. Nonintrusive flow measurement. Microprocessors with expert system software. Preventive Maintenance Task Packaging This task consists of three major elements: Task Specification. The task specification provides complete technical definition and direction of specific requirements to the implementing maintenance organization. This document, which is the key transition from the ideal to the real world, either (1) details the data measurement and evaluation requirements for a condition-directed task along with the limiting acceptance criteria or (2) specifies critical requirements that must be met in a time-directed overhaul task. Procedure. The procedure is a basic document that guides the execution of a preventive maintenance task. The document may be a one page instruction for a simple task or complex details on precisely how the preventive maintenance task is to be achieved. Logistics. The logistics entail a variety of administrative and production support activities. Typical logistic considerations include tooling, spare parts, vendor support, training, documents and drawings, make\/buy decisions, test equipment, scheduling, etc. Clearly, these considerations closely interplay with both the task specification and procedure and constitute a major portion of maintenance planning. In summary, a preventive maintenance program can be created or upgraded by implementing the ideas given above. With the support of key technologies, it will produce the quotwhat taskquot and quotwhen donequot information. Reliability Centered Maintenance (RCM) As conveyed above, the objective of most of the current preventive maintenance practices is to preserve equipment operation. Until recently, this has resulted in little, if any, consideration as to why certain preventive maintenance actions and are taken and what priority should be assigned to the expenditure of preventive maintenance resources. Almost without fail, maintenance planning starts with the equipment and seeks to specify as quickly as possible those components necessary to keep it running. RCM is not just another approach to this repetitive process. The basic RCM concept is really quite simple and might be characterized as organized engineering common sense. The features that define and characterize RCM and set it apart from any other preventive maintenance planning processes in use today are described below. Preserves System Function. Unlike the ingrained notion that preventive maintenance is performed to preserve equipment operation, the primary objective of RCM is to preserve system function. Although equipment preservation leads ultimately to system preservation, it is not the initial step in the RCM process. In RCM, the expected output is known, and preserving that output or function is the primary task. This feature enables systematic decisions in later stages of the process as to just what equipment relates to that function and does not assume a priori that quotevery item of equipment is equally important,quot a tendency that seems to pervade the current preventive maintenance approach. Identifies Failure Modes That Can Produce Unwanted Functional Failures. After preserving system function, avoiding loss of function or functional failure is the next item of RCM consideration. Functional failures take many forms and may occur in various stages, all of which must be considered. The loss of fluid boundary integrity is a functional failure that illustrates this point. A system loss of fluid can be caused by (1) a minor leak that may be qualitatively defined as a drip; (2) a leak defined as a design basis leak (any loss beyond a certain gallon per minute value will produce a negative effect on system function); or (3) a total loss of boundary integrity, which can be defined as a catastrophic loss of fluid and loss of function. In this example, a single function could lead to three distinct functional failures. The key to the failure identification feature is to identify the specific failure modes in specific components that can potentially produce those unwanted functional failures. Enables Prioritization of Failure Modes. In preserving system function, RCM provides a systematic approach to deciding what priority must be assigned to budget and resource allocations. Since functional failures and their related failure modes are as diverse as the functions and components they affect, the prioritization of failure modes is essential. Allows Preventive Maintenance Tasks To Be Judged As To Applicability and Effectiveness. The features described above help in developing a very specific roadmap to the where and why, of the maintenance task and the priority that should be assigned to it. Each potential task must then be judged as to (1) its applicability (i.e., will it prevent or mitigate a failure, detect the onset of a failure, or discover a hidden failure) and (2) its effectiveness (i.e., does it justify the spending of resources to do it). Generally, if more than one candidate task is judged to be applicable and effective, the least expensive task will be selected. If a task fails either the applicability or effectiveness test, a run-to failure decision must be made. Cost-Benefit Considerations. The primary force behind the invention of RCM was the need to develop a preventive maintenance strategy that could adequately address system availability and safety without creating a totally impractical cost requirement. Figure 2 illustrates the success of keeping commercial aircraft maintenance cost per flight hour constant from the late 1960's to the early 1980's. [D] Table 1 presents another way to view the impact of RCM on the commercial aircraft world. [D] Two significant points can be observed from these data: (1) the dramatic shift in the reduction of costly component overhauls during the pre-1964 and post-1960\/1987 periods; and (2) the constancy of the condition-directed task structure. The reduction in expensive component overhauls, brought about by run-to-failure decisions, was made possible by a design philosophy that included double and triple structural design redundancy in the flight-critical functions. RCM was used to take advantage of these structural design features when preventive maintenance was critical and the run-to-failure decision was appropriate. The constancy of the condition-directed task structure is attributed to the fact that the commercial aircraft industry was one of the early users of performance and diagnostic monitoring as a preventive maintenance tool. It has continued to successfully apply this practice throughout the generation of the newer jet aircraft. The results indicated in figure 2 and table 1 have led to a growing interest in other such areas as nuclear power generation and electric utility plants. The obvious reasons for this growing interest are (1) control and reduction of O&M costs and (2) increase in plant availability. All of this indicates that the cost-reduction benefits of RCM that dramatically impacted commercial aviation offer similar potential dramatic payoffs in other areas in which complex plants and systems are routinely operated. Conclusion RCM is a logical approach to preventive maintenance which does not rely on any heuristic processes. RCM helps in making direct and deliberate preventive maintenance decisions that were not previously possible. It can also be used as the methodology for defining preventive maintenance for a such new systems as the Space Station. Virtually every organization that has conducted an RCM program has recognized the value of the system analysis process as a training ground for system engineers. In addition, the failure scenarios developed in RCM analyses may be used beneficially as simulator inputs to plant transient or upset conditions in order to anticipate such occurrences in the future. References Annual Reliability and Maintainability Symposium, 1991 Proceedings. Matteson, Thomas D., quotThe Origin of Reliability-Centered Maintenance,quot Proceedings of the Sixth International Maintenance Conference, Institute of Industrial Engineers, October 1989. quotReliability-Centered Maintenance for Aircraft Engines and Equipment,quot MIL-STD-1843, February 8, 1985. quotRCM Cost-Benefits Evaluation,quot Electric Power Research Institute, Interim EPRI Report, January 1992.","Lesson ID":891}
{"Driving Event":"This Lesson Learned is based on Reliability Practice number PT-TE-1404, from NASA Technical Memorandum 4322A, Reliability Preferred Practices for Design and Test. This test, coupled with rigorous design practices, provides high confidence that the hardware design is not marginal during its intended long life high reliability mission. Establish a minimum hardware test temperature level range of -20\u00b0C \/ +75\u00b0C and specify that a single cycle thermal dwell test be performed for the appropriate durations (24 hours cold and 144 to 288 hours hot). In the early 1960s, JPL adopted a conservative set of thermal design and test temperature levels to demonstrate hardware design adequacy. As a starting point, a reasonable short term flight temperature excursion (+5\u00b0C to +50\u00b0C) was established for thermal control surfaces (shearplates). The +5\u00b0C lower level is a few degrees Celsius above the freezing point of hydrazine, thus integrated thermal control of bus electronics and propulsion systems is possible. The 50\u00b0C upper limit is the approximate level reached by a louvered bus electronics bay after about one hour of full (perpendicular) solar irradiance at one A.U. (astronomical unit) and accommodates near earth maneuvers. The long term desired thermal control range is typically 25\u00b15\u00b0C, but this range may be broader depending on the tradeoffs of long term reliability and thermal control costs. This original approach reduced the overall complexity of the system thermal control design process: the wide range reduced the sensitivity to louver\/radiator size, heater size, power variations, etc. A margin of \u00b125\u00b0C was then applied to the allowable flight range for qualification and protoflight test levels of assemblies mounted to such thermal control surfaces. These levels accommodate thermal compromises in the design where the short term extremes may be approached during steady state operation; they also have been demonstrated to provide an effective screen of assemblies. This resulted in the JPL standard minimum test range of -20\u00b0C to +75\u00b0C (for electronic assemblies in particular). These conservative test level ranges lead to several desirable features. The conservative high temperature limit restricts the permitted temperature rise from the shearplate to the junction of electronic piece parts. Thus junction temperatures during the bulk of a mission are much cooler than assemblies designed and tested at lower shearplate temperatures. The increase in theoretical reliability is on the order of a factor of 10 per 25\u00b0C. (refer to quotPart junction Temperaturequot, Reliability Preferred Practice No. PD-ED-1204) There are at least two failure mechanisms for both design and workmanship that should be screened by an adequate thermal environmental test of any given assembly. The first is based on Arrhenius rate related physics where time at high temperature is the key to demonstrating reliability during testing. Electronic part life is a prime example of an Arrhenius mechanism, but so are other elements of assemblies including interactions between metal traces within printed wiring boards (PWB's), certain component to board joints, and even solder joints to a certain extent. The other identifiable mechanism is thermally induced mechanical stress (including fatigue) as between components and the board and especially solder joints. Arrhenius Rate Physics: Contrast the test level of 75\u00b0C (shearplate) to 50\u00b0C short term worst case transients during flight and 25\u00b0C for the bulk of the mission. Based on Arrhenius reaction rate physics described in the following figures, the 75\u00b0C test provides a demonstrated reliability some 2 to 8 times that of short transients to 50\u00b0C, (typical of thermal cycling tests), and some 4 to 94 times that of long term mission shearplate temperatures (25\u00b0C). These reliability ratios are based on activation energies of 0.3 eV to 1.0 eV which cover most assembly element reaction physics. [D] [D] The Mariner and Viking spacecraft performed a hot dwell test (75\u00b0C) of 288 hours duration. This was reduced to 144 hours for the Voyager and Galileo spacecraft. The statistical database supporting this shorter test is unique to the JPL design rules and processes; therefore, the longer hot dwell duration of 288 hours is recommended for assemblies designed to non-equivalent or less conservative practices. The following figure shows the percentage of the screening test capability for Class S parts that is used by a JPL assembly test at 75\u00b0C for 144 hours. A very conservative assumption here is that all parts in the assembly test have a 35\u00b0C temperature rise and that they are at 110\u00b0C for the entire test. Even given this over-conservative assumption, the JPL test uses only 0.018% of the class S parts minimum screened capability. Clearly less than 2\/10000's of the minimum parts capability being dedicated to the assembly protoflight test is not a concern. The parts are not over-stressed by this test. [D] Thermally Induced Mechanical Stress (Fatigue): JPL has historically done a thermal dwell test rather than a specific thermal cycle test. There are data that indicate thermal cycling uses up hardware life and therefore is degrading to the flight hardware. In practice, the JPL test approach is never really just a one-cycle dwell test. The assembly test program (plus any retest) and the systems test program (frequently two phases) result in a minimum of two cycles and as many as four (or more) are possible although they are not continuous and the transients are controlled to < 30\u00b0C\/hr to prevent thermal shock. The Voyager hardware was tested as follows: [D] In a recent JPL study, a fatigue life relationship of equivalent thermal cycles was determined over different temperature ranges as follows: [D] where: C 1 is the number of thermal cycles over a T 1 range C 2 is the number of thermal cycles over a T 2 range and Y = 2.6 for eutectic solder. As a frame of comparison for workmanship purposes, the JPL protoflight test of 1 cycle over -20\/75\u00b0C range can be correlated to an acceptance test of 6 cycles over a 0\/50\u00b0C range. In this case: C1 = 1, T1 = 95\u00b0C, C2 = TBD, T2 = 50\u00b0C and the equivalent cycles of the JPL test are: C2 = 1(95\u00b0C\/50\u00b0C)2.6 = 5.3 cycles. Therefore, in terms of solder joint fatigue life, the JPL protoflight test equivalency to 5.3 cycles over a 50\u00b0C range says that, for workmanship acceptance purposes, the JPL protoflight test is essentially the same as the example thermal cycle acceptance test, i.e., 5.3 equals approximately 6 cycles. The following figure provides comparison of solder joint fatigue life. The recommended -20\/+75\u00b0C single cycle dwell test uses only 0.14% of the fatigue life of a solder joint qualified to NHB 5300.4 (3A-1). The point of this comparison is that the JPL protoflight test is less strenuous to solder joints than thermal cycle testing performed by most organizations. [D] Ground Test & Thermally Related Problem\/Failure Statistics: These practices were applied to the Mariner spacecraft series, the two Viking 75 spacecraft, the two Voyager 77 spacecraft, and more recently Galileo. These spacecraft all completed (or exceeded) their intended mission successfully (the Galileo mission is still underway at the time of this edition). In fact, the Voyager spacecraft have worked for over 13 years. The total number of assembly problems\/failures during these missions is small, and the number of thermally induced problems even smaller. This is shown in the following table where the number of problem\/failures identified during assembly level thermal testing are compared with suspected flight problems\/failures for the Viking, Voyager, and Galileo programs: [D]","Lesson ID":783}
{"Driving Event":"During dimensional inspection of orbital tube welds involving 316L tubing, it was found that 8 of 8 welds failed because of weld mismatch. The weld joints were located between two bends that formed a \"S\" bend. There was approximately 1 inch of straight tubing from each bend to the joint of the weld. The mismatch in this case is not to exceed 25% or 0.010 inch which ever is less. Root cause: Tube bending \/ shaping typically causes the tube to take an oval shape, creating matching problems during weld fitting. Engineering drawings provided insufficient length for oval \/ runout to occur of the shaped \/ bent tube prior to welding of the joint.","Lesson ID":1230}

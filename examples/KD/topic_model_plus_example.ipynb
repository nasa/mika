{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Model Plus Example\n",
    "\n",
    "This example goes over topic model plus and includes steps for performing:\n",
    "\n",
    "- LDA topic modeling\n",
    "- hLDA topic modeling\n",
    "- BERTopic modeling\n",
    "\n",
    "First, we load our data, in this case the ICS-209-PLUS data set, filter it, then set up our topic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(\"..\",\"..\"))\n",
    "\n",
    "from mika.kd import Topic_Model_plus\n",
    "from mika.utils import Data\n",
    "from mika.utils.stopwords.ICS_stop_words import stop_words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic import BERTopic\n",
    "import os\n",
    "import pandas as pd \n",
    "\n",
    "ICS_stop_words = stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing Incomplete Rows…: 100%|██████████| 120804/120804 [01:22<00:00, 1462.63it/s]\n",
      "Creating Unique IDs…: 100%|██████████| 37350/37350 [00:01<00:00, 20368.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data preparation:  1.43 minutes \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sentence Tokenization…: 100%|██████████| 26397/26397 [00:37<00:00, 703.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# load data for BERTopic\n",
    "ICS_data = Data()\n",
    "file_name = os.path.join('..','..','data','ICS','ics209-plus-wf_sitreps_1999to2014.csv')\n",
    "text_columns = [\"REMARKS\", \"SIGNIF_EVENTS_SUMMARY\", \"MAJOR_PROBLEMS\"]\n",
    "document_id_col = \"INCIDENT_ID\"\n",
    "ICS_data.load(file_name, id_col=document_id_col, text_columns=text_columns, load_kwargs={'dtype':str})\n",
    "ICS_data.prepare_data(create_ids=True, combine_columns=text_columns, remove_incomplete_rows=True)\n",
    "ICS_data.text_columns = ['Combined Text']\n",
    "save_words = ['jurisdictions', 'team', 'command', 'organization', 'type', 'involved', 'transition', 'transfer', 'impact', 'concern', 'site', 'nation', 'political', 'social', 'adjacent', 'community', 'cultural', 'tribal', 'monument', 'archeaological', 'highway', 'traffic', 'road', 'travel', 'interstate', 'closure', 'remain', 'remains', 'close', 'block', 'continue', 'impact', 'access', 'limit', 'limited', 'terrain', 'rollout', 'snag', 'steep', 'debris', 'access', 'terrian', 'concern', 'hazardous', 'pose', 'heavy', 'rugged', 'difficult', 'steep', 'narrow', 'violation', 'notification', 'respond', 'law', 'patrol', 'cattle', 'buffalo', 'grow', 'allotment', 'ranch', 'sheep', 'livestock', 'grazing', 'pasture', 'threaten', 'concern', 'risk', 'threat', 'evacuation', 'evacuate', ' threaten', 'threat', 'resident', ' residence', 'level', 'notice', 'community', 'structure', 'subdivision', 'mandatory', 'order', 'effect', 'remain', 'continue', 'issued', 'issue', 'injury', 'hospital', 'injured', 'accident', 'treatment', 'laceration', 'firefighter', 'treated', 'minor', 'report', 'transport', 'heat', 'shoulder', 'ankle', 'medical', 'released', 'military', 'unexploded', 'national', 'training', 'present', 'ordinance', 'guard', 'infrastructure', 'utility', 'powerline', 'water', 'electric', 'pipeline', 'powerlines', 'watershed', 'pole', 'power', 'gas', 'concern', 'near', 'hazard', 'critical', 'threaten', 'threat', 'off', 'weather', 'behavior', 'wind', 'thunderstorm', 'storm', 'gusty', 'lightning', 'flag', 'unpredictable', 'extreme', 'erratic', 'strong', 'red', 'warning', 'species', 'specie', 'habitat', 'animal', 'plant', 'conservation', 'threaten', 'endanger', 'threat', 'sensitive', 'threatened', 'endangered', 'risk', 'loss', 'impacts', 'unstaffed', 'resources', 'support', 'crew', 'aircraft', 'helicopter', 'engines', 'staffing', 'staff', 'lack', 'need', 'shortage', 'minimal', 'share', 'necessary', 'limited', 'limit', 'fatigue', 'flood', 'flashflood', 'flash', 'risk', 'potential', 'mapping', 'map', 'reflect', 'accurate', 'adjustment', 'change', 'reflect', 'aircraft', 'heli', 'helicopter', 'aerial', 'tanker', 'copter', 'grounded', 'ground', 'suspended', 'suspend', 'smoke', 'impact', 'hazard', 'windy', 'humidity', 'moisture', 'hot', 'drought', 'low', 'dry', 'prolonged']\n",
    "# filter data\n",
    "file = os.path.join('..','..','data','ICS','summary_reports_cleaned.csv')\n",
    "filtered_df = pd.read_csv(file, dtype=str)\n",
    "filtered_ids = filtered_df['INCIDENT_ID'].unique()\n",
    "ICS_data.data_df = ICS_data.data_df.loc[ICS_data.data_df['INCIDENT_ID'].isin(filtered_ids)].reset_index(drop=True)\n",
    "ICS_data.doc_ids = ICS_data.data_df['Unique IDs'].tolist()\n",
    "# save raw text for bertopic\n",
    "raw_text = ICS_data.data_df[ICS_data.text_columns]\n",
    "ICS_data.sentence_tokenization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for LDA and hLDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data for LDA/hLDA\n",
    "\n",
    "file = os.path.join('..','..','data','ICS','ICS_filtered_preprocessed_combined_data.csv')\n",
    "ICS_data_processed = Data()\n",
    "ICS_data_processed.load(file, preprocessed=True, id_col='Unique IDs', text_columns=['Combined Text'], name='ICS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate topic model plus object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICS_tm = Topic_Model_plus(text_columns=['Combined Text Sentences'], data=ICS_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERTopic \n",
    "\n",
    "To use BERTopic in MIKA, you can define:\n",
    "\n",
    "- a vectorizor model, which creates ngrams while excluding stopwords\n",
    "- seed topics\n",
    "\n",
    "One key difference between MIKA and the base BERTopic is that MIKA has a from_probs argument that allows users to assign topics to documents based on a probability threshold, whereas traditional BERTopic only assigns one topic to each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "total_stopwords = stopwords.words('english')+ICS_stop_words\n",
    "vectorizer_model = CountVectorizer(ngram_range=(1, 3), stop_words=total_stopwords) #removes stopwords\n",
    "seed_topic_list = [['highway', 'traffic', 'road', 'travel', 'interstate', 'closure', 'remain', 'remains', 'close', 'block', 'impact', 'access', 'limit', 'limited'], \n",
    "                    ['transition', 'transfer'], \n",
    "                    ['evacuation', 'evacuate',], \n",
    "                    ['mapping', 'map', 'reflect', 'accurate', 'adjustment', 'change', 'reflect', 'inaccurate'], \n",
    "                    ['aerial','inversion', 'suspend', 'suspendsion', 'prohibit', 'delay', 'hamper', 'unable', 'cancel', 'inability', 'loss', 'curtail', 'challenge', 'smoke'], \n",
    "                    ['unstaffed', 'resource', 'lack', 'need', 'shortage', 'minimal', 'share', 'necessary', 'limited', 'limit', 'fatigue'], \n",
    "                    ['injury', 'hospital', 'injured', 'accident', 'treatment', 'laceration', 'firefighter', 'treat', 'minor', 'report', 'transport', 'heat', 'shoulder', 'ankle', 'medical', 'release'], \n",
    "                    ['cultural', 'tribal', 'monument', 'archaeological', 'heritage', 'site', 'nation', 'political', 'social', 'adjacent', 'community'], \n",
    "                    ['cattle', 'buffalo', 'allotment', 'ranch', 'sheep', 'livestock', 'grazing', 'pasture', 'threaten', 'concern', 'risk', 'threat', 'private', 'area', 'evacuate', 'evacuation', 'order'], \n",
    "                    ['violation', 'arson', 'notification', 'respond', 'law'], \n",
    "                    ['military', 'unexploded', 'training', 'present', 'ordinance', 'proximity', 'activity', 'active', 'base', 'area'], \n",
    "                    ['infrastructure', 'utility', 'powerline', 'water', 'electric', 'pipeline', 'powerlines', 'watershed', 'pole', 'power', 'gas'], \n",
    "                    ['weather', 'behavior', 'wind', 'thunderstorm', 'storm', 'gusty', 'lightning', 'flag', 'unpredictable', 'extreme', 'erratic', 'strong', 'red', 'warning', 'warn'], \n",
    "                    ['species', 'habitat', 'animal', 'plant', 'conservation', 'threaten', 'endanger', 'threat', 'sensitive', 'risk', 'loss', 'impact'], \n",
    "                    ['terrain', 'rollout', 'snag', 'steep', 'debris', 'access', 'concern', 'hazardous', 'pose', 'heavy', 'rugged', 'difficult', 'steep', 'narrow'], \n",
    "                    ['humidity', 'moisture', 'hot', 'drought', 'low', 'dry', 'prolong']]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6b5f33bc7743d5b4d52b714f9401b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6583 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 09:11:58,268 - BERTopic - Transformed documents to Embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e047d3d3b184c29b04eca7f2f397423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 09:23:08,908 - BERTopic - Reduced dimensionality\n",
      "2023-09-19 09:26:58,891 - BERTopic - Clustered reduced embeddings\n"
     ]
    }
   ],
   "source": [
    "BERTkwargs={\"seed_topic_list\":seed_topic_list,\n",
    "            \"top_n_words\": 20, \n",
    "            'min_topic_size':150}\n",
    "ICS_tm.bert_topic(count_vectorizor=vectorizer_model, BERTkwargs=BERTkwargs, from_probs=True)\n",
    "ICS_tm.save_bert_results(from_probs=True) #warning: saving in excel can result in missing data when char limit is reached\n",
    "ICS_tm.save_bert_topics_from_probs()\n",
    "#get coherence\n",
    "ICS_tm.save_bert_coherence(coh_method='c_v')\n",
    "ICS_tm.save_bert_coherence(coh_method='c_npmi')\n",
    "ICS_tm.save_bert_vis()\n",
    "ICS_tm.save_bert_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Topic Modeling\n",
    "\n",
    "LDA topic modeling is a wrapper for tomotopy (https://bab2min.github.io/tomotopy/v/en/) and requires preprocessed text. Users must specify the number of topics, while other arguments are optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICS_tm = Topic_Model_plus(text_columns=['Combined Text'], data=ICS_data_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Combined Text LDA…: 100%|██████████| 100/100 [01:40<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA:  1.7821103811264039  minutes\n"
     ]
    }
   ],
   "source": [
    "text_columns = [\"Combined Text\"]\n",
    "num_topics = {attr:50 for attr in text_columns}\n",
    "ICS_tm.lda(min_cf=1, num_topics=num_topics, min_df=1, alpha=1, eta=0.0001)\n",
    "ICS_tm.save_lda_results()\n",
    "ICS_tm.save_lda_models()\n",
    "for attr in text_columns:\n",
    "    ICS_tm.lda_visual(attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hLDA Topic Modeling\n",
    "\n",
    "hLDA topic modeling is a wrapper for tomotopy (https://bab2min.github.io/tomotopy/v/en/) and requires preprocessed text. Users must specify the number of levels in the hierarchical model, while other arguments are optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Combined Text hLDA…: 100%|██████████| 100/100 [1:32:36<00:00, 55.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hLDA:  92.72793128490449  minutes\n"
     ]
    }
   ],
   "source": [
    "ICS_tm.hlda(levels=3, eta=0.50, min_cf=1, min_df=1)\n",
    "ICS_tm.save_hlda_models()\n",
    "ICS_tm.save_hlda_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading existing models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERTopic\n",
    "\n",
    "Previously trained models can be loaded back into topic model plus for new inference or further training, using BERTopics load feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(r\"C:\\Users\\srandrad\\smart_nlp\\examples\\KD\\topic_model_resultsSep-19-2023\")\n",
    "ICS_tm = Topic_Model_plus(text_columns=['Combined Text Sentences'], data=ICS_data)\n",
    "ICS_tm.load_bert_model(model_path, reduced=False, from_probs=True)\n",
    "ICS_tm.save_bert_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hLDA/LDA\n",
    "\n",
    "Similarly, previously trained hLDA and LDA models can be loaded back into topic model plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_columns = [\"Combined Text\"]\n",
    "ICS_tm = Topic_Model_plus(text_columns=text_columns, data=ICS_data)\n",
    "ICS_tm.combine_cols = True\n",
    "filepath = os.path.join(\"topic_model_results\")\n",
    "ICS_tm.hlda_extract_models(filepath)\n",
    "ICS_tm.save_hlda_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MIKA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
